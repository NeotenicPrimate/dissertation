PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	C3	RP	EM	RI	OI	FU	FP	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	DL	D2	EA	PG	WC	WE	SC	GA	PM	OA	HC	HP	DA	UT
J	Bajcsy, R; Lee, SW; Leonardis, A				Bajcsy, R; Lee, SW; Leonardis, A			Detection of diffuse and specular interface reflections and inter-reflections by color image segmentation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							REFLECTANCE; CONSTANCY; VISION	We present a computational model and algorithm for detecting diffuse and specular interface reflections and some inter-reflections. Our color reflection model is based on the dichromatic model for dielectric materials and on a color space, called S space, formed with three orthogonal basis functions. We transform color pixels measured in RGB into the S space and analyze color variations on objects in terms of brightness, hue and saturation which are defined in the S space. When transforming the original RGB data into the S space, we discount the scene illumination color that is estimated using a white reference plate as an active probe. As a result, the color image appears as if the scene illumination is white. Under the whitened illumination, the interface reflection clusters in the S space are all aligned with the brightness direction. The brightness, hue and saturation values exhibit a more direct correspondence to body colors and to diffuse and specular interface reflections, shading, shadows and interreflections than the RGB coordinates. We exploit these relationships to segment the color image, and to separate specular and diffuse interface reflections and some inter-reflections from body reflections. The proposed algorithm is efficacious for uniformly colored dielectric surfaces under singly colored scene illumination. Experimental results conform to our model and algorithm within the limitations discussed.	UNIV MICHIGAN,DEPT ELECT ENGN & COMP SCI,ANN ARBOR,MI 48109; FAC ELECT ENGN & COMP SCI,LJUBLJANA 61001,SLOVENIA	University of Michigan System; University of Michigan	Bajcsy, R (corresponding author), UNIV PENN,DEPT COMP & INFORMAT SCI,GRASP LAB,PHILADELPHIA,PA 19104, USA.							BAJCSY R, 1989, COMPUTATIONAL ASPECT; BAJCSY R, 1990, P 10 INT C PATT REC; BECK J, 1967, SURFACE COLOR PERCEP; Beckmann Petr, 1987, SCATTERING ELECTROMA, P4; BLAKE A, 1985, P INT JOINT C ART IN, P973; Brelstaff G., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P297, DOI 10.1109/CCV.1988.590004; BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7; COHEN J, 1964, PSYCHON SCI, V1, P369, DOI 10.3758/BF03342963; COLEMAN E, 1982, COMP GRAPHICS IMAGE, V18, P308; DZMURA M, 1986, J OPT SOC AM A, V3, P1662, DOI 10.1364/JOSAA.3.001662; FORSYTH DA, 1988, P ICCV, V2, P9; FUNKALEA G, 1993, P IJCAI 93 FRANC; FUNT BV, 1991, COLOR SPACE ANAL MUT; GERSHON R, 1987, THESIS U TORONTO; HANSON AR, 1978, SEGMENTATION NATURAL; Healey G., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P10, DOI 10.1109/CVPR.1988.196210; HEALEY G, 1989, J OPT SOC AM A, P6; HEALEY GH, 1988, COMPUTER VISION GRAP, P42; Horn B., 1986, ROBOT VISION, P1; JEPSON AD, 1986, J OPT SOC AM A, V3, P1700; JUDD DB, 1964, J OPT SOC AM, P54; KANADE T, 1991, IEEE T PATTERN ANAL, V13, P609; LEE HC, 1986, J OPT SOC AM A, V3, P1694, DOI 10.1364/JOSAA.3.001694; LEE HC, 1990, IEEE T PATTERN ANAL, V12, P402, DOI 10.1109/34.50626; LEE SW, 1992, IMAGE VISION COMPUT, V10, P643, DOI 10.1016/0262-8856(92)90009-R; LEE SW, 1991, THESIS U PENNS; Leonardis A., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P121, DOI 10.1109/ICCV.1990.139508; MALONEY LT, 1986, J OPT SOC AM A, V3, P29, DOI 10.1364/JOSAA.3.000029; MALONEY LT, 1985, COMPUTATIONAL COLOR; NASSAU K, 1983, PHYSICS CHEM COLOR; Nayar S. K., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P2, DOI 10.1109/ICCV.1990.139482; NAYAR SK, 1990, IEEE T ROBOTIC AUTOM, V6, P418, DOI 10.1109/70.59367; NAYAR SK, 1991, IEEE T PATTERN ANAL, V13, P611, DOI 10.1109/34.85654; NAYAR SK, 1993, P DARPA IM UND WORKS, P1049; Novak C. L., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P599, DOI 10.1109/CVPR.1992.223129; NOVAK CL, 1990, SUPERVISED COLOR CON; NOVAK CL, 1991, CMUCS91203 CARN MELL; OHLANDER R, 1978, COMPUT VISION GRAPH, V8, P313, DOI 10.1016/0146-664X(78)90060-6; OREN MO, 1993, P DARPA IM UND WORKS, P1037; Park J.-S., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P331, DOI 10.1109/ICPR.1990.118125; SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409; SHAFER SA, 1990, INT J COMPUTER VISIO; TAGARE HD, 1990, P IEEE INT C COMP VI; TAGARE HD, 1991, IEEE T PAMI, P13; THOMAS Y, 1953, COLOR SCI; TOMINAGA S, 1990, J OPT SOC AM, P7; TOMINAGA S, 1989, J OPT SOC AM, P6; TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105; WANDELL BA, 1987, IEEE T PATTERN ANAL, V9, P2, DOI 10.1109/TPAMI.1987.4767868; WOLFF LB, 1989, JUN P IEEE C COMP VI, P363; WOLFF LB, 1993, P DARPA IMAGE UNDERS, P1025; WOLFF LB, 1991, THESIS COLUMBIA U; Wyszecki G., 1967, COLOR SCI	53	90	100	0	4	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	1996	17	3					241	272		10.1007/BF00128233	http://dx.doi.org/10.1007/BF00128233			32	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	UB510					2022-12-18	WOS:A1996UB51000002
J	Whyte, O; Sivic, J; Zisserman, A				Whyte, Oliver; Sivic, Josef; Zisserman, Andrew			Deblurring Shaken and Partially Saturated Images	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Non-blind deblurring; Saturation; Ringing; Outliers	ALGORITHM; CAMERA	We address the problem of deblurring images degraded by camera shake blur and saturated (over-exposed) pixels. Saturated pixels violate the common assumption that the image-formation process is linear, and often cause ringing in deblurred outputs. We provide an analysis of ringing in general, and show that in order to prevent ringing, it is insufficient to simply discard saturated pixels. We show that even when saturated pixels are removed, ringing is caused by attempting to estimate the values of latent pixels that are brighter than the sensor's maximum output. Estimating these latent pixels is likely to cause large errors, and these errors propagate across the rest of the image in the form of ringing. We propose a new deblurring algorithm that locates these error-prone bright pixels in the latent sharp image, and by decoupling them from the remainder of the latent image, greatly reduces ringing. In addition, we propose an approximate forward model for saturated images, which allows us to estimate these error-prone pixels separately without causing artefacts. Results are shown for non-blind deblurring of real photographs containing saturated regions, demonstrating improved deblurred image quality compared to previous work.	[Whyte, Oliver] Microsoft Corp, Redmond, WA 98052 USA; [Sivic, Josef] Ecole Normale Super, INRIA Willow Project Lab Informat, UMR 8548, CNRS,ENS,INRIA, Paris, France; [Zisserman, Andrew] Univ Oxford, Dept Engn Sci, Visual Geometry Grp, Oxford OX1 3PJ, England	Microsoft; Centre National de la Recherche Scientifique (CNRS); Inria; University of Oxford	Whyte, O (corresponding author), Microsoft Corp, Redmond, WA 98052 USA.	oliverw@microsoft.com; josef.sivic@ens.fr; az@robots.ox.ac.uk		Whyte, Oliver/0000-0002-7029-9410	MSR-INRIA laboratory; EIT ICT labs; ERC [228180]	MSR-INRIA laboratory; EIT ICT labs; ERC(European Research Council (ERC)European Commission)	This work was partly supported by the MSR-INRIA laboratory, the EIT ICT labs and ERC grant VisRec no. 228180.	Afonso MV, 2010, IEEE T IMAGE PROCESS, V19, P2345, DOI 10.1109/TIP.2010.2047910; Almeida MSC, 2013, IEEE T IMAGE PROCESS, V22, P3074, DOI 10.1109/TIP.2013.2258354; Bar L, 2006, INT J COMPUT VISION, V70, P279, DOI 10.1007/s11263-006-6468-1; Bournan C, 1993, IEEE T IMAGE PROCESS, V2, P296, DOI 10.1109/83.236536; Cai J.-F., 2009, P CVPR; Cho S., 2011, P ICCV; Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491; CHOU PB, 1990, INT J COMPUT VISION, V4, P185, DOI 10.1007/BF00054995; Chunhui Chen, 1996, Computational Optimization and Applications, V5, P97, DOI 10.1007/BF00249052; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; Gamelin T, 2001, COMPLEX ANAL; Gupta A., 2010, P ECCV; Harmeling S., 2010, P ICIP; Harmeling S., 2010, NIPS; Ji H, 2012, IEEE T IMAGE PROCESS, V21, P1624, DOI 10.1109/TIP.2011.2171699; Joshi N, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778767; Krishnan D., 2011, P CVPR; Krishnan D., 2009, NIPS; Levin A., 2009, UNDERSTANDING EVALUA; Levin A., 2011, PROC; Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521; LUCY LB, 1974, ASTRON J, V79, P745, DOI 10.1086/111605; RICHARDSON WH, 1972, J OPT SOC AM, V62, P55, DOI 10.1364/JOSA.62.000055; SCHULTZ RR, 1994, IEEE T IMAGE PROCESS, V3, P233, DOI 10.1109/83.287017; Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672; Tai Y.-W., 2008, PROC; Tai YW, 2011, IEEE T PATTERN ANAL, V33, P1603, DOI 10.1109/TPAMI.2010.222; Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Welk M., 2010, 261 SAARL U; Whyte O., 2010, P CVPR; Whyte O, 2012, THESIS ENS CACHAN; Whyte O., 2011, P CPCV ICCV; Whyte O, 2012, INT J COMPUT VISION, V98, P168, DOI 10.1007/s11263-011-0502-7; Xu L., 2010, P ECCV; Yang JF, 2009, SIAM J SCI COMPUT, V31, P2842, DOI 10.1137/080732894; Yuan L, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239452; Yuan L, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360673; Zoran D., 2011, P ICCV	41	89	92	1	25	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	2014	110	2			SI		185	201		10.1007/s11263-014-0727-3	http://dx.doi.org/10.1007/s11263-014-0727-3			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AY5UE		Green Submitted			2022-12-18	WOS:000347636400008
J	Khan, FS; Anwer, RM; van de Weijer, J; Bagdanov, AD; Lopez, AM; Felsberg, M				Khan, Fahad Shahbaz; Anwer, Rao Muhammad; van de Weijer, Joost; Bagdanov, Andrew D.; Lopez, Antonio M.; Felsberg, Michael			Coloring Action Recognition in Still Images	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Color features; Image representation; Action recognition	OBJECT; CLASSIFICATION; FEATURES	In this article we investigate the problem of human action recognition in static images. By action recognition we intend a class of problems which includes both action classification and action detection (i.e. simultaneous localization and classification). Bag-of-words image representations yield promising results for action classification, and deformable part models perform very well object detection. The representations for action recognition typically use only shape cues and ignore color information. Inspired by the recent success of color in image classification and object detection, we investigate the potential of color for action classification and detection in static images. We perform a comprehensive evaluation of color descriptors and fusion approaches for action recognition. Experiments were conducted on the three datasets most used for benchmarking action recognition in still images: Willow, PASCAL VOC 2010 and Stanford-40. Our experiments demonstrate that incorporating color information considerably improves recognition performance, and that a descriptor based on color names outperforms pure color descriptors. Our experiments demonstrate that late fusion of color and shape information outperforms other approaches on action recognition. Finally, we show that the different color-shape fusion approaches result in complementary information and combining them yields state-of-the-art performance for action classification.	[Khan, Fahad Shahbaz; Felsberg, Michael] Linkoping Univ, Comp Vis Lab, Linkoping, Sweden; [Anwer, Rao Muhammad; van de Weijer, Joost; Lopez, Antonio M.] Univ Autonoma Barcelona, Comp Vis Ctr Barcelona, E-08193 Barcelona, Spain; [Bagdanov, Andrew D.] Univ Florence, Media Integrat & Commun Ctr, Florence, Italy	Linkoping University; Autonomous University of Barcelona; University of Florence	Khan, FS (corresponding author), Linkoping Univ, Comp Vis Lab, Linkoping, Sweden.	fahad@cvc.uab.es	van de Weijer, Joost/A-1643-2009; Khan, Fahad Shahbaz/ABD-6646-2021; López, Antonio M/L-5303-2014; Bagdanov, Andrew/K-3932-2014	van de Weijer, Joost/0000-0002-9656-9706; Khan, Fahad Shahbaz/0000-0002-4263-3143; López, Antonio M/0000-0002-6979-5783; Bagdanov, Andrew/0000-0001-6408-7043; Felsberg, Michael/0000-0002-6096-3648	MNEMOSYNE [A.IV-OB.2]; Collaborative Unmanned Aerial Systems(within the Linnaeus environment CADICS); ELLIIT; Strategic Area for ICT research; Swedish Government;  [TRA2011-29454-C03-01];  [TIN2009-14173]	MNEMOSYNE; Collaborative Unmanned Aerial Systems(within the Linnaeus environment CADICS); ELLIIT; Strategic Area for ICT research; Swedish Government; ; 	We gratefully acknowledge the support of MNEMOSYNE (POR-FSE 2007-2013, A.IV-OB.2), Collaborative Unmanned Aerial Systems(within the Linnaeus environment CADICS), ELLIIT, the Strategic Area for ICT research, funded by the Swedish Government, and Spanish projects TRA2011-29454-C03-01 and TIN2009-14173.	Benavente R, 2008, J OPT SOC AM A, V25, P2582, DOI 10.1364/JOSAA.25.002582; Berlin B, 1969, BASIC COLOR TERMS TH; Bosch A., 2006, P EUR C COMP VIS; Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N., 2005 IEEE COMP SOC C; Delaitre V., 2011, NEURIPS; Delaitre V., 2010, RECOGNIZING HUMAN AC; Desai C., 2012, P EUR C COMP VIS; Elfiky NM, 2012, PATTERN RECOGN, V45, P1627, DOI 10.1016/j.patcog.2011.09.020; Everingham M, 2009, PASCAL VISUAL OBJECT; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Felsberg M, 2007, J REAL-TIME IMAGE PR, V2, P103, DOI 10.1007/s11554-007-0044-y; Gaidon A, 2011, PROC CVPR IEEE; Gehler P.V., 2009, P IEEE INT C COMP VI; Geusebroek JM, 2001, IEEE T PATTERN ANAL, V23, P1338, DOI 10.1109/34.977559; Hoiem D., 2012, EUR C COMP VIS; HU Y, 2009, P IEEE INT C COMP VI; Khan F., 2011, ADV NEURAL INFORM PR; Khan F. S., 2012, C COMP VIS PATT REC; Lan Z. Z., 2012, MULTIMEDIA MODELING; Lazebnik S, 2006, COMPUTER VISION PATT, P2169, DOI [10.1109/CVPR.2006.68, DOI 10.1109/CVPR.2006.68]; Lenz R, 2005, J MATH IMAGING VIS, V23, P297, DOI 10.1007/s10851-005-0485-5; Li L.-J., 2010, ADV NEURAL INFORM PR; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maji S., 2011, COMPUTER VISION PATT; MULLEN KT, 1985, J PHYSIOL-LONDON, V359, P381, DOI 10.1113/jphysiol.1985.sp015591; Pagani A., 2009, P INT CONS INT PROGR; Prest A, 2012, IEEE T PATTERN ANAL, V34, P601, DOI 10.1109/TPAMI.2011.158; Khan FS, 2012, INT J COMPUT VISION, V98, P49, DOI 10.1007/s11263-011-0495-2; Shapovalova N., 2011, IB C PATT REC IM AN; Sharma G., 2013, C COMP VIS PATT REC; Sharma G., 2012, C COMP VIS PATT REC; Tran D., 2012, ADV NEURAL INFORM PR; van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154; van de Weijer J., 2007, INT CONSORTIUM INTER; van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809; VANDEWEIJER J, 2006, P EUR C COMP VIS; VEDALDI A., 2009, P IEEE INT C COMP VI; Vigo D. A. R., 2010, INDIAN COUNCIL PHILO; Wang J., 2010, C COMP VIS PATT REC; Yao B., 2011, P IEEE INT C COMP VI; Yao BP, 2012, IEEE T PATTERN ANAL, V34, P1691, DOI 10.1109/TPAMI.2012.67; Yuan JS, 2009, PROC CVPR IEEE, P2442, DOI [10.1109/CVPR.2009.5206671, 10.1109/CVPRW.2009.5206671]; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; Zhang J., 2010, IEEE C COMP VIS PATT	46	89	95	4	57	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	2013	105	3					205	221		10.1007/s11263-013-0633-0	http://dx.doi.org/10.1007/s11263-013-0633-0			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	208EN		Green Submitted			2022-12-18	WOS:000323659900002
J	Rousson, M; Paragios, N				Rousson, Mikael; Paragios, Nikos			Prior knowledge, level set representations & visual grouping	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						level set method; distance transforms; curve propagation; similarity transformation; pose estimation; object extraction	SHAPE; SEGMENTATION; MODELS	In this paper, we propose a level set method for shape-driven object extraction. We introduce a voxel-wise probabilistic level set formulation to account for prior knowledge. To this end, objects are represented in an implicit form. Constraints on the segmentation process are imposed by seeking a projection to the image plane of the prior model modulo a similarity transformation. The optimization of a statistical metric between the evolving contour and the model leads to motion equations that evolve the contour toward the desired image properties while recovering the pose of the object in the new image. Upon convergence, a solution that is similarity invariant with respect to the model and the corresponding transformation are recovered. Promising experimental results demonstrate the potential of such an approach.	[Rousson, Mikael] Siemens Corporate Res, Princeton, NJ 08540 USA; [Paragios, Nikos] MAS Ecole Cent Paris, F-92295 Chatenay Malabry, France	Siemens AG; UDICE-French Research Universities; Universite Paris Saclay	Rousson, M (corresponding author), Siemens Corporate Res, 755 Coll Rd E, Princeton, NJ 08540 USA.	mikael.rousson@siemens.com; nikos.paragios@ecp.fr						BASCLE B, 1994, THESIS U NICE SOPHIA; Bertalmio M, 2000, IEEE T PATTERN ANAL, V22, P733, DOI 10.1109/34.865191; Birchfield S, 1998, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.1998.698614; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; BRESSON X, 2003, IEEE ICIP, V3, P428; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685; CHARPIAT G, 2003, APPROXIMATION SHAPE; Chen YM, 2002, INT C PATT RECOG, P747, DOI 10.1109/ICPR.2002.1044866; Chen YM, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P145, DOI 10.1109/VLSM.2001.938893; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568; Cootes TF, 1999, LECT NOTES COMPUT SC, V1613, P322; Cremers D, 2003, LECT NOTES COMPUT SC, V2695, P388; Cremers D, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P137, DOI 10.1109/VLSM.2001.938892; Cremers D, 2006, INT J COMPUT VISION, V69, P335, DOI 10.1007/s11263-006-7533-5; DERVIEUX A, 1979, LECT NOTES MATH, V771, P145; DERVIEUX A, 1980, LECT NOTE PHYS, V141, P158; Dufour RM, 2002, IEEE T IMAGE PROCESS, V11, P1385, DOI 10.1109/TIP.2002.806245; FAUGERAS O, 1998, ECCV, V1, P379; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Huang XL, 2006, IEEE T PATTERN ANAL, V28, P1303, DOI 10.1109/TPAMI.2006.171; Jehan-Besson S, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P643; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855; KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741; KIMMEL R, 1995, COMPUT VIS IMAGE UND, V62, P47, DOI 10.1006/cviu.1995.1040; Leventon ME, 2000, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P4, DOI 10.1109/MMBIA.2000.852354; LEVENTON ME, 2000, CVPR, P1316; LIPSON P, 1990, EUR C COMP VIS, P413; Malladi R, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P304, DOI 10.1109/ICCV.1998.710735; MALLADI R, 1994, ECCV94, V1, P3; METZXAS D, 1997, GRAPHICS MED IMAGING; Mumford D., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P22; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Osher S., 2003, GEOMETRIC LEVEL SET; Paragios N, 2003, COMPUT VIS IMAGE UND, V89, P142, DOI 10.1016/S1077-3142(03)00010-9; Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068; PARAGIOS N, 2002, ECCV, V2, P775; Paragios N., 2005, HDB MATH MODELS COMP; Rousson M, 2004, LECT NOTES COMPUT SC, V3216, P209; Rousson M, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P56, DOI 10.1109/MOTION.2002.1182214; ROUSSON M, 2005, INT C MED IM COMP CO, V2, P757; ROUSSON M, 2002, P EUR C COMP VIS, V2, P78; SAMSON C, 1999, INT C SCAL SPAC THEO, P306; Sapiro G., 2001, GEOMETRIC PARTIAL DI; Sethian J., 1996, LEVEL SET METHODS; SUSSMAN M, 1994, J COMPUT PHYS, V114, P146, DOI 10.1006/jcph.1994.1155; TARON M, 2005, ICCV 05; TEK H, 1995, ICCV, P156; Tikhonov A., 1992, ILL POSED PROBLEMS N; Tsai A, 2001, PROC CVPR IEEE, P463; Tsai A, 2003, IEEE T MED IMAGING, V22, P137, DOI 10.1109/TMI.2002.808355; VELTKAMP RC, 1999, STATE OF THE ART SHA; Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076; Wang YM, 1998, PROC CVPR IEEE, P338, DOI 10.1109/CVPR.1998.698628; Yezzi A, 2003, INT J COMPUT VISION, V53, P31, DOI 10.1023/A:1023079624234; Yezzi A, 2001, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P44, DOI 10.1109/MMBIA.2001.991698; YUILLE AL, 1991, J COGNITIVE NEUROSCI, V3, P59, DOI 10.1162/jocn.1991.3.1.59; YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169; Zhao HK, 1996, J COMPUT PHYS, V127, P179, DOI 10.1006/jcph.1996.0167; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	65	89	100	0	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2008	76	3					231	243		10.1007/s11263-007-0054-z	http://dx.doi.org/10.1007/s11263-007-0054-z			13	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	255VI					2022-12-18	WOS:000252685500002
J	BEVERIDGE, JR; GRIFFITH, J; KOHLER, RR; HANSON, AR; RISEMAN, EM				BEVERIDGE, JR; GRIFFITH, J; KOHLER, RR; HANSON, AR; RISEMAN, EM			SEGMENTING IMAGES USING LOCALIZED HISTOGRAMS AND REGION MERGING	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article									UNIV MASSACHUSETTS,COMP & INFORMAT SCI,AMHERST,MA 01003	University of Massachusetts System; University of Massachusetts Amherst								AKOHL C, 1988, THESIS U MASSACHUSET; Ballard D.H., 1982, COMPUTER VISION; Barrow H. G., 1971, Machine Intelligence Volume 6, P377; BELKNAP R, 1986, CVPR86 P IEEE COMPUT, P227; BEVERIDGE JR, 1987, 8788 U MASS DEP COMP; BHANU B, 1982, IEEE T PATTERN ANAL, V4, P408, DOI 10.1109/TPAMI.1982.4767273; BRICE CR, 1970, ARTIF INTELL, V1, P205, DOI 10.1016/0004-3702(70)90008-1; BROWNING JD, 1982, PATTERN RECOGN, V15, P1, DOI 10.1016/0031-3203(82)90055-3; CHEN PC, 1978, 4TH IJCPR KYOTO, P205; Chow CK, 1972, FRONTIERS PATTERN RE, P61; COLEMAN GB, 1979, P IEEE, V67, P773, DOI 10.1109/PROC.1979.11327; DRAPER BA, 1987, FEB P DARPA IM UND W, P178; DRAPER BA, 1989, INT J COMPUTER VISIO, V2; DRAPER BA, 1988, JUN CVPT 88 P IEEE C, P129; Duda RO, 1973, PATTERN RECOGNITION; FELDMAN JA, 1974, ARTIF INTELL, V5, P349, DOI 10.1016/0004-3702(74)90002-2; FIRSCHEIN O, 1971, PATTERN RECOGN, V3, P421, DOI 10.1016/0031-3203(71)90031-8; FREUDER EC, 1976, COMPUT GRAPHICS IMAG, V5, P254; Hanson A. R., 1978, COMPUTER VISION SYST, P129; HANSON AR, 1986, 8662 U MASS DEPT COM; HANSON AR, 1984, IEEE T PAMI, V6; HANSON AR, 1975, TR75C3 U MASS TECH R; Haralick R. M., 1979, Proceedings of the 1979 IEEE Computer Society Conference on Pattern Recognition and Image Processing, P489; HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7; KELLY MD, 1971, MACH INTELL, V6, P379; KITTLER J, 1985, IEEE T SYST MAN CYB, V15, P652, DOI 10.1109/TSMC.1985.6313443; Klinger A., 1973, 1st International Joint Conference on Pattern Recognition, P497; Klinger A., 1976, COMPUT VISION GRAPH, V5, P68, DOI [10.1016/S0146-664X(76)80006-8, DOI 10.1016/S0146-664X(76)80006-8]; KOHL C, 1987, 10TH P INT JOINT C A, P811; KOHL CA, 1987, FEB P DARPA IM UND W, P538; KOHLER RP, 1984, THESIS U MASSACHUSET; LEE CH, 1986, COMPUT VISION GRAPH, V33, P237, DOI 10.1016/0734-189X(86)90116-7; LEHRER N, 1987, FEB P WORKSH IM UND, P521; LEVINE MD, 1985, IEEE T PATTERN ANAL, V7, P155, DOI 10.1109/TPAMI.1985.4767640; Nagao M., 1980, STRUCTURAL ANAL COMP; NAGIN PA, 1979, AUG P IEEE C PATT RE, P515; NAGIN PA, 1979, 7915 U MASS TECH REP; NAGIN PA, 1982, IEEE T PAMI, V4; NAZIF AM, 1983, THESIS MCGILL U; OHLANDER RB, 1979, COMPUTER GRAPHICS IM, V3; OHLANDER RB, 1975, THESIS PITTSBURGH; OHTA Y, 1980, COMPUT VISION GRAPH, V13, P222, DOI 10.1016/0146-664X(80)90047-7; OTSU N, 1979, IEE T SYST MAN CYBER, V9; Overton K. J., 1979, Proceedings of the 1979 IEEE Computer Society Conference on Pattern Recognition and Image Processing, P498; Pavlidis T., 1977, STRUCTURAL PATTERN R; PELEG S, 1978, IEEE T SYST MAN CYB, V8, P548; PREWITT JSM, 1986, ANAL NY ACAD SCI, V128, P1035; PRICE KE, 1984, IEEE T PAMI, V6; REDDI SS, 1984, IEEE T SYST MAN CYB, V14, P661, DOI 10.1109/TSMC.1984.6313341; REYNOLDS G, 1987, P DEFENSE ADV RES PR, P257; REYNOLDS G, 1984, IEEE P WORKSHOP COMP, P238; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; ROSENFELD A, 1978, PATTERN RECOGN, V10, P181, DOI 10.1016/0031-3203(78)90026-2; Rosenfeld Azriel, 1976, DIGITAL PICTURE PROC, V2, P8; Shvaytser H., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P320; TENENBAUM JM, 1976, ARTIF INTELL, V8, P241; WEISS R, 1986, 8653 U MASS TECH REP; WEYMOUTH TE, 1986, THESIS U MASS; WEYMOUTH TE, 1986, THESIS U MASS TECH R; YAKIMOVSKY Y, 1976, J ACM, V23, P599, DOI 10.1145/321978.321981; Zucker S. W., 1976, Computer Graphics and Image Processing, V5, P382, DOI 10.1016/S0146-664X(76)80014-7	61	89	91	0	2	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	1989	2	3					311	347		10.1007/BF00158168	http://dx.doi.org/10.1007/BF00158168			37	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AC191					2022-12-18	WOS:A1989AC19100005
J	Ryoo, MS; Aggarwal, JK				Ryoo, M. S.; Aggarwal, J. K.			Semantic Representation and Recognition of Continued and Recursive Human Activities	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Human activity recognition; Event detection; Semantic-level video analysis; Hierarchical action recognition	EVENT RECOGNITION	This paper describes a methodology for automated recognition of complex human activities. The paper proposes a general framework which reliably recognizes high-level human actions and human-human interactions. Our approach is a description-based approach, which enables a user to encode the structure of a high-level human activity as a formal representation. Recognition of human activities is done by semantically matching constructed representations with actual observations. The methodology uses a context-free grammar (CFG) based representation scheme as a formal syntax for representing composite activities. Our CFG-based representation enables us to define complex human activities based on simpler activities or movements. Our system takes advantage of both statistical recognition techniques from computer vision and knowledge representation concepts from traditional artificial intelligence. In the low-level of the system, image sequences are processed to extract poses and gestures. Based on the recognition of gestures, the high-level of the system hierarchically recognizes composite actions and interactions occurring in a sequence of image frames. The concept of hallucinations and a probabilistic semantic-level recognition algorithm is introduced to cope with imperfect lower-layers. As a result, the system recognizes human activities including 'fighting' and 'assault', which are high-level activities that previous systems had difficulties. The experimental results show that our system reliably recognizes sequences of complex human activities with a high recognition rate.	[Ryoo, M. S.; Aggarwal, J. K.] Univ Texas Austin, Comp & Vis Res Ctr, Austin, TX 78712 USA	University of Texas System; University of Texas Austin	Ryoo, MS (corresponding author), Univ Texas Austin, Comp & Vis Res Ctr, Austin, TX 78712 USA.	mryoo@ece.utexas.edu; aggarwal@ece.utexas.edu						Allen J. E., 1994, Journal of Logic and Computation, V4, P531, DOI 10.1093/logcom/4.5.531; Bobick AF, 1997, IEEE T PATTERN ANAL, V19, P1325, DOI 10.1109/34.643892; CHOMSKY N, 1956, IRE T INFORM THEOR, V2, P113; Fine S, 1998, MACH LEARN, V32, P41, DOI 10.1023/A:1007469218079; Hongeng S, 2004, COMPUT VIS IMAGE UND, V96, P129, DOI 10.1016/j.cviu.2004.02.005; Ivanov YA, 2000, IEEE T PATTERN ANAL, V22, P852, DOI 10.1109/34.868686; Lee SC, 2004, PROC CVPR IEEE, P113; MINNEN D, 2003, CVPR 03, P626; Moore D, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P770; Natarajan P., 2007, P IEEE WORKSH MOT VI, P10, DOI DOI 10.1109/WMVC.2007.12; Nguyen NT, 2005, PROC CVPR IEEE, P955; Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684; Park S, 2006, COMPUT VIS IMAGE UND, V102, P1, DOI 10.1016/j.cviu.2005.07.011; Park S, 2004, MULTIMEDIA SYST, V10, P164, DOI 10.1007/s00530-004-0148-1; PARK S, 2004, CVPRW, V1, P12; PINHANEZ C, 1999, THESIS MIT MEDIA LAB; Ryoo MS, 2006, INT C PATT RECOG, P379; RYOO MS, 2007, IJCAI 2007 P 20 INT, P2850; RYOO MS, 2006, CVPR, P1709; Seong-Wook J., 2006, P C COMP VIS PATT RE, P107; SHI Y, 2004, CVPR, P862; Siskind JM, 2001, J ARTIF INTELL RES, V15, P31, DOI 10.1613/jair.790; Starner T., 1995, Proceedings International Symposium on Computer Vision (Cat. No.95TB100006), P265, DOI 10.1109/ISCV.1995.477012; VU VT, 2003, INT JOINT C ART INT, P1295; Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161	25	88	94	1	16	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	2009	82	1					1	24		10.1007/s11263-008-0181-1	http://dx.doi.org/10.1007/s11263-008-0181-1			24	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	402AH					2022-12-18	WOS:000262986100001
J	Wu, B; Nevatia, R				Wu, Bo; Nevatia, Ram			Detection and Segmentation of Multiple, Partially Occluded Objects by Grouping, Merging, Assigning Part Detection Responses	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Object detection; Object segmentation		We propose a method that detects and segments multiple, partially occluded objects in images. A part hierarchy is defined for the object class. Both the segmentation and detection tasks are formulated as binary classification problem. A whole-object segmentor and several part detectors are learned by boosting local shape feature based weak classifiers. Given a new image, the part detectors are applied to obtain a number of part responses. All the edge pixels in the image that positively contribute to the part responses are extracted. A joint likelihood of multiple objects is defined based on the part detection responses and the object edges. Computation of the joint likelihood includes an inter-object occlusion reasoning that is based on the object silhouettes extracted with the whole-object segmentor. By maximizing the joint likelihood, part detection responses are grouped, merged, and assigned to multiple object hypotheses. The proposed approach is demonstrated with the class of pedestrians. The experimental results show that our method outperforms the previous ones.	[Wu, Bo; Nevatia, Ram] Univ So Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA	University of Southern California	Wu, B (corresponding author), Univ So Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA.	bowu@usc.edu; nevatia@usc.edu						Bray M., 2006, ECCV; Chan AB, 2008, PROC CVPR IEEE, P1766, DOI 10.1109/cvpr.2008.4587569; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N., 2006, ECCV; Ess A., 2007, ICCV; Gavrila D., 2000, ECCV; Gavrila D. M., 1999, ICCV; Gavrila DM, 2007, IEEE T PATTERN ANAL, V29, P1408, DOI 10.1109/TPAMI.2007.1062; HUANG C, 2005, ICCV; HUANG C, 2006, FG; Huang C, 2007, IEEE T PATTERN ANAL, V29, P671, DOI 10.1109/TPAMI.2007.1011; KAPOOR A, 2006, ECCV; Kong D., 2006, ICPR; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; Kumar M.P., 2005, CVPR; Leibe B, 2004, WORKSH STAT LEARN CO; Leibe B., 2005, CVPR; Lin Y.-Y., 2004, ECCV; Lin Z., 2007, ICCV; Medioni G., 2000, COMPUTATIONAL FRAMEW; Mikolajczyk C., 2004, ECCV; Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571; Munder S, 2006, IEEE T PATTERN ANAL, V28, P1863, DOI 10.1109/TPAMI.2006.217; Mutch J., 2006, CVPR; Opelt A., 2006, ECCV; PAPAGEORGIOU C, 1998, P INT VEH; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Sabzmeydani P., 2007, CVPR; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; SCHNEIDERMAN H, 2000, CVPR; Sharma V., 2007, ICCV; Shashua A., 2004, IEEE INT VEH S; Shet V.D., 2007, CVPR; Shotton J., 2006, ECCV; Shotton J., 2005, ICCV; Todorovic S., 2006, CVPR; Tu Z., 2001, ICCV; Tuzel O., 2007, CVPR; VIOLA P, 2003, ICCV; Viola P., 2001, P 2001 IEEE COMP SOC, pI, DOI [10.1109/CVPR.2001.990517, DOI 10.1109/CVPR.2001.990517]; WINN J, 2006, CVPR; Winn J. M., 2005, ICCV; Wu B., 2007, CVPR; WU B, 2008, CVPR; Wu B., 2007, ICCV; Wu B., 2005, ICCV; Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7; Zhao L., 2005, ICCV; Zhu Q., 2006, CVPR	49	88	99	0	20	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	2009	82	2					185	204		10.1007/s11263-008-0194-9	http://dx.doi.org/10.1007/s11263-008-0194-9			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	408FP					2022-12-18	WOS:000263421200004
J	Brubaker, SC; Wu, JX; Sun, J; Mullin, MD; Rehg, JM				Brubaker, S. Charles; Wu, Jianxin; Sun, Jie; Mullin, Matthew D.; Rehg, James M.			On the design of Cascades of boosted ensembles for face detection	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						face detection; boosting; cascade classifier		Cascades of boosted ensembles have become popular in the object detection community following their highly successful introduction in the face detector of Viola and Jones. Since then, researchers have sought to improve upon the original approach by incorporating new methods along a variety of axes ( e. g. alternative boosting methods, feature sets, etc.). Nevertheless, key decisions about how many hypotheses to include in an ensemble and the appropriate balance of detection and false positive rates in the individual stages are often made by user intervention or by an automatic method that produces unnecessarily slow detectors. We propose a novel method for making these decisions, which exploits the shape of the stage ROC curves in ways that have been previously ignored. The result is a detector that is significantly faster than the one produced by the standard automatic method. When this algorithm is combined with a recycling method for reusing the outputs of early stages in later ones and with a retracing method that inserts new early rejection points in the cascade, the detection speed matches that of the best hand-crafted detector. We also exploit joint distributions over several features in weak learning to improve overall detector accuracy, and explore ways to improve training time by aggressively filtering features.	[Brubaker, S. Charles; Wu, Jianxin; Sun, Jie; Mullin, Matthew D.; Rehg, James M.] Georgia Inst Technol, Sch Interact Comp, Atlanta, GA 30332 USA	University System of Georgia; Georgia Institute of Technology	Brubaker, SC (corresponding author), Georgia Inst Technol, Sch Interact Comp, 85 5th St NW,Suite 205, Atlanta, GA 30332 USA.	brubaker@cc.gatech.edu	Wu, Jianxin/B-8539-2012; Rehg, James/AAM-6888-2020; Wu, Jianxin/A-3700-2011	Rehg, James/0000-0003-1793-5462; 				Amit Y, 1999, NEURAL COMPUT, V11, P1691, DOI 10.1162/089976699300016197; Anthony M, 2004, J MACH LEARN RES, V5, P189; BAKER S, 1996, P ICPR, V2, P869; BARTLETT MS, 2003, REAL TIME FACE DETEC; Blanchard G, 2005, ANN STAT, V33, P1155, DOI 10.1214/009053605000000174; BRUBAKER SC, 2006, ECCV, P325; Chen X., 2005, CVPR, P20; Elad M, 2002, PATTERN RECOGN LETT, V23, P1459, DOI 10.1016/S0167-8655(02)00106-X; Elisseeff A., 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616; Fleuret F, 2002, INT C PATT RECOG, P235; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Froba B, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P91, DOI 10.1109/AFGR.2004.1301514; Gangaputra S., 2006, P IEEE C COMP VIS PA, V2, P1877, DOI 10.1109/CVPR.2006.21; GROSSMANN E, 2005, P ICCV VS PETS WORKS; GROSSMANN E, 2004, INT IAPR WORKSH STAT; Heisele B, 2001, PROC CVPR IEEE, P18; Keren D, 2001, IEEE T PATTERN ANAL, V23, P747, DOI 10.1109/34.935848; KIENZLE W, 2005, NIPS, V17, P673; LEVI K, 2004, P CVPR, V2; Li SZ, 2004, IEEE T PATTERN ANAL, V26, P1112, DOI 10.1109/TPAMI.2004.68; Lienhart R., 2002, EMPIRICAL ANAL DETEC; Liu C, 2003, PROC CVPR IEEE, P587; LUO H, 2005, P CVPR, V1, P480; Mas-Colell A., 1995, MICROECONOMIC THEORY; Olshen R., 1984, CLASSIFICATION REGRE; Opelt A, 2004, LECT NOTES COMPUT SC, V3022, P71; OSADCHY R, 2005, NIPS, V17; Rivest R. L., 1987, Machine Learning, V2, P229, DOI 10.1023/A:1022607331053; Romdhani S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P695, DOI 10.1109/ICCV.2001.937694; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901; Schneiderman H, 2004, PROC CVPR IEEE, P29; Sochman J, 2005, PROC CVPR IEEE, P150; Sun J, 2004, PROC CVPR IEEE, P276; Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648; Tu ZW, 2005, IEEE I CONF COMP VIS, P1589; Vidal-Naquet M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P281; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; VIOLA P, 2002, NIPS, V14; Wu J., 2005, P 22 INT C MACH LEAR, V22, P993; WU J, 2004, NIPS, V16; Xiao R, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P709	43	88	97	0	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2008	77	1-3					65	86		10.1007/s11263-007-0060-1	http://dx.doi.org/10.1007/s11263-007-0060-1			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	267RE		Green Submitted			2022-12-18	WOS:000253526100005
J	Demirci, MF; Shokoufandeh, A; Keselman, Y; Bretzner, L; Dickinson, S				Demirci, M. Fatih; Shokoufandeh, Ali; Keselman, Yakov; Bretzner, Lars; Dickinson, Sven			Object recognition as many-to-many feature matching	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						graph matching. graph embedding; Earth Mover's Distance (EMD); object recognition	ALGORITHM; SHAPE	Object recognition can be formulated as matching image features to model features. When recognition is exemplar-based, feature correspondence is one-to-one. However, segmentation errors, articulation, scale difference, and within-class deformation can yield image and model features which don't match one-to-one but rather many-to-many. Adopting a graph-based representation of a set of features, we present a matching algorithm that establishes many-to-many correspondences between the nodes of two noisy, vertex-labeled weighted graphs. Our approach reduces the problem of many-to-many matching of weighted graphs to that of many-to-many matching of weighted point sets in a normed vector space. This is accomplished by embedding the initial weighted graphs into a normed vector space with low distortion using a novel embedding technique based on a spherical encoding of graph structure. Many-to-many vector correspondences established by the Earth Mover's Distance framework are mapped back into many-to-many correspondences between graph nodes. Empirical evaluation of the algorithm on an extensive set of recognition trials, including a comparison with two competing graph matching approaches, demonstrates both the robustness and efficacy of the overall approach.	Drexel Univ, Dept Comp Sci, Philadelphia, PA 19104 USA; Depaul Univ, Sch Comp Sci Telecommun & Informat Syst, Chicago, IL 60604 USA; KTH, Computat Vis & Act Precept Lab, Dept Numer Anal & Comp Sci, Stockholm, Sweden; Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada	Drexel University; DePaul University; Royal Institute of Technology; University of Toronto	Demirci, MF (corresponding author), Drexel Univ, Dept Comp Sci, Philadelphia, PA 19104 USA.							Agarwala R, 1999, SIAM J COMPUT, V28, P1073, DOI 10.1137/S0097539795296334; ATHITSOS V, 2004, P IEEE C COMP VIS PA; ATKINSON DS, 1995, ALGORITHMICA, V13, P442, DOI 10.1007/BF01190848; Bell ET., 1934, AM MATH MON, V41, P411, DOI DOI 10.2307/2300300; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Buneman P., 1971, MATH ARCHAEOLOGICAL, P387; Carcassoni M, 2003, IEEE T PATTERN ANAL, V25, P1609, DOI 10.1109/TPAMI.2003.1251153; Cohen S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1076, DOI 10.1109/ICCV.1999.790393; Conway J. H., 1998, SPHERE PACKING LATTI; DEMIRCI F, 2004, P 8 EUR C COMP VIS P; Demirci MF, 2003, LECT NOTES COMPUT SC, V2695, P17; Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Grauman K, 2004, PROC CVPR IEEE, P220; Gupta A., 1999, Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, P694, DOI 10.1145/301250.301434; GUPTA A, 1999, P S FDN COMP SCI; INDYK P, 2001, P 42 ANN S FDN COMP; KESELMAN Y, 2005, IEEE PAMI, V27; KESELMAN Y, 2003, P IEEE C COMP VIS PA; KOSINOV S, 2002, P SSPR SPR, V2396, P133; Leibe Bastian, 2003, IEEE C COMP VIS PATT; Lindeberg T, 1998, INT J COMPUT VISION, V30, P117, DOI 10.1023/A:1008097225773; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; Matousek J, 1999, ISRAEL J MATH, V114, P221, DOI 10.1007/BF02785579; Messmer B. T., 1995, Shape, Structure and Pattern Recognition, P231; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Myers R, 2000, IEEE T PATTERN ANAL, V22, P628, DOI 10.1109/34.862201; Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; SCOTT GL, 1991, P ROY SOC B-BIOL SCI, V244, P21, DOI 10.1098/rspb.1991.0045; Sebastian T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P755, DOI 10.1109/ICCV.2001.937602; Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924; Shokoufandeh A, 2002, LECT NOTES COMPUT SC, V2352, P759; SHOKOUFANDEH A, 2005, IEEE PAMI, V27; Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703; [No title captured]	36	88	92	0	14	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2006	69	2					203	222		10.1007/s11263-006-6993-y	http://dx.doi.org/10.1007/s11263-006-6993-y			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	065LW		Green Submitted			2022-12-18	WOS:000239162400003
J	Caspi, Y; Simakov, D; Irani, M				Caspi, Yaron; Simakov, Denis; Irani, Michal			Feature-based sequence-to-sequence matching	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	Workshop on Vision and Modelling of Dynamic Scenes held in Conjuction with the European Conference on Computer Vision	2002	Copenhagen, DENMARK			sequence-to-sequence matching; alignment in space and time; dynamic information; multi-sensor alignment; wide base-line matching; trajectory matching	SCALE	This paper studies the problem of matching two unsynchronized video sequences of the same dynamic scene, recorded by different stationary uncalibrated video cameras. The matching is done both in time and in space, where the spatial matching can be modeled by a homography (for 2D scenarios) or by a fundamental matrix (for 3D scenarios). Our approach is based on matching space-time trajectories of moving objects, in contrast to matching interest points (e.g., corners), as done in regular feature-based image-to-image matching techniques. The sequences are matched in space and time by enforcing consistent matching of all points along corresponding space-time trajectories. By exploiting the dynamic properties of these space-time trajectories, we obtain sub-frame temporal correspondence (synchronization) between the two video sequences. Furthermore, using trajectories rather than feature-points significantly reduces the combinatorial complexity of the spatial point-matching problem when the search space is large. This benefit allows for matching information across sensors in situations which are extremely difficult when only image-to-image matching is used, including: (a) matching under large scale (zoom) differences, (b) very wide base-line matching, and (c) matching across different sensing modalities (e.g., IR and visible-light cameras). We show examples of recovering homographies and fundamental matrices under such conditions.	Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel	Weizmann Institute of Science	Caspi, Y (corresponding author), Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel.	caspiy@tau.ac.il						BERGEN JR, 1992, EUR C COMP VIS, P237; Burt P. J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P173, DOI 10.1109/ICCV.1993.378222; Caspi Y, 2000, PROC CVPR IEEE, P682, DOI 10.1109/CVPR.2000.854940; CASPI Y, 2002, ECCV VAMODS WORKSH C; FAUGERAS O, 2001, GEOMETRY MULTIPLE I; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Giese MA, 2000, INT J COMPUT VISION, V38, P59, DOI 10.1023/A:1008118801668; Hampel FR., 2011, WILEY SERIES PROBABI; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; KADIR T, 2004, EUR C COMP VIS ECCV; Lee L, 2000, IEEE T PATTERN ANAL, V22, P758, DOI 10.1109/34.868678; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Mindru F, 2004, COMPUT VIS IMAGE UND, V94, P3, DOI 10.1016/j.cviu.2003.10.011; Mundy J., 1992, GEOMETRIC INVARIANCE; Rousseeuw P. J., 1987, ROBUST REGRESSION OU; SHECHTMAN E, 2002, EUR C COMP VIS ECCV; Stauffer C, 2003, PROC CVPR IEEE, P259; STEIN GP, 1998, DARPA IU WORKSH, P1037; SZELISKI R, 1997, P SIGGRAPH, P251; TOMASI C, 1991, CMUCS9132 CARN MELLO; TRESADERN P, 2003, BRIT MACHINE VISION, V2, P629; Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8; Wong J, 2001, RES SOCIAL WORK PRAC, V11, P217, DOI 10.1177/104973150101100208; XU C, 1996, EPIPOLAR GEOMETRY ST; ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4; Zoghlami I, 1997, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.1997.609359	30	88	95	0	13	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2006	68	1					53	64		10.1007/s11263-005-4842-z	http://dx.doi.org/10.1007/s11263-005-4842-z			12	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	052JB		Green Submitted			2022-12-18	WOS:000238228900005
J	Wu, Y; Huang, TS				Wu, Y; Huang, TS			Robust visual tracking by integrating multiple cues based on co-inference learning	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						visual tracking; sequential Monte Carlo; importance sampling; co-inference; factorized graphical model; variational analysis	DYNAMICS	Visual tracking can be treated as a parameter estimation problem that infers target states based on image observations from video sequences. A richer target representation may incur better chances of successful tracking in cluttered and dynamic environments, and thus enhance the robustness. Richer representations can be constructed by either specifying a detailed model of a single cue or combining a set of rough models of multiple cues. Both approaches increase the dimensionality of the state space, which results in a dramatic increase of computation. To investigate the integration of rough models from multiple cues and to explore computationally efficient algorithms, this paper formulates the problem of multiple cue integration and tracking in a probabilistic framework based on a factorized graphical model. Structured variational analysis of such a graphical model factorizes different modalities and suggests a co-inference process among these modalities. Based on the importance sampling technique, a sequential Monte Carlo algorithm is proposed to provide an efficient simulation and approximation of the co-inferencing of multiple cues. This algorithm runs in real-time at around 30 Hz. Our extensive experiments show that the proposed algorithm performs robustly in a large variety of tracking scenarios. The approach presented in this paper has the potential to solve other problems including sensor fusion problems.	Northwestern Univ, Dept Elect & Comp Engn, Evanston, IL 60208 USA; Univ Illinois, Beckman Inst, Urbana, IL 61801 USA	Northwestern University; University of Illinois System; University of Illinois Urbana-Champaign	Wu, Y (corresponding author), Northwestern Univ, Dept Elect & Comp Engn, 2145 Sheridan Rd, Evanston, IL 60208 USA.	yingwu@ece.nortliwestern.edu; huang@ifp.uiuc.edu	Wu, Ying/B-7283-2009					Azoz Y, 1998, PROC CVPR IEEE, P905, DOI 10.1109/CVPR.1998.698712; Birchfield S, 1998, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.1998.698614; BLACK M, 1996, P EUR C COMP VIS, V1, P343; Blake A., 1998, ACTIVE CONTOURS, DOI [10.1007/978-1-4471-1555-7, DOI 10.1007/978-1-4471-1555-7]; Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962; Bregler C, 1997, PROC CVPR IEEE, P568, DOI 10.1109/CVPR.1997.609382; CHAM TJ, 1999, P COMP VIS PATT REC, V2, P239; Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761; Darrell T, 1998, PROC CVPR IEEE, P601, DOI 10.1109/CVPR.1998.698667; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Deutscher J, 2000, PROC CVPR IEEE, P126, DOI 10.1109/CVPR.2000.854758; Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; GHAHRAMANI Z, 1995, ADV NEURAL INFORMATI, V7, P617; Hager GD, 1996, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.1996.517104; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; ISARD M, 1998, P EUR C COMP VIS, V1, P767; ISARD M, 1996, P EUR C COMP VIS, P343; Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178; Li BX, 2000, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2000.854755; LIU J, 2000, SEQUENTIAL MONTE CAR; Liu JS, 1998, J AM STAT ASSOC, V93, P1032, DOI 10.2307/2669847; MacCormick J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P572, DOI 10.1109/ICCV.1999.791275; MACCORMICK J, 2000, P EUR C COMP VIS, V2, P3; Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Raja Y., 1998, P EUR C COMP VIS, P460; Rasmussen C, 1998, PROC CVPR IEEE, P16, DOI 10.1109/CVPR.1998.698582; Saul LK, 1996, ADV NEUR IN, V8, P486; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Tanner M. A, 1993, TOOLS STAT INFERENCE; Tao H, 2000, PROC CVPR IEEE, P134, DOI 10.1109/CVPR.2000.854760; TAO H, 1999, P ICCV 99 WORKSH VIS; Toyama K, 1996, PROC CVPR IEEE, P189, DOI 10.1109/CVPR.1996.517073; TOYAMA K, 2000, P EUR C COMP VIS IRL; TOYAMA K, 1999, INT C COMP VIS, P255, DOI DOI 10.1109/ICCV.1999.791228; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236; Wu Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P26, DOI 10.1109/ICCV.2001.937590; Wu Y, 2001, IEEE SIGNAL PROC MAG, V18, P51; Wu Y, 2000, PROC CVPR IEEE, P133, DOI 10.1109/CVPR.2000.855810	41	88	100	0	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2004	58	1					55	71		10.1023/B:VISI.0000016147.97880.cd	http://dx.doi.org/10.1023/B:VISI.0000016147.97880.cd			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	823OD		Green Submitted			2022-12-18	WOS:000221621600005
J	Garding, J; Lindeberg, T				Garding, J; Lindeberg, T			Direct computation of shape cues using scale-adapted spatial derivative operators	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							SIMPLE RECEPTIVE-FIELDS; CAT STRIATE CORTEX; TEXTURE-DISCRIMINATION; SURFACE ORIENTATION; EARLY VISION; IMAGES; SPACE; PERCEPTION; STEREOPSIS; MODEL	This paper addresses the problem of computing cues to the three-dimensional structure of surfaces in the world directly from the local structure of the brightness pattern of either a single monocular image or a binocular image pair. It is shown that starting from Gaussian derivatives of order up to two at a range of scales in scale-space, local estimates of (i) surface orientation from monocular texture foreshortening, (ii) surface orientation from monocular texture gradients, and (iii) surface orientation from the binocular disparity gradient can be computed without iteration or search, and by using essentially the same basic mechanism. The methodology is based on a multi-scale descriptor of image structure called the windowed second moment matrix, which is computed with adaptive selection of both scale levels and spatial positions. Notably, this descriptor comprises two scale parameters; a local scale parameter describing the amount of smoothing used in derivative computations, and an integration scale parameter determining over how large a region in space the statistics of regional descriptors is accumulated. Experimental results for both synthetic and natural images are presented, and the relation with models of biological vision is briefly discussed.			Garding, J (corresponding author), ROYAL INST TECHNOL, DEPT NUMER ANAL & COMP SCI, CVAP, KTH, S-10044 STOCKHOLM, SWEDEN.		Lindeberg, Tony/G-3580-2011	Lindeberg, Tony/0000-0002-9081-2170				ALOIMONOS J, 1988, BIOL CYBERN, V58, P345, DOI 10.1007/BF00363944; BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; BERGEN JR, 1988, NATURE, V333, P363, DOI 10.1038/333363a0; BIGUN J, 1991, IEEE T PATTERN ANAL, V13, P775, DOI 10.1109/34.85668; BIJL P, 1993, VISION RES, V33, P243, DOI 10.1016/0042-6989(93)90162-P; BLAKE A, 1990, ARTIF INTELL, V45, P323, DOI 10.1016/0004-3702(90)90011-N; BLAKE A, 1990, P 3 INT C COMP VIS O, P350; BLAKEMORE C, 1970, VISION RES, V10, P1181, DOI 10.1016/0042-6989(70)90036-2; BLOSTEIN D, 1989, IEEE T PATTERN ANAL, V11, P1233, DOI 10.1109/34.41363; BLOSTEIN D, 1989, COMPUT VISION GRAPH, V45, P22, DOI 10.1016/0734-189X(89)90068-6; BROWN LG, 1990, IEEE T PATTERN ANAL, V12, P584, DOI 10.1109/34.56194; CAELLI T, 1985, Spatial Vision, V1, P19, DOI 10.1163/156856885X00044; CASADEI S, 1992, LECT NOTES COMPUT SC, V588, P174; DAVIS LS, 1983, IEEE T PATTERN ANAL, V5, P485, DOI 10.1109/TPAMI.1983.4767427; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; FLORACK LMJ, 1992, IMAGE VISION COMPUT, V10, P376, DOI 10.1016/0262-8856(92)90024-W; FORSTNER MA, 1987, P INT WORKSH INT SOC; GARDING J, 1993, ARTIF INTELL, V64, P243, DOI 10.1016/0004-3702(93)90106-L; GARDING J, 1992, J MATH IMAGING VIS, V2, P329; GARDING J, 1994, P 3 EUR C COMP VIS S; GARDING J, 1991, THESIS ROYAL I TECHN; Gibson James J., 1950, PERCEPTION VISUAL WO, P3; JONES DG, 1992, LECT NOTES COMPUT SC, V588, P661; JONES JP, 1987, J NEUROPHYSIOL, V58, P1187, DOI 10.1152/jn.1987.58.6.1187; JONES JP, 1987, J NEUROPHYSIOL, V58, P1233, DOI 10.1152/jn.1987.58.6.1233; JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0; KANATANI K, 1984, ARTIF INTELL, V23, P213, DOI 10.1016/0004-3702(84)90010-9; KANATANI K, 1989, ARTIF INTELL, V38, P1, DOI 10.1016/0004-3702(89)90066-0; KOENDERINK JJ, 1976, BIOL CYBERN, V21, P29, DOI 10.1007/BF00326670; KOENDERINK JJ, 1992, IEEE T PATTERN ANAL, V14, P597, DOI 10.1109/34.141551; KOENDERINK JJ, 1990, BIOL CYBERN, V63, P291, DOI 10.1007/BF00203452; Lindeberg T., 1993, Proceedings of the 8th Scandinavian Conference on Image Analysis, P857; LINDEBERG T, 1993, INT J COMPUT VISION, V11, P283, DOI 10.1007/BF01469346; LINDEBERG T, 1990, IEEE T PATTERN ANAL, V12, P234, DOI 10.1109/34.49051; Lindeberg T., 1993, Journal of Mathematical Imaging and Vision, V3, P349, DOI 10.1007/BF01664794; Lindeberg T., 1994, SCALE SPACE THEORY C; LINDEBERG T, 1994, P 3 EUR C COMP VIS S, V800, P389; LINDEBERG T, 1994, KTHNAP9403SE ISRN RO; MALIK J, 1990, J OPT SOC AM A, V7, P923, DOI 10.1364/JOSAA.7.000923; MARDIA KV, 1972, STATISTICS DIRECTION; MARR D, 1976, PHILOS T R SOC B, V275, P483, DOI 10.1098/rstb.1976.0090; Marr D., 1982, VISION; ONeill B., 1966, ELEMENTARY DIFFERENT; PENTLAND AP, 1986, ARTIF INTELL, V29, P147, DOI 10.1016/0004-3702(86)90017-2; POLLARD SB, 1985, PERCEPTION, V14, P449, DOI 10.1068/p140449; RAO AR, 1991, CVGIP-GRAPH MODEL IM, V53, P157, DOI 10.1016/1049-9652(91)90059-S; ROGERS B J, 1989, Investigative Ophthalmology and Visual Science, V30, P262; STONE JV, 1990, P BRIT MACH VIS C, P181; Super B. J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P296, DOI 10.1109/CVPR.1992.223260; TURNER MR, 1986, BIOL CYBERN, V55, P71; TYLER CW, 1979, VISION RES, V19, P859, DOI 10.1016/0042-6989(79)90019-1; VOORHEES H, 1987, P 1 INT C COMP VIS L; WILDES RP, 1991, IEEE T PATTERN ANAL, V13, P761, DOI 10.1109/34.85667; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; WITKIN AP, 1981, ARTIF INTELL, V17, P17, DOI 10.1016/0004-3702(81)90019-9; YOUNG R A, 1987, Spatial Vision, V2, P273, DOI 10.1163/156856887X00222; YOUNG RA, 1985, GMR4920 GEN MOT RES; YUILLE AL, 1986, IEEE T PATTERN ANAL, V8, P15, DOI [10.1109/34.41383, 10.1109/TPAMI.1986.4767748]	59	88	93	1	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	FEB	1996	17	2					163	191		10.1007/BF00058750	http://dx.doi.org/10.1007/BF00058750			29	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	TZ498		Green Submitted			2022-12-18	WOS:A1996TZ49800004
J	AYACHE, N; FAVERJON, B				AYACHE, N; FAVERJON, B			EFFICIENT REGISTRATION OF STEREO IMAGES BY MATCHING GRAPH DESCRIPTIONS OF EDGE SEGMENTS	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article									INST NATL RECH INFORMAT & AUTOMAT, DOMAINE VOLUCEAU, BP 105, F-78153 LE CHESNAY, FRANCE									Arnold R. D., 1980, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V238, P281; Ayache N., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P662; AYACHE N, 1986, IEEE T PATTERN ANAL, V8, P44, DOI 10.1109/TPAMI.1986.4767751; AYACHE N, 1987, 1ST P INT C COMP VIS; AYACHE N, 1985, 3RD P WORKSH COMP VI, P27; AYACHE N, 1985, 3RD P WORKSH COMP VI, P197; BAKER HH, 1981, 7TH P INT JOINT C AR, P631; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; BENARD M, 1983, P EURASIP ERLANGEN, P227; Berthod M., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P841; BERTHOD M, 1987, IN PRESS POLYGONAL A; CANNY JF, 1983, MIT AI720 ART INT LA; Castan S., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P444; DERICHE R, 1987, INT J COMPUT VISION; Elmenreich W., 2002, P IEEE INT C ROB AUT, V502; Faugeras O. D., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P15; Gennery D. B., 1977, P 5 INT JOINT C ART, V2, P576; GRIMSON WEL, 1984, MIT AI762 MEM; GRIMSON WEL, 1981, IMAGES SURFACES; HWANG JJ, 1982, COMPUT VISION GRAPH, V20, P22, DOI 10.1016/0146-664X(82)90071-5; Keskes N., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P855; KNUTH DE, 1975, ART COMPUTER PROGRAM, V3; MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MAYHEW JEW, 1981, ARTIF INTELL, V17, P349, DOI 10.1016/0004-3702(81)90029-1; MEDIONI G, 1983, P IMAGE UNDERSTANDIN, P128; MOHR R, 1984, 4TH P AFCET INRIA C, P71; Morevec H.P., 1977, INT JOINT C ART INT, V2, P584; Mori K., 1973, COMPUT GRAPHICS IMAG, V2, P393; NEVATIA R, 1976, COMPUT GRAPH IMAGE P, V5, P203; NISHIHARA HK, 1984, MIT AI780 MEM; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; Pavlidis T., 1977, STRUCTURAL PATTERN R; POGGIO GF, 1984, ANNU REV NEUROSCI, V7, P379, DOI 10.1146/annurev.ne.07.030184.002115; POLLARD S, 1986, AIVRU010 U SHEFF INT; RHOUMA KB, 1983, 1983 P EURASIP ERL; Yagi, 1973, COMPUT VISION GRAPH, V2, P131	37	88	90	0	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.		1987	1	2					107	131		10.1007/BF00123161	http://dx.doi.org/10.1007/BF00123161			25	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	M2049		Green Submitted			2022-12-18	WOS:A1987M204900001
J	Zhang, DW; Han, JW; Zhao, L; Meng, DY				Zhang, Dingwen; Han, Junwei; Zhao, Long; Meng, Deyu			Leveraging Prior-Knowledge for Weakly Supervised Object Detection Under a Collaborative Self-Paced Curriculum Learning Framework	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Weakly supervised learning; Object detection; Self-paced larning	LOCALIZATION	Weakly supervised object detection is an interesting yet challenging research topic in computer vision community, which aims at learning object models to localize and detect the corresponding objects of interest only under the supervision of image-level annotation. For addressing this problem, this paper establishes a novel weakly supervised learning framework to leverage both the instance-level prior-knowledge and the image-level prior-knowledge based on a novel collaborative self-paced curriculum learning (C-SPCL) regime. Under the weak supervision, C-SPCL can leverage helpful prior-knowledge throughout the whole learning process and collaborate the instance-level confidence inference with the image-level confidence inference in a robust way. Comprehensive experiments on benchmark datasets demonstrate the superior capacity of the proposed C-SPCL regime and the proposed whole framework as compared with state-of-the-art methods along this research line.	[Zhang, Dingwen; Han, Junwei; Zhao, Long] Northwestern Polytech Univ, Sch Automat, Xian 710072, Peoples R China; [Meng, Deyu] Xi An Jiao Tong Univ, Inst Informat & Syst Sci, Sci, Xian, Shaanxi, Peoples R China; [Meng, Deyu] Xi An Jiao Tong Univ, Minist Educ, Key Lab Intelligent Networks & Network Secur, Xian, Shaanxi, Peoples R China	Northwestern Polytechnical University; Xi'an Jiaotong University; Xi'an Jiaotong University	Han, JW (corresponding author), Northwestern Polytech Univ, Sch Automat, Xian 710072, Peoples R China.	junweihan2010@gmail.com; dymeng@xjtu.edu.cn	zhang, dingwen/R-3463-2019	zhang, dingwen/0000-0001-8369-8886	National Key R&D Program of China [2017YFB0502904]; National Science Foundation of China [61876140, 61773301]; Fundamental Research Funds for the Central Universities [JBZ170401]; China Postdoctoral Support Scheme for Innovative Talents [BX20180236]	National Key R&D Program of China; National Science Foundation of China(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); China Postdoctoral Support Scheme for Innovative Talents	This work was supported in part by the "National Key R&D Program of China" (2017YFB0502904), the National Science Foundation of China under Grants 61876140 and 61773301, the Fundamental Research Funds for the Central Universities under Grant JBZ170401, and the China Postdoctoral Support Scheme for Innovative Talents under Grant BX20180236.	Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Bengio Yoshua., 2009, P 26 ANN INT C MACHI, P41, DOI 10.1145/ 1553374.1553380; Bilen H, 2014, P BMVC 2014, P1997; Bilen H, 2015, PROC CVPR IEEE, P1081, DOI 10.1109/CVPR.2015.7298711; Bilen Hakan, 2016, CVPR, DOI DOI 10.1109/CVPR.2016.331; Chen XL, 2015, IEEE I CONF COMP VIS, P1431, DOI 10.1109/ICCV.2015.168; Cinbis R., 2014, CVPR; Cinbis RG, 2017, IEEE T PATTERN ANAL, V39, P189, DOI 10.1109/TPAMI.2016.2535231; Deselaers T, 2012, INT J COMPUT VISION, V100, P275, DOI 10.1007/s11263-012-0538-3; Deselaers T, 2010, LECT NOTES COMPUT SC, V6314, P452, DOI 10.1007/978-3-642-15561-1_33; Diba A, 2017, PROC CVPR IEEE, P1541, DOI 10.1109/CVPR.2017.168; Everingham M., 2007, PASCAL VISUAL OBJECT, DOI DOI 10.1007/S11263-014-0733-5; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Girshick R., 2015, ICCV; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424; Jiang L, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P547, DOI 10.1145/2647868.2654918; Jiang L, 2015, AAAI CONF ARTIF INTE, P2694; Jiang L, 2014, ADV NEUR IN, V27; Jie ZQ, 2017, PROC CVPR IEEE, P4294, DOI 10.1109/CVPR.2017.457; Kantorov V, 2016, LECT NOTES COMPUT SC, V9909, P350, DOI 10.1007/978-3-319-46454-1_22; Khan Faisal, 2011, ADV NEURAL INFORM PR, P1449; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kumar M., 2010, NIPS, P1189, DOI DOI 10.5555/2997189.2997322; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Meng DY, 2017, INFORM SCIENCES, V414, P319, DOI 10.1016/j.ins.2017.05.043; Pandey M, 2011, IEEE I CONF COMP VIS, P1307, DOI 10.1109/ICCV.2011.6126383; Ren WQ, 2016, IEEE T PATTERN ANAL, V38, P405, DOI 10.1109/TPAMI.2015.2456908; Russakovsky O, 2012, LECT NOTES COMPUT SC, V7573, P1, DOI 10.1007/978-3-642-33709-3_1; Shi M., 2016, ECCV; Shi ZY, 2015, IEEE T PATTERN ANAL, V37, P1959, DOI 10.1109/TPAMI.2015.2392769; Singh K.K., 2016, CVPR; Siva P, 2013, PROC CVPR IEEE, P3238, DOI 10.1109/CVPR.2013.416; Siva P, 2012, LECT NOTES COMPUT SC, V7574, P594, DOI 10.1007/978-3-642-33712-3_43; Siva P, 2011, IEEE I CONF COMP VIS, P343, DOI 10.1109/ICCV.2011.6126261; Song HO., 2014, ADV NEURAL INFORM PR, V2, P1637; Song HO, 2014, PR MACH LEARN RES, V32, P1611; Spitkovsky V. I., 2009, NIPS GRAMMAR INDUCTI; Su SC, 2016, PROC CVPR IEEE, pCP40, DOI 10.1109/CVPR.2016.382; Supancic D., 2013, CVPR; Tang Y., 2012, ACM MM; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Wang Chong, 2014, ECCV; Wang L, 2014, LECT NOTES COMPUT SC, V8692, P640, DOI 10.1007/978-3-319-10593-2_42; Yang X, 2007, INT J PATTERN RECOGN, V21, P961, DOI 10.1142/S0218001407005703; Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222; Zhang D., 2016, IJCAI; Zhang D., 2017, CVPR; Zhang DW, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3158674; Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	54	87	90	3	22	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	2019	127	4					363	380		10.1007/s11263-018-1112-4	http://dx.doi.org/10.1007/s11263-018-1112-4			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	HN4DR					2022-12-18	WOS:000460135000003
J	Wang, P; Zeng, G; Gan, R; Wang, JD; Zha, HB				Wang, Peng; Zeng, Gang; Gan, Rui; Wang, Jingdong; Zha, Hongbin			Structure-Sensitive Superpixels via Geodesic Distance	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Superpixel segmentation; Geodesic distance; Iterative optimization; Structure-sensitivity	ALGORITHM; SEGMENTATION; RECOGNITION; CONTEXT	Segmenting images into superpixels as supporting regions for feature vectors and primitives to reduce computational complexity has been commonly used as a fundamental step in various image analysis and computer vision tasks. In this paper, we describe the structure-sensitive superpixel technique by exploiting Lloyd's algorithm with the geodesic distance. Our method generates smaller superpixels to achieve relatively low under-segmentation in structure-dense regions with high intensity or color variation, and produces larger segments to increase computational efficiency in structure-sparse regions with homogeneous appearance. We adopt geometric flows to compute geodesic distances amongst pixels. In the segmentation procedure, the density of over-segments is automatically adjusted through iteratively optimizing an energy functional that embeds color homogeneity, structure density. Comparative experiments with the Berkeley database show that the proposed algorithm outperforms the prior arts while offering a comparable computational efficiency as TurboPixels. Further applications in image compression, object closure extraction and video segmentation demonstrate the effective extensions of our approach.	[Wang, Peng; Zeng, Gang; Zha, Hongbin] Peking Univ, Key Lab Machine Percept, Beijing 100871, Peoples R China; [Gan, Rui] Peking Univ, Sch Math Sci, Beijing 100871, Peoples R China; [Wang, Jingdong] Microsoft Res Asia, Beijing, Peoples R China	Peking University; Peking University; Microsoft; Microsoft Research Asia	Zeng, G (corresponding author), Peking Univ, Key Lab Machine Percept, Beijing 100871, Peoples R China.	jerrywang@pku.edu.cn; g.zeng@ieee.org; raygan@ieee.org; jingdw@microsoft.com; zha@cis.pku.edu.cn	Wang, Jingdong/E-9920-2017	Wang, Jingdong/0000-0002-4888-4445	National Nature Science Foundation of China (NSFC) [61005037, 90920304]; National Basic Research Program of China (973 Program) [2011CB302202]; Beijing Natural Science Foundation (BJNSF) [4113071]	National Nature Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); National Basic Research Program of China (973 Program)(National Basic Research Program of China); Beijing Natural Science Foundation (BJNSF)	This work is supported by National Nature Science Foundation of China (NSFC Grant) 61005037 and 90920304, National Basic Research Program of China (973 Program) 2011CB302202, and Beijing Natural Science Foundation (BJNSF Grant) 4113071.	Achanta R., 2010, 149300 EPFL; Alpert S., 2007, CVPR; Arbelaez P, 2009, PROC CVPR IEEE, P2294, DOI 10.1109/CVPRW.2009.5206707; Bai XF, 2007, IEEE IC COMP COM NET, P1; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Criminisi A, 2008, LECT NOTES COMPUT SC, V5302, P99, DOI 10.1007/978-3-540-88682-2_9; Dollar P., 2006, P IEEE COMP SOC C CO, V2, P1964, DOI DOI 10.1109/CVPR.2006.298; Du Q, 2006, SIAM J NUMER ANAL, V44, P102, DOI 10.1137/040617364; Feil B, 2007, ADV SOFT COMP, V39, P50; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Fulkerson B., 2009, IEEE I CONF COMP VIS, P670, DOI [10.1109/ICCV.2009.5459175, DOI 10.1109/ICCV.2009.5459175]; Gulshan V, 2010, PROC CVPR IEEE, P3129, DOI 10.1109/CVPR.2010.5540073; Harel J., 2006, PAPER PRESENTED INT, P545, DOI DOI 10.7551/MITPRESS/7503.003.0073; He XM, 2006, LECT NOTES COMPUT SC, V3951, P338; Hoiem D, 2005, IEEE I CONF COMP VIS, P654; Hyvarinen A, 1999, NEURAL PROCESS LETT, V10, P1, DOI 10.1023/A:1018647011077; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Kaufhold J, 2006, INT C PATT RECOG, P755; Kim J, 2007, INT CONF ACOUST SPEE, P429; Levinshtein A., 2010, ECCV, V2, P429; Levinshtein A, 2009, IEEE I CONF COMP VIS, P2162, DOI 10.1109/ICCV.2009.5459472; Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96; Li YJ, 2007, J SUPERCOMPUT, V39, P19, DOI 10.1007/s11227-006-0002-7; Liu C, 2009, PROC CVPR IEEE, P1972, DOI 10.1109/CVPRW.2009.5206536; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; Maire M., 2008, CVPR; Malisiewicz T., 2007, BMVC; Martin D., 2001, P ICCV, P416, DOI DOI 10.1109/ICCV.2001.937655; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Meyer F, 1999, LECT NOTES COMPUT SC, V1682, P351; Micusik B, 2010, INT J COMPUT VISION, V89, P106, DOI 10.1007/s11263-010-0327-9; Moore A., 2008, CVPR; Moore AP, 2010, PROC CVPR IEEE, P2117, DOI 10.1109/CVPR.2010.5539890; Moore AP, 2009, IEEE I CONF COMP VIS, P771, DOI 10.1109/ICCV.2009.5459246; Mori G, 2005, IEEE I CONF COMP VIS, P1417; Muhr M, 2009, PROCEEDINGS OF THE 20TH INTERNATIONAL WORKSHOP ON DATABASE AND EXPERT SYSTEMS APPLICATION, P363, DOI 10.1109/DEXA.2009.39; Nwogu I., 2008, CVPR; Peyre G, 2009, FOUND TRENDS COMPUT, V5, DOI 10.1561/0600000029; Rasmussen C, 2007, LECT NOTES COMPUT SC, V4841, P46; Russell B. C., 2006, P IEEE C COMP VIS PA, V2, P1605; Savaresi S. M., 2004, Intelligent Data Analysis, V8, P345; Sethian JA, 1996, P NATL ACAD SCI USA, V93, P1591, DOI 10.1073/pnas.93.4.1591; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1; Tai XC, 2007, LECT NOTES COMPUT SC, V4485, P178; Veksler O, 2010, LECT NOTES COMPUT SC, V6315, P211, DOI 10.1007/978-3-642-15555-0_16; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344; Wang J., 2008, CVPR; Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385; Xiao JX, 2009, IEEE I CONF COMP VIS, P686, DOI 10.1109/ICCV.2009.5459249; Yatziv L, 2006, J COMPUT PHYS, V212, P393, DOI 10.1016/j.jcp.2005.08.005	52	87	97	1	42	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2013	103	1					1	21		10.1007/s11263-012-0588-6	http://dx.doi.org/10.1007/s11263-012-0588-6			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	137CV		Green Submitted			2022-12-18	WOS:000318413500001
J	Zheng, L; Wang, SJ; Wang, JD; Tian, Q				Zheng, Liang; Wang, Shengjin; Wang, Jingdong; Tian, Qi			Accurate Image Search with Multi-Scale Contextual Evidences	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Image search; BoW model; Convolutional neural network; Contextual evidences	REPRESENTATION; FEATURES	This paper considers the task of image search using the Bag-of-Words (BoW) model. In this model, the precision of visual matching plays a critical role. Conventionally, local cues of a keypoint, e.g., SIFT, are employed. However, such strategy does not consider the contextual evidences of a keypoint, a problem which would lead to the prevalence of false matches. To address this problem and enable accurate visual matching, this paper proposes to integrate discriminative cues frommultiple contextual levels, i.e., local, regional, and global, via probabilistic analysis. "True match" is defined as a pair of keypoints corresponding to the same scene location on all three levels (Fig. 1). Specifically, the Convolutional Neural Network (CNN) is employed to extract features from regional and global patches. We show that CNN feature is complementary to SIFT due to its semantic awareness and compares favorably to several other descriptors such as GIST, HSV, etc. To reduce memory usage, we propose to index CNN features outside the inverted file, communicated by memory-efficient pointers. Experiments on three benchmark datasets demonstrate that our method greatly promotes the search accuracy when CNN feature is integrated. We show that our method is efficient in terms of time cost compared with the BoW baseline, and yields competitive accuracy with the state-of-the-arts.	[Zheng, Liang; Wang, Shengjin] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China; [Wang, Jingdong] Microsoft Res Asia, Media Comp Grp, Beijing 100084, Peoples R China; [Zheng, Liang; Tian, Qi] Univ Texas San Antonio, San Antonio, TX 78249 USA	Tsinghua University; Microsoft; Microsoft Research Asia; University of Texas System; University of Texas at San Antonio (UTSA)	Wang, SJ (corresponding author), Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.; Tian, Q (corresponding author), Univ Texas San Antonio, San Antonio, TX 78249 USA.	liangzheng06@gmail.com; wgsgj@tsinghua.edu.cn; jingdw@microsoft.com; qitian@cs.utsa.edu	Wang, Jingdong/E-9920-2017	Wang, Jingdong/0000-0002-4888-4445	National High Technology Research and Development Program of China (863 program) [2012AA011004]; National Science and Technology Support Program [2013BAK02B04]; ARO [W911NF-15-1-0290]; NEC Laboratories of America and Blippar; National Science Foundation of China (NSFC) [61429201]	National High Technology Research and Development Program of China (863 program)(National High Technology Research and Development Program of China); National Science and Technology Support Program; ARO; NEC Laboratories of America and Blippar; National Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC))	This work was supported by the National High Technology Research and Development Program of China (863 program) under Grant No. 2012AA011004 and the National Science and Technology Support Program under Grant No. 2013BAK02B04. This work was supported in part to Dr. Qi Tian by ARO grants W911NF-15-1-0290 and Faculty Research Gift Awards by NEC Laboratories of America and Blippar. This work was supported in part by National Science Foundation of China (NSFC) 61429201.	[Anonymous], 2010, MIR 10 P 2010 ACM IN; Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018; Arandjelovic R, 2011, IEEE I CONF COMP VIS, P375, DOI 10.1109/ICCV.2011.6126265; Babenko A, 2014, ARXIV14041777; Carson C., 1998, P 3 INT C VIS INF SY, P509, DOI DOI 10.1007/3-540-48762-X_63; Charikar M.S., 2002, P 34 ANN ACM S THEOR, V34, P380, DOI DOI 10.1145/509907.509965; Chen YX, 2002, IEEE T PATTERN ANAL, V24, P1252, DOI 10.1109/TPAMI.2002.1033216; Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Deng C, 2013, IEEE I CONF COMP VIS, P2600, DOI 10.1109/ICCV.2013.323; Donahue J., 2013, 31 INT C MACH LEARN; Fang Quan, 2013, P 21 ACM INT C MULT, P13, DOI DOI 10.1145/2502081.2502088; Ge TZ, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.132; Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26; Han GL, 2015, IEEE IC COMP COM NET; Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24; Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Jegou H, 2009, PROC CVPR IEEE, P1169, DOI 10.1109/CVPRW.2009.5206609; Lazebnik S., 2006, P IEEE INT C COMP VI, P2169, DOI DOI 10.1109/CVPR.2006.68; LeCun Y, 2004, PROC CVPR IEEE, P97; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803; Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424; Niester D., 2006, CVPR; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Perd'och M, 2009, PROC CVPR IEEE, P9, DOI 10.1109/CVPRW.2009.5206529; PERRONNIN F, 2010, PROC CVPR IEEE, P3384, DOI DOI 10.1109/CVPR.2010.5540009; Qin DF, 2013, PROC CVPR IEEE, P1610, DOI 10.1109/CVPR.2013.211; Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131; Shen X, 2012, C COMP VIS PATT REC, DOI DOI 10.1109/CVPR.2012.6248031; Shi M., 2015, COMPUTER VISION PATT; Souvannavong F., 2005, INT WORKSH CONT BAS; Tao R, 2014, PROC CVPR IEEE, P2099, DOI 10.1109/CVPR.2014.269; Tolias G, 2013, IEEE I CONF COMP VIS, P1401, DOI 10.1109/ICCV.2013.177; van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132; Wang J., 2014, HASHING SIMILARITY S; Wengert C., 2011, P 19 ACM INT C MULT, P1437, DOI [10.1145/2072298.2072034, DOI 10.1145/2072298.2072034]; White T., 2012, HADOOP DEFINITIVE GU; Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224; Xie L., 2015, INT C MULT RETR; Zhang Hanwang, 2013, P INT ACM C MULT, P33, DOI DOI 10.1145/2502081.2502093; Zhang ST, 2012, LECT NOTES COMPUT SC, V7573, P660, DOI 10.1007/978-3-642-33709-3_47; Zhang SL, 2013, IEEE I CONF COMP VIS, P1673, DOI 10.1109/ICCV.2013.210; Zheng L., 2014, CVPR; Zheng L., 2014, CVPR 2014; Zheng L, 2015, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2015.7298783	47	85	86	0	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	OCT	2016	120	1					1	13		10.1007/s11263-016-0889-2	http://dx.doi.org/10.1007/s11263-016-0889-2			13	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	DU3DX					2022-12-18	WOS:000382092100001
J	Giese, MA; Poggio, T				Giese, MA; Poggio, T			Morphable models for the analysis and synthesis of complex motion patterns	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						computer vision; learning; morphing; action recognition; nonrigid motion; animation; prototype; linear superposition; correspondence; structural risk minimization	RECOGNITION; IMAGE	The linear combination of prototypical views provides a powerful approach for the recognition and the synthesis of images of stationary three-dimensional objects. In this article, we present initial results that demonstrate that similar ideas can be developed for the recognition and synthesis of complex motion patterns. We present a technique that permits to represent complex motion or action patterns by linear combinations of a small number of prototypical image sequences. We demonstrate the applicability of this new approach for the synthesis and analysis of biological motion using simulated and real video data from different locomotion patterns. Our results show that complex motion patterns are embedded in pattern spaces with a defined topological structure, which can be uncovered with our methods. The underlying pattern space seems to have locally, but not globally, the properties of a linear vector space. We show how the knowledge about the topology of the pattern space can be exploited during pattern recognition. Our method may provide a new interesting approach for the analysis and synthesis of video sequences and complex movements.	MIT, Artificial Intelligence Lab, Ctr Biol & Computat Learning, Cambridge, MA 02139 USA	Massachusetts Institute of Technology (MIT)	Giese, MA (corresponding author), MIT, Artificial Intelligence Lab, Ctr Biol & Computat Learning, Cambridge, MA 02139 USA.	giese@mit.edu; tp@ai.mit.edu						AHMAD T, 1997, IN PRESS IMAGE VISIO, V19; BADLER NI, 1993, SIMULATING HUMANS; Beymer D, 1996, SCIENCE, V272, P1905, DOI 10.1126/science.272.5270.1905; BEYMER D, 1993, 1431 MIT; BLACK MJ, 1996, P EUR C COMP VIS COM; Blake A., 1998, ACTIVE CONTOURS, DOI [10.1007/978-1-4471-1555-7, DOI 10.1007/978-1-4471-1555-7]; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; BRUDERLIN A, 1995, P 22 ANN C COMP GRAP, P97, DOI DOI 10.1145/218380.218421; DARRELL TJ, 1995, 364 MIT; DAVIS JW, 1996, 402 MIT; Essa IA, 1997, IEEE T PATTERN ANAL, V19, P757, DOI 10.1109/34.598232; EZZAT T, 1999, 1658 MIT; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; Giese MA, 1999, IEEE WORKSHOP ON MULTI-VIEW MODELING & ANALYSIS OF VISUAL SCENES (MVIEW'99). PROCEEDINGS, P73, DOI 10.1109/MVIEW.1999.781085; JONES M, 1997, THESIS MIT CAMBRIDGE; JONES M, 1997, P DARPA IM UND WORKS, P1357; Lee J, 1999, COMP GRAPH, P39; NIYOGI SA, 1994, 223 MIT; OROURKE J, 1980, IEEE T PATTERN ANAL, V2, P522, DOI 10.1109/TPAMI.1980.6447699; POGGIO T, 1990, NATURE, V343, P263, DOI 10.1038/343263a0; Rabiner L., 1993, FUNDAMENTALS SPEECH; SHELTON CR, 1998, THESIS DEP COMPUTER; STAMER T, 1995, P INT WORKSH AUT FAC, P265; Takahashi K., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P23, DOI 10.1109/MNRAO.1994.346259; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; Vapnik V.N, 1998, STAT LEARNING THEORY; Vetter T, 1997, IEEE T PATTERN ANAL, V19, P733, DOI 10.1109/34.598230; Vetter T, 1998, INT J COMPUT VISION, V28, P103, DOI 10.1023/A:1008058932445; VETTER T, 1995, 1531 MIT; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236; Yacoob Y, 1999, COMPUT VIS IMAGE UND, V73, P232, DOI 10.1006/cviu.1998.0726	32	85	85	0	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2000	38	1					59	73		10.1023/A:1008118801668	http://dx.doi.org/10.1023/A:1008118801668			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	342GH					2022-12-18	WOS:000088636500006
J	Bab-Hadiashar, A; Suter, D				Bab-Hadiashar, A; Suter, D			Robust optic flow computation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							LEAST-SQUARES METHODS; REGRESSION; MOTION; PERFORMANCE; VELOCITY; FIELDS	This paper formulates the optic flow problem as a set of over-determined simultaneous linear equations. It then introduces and studies two new robust optic flow methods. The first technique is based on using the Least Median of Squares (LMedS) to detect the outliers. Then, the inlier group is solved using the least square technique. The second method employs a new robust statistical method named the Least Median of Squares Orthogonal Distances (LMSOD) to identify the outliers and then uses total least squares to solve the optic flow problem. The performance of both methods are studied by experiments on synthetic and real image sequences. These methods outperform other published methods both in accuracy and robustness.	Monash Univ, Dept Elect & Comp Syst Engn, Intelligent Robot Res Ctr, Clayton, Vic 3168, Australia	Monash University	Bab-Hadiashar, A (corresponding author), Monash Univ, Dept Elect & Comp Syst Engn, Intelligent Robot Res Ctr, Clayton, Vic 3168, Australia.	ali.bab-hadiashar@eng.monash.edu.au; david.suter@eng.monash.edu.au	Bab-Hadiashar, Alireza/A-9157-2010	Bab-Hadiashar, Alireza/0000-0002-6192-2303; Suter, David/0000-0001-6306-3023				BABHADIASHAR A, 1996, 962 MECSE MON U; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Bergen J. R., 1991, Artificial Intelligence and Computer Vision. Proceedings of the Seventh Israeli Conference, P147; BERGEN JR, 1992, P EUR C COMP VIS, P237; BLACK M, 1994, P EUR C COMP VIS STO, P138; Black M. J., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P296, DOI 10.1109/CVPR.1991.139705; Black M. J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P231, DOI 10.1109/ICCV.1993.378214; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; BLACK MJ, 1994, WORKSH MOT NONR ART, P220; BOBER M, 1994, IMAGE VISION COMPUT, V12, P661, DOI 10.1016/0262-8856(94)90041-8; BOBER M, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P947, DOI 10.1109/CVPR.1994.323931; Burt P. J., 1989, Proceedings. Workshop on Visual Motion (IEEE Cat. No.89CH2716-9), P2, DOI 10.1109/WVM.1989.47088; CAFFORIO C, 1976, IEEE T INFORM THEORY, V22, P573, DOI 10.1109/TIT.1976.1055602; CHAUDHURI S, 1991, IEEE T ROBOTIC AUTOM, V7, P707, DOI 10.1109/70.97884; CHU CH, 1989, J OPT SOC AM A, V6, P871, DOI 10.1364/JOSAA.6.000871; Darrell T., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P173, DOI 10.1109/WVM.1991.212810; EDELSBRUNNER H, 1990, J AM STAT ASSOC, V85, P115, DOI 10.2307/2289532; FENNEMA CL, 1979, COMPUT VISION GRAPH, V9, P301, DOI 10.1016/0146-664X(79)90097-2; FLEET DJ, 1990, INT J COMPUT VISION, V5, P77, DOI 10.1007/BF00056772; GIACHETTI A, 1996, P 4 EUR C COMP VIS E, P151; Hampel FR., 2011, WILEY SERIES PROBABI; HEEGER D, 1997, COMMUNICATION; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; IU SL, 1995, J VIS COMMUN IMAGE R, V6, P132, DOI 10.1006/jvci.1995.1012; Jahne B, 1993, SPATIO TEMPORAL IMAG; Jepson A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P760, DOI 10.1109/CVPR.1993.341161; JEPSON AD, 1995, DIMACS SERIES DISCRE, V19, P271; Ju SX, 1996, PROC CVPR IEEE, P307, DOI 10.1109/CVPR.1996.517090; KVALSETH TO, 1985, AM STAT, V39, P279, DOI 10.2307/2683704; LIMB JO, 1975, IEEE T COMMUN, VCO23, P474, DOI 10.1109/TCOM.1975.1092828; LIU H, 1996, P 4 EUR C COMP VIS E, P174; MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126; MITICHE A, 1994, COMPUTATIONAL ANAL V; NAGEL HH, 1987, ARTIF INTELL, V33, P299, DOI 10.1016/0004-3702(87)90041-5; NAGEL HH, 1995, INT J COMPUT VISION, V15, P271, DOI 10.1007/BF01451744; NESI P, 1995, COMPUT VIS IMAGE UND, V62, P59, DOI 10.1006/cviu.1995.1041; ODOBEZ JM, 1995, J VIS COMMUN IMAGE R, V6, P348, DOI 10.1006/jvci.1995.1029; OTTE M, 1994, P 3 EUR C COMP VIS S, P51; Rousseeuw P. J., 1987, ROBUST REGRESSION OU; ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718; SCHUNCK BG, 1989, IEEE T PATTERN ANAL, V11, P1010, DOI 10.1109/34.42834; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; STEELE JM, 1986, DISCRETE APPL MATH, V14, P93, DOI 10.1016/0166-218X(86)90009-0; STEWART C, 1996, TR121803590 RENSS PO; SZELISKI R, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P194, DOI 10.1109/CVPR.1994.323829; Van Huffel S., 1991, TOTAL LEAST SQUARES; VANMIEGHEM JA, 1995, J VIS COMMUN IMAGE R, V6, P59, DOI 10.1006/jvci.1995.1005; WANG S, 1992, P SOC PHOTO-OPT INS, V1698, P42, DOI 10.1117/12.139397; WEBER J, 1995, INT J COMPUT VISION, V14, P67, DOI 10.1007/BF01421489	50	85	88	0	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	1998	29	1					59	77		10.1023/A:1008090730467	http://dx.doi.org/10.1023/A:1008090730467			19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	125XY					2022-12-18	WOS:000076263700004
J	Qi, GJ				Qi, Guo-Jun			Loss-Sensitive Generative Adversarial Networks on Lipschitz Densities	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article								In this paper, we present the Lipschitz regularization theory and algorithms for a novel Loss-Sensitive Generative Adversarial Network (LS-GAN). Specifically, it trains a loss function to distinguish between real and fake samples by designated margins, while learning a generator alternately to produce realistic samples by minimizing their losses. The LS-GAN further regularizes its loss function with a Lipschitz regularity condition on the density of real data, yielding a regularized model that can better generalize to produce new data from a reasonable number of training examples than the classic GAN. We will further present a Generalized LS-GAN (GLS-GAN) and show it contains a large family of regularized GAN models, including both LS-GAN and Wasserstein GAN, as its special cases. Compared with the other GAN models, we will conduct experiments to show both LS-GAN and GLS-GAN exhibit competitive ability in generating new images in terms of the Minimum Reconstruction Error (MRE) assessed on a separate test set. We further extend the LS-GAN to a conditional form for supervised and semi-supervised learning problems, and demonstrate its outstanding performance on image classification tasks.	[Qi, Guo-Jun] Futurewei Technol, Bellevue, WA 98007 USA	Huawei Technologies	Qi, GJ (corresponding author), Futurewei Technol, Bellevue, WA 98007 USA.	guojun.qi@futurewei.com	Qi, Guo-Jun/AAH-8294-2019	Qi, Guo-Jun/0000-0003-3508-1851				Arjovsky M., 2017, ARXIV170107875; Arjovsky Mart<prime>in, 2017, P 5 INT C LEARN REPR; Arora S., 2017, RXIV170300573; Border K.C., 1989, FIXED POINT THEOREMS; Carando D, 2009, J MULTIVARIATE ANAL, V100, P981, DOI 10.1016/j.jmva.2008.10.001; Coates A., 2011, ADV NEURAL INFORM PR, P2528, DOI DOI 10.1016/J.PSYCHRES.2009.03.008; Denton Emily L, 2015, NEURIPS, V2, P4; Dosovitskiy A, 2016, IEEE T PATTERN ANAL, V38, P1734, DOI 10.1109/TPAMI.2015.2496141; Dosovitskiy A, 2015, PROC CVPR IEEE, P1538, DOI 10.1109/CVPR.2015.7298761; Dumoulin Vincent, 2016, ARXIV E PRINTS; Edraki M, 2018, LECT NOTES COMPUT SC, V11209, P90, DOI 10.1007/978-3-030-01228-1_6; Gatys LA., 2015, PROC CVPR IEEE, V16, P326, DOI [10.1167/16.12.326, DOI 10.1109/CVPR.2016.265]; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gregor K, 2015, PR MACH LEARN RES, V37, P1462; Gulrajani I, 2017, P NIPS 2017; Hui K. Y, 2013, INT C MACH LEARN, P352; Im D., 2016, GENERATING IMAGES RE; Kingma D.P, P 3 INT C LEARNING R; Kingma D. P, 2014, ARXIV13126114; Kingma D. P., 2013, AUTO ENCODING VARIAT; Krizhevsky A, 2009, LEARNING MULTIPLE LA; Laine Samuli, 2016, ARXIV161002242; Maaloe L, 2016, PR MACH LEARN RES, V48; Mirza M., 2014, ARXIV; Miyato T, 2015, ARXIV150700677; Nagarajan V, 2017, ADV NEUR IN, V30; Netzer Y, 2011, NIPS WORKSH DEEP LEA, P2011, DOI DOI 10.2118/18761-MS; Nowozin S, 2016, ADV NEUR IN, V29; Odena A., 2016, SEMISUPERVISED LEARN; Qi GJ, 2018, PROC CVPR IEEE, P1517, DOI 10.1109/CVPR.2018.00164; Radford A., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.1051/0004-6361/201527329; Rasmus A., 2015, ADV NEURAL INFORM PR, P3546, DOI DOI 10.1186/1477-5956-9-S1-S5; Sajjadi Mehdi, 2016, NEURIPS; Salimans T, 2016, ADV NEUR IN, V29; Springenberg Jost Tobias, 2015, ARXIV151106390; Tarvainen Antti, 2017, CORR, Vabs/1703; Valpola H., 2015, ADV INDEPENDENT COMP, P143, DOI [10.1016/B978-0-12-802806-3.00008-7, DOI 10.1016/B978-0-12-802806-3.00008-7]; Yadav A, 2017, ARXIV PREPRINT ARXIV; Zhao J., 2015, ARXIV150602351; Zhao J, 2016, 2016 IEEE MTT-S INTERNATIONAL WIRELESS SYMPOSIUM (IWS), DOI 10.1109/ICSSSM.2016.7538614; Zhao Y, 2018, IRF2018: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INTEGRITY-RELIABILITY-FAILURE, P507	43	84	86	4	22	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2020	128	5					1118	1140		10.1007/s11263-019-01265-2	http://dx.doi.org/10.1007/s11263-019-01265-2		NOV 2019	23	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	LL3BW		Green Submitted			2022-12-18	WOS:000498972200001
J	Hwang, SJ; Grauman, K				Hwang, Sung Ju; Grauman, Kristen			Learning the Relative Importance of Objects from Tagged Images for Retrieval and Cross-Modal Search	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Image retrieval; Image tags; Multi-modal retrieval; Cross-modal retrieval; Image search; Object recognition; Auto annotation; Kernelized canonical correlation analysis	SCALE	We introduce an approach to image retrieval and auto-tagging that leverages the implicit information about object importance conveyed by the list of keyword tags a person supplies for an image. We propose an unsupervised learning procedure based on Kernel Canonical Correlation Analysis that discovers the relationship between how humans tag images (e.g., the order in which words are mentioned) and the relative importance of objects and their layout in the scene. Using this discovered connection, we show how to boost accuracy for novel queries, such that the search results better preserve the aspects a human may find most worth mentioning. We evaluate our approach on three datasets using either keyword tags or natural language descriptions, and quantify results with both ground truth parameters as well as direct tests with human subjects. Our results show clear improvements over approaches that either rely on image features alone, or that use words and image features but ignore the implied importance cues. Overall, our work provides a novel way to incorporate high-level human perception of scenes into visual representations for enhanced image search.	[Hwang, Sung Ju; Grauman, Kristen] Univ Texas Austin, Dept Comp Sci, Austin, TX 78712 USA	University of Texas System; University of Texas Austin	Hwang, SJ (corresponding author), Univ Texas Austin, Dept Comp Sci, Austin, TX 78712 USA.	sjhwang@cs.utexas.edu; grauman@cs.utexas.edu	Hwang, Sung Ju/A-8817-2018		Luce Foundation; DARPA CSSG [N11AP20004]	Luce Foundation; DARPA CSSG(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA))	We thank the anonymous reviewers for their constructive feedback and helpful suggestions to improve this manuscript. This research is supported in part by the Luce Foundation and DARPA CSSG N11AP20004.	AKAHO S, 2001, INT M PSYCH SOC; [Anonymous], 2005, NIPS; [Anonymous], 2008, CVPR; [Anonymous], 2007, PASCAL VISUAL OBJECT; Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; Bekkerman Ron, 2007, CVPR; Berg T. L., 2004, NIPS; Blaschko M., 2008, CVPR; Dabbish L., 2004, CHI; Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248; Deng J., 2009, CVPR; Duygulu P., 2002, ECCV; Einhauser W, 2008, J VISION, V8, DOI 10.1167/8.2.2; Elazary L, 2008, J VISION, V8, DOI 10.1167/8.3.3; Farhadi A., 2010, ECCV; Fergus R., 2005, ICCV; FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619; Fyfe C., 2001, INT J NEURAL SYST, V10, P365; Gupta A., 2008, ECCV; Hardoon D., 2004, NEURAL COMPUTATION, V16; HARDOON DR, 2003, 3 INT WORKSH CONT BA; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; HWANG S, 2010, CVPR; Hwang S. J., 2010, BRIT MACH VIS C; Jarvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418; Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855; Kulis Brian, 2009, ICCV; Lavrenko V., 2003, NIPS; Li L., 2009, CVPR; Li L.-J., 2007, CVPR; Li Y., 2006, J INTELLIGENT INFORM, V27; LOEFF N, 2008, ECCV; LOWE DG, 2004, IJCV, V60; Makadia A., 2008, ECCV; MONAY F, 2003, ACM MULTIMEDIA; Qi G.J., 2009, ACM MULTIMEDIA; Quack T., 2008, CIVR; Quattoni A., 2007, CVPR; Russell B., 2005, LABELME DATABASE WEB; Schroff F., 2007, ICCV; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Spain M., 2008, ECCV; Tatler BW, 2005, VISION RES, V45, P643, DOI 10.1016/j.visres.2004.09.017; Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951; Wolfe JM, 2004, NAT REV NEUROSCI, V5, P495, DOI 10.1038/nrn1411; Yakhnenko O., 2009, WORKSH VIS CONT LEAR	47	84	92	1	16	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	2012	100	2					134	153		10.1007/s11263-011-0494-3	http://dx.doi.org/10.1007/s11263-011-0494-3			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	000CQ		Green Submitted			2022-12-18	WOS:000308364500003
J	Sudderth, EB; Torralba, A; Freeman, WT; Willsky, AS				Sudderth, Erik B.; Torralba, Antonio; Freeman, William T.; Willsky, Alan S.			Describing visual scenes using transformed objects and parts	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						object recognition; Dirichlet process; hierarchical Dirichlet process; transformation; context; graphical models; scene analysis	SAMPLING METHODS; DIRICHLET	We develop hierarchical, probabilistic models for objects, the parts composing them, and the visual scenes surrounding them. Our approach couples topic models originally developed for text analysis with spatial transformations, and thus consistently accounts for geometric constraints. By building integrated scene models, we may discover contextual relationships, and better exploit partially labeled training images. We first consider images of isolated objects, and show that sharing parts among object categories improves detection accuracy when learning from few examples. Turning to multiple object scenes, we propose nonparametric models which use Dirichlet processes to automatically learn the number of parts underlying each object category, and objects composing each scene. The resulting transformed Dirichlet process (TDP) leads to Monte Carlo algorithms which simultaneously segment and recognize objects in street and office scenes.	[Sudderth, Erik B.] Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA; [Torralba, Antonio; Freeman, William T.; Willsky, Alan S.] MIT, Cambridge, MA 02139 USA	University of California System; University of California Berkeley; Massachusetts Institute of Technology (MIT)	Sudderth, EB (corresponding author), Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA.	sudderth@eecs.berkeley.edu; torralba@csail.mit.edu; billf@mit.edu; willsky@mit.edu		Sudderth, Erik/0000-0002-0595-9726				Adams NJ, 2003, IMAGE VISION COMPUT, V21, P865, DOI 10.1016/S0262-8856(03)00073-8; AMIT Y, 2007, CATEGORY LEVEL OBJEC; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Bienenstock E, 1997, ADV NEUR IN, V9, P838; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Borenstein E, 2002, LECT NOTES COMPUT SC, V2351, P109; Bosch A, 2006, LECT NOTES COMPUT SC, V3954, P517; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Casella G, 1996, BIOMETRIKA, V83, P81, DOI 10.1093/biomet/83.1.81; Csurka G., 2004, ECCV WORKSHOPS; De Iorio M, 2004, J AM STAT ASSOC, V99, P205, DOI 10.1198/016214504000000205; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; ESCOBAR MD, 1995, J AM STAT ASSOC, V90, P577, DOI 10.2307/2291069; Fei-Fei L, 2005, PROC CVPR IEEE, P524; FEIFEI L, 2004, CVPR WORKSH GEN MODE; Fergus R, 2005, IEEE I CONF COMP VIS, P1816; FINK M, 2004, NEURAL INFORM PROCES, V16; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Frey BJ, 2003, IEEE T PATTERN ANAL, V25, P1, DOI 10.1109/TPAMI.2003.1159942; Gelfand AE, 2005, J AM STAT ASSOC, V100, P1021, DOI 10.1198/016214504000002078; Gelman A., 2004, BAYESIAN DATA ANAL, V2nd, DOI DOI 10.1201/9780429258411; Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101; He XM, 2004, PROC CVPR IEEE, P695; HELMER S, 2004, CVPR WORKSH GEN MOD; Hinton GE, 2000, ADV NEUR IN, V12, P463; Ishwaran H, 2001, J AM STAT ASSOC, V96, P161, DOI 10.1198/016214501750332758; Ishwaran H, 2002, STAT SINICA, V12, P941; Jin Y., 2006, CVPR, V2, P2145; Jojic N, 2001, PROC CVPR IEEE, P199; Jordan MI, 2004, STAT SCI, V19, P140, DOI 10.1214/088342304000000026; JORDAN MI, 2005, NEURAL INFORM PROCES; Kovesi P. D., 2005, MATLAB OCTAVE FUNCTI; LeCun Y, 2004, PROC CVPR IEEE, P97; Leibe B., 2004, STAT LEARNING COMPUT; Liter JC, 1998, Z NATURFORSCH C, V53, P610; LOEFF N, 2006, NEURAL INFORM PROCES, V18, P811; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MACEACHERN SN, 1999, P SECT BAY STAT SCI, P50; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Milch B, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P1352; Miller EG, 2003, PROC CVPR IEEE, P114; Miller EG, 2000, PROC CVPR IEEE, P464, DOI 10.1109/CVPR.2000.855856; MURPHY K, 2004, NEURAL INFORM PROCES, V16; Neal RM, 2000, J COMPUT GRAPH STAT, V9, P249, DOI 10.2307/1390653; PITMAN J., 2002, 621 UC BERK DEP STAT; Rodriguez A., 2006, 200619 DUK I STAT DE; ROSENZVI M, 2004, UAI, V20, P487; RUSSELL BC, 2005, 2005025 MIT AI LAB; SHEPARD RN, 1980, SCIENCE, V210, P390, DOI 10.1126/science.210.4468.390; Simard PY, 1998, LECT NOTES COMPUT SC, V1524, P239; SISKIND JM, 2004, UNPUB IEEE T PATTERN; Sivic J, 2005, IEEE I CONF COMP VIS, P370; Storkey AJ, 2003, IEEE T PATTERN ANAL, V25, P859, DOI 10.1109/TPAMI.2003.1206515; Sudderth E., 2006, IEEE C COMP VIS PATT, V2, P2410; Sudderth EB, 2005, IEEE I CONF COMP VIS, P1331; SUDDERTH EB, 2006, NEURAL INFORM PROCES, V18, P1297; SUDDERTH EB, 2005, THESIS MIT; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; TENENBAUM JM, 1977, ARTIF INTELL, V8, P241, DOI 10.1016/0004-3702(77)90031-5; Torralba A, 2004, PROC CVPR IEEE, P762; Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951; Tu ZW, 2005, INT J COMPUT VISION, V63, P113, DOI 10.1007/s11263-005-6642-x; Ullman S, 2002, NAT NEUROSCI, V5, P682, DOI 10.1038/nn870; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Weber M, 2000, LECT NOTES COMPUT SC, V1842, P18; WILLIAMS CKI, 2006, 719 U ED INF RES	69	84	90	0	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2008	77	1-3					291	330		10.1007/s11263-007-0069-5	http://dx.doi.org/10.1007/s11263-007-0069-5			40	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	267RE		Green Submitted			2022-12-18	WOS:000253526100016
J	Vidal, R; Ma, Y; Soatto, S; Sastry, S				Vidal, Rene; Ma, Yi; Soatto, Stefano; Sastry, Shankar			Two-view multibody structure from motion	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	Workshop on Vision and Modelling of Dynamic Scenes held in Conjuction with the European Conference on Computer Vision	2002	Copenhagen, DENMARK			multibody structure from motion; 3-D motion segmentation; multibody epipolar constraint; multibody fundamental matrix; generalized PCA (GPCA)		We present an algebraic geometric approach to 3-D motion estimation and segmentation of multiple rigid-body motions from noise-free point correspondences in two perspective views. Our approach exploits the algebraic and geometric properties of the so-called multibody epipolar constraint and its associated multibody fundamental matrix, which are natural generalizations of the epipolar constraint and of the fundamental matrix to multiple motions. We derive a rank constraint on a polynomial embedding of the correspondences, from which one can estimate the number of independent motions as well as linearly solve for the multibody fundamental matrix. We then show how to compute the epipolar lines from the first-order derivatives of the multibody epipolar constraint and the epipoles by solving a plane clustering problem using Generalized PCA (GPCA). Given the epipoles and epipolar lines, the estimation of individual fundamental matrices becomes a linear problem. The clustering of the feature points is then automatically obtained from either the epipoles and epipolar lines or from the individual fundamental matrices. Although our approach is mostly designed for noise-free correspondences, we also test its performance on synthetic and real data with moderate levels of noise.	Johns Hopkins Univ, Dept Biomed Engn, Ctr Imaging Sci, Baltimore, MD 21218 USA; Univ Illinois, Dept ECE, Urbana, IL 61801 USA; Univ Calif Los Angeles, Comp Sci Dept, Los Angeles, CA 90095 USA; Univ Calif Berkeley, Dept EECS, Berkeley, CA 94720 USA	Johns Hopkins University; University of Illinois System; University of Illinois Urbana-Champaign; University of California System; University of California Los Angeles; University of California System; University of California Berkeley	Vidal, R (corresponding author), Johns Hopkins Univ, Dept Biomed Engn, Ctr Imaging Sci, 308B Clark Hall, Baltimore, MD 21218 USA.	rvidal@cis.jhu.edu; yima@uiuc.edu; soatto@cs.ucla.edu; sastry@eecs.berkeley.edu	Vidal, Rene/A-3367-2010					Avidan S, 2000, IEEE T PATTERN ANAL, V22, P348, DOI 10.1109/34.845377; COSTEIRA J, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1071, DOI 10.1109/ICCV.1995.466815; FAN X, 2005, ICCV WORKSH DYN VIS; Feng XL, 1998, PROC CVPR IEEE, P225, DOI 10.1109/CVPR.1998.698613; Han M, 2000, PROC CVPR IEEE, P542, DOI 10.1109/CVPR.2000.854908; HARRIS J., 1992, ALGEBRAIC GEOMETRY 1; Hartley R, 2004, PROC CVPR IEEE, P769; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Kanatani K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P586, DOI 10.1109/ICCV.2001.937679; KANATANI K, 2002, AS C COMP VIS, P7; Lang S., 1993, ALGEBRA; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Ma Y, 2001, INT J COMPUT VISION, V44, P219, DOI 10.1023/A:1012276232049; Shashua A, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P592, DOI 10.1109/ICCV.2001.937680; SOATTO MY, 2003, INVITATVION 3D VISIO; STURM P, 2002, EUR C COMP VIS, P867; Torr PHS, 2001, IEEE T PATTERN ANAL, V23, P297, DOI 10.1109/34.910882; Torr PHS, 1998, PHILOS T R SOC A, V356, P1321, DOI 10.1098/rsta.1998.0224; Vidal R, 2004, PROC CVPR IEEE, P310; Vidal R, 2004, PROC CVPR IEEE, P510; Vidal R, 2003, PROC CVPR IEEE, P281; Vidal R, 2003, PROC CVPR IEEE, P621; VIDAL R, 2004, EUR C COMP VIS, P1; Vidal R., 2005, IEEE T PATTERN ANAL, V27, P1; VIDAL R, M0202 UCBERL; VIDAL R, 2000, ECCV WORKSH VIS MOD; Wolf L, 2001, PROC CVPR IEEE, P263; Wolf L, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P238, DOI 10.1109/ICCV.2001.937630	28	84	91	0	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2006	68	1					7	25		10.1007/s11263-005-4839-7	http://dx.doi.org/10.1007/s11263-005-4839-7			19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	052JB		Green Submitted			2022-12-18	WOS:000238228900002
J	Ma, Y; Kosecka, J; Sastry, S				Ma, Y; Kosecka, J; Sastry, S			Optimization criteria and geometric algorithms for motion and structure estimation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						motion and structure recovery; optimal triangulation; essential manifold; Riemannian Newton's algorithm; Stiefel manifold		Prevailing efforts to study the standard formulation of motion and structure recovery have recently been focused on issues of sensitivity and robustness of existing techniques. While many cogent observations have been made and verified experimentally, many statements do not hold in general settings and make a comparison of existing techniques difficult. With an ultimate goal of clarifying these issues, we study the main aspects of motion and structure recovery: the choice of objective function, optimization techniques and sensitivity and robustness issues in the presence of noise. We clearly reveal the relationship among different objective functions, such as "(normalized) epipolar constraints," "reprojection error" or "triangulation," all of which can be unified in a new "optimal triangulation" procedure. Regardless of various choices of the objective function, the optimization problems all inherit the same unknown parameter space, the so-called "essential manifold." Based on recent developments of optimization techniques on Riemannian manifolds, in particular on Stiefel or Grassmann manifolds, we propose a Riemannian Newton algorithm to solve the motion and structure recovery problem, making use of the natural differential geometric structure of the essential manifold. We provide a clear account of sensitivity and robustness of the proposed linear and nonlinear optimization techniques and study the analytical and practical equivalence of different objective functions. The geometric characterization of critical points and the simulation results clarify the difference between the effect of bas-relief ambiguity, rotation and translation confounding and other types of local minima. This leads to consistent interpretations of simulation results over a large range of signal-to-noise ratio and variety of configurations.	Univ Illinois, Dept Elect & Comp Engn, Urbana, IL 61801 USA; George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA; Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA	University of Illinois System; University of Illinois Urbana-Champaign; George Mason University; University of California System; University of California Berkeley	Ma, Y (corresponding author), Univ Illinois, Dept Elect & Comp Engn, 1406 W Green St, Urbana, IL 61801 USA.	yima@uiuc.edu; kosecka@cs.gmu.edu; sastry@eecs.berkeley.edu						ADIV G, 1989, IEEE T PATTERN ANAL, V11, P477, DOI 10.1109/34.24780; [Anonymous], 1979, COMPREHENSIVE INTRO; Boothby W. M., 1986, INTRO DIFFERENTIAL M; DANIILIDIS K, 1990, IMAGE VISION COMPUT, V8, P297, DOI 10.1016/0262-8856(90)80006-F; DANILIDIS K, 1997, VISUAL NAVIGATION; Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Hartley RI, 1997, COMPUT VIS IMAGE UND, V68, P146, DOI 10.1006/cviu.1997.0547; HORN BKP, 1990, INT J COMPUT VISION, V4, P59, DOI 10.1007/BF00137443; JEPSON AD, 1993, SPATIAL VISION IN HUMANS AND ROBOTS, P39; Kanatani K., 1993, GEOMETRIC COMPUTATIO; Kobayashi S., 1996, FDN DIFFERENTIAL GEO, V1; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Luong QT, 1996, INT J COMPUT VISION, V17, P43, DOI 10.1007/BF00127818; Ma Y, 2000, INT J COMPUT VISION, V36, P71, DOI 10.1023/A:1008124507881; MA Y, 1998, M9864 UCBERL; MAYBANK S, 1993, THEORY RECONSTRUCTIO; Milnor J., 1969, MORSE THEORY ANN MAT; Murray R. M., 1994, MATH INTRO ROBOTIC M; OLIENSIS J, 1999, IEEE P CVPR, P185; Sastry S., 2013, NONLINEAR SYSTEMS AN, V10; Smith S.T., 1993, THESIS HARVARD U CAM; Soatto S, 1996, IEEE T AUTOMAT CONTR, V41, P393, DOI 10.1109/9.486640; SOATTO S, 1998, P IEEE INT C COMP VI; SPETSAKIS M, 1994, CVGIP-IMAG UNDERSTAN, V60, P300, DOI 10.1006/ciun.1994.1059; TAYLOR CJ, 1995, IEEE T PATTERN ANAL, V17, P1021, DOI 10.1109/34.473228; THOMAS I, 1995, MSCIS9461 U PENNS GR; Tian Tina Yu, 1996, CVPR; Weng J., 1993, MOTION STRUCTURE IMA; WENG JY, 1993, IEEE T PATTERN ANAL, V15, P864, DOI 10.1109/34.232074; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779; ZHANG T, 1999, P CVPR; Zhang ZY, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P772, DOI 10.1109/ICCV.1998.710805	33	84	88	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP-OCT	2001	44	3					219	249		10.1023/A:1012276232049	http://dx.doi.org/10.1023/A:1012276232049			31	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	496NM					2022-12-18	WOS:000172402900004
J	Vijayanarasimhan, S; Grauman, K				Vijayanarasimhan, Sudheendra; Grauman, Kristen			Large-Scale Live Active Learning: Training Object Detectors with Crawled Data and Crowds	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Object detection; Active learning; Large-scale learning; Hashing; Crowdsourcing; Image annotation		Active learning and crowdsourcing are promising ways to efficiently build up training sets for object recognition, but thus far techniques are tested in artificially controlled settings. Typically the vision researcher has already determined the dataset's scope, the labels "actively" obtained are in fact already known, and/or the crowd-sourced collection process is iteratively fine-tuned. We present an approach for live learning of object detectors, in which the system autonomously refines its models by actively requesting crowd-sourced annotations on images crawled from the Web. To address the technical issues such a large-scale system entails, we introduce a novel part-based detector amenable to linear classifiers, and show how to identify its most uncertain instances in sub-linear time with a hashing-based solution. We demonstrate the approach with experiments of unprecedented scale and autonomy, and show it successfully improves the state-of-the-art for the most challenging objects in the PASCAL VOC benchmark. In addition, we show our detector competes well with popular nonlinear classifiers that are much more expensive to train.	[Vijayanarasimhan, Sudheendra; Grauman, Kristen] Univ Texas Austin, Austin, TX 78712 USA	University of Texas System; University of Texas Austin	Grauman, K (corresponding author), Univ Texas Austin, Austin, TX 78712 USA.	svnaras@cs.utexas.edu; grauman@cs.utexas.edu			NSF [IIS-0747356]; DARPA Mind's Eye	NSF(National Science Foundation (NSF)); DARPA Mind's Eye	The authors thank the anonymous reviewers for their helpful comments. This research is supported in part by NSF CAREER IIS-0747356 and DARPA Mind's Eye.	[Anonymous], 2010, P IEEE C COMP VIS PA; Boureau Y., 2010, P IEEE C COMP VIS PA; Charikar M., 2002, S THEOR COMP; Chum 0., 2007, P IEEE C COMP VIS PA; Dalal N., 2005, HISTOGRAMS ORIENTED; Dean T., 2013, P IEEE C COMP VIS PA; Deng J., 2009, 2009 IEEE C COMP VIS, P248, DOI [DOI 10.1109/CVPR.2009.5206848, 10.1109/CVPR.2009.5206848]; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Felzenszwalb P., 2009, IEEE T PATTERN ANAL, V99, P5555; Fergus R., 2005, P INT C COMP VIS ICC; Jain P., 2010, ADV NEURAL INFORM PR; Joachims T., 2006, INT C KNOWL DISC DAT; Joshi A., 2009, P IEEE C COMP VIS PA; Kapoor A., 2007, INT C COMP VIS ICCV; LAMPERT C. H., 2008, P IEEE C COMP VIS PA; Lee Y. J., 2010, P IEEE INT C COMP VI; Li L., 2007, P IEEE C COMP VIS PA; Pirsiavash H., 2012, P IEEE C COMP VIS PA; Qi G.-J., 2008, P IEEE C COMP VIS PA; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Siddiquie B., 2010, P IEEE C COMP VIS PA; Song H. O., 2012, P EUR C COMP VIS; Sorokin A., 2008, WORKSH INT VIS; Tong S., 2000, P INT C MACH LEARN I; Torralba A, 2007, IEEE T PATTERN ANAL, V29, P854, DOI 10.1109/TPAMI.2007.1055; UIJLINGS JRR, 2009, P IEEE C COMP VIS PA; Vedaldi A., 2009, INT C COMP VIS ICCV; VIJAYANARASIMHA.S, 2008, P IEEE C COMP VIS PA; VIJAYANARASIMHA.S, 2008, ADV NEURAL INFORM PR; Vijayanarasimhan S., 2010, P IEEE INT C COMP VI; VIJAYANARASIMHAN S., 2011, P IEEE C COMP VIS PA; Vijayanarasimhan S, 2014, IEEE T PATTERN ANAL, V36, P276, DOI 10.1109/TPAMI.2013.121; Viola Paul, 2001, PROC CVPR IEEE; Von Ahn L, 2004, P ANN ACM CHI C VIEN; Welinder P., 2010, WORKSH ADV COMP VIS; Yang J., 2009, P IEEE C COMP VIS PA	36	83	86	0	16	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2014	108	1-2			SI		97	114		10.1007/s11263-014-0721-9	http://dx.doi.org/10.1007/s11263-014-0721-9			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AG7BT		Green Submitted			2022-12-18	WOS:000335573700007
J	Creusot, C; Pears, N; Austin, J				Creusot, Clement; Pears, Nick; Austin, Jim			A Machine-Learning Approach to Keypoint Detection and Landmarking on 3D Meshes	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						keypoint detection; landmarking; 3D face recognition; Machine learning; LDA; AdaBoost	FACE RECOGNITION; REGISTRATION	We address the problem of automatically detecting a sparse set of 3D mesh vertices, likely to be good candidates for determining correspondences, even on soft organic objects. We focus on 3D face scans, on which single local shape descriptor responses are known to be weak, sparse or noisy. Our machine-learning approach consists of computing feature vectors containing different local surface descriptors. These vectors are normalized with respect to the learned distribution of those descriptors for some given target shape (landmark) of interest. Then, an optimal function of this vector is extracted that best separates this particular target shape from its surrounding region within the set of training data. We investigate two alternatives for this optimal function: a linear method, namely Linear Discriminant Analysis, and a non-linear method, namely AdaBoost. We evaluate our approach by landmarking 3D face scans in the FRGC v2 and Bosphorus 3D face datasets. Our system achieves state-of-the-art performance while being highly generic.	[Creusot, Clement; Pears, Nick; Austin, Jim] Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England	University of York - UK	Creusot, C (corresponding author), Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England.	clementcreusot@gmail.com; nick.pears@york.ac.uk; jim.austin@york.ac.uk		Creusot, Clement/0000-0002-7232-4472				Alyuz N, 2010, IEEE T INF FOREN SEC, V5, P425, DOI 10.1109/TIFS.2010.2054081; Ben Azouz Z, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P750; Berretti S, 2010, P ACM WORKSH 3D OBJ, P81, DOI DOI 10.1145/1877808.1877825; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Boyer E., 2011, EUR WORKSH 3D OBJ, DOI [10.2312/3DOR/3DOR11/071-078, DOI 10.2312/3DOR/3DOR11/071-078]; Castellani U, 2008, COMPUT GRAPH FORUM, V27, P643, DOI 10.1111/j.1467-8659.2008.01162.x; Chang KI, 2006, IEEE T PATTERN ANAL, V28, P1695, DOI 10.1109/TPAMI.2006.210; Choi E, 2003, PATTERN RECOGN, V36, P1703, DOI 10.1016/S0031-3203(03)00035-9; Cipoll Roberto, 2008, PROC CVPR IEEE, P1; Colbry Dirk, 2005, IEEE COMP SOC C COMP, P1, DOI DOI 10.1109/CVPR.2005.441; Creusot C., 2011, 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), P204, DOI 10.1109/3DIMPVT.2011.33; Creusot C., 2011, THESIS U YORK; Creusot C., 2010, P ACM WORKSH 3D OBJ, P27, DOI DOI 10.1145/1877808.1877815; DHose J., 2007, P IEEE C BIOM THEOR, P1; Faltemier TC, 2008, P 8 IEEE INT C AUT F, P1, DOI DOI 10.1109/AFGR.2008.4813413; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Goldfeather J, 2004, ACM T GRAPHIC, V23, P45, DOI 10.1145/966131.966134; Itskovich A, 2011, COMPUT GRAPH-UK, V35, P334, DOI 10.1016/j.cag.2010.11.010; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; Kim JS, 2009, COMPUT ANIMAT VIRT W, V20, P289, DOI 10.1002/cav.294; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Max N., 1999, Journal of Graphics Tools, V4, P1, DOI 10.1080/10867651.1999.10487501; Mayo M, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P290, DOI 10.1109/AVSS.2009.11; Mian A, 2010, INT J COMPUT VISION, V89, P348, DOI 10.1007/s11263-009-0296-z; Mian A, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P735; Mian AS, 2008, INT J COMPUT VISION, V79, P1, DOI 10.1007/s11263-007-0085-5; Pears N, 2010, INT J COMPUT VISION, V89, P152, DOI 10.1007/s11263-009-0297-y; Phillips PJ, 2005, PROC CVPR IEEE, P947; Romero M, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P73, DOI 10.1109/AVSS.2009.90; Romero-Huertas  Marcelo, 2008, 2 IEEE INT C BIOM TH, P1, DOI [10.1109/BTAS.2008.4699390, DOI 10.1109/BTAS.2008.4699390]; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Salah A. A., 2008, 2 IEEE INT C BIOM TH, P1, DOI [DOI 10.1109/BTAS.2008.4699324, 10.1109/BTAS.2008.4699324]; Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6; Segundo MP, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P431, DOI 10.1109/ICIAP.2007.4362816; Segundo MP, 2010, IEEE T SYST MAN CY B, V40, P1319, DOI 10.1109/TSMCB.2009.2038233; Szeptycki P, 2009, 2009 IEEE 3RD INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P32, DOI 10.1109/BTAS.2009.5339052; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Zaharescu A, 2009, PROC CVPR IEEE, P373, DOI 10.1109/CVPRW.2009.5206748; Zhao X, 2011, IEEE T SYST MAN CY B, V41, P1417, DOI 10.1109/TSMCB.2011.2148711	40	83	88	0	46	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2013	102	1-3					146	179		10.1007/s11263-012-0605-9	http://dx.doi.org/10.1007/s11263-012-0605-9			34	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	097VO					2022-12-18	WOS:000315501800010
J	Cheung, KM; Baker, S; Kanade, T				Cheung, KM; Baker, S; Kanade, T			Shape-From-Silhouette across time part II: Applications to human modeling and markerless motion tracking	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						human kinematic modeling; markerless motion capture; articulated human tracking; 3D reconstruction; Shape-From-Silhouette; visual hull; stereo; temporal alignment	ACQUISITION	In Part I of this paper we developed the theory and algorithms for performing Shape-From-Silhouette (SFS) across time. In this second part, we show how our temporal SFS algorithms can be used in the applications of human modeling and markerless motion tracking. First we build a system to acquire human kinematic models consisting of precise shape (constructed using the temporal SFS algorithm for rigid objects), joint locations, and body part segmentation (estimated using the temporal SFS algorithm for articulated objects). Once the kinematic models have been built, we show how they can be used to track the motion of the person in new video sequences. This marker-less tracking algorithm is based on the Visual Hull alignment algorithm used in both temporal SFS algorithms and utilizes both geometric (silhouette) and photometric (color) information.	Neven Vis, Santa Monica, CA 90404 USA; Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Cheung, KM (corresponding author), Neven Vis, 2400 Broadway,Suite 240, Santa Monica, CA 90404 USA.	german@cs.emu.edu; simonb@cs.cmu.edu; tk@cs.cmu.edu						ALLEN B, 2003, COMPUTER GRAPHIC ANN, P587; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; BARRON C, 2000, P IEEE C COMP VIS PA; BEYMER D, 1999, P INT C COMP VIS ICC; Blinn J. F., 1982, Computer Graphics, V16, DOI 10.1145/965145.801290; Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581; BREGLER C, 1997, CSD97973 U CAL BERK; Cai Q., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P68, DOI 10.1109/ICPR.1996.546796; CAI Q, 1998, P 6 INT C COMP VIS I; CARRANZA J, 2003, COMPUTER GRAPHICS AN, P569; CHAM T, 1999, P IEEE C COMP VIS PA; CHAM T, 1999, P INT C COMP VIS ICC; CHEUNG G, 2003, P IEEE C COMP VIS PA; CHEUNG G, 2003, THESIS CARNEGIEMELLO; Cheung G. K., 2000, P IEEE C COMP VIS PA; CHEUNG K, 2004, P 2 INT S 3D DAT PRO; Cheung KM, 2005, INT J COMPUT VISION, V62, P221, DOI 10.1007/s11263-005-4881-5; COEN M, 1998, P AAAI SPRING S INT; DELAMARRE Q, 1999, P INT C COMP VIS ICC; Deutscher J., 2000, P IEEE C COMP VIS PA; DIFRANCO D, 1999, 997 CRL COMP; DIFRANCO D, 2001, P IEEE C COMP VIS PA; Drummond T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P315, DOI 10.1109/ICCV.2001.937642; FUA P, 2000, 19 ISPRS C; FUA P, 2002, INT ARCH PHOTOGRAMME, V34, P256; GAVRILA G, 1996, ARPA IM UND WORKSH 1; HARITAOGLU I, 1998, P IEEE INT C AUT FAC; JOJIC N, 1999, P INT C COMP VIS ICC; JU S, 1996, P IEEE INT C AUT FAC; Kakadiaris IA, 1998, INT J COMPUT VISION, V30, P191, DOI 10.1023/A:1008071332753; KAKADIARIS IA, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P618, DOI 10.1109/ICCV.1995.466881; KAKADIARIS L, 1994, 9418 IRCS U PENNS; KRAHNSTOEVER N, 2003, IN PRESS MACHINE VIS; KRAHNSTOEVER N, 2001, P IEEE C COMP VIS PA; LEUNG MK, 1995, IEEE T PATTERN ANAL, V17, P359, DOI 10.1109/34.385981; LIEBOWITZ D, 2001, P INT C COMP VIS ICC; LUCENTE M, 1998, P AAAI SPRING S INT; MATUSIK W, 2001, THESIS MIT; Mikic I, 2003, INT J COMPUT VISION, V53, P199, DOI 10.1023/A:1023012723347; MIKIC I, 2001, P IEEE C COMP VIS PA; Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897; MOEZZI S, 1997, IEEE COMPUTER SOC MU, V4; Murray R. M., 1994, MATH INTRO ROBOTIC M; O'Brien JF, 2000, PROC GRAPH INTERF, P53; PAVLOVIC V, 1999, P INT C COMP VIS ICC; Plankers R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P394, DOI 10.1109/ICCV.2001.937545; PLANKERS R, 1999, P 1999 INT WORKSH MO; REHG JM, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P612, DOI 10.1109/ICCV.1995.466882; SAND P, 2003, COMP GRAPH ANN C SER, P578; SHAFER S, 1998, P JOINT DARPA NIST S; SIDENBLADH H, 2000, P EUR C COMP VIS ECC; SIDENBLADH H, 2000, P IEEE INT C AUT FAC; SULLIVAN J, 2002, P EUR C COMP VIS ECC; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236; Yamamoto M, 1998, PROC CVPR IEEE, P2, DOI 10.1109/CVPR.1998.698580	55	83	87	0	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2005	63	3					225	245		10.1007/s11263-005-6879-4	http://dx.doi.org/10.1007/s11263-005-6879-4			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	928YR					2022-12-18	WOS:000229308500004
J	Grossberg, MD; Nayar, SK				Grossberg, MD; Nayar, SK			The raxel imaging model and ray-based calibration	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						calibration; caustic; catacaustic; catadioptric; diacaustic; imaging model; light-field; non-single viewpoint; non-perspective; perspective; plenoptic; raxel; ray surface; ray-based; viewpoint locus	CAMERA CALIBRATION	An imaging model provides a mathematical description of correspondence between points in a scene and in an image. The dominant imaging model, perspective projection, has long been used to describe traditional cameras as well as the human eye. We propose an imaging model which is flexible enough to represent an arbitrary imaging system. For example using this model we can describe systems using fisheye lenses or compound insect eyes, which violate the assumptions of perspective projection. By relaxing the requirements of perspective projection, we give imaging system designers greater freedom to explore systems which meet other requirements such as compact size and wide field of view. We formulate our model by noting that all imaging systems perform a mapping from incoming scene rays to photosensitive elements on the image detector. This mapping can be conveniently described using a set of virtual sensing elements, called raxels. Raxels include geometric, radiometric and optical properties. We present a novel ray based calibration method that uses structured light patterns to extract the raxel parameters of an arbitrary imaging system. Experiments' results for perspective as well as non-perspective imaging systems are included.	Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Columbia University	Grossberg, MD (corresponding author), Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.	mdog@cs.columbia.edu; nayar@cs.columbia.edu						[Anonymous], 1997, P 1997 DARPA IM UND; BAKER P, 2001, CVPR01, P576; Baker S, 1999, INT J COMPUT VISION, V35, P175, DOI 10.1023/A:1008128724364; Bergen J. R., 1991, COMPUTATIONAL MODELS, V1, P8; Born M., 1968, PRINCIPLES OPTICS; Brown Duane C, 1966, PHOTOGRAMMETRIC ENG, P2, DOI DOI 10.1234/12345678; BURKHARD DG, 1973, J OPT SOC AM, V63, P299, DOI 10.1364/JOSA.63.000299; Conrady A. E., 1919, MON NOT R ASTRON SOC, V79, P384; CORNBLEET S, 1994, MICROWAVE GEOMETRICA; Dawkins R, 1996, CLIMBING MOUNT IMPRO; DEBEVEC PE, 1997, SIGGRAPH, V31, P369; FAUGERAS, 1993, 3 DIMENSIONAL COMPUT; FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P564; FELDMAN D, 2002, MOTION02, P195; GATEN E, 1994, J COMP PHYSIOL A, V175, P749; Gershun A., 1939, J MATH PHYS, V18, P51, DOI [DOI 10.1002/SAPM193918151, 10.1002/sapm193918151]; GLUCKMAN J, 1999, CVRP, P22; Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200; GOSHTASBY A, 1989, COMPUT VISION GRAPH, V47, P385, DOI 10.1016/0734-189X(89)90120-5; Griffiths P, 1994, PRINCIPLES ALGEBRAIC; Grossberg MD, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P108, DOI 10.1109/ICCV.2001.937611; Guillemin V., 1977, GEOMETRIC ASYMPTOTIC, V14; Hammond John H., 1981, CAMERA OBSCURA CHRON; HARTLEY R, 1993, P ECCV, P579; Hecht E., 2017, OPTICS, V5th ed.; Horn B., 1986, ROBOT VISION, P1; Jensen HW, 1997, COMPUT GRAPH FORUM, V16, P57, DOI 10.1111/1467-8659.116; Langer MS, 1997, PROC CVPR IEEE, P172, DOI 10.1109/CVPR.1997.609316; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; MANN S, 1995, IS&T'S 48TH ANNUAL CONFERENCE - IMAGING ON THE INFORMATION SUPERHIGHWAY, FINAL PROGRAM AND PROCEEDINGS, P442; MANN S, 1996, PENCIGRAPHY AGC JOIN; MCCUTCHEN D, 1991, Patent No. 5023725; MITCHELL D, 1992, COMP GRAPH, V26, P283, DOI 10.1145/142920.134082; Mitsunaga T., P 1999 IEEE COMP SOC, P374; MIYAMOTO K, 1964, J OPT SOC AM, V54, P1060, DOI 10.1364/JOSA.54.001060; Moini A., 2000, VISION CHIPS; NAYAR S, 2000, 360 360 MOSAICS; NAYAR SK, 1999, COMPUTER VISION PATT, P217; Neumann J, 2003, PROC CVPR IEEE, P294; Pajdla T, 2002, INT J COMPUT VISION, V47, P161, DOI 10.1023/A:1014593824520; PELEG S, 2000, P CVPR IEEE COMP SOC, V2, P201; Pless R, 2003, PROC CVPR IEEE, P587, DOI 10.1109/cvpr.2003.1211520; Pless R, 2002, THIRD WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P53, DOI 10.1109/OMNVIS.2002.1044491; SATO K, 1985, J ROBOTIC SYST, V2, P27; Seitz SM, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P26, DOI 10.1109/ICCV.2001.937495; SWAMINATHAN R, 2001, P ICCV; SWAMINATHAN R, 2000, PAMI, V22, P1172; TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109; Tyson R. K., 1998, PRINCIPLES ADAPTIVE; Watt M., 1990, Computer Graphics, V24, P377, DOI 10.1145/97880.97920; WENG JY, 1992, IEEE T PATTERN ANAL, V14, P965, DOI 10.1109/34.159901; YAGI Y, 1990, IROS90; Zemanian A, 1965, DISTRIBUTION THEORY	53	83	87	0	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	FEB	2005	61	2					119	137		10.1023/B:VISI.0000043754.56350.10	http://dx.doi.org/10.1023/B:VISI.0000043754.56350.10			19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	866XQ		Green Submitted			2022-12-18	WOS:000224807100001
J	Pizer, SM; Siddiqi, K; Szekely, G; Damon, JN; Zucker, SW				Pizer, SM; Siddiqi, K; Szekely, G; Damon, JN; Zucker, SW			Multiscale medial loci and their properties	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Review						medial loci; multiscale; shape	ZOOM-INVARIANT VISION; SHAPE-DESCRIPTION; VORONOI DIAGRAMS; FIGURAL SHAPE; AXIS; DISTANCE; RECOGNITION; RIDGES; CORES; SKELETONIZATION	Blum's medial axes have great strengths, in principle, in intuitively describing object shape in terms of a quasi-hierarchy of figures. But it is well known that, derived from a boundary, they are damagingly sensitive to detail in that boundary. The development of notions of spatial scale has led to some definitions of multiscale medial axes different from the Blum medial axis that considerably overcame the weakness. Three major multiscale medial axes have been proposed: iteratively pruned trees of Voronoi edges (Ogniewicz, 1993; Szekely, 1996; Naf, 1996), shock loci of reaction-diffusion equations (Kimia et al., 1995; Siddiqi and Kimia, 1996), and height ridges of medialness (cores) (Fritsch et al., 1994; Morse et al., 1993; Pizer et al., 1998). These are different from the Blum medial axis, and each has different mathematical properties of generic branching and ending properties, singular transitions, and geometry of implied boundary, and they have different strengths and weaknesses for computing object descriptions from images or from object boundaries. These mathematical properties and computational abilities are laid out and compared and contrasted in this paper.	Univ N Carolina, Chapel Hill, NC 27515 USA; McGill Univ, Montreal, PQ, Canada; ETH, Elect Engn, Zurich, Switzerland; Yale Univ, New Haven, CT USA	University of North Carolina; University of North Carolina Chapel Hill; McGill University; Swiss Federal Institutes of Technology Domain; ETH Zurich; Yale University	Pizer, SM (corresponding author), Univ N Carolina, Chapel Hill, NC 27515 USA.		Szekely, Gabor/A-3880-2008	Siddiqi, Kaleem/0000-0002-7347-9716				ARCELLI C, 1992, PATTERN RECOGN LETT, V13, P237, DOI 10.1016/0167-8655(92)90074-A; ARCELLI C, 1981, IEEE T PATTERN ANAL, V3, P134, DOI 10.1109/TPAMI.1981.4767071; ARCELLI C, 1986, PATTERN RECOGN LETT, V4, P383, DOI 10.1016/0167-8655(86)90060-7; ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; ATTALI D, 1994, P 12 INT C PATT REC, V1, P626; Attali D., 1994, ASPECTS VISUAL FORM, P32; Attali D, 1995, THESIS U J FOURIER G THESIS U J FOURIER G; ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663; August J, 1999, COMPUT VIS IMAGE UND, V76, P146, DOI 10.1006/cviu.1998.0795; August J, 1999, COMPUT VIS IMAGE UND, V76, P231, DOI 10.1006/cviu.1999.0802; AUGUST J, 1999, ICCV, P315; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; Blum H., 1967, MODELS PERCEPTION SP, P363; BOGAEVSKII IA, 1990, LENINGRAD MATH J, V1, P807; BRADY M, 1984, INT J ROBOT RES, V3, P36, DOI 10.1177/027836498400300302; BRANDT JW, 1992, CVGIP-IMAG UNDERSTAN, V55, P329, DOI 10.1016/1049-9660(92)90030-7; BRANDT JW, 1992, SPIE, V1830, P258; BROCKETT R, 1992, P IEEE C AC SPEECH S; BRUCE JW, 1986, P ROY SOC EDINB A, V104, P179, DOI 10.1017/S030821050001917X; Bruce JW, 1996, INT J COMPUT VISION, V18, P195, DOI 10.1007/BF00123141; BRUCE JW, 1985, P ROY SOC EDINB A, V101, P163, DOI 10.1017/S0308210500026263; BURBECK CA, 1995, VISION RES, V35, P1917, DOI 10.1016/0042-6989(94)00286-U; BURBECK CA, 1993, J OPT SOC AM A, V10, P5, DOI 10.1364/JOSAA.10.000005; Burbeck CA, 1996, VISION RES, V36, P361, DOI 10.1016/0042-6989(95)00106-9; CIGNONI P, 1992, MERGE 1 DIVIDE CONQU; Cross ADJ, 1997, PROC CVPR IEEE, P738, DOI 10.1109/CVPR.1997.609408; Culver T., 1999, P 5 ACM S SOL MOD AP, P179; CULVER T, 2000, THESIS U NC; Damon J, 1999, J MATH IMAGING VIS, V10, P163, DOI 10.1023/A:1008379107611; Damon J, 1998, SIAM J APPL MATH, V59, P97, DOI 10.1137/S0036139997318032; DAMON J, 1997, MAT CONT, V12, P45; DIMITROV P, 2000, CVPR 00, V1, P417; EBERLY D, 1996, SERIES COMPUTATIONAL; EDELSBRUNNER H, 1987, MONOGRAPHS THEORETIC, V10; ELDER J, 1993, VISION RES, V33, P981, DOI 10.1016/0042-6989(93)90080-G; FANG TP, 1993, IEEE COMPUT GRAPH, V13, P36, DOI 10.1109/38.210490; FRIDMAN Y, 2003, LECT NOTES COMPUTER, V2878; FRITSCH DS, 1994, PATTERN RECOGN LETT, V15, P445, DOI 10.1016/0167-8655(94)90135-X; Furst JD, 1997, LECT NOTES COMPUT SC, V1252, P176; FURST JD, 2001, IASTED INT C SIGN IM, P22; Geiger B, 1993, RR2105 INRIA; GIBLIN P, 2000, P IEEE CVPR, V11, P566; Giblin P. J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P385, DOI 10.1109/ICCV.1999.791246; GIBLIN PJ, 2002, P 7 EUR C COMP VIS, P718; GOMES J, 2000, P ECCV 2000 DUBL IR, V1, P588; Held M, 1998, COMPUT AIDED DESIGN, V30, P287, DOI 10.1016/S0010-4485(97)00071-7; KATZ RA, 2003, INT J COMPUT VISION, V55, P155; KELLER R, 1999, THESIS U NC; KIMIA B, 1990, LECT NOTES COMPUTER, V427; KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741; KIMMEL R, 1995, COMPUT VIS IMAGE UND, V62, P382, DOI 10.1006/cviu.1995.1062; Klein F., 1987, Proceedings of the 5th Scandinavian Conference on Image Analysis, P443; Koenderink J., 1990, SOLID SHAPE; LEE DT, 1982, IEEE T PATTERN ANAL, V4, P363, DOI 10.1109/TPAMI.1982.4767267; LEE TS, 1996, P 4 ANN COMP NEUR C; LEYMARIE F, 1992, IEEE T PATTERN ANAL, V14, P56, DOI 10.1109/34.107013; LEYTON M, 1987, COMPUT VISION GRAPH, V38, P327, DOI 10.1016/0734-189X(87)90117-4; MALANDAIN G, 1993, INT J COMPUT VISION, V10, P183, DOI 10.1007/BF01420736; MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020; MATHER JN, 1983, P SYMP PURE MATH, V40, P199; MATHERON G, 1988, IMAGE ANAL MATH MORP, P217; MEYER F, 1989, SIGNAL PROCESS, V16, P335, DOI 10.1016/0165-1684(89)90030-3; Miller J, 1999, LECT NOTES COMPUT SC, V1682, P93; Morse BS, 1998, COMPUT VIS IMAGE UND, V69, P72, DOI 10.1006/cviu.1997.0564; MORSE BS, 1993, LECT NOTES COMPUTER, V687, P327; NA M, 1996, THESIS ETH ZURICH; NACKMAN LR, 1985, IEEE T PATTERN ANAL, V7, P187, DOI 10.1109/TPAMI.1985.4767643; NACKMAN LR, 1981, THESIS U NC; Ogniewicz R. L., 1993, DISCRETE VORONOI SKE; OGNIEWICZ RL, 1995, PATTERN RECOGN, V28, P343, DOI 10.1016/0031-3203(94)00105-U; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; PELILLO M, 1998, P EUR C COMP VIS; PIZER S, 1996, IEEE T MED IMAGING, V18, P851; Pizer SM, 1998, COMPUT VIS IMAGE UND, V69, P55, DOI 10.1006/cviu.1997.0563; PIZER SM, 1987, IEEE T PATTERN ANAL, V9, P505, DOI 10.1109/TPAMI.1987.4767938; PIZER SM, 2000, INT J COMPUT VISION, V55, P85; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; Pudney C, 1998, COMPUT VIS IMAGE UND, V72, P404, DOI 10.1006/cviu.1998.0680; ROM H, 1993, IEEE T PATTERN ANAL, V15, P973, DOI 10.1109/34.254054; Romeny B.M., 1994, GEOMETRY DRIVEN DIFF; SCHMITT M, 1989, LECT NOTES COMPUT SC, V391, P225; Sclaroff S, 1997, PATTERN RECOGN, V30, P627, DOI 10.1016/S0031-3203(96)00108-2; SEBASTIAN TB, 2001, P 8 ICCV IEEE; Serra J, 1982, IMAGE ANAL MATH MORP; Sethian JA, 1996, LEVEL SET METHODS EV; Shah J, 1996, PROC CVPR IEEE, P136, DOI 10.1109/CVPR.1996.517065; Siddiqi K, 2002, INT J COMPUT VISION, V48, P215, DOI 10.1023/A:1016376116653; Siddiqi K, 1996, PROC CVPR IEEE, P507, DOI 10.1109/CVPR.1996.517119; Siddiqi K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P828, DOI 10.1109/ICCV.1999.790307; Siddiqi K, 2001, VISION RES, V41, P1153, DOI 10.1016/S0042-6989(00)00274-1; Siddiqi K, 1997, GRAPH MODEL IM PROC, V59, P278, DOI 10.1006/gmip.1997.0438; STYNER M, 2001, LECT NOTES COMPUTER, V2082, P502; SZEKELY G, 1992, P SOC PHOTO-OPT INS, V1808, P130, DOI 10.1117/12.131073; SZEKELY G, 1994, P 2 INT WORKSH VIS F, P532; SZEKELY G, 1996, SHAPE CHARACTERIZATI; Tari ZSG, 1997, COMPUT VIS IMAGE UND, V66, P133, DOI 10.1006/cviu.1997.0612; TIHONOV AN, 1977, SOLUTION ILL POSED P; WEISS I, 1990, IEEE T PATTERN ANAL, V12, P345, DOI 10.1109/34.50621; WEISS I, 1986, CARTR22 U MAR COMP V; WHITNEY GG, 1985, BIOL CONSERV, V31, P265, DOI 10.1016/0006-3207(85)90071-0; YOMDIN Y, 1981, COMPOS MATH, V43, P225; YU Z, 1992, THEORETICAL FDN COMP, P13; Zarantonello E. A., 1971, CONTRIBUTIONS NONLIN, P603; Zhu SC, 1996, INT J COMPUT VISION, V20, P187; [No title captured]; [No title captured]	108	83	84	0	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV-DEC	2003	55	2-3					155	179		10.1023/A:1026135101267	http://dx.doi.org/10.1023/A:1026135101267			25	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	732YN					2022-12-18	WOS:000185973300006
J	Xia, GS; Delon, J; Gousseau, Y				Xia, Gui-Song; Delon, Julie; Gousseau, Yann			Accurate Junction Detection and Characterization in Natural Images	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Junction detection; Scale characterization; a-contrario method; Scale-invariant keypoints; Contrast invariance	CORNER DETECTION; SCALE; EDGE; CLASSIFICATION; SEGMENTATION	Accurate junction detection and characterization are of primary importance for several aspects of scene analysis, including depth recovery and motion analysis. In this work, we introduce a generic junction analysis scheme. The first asset of the proposed procedure is an automatic criterion for the detection of junctions, permitting to deal with textured parts in which no detection is expected. Second, the method yields a characterization of L-, Y- and X- junctions, including a precise computation of their type, localization and scale. Contrary to classical approaches, scale characterization does not rely on the linear scale-space. First, an a contrario approach is used to compute the meaningfulness of a junction. This approach relies on a statistical modeling of suitably normalized gray level gradients. Then, exclusion principles between junctions permit their precise characterization. We give implementation details for this procedure and evaluate its efficiency through various experiments.	[Xia, Gui-Song] Wuhan Univ, State Key Lab LIESMARS, Wuhan 430079, Peoples R China; [Delon, Julie; Gousseau, Yann] Telecom ParisTech, LTCI CNRS, F-75013 Paris, France	Wuhan University; Centre National de la Recherche Scientifique (CNRS); IMT - Institut Mines-Telecom; Institut Polytechnique de Paris	Xia, GS (corresponding author), Wuhan Univ, State Key Lab LIESMARS, 129 Luoyu Rd, Wuhan 430079, Peoples R China.	guisong.xia@whu.edu.cn; delon@telecom-paristech.fr; gousseau@telecom-paristech.fr	Delon, Julie/U-5964-2017	Delon, Julie/0000-0002-7182-7537; Xia, Gui-Song/0000-0001-7660-6090	ANR project Callisto; FUI project CEDCA	ANR project Callisto(French National Research Agency (ANR)); FUI project CEDCA	The authors would like to thank Stephane Belardi, who implemented a primary version of this algorithm, Michael Lindenbaum for his comments and suggestions and Wolfgang Forstner and Michael Maire, who kindly made their code available. We thank the anonymous reviewers for their interesting comments and suggestions that helped improving the paper. This work has benefited from the support of the ANR project Callisto as well as from the FUI project CEDCA.	Adelson E. H., 2000, NEW COGNITIVE NEUROS, V339, P339, DOI DOI 10.1068/P230869; Alvarez L, 1997, INT J COMPUT VISION, V25, P95, DOI 10.1023/A:1007959616598; Awrangjeb M, 2008, IEEE T IMAGE PROCESS, V17, P2425, DOI 10.1109/TIP.2008.2006441; Bergevin R, 2004, COMPUT VIS IMAGE UND, V93, P288, DOI 10.1016/j.cviu.2003.10.003; Beymer D. J., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P720, DOI 10.1109/CVPR.1991.139798; Bolles R. C., 1982, INT J ROBOT RES, V1, P57; Cao F, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P440; Caselles V, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL I, P493, DOI 10.1109/ICIP.1996.559541; Cazorla M, 2002, PATTERN RECOGN, V35, P1869, DOI 10.1016/S0031-3203(01)00150-9; Cazorla MA, 2003, IEEE T IMAGE PROCESS, V12, P317, DOI 10.1109/TIP.2002.806242; Deriche R., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P530, DOI 10.1109/CVPR.1993.341079; DERICHE R, 1993, INT J COMPUT VISION, V10, P101, DOI 10.1007/BF01420733; Deschenes F, 2004, INT J REMOTE SENS, V25, P511, DOI 10.1080/0143116031000139845; Desolneux A, 2000, INT J COMPUT VISION, V40, P7, DOI 10.1023/A:1026593302236; Desolneux A., 2008, GESTALT THEORY IMAGE, V1st ed.; Dickscheid T, 2011, INT J COMPUT VISION, V94, P154, DOI 10.1007/s11263-010-0340-z; Dimiccoli M, 2009, INT CONF ACOUST SPEE, P1229, DOI 10.1109/ICASSP.2009.4959812; Forstner W, 2009, IEEE I CONF COMP VIS, P2256, DOI 10.1109/ICCV.2009.5459458; Forstner W., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P383, DOI 10.1007/BFb0028370; Forstner W., 1986, ISP COMMISSION 3; FREEMAN W, 1992, THESIS MIT CAMBRIDGE; FUCHS C, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P175, DOI 10.1109/ICCV.1995.466789; Geiger D, 1996, PROC CVPR IEEE, P155, DOI 10.1109/CVPR.1996.517068; Golubchyck R., 2006, MSC200607; Guo CE, 2007, COMPUT VIS IMAGE UND, V106, P5, DOI 10.1016/j.cviu.2005.09.004; Guzman A., 1968, P DEC 9 11 1968 FA 1, V33, P291; HANNAH MJ, 1974, THESIS STANFORD U; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Ishikawa H, 1998, PROC CVPR IEEE, P125, DOI 10.1109/CVPR.1998.698598; Kanizsa Gaetano, 1979, ORG VISION ESSAYS GE; Kenney CS, 2005, PROC CVPR IEEE, P191; Kitchen L, 1982, PATTERN RECOGN LETT, V1, P93, DOI 10.1016/0167-8655(82)90019-8; Kovesi P., 2003, AUSTR PATT REC SOC C; Leichter I, 2009, IEEE I CONF COMP VIS, P9, DOI 10.1109/ICCV.2009.5459208; Lin L., 2007, P INT C COMP VIS; Lindeberg T, 1997, COMPUT VIS IMAGE UND, V67, P88, DOI 10.1006/cviu.1996.0510; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; LINDEBERG T, 1994, IEEE IMAGE PROC, P924, DOI 10.1109/ICIP.1994.413244; Liu SF, 2013, PROCEEDINGS OF 2013 IEEE INTERNATIONAL CONFERENCE ON GREY SYSTEMS AND INTELLIGENT SERVICES (GSIS), P1, DOI 10.1109/GSIS.2013.6714728; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Luo B, 2007, IEEE T IMAGE PROCESS, V16, P2503, DOI 10.1109/TIP.2007.906004; Maire M., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587420; Marr D., 1982, VISION COMPUTATIONAL; McDermott J, 2004, PERCEPTION, V33, P1101, DOI 10.1068/p5265; METELLI F, 1974, SCI AM, V230, P91, DOI 10.1038/scientificamerican0474-90; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Moisan L, 2004, INT J COMPUT VISION, V57, P201, DOI 10.1023/B:VISI.0000013094.38752.54; Mokhtarian F, 1998, IEEE T PATTERN ANAL, V20, P1376, DOI 10.1109/34.735812; Morevec H.P., 1977, INT JOINT C ART INT, V2, P584; Muse P, 2006, INT J COMPUT VISION, V69, P295, DOI 10.1007/s11263-006-7546-0; Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479; Parida L, 1998, IEEE T PATTERN ANAL, V20, P687, DOI 10.1109/34.689300; PERONA P, 1992, LECT NOTES COMPUT SC, V588, P3, DOI 10.1016/0262-8856(92)90011-Q; Rabin J, 2009, SIAM J IMAGING SCI, V2, P931, DOI 10.1137/090751359; RATTARANGSI A, 1992, IEEE T PATTERN ANAL, V14, P430, DOI 10.1109/34.126805; Ren XF, 2006, LECT NOTES COMPUT SC, V3952, P614; ROHR K, 1992, INT J COMPUT VISION, V9, P213, DOI 10.1007/BF00133702; ROSENFELD A, 1973, IEEE T COMPUT, VC 22, P875, DOI 10.1109/TC.1973.5009188; ROSENTHALER L, 1992, LECT NOTES COMPUT SC, V588, P78; Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275; Rubin N, 2001, PERCEPTION, V30, P339, DOI 10.1068/p3173; RUDERMAN DL, 1994, PHYS REV LETT, V73, P814, DOI 10.1103/PhysRevLett.73.814; Ruzon MA, 2001, IEEE T PATTERN ANAL, V23, P1281, DOI 10.1109/34.969118; Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Sinzinger ED, 2008, PATTERN RECOGN, V41, P494, DOI 10.1016/j.patcog.2007.06.032; Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710; TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447; Trajkovic M, 1998, IMAGE VISION COMPUT, V16, P75, DOI 10.1016/S0262-8856(97)00056-5; von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300; Wallach H, 1935, PSYCHOL FORSCH, V20, P325, DOI 10.1007/BF02409790; WANG H, 1995, IMAGE VISION COMPUT, V13, P695, DOI 10.1016/0262-8856(95)98864-P; Wu T.-F., 2007, P IEEE C COMP VIS PA, P1; Xia G.-S., 2012, P INT C PATT REC	74	82	86	1	28	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2014	106	1					31	56		10.1007/s11263-013-0640-1	http://dx.doi.org/10.1007/s11263-013-0640-1			26	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	288QM		Green Submitted			2022-12-18	WOS:000329626800002
J	Garg, R; Roussos, A; Agapito, L				Garg, Ravi; Roussos, Anastasios; Agapito, Lourdes			A Variational Approach to Video Registration with Subspace Constraints	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							PRIMAL-DUAL ALGORITHMS; OPTIC FLOW COMPUTATION; FRAMEWORK; TRACKING; MOTION	This paper addresses the problem of non-rigid video registration, or the computation of optical flow from a reference frame to each of the subsequent images in a sequence, when the camera views deformable objects. We exploit the high correlation between 2D trajectories of different points on the same non-rigid surface by assuming that the displacement of any point throughout the sequence can be expressed in a compact way as a linear combination of a low-rank motion basis. This subspace constraint effectively acts as a trajectory regularization term leading to temporally consistent optical flow. We formulate it as a robust soft constraint within a variational framework by penalizing flow fields that lie outside the low-rank manifold. The resulting energy functional can be decoupled into the optimization of the brightness constancy and spatial regularization terms, leading to an efficient optimization scheme. Additionally, we propose a novel optimization scheme for the case of vector valued images, based on the dualization of the data term. This allows us to extend our approach to deal with colour images which results in significant improvements on the registration results. Finally, we provide a new benchmark dataset, based on motion capture data of a flag waving in the wind, with dense ground truth optical flow for evaluation of multi-frame optical flow algorithms for non-rigid surfaces. Our experiments show that our proposed approach outperforms state of the art optical flow and dense non-rigid registration algorithms.	[Garg, Ravi; Roussos, Anastasios; Agapito, Lourdes] Queen Mary Univ London, London E1 4NS, England	University of London; Queen Mary University London	Agapito, L (corresponding author), Queen Mary Univ London, Mile End Rd, London E1 4NS, England.	rgarg@eecs.qmul.ac.uk; troussos@eecs.qmul.ac.uk; lourdes@dcs.qmul.ac.uk		Roussos, Anastasios/0000-0001-6015-3357	European Research Council under ERC Starting Grant [204871-HUMANIS]	European Research Council under ERC Starting Grant	This work is supported by the European Research Council under ERC Starting Grant agreement 204871-HUMANIS. We thank T. Collins for his texture mapping code and D. Pizarro for providing results of their method (Pizarro and Bartoli 2010) and tracks for the synthetic sequence. We also thank A. Handa and L. Pizarro for fruitful discussions.	Akhter I, 2011, IEEE T PATTERN ANAL, V33, P1442, DOI 10.1109/TPAMI.2010.201; Akhter Ijaz, 2008, ADV NEURAL INFORM PR, P41; Alvarez L, 2000, INT J COMPUT VISION, V39, P41, DOI 10.1023/A:1008170101536; Alvarez L., 1999, P 16 C EC DIF APL LA, P1349; Aubert G, 1999, SIAM J APPL MATH, V60, P156, DOI 10.1137/S0036139998340170; Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2; Blomgren P, 1998, IEEE T IMAGE PROCESS, V7, P304, DOI 10.1109/83.661180; Brand M, 2001, PROC CVPR IEEE, P456; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3; Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143; Chambolle A, 2004, J MATH IMAGING VIS, V20, P89; Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1; Deriche R., 1995, ACCV '95. Second Asian Conference on Computer Vision. Proceedings, P290; Esser E, 2010, SIAM J IMAGING SCI, V3, P1015, DOI 10.1137/09076934X; Garg Ravi, 2011, Energy Minimization Methods in Computer Vision and Pattern Recognition. Proceedings 8th International Conference, EMMCVPR 2011, P300, DOI 10.1007/978-3-642-23094-3_22; Garg R, 2011, LECT NOTES COMPUT SC, V6495, P460, DOI 10.1007/978-3-642-19282-1_37; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Irani M, 2002, INT J COMPUT VISION, V48, P173, DOI 10.1023/A:1016372015744; Kumar A, 1996, IEEE T IMAGE PROCESS, V5, P598, DOI 10.1109/83.491336; Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147; Lucas Bruce D, 1981, P 7 INT JOINT C ART; Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513; Nir T, 2008, INT J COMPUT VISION, V76, P205, DOI 10.1007/s11263-007-0051-2; Papadakis N, 2007, 2007 IEEE 11 INT C C, P1; Papenberg N, 2006, INT J COMPUT VISION, V67, P141, DOI 10.1007/s11263-005-3960-y; Pizarro D., 2010, INT S 3D DAT PROC VI; Pock T, 2011, IEEE I CONF COMP VIS, P1762, DOI 10.1109/ICCV.2011.6126441; Pock T, 2010, SIAM J IMAGING SCI, V3, P1122, DOI 10.1137/090757617; Raket Lars Lau, 2011, Energy Minimization Methods in Computer Vision and Pattern Recognition. Proceedings 8th International Conference, EMMCVPR 2011, P329, DOI 10.1007/978-3-642-23094-3_24; Ricco S, 2012, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2012.6247877; ROCKAFELLAR R. T., 1997, PRINCETON LANDMARKS; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Sapiro G, 1997, COMPUT VIS IMAGE UND, V68, P247, DOI 10.1006/cviu.1997.0562; Sayd P., 2008, P IEEE C COMP VIS PA, P1; Schnorr C., 1994, Proceedings of the 12th IAPR International Conference on Pattern Recognition (Cat. No.94CH3440-5), P661, DOI 10.1109/ICPR.1994.576391; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Steinbrucker F, 2009, IEEE I CONF COMP VIS, P1609, DOI 10.1109/ICCV.2009.5459364; Stuhmer J, 2010, LECT NOTES COMPUT SC, V6376, P11; Sun DQ, 2008, LECT NOTES COMPUT SC, V5304, P83; Tian YD, 2010, PROC CVPR IEEE, P1277, DOI 10.1109/CVPR.2010.5539822; Torresani L, 2001, PROC CVPR IEEE, P493; Torresani L, 2002, LECT NOTES COMPUT SC, V2350, P801; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; Tschumperle D, 2005, IEEE T PATTERN ANAL, V27, P506, DOI 10.1109/TPAMI.2005.87; URAS S, 1988, BIOL CYBERN, V60, P79, DOI 10.1007/BF00202895; Varol A, 2009, IEEE I CONF COMP VIS, P1811, DOI 10.1109/ICCV.2009.5459403; Volz S, 2011, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2011.6126359; Wedel A., 2008, 2008 23 INT C IM VIS, P1; Wedel A, 2009, IEEE I CONF COMP VIS, P1663, DOI 10.1109/ICCV.2009.5459375; Wedel A, 2009, LECT NOTES COMPUT SC, V5604, P23, DOI 10.1007/978-3-642-03061-1_2; Weickert J, 2001, J MATH IMAGING VIS, V14, P245, DOI 10.1023/A:1011286029287; Weickert J, 2001, INT J COMPUT VISION, V45, P245, DOI 10.1023/A:1013614317973; WEICKERT J, 1998, P COMP VIS MOB ROB W, P115; Werlberger M., 2009, BMVC, V1, P1, DOI DOI 10.5244/C.23.108; White R, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239485; Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22	57	82	85	0	21	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2013	104	3			SI		286	314		10.1007/s11263-012-0607-7	http://dx.doi.org/10.1007/s11263-012-0607-7			29	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	190VT	23908564	hybrid, Green Published			2022-12-18	WOS:000322371100005
J	Black, MJ; Fleet, DJ				Black, MJ; Fleet, DJ			Probabilistic detection and tracking of motion boundaries	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	7th IEEE International Conference on Computer Vision	SEP 20-27, 1999	KERKYRA, GREECE	IEEE		motion discontinuities; occlusion; optical flow; Bayesian methods; particle filtering	FLOW-FIELDS; SEGMENTATION	We propose a Bayesian framework for representing and recognizing local image motion in terms of two basic models: translational motion and motion boundaries. Motion boundaries are represented using a non-linear generative model that explicitly encodes the orientation of the boundary, the velocities on either side, the motion of the occluding edge over time, and the appearance/disappearance of pixels at the boundary. We represent the posterior probability distribution over the model parameters given the image data using discrete samples. This distribution is propagated over time using a particle filtering algorithm. To efficiently represent such a high-dimensional space we initialize samples using the responses of a low-level motion discontinuity detector. The formulation and computational model provide a general probabilistic framework for motion estimation with multiple, non-linear, models.	Xerox Corp, Palo Alto Res Ctr, Palo Alto, CA 94304 USA; Brown Univ, Dept Comp Sci, Providence, RI 02912 USA; Queens Univ, Dept Comp Sci, Kingston, ON K7L 3N6, Canada	Xerox; Brown University; Queens University - Canada	Black, MJ (corresponding author), Xerox Corp, Palo Alto Res Ctr, 3333 Coyote Hill Rd, Palo Alto, CA 94304 USA.	black@cs.brown.edu; fleet@cs.queensu.ca		/0000-0003-0734-7114; Black, Michael/0000-0001-6077-4540				AYER S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P777, DOI 10.1109/ICCV.1995.466859; BabHadiashar A, 1997, PROC CVPR IEEE, P988, DOI 10.1109/CVPR.1997.609448; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Beauchemin SS, 2000, IEEE T PATTERN ANAL, V22, P200, DOI 10.1109/34.825758; BERGEN JR, 1992, P EUR C COMP VIS, P237; Black M. J., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P326, DOI 10.1109/CVPR.1999.786959; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; BLACK MJ, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P1060; CHOU GT, 1995, IEEE INT C COMP VIS, P1050; CORNELIUS NH, 1983, P ACM SIGGRAPH SIGAR, P50; FLEET DJ, 1994, VISION RES, V34, P3057, DOI 10.1016/0042-6989(94)90278-X; Fleet DJ, 2000, INT J COMPUT VISION, V36, P171, DOI 10.1023/A:1008156202475; Fleet DJ, 1992, MEASUREMENT IMAGE VE; Freeman W. T., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1182, DOI 10.1109/ICCV.1999.790414; HARRIS JG, 1990, INT J COMPUT VISION, V4, P211, DOI 10.1007/BF00054996; HEITZ F, 1993, IEEE T PATTERN ANAL, V15, P1217, DOI 10.1109/34.250841; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; ISARD M, 1998, LECT NOTES COMPUTER, V1406, P893, DOI DOI 10.1007/BFB0055711; JEPSON A, 1993, PARTITIONING DATA SE, P271; KONRAD J, 1988, P 2 IEEE INT C COMP, P354; Liu JS, 1998, J AM STAT ASSOC, V93, P1032, DOI 10.2307/2669847; MURRAY DW, 1987, IEEE T PATTERN ANAL, V9, P220, DOI 10.1109/TPAMI.1987.4767896; MUTCH KM, 1985, IEEE T PATTERN ANAL, V7, P133, DOI 10.1109/TPAMI.1985.4767638; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; NIYOGI SA, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1044, DOI 10.1109/ICCV.1995.466819; OTTE M, 1994, LECTURE NOTES COMPUT, V800, P51; POTTER JL, 1980, IEEE T SMC, V5, P390; Sawhney HS, 1996, IEEE T PATTERN ANAL, V18, P814, DOI 10.1109/34.531801; SCHUNCK BG, 1989, IEEE T PATTERN ANAL, V11, P1010, DOI 10.1109/34.42834; Shulman D., 1989, Proceedings. Workshop on Visual Motion (IEEE Cat. No.89CH2716-9), P81, DOI 10.1109/WVM.1989.47097; Spoerri A., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P209; THOMPSON WB, 1985, IEEE T PATTERN ANAL, V7, P374, DOI 10.1109/TPAMI.1985.4767677; Weiss Y, 1996, PROC CVPR IEEE, P321, DOI 10.1109/CVPR.1996.517092	34	82	83	0	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2000	38	3					231	245		10.1023/A:1008195307933	http://dx.doi.org/10.1023/A:1008195307933			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	352VV					2022-12-18	WOS:000089239400004
J	Wells, WM				Wells, WM			Statistical approaches to feature-based object recognition	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							EM ALGORITHM; IMAGES; VISION	This paper examines statistical approaches to model-based object recognition. Evidence is presented indicating that, in some domains, normal (Gaussian) distributions are more accurate than uniform distributions for modeling feature fluctuations. This motivates the development of new maximum-likelihood and MAP recognition formulations which are based on normal feature models. These formulations lead to an expression for the posterior probability of the pose and correspondences given an image. Several avenues are explored for specifying a recognition hypothesis. In the first approach, correspondences are included as a part of the hypotheses. Search for solutions may be ordered as a combinatorial search in correspondence space, or as a search over pose space, where the same criterion can equivalently be viewed as a robust variant of chamfer matching. In the second approach, correspondences are not viewed as being a part of the hypotheses. This leads to a criterion that is a smooth function of pose that is amenable to local search by continuous optimization methods. The criteria is also suitable for optimization via the Expectation-Maximization (EM) algorithm, which alternates between pose refinement and re-estimation of correspondence probabilities until convergence is obtained. Recognition experiments are described using the criteria with features derived from video images and from synthetic range images.	HARVARD UNIV, SCH MED, BRIGHAM & WOMENS HOSP, DEPT RADIOL, CAMBRIDGE, MA 02138 USA	Harvard University; Brigham & Women's Hospital	Wells, WM (corresponding author), MIT, ARTIFICIAL INTELLIGENCE LAB, 545 TECHNOL SQ, CAMBRIDGE, MA 02139 USA.							[Anonymous], 2018, A A PRACT, V11, P321; [Anonymous], [No title captured]; [Anonymous], 1985, PERCEPTUAL ORG VISUA; AYACHE N, 1986, IEEE T PATTERN ANAL, V8, P44, DOI 10.1109/TPAMI.1986.4767751; Barrow HG, 1977, P 5 INT JOINT C ART; Beck J., 1977, PARAMETER ESTIMATION; BESL PJ, 1985, COMPUT SURV, V17, P75, DOI 10.1145/4078.4081; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BEVERIDGE JR, 1989, P IM UND WORKSH LOS, P815; BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107; BREUEL TM, 1992, THESIS MIT; BROOKS RA, 1983, IEEE T PATTERN ANAL, V5, P140, DOI 10.1109/TPAMI.1983.4767366; BURNS J, 1992, P IM UND WORKSH M KA, P675; BURNS J, 1992, THESIS MIT; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CASS T, 1992, THESIS MIT; CASS TA, 1992, LECT NOTES COMPUT SC, V588, P834; CHIN RT, 1986, COMPUT SURV, V18, P67, DOI 10.1145/6462.6464; CLEMENS D, 1990, S ADV INT SYST SPIE; CLEMENS DT, 1991, IEEE T PATTERN ANAL, V13, P1007, DOI 10.1109/34.99235; Cohen F. S., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P964, DOI 10.1109/CVPR.1988.196349; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Duda R.O., 1973, J ROYAL STAT SOC SER; DYKSTRA PC, 1987, P 4 COMP GRAPH WORKS, P73; EDELMAN S, 1990, 1181 MIT AI; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; FUA P, 1989, P DARPA IMAGE UNDERS, P676; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Goad C., 1986, PIXELS PREDICATES, P371; GREEN T, 1992, OPT ENG; GREEN T, 1992, THESIS MIT; GRIMSON W, 1990, 1 EUR C COMP VIS, P489; Grimson W. E. L., 1990, OBJECT RECOGNITION C; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615; GRIMSON WEL, 1987, IEEE T PATTERN ANAL, V9, P469, DOI 10.1109/TPAMI.1987.4767935; HARALICK RM, 1989, IEEE T SYST MAN CYB, V19, P1426, DOI 10.1109/21.44063; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; HUTTENLOCHER DP, 1988, APR P DARPA IU WORKS, P1114; HUTTENLOCHER DP, 1991, 7TH P ACM S COMP GEO, P194; ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1; JACOBS D, 1992, THESIS MIT; JAYNES ET, 1982, MAXIMUM ENTROPY BAYE, P21; JIANG H, 1992, SPIE, V1808, P196; Kumar R., 1989, P WORKSHOP INTERPRET, P52; Lamdan Y., 1988, 2 INT C COMP VIS; LEVITT T, 1988, P COMP SOC C COMP VI; LIPSON P, 1992, THESIS MIT; Marr D., 1982, VISION; MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127; MARROQUIN J, 1985, THESIS MIT; MENON M, 1990, P INT JOINT C NEUR N; PERRETT DI, 1985, PROC R SOC SER B-BIO, V223, P293, DOI 10.1098/rspb.1985.0003; PONCE J, 1989, IMAGE UNDERSTANDING WORKSHOP /, P461; Press WH, 1986, NUMERICAL RECIPES C, V818; RIVLIN E, 1992, CARTR631 U MAR; Shapiro J. H., 1986, Proceedings of the SPIE - The International Society for Optical Engineering, V663, P38; Shapiro S. C., 1987, ENCY ARTIFICIAL INTE; STEPHENS RS, 1990, P 1990 BRIT MACH VIS, P55; THOMPSON D, 1989, P IM UND WORKSH MORG, P1070; Thompson Dennis, 1987, P IEEE INT C ROB AUT, P108; ULLMAN S, 1989, 1152 MIT AI; Well W. M.  III, 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P486, DOI 10.1109/CVPR.1991.139740; WELLS W, 1993, P IM UND WORKSH MORG; WELLS W, 1992, 1398 MIT TR AI LAB; WELLS W, 1990, SPIE; WU CFJ, 1983, ANN STAT, V11, P95, DOI 10.1214/aos/1176346060; YUILLE A, 1990, 1ST P EUR C COMP VIS, P73; Yuille AL, 1990, NEURAL COMPUT, V2, P1, DOI 10.1162/neco.1990.2.1.1	69	82	105	0	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	1997	21	1-2					63	98		10.1023/A:1007923522710	http://dx.doi.org/10.1023/A:1007923522710			36	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	WM797					2022-12-18	WOS:A1997WM79700004
J	FUNT, BV; DREW, MS; HO, JA				FUNT, BV; DREW, MS; HO, JA			COLOR CONSTANCY FROM MUTUAL REFLECTION	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							SURFACE SPECTRAL REFLECTANCE; ILLUMINATION; LIGHT	Mutual reflection occurs when light reflected from one surface illuminates a second surface. In this situation, the color of one or both surfaces can be modified by a color-bleeding effect. In this article we examine how sensor values (e.g., RGB values) are modified in the mutual reflection region and show that a good approximation of the surface spectral reflectance function for each surface can be recovered by using the extra information from mutual reflection. Thus color constancy results from an examination of mutual reflection. Use is made of finite dimensional linear models for ambient illumination and for surface spectral reflectance. If m and n are the number of basis functions required to model illumination and surface spectral reflectance respectively, then we find that the number of different sensor classes p must satisfy the condition p greater-than-or-equal-to (2 n + m)/3. If we use three basis functions to model illumination and three basis functions to model surface spectral reflectance, then only three classes of sensors are required to carry out the algorithm. Results are presented showing a small increase in error over the error inherent in the underlying finite dimension models.	SIMON FRASER UNIV,SCH COMP SCI,BURNABY V5A 1S6,BC,CANADA	Simon Fraser University								Beck J., 1972, SURFACE COLOR PERCEP; BLACKWELL KT, 1988, J OPT SOC AM A, V5, P1772, DOI 10.1364/JOSAA.5.001772; BRAINARD DH, 1989, IEEE T BIO-MED ENG, V36, P140, DOI 10.1109/10.16459; BRAINARD DH, 1989, IEEE T BIO-MED ENG, V36, P572; BRILL MH, 1986, COLOR RES APPL, V11, P196, DOI 10.1002/col.5080110306; BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7; Burden RL, 1981, NUMERICAL ANAL; COHEN J, 1964, PSYCHON SCI AM A, V6, P318; DIXON ER, 1978, J OPT SOC AM, V68, P437, DOI 10.1364/JOSA.68.000437; DREW MS, 1990, DEC P INT C COMP VIS; DZMURA M, J OPT SOC AM, P1662; Forsyth D., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P466, DOI 10.1109/CVPR.1989.37889; FORSYTH D, 1990, IMAGE VISION COMPUT, V8, P42, DOI 10.1016/0262-8856(90)90055-A; Funt B., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P2, DOI 10.1109/CCV.1988.589966; FUNT BV, 1989, INT J COMPUT VISION, V3; GERSHON R, 1986, J OPT SOC AM A, V3, P1700, DOI 10.1364/JOSAA.3.001700; GERSHON R, 1987, 10TH P IJCAI MIL, P755; Goral C. M., 1984, Computers & Graphics, V18, P213; HO JA, 1990, IEEE T PATTERN ANAL, V12, P966, DOI 10.1109/34.58869; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1977, ARTIF INTELL, V8, P201, DOI 10.1016/0004-3702(77)90020-0; JUDD DB, 1964, J OPT SOC AM, V54, P1031, DOI 10.1364/JOSA.54.001031; KOENDERINK JJ, 1983, J OPT SOC AM, V73, P843, DOI 10.1364/JOSA.73.000843; KRINOV EL, 1947, TT439 NAT RES COUNC; MALONEY LT, 1986, J OPT SOC AM A, V3, P1673, DOI 10.1364/JOSAA.3.001673; MALONEY LT, 1986, J OPT SOC AM A, V3, P29, DOI 10.1364/JOSAA.3.000029; MALONEY LT, 1985, THESIS STANFORD U; NAYAR SK, 1990, DEC P INT C COMP VIS; PARKKINEN JPS, 1989, J OPT SOC AM A, V6, P318, DOI 10.1364/JOSAA.6.000318; Siegel R., 1981, THERMAL RAD HEAT TRA; SPARROW EM, 1978, THERMAL RAD HEAT TRA; WANDELL BA, 1987, IEEE T PATTERN ANAL, V9, P2, DOI 10.1109/TPAMI.1987.4767868; Wyszecki Gunter, 1982, COLOR SCI, V8; YUILLE A, 1987, BIOL CYBERN, V56, P195, DOI 10.1007/BF00317994	34	82	82	0	4	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	APR	1991	6	1					5	24		10.1007/BF00127123	http://dx.doi.org/10.1007/BF00127123			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	FL254					2022-12-18	WOS:A1991FL25400001
J	Mobahi, H; Rao, SR; Yang, AY; Sastry, SS; Ma, Y				Mobahi, Hossein; Rao, Shankar R.; Yang, Allen Y.; Sastry, Shankar S.; Ma, Yi			Segmentation of Natural Images by Texture and Boundary Compression	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Image segmentation; Texture segmentation; Minimum description length	UNSUPERVISED SEGMENTATION; ALGORITHM; CONTOUR	We present a novel algorithm for segmentation of natural images that harnesses the principle of minimum description length (MDL). Our method is based on observations that a homogeneously textured region of a natural image can be well modeled by a Gaussian distribution and the region boundary can be effectively coded by an adaptive chain code. The optimal segmentation of an image is the one that gives the shortest coding length for encoding all textures and boundaries in the image, and is obtained via an agglomerative clustering process applied to a hierarchy of decreasing window sizes as multi-scale texture features. The optimal segmentation also provides an accurate estimate of the overall coding length and hence the true entropy of the image. We test our algorithm on the publicly available Berkeley Segmentation Dataset. It achieves state-of-the-art segmentation results compared to other existing methods.	[Yang, Allen Y.; Sastry, Shankar S.] Univ Calif Berkeley, Dept EECS, Berkeley, CA 94720 USA; [Mobahi, Hossein; Ma, Yi] Univ Illinois, Coordinated Sci Lab, Urbana, IL 61801 USA; [Rao, Shankar R.] HRL Labs LLC, Malibu, CA 90265 USA; [Ma, Yi] Microsoft Res Asia, Visual Comp Grp, Beijing, Peoples R China	University of California System; University of California Berkeley; University of Illinois System; University of Illinois Urbana-Champaign; HRL Laboratories; Microsoft; Microsoft Research Asia	Yang, AY (corresponding author), Univ Calif Berkeley, Dept EECS, Cory Hall, Berkeley, CA 94720 USA.	hmobahi2@illinois.edu; srrao@hrl.com; yang@eecs.berkeley.edu; sastry@eecs.berkeley.edu; yima@illinois.edu			NSF IIS [07-03756]; ONR [N00014-09-1-0230]; ARO MURI [W911NF-06-1-0076]; ARL MAST-CTA [W911NF-08-2-0004]; University of Illinois at Urbana-Champaign	NSF IIS(National Science Foundation (NSF)); ONR(Office of Naval Research); ARO MURI(MURI); ARL MAST-CTA; University of Illinois at Urbana-Champaign	Research was supported in part by NSF IIS 07-03756, ONR N00014-09-1-0230, ARO MURI W911NF-06-1-0076, and ARL MAST-CTA W911NF-08-2-0004. Hossein Mobahi was supported by Computational Science & Engineering (CSE) Ph.D. fellowship of University of Illinois at Urbana-Champaign. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Army Research Laboratory, US Government, or the CSE program. The US Government is authorized to reproduce and distribute for Government purposes notwithstanding any copyright notation hereon.	ARBELAEZ P, 2006, WORKSH PERC ORG COMP; ARBELAEZ P, 2009, P IEEE C COMP VIS PA; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; COUR T, 2005, P IEEE C COMP VIS PA; Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985; DONOSER M, 2009, P INT C COMP VIS; Duda R.O., 2001, PATTERN CLASSIFICATI; Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383; ELDER J, 1996, P EUR C COMP VIS; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Freixenet J, 2002, LECT NOTES COMPUT SC, V2352, P408, DOI 10.1007/3-540-47977-5_27; GEVERS T, 1997, P IEEE C COMP VIS PA; HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7; Jain A. K., 1989, FUNDAMENTALS DIGITAL; Kim JM, 2005, IEEE T IMAGE PROCESS, V14, P1486, DOI 10.1109/TIP.2005.854442; KIM T, 2010, P IEEE C COMP VIS PA; Kurita T, 1995, IEICE T INF SYST, VE78D, P1546; Levina E, 2006, ANN STAT, V34, P1751, DOI 10.1214/009053606000000588; Liu YK, 2005, PATTERN RECOGN, V38, P553, DOI 10.1016/j.patcog.2004.08.017; Ma Y, 2007, IEEE T PATTERN ANAL, V29, P1546, DOI 10.1109/TP'AMI.2007.1085; Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800; MARTIN D, 2001, P INT C COMP VIS; MEILA M, 2005, P INT C MACH LEARN; MORI G, 2004, P IEEE C COMP VIS PA; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; Rao SR, 2010, LECT NOTES COMPUT SC, V5994, P135; REN X, 2005, P INT C COMP VIS; Ren XF, 2008, INT J COMPUT VISION, V77, P47, DOI 10.1007/s11263-007-0092-6; Tremeau A, 1997, PATTERN RECOGN, V30, P1191, DOI 10.1016/S0031-3203(96)00147-1; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; VARMA M, 2003, P IEEE C COMP VIS PA; WANG J, 2008, P IEEE C COMP VIS PA; Yang AY, 2008, COMPUT VIS IMAGE UND, V110, P212, DOI 10.1016/j.cviu.2007.07.005; YU S, 2005, P IEEE C COMP VIS PA; ZHU Q, 2007, P INT C COMP VIS	35	81	87	0	27	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	OCT	2011	95	1					86	98		10.1007/s11263-011-0444-0	http://dx.doi.org/10.1007/s11263-011-0444-0			13	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	815ZU		Green Submitted			2022-12-18	WOS:000294569300006
J	Torr, PHS; Fitzgibbon, AW; Zisserman, A				Torr, PHS; Fitzgibbon, AW; Zisserman, A			The problem of degeneracy in structure and motion recovery from uncalibrated image sequences	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	6th International Conference on Computer Vision	JAN 04-07, 1998	BOMBAY, INDIA	IEEE Comp Soc		projective reconstruction; multiview geometry; match moving	TRIFOCAL TENSOR	The aim of this work is the recovery of 3D structure and camera projection matrices for each frame of an uncalibrated image sequence. In order to achieve this, correspondences are required throughout the sequence. A significant and successful mechanism for automatically establishing these correspondences is by the use of geometric constraints arising from scene rigidity. However, problems arise with such geometry guided matching if general viewpoint and general structure are assumed whilst frames in the sequence and/or scene structure do not conform to these assumptions. Such cases are termed degenerate. In this paper we describe two important cases of degeneracy and their effects on geometry guided matching. The cases are a motion degeneracy where the camera does not translate between frames, and a structure degeneracy where the viewed scene structure is planar. The effects include the loss of correspondences due to under or over fitting of geometric models estimated from image data, leading to the failure of the tracking method. These degeneracies are not a theoretical curiosity, but commonly occur in real sequences where models are statistically estimated from image points with measurement error. We investigate two strategies for tackling such degeneracies: the first uses a statistical model selection test to identify when degeneracies occur: the second uses multiple motion models to overcome the degeneracies. The strategies are evaluated on real sequences varying in motion, scene type, and length from 13 to 120 frames.	Microsoft Corp, Res, Redmond, WA 98052 USA; Univ Oxford, Dept Engn Sci, Robot Res Grp, Oxford OX1 3PJ, England	Microsoft; University of Oxford	Torr, PHS (corresponding author), Microsoft Corp, Res, 1 Microsoft Way, Redmond, WA 98052 USA.	philtorr@microsoft.com; awf@robots.ox.ac.uk; az@robots.ox.ac.uk						AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; Ayache N, 1991, ARTIFICIAL VISION MO; Bar-Shalom Y., 1988, TRACKING DATA ASS; BEARDSLEY PA, 1996, LNCS, V1065, P683; BEARDSLEY PA, 1994, LNCS SERIES, V801, P85; Capel D, 1998, PROC CVPR IEEE, P885, DOI 10.1109/CVPR.1998.698709; COX IJ, 1992, LECT NOTES COMPUT SC, V588, P72; FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P564; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; FITZGIBBON AW, 1998, P EUR C COMP VIS, P311; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; HARRIS CG, 1987, 3RD ALV VIS C, P189; HARTLEY R, 1994, LECT NOTES COMPUTER, V800, P471; HARTLEY R, 1992, P C COMP VIS PATT RE; HARTLEY RI, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P882, DOI 10.1109/ICCV.1995.466843; Hartley RI, 1997, INT J COMPUT VISION, V22, P125, DOI 10.1023/A:1007936012022; HARTLEY RI, 1994, LNCS SERIES, V825, P237; Huber P., 1981, ROBUST STAT; Irani M., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P17, DOI 10.1007/BFb0015520; KANATANI K, 1996, LECT NOTES COMPUTER, V1064, P697; LAVEAU S, 1996, THESIS INRIA; MAYBANK S, 1993, THEORY RECONSTRUCTIO; MCLAUCHLAN PF, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P314, DOI 10.1109/ICCV.1995.466923; MILGRAM P, 1993, IROS 93 : PROCEEDINGS OF THE 1993 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOL 1-3, P1467, DOI 10.1109/IROS.1993.583833; Pollefeys M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P90, DOI 10.1109/ICCV.1998.710705; Press WH, 1988, NUMERICAL RECIPES C; RAO B, 1992, ACTIVE VISION, P91; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SHASHUA A, 1994, P ECCV, V1, P479; SPETSAKIS M, 1991, INT J COMPUT VISION, V6, P245, DOI 10.1007/BF00115698; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torr P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P727, DOI 10.1109/ICCV.1998.710798; Torr P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P485, DOI 10.1109/ICCV.1998.710762; Torr PHS, 1997, IMAGE VISION COMPUT, V15, P591, DOI 10.1016/S0262-8856(97)00010-3; TORR PHS, 1993, IMAGE VISION COMPUT, V11, P180, DOI 10.1016/0262-8856(93)90034-E; TORR PHS, 1997, IN PRESS CVIU; TRIGGS W, 1998, P 5 EUR C COMP VIS F; ZELLER C, 1996, THESIS INRIA SOPHIA; ZHANG Z, 1992, 3D DYNAMIC SCENE ANA; ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4	40	81	93	0	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	1999	32	1					27	44		10.1023/A:1008140928553	http://dx.doi.org/10.1023/A:1008140928553			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	237NW					2022-12-18	WOS:000082663800003
J	Wang, LM; Qiao, Y; Tang, XO				Wang, Limin; Qiao, Yu; Tang, Xiaoou			MoFAP: A Multi-level Representation for Action Recognition	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Action recognition; Motion Feature; Motion Atom; Motion Phrase		This paper proposes a multi-level video representation by stacking the activations of motion features, atoms, and phrases (MoFAP). Motion features refer to those low-level local descriptors, while motion atoms and phrases can be viewed as mid-level "temporal parts". Motion atom is defined as an atomic part of action, and captures the motion information of video in a short temporal scale. Motion phrase is a temporal composite of multiple motion atoms defined with an AND/OR structure. It further enhances the discriminative capacity of motion atoms by incorporating temporal structure in a longer temporal scale. Specifically, we first design a discriminative clustering method to automatically discover a set of representative motion atoms. Then, we mine effective motion phrases with high discriminative and representative capacity in a bottom-up manner. Based on these basic units of motion features, atoms, and phrases, we construct a MoFAP network by stacking them layer by layer. This MoFAP network enables us to extract the effective representation of video data from different levels and scales. The separate representations from motion features, motion atoms, and motion phrases are concatenated as a whole one, called Activation of MoFAP. The effectiveness of this representation is demonstrated on four challenging datasets: Olympic Sports, UCF50, HMDB51, and UCF101. Experimental results show that our representation achieves the state-of-the-art performance on these datasets.	[Wang, Limin; Tang, Xiaoou] Chinese Univ Hong Kong, Dept Informat Engn, Shatin, Hong Kong, Peoples R China; [Qiao, Yu] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China	Chinese University of Hong Kong; Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS	Wang, LM (corresponding author), Chinese Univ Hong Kong, Dept Informat Engn, Shatin, Hong Kong, Peoples R China.	07wanglimin@gmail.com; yu.qiao@siat.ac.cn; xtang@ie.cuhk.edu.hk	Qiao, Yu/ABD-5787-2021; Wang, Limin/AAE-3419-2019	Wang, Limin/0000-0002-3674-7718				Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653; Agrawal R., 1994, P 20 INT C VER LARG, P487; Amer MR, 2012, LECT NOTES COMPUT SC, V7575, P187, DOI 10.1007/978-3-642-33765-9_14; Berg TL, 2010, LECT NOTES COMPUT SC, V6311, P663, DOI 10.1007/978-3-642-15549-9_48; Bishop C.M, 2006, PATTERN RECOGN; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Cai ZW, 2014, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2014.83; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chen Y., 2007, NIPS; Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Doersch Carl, 2013, NIPS; Forsyth David A., 2005, FDN TRENDS COMPUTER, V1; Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800; Gaidon A, 2014, INT J COMPUT VISION, V107, P219, DOI 10.1007/s11263-013-0677-1; Gaidon A, 2013, IEEE T PATTERN ANAL, V35, P2782, DOI 10.1109/TPAMI.2013.65; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; JAIN A, 2013, CVPR, P2571, DOI DOI 10.1109/CVPR.2013.332; Jain M, 2013, PROC CVPR IEEE, P2555, DOI 10.1109/CVPR.2013.330; Jiang Y., 2013, THUMOS CHALLENGE ACT; Jiang YG, 2012, LECT NOTES COMPUT SC, V7576, P425, DOI 10.1007/978-3-642-33715-4_31; Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Kliper-Gross O, 2012, LECT NOTES COMPUT SC, V7577, P256, DOI 10.1007/978-3-642-33783-3_19; Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Laxton BM, 2007, PROC CVPR IEEE, P799; Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29; Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684; Parikh D, 2011, IEEE I CONF COMP VIS, P503, DOI 10.1109/ICCV.2011.6126281; Pirsiavash H, 2014, PROC CVPR IEEE, P612, DOI 10.1109/CVPR.2014.85; Raptis M, 2012, PROC CVPR IEEE, P1242, DOI 10.1109/CVPR.2012.6247807; Reddy KK, 2013, MACH VISION APPL, V24, P971, DOI 10.1007/s00138-012-0450-4; Rohrbach M, 2012, LECT NOTES COMPUT SC, V7572, P144, DOI 10.1007/978-3-642-33718-5_11; Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Sapienza M., 2012, BMVC, P1; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Si ZZ, 2013, IEEE T PATTERN ANAL, V35, P2189, DOI 10.1109/TPAMI.2013.35; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Singh S, 2012, LECT NOTES COMPUT SC, V7573, P73, DOI 10.1007/978-3-642-33709-3_6; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Soomro K., 2012, ARXIV; Tang K, 2012, PROC CVPR IEEE, P1250, DOI 10.1109/CVPR.2012.6247808; Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Wang Heng, 2013, ICCV WORKSH ACT REC; Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059; Wang LM, 2013, IEEE I CONF COMP VIS, P2680, DOI 10.1109/ICCV.2013.333; Wang LM, 2014, LECT NOTES COMPUT SC, V8693, P565, DOI 10.1007/978-3-319-10602-1_37; Wang LM, 2013, PROC CVPR IEEE, P2674, DOI 10.1109/CVPR.2013.345; Wang LM, 2014, IEEE T IMAGE PROCESS, V23, P810, DOI 10.1109/TIP.2013.2295753; Wang S. B., 2006, PROC IEEE COMPUT SOC, P1521, DOI DOI 10.1109/CVPR.2006.132; Wang Xingxing, 2012, ASIAN C COMPUTER VIS, P572; Wu JX, 2014, PROC CVPR IEEE, P2577, DOI 10.1109/CVPR.2014.330; Yao Bangpeng, 2010, CVPR, DOI DOI 10.1109/CVPR.2010.5540234; Zhang WY, 2013, IEEE I CONF COMP VIS, P2248, DOI 10.1109/ICCV.2013.280; Zhao Y., 2011, ADV NEURAL INFORM PR, P73; Zhu J, 2013, IEEE I CONF COMP VIS, P3559, DOI 10.1109/ICCV.2013.442	60	80	85	1	20	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2016	119	3			SI		254	271		10.1007/s11263-015-0859-0	http://dx.doi.org/10.1007/s11263-015-0859-0			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	DS0FE					2022-12-18	WOS:000380270000004
J	Castrodad, A; Sapiro, G				Castrodad, Alexey; Sapiro, Guillermo			Sparse Modeling of Human Actions from Motion Imagery	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Action classification; Sparse modeling; Dictionary learning; Supervised learning		An efficient sparse modeling pipeline for the classification of human actions from video is here developed. Spatio-temporal features that characterize local changes in the image are first extracted. This is followed by the learning of a class-structured dictionary encoding the individual actions of interest. Classification is then based on reconstruction, where the label assigned to each video comes from the optimal sparse linear combination of the learned basis vectors (action primitives) representing the actions. A low computational cost deep-layer model learning the inter-class correlations of the data is added for increasing discriminative power. In spite of its simplicity and low computational cost, the method outperforms previously reported results for virtually all standard datasets.	[Castrodad, Alexey; Sapiro, Guillermo] Univ Minnesota, Dept Elect & Comp Engn, Minneapolis, MN 55455 USA	University of Minnesota System; University of Minnesota Twin Cities	Castrodad, A (corresponding author), Univ Minnesota, Dept Elect & Comp Engn, Minneapolis, MN 55455 USA.	castr103@umn.edu; guille@umn.edu			NGA; ONR; ARO; NSF; Level Sets Systems; AFOSR (NSSEFF)	NGA; ONR(Office of Naval Research); ARO; NSF(National Science Foundation (NSF)); Level Sets Systems; AFOSR (NSSEFF)	Work partially supported by NGA, ONR, ARO, NSF, Level Sets Systems, and AFOSR (NSSEFF). The authors would like to thank Pablo Sprechmann, Dr. Mariano Tepper, and David S. Hermina for very helpful suggestions and insightful discussions. We also thank Dr. Julien Mairal for providing publicly available sparse modeling code (SPAMS http://www.di.ens.fr/willow/SPAMS/downloads.html) used in this work.	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; [Anonymous], 2010, P INT C MACH LEARN; Blake R, 2007, ANNU REV PSYCHOL, V58, P47, DOI 10.1146/annurev.psych.57.102904.190152; Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704; Cadieu C. F., 2008, ADV NEURAL INFORM PR, P209; Castrodad A, 2011, IEEE T GEOSCI REMOTE, V49, P4263, DOI 10.1109/TGRS.2011.2163822; Charles A., 2011, IEEE J SELECTED TOPI; Chen C.-C., 2010, UT TOWER DATASET AER; Dalal N., 2006, ECCV; Dean T, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P645, DOI 10.1109/ISM.2009.28; Dollar P, 2005, VS PETS, P65; Donoho David, 2000, HIGH DIMENSIONAL DAT; Gall J, 2011, IEEE T PATTERN ANAL, V33, P2188, DOI 10.1109/TPAMI.2011.70; Hastie T, 1996, J ROY STAT SOC B MET, V58, P155; Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407; Ikizler-Cinbis N, 2010, LECT NOTES COMPUT SC, V6311, P494, DOI 10.1007/978-3-642-15549-9_36; Jhuang H, 2007, IEEE I CONF COMP VIS, P1253; Kai Guo, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P188, DOI 10.1109/AVSS.2010.71; Klaser Alexander, 2008, P BRIT MACH VIS C; Kovashka A, 2010, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2010.5539881; Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378; Laptev I., 2008, CVPR; Le Q. V., 2011, CVPR; Liu J., 2009, CVPR; Mairal J., 2008, ADV NEURAL INFORM PR, P1033; Mairal J, 2010, J MACH LEARN RES, V11, P19; Marszalek M., 2009, CVPR; Ramirez I, 2010, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR.2010.5539964; Rodriguez M. D., 2008, CVPR; Ryoo MS, 2010, LECT NOTES COMPUT SC, V6388, P270, DOI 10.1007/978-3-642-17711-8_28; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Scovanner P., 2007, ACM MM, P357; Shao L., 2010, P ACM INT C IM VID R, P477; Sprechmann P., 2010, ICASSP; Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11; Vezzani R, 2010, LECT NOTES COMPUT SC, V6388, P286, DOI 10.1007/978-3-642-17711-8_29; Wang H, 2009, BMVC; Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Xiang Z., 2011, ADV NEURAL INFORM PR, V24, P900; Yeffet L, 2009, IEEE I CONF COMP VIS, P492, DOI 10.1109/ICCV.2009.5459201	41	80	87	0	32	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	OCT	2012	100	1					1	15		10.1007/s11263-012-0534-7	http://dx.doi.org/10.1007/s11263-012-0534-7			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	962SH		Green Submitted			2022-12-18	WOS:000305564800001
J	Xia, GS; Delon, J; Gousseau, Y				Xia, Gui-Song; Delon, Julie; Gousseau, Yann			Shape-based Invariant Texture Indexing	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Topographic map; Level lines; Texture analysis; Local invariance	GRAY-SCALE; PATTERN-RECOGNITION; ROTATION; CLASSIFICATION; SEGMENTATION; CONTRAST; REPRESENTATION; COMPUTATION; ALGORITHM; OPERATORS	This paper introduces a new texture analysis scheme, which is invariant to local geometric and radiometric changes. The proposed methodology relies on the topographic map of images, obtained from the connected components of level sets. This morphological tool, providing a multi-scale and contrast-invariant representation of images, is shown to be well suited to texture analysis. We first make use of invariant moments to extract geometrical information from the topographic map. This yields features that are invariant to local similarities or local affine transformations. These features are invariant to any local contrast change. We then relax this invariance by computing additional features that are invariant to local affine contrast changes and investigate the resulting analysis scheme by performing classification and retrieval experiments on three texture databases. The obtained experimental results outperform the current state of the art in locally invariant texture analysis.	[Xia, Gui-Song; Delon, Julie; Gousseau, Yann] CNRS, LTCI, Telecom ParisTech, F-75013 Paris, France	Centre National de la Recherche Scientifique (CNRS); IMT - Institut Mines-Telecom; Institut Polytechnique de Paris; UDICE-French Research Universities; Universite Paris Cite	Xia, GS (corresponding author), CNRS, LTCI, Telecom ParisTech, 46 Rue Barrault, F-75013 Paris, France.	xia@enst.fr; delon@enst.fr; gousseau@enst.fr	Delon, Julie/U-5964-2017	Delon, Julie/0000-0002-7182-7537; Xia, Gui-Song/0000-0001-7660-6090				Asano A, 2000, INT C PATT RECOG, P475, DOI 10.1109/ICPR.2000.903587; Ayala G, 2001, IEEE T PATTERN ANAL, V23, P1430, DOI 10.1109/34.977566; Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; Caselles V, 1999, IEEE T IMAGE PROCESS, V8, P220, DOI 10.1109/83.743856; Caselles V, 1999, INT J COMPUT VISION, V33, P5, DOI 10.1023/A:1008144113494; CASELLES V, 1997, P INT C SCAL SPAC TH, V11, P29; CASELLES V, 2009, LECT NOTES MATH; CHEN CH, 1982, P INT C PATT REC; CHEN JL, 1994, IEEE T PATTERN ANAL, V16, P208, DOI 10.1109/34.273730; CHEN YD, 1994, OPT ENG, V33, P2713, DOI 10.1117/12.173552; COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P192, DOI 10.1109/34.67648; Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778; DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P251, DOI 10.1109/TPAMI.1979.4766921; DAVIS LS, 1981, PATTERN RECOGN, V13, P219, DOI 10.1016/0031-3203(81)90098-4; Do MN, 2002, IEEE T MULTIMEDIA, V4, P517, DOI 10.1109/TMM.2002.802019; Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383; Fei-Fei L, 2005, PROC CVPR IEEE, P524; Fletcher ND, 2005, COMPUT IMAGING VIS, V30, P367; FLOYD RW, 1962, COMMUN ACM, V5, P345, DOI 10.1145/367766.368168; FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H; GIDAS B, 1989, IEEE T PATTERN ANAL, V11, P164, DOI 10.1109/34.16712; GOUSSEAU Y, 2002, P INT WORKSH TEXT AN, P53; Hamdan HM, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P937, DOI 10.1109/ICIP.2002.1039127; Hanbury A, 2005, COMPUT IMAGING VIS, V30, P377; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Heijmans HJAM, 1999, COMPUT VIS IMAGE UND, V73, P99, DOI 10.1006/cviu.1998.0703; HOUHOU N, 2008, P COMP VIS PATT REC; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; JAIN AK, 1990, 1990 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, P14, DOI 10.1016/0031-3203(91)90143-S; KAIZER H, 1955, 121 BOST U; KASHYAP RL, 1986, IEEE T PATTERN ANAL, V8, P472, DOI 10.1109/TPAMI.1986.4767811; Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151; Lazebnik S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P649; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; Li W, 1997, PATTERN RECOGN, V30, P1081, DOI 10.1016/S0031-3203(96)00146-X; Liao SX, 1996, IEEE T PATTERN ANAL, V18, P254, DOI 10.1109/34.485554; Luo B, 2008, IEEE T IMAGE PROCESS, V17, P1465, DOI 10.1109/TIP.2008.925367; Luo H, 2009, IEEE T MOBILE COMPUT, V8, P1, DOI 10.1109/TMC.2008.82; MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; Mellor M, 2008, IEEE T PATTERN ANAL, V30, P52, DOI 10.1109/TPAMI.2007.1161; MEYER Y, 2007, WORKSH INT APPR TEXT; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Monasse P, 1999, INT CONF ACOUST SPEE, P3221, DOI 10.1109/ICASSP.1999.757527; Monasse P, 2000, J VIS COMMUN IMAGE R, V11, P224, DOI 10.1006/jvci.1999.0441; Monasse P, 2000, IEEE T IMAGE PROCESS, V9, P860, DOI 10.1109/83.841532; MONASSE P, 2000, THESIS PARIS DAUPHIN; OBDRZALEK S, 2002, P BRIT MACH VIS C, P113; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Peleg S, 1984, IEEE Trans Pattern Anal Mach Intell, V6, P518, DOI 10.1109/TPAMI.1984.4767557; PEYRE G, 2009, IEEE T PATT IN PRESS; Pietikainen M, 2000, PATTERN RECOGN, V33, P43, DOI 10.1016/S0031-3203(99)00032-1; Pun CM, 2003, IEEE T PATTERN ANAL, V25, P590, DOI 10.1109/TPAMI.2003.1195993; Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261; REED TR, 1993, CVGIP-IMAG UNDERSTAN, V57, P359, DOI 10.1006/ciun.1993.1024; SALEMBIER P, 1995, IEEE T IMAGE PROCESS, V4, P1153, DOI 10.1109/83.403422; Sandler R, 2009, INT J COMPUT VISION, V84, P308, DOI 10.1007/s11263-009-0237-x; Schaffalitzky F, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P636, DOI 10.1109/ICCV.2001.937686; Serra H.M., 1967, ANN MINES, VXI, P736; Serra J., 1982, IMAGE ANAL MATH MORP; Simoncelli EP, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P62, DOI 10.1109/ICIP.1998.723417; Song YQ, 2007, IEEE T IMAGE PROCESS, V16, P2107, DOI 10.1109/TIP.2007.899616; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tuceryan M., 1993, HDB PATTERN RECOGNIT, P235, DOI DOI 10.1142/9789814343138_0010; Urbach ER, 2007, IEEE T PATTERN ANAL, V29, P272, DOI 10.1109/TPAMI.2007.28; Varma M, 2002, LECT NOTES COMPUT SC, V2352, P255; VARMA M, 2007, P INT C COMP VIS, P14; Varma M, 2007, IEEE I CONF COMP VIS, P369; Wu J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P848, DOI 10.1109/ICCV.2003.1238437; XIA GS, 2009, INVARIANT TEXTURE AN; XIA GS, 2008, P INT C PATT REC; Xu Y., 2006, INT C COMP VIS PATT, P1932; Xu Y, 2009, INT J COMPUT VISION, V83, P85, DOI 10.1007/s11263-009-0220-6; Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; Zhang JG, 2002, PATTERN RECOGN, V35, P735, DOI 10.1016/S0031-3203(01)00074-7	78	80	84	0	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2010	88	3					382	403		10.1007/s11263-009-0312-3	http://dx.doi.org/10.1007/s11263-009-0312-3			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	580EL		Green Submitted			2022-12-18	WOS:000276429900003
J	Jin, HL; Soatto, S; Yezzi, AJ				Jin, HL; Soatto, S; Yezzi, AJ			Multi-view stereo reconstruction of dense shape and complex appearance	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						image-based modeling and rendering; multi-view stereo; non-Lambertian reflection; 3-D shape reconstruction; variational methods; level set methods; appearance models		We address the problem of estimating the three-dimensional shape and complex appearance of a scene from a calibrated set of views under fixed illumination. Our approach relies on a rank condition that must be satisfied when the scene exhibits "specular + diffuse" reflectance characteristics. This constraint is used to define a cost functional for the discrepancy between the measured images and those generated by the estimate of the scene, rather than attempting to match image-to-image directly. Minimizing such a functional yields the optimal estimate of the shape of the scene, represented by a dense surface, as well as its radiance, represented by four functions defined on such a surface. These can be used to generate novel views that capture the non-Lambertian appearance of the scene.	Adobe Syst Inc, Off Technol, San Jose, CA 95110 USA; Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA; Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA	Adobe Systems Inc.; University of California System; University of California Los Angeles; University System of Georgia; Georgia Institute of Technology	Jin, HL (corresponding author), Adobe Syst Inc, Off Technol, 345 Pk Ave, San Jose, CA 95110 USA.	hljin@adobe.com; soatto@cs.ucla.edu; ayezzi@ece.gatech.edu	Yezzi, Anthony/AAB-4235-2020; Jin, Huali/F-3650-2011					BHAT DN, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1087; BLAKE A, 1985, P INT JOINT C ART IN, P973; BRELSTAFF G, 1988, P IEEE INT C COMP VI, P297; CHAN WCW, 2000, P SOC PHOTO-OPT INS, V1, P2; CHEN WC, 2002, P ACM SIGGRAPH; EPSTEIN CL, 1987, MATH SCI RES I PUBL, V7, P15; Faugeras O, 1998, IEEE T IMAGE PROCESS, V7, P336, DOI 10.1109/83.661183; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; HERTZMANN A, 2003, P IEEE C COMP VIS PA; Horn B., 1986, ROBOT VISION, P1; IKEUCHI K, 1981, IEEE T PATTERN ANAL, V3, P661, DOI 10.1109/TPAMI.1981.4767167; JIN H, 2004, P EUR C COMP VIS; JIN H, 2003, THESIS WASHINGTON U; JIN H, 2002, P 1 INT S 3D DAT PRO; JIN H, 2004, 0453 UCLA CAM DEP MA; Jin HL, 2003, PROC CVPR IEEE, P171; Jin HL, 2003, J SCI COMPUT, V19, P267, DOI 10.1023/A:1025308109816; KERIVEN R, 1997, THESIS ENPC FRANCE; Kim J., 2003, P INT C COMP VIS; Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954; Ma Y., 2003, INVITATION 3 D VISIO; MAGDA S, 2001, P INT C COMP VIS; NAYAR SK, 1993, P IEEE C COMP VIS PA, P585; NISHINO K, 1999, P IEEE C COMP VIS PA; OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; TSIN Y, 2003, P IEEE C COMP VIS PA; WARD GJ, 1992, COMP GRAPH, V26, P265, DOI 10.1145/142920.134078; Yezzi A, 2003, INT J COMPUT VISION, V53, P31, DOI 10.1023/A:1023079624234; Yu Y., 1999, P ACM SIGGRAPH; Zickler TE, 2002, INT J COMPUT VISION, V49, P215, DOI 10.1023/A:1020149707513	33	80	87	1	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2005	63	3					175	189		10.1007/s11263-005-6876-7	http://dx.doi.org/10.1007/s11263-005-6876-7			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	928YR		Green Submitted			2022-12-18	WOS:000229308500001
J	Schechner, YY; Kiryati, N; Basri, R				Schechner, YY; Kiryati, N; Basri, R			Separation of transparent layers using focus	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						semireflections; depth from focus; blind deconvolution; blur estimation; enhancement; image reconstruction and recovery; inverse problems; optical sectioning; signal separation; decorrelation	OPTICAL-SECTIONING MICROSCOPY; IMAGES; VISION; LIGHT; DEPTH; RECONSTRUCTION; ARCHITECTURE; ACQUISITION; INFORMATION; ARTIFACTS	Consider situations where the depth at each point in the scene is multi-valued, due to the presence of a virtual image semi-reflected by a transparent surface. The semi-reflected image is linearly superimposed on the image of an object that is behind the transparent surface. A novel approach is proposed for the separation of the superimposed layers. Focusing on either of the layers yields initial separation, but crosstalk remains. The separation is enhanced by mutual blurring of the perturbing components in the images. However, this blurring requires the estimation of the defocus blur kernels. We thus propose a method for self calibration of the blur kernels, given the raw images. The kernels are sought to minimize the mutual information of the recovered layers. Autofocusing and depth estimation in the presence of semi-reflections are also considered. Experimental results are presented.	Columbia Univ, Dept Comp Sci, New York, NY 10027 USA; Tel Aviv Univ, Fac Engn, Dept Elect Engn Syst, IL-69978 Ramat Aviv, Israel; Weizmann Inst Sci, Dept Appl Math, IL-76100 Rehovot, Israel	Columbia University; Tel Aviv University; Weizmann Institute of Science	Schechner, YY (corresponding author), Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.	yoav@cs.columbia.edu; nk@eng.tau.ac.il; ronen@wisdom.weizmann.ac.il		Kiryati, Nahum/0000-0003-1436-2275				AGARD DA, 1984, ANNU REV BIOPHYS BIO, V13, P191; AGARD DA, 1983, NATURE, V302, P676, DOI 10.1038/302676a0; Aghdasi F, 1996, IEEE T IMAGE PROCESS, V5, P611, DOI 10.1109/83.491337; AHUJA N, 1993, IEEE T PATTERN ANAL, V15, P1007, DOI 10.1109/34.254059; Aizawa K, 2000, IEEE T CIRC SYST VID, V10, P323, DOI 10.1109/76.825731; BERGEN JR, 1992, IEEE T PATTERN ANAL, V14, P886, DOI 10.1109/34.161348; BORGA M, 1999, P SCIA, V1, P127; CASTLEMAN KR, 1979, DIGITAL IMAGE PROCES, P357; CHIU MY, 1979, J OPT SOC AM, V69, P1323, DOI 10.1364/JOSA.69.001323; CONCHELLO JA, 1990, APPL OPTICS, V29, P3795, DOI 10.1364/AO.29.003795; Cover T., 1991, ELEMENTS INFORM THEO, V1, P12, DOI DOI 10.1002/0471200611.CH2; Darrell T., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P504, DOI 10.1109/CVPR.1988.196282; Darrell T., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P738, DOI 10.1109/CVPR.1993.341150; DARRELL T, 1993, TR244 MIT MED LAB; DIASPRO A, 1990, IMAGE VISION COMPUT, V8, P130, DOI 10.1016/0262-8856(90)90028-4; ENGELHARDT K, 1988, APPL OPTICS, V27, P4684, DOI 10.1364/AO.27.004684; ERHARDT A, 1985, APPL OPTICS, V24, P194, DOI 10.1364/AO.24.000194; Farid H, 1999, J OPT SOC AM A, V16, P2136, DOI 10.1364/JOSAA.16.002136; FAY FS, 1983, J CELL BIOL, V96, P783, DOI 10.1083/jcb.96.3.783; Fujikake H, 1998, OPT REV, V5, P93, DOI 10.1007/s10043-998-0093-x; HAUSLER G, 1984, APPL OPTICS, V23, P2468, DOI 10.1364/AO.23.002468; IRANI M, 1994, INT J COMPUT VISION, V12, P5, DOI 10.1007/BF01420982; ITOH K, 1989, APPL OPTICS, V28, P3487, DOI 10.1364/AO.28.003487; JANSSON PA, 1970, J OPT SOC AM, V60, P596, DOI 10.1364/JOSA.60.000596; JARVIS RA, 1983, IEEE T PATTERN ANAL, V5, P122, DOI 10.1109/TPAMI.1983.4767365; Krishnan A, 1996, PROC CVPR IEEE, P379, DOI 10.1109/CVPR.1996.517100; Kubota A., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P447, DOI 10.1109/ICIP.1999.822936; LUENBERGER D.G., 1989, INTRO LINEAR NONLINE; MARCIASGARZA F, 1988, P ICASSP, V2, P890; MCNALLY JG, 1994, J OPT SOC AM A, V11, P1056, DOI 10.1364/JOSAA.11.001056; Nair H. N., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P309, DOI 10.1109/CVPR.1992.223258; Nayar S. K., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P302, DOI 10.1109/CVPR.1992.223259; NAYAR SK, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P995, DOI 10.1109/ICCV.1995.466826; NOGUCHI M, 1994, INT C PATT RECOG, P147, DOI 10.1109/ICPR.1994.576247; OHNISHI N, 1996, LECT NOTES COMPUTER, V1065, P636; OREN M, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P740, DOI 10.1109/ICCV.1995.466864; PREZA C, 1992, J OPT SOC AM A, V9, P219, DOI 10.1364/JOSAA.9.000219; Schechner Y. Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P814, DOI 10.1109/ICCV.1999.790305; Schechner YY, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1061, DOI 10.1109/ICCV.1998.710848; Schechner YY, 1998, INT C PATT RECOG, P1784, DOI 10.1109/ICPR.1998.712074; Schechner YY, 1999, OPT LETT, V24, P1088, DOI 10.1364/OL.24.001088; Schechner YY, 2000, J OPT SOC AM A, V17, P276, DOI 10.1364/JOSAA.17.000276; SCHECHNER YY, 2000, P IEEE COMP SOC C CO, V1, P38; SCHECHNER YY, 1999, P IEEE INT C COMP VI, V2, P843; SCHECHNER YY, 1999, P SCIA, V1, P235; SHEPPARD CJR, 1991, OPT COMMUN, V81, P276, DOI 10.1016/0030-4018(91)90615-K; Shizawa M., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P447, DOI 10.1109/ICCV.1993.378182; SHIZAWA M, 1992, P ECCV, P411; SHIZAWA M, 1990, P 10 INT C PATT REC, V1, P274; STREIBL N, 1985, J OPT SOC AM A, V2, P121, DOI 10.1364/JOSAA.2.000121; STREIBL N, 1984, OPTIK, V66, P341; SUBBARAO M, 1995, P SOC PHOTO-OPT INS, V2598, P89, DOI 10.1117/12.220891; SUGIMOTO SA, 1985, APPL OPTICS, V24, P2076, DOI 10.1364/AO.24.002076; Sundaram H, 1997, PROC CVPR IEEE, P814, DOI 10.1109/CVPR.1997.609421; Thevenaz P, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P833, DOI 10.1109/ICIP.1998.723645; TORROBA P, 1994, J MOD OPTIC, V41, P111, DOI 10.1080/09500349414550121; Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918; Wang J. Y. A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P361, DOI 10.1109/CVPR.1993.341105; Watanabe M., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P439; WEINSHALL D, 1989, NATURE, V341, P737, DOI 10.1038/341737a0; Xiong Y., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P68, DOI 10.1109/CVPR.1993.340977; YEO TTE, 1993, IMAGE VISION COMPUT, V11, P629, DOI 10.1016/0262-8856(93)90059-P	62	80	86	0	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2000	39	1					25	39		10.1023/A:1008166017466	http://dx.doi.org/10.1023/A:1008166017466			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	352WA					2022-12-18	WOS:000089241300002
J	Florack, L; TerHaarRomeny, B; Viergever, M; Koenderink, J				Florack, L; TerHaarRomeny, B; Viergever, M; Koenderink, J			The Gaussian scale-space paradigm and the multiscale local jet	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							GEOMETRY; IMAGES; BLUR	A representation of local image structure is proposed which takes into account both the image's spatial structure at a given location, as well as its ''deep structure'', that is, its local behaviour as a function of scale or resolution (scale-space). This is of interest for several low-level image tasks. The proposed basis of scale-space, for example, enables a precise local study of interactions of neighbouring image intensities in the course of the blurring process. It also provides an extrapolation scheme for local image data, obtained at a given spatial location and resolution, to a finite scale-space neighbourhood. This is especially useful for the determination of sampling rates and for interpolation algorithms in a multilocal context. Another, particularly straightforward application is image enhancement or deblurring, which is an instance of data extrapolation in the high-resolution direction. A potentially interesting feature of the proposed local image parametrisation is that it captures a trade-off between spatial and scale extrapolations from a given interior point that do not exceed a given tolerance. This trade-off suggests the possibility of a fairly coarse scale sampling at the expense of a dense spatial sampling (large relative spatial overlap of scale-space kernels). The central concept developed in this paper is an equivalence class called the multiscale local jet, which is a hierarchical, local characterisation of the image in a full scale-space neighbourhood. For this local jet, a basis of fundamental polynomials is constructed that captures the scale-space paradigm at the local level up to any given order.	UNIV UTRECHT HOSP,COMP VIS RES GRP,3584 CX UTRECHT,NETHERLANDS; UNIV UTRECHT,DEPT MED & PHYSIOL PHYS,3584 CC UTRECHT,NETHERLANDS	Utrecht University; Utrecht University Medical Center; Utrecht University	Florack, L (corresponding author), UNIV AVEIRO,DET,INESC,P-3800 AVEIRO,PORTUGAL.		Romenij, Bart M. ter Haar/A-5323-2013; Viergever, Max A/J-1215-2014					BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; BARRETT HH, 1992, NATO ASI F, V98, P3; Blom J., 1993, Journal of Visual Communication and Image Representation, V4, P1, DOI 10.1006/jvci.1993.1001; DAMON J, 1990, LOCAL MORSE THEORY S; Florack L. M. J., 1993, Journal of Mathematical Imaging and Vision, V3, P327, DOI 10.1007/BF01664793; Florack L. M. J., 1994, Journal of Mathematical Imaging and Vision, V4, P325, DOI 10.1007/BF01262401; FLORACK LMJ, 1992, IMAGE VISION COMPUT, V10, P376, DOI 10.1016/0262-8856(92)90024-W; HUMMEL RA, 1987, COMPUT VISION GRAPH, V38, P66, DOI 10.1016/S0734-189X(87)80153-6; JOHANSEN P, 1986, P 8 INT C PATT REC P, P215; Kay D. C., 1988, TENSOR CALCULUS; KIMIA BB, 1993, OPT ENG, V32, P166, DOI 10.1117/12.60917; Koenderink J. J., 1984, LIMITS PERCEPTION, P495; KOENDERINK JJ, 1986, BIOL CYBERN, V53, P383, DOI 10.1007/BF00318204; KOENDERINK JJ, 1990, BIOL CYBERN, V63, P291, DOI 10.1007/BF00203452; KOENDERINK JJ, 1990, PSYCHOL RES-PSYCH FO, V52, P122, DOI 10.1007/BF00877519; KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371; KOENDERINK JJ, 1992, THEORY APPL IMAGE AN, V2, P15; LAWDEN DF, 1962, INTRO TENSOR CALCULU; LINDEBERG T, 1990, IEEE T PATTERN ANAL, V12, P234, DOI 10.1109/34.49051; LINDEBERG T, 1992, S MACH PERC, V2, P38; Lindeberg T., 1992, Journal of Mathematical Imaging and Vision, V1, P65, DOI 10.1007/BF00135225; LINDEBERG T, 1990, J VIS COMMUN IMAGE R, V2, P55; Lipschutz M., 1969, DIFFERENTIAL GEOMETR; LOTZE H, 1884, MIKROKOSMOS; ROMENY BMT, 1994, P MATH METHODS MED I, V2, P25; SALDEN AH, 1994, NATO ASI F, V126; SCHWARTZ L, 1950, THEORIE DISTRIBUTION, V2, P1122; SCHWARTZ L, 1950, THEORIE DISTRIBUTION, V1, P1091; Spivak M., 1970, COMPREHENSIVE INTRO, V4; WANG DCC, 1983, COMPUT VISION GRAPH, V24, P363, DOI 10.1016/0734-189X(83)90061-0; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729	32	80	81	0	2	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	APR	1996	18	1					61	75		10.1007/BF00126140	http://dx.doi.org/10.1007/BF00126140			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	UJ409					2022-12-18	WOS:A1996UJ40900004
J	THOMPSON, WB; PONG, TC				THOMPSON, WB; PONG, TC			DETECTING MOVING-OBJECTS	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article									UNIV MINNESOTA,DEPT COMP SCI,MINNEAPOLIS,MN 55455	University of Minnesota System; University of Minnesota Twin Cities								ADIV G, 1985, 3RD P IEEE C COMP VI, P70; [Anonymous], COMMUNICATION; BALLARD DH, 1983, COMPUT VISION GRAPH, V22, P95, DOI 10.1016/0734-189X(83)90097-X; Bandopadhay A., 1986, Proceedings of the Workshop on Motion: Representation and Analysis (Cat. No.86CH2322-6), P23; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; BROOKS RA, 1987, 4TH P INT S ROB RES; BRUSS AR, 1983, COMPUT VISION GRAPH, V21, P3, DOI 10.1016/S0734-189X(83)80026-7; CLOCKSIN WF, 1980, PERCEPTION, V9, P253, DOI 10.1068/p090253; Gibson James J., 1950, PERCEPTION VISUAL WO, P3; Heeger D. J., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P435, DOI 10.1109/CCV.1988.590020; Huang T. S., 1986, Proceedings of the Workshop on Motion: Representation and Analysis (Cat. No.86CH2322-6), P45; JAIN R, 1979, 6TH P INT JOINT C AR, P425; JAIN R, 1977, 5TH P INT JOINT C AR, P425; JAIN RC, 1984, IEEE T PATTERN ANAL, V6, P624, DOI 10.1109/TPAMI.1984.4767575; Marr D., 1982, VISION; NAKAYAMA K, 1974, PERCEPTION, V3, P63, DOI 10.1068/p030063; REIGER JH, 1983, 8TH P INT JOINT C AR, P1027; Thompson W. B., 1986, Proceedings of the Workshop on Motion: Representation and Analysis (Cat. No.86CH2322-6), P15; THOMPSON WB, 1985, IEEE T PATTERN ANAL, V7, P374, DOI 10.1109/TPAMI.1985.4767677; THOMPSON WB, 1980, IEEE T PATTERN ANAL, V2, P543, DOI 10.1109/TPAMI.1980.6447701; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; WAXMAN AM, 1986, P WORKSHOP MOTION RE; ZHANG Z, 1988, 2ND P INT C COMP VIS, P177; 1986, MAY P WORKSH MOT REP	25	80	87	0	2	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	1990	4	1					39	57		10.1007/BF00137442	http://dx.doi.org/10.1007/BF00137442			19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	CU085					2022-12-18	WOS:A1990CU08500002
J	Gupta, M; Agrawal, A; Veeraraghavan, A; Narasimhan, SG				Gupta, Mohit; Agrawal, Amit; Veeraraghavan, Ashok; Narasimhan, Srinivasa G.			A Practical Approach to 3D Scanning in the Presence of Interreflections, Subsurface Scattering and Defocus	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Structured light 3D scanning; Interreflections; Subsurface scattering; Defocus; Global illumination; Indirect illumination; Light transport; Projectors		Global or indirect illumination effects such as interreflections and subsurface scattering severely degrade the performance of structured light-based 3D scanning. In this paper, we analyze the errors in structured light, caused by both long-range (interreflections) and short-range (subsurface scattering) indirect illumination. The errors depend on the frequency of the projected patterns, and the nature of indirect illumination. In particular, we show that long-range effects cause decoding errors for low-frequency patterns, whereas short-range effects affect high-frequency patterns. Based on this analysis, we present a practical 3D scanning system which works in the presence of a broad range of indirect illumination. First, we design binary structured light patterns that are resilient to individual indirect illumination effects using simple logical operations and tools from combinatorial mathematics. Scenes exhibiting multiple phenomena are handled by combining results from a small ensemble of such patterns. This combination also allows detecting any residual errors that are corrected by acquiring a few additional images. Our methods can be readily incorporated into existing scanning systems without significant overhead in terms of capture time or hardware. We show results for several scenes with complex shape and material properties.	[Gupta, Mohit] Columbia Univ, Dept Comp Sci, New York, NY 10027 USA; [Agrawal, Amit] Mitsubishi Elect Res Labs, Cambridge, MA 02139 USA; [Veeraraghavan, Ashok] Rice Univ, Dept Elect & Comp Engn, Houston, TX 77005 USA; [Narasimhan, Srinivasa G.] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA	Columbia University; Rice University; Carnegie Mellon University	Gupta, M (corresponding author), Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.	mohitg@cs.columbia.edu; agrawal@merl.com; vashok@rice.edu; srinivas@cs.cmu.edu			ONR [N00014-11-1-0295]; NSF [IIS-0964562, IIS-1116718, CCF-1117939, CAREER IIS-0643628]; Samsung SAIT GRO grant; Division of Computing and Communication Foundations [1117939] Funding Source: National Science Foundation	ONR(Office of Naval Research); NSF(National Science Foundation (NSF)); Samsung SAIT GRO grant(Samsung); Division of Computing and Communication Foundations(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	We thank Jay Thornton, Joseph Katz, John Barnwell and Haruhisa Okuda (Mitsubishi Electric Japan) for their help and support. Mohit Gupta was partially supported by ONR grant N00014-11-1-0295. Srinivasa Narasimhan was partially supported by NSF grants IIS-0964562 and CAREER IIS-0643628 and a Samsung SAIT GRO grant. Ashok Veeraraghavan was partially supported by NSF Grants IIS-1116718 and CCF-1117939. The authors thank Vincent Chapdelaine-Couture for sharing their data-sets.	Aliaga D. G., 2008, CVPR; Atcheson B, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409085; Caspi D, 1998, IEEE T PATTERN ANAL, V20, P470, DOI 10.1109/34.682177; Chandraker M. K., 2005, CVPR; Chen T., 2008, CVPR, p[1, 2]; Chen Tongbo, 2007, CVPR; Couture V., 2011, ICCV; Er M. C., 1984, IEEE T COMPUTERS, VC-33; Goddyn L., 2003, ELECT J COMBINATORIC; Godin G., 2001, P 5 C OPT 3D MEAS TE; GU J, 2008, ECCV; Gu J., 2011, ICCV; Guhring J, 2001, PROC SPIE, V4309, P220; Gupta M., 2009, CVPR, P2; Gupta M., 2012, CVPR; Gupta M., 2011, CVPR; Gupta M., 2008, CVPR; Hermans C., 2009, CVPR; Holroyd M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778836; Horn E., 1997, P INT C REC ADV 3 D; Ihrke Ivo, 2008, STAR P EUR; Liu S., 2010, ECCV; Minou M., 1981, T IECE JAP, V64; Morris N. J. W., 2007, ICCV; Narasimhan S. G., 2005, ICCV; Nayar S. K., 2006, ACM T GRAPHICS, V25; Nayar S. K., 1991, IJCV, V6; Nehab D, 2005, ACM T GRAPHIC, V24, P536, DOI 10.1145/1073204.1073226; Park J., 2008, IEEE T VISUALIZATION, V14; Park J., 2004, ACCV; POSDAMER JL, 1982, COMPUT VISION GRAPH, V18, P1, DOI 10.1016/0146-664X(82)90096-X; Salvi J., 2010, PATTERN RECOGNITION, V43; Steger E., 2008, INT J COMPUTER VISIO, V76; Trobina Marjan, 1995, TECHNICAL REPORT, P3; Will P. M., 1971, ARTIFICIAL INTELLIGE, V2; Xu Y., 2009, IEEE T VISUALIZATION; Zhang L, 2006, ACM T GRAPHIC, V25, P907, DOI 10.1145/1141911.1141974; Zhang S., 2005, THESIS STONY BROOK U; Zhang S., 2010, OPTICS EXPRESS, V18	39	79	84	2	20	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2013	102	1-3					33	55		10.1007/s11263-012-0554-3	http://dx.doi.org/10.1007/s11263-012-0554-3			23	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	097VO		Green Submitted			2022-12-18	WOS:000315501800004
J	Al-Osaimi, F; Bennamoun, M; Mian, A				Al-Osaimi, F.; Bennamoun, M.; Mian, A.			An Expression Deformation Approach to Non-rigid 3D Face Recognition	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						3D face recognition; Expression invariance; Non-rigid matching		The accuracy of non-rigid 3D face recognition approaches is highly influenced by their capacity to differentiate between the deformations caused by facial expressions from the distinctive geometric attributes that uniquely characterize a 3D face, interpersonal disparities. We present an automatic 3D face recognition approach which can accurately differentiate between expression deformations and interpersonal disparities and hence recognize faces under any facial expression. The patterns of expression deformations are first learnt from training data in PCA eigenvectors. These patterns are then used to morph out the expression deformations. Similarity measures are extracted by matching the morphed 3D faces. PCA is performed in such a way it models only the facial expressions leaving out the interpersonal disparities. The approach was applied on the FRGC v2.0 dataset and superior recognition performance was achieved. The verification rates at 0.001 FAR were 98.35% and 97.73% for scans under neutral and non-neutral expressions, respectively.	[Al-Osaimi, F.; Bennamoun, M.; Mian, A.] Univ Western Australia, Sch Comp Sci & Software Engn, Crawley, WA 6009, Australia	University of Western Australia	Al-Osaimi, F (corresponding author), Univ Western Australia, Sch Comp Sci & Software Engn, 35 Stirling Highway, Crawley, WA 6009, Australia.	faisal@csse.uwa.edu.au; bennamou@csse.uwa.edu.au; ajmal@csse.uwa.edu.au	Bennamoun, Mohammed/C-2789-2013	Bennamoun, Mohammed/0000-0002-6603-3257; Mian, Ajmal/0000-0002-5206-3842	Australian Research Council [DP0664228, DP0881813, LE0775672]	Australian Research Council(Australian Research Council)	Thanks to F. Enezi and S. Harbi for their help in 3D data acquisition. We also thank the FRGC organizers (Phillips et al. 2005). This research is sponsored by the following Australian Research Council grants DP0664228, DP0881813 and LE0775672.	BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Blanz V., 2003, COMPUTER GRAPHICS FO; Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005; BRONSTEIN A, 2006, P EUR C COMP VIS; Bronstein AM, 2006, P NATL ACAD SCI USA, V103, P1168, DOI 10.1073/pnas.0508601103; Bronstein AM, 2005, INT J COMPUT VISION, V64, P5, DOI 10.1007/s11263-005-1085-y; CHANG K, 2005, IEEE C COMP VIS PATT; Chang KI, 2005, IEEE T PATTERN ANAL, V27, P619, DOI 10.1109/TPAMI.2005.70; Chang KI, 2006, IEEE T PATTERN ANAL, V28, P1695, DOI 10.1109/TPAMI.2006.210; CHEN Y, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P2724, DOI 10.1109/ROBOT.1991.132043; CHUA C, 2000, IEEE C AUT FAC GEST; FALTEMIER T, 2007, IEEE C BIOM THEOR AP; GOKBERK B, 2005, INT C AUD BAS BIOM P; GREENSPAN M, 2003, IEEE INT C REC ADV 3; HESHER C, 2003, INT S SIGN PROC ITS; HUSKEN M, 2005, IEEE WORKSH FAC REC; Jollife I. T., 1986, PRINCIPAL COMPONENT; Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; LI X, 2007, IEEE C SHAP MOD APPL; LU X, 2004, P INT C BIOM AUTH; Lu XG, 2006, IEEE T PATTERN ANAL, V28, P31, DOI 10.1109/TPAMI.2006.15; Lu XG, 2008, IEEE T PATTERN ANAL, V30, P1346, DOI 10.1109/TPAMI.2007.70784; MAURER T, 2005, IEEE C COMP VIS PATT; MIAN A, 2006, INT S 3D DAT PROC VI; MIAN A, 2008, INT J COMPUTER VISIO; Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105; PAN G, 2005, IEEE WORKSH FAC REC; PARKE P, 1996, COMPUTER FACIAL ANIM; PASSALIS G, 2005, FRGC WORKSH IEEE C C; Passalis G, 2007, IEEE T PATTERN ANAL, V29, P218, DOI 10.1109/TPAMI.2007.37; Phillips PJ, 2005, PROC CVPR IEEE, P947; RAMACHANDRAN M, 2005, IEEE C AC SPEECH SIG; Russo Michael, 2006, Biotechnol Healthc, V3, P3; RYDFALK M, 1987, LITHISYI866; Samir C, 2006, IEEE T PATTERN ANAL, V28, P1858, DOI 10.1109/TPAMI.2006.235; SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Wang Y, 2007, PROCEEDINGS OF THE SIXTH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS, P3; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342	42	79	87	0	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2009	81	3					302	316		10.1007/s11263-008-0174-0	http://dx.doi.org/10.1007/s11263-008-0174-0			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	394GK		Green Submitted			2022-12-18	WOS:000262433800005
J	Alvarez, L; Deriche, R; Papadopoulo, T				Alvarez, Luis; Deriche, Rachid; Papadopoulo, Theo			Symmetrical dense optical flow estimation with occlusions detection	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						optical flow; PDEs; anisotropic diffusion; occlusion	FIELDS; DIFFUSION; PDE	Traditional techniques of dense optical flow estimation do not generally yield symmetrical solutions: the results will differ if they are applied between images I-1 and I-2 or between images I-2 and I-1. In this work, we present a method to recover a dense optical flow field map from two images, while explicitely taking into account the symmetry across the images as well as possible occlusions in the flow field. The idea is to consider both displacements vectors from I-1 to I-2 and I-2 to I-1 and to minimise an energy functional that explicitely encodes all those properties. This variational problem is then solved using the gradient flow defined by the Euler-Lagrange equations associated to the energy. To prove the importance of the concepts of symmetry and occlusions for optical flow computation, we have extended a classical approach to handle those. Experiments clearly show the added value of these properties to improve the accuracy of the computed flows.	Univ as a,as, Gran Canaria, Spain; INRIA Sophia Antipolis, F-06902 Sophia Antipolis, France		Papadopoulo, T (corresponding author), Univ as a,as, Gran Canaria, Spain.	lalvarez@dis.ulpgc.es; rachid.deriche@sophia.inria.fr; theodore.papadopoulo@sophia.inria.fr	Sánchez, Javier/A-7009-2011; Papadopoulo, Theodore/AAN-1245-2021; Deriche, Rachid/AAM-9869-2021; Alvarez, Luis/A-9190-2009	Sánchez, Javier/0000-0001-8514-4350; Papadopoulo, Theodore/0000-0002-1643-9988; Deriche, Rachid/0000-0002-4643-8417; Alvarez, Luis/0000-0002-6953-9587				Alvarez L, 2002, LECT NOTES COMPUT SC, V2350, P721; Alvarez L, 2002, J VIS COMMUN IMAGE R, V13, P3, DOI 10.1006/jvci.2001.0482; ALVAREZ L, 1992, SIAM J NUMER ANAL, V29, P845, DOI 10.1137/0729052; Alvarez L, 1999, LECT NOTES COMPUT SC, V1682, P235; Alvarez L, 2000, INT J COMPUT VISION, V39, P41, DOI 10.1023/A:1008170101536; Aubert G, 1999, SIAM J APPL MATH, V60, P156, DOI 10.1137/S0036139998340170; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Beg MF, 2005, INT J COMPUT VISION, V61, P139, DOI 10.1023/B:VISI.0000043755.93987.aa; Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148; BROX T, 2004, P 8 EUR C COMP VIS, V4, P25; BROX T, 2002, DAGM S, P446; Cachier P, 2000, LECT NOTES COMPUT SC, V1935, P472; Caselles V, 1998, IEEE T IMAGE PROCESS, V7, P269, DOI 10.1109/TIP.1998.661176; Christensen GE, 1999, LECT NOTES COMPUT SC, V1613, P224; Cohen I., 1993, Proceedings of the 8th Scandinavian Conference on Image Analysis, P523; Deriche R., 1995, P 2 AS C COMP VIS SI, V2, P71; ENKELMANN W, 1988, COMPUT VISION GRAPH, V43, P150, DOI 10.1016/0734-189X(88)90059-X; FAUGERAS O, 1993, CR HEBD ACAD SCI, V1, P565; Ghosal S, 1996, IEEE T PATTERN ANAL, V18, P181, DOI 10.1109/34.481542; Guichard F, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL I, P497, DOI 10.1109/ICIP.1996.559542; HEITZ F, 1993, IEEE T PATTERN ANAL, V15, P1217, DOI 10.1109/34.250841; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; McCane B, 2001, COMPUT VIS IMAGE UND, V84, P126, DOI 10.1006/cviu.2001.0930; MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126; MEMIN E, 1995, P INT SOC OPTICAL EN, P30; NAGEL H, 1983, INT JOINT C ART INT, P156; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; NAGEL HH, 1987, ARTIF INTELL, V33, P299, DOI 10.1016/0004-3702(87)90041-5; NESI P, 1993, IMAGE VISION COMPUT, V11, P419, DOI 10.1016/0262-8856(93)90046-J; NIELSEN M, 2002, MED IMAGE COMPUTING, V2488; Otte M., 1994, Computer Vision - ECCV'94. Third European Conference on Computer Vision. Proceedings. Vol.I, P51; PROESMANS M, 1994, P 3 EUR C COMP VIS, V2, P295; Sapiro G., 2001, GEOMETRIC PARTIAL DI; SCHNORR C, 1991, INT J COMPUT VISION, V6, P25, DOI 10.1007/BF00127124; SNYDER M, 1995, IEEE T PATTERN ANAL, V13, P1105; Strecha C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1194; Szeliski R, 2002, LECT NOTES COMPUT SC, V2351, P525; TROUVE A, 2000, P 6 EUR C COMP VIS T, P573; Weickert J, 2001, INT J COMPUT VISION, V45, P245, DOI 10.1023/A:1013614317973; Weickert J., 1996, THESIS U KAISERSLAUT; WEICKERT J, 1996, COMP SUPPL, V11, P221; WEICKERT J, 1998, P COMP VIS MOB ROB W, P115; ZHANG Z, 1996, 2927 INRIA	43	79	84	0	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	2007	75	3					371	385		10.1007/s11263-007-0041-4	http://dx.doi.org/10.1007/s11263-007-0041-4			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	211QS					2022-12-18	WOS:000249539000004
J	Vishwanathan, SVN; Smola, AJ; Vidal, R				Vishwanathan, S. V. N.; Smola, Alexander J.; Vidal, Rene			Binet-cauchy kernels on dynamical systems and its application to the analysis of dynamic scenes	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Binet-Cauchy theorem; ARMA models and dynamical systems; Sylvester equation; kernel methods; reproducing kernel Hilbert spaces; dynamic scenes; dynamic textures	LINEAR-SYSTEM; TIME-SERIES	We propose a family of kernels based on the Binet-Cauchy theorem, and its extension to Fredholm operators. Our derivation provides a unifying framework for all kernels on dynamical systems currently used in machine learning, including kernels derived from the behavioral framework, diffusion processes, marginalized kernels, kernels on graphs, and the kernels on sets arising from the subspace angle approach. In the case of linear time-invariant systems, we derive explicit formulae for Computing the proposed Binet-Cauchy kernels by solving Sylvester equations, and relate the proposed kernels to existing kernels based on cepstrum coefficients and subspace angles. We show efficient methods for computing Our kernels which make them viable for the practitioner. Besides their theoretical appeal, these kernels can be used efficiently in the comparison of video sequences of dynamic scenes that can be modeled as the output of a linear time-invariant dynamical system. One advantage of our kernels is that they take the initial conditions of the dynamical systems into account. As a first example, we use our kernels to compare video sequences of dynamic textures. As a second example, we apply our kernels to the problem of clustering short clips of a movie. Experimental evidence shows superior performance of our kernels.	Natl ICT Australia, Stat Machine Learning Program, Canberra, ACT 0200, Australia; Johns Hopkins Univ, Dept Biomed Engn, Ctr Imaging Sci, Baltimore, MD 21218 USA	NICTA; Johns Hopkins University	Vishwanathan, SVN (corresponding author), Natl ICT Australia, Stat Machine Learning Program, Canberra, ACT 0200, Australia.	SVN.Vishwanathan@nicta.com.au; Alex.Smola@nicta.com.au; rvidal@cis.jhu.edu	Vidal, Rene/A-3367-2010					Aggarwal G, 2004, INT C PATT RECOG, P175, DOI 10.1109/ICPR.2004.1333732; AITKEN AC, 1946, DETERMINANTS MATRICE; BACH FR, 2002, J MACHINE LEARNING R, V3, P1; BAKIR G, 2003, ADV NEURAL INFORM PR, V16; Barla A, 2002, LECT NOTES COMPUT SC, V2353, P20; BAXTER J, 1999, DIRECT GRADIENT BASE; BERNSTEIN D. S., 2005, MATRIX MATH; BLANZ V, 1996, LNCS, V1112, P251; BURGES CJC, 1995, NEW METHOD CONSTRUCT; BURKHARDT H, 2004, INVARIANTS SKELETONS; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646; Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482; CORTES C, 2002, ADV NEURAL INFORM PR, V14; Cristianini Nello, 2000, INTRO SUPPORT VECTOR, DOI DOI 10.1017/CBO9780511801389; De Cock K, 2002, SYST CONTROL LETT, V46, P265, DOI 10.1016/S0167-6911(02)00135-4; de Finetti B., 1990, THEORY PROBABILITY, V1; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; GARDINER JD, 1992, ACM T MATH SOFTWARE, V18, P223, DOI 10.1145/146847.146929; Gartner T, 2003, LECT NOTES ARTIF INT, V2777, P129, DOI 10.1007/978-3-540-45167-9_11; Golub G. H., 2012, MATRIX COMPUTATIONS; GRETTON A, 2003, P ICASSP; GROBNER W, 1965, MATRIZENRECHNUNG; Heisele B, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P688, DOI 10.1109/ICCV.2001.937693; Herbrich R., 2002, LEARNING KERNEL CLAS; Isidori A., 1989, NONLINEAR CONTROL SY; Joachims T., 1998, P EUROPEAN C MACHINE, P137, DOI [10.1007/bfb0026683, 10.1007/BFb0026683]; KASHIMA H, 2004, KERNELS BIOINFORMATI; Kashima Hisashi, 2003, P 20 INT C MACH LEAR, P321; Kondor I.R., 2002, INT C MACHINE LEARNI; Luenberger D. G., 1979, INTRO DYNAMIC SYSTEM; Martin RJ, 2000, IEEE T SIGNAL PROCES, V48, P1164, DOI 10.1109/78.827549; Nocedal J., 2006, NUMERICAL OPTIMIZATI; PINKUS A, 1996, TOTAL POSTITIVITY IT, P1; Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185; RALAIVOLA L, 2003, ADV NEURAL INFORM PR, V16; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Saisan P, 2001, PROC CVPR IEEE, P58; Scholkopf B., 2002, LEARNING KERNELS; Scholkopf Bernhard, 1997, SUPPORT VECTOR LEARN; SHASHUA A, 2005, ADV NEURAL INFORM PR, V17, P1257; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Smola AJ, 2003, LECT NOTES ARTIF INT, V2777, P144, DOI 10.1007/978-3-540-45167-9_12; SMOLA AJ, 2003, P 13 IFAC S SYST ID; Soatto S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P439, DOI 10.1109/ICCV.2001.937658; Sutton RS, 2018, ADAPT COMPUT MACH LE, P1; Vapnik VN, 1998, STAT LEARNING THEORY, DOI DOI 10.1007/978-1-4419-1428-6_5864; VIDAL R, 2005, IN PRESS IEEE T PATT; VISHWANATHAN SVN, 2003, P 20 INT C MACH LEAR; VISHWANATHAN SVN, 2006, UNPUB INT C MACH LEA; VISHWANATHAN SVN, 2002, THESIS INDIAN I SCI; WILLEMS JC, 1987, AUTOMATICA, V23, P87, DOI 10.1016/0005-1098(87)90120-8; WILLEMS JC, 1986, AUTOMATICA, V22, P675, DOI 10.1016/0005-1098(86)90005-1; WOLF L, 2003, J MACHINE LEARNING R, V4, P913	55	79	84	0	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2007	73	1					95	119		10.1007/s11263-006-9352-0	http://dx.doi.org/10.1007/s11263-006-9352-0			25	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	141YV		Green Submitted			2022-12-18	WOS:000244616100005
J	Ortner, M; Descombes, X; Zerubia, J				Ortner, Mathias; Descombes, Xavier; Zerubia, Josiane			Building outline extraction from digital elevation models using marked point processes	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						image processing; inhomogeneous Poisson point process; stochastic geometry; dense urban area; digital elevation models; laser data; land register; building detection; MCMC; RJMCMC; simulated annealing	IMAGES	`This work presents an automatic algorithm for extracting vectorial land registers from altimetric data in dense urban areas. We focus on elementary shape extraction and propose a method that extracts rectangular buildings. The result is a vectorial land register that can be used, for instance, to perform precise roof shape estimation. Using a spatial point process framework, we model towns as configurations of and unknown number of rectangles. An energy is defined, which takes into account both low level information provided by the altimetry of the scene, and geometric knowledge about the disposition of buildings in towns. Estimation is done by minimizing the energy using simulated annealing. We use an MCMC sampler that is a combination of general Metropolis Hastings Green techniques and the Geyer and Moller algorithm for point process sampling. We define some original proposition kernels. such as birth or death in a neighborhood and define the energy with respect to an inhomogeneous Poisson point process. We present results on real data provided by the IGN (French National Geographic Institute). Results were obtained automatically. These results consist of configurations of rectangles describing a dense urban area.	UNSA, CNRS, INRIA, Ariana Joint Res Grp, Sophia Antipolis, France	Centre National de la Recherche Scientifique (CNRS); Inria; UDICE-French Research Universities; Universite Cote d'Azur	Ortner, M (corresponding author), UNSA, CNRS, INRIA, Ariana Joint Res Grp, 2004 Route Lucioles,BP 93, Sophia Antipolis, France.	mathias.ortner@sophia.inria.fr						BADDELEY A, 1993, STAT IMAGES, V1, P233; BANORFFNIELSEN OE, 1999, STOCHASTIC GEOMETRY; Fischer A, 1998, COMPUT VIS IMAGE UND, V72, P185, DOI 10.1006/cviu.1998.0721; FRADKIN M, 1999, ISPRS C AUT EXTR GIS; FRADKIN M, 1999, IEEE C COMP VIS PATT, V1, P262; FRUEH C, 2003, IEEE COMPUTER GRAPHI; FUCHS F, 2001, THEIS U RENE DESCART; GEYER CJ, 1994, SCAND J STAT, V21, P359; GREEN PJ, 1995, BIOMETRIKA, V57, P97; JIBRINI H, 2002, THESIS ENST PARIS FR; LACOSTE C, 2002, 4516 INRIA; Maas HG, 1999, ISPRS J PHOTOGRAMM, V54, P153, DOI 10.1016/S0924-2716(99)00004-0; Mayer H, 1999, COMPUT VIS IMAGE UND, V74, P138, DOI 10.1006/cviu.1999.0750; ORTNER M, 2003, 4900 INRIA; ORTNER M, 2003, ICASSP, V3; ORTNER M, 2003, 4919 INRIA; Pievatolo A, 1998, J ROY STAT SOC B, V60, P609, DOI 10.1111/1467-9868.00143; Rue H, 1998, ADV APPL PROBAB, V30, P64, DOI 10.1017/S0001867800008089; Rue H, 1999, BIOMETRIKA, V86, P649, DOI 10.1093/biomet/86.3.649; SRIVASTAVA A, 1999, J STAT PLANNING INFE; Stassopoulou A, 2000, INT J PATTERN RECOGN, V14, P715, DOI 10.1142/S0218001400000477; Stoica R, 2004, INT J COMPUT VISION, V57, P121, DOI 10.1023/B:VISI.0000013086.45688.5d; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; van Lieshout, 2000, MARKOV POINT PROCESS; van Lieshout, 1999, STOCHASTIC GEOMETRY; van Lieshout M., 1993, BSR9306 CWI; VESTRI C, 2001, CVPR; VINSON S, 2002, P ICPR INT C PATT RE; VINSON S, 2001, SCIA; WEIDNER U, 1995, BUILDING EXTRATION D; Winkler G., 2003, IMAGE ANAL RANDOM FI	31	79	83	0	12	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	APR	2007	72	2					107	132		10.1007/s11263-005-5033-7	http://dx.doi.org/10.1007/s11263-005-5033-7			26	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	127XW					2022-12-18	WOS:000243620700001
J	Rochery, M; Jermyn, IH; Zerubia, J				Rochery, Marie; Jermyn, Ian H.; Zerubia, Josiane			Higher order active contours	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	2nd IEEE Workshop on Variational, Geometric and Level Set Methods held in Conjunction with the IEEE International Conference on Computer Vision	OCT, 2003	Nice, FRANCE	IEEE, French Natl Inst Res Comp Sci & Control, Siemens Corp Res, Imaging & Visualizat Dept		active contour; shape prior; geometric; higher-order; polynomial; quadratic; road network; remote sensing	AERIAL IMAGES; ROADS; REGIONS; EXTRACTION; MODEL	We introduce a new class of active contour models that hold great promise for region and shape modelling, and we apply a special case of these models to the extraction of road networks from satellite and aerial imagery. The new models are arbitrary polynomial functionals oil the space of boundaries, and thus greatly generalize the linear functionals used in classical contour energies. While classical energies are expressed as single integrals over the contour, the new energies incorporate multiple integrals. and thus describe long-range interactions between different sets of contour points. As prior terms, they describe families of contours that share complex geometric properties, without making reference to any particular shape. and they require no pose estimation. As likelihood terms, they can describe multi-point interactions between the contour and the data. To optimize the energies, we use a level set approach. The forces derived from the new energies are non-local however. thus necessitating an extension of standard level set methods. Networks are a shape family of great importance in a number of applications, including remote sensing imagery. To model them. we make a particular choice of prior quadratic energy that describes reticulated structures. and augment it with a likelihood term that couples the data at pairs of contour points to their joint geometry. Promising experimental results are shown on real images.	INRIA, Ariana Joint Res Grp, I3S, F-06902 Sophia Antipolis, France	Inria	Rochery, M (corresponding author), INRIA, Ariana Joint Res Grp, I3S, BP 93, F-06902 Sophia Antipolis, France.	marie.rochery@inria.fr; ian.jermyn@inria.fr; josiane.zerubia@inria.fr		Zerubia, Josiane/0000-0002-7444-0856				Adalsteinsson D, 1999, J COMPUT PHYS, V148, P2, DOI 10.1006/jcph.1998.6090; Barzohar M, 1996, IEEE T PATTERN ANAL, V18, P707, DOI 10.1109/34.506793; Bossavit A., 2002, APPL DIFFERENTIAL GE; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Chen YM, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P145, DOI 10.1109/VLSM.2001.938893; Cohen-Smith D, 1999, Nicotine Tob Res, V1, P211, DOI 10.1080/14622299050011321; Cremers D, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P137, DOI 10.1109/VLSM.2001.938892; FISCHLER MA, 1981, COMPUT VISION GRAPH, V15, P201, DOI 10.1016/0146-664X(81)90056-3; Foulonneau A, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P413; Fua P., 1990, Machine Vision and Applications, V3, P45, DOI 10.1007/BF01211451; Geman D, 1996, IEEE T PATTERN ANAL, V18, P1, DOI 10.1109/34.476006; Jehan-Besson S, 2003, INT J COMPUT VISION, V53, P45, DOI 10.1023/A:1023031708305; Jermyn IH, 2001, IEEE T PATTERN ANAL, V23, P1075, DOI 10.1109/34.954599; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855; Kimmel R, 2003, INT J COMPUT VISION, V53, P225, DOI 10.1023/A:1023030907417; LACOSTE C, 2002, 4516 INRIA; Laptev I, 2000, MACH VISION APPL, V12, P23, DOI 10.1007/s001380050121; LEVENTON ME, 2000, PROC CVPR IEEE, P316, DOI DOI 10.1109/CVPR.2000.855835; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; Mehrang Saeed, IEEE T GEOSCI REMOTE, V20, P7957, DOI [10.1109/JSEN.2020.2981334, DOI 10.1109/TGRS.2018.2872081]; Merlet N, 1996, IEEE T PATTERN ANAL, V18, P426, DOI 10.1109/34.491623; Neuenschwander WM, 1997, INT J COMPUT VISION, V25, P191, DOI 10.1023/A:1007924018415; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Paragios N, 2002, J VIS COMMUN IMAGE R, V13, P249, DOI 10.1006/jvci.2001.0475; ROCHERY M, 2003, P IEEE WORKSH VLSM I; Rousson M, 2002, LECT NOTES COMPUT SC, V2351, P78; Sethian J. A., 1999, LEVEL SET METHODS FA; SETHIAN JA, 1996, SIAM REV, V412, P199; Siddiqi K, 1997, GRAPH MODEL IM PROC, V59, P278, DOI 10.1006/gmip.1997.0438; Steiner A, 1998, GRAPH MODEL IM PROC, V60, P112, DOI 10.1006/gmip.1998.0461; Stoica R, 2004, INT J COMPUT VISION, V57, P121, DOI 10.1023/B:VISI.0000013086.45688.5d; SUSSMAN M, 1994, J COMPUT PHYS, V114, P146, DOI 10.1006/jcph.1994.1155; Sussman M, 1999, SIAM J SCI COMPUT, V20, P1165, DOI 10.1137/S1064827596298245; Tupin F, 1998, IEEE T GEOSCI REMOTE, V36, P434, DOI 10.1109/36.662728; Vasilevskiy A, 2002, IEEE T PATTERN ANAL, V24, P1565, DOI 10.1109/TPAMI.2002.1114849	38	79	82	0	14	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2006	69	1					27	42		10.1007/s11263-006-6851-y	http://dx.doi.org/10.1007/s11263-006-6851-y			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	063QH		Green Accepted, Green Submitted			2022-12-18	WOS:000239034100003
J	Li, ZC; Tang, JH; Zhang, LY; Yang, J				Li, Zechao; Tang, Jinhui; Zhang, Liyan; Yang, Jian			Weakly-supervised Semantic Guided Hashing for Social Image Retrieval	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Hashing; Image retrieval; Matrix factorization; Social image; Discrete code	QUANTIZATION	Hashing has been widely investigated for large-scale image retrieval due to its search effectiveness and computation efficiency. In this work, we propose a novel Semantic Guided Hashing method coupled with binary matrix factorization to perform more effective nearest neighbor image search by simultaneously exploring the weakly-supervised rich community-contributed information and the underlying data structures. To uncover the underlying semantic information from the weakly-supervised user-provided tags, the binary matrix factorization model is leveraged for learning the binary features of images while the problem of imperfect tags is well addressed. The uncovered semantic information enables to well guide the discrete hash code learning. The underlying data structures are discovered by adaptively learning a discriminative data graph, which makes the learned hash codes preserve the meaningful neighbors. To the best of our knowledge, the proposed method is the first work that incorporates the hash code learning, the semantic information mining and the data structure discovering into one unified framework. Besides, the proposed method is extended to one deep approach for the optimal compatibility of discriminative feature learning and hash code learning. Experiments are conducted on two widely-used social image datasets and the proposed method achieves encouraging performance compared with the state-of-the-art hashing methods.	[Li, Zechao; Tang, Jinhui; Yang, Jian] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing, Peoples R China; [Zhang, Liyan] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing, Peoples R China	Nanjing University of Science & Technology; Nanjing University of Aeronautics & Astronautics	Tang, JH (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing, Peoples R China.	zechao.li@njust.edu.cn; jinhuitang@njust.edu.cn; zhangliyan@nuaa.edu.cn; csjyang@njust.edu.cn		Tang, Jinhui/0000-0001-9008-222X	National Key R&D Program of China [2018AAA0102002]; National Natural Science Foundation of China [61772275, 61732007, 61772268, 61672285]; Natural Science Foundation of Jiangsu Province [BK20170033]	National Key R&D Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Jiangsu Province(Natural Science Foundation of Jiangsu Province)	This work was partially supported by the National Key R&D Program of China under Grant 2018AAA0102002, the National Natural Science Foundation of China (Grant No. 61772275, 61732007, 61772268 and 61672285) and the Natural Science Foundation of Jiangsu Province (Grant BK20170033).	Cao Y, 2018, PROC CVPR IEEE, P1229, DOI 10.1109/CVPR.2018.00134; Cao ZJ, 2017, IEEE I CONF COMP VIS, P5609, DOI 10.1109/ICCV.2017.598; Dizaji KG, 2018, PROC CVPR IEEE, P3664, DOI 10.1109/CVPR.2018.00386; Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4; Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193; Gordo A, 2017, INT J COMPUT VISION, V124, P237, DOI 10.1007/s11263-017-1016-8; Guan ZY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3776; Gui J, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1485, DOI 10.1145/3219819.3219955; Gui J, 2018, IEEE T PATTERN ANAL, V40, P490, DOI 10.1109/TPAMI.2017.2678475; Heo JP, 2015, IEEE T PATTERN ANAL, V37, P2304, DOI 10.1109/TPAMI.2015.2408363; Heo JP, 2012, PROC CVPR IEEE, P2957, DOI 10.1109/CVPR.2012.6248024; Hu HF, 2019, IEEE T IMAGE PROCESS, V28, P739, DOI 10.1109/TIP.2018.2860898; Huiskes Mark J, 2008, P 1 ACM INT C MULTIM, P39, DOI DOI 10.1145/1460096.1460104; Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876; Ji Jianqiu, 2012, ADV NEURAL INFORM PR, P108; Jiang QY, 2018, AAAI CONF ARTIF INTE, P3342; Jiang QY, 2018, IEEE T IMAGE PROCESS, V27, P5996, DOI 10.1109/TIP.2018.2864894; Jin L, 2019, IEEE T IMAGE PROCESS, V28, P2173, DOI 10.1109/TIP.2018.2883522; Jin L, 2019, IEEE T NEUR NET LEAR, V30, P1429, DOI 10.1109/TNNLS.2018.2869601; Kan MN, 2014, IEEE T CIRC SYST VID, V24, P704, DOI 10.1109/TCSVT.2013.2276713; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466; Kulis Brian, 2009, ADV NEURAL INFORM PR, P1042; Li Q, 2017, ADV NEUR IN, V30; Li W., 2016, INT JOINT C ARTIFICI, P1711; Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750; Li ZC, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2624140; Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035; Lin K, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301269; Liong VE, 2017, IEEE I CONF COMP VIS, P4097, DOI 10.1109/ICCV.2017.439; Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862; Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227; LIU W, 2011, P INT C MACH LEARN, P1, DOI DOI 10.1109/MMSP.2011.6093823; Liu XL, 2017, IEEE T IMAGE PROCESS, V26, P5324, DOI 10.1109/TIP.2017.2729896; Liu XL, 2017, IEEE T IMAGE PROCESS, V26, P5367, DOI 10.1109/TIP.2017.2695895; Liu XL, 2016, IEEE T IMAGE PROCESS, V25, P907, DOI 10.1109/TIP.2015.2505180; Mandal D, 2019, IEEE T IMAGE PROCESS, V28, P102, DOI 10.1109/TIP.2018.2863040; Raginsky M., 2009, ADV NEURAL INFORM PR, P1509, DOI [10.5555/2984093.2984263, DOI 10.5555/2984093.2984263]; Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598; Shen FM, 2013, PROC CVPR IEEE, P1562, DOI 10.1109/CVPR.2013.205; Sohn S, 2017, IEEE T IMAGE PROCESS, V26, P3759, DOI 10.1109/TIP.2017.2695099; Tang JH, 2019, IEEE T PATTERN ANAL, V41, P2027, DOI 10.1109/TPAMI.2019.2906603; Tang JH, 2018, IEEE T NEUR NET LEAR, V29, P6154, DOI 10.1109/TNNLS.2018.2816743; Tang JH, 2018, IEEE T CIRC SYST VID, V28, P2730, DOI 10.1109/TCSVT.2017.2715227; Tang JH, 2018, PATTERN RECOGN, V75, P25, DOI 10.1016/j.patcog.2017.03.028; Tang JH, 2017, IEEE T PATTERN ANAL, V39, P1662, DOI 10.1109/TPAMI.2016.2608882; Tang JH, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2998574; Tang JH, 2015, IEEE T IMAGE PROCESS, V24, P2827, DOI 10.1109/TIP.2015.2421443; Venkateswara H, 2017, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2017.572; Wang DX, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2291; Wang J, 2017, IEEE INFOCOM SER, DOI 10.1007/s12083-017-0556-6; Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48; Weiss P, 2008, INT CONF ACOUST SPEE, P1173, DOI 10.1109/ICASSP.2008.4517824; Wu F, 2014, IEEE T MULTIMEDIA, V16, P427, DOI 10.1109/TMM.2013.2291214; Xia RK, 2014, AAAI CONF ARTIF INTE, P2156; Zhai DM, 2018, IEEE T MULTIMEDIA, V20, P675, DOI 10.1109/TMM.2017.2749160; Zhang D, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P18; Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177; Zhang HF, 2018, IEEE T IMAGE PROCESS, V27, P1626, DOI 10.1109/TIP.2017.2781422; Zhang ZG, 2007, IEEE DATA MINING, P391, DOI 10.1109/ICDM.2007.99; Zhang ZM, 2016, PROC CVPR IEEE, P1487, DOI 10.1109/CVPR.2016.165; Zhu H, 2016, AAAI CONF ARTIF INTE, P2415; Zhu X., 2013, P 21 ACM INT C MULTI, P143, DOI [10.1145/2502081.2502107, DOI 10.1145/2502081.2502107]; ZHUANG Y, 2011, P ACM MULT, P1457, DOI DOI 10.1145/2072298.2072039	64	78	84	1	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2020	128	8-9			SI		2265	2278		10.1007/s11263-020-01331-0	http://dx.doi.org/10.1007/s11263-020-01331-0		MAY 2020	14	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	MZ8HG					2022-12-18	WOS:000532078000001
J	Zhou, BL; Tang, XO; Wang, XG				Zhou, Bolei; Tang, Xiaoou; Wang, Xiaogang			Learning Collective Crowd Behaviors with Dynamic Pedestrian-Agents	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Crowd behavior analysis; Video surveillance; Motion analysis	VIDEO; SURVEILLANCE; PATTERN	Collective behaviors characterize the intrinsic dynamics of the crowds. Automatically understanding collective crowd behaviors has important applications to video surveillance, traffic management and crowd control, while it is closely related to scientific fields such as statistical physics and biology. In this paper, a new mixture model of dynamic pedestrian-Agents (MDA) is proposed to learn the collective behavior patterns of pedestrians in crowded scenes from video sequences. From agent-based modeling, each pedestrian in the crowd is driven by a dynamic pedestrian-agent, which is a linear dynamic system with initial and termination states reflecting the pedestrian's belief of the starting point and the destination. The whole crowd is then modeled as a mixture of dynamic pedestrian-agents. Once the model parameters are learned from the trajectories extracted from videos, MDA can simulate the crowd behaviors. It can also infer the past behaviors and predict the future behaviors of pedestrians given their partially observed trajectories, and classify them different pedestrian behaviors. The effectiveness of MDA and its applications are demonstrated by qualitative and quantitative experiments on various video surveillance sequences.	[Zhou, Bolei] MIT, Dept Elect Engn & Comp Sci, Cambridge, MA 02139 USA; [Tang, Xiaoou] Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China; [Wang, Xiaogang] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China	Massachusetts Institute of Technology (MIT); Chinese University of Hong Kong; Chinese University of Hong Kong	Zhou, BL (corresponding author), MIT, Dept Elect Engn & Comp Sci, Cambridge, MA 02139 USA.	bolei@mit.edu; xtang@ie.cuhk.edu.hk; xgwang@ee.cuhk.edu.hk			General Research Fund - Research Grants Council of Hong Kong [CUHK417110, CUHK417011, CUHK 429412]	General Research Fund - Research Grants Council of Hong Kong(Hong Kong Research Grants Council)	This work is partially supported by the General Research Fund sponsored by the Research Grants Council of Hong Kong (Project No. CUHK417110, CUHK417011, and CUHK 429412).	Ali S., 2007, P CVPR; Ali S, 2008, P ECCV; [Anonymous], 1897, CROWD STUDY POPULAR; Antonini G, 2006, INT J COMPUT VISION, V69, P159, DOI 10.1007/s11263-005-4797-0; Ball P., 2004, CRITICAL MASS ONE TH; Berg J., 2008, P IEEE INT C ROB AUT; Bolei Zhou, 2012, P CVPR; Bonabeau E, 2002, P NATL ACAD SCI USA, V99, P7280, DOI 10.1073/pnas.082080899; Chan AB, 2008, IEEE T PATTERN ANAL, V30, P909, DOI 10.1109/TPAMI.2007.70738; Chang M.-C., 2011, P ICCV; Choi W., 2011, P CVPR; Couzin ID, 2009, TRENDS COGN SCI, V13, P36, DOI 10.1016/j.tics.2008.10.002; Couzin ID, 2002, J THEOR BIOL, V218, P1, DOI 10.1006/jtbi.2002.3065; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; Emonet R., 2011, P CVPR; Forsyth D.R., 2009, GROUP DYNAMICS; Ge WN, 2012, IEEE T PATTERN ANAL, V34, P1003, DOI 10.1109/TPAMI.2011.176; Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023; HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282; Hospedales T., 2009, P ICCV; Hospedales TM, 2011, IEEE T PATTERN ANAL, V33, P2451, DOI 10.1109/TPAMI.2011.81; Hu WM, 2007, IEEE T IMAGE PROCESS, V16, P1168, DOI 10.1109/TIP.2006.891352; Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274; Hughes RL, 2003, ANNU REV FLUID MECH, V35, P169, DOI 10.1146/annurev.fluid.35.101101.161136; KAUCIC R, 2005, P CVPR; Kim K., 2011, P ICCV; Kingman J. F. C., 1993, POISSON PROCESSES; Kratz L, 2009, P CVPR; Kuettel D., 2010, P CVPR; Lan T., 2012, P CVPR; Lan T, 2012, IEEE T PATTERN ANAL, V34, P1549, DOI 10.1109/TPAMI.2011.228; Li J, 2008, P ECCV; Lin D., 2010, P CVPR; Lin D., 2009, P CVPR; Loy CC, 2009, P CVPR; Mahadevan V, 2010, P CVPR; Makris D, 2005, IEEE T SYST MAN CY B, V35, P397, DOI 10.1109/TSMCB.2005.846652; Mehran R., 2009, P CVPR; Mehran Ramin, 2010, P ECCV; Moberts B., 2005, P IEEE VIS; Morris BT, 2008, IEEE T CIRC SYST VID, V18, P1114, DOI 10.1109/TCSVT.2008.927109; Morris BT, 2011, IEEE T PATTERN ANAL, V33, P2287, DOI 10.1109/TPAMI.2011.64; Moussaid M, 2011, P NATL ACAD SCI USA, V108, P6884, DOI 10.1073/pnas.1016507108; Moussaid M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010047; Moussaid M, 2009, TOP COGN SCI, V1, P469, DOI 10.1111/j.1756-8765.2009.01028.x; Oh S. M., 2005, P ICCV; Palma W, 2007, LONG MEMORY TIME SER; Parrish JK, 1999, SCIENCE, V284, P99, DOI 10.1126/science.284.5411.99; Patil S, 2011, IEEE T VIS COMPUT GR, V17, P244, DOI 10.1109/TVCG.2010.33; Pavlovic V., 1999, P CVPR; Pellegrini S., 2009, P ICCV; Pellegrini S., 2010, P ECCV; RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239; Rodriguez M., 2009, P ICCV; Rodriguez M, 2011, P ICCV; Saleemi I., 2010, P CVPR; Saligrama V., 2012, P CVPR; Schneider P. J., 2003, GEOMETRIC TOOLS COMP, DOI [10.1016/B978-1-55860-594-7.X5000-0, DOI 10.1016/B978-1-55860-594-7.X5000-0]; Scovanner P., 2009, P ICCV; Shumway R. H., 1982, Journal of Time Series Analysis, V3, P253, DOI 10.1111/j.1467-9892.1982.tb00349.x; Stauffer C., 2003, P CVPR WORKSH; Tomasi C., 1991, INT J COMPUTER VISIO; Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008; Van den Berg J., 2008, P ICRA; VICSEK T, 1995, PHYS REV LETT, V75, P1226, DOI 10.1103/PhysRevLett.75.1226; Wang M., 2011, P CVPR; Wang X., 2006, P ECCV; WANG X, 2008, P CVPR; Wang XG, 2011, INT J COMPUT VISION, V95, P287, DOI 10.1007/s11263-011-0459-6; Wang XG, 2009, IEEE T PATTERN ANAL, V31, P539, DOI 10.1109/TPAMI.2008.87; Wu S, 2010, P CVPR; Yamaguchi K., 2011, P CVPR; Yang Y., 2009, P ICCV; Zen G., 2011, P ICCV; Zhao X., 2011, P ICCV; Zhou B., 2012, P ECCV; Zhou B, 2011, P CVPR; Zhou B, 2013, P CVPR; Zhou B., 2014, IEEE T PAMI; Zhou SP, 2010, ACM T MODEL COMPUT S, V20, DOI 10.1145/1842722.1842725	80	78	83	1	40	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2015	111	1					50	68		10.1007/s11263-014-0735-3	http://dx.doi.org/10.1007/s11263-014-0735-3			19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AZ6RC		Green Submitted			2022-12-18	WOS:000348345400004
J	Yezzi, AJ; Soatto, S				Yezzi, AJ; Soatto, S			Deformotion: Deforming motion, shape average and the joint registration and approximation of structures in images	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						shape; segmentation; motion; registration	LEVEL SETS; TRACKING	What does it mean for a deforming object to be "moving"? How can we separate the overall motion ( a finite-dimensional group action) from the more general deformation ( a diffeomorphism)? In this paper we propose a definition of motion for a deforming object and introduce a notion of "shape average" as the entity that separates the motion from the deformation. Our definition allows us to derive novel and efficient algorithms to register nonidentical shapes using region-based methods, and to simultaneously approximate and align structures in greyscale images. We also extend the notion of shape average to that of a "moving average" in order to track moving and deforming objects through time. The algorithms we propose extend prior work on landmark-based matching to smooth curves, and involve the numerical integration of partial differential equations, which we address within the framework of level set methods.	Georgia Inst Technol, Atlanta, GA 30332 USA; Univ Calif Los Angeles, Los Angeles, CA 90095 USA	University System of Georgia; Georgia Institute of Technology; University of California System; University of California Los Angeles	Yezzi, AJ (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.	ayezzi@ece.gatech.edu; soatto@ucla.edu	Yezzi, Anthony/AAB-4235-2020					Alvarez L, 1999, LECT NOTES COMPUT SC, V1682, P235; ALVAREZ L, 1993, ARCH RATIONAL MECH, V123; ALVAREZ L, 1994, GEOMETRIC DRIVEN DIF; Arnold VI., 1989, MATH METHODS CLASSIC, V2, DOI [10.1007/978-1-4757-1693-1, 10.1007/978-1-4757-2063-1, DOI 10.1007/978-1-4757-2063-1]; AZENCOTT R, 1996, P 13 INT C PATT REC, V1, P687; BELONGIE S., 2001, P IEEE INT C COMP VI; BEREZIAT D, 1997, P SPIE; Blake A., 1998, ACTIVE CONTOURS, DOI [10.1007/978-1-4471-1555-7, DOI 10.1007/978-1-4471-1555-7]; CARNE TK, 1990, P LOND MATH SOC, V61, P407; Chui HL, 2000, PROC CVPR IEEE, P44, DOI 10.1109/CVPR.2000.854733; DAVIES R, 2001, 17 C INF PROC MED IM, P50; DUTTA N, 2001, UNPUB MMBIA; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Giblin P. J., 1977, GRAPHS SURFACES HOMO; GRENANDER U, 1994, J R STAT SOC B, V56, P549; Grenander U., 1993, GEN PATTERN THEORY; Jackway PT, 1996, IEEE T PATTERN ANAL, V18, P38, DOI 10.1109/34.476009; KENDALL DG, 1984, B LONDON MATH SOC, V16; KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741; KIMMEL R, 1995, COMPUT VIS IMAGE UND, V62, P47, DOI 10.1006/cviu.1995.1040; Kimmel R, 1998, IEEE T ROBOTIC AUTOM, V14, P427, DOI 10.1109/70.678452; KIMMEL R, 1997, LECT NOTES COMPUTER; Koenderink J., 1990, SOLID SHAPE; LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173; LE HL, 1993, ANN STAT, V21, P1225, DOI 10.1214/aos/1176349259; Leventon M. E., 2000, P IEEE C COMP VIS PA; Ljung L., 1987, SYSTEM IDENTIFICATIO; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; MALLADI R, 1996, P MATH METH BIOM IM, P21; MARDIA KV, 1989, ADV APPL PROBAB, V21, P742, DOI 10.2307/1427764; Matheron G., 1975, RANDOM SETS INTEGRAL; MILLER MI, 1999, P SCTV; Mumford D., 1991, GEOMETRIC METHODS CO, V1570, P2; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758; ROMENY BMT, 1997, LECT NOTES COMPUTER, V1252; SAMSON C, 1999, INT C SCAL SPAC THEO, P306; Sebastian TB, 2000, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P70, DOI 10.1109/MMBIA.2000.852362; Thom R., 2018, STRUCTURAL STABILITY; Thompson DW, 1917, GROWTH FORM; Thompson P, 1996, IEEE T MED IMAGING, V15, P402, DOI 10.1109/42.511745; Veltkamp R., 1999, UUCS199927; YEZZI A, 2001, P IEEE C COMP VIS PA; Yezzi AJ, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P59, DOI 10.1109/ICCV.2001.937499; Younes L, 1998, SIAM J APPL MATH, V58, P565, DOI 10.1137/S0036139995287685; YUILLE AL, 1991, J COGNITIVE NEUROSCI, V3, P59, DOI 10.1162/jocn.1991.3.1.59; ZHU SC, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P416, DOI 10.1109/ICCV.1995.466909	47	78	81	0	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2003	53	2					153	167		10.1023/A:1023048024042	http://dx.doi.org/10.1023/A:1023048024042			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	674WZ					2022-12-18	WOS:000182661300003
J	Gluckman, J; Nayar, SK				Gluckman, J; Nayar, SK			Catadioptric stereo using planar mirrors	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						stereo vision; real-time stereo; sensors; catadioptric mirrors		By using mirror reflections of a scene, stereo images can be captured with a single camera (catadioptric stereo). In addition to simplifying data acquisition single camera stereo provides both geometric and radiometric advantages over traditional two camera stereo. In this paper, we discuss the geometry and calibration of catadioptric stereo with two planar mirrors. In particular, we will show that the relative orientation of a catadioptric stereo rig is restricted to the class of planar motions thus reducing the number of external calibration parameters from 6 to 5. Next we derive the epipolar geometry for catadioptric stereo and show that it has 6 degrees of freedom rather than 7 for traditional stereo. Furthermore, we show how focal length can be recovered from a single catadioptric image solely from a set of stereo correspondences. To test the accuracy of the calibration we present a comparison to Tsai camera calibration and we measure the quality of Euclidean reconstruction. In addition, we will describe a real-time system which demonstrates the viability of stereo with mirrors as an alternative to traditional two camera stereo.	Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Columbia University	Gluckman, J (corresponding author), Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.							ARMSTRONG M, 1996, P 1996 EUR C COMP VI; ARMSTRONG MN, 1996, THESIS U OXFORD; CHAEN A, 1997, 96122 IEICE; FAUGERAS O, 1993, 2013 INRIA; FAUGERAS OD, 1992, P 2 EUR C COMP VIS S, P563; GLUCKMAN J, 1999, P 1999 C COMP VIS PA; GLUCKMAN J, 1998, P 1998 DARPA IM UND; GOSHTASBY A, 1993, PATTERN RECOGN, V26, P923, DOI 10.1016/0031-3203(93)90058-5; HARTLEY R, 1992, P 1992 EUR C COMP VI; Hartley R. I., 1995, Proceedings. Fifth International Conference on Computer Vision (Cat. No.95CB35744), P1064, DOI 10.1109/ICCV.1995.466816; HARTLEY RI, 1993, P 1993 C COMP VIS PA; Hecht E., 1974, OPTICS; INABA M, 1993, P INT C ROB SYST JUL; KANADE T, 1996, P 1996 C COMP VIS PA; KAWANISHI T, 1998, INT C PATT REC 1998; KONOLIGE K, 1997, 8 INT S ROB RES HAYA; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Mathieu H., 1995, 0172 INRIA; MATTHIES L, 1992, INT J COMPUT VISION, V8, P71, DOI 10.1007/BF00126401; MAYBANK S, 1993, THEORY RECONSTRUCTIO; MITSUMOTO H, 1992, IEEE T PATTERN ANAL, V14, P941, DOI 10.1109/34.161352; MURRAY DW, 1995, COMPUT VIS IMAGE UND, V61, P285, DOI 10.1006/cviu.1995.1021; NAYAR S, 1988, Patent No. 4893183; NAYAR SK, 1997, P 1997 DARPA IM UND; NENE S, 1998, P 6 INT C COMP VIS B; NISHIMOTO Y, 1987, CVPR87, P192; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; SHASHUA A, 1998, WORKSH APPL COMP VIS; SOUTHWELL D, 1996, P INT C PATT REC; TEOH W, 1984, P INT C ROB, P186; TRIGGS B, 1997, P 1997 C COMP VIS PA; Tsai RY, 1986, EFFICIENT ACCURATE C; VIEVILLE T, 1995, 2678 INRIA; Xu A., 2018, KINETIC THEORY, DOI [10.1007/978-94-015-8668-9, DOI 10.1007/978]; ZELLER C, 1996, 2793 INRIA; ZHANG Z, 1995, ARTIFICIAL INTELLIGE, V78; ZHANG ZY, 1998, INT C PATTERN RECOGN	37	78	87	0	13	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2001	44	1					65	79		10.1023/A:1011172403203	http://dx.doi.org/10.1023/A:1011172403203			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	464WT					2022-12-18	WOS:000170556900003
J	Seitz, SM; Dyer, CR				Seitz, SM; Dyer, CR			View-invariant analysis of cyclic motion	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							RECOGNITION	This paper presents a general framework for image-based analysis of 3D repeating motions that addresses two limitations in the state of the art. First, the assumption that a motion be perfectly even from one cycle to the next is relaxed. Real repeating motions tend not to be perfectly even, i.e., the length of a cycle varies through time because of physically important changes in the scene. A generalization of period is defined for repeating motions that makes this temporal variation explicit. This representation, called the period trace, is compact and purely temporal, describing the evolution of an object or scene without reference to spatial quantities such as position or velocity. Second, the requirement that the observer be stationary is removed. Observer motion complicates image analysis because an object that undergoes a 3D repeating motion will generally not produce a repeating sequence of images. Using principles of affine invariance, we derive necessary and sufficient conditions for an image sequence to be the projection of a 3D repeating motion, accounting for changes in viewpoint and other camera parameters. Unlike previous work in visual invariance, however, our approach is applicable to objects and scenes whose motion is highly non-rigid. Experiments on real image sequences demonstrate how the approach may be used to detect several types of purely temporal motion features, relating to motion trends and irregularities. Applications to athletic and medical motion analysis are discussed.			Seitz, SM (corresponding author), UNIV WISCONSIN, DEPT COMP SCI, 1210 W DAYTON ST, MADISON, WI 53706 USA.							ALLMEN M, 1990, 10TH P INT C PATT RE, P365; BAKER HH, 1989, INT J COMPUT VISION, V3, P33, DOI 10.1007/BF00054837; BAUMBERG A, 1994, IEEE WORKSH MOT NONR, P194; Bobick A. F., 1995, Proceedings. Fifth International Conference on Computer Vision (Cat. No.95CB35744), P382, DOI 10.1109/ICCV.1995.466914; CEDRAS C, 1995, IMAGE VISION COMPUT, V13, P129, DOI 10.1016/0262-8856(95)93154-K; Darrell T., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P335, DOI 10.1109/CVPR.1993.341109; DAVIS J, 1994, IEE P-VIS IMAGE SIGN, V141, P101, DOI 10.1049/ip-vis:19941058; ESSA IA, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P76, DOI 10.1109/CVPR.1994.323813; GODDARD NH, 1989, MAR P WORKSH VIS MOT, P212; Gould K., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P79, DOI 10.1109/CVPR.1989.37831; HOGG D, 1983, IMAGE VISION COMPUT, V1, P5, DOI DOI 10.1016/0262-8856(83)90003-3; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; MCREYNOLDS DP, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P945, DOI 10.1109/ICCV.1995.466833; Mundy J., 1992, GEOMETRIC INVARIANCE; PERRY TS, 1990, IEEE SPECTRUM, V27, P43, DOI 10.1109/6.58366; Polana R., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P129, DOI 10.1109/CVPR.1992.223216; Polana R., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P2, DOI 10.1109/CVPR.1993.341009; PRESS WH, 1988, NMERICAL RECIPES C; Rohr K., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P8, DOI 10.1109/CVPR.1993.341008; SEITZ S, 1997, MOTION BASED RECOGNI, P61; Seitz S. M., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P178, DOI 10.1109/MNRAO.1994.346238; SEITZ SM, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P970, DOI 10.1109/CVPR.1994.323936; SHAH M, 1997, MOTION BASED RECOGNI; SHAPIRO LS, 1994, P EUR C COMP VIS STO, P73; SOATTO S, 1994, IEEE WORKSH MOT NONR, P228; Stewart G., 1973, INTRO MATRIX COMPUTA; TERZOPOULOS D, 1988, P AAAI C, P91; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; TSAI PS, 1994, PATTERN RECOGN, V27, P1591, DOI 10.1016/0031-3203(94)90079-5; WILLIAMS DJ, 1992, CVGIP-IMAG UNDERSTAN, V55, P14, DOI 10.1016/1049-9660(92)90003-L; YACOOB Y, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P70, DOI 10.1109/CVPR.1994.323812	34	78	81	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	1997	25	3					231	251		10.1023/A:1007928103394	http://dx.doi.org/10.1023/A:1007928103394			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	YK778					2022-12-18	WOS:A1997YK77800003
J	SPETSAKIS, M; ALOIMONOS, J				SPETSAKIS, M; ALOIMONOS, J			A MULTIFRAME APPROACH TO VISUAL-MOTION PERCEPTION	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							NOISY IMAGES; PARAMETERS; UNIQUENESS; SEQUENCE	One of the main issues in the area of motion estimation given the correspondences of some features in a sequence of images is sensitivity to error in the input. The main way to attack the problem, as with several other problems in science and engineering, is redundancy in the data. Up to now all the algorithms developed either used two frames or depended on assumptions about the motion or the shape of the scene. We present in this paper an algorithm based on multiple frames that employs only the rigidity assumption, is simple and mathematically elegant and, experimentally proves to be a major improvement over the two-frame algorithms. The algorithm does minimization of the squared error which we prove equivalent to an eigenvalue minimization problem. One of the side effects of this mean-square method is that the algorithm can have a very descriptive physical interpretation in terms of the "loaded spring model."	UNIV MARYLAND,CTR AUTOMAT RES,COMP VIS LAB,COLLEGE PK,MD 20742	University System of Maryland; University of Maryland College Park								BROIDA TJ, 1986, IEEE T PATTERN ANAL, V8, P90, DOI 10.1109/TPAMI.1986.4767755; BROIDA TJ, 1989, J OPT SOC AM A, V6, P879, DOI 10.1364/JOSAA.6.000879; FAUGERAS OD, 1987, P INT C COMPUT VISIO; HORN BKP, 1987, INT J COMPUT VISION, V1, P259, DOI 10.1007/BF00127824; Kato T., 1976, GRUNDLEHREN MATH WIS; MATTHIES L, 1988, P CVPR 88; SHARIAT H, 1986, THESIS U SO CALIFORN; SHARIAT H, 1986, IRIS202 U SO CAL I R; SHULMAN D, 1988, P ROY SOC LOND B BIO, V223, P217; SPETSAKIS ME, 1987, P AM ASS ARTIF INTEL; SPETSAKIS ME, 1988, P INT C COMPUT VISIO; Stoer J, 2013, INTRO NUMERICAL ANAL; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; WENG J, 1987, P IEEE COMPUT SOC WO; WENG JY, 1987, IEEE T PATTERN ANAL, V9, P370, DOI 10.1109/TPAMI.1987.4767920; YOUNG GS, 1988, P CVPR 88; YOUNG GSJ, 1990, IEEE T PATTERN ANAL, V12, P735, DOI 10.1109/34.57666	17	78	78	0	5	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	1991	6	3					245	255		10.1007/BF00115698	http://dx.doi.org/10.1007/BF00115698			11	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	GG465					2022-12-18	WOS:A1991GG46500004
J	Wang, Q; Chen, K				Wang, Qian; Chen, Ke			Zero-Shot Visual Recognition via Bidirectional Latent Embedding	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Zero-shot learning; Object recognition; Human action recognition; Supervised locality preserving projection; Landmark-based Sammon mapping; Multiple visual and semantic representations	SPACE	Zero-shot learning for visual recognition, e.g., object and action recognition, has recently attracted a lot of attention. However, it still remains challenging in bridging the semantic gap between visual features and their underlying semantics and transferring knowledge to semantic categories unseen during learning. Unlike most of the existing zero-shot visual recognition methods, we propose a stagewise bidirectional latent embedding framework of two subsequent learning stages for zero-shot visual recognition. In the bottom-up stage, a latent embedding space is first created by exploring the topological and labeling information underlying training data of known classes via a proper supervised subspace learning algorithm and the latent embedding of training data are used to form landmarks that guide embedding semantics underlying unseen classes into this learned latent space. In the top-down stage, semantic representations of unseen-class labels in a given label vocabulary are then embedded to the same latent space to preserve the semantic relatedness between all different classes via our proposed semi-supervised Sammon mapping with the guidance of landmarks. Thus, the resultant latent embedding space allows for predicting the label of a test instance with a simple nearest-neighbor rule. To evaluate the effectiveness of the proposed framework, we have conducted extensive experiments on four benchmark datasets in object and action recognition, i.e., AwA, CUB-200-2011, UCF101 and HMDB51. The experimental results under comparative studies demonstrate that our proposed approach yields the state-of-the-art performance under inductive and transductive settings.	[Wang, Qian; Chen, Ke] Univ Manchester, Sch Comp Sci, Manchester M13 9PL, Lancs, England	University of Manchester	Chen, K (corresponding author), Univ Manchester, Sch Comp Sci, Manchester M13 9PL, Lancs, England.	Qian.Wang@manchester.ac.uk; Ke.Chen@manchester.ac.uk	Chen, Ke/C-2560-2008; , Ke/ABG-5874-2020	Chen, Ke/0000-0001-9457-9364; 				Akata Z., 2014, ARXIV14098403; Akata Z, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2487986; Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911; Akata Z, 2013, PROC CVPR IEEE, P819, DOI 10.1109/CVPR.2013.111; Al-Halah Z, 2015, IEEE WINT CONF APPL, P837, DOI 10.1109/WACV.2015.116; Andreopoulos A, 2013, COMPUT VIS IMAGE UND, V117, P827, DOI 10.1016/j.cviu.2013.04.005; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Cai D., 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383054; Changpinyo S., 2016, ARXIV160508151; Changpinyo S, 2016, PROC CVPR IEEE, P5327, DOI 10.1109/CVPR.2016.575; Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76; Cheng J, 2005, NEUROCOMPUTING, V67, P443, DOI 10.1016/j.neucom.2004.08.006; Cox T., 2000, MULTIDIMENSIONAL SCA; Cristianini Nello, 2000, INTRO SUPPORT VECTOR, DOI DOI 10.1017/CBO9780511801389; Dean J, 2014, C WORKSH NEUR INF PR; Dinu Georgiana, 2015, WORKSH TRACK INT C L; Drucker H, 1997, ADV NEUR IN, V9, P155; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Elhoseiny M., 2015, IEEE C COMP VIS PATT; Frome Andrea, 2013, NEURIPS; Fu YW, 2015, IEEE T PATTERN ANAL, V37, P2332, DOI 10.1109/TPAMI.2015.2408354; Fu Y, 2010, RIV PUB S INFORM SCI, V6, P215; Gan C, 2015, AAAI CONF ARTIF INTE, P3769; Gan Chuang, 2016, IEEE C COMP VIS PATT; Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4; Griffin G., 2007, TECHNICAL REPORT 769; Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He XF, 2004, ADV NEUR IN, V16, P153; Jayaraman D, 2014, ADV NEUR IN, V27; Jiang Y.-G., 2014, THUMOS CHALLENGE ACT; Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Kodirov E, 2015, IEEE I CONF COMP VIS, P2452, DOI 10.1109/ICCV.2015.282; Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543; Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140; Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594; Mensink T, 2014, PROC CVPR IEEE, P2441, DOI 10.1109/CVPR.2014.313; Mikolov Tomas., 2013, ADV NEURAL INFORM PR, P3111, DOI DOI 10.1162/JMLR.2003.3.4-5.951; Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013; Radovanovic M, 2010, J MACH LEARN RES, V11, P2487; Reed S, 2016, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2016.13; Romera-Paredes Bernardino, 2015, ICML; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678; Shao L, 2016, INT J COMPUT VISION, V118, P115, DOI 10.1007/s11263-015-0861-6; Shao L, 2014, IEEE T CYBERNETICS, V44, P817, DOI 10.1109/TCYB.2013.2273174; Shigeto Y, 2015, LECT NOTES ARTIF INT, V9284, P135, DOI 10.1007/978-3-319-23528-8_9; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Solmaz B, 2013, MACH VISION APPL, V24, P1473, DOI 10.1007/s00138-012-0449-x; Soomro K., 2012, ARXIV; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412; Wah C., 2011, CNSTR2010001 CAL I T; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2; Wu Z., 2016, ACM MULTIMEDIA ACM M; Xian YQ, 2016, PROC CVPR IEEE, P69, DOI 10.1109/CVPR.2016.15; Xu X., 2015, ARXIV151104458; Xu X, 2015, IEEE IMAGE PROC, P63, DOI 10.1109/ICIP.2015.7350760; Yu M., 2015, ARXIV150800430; Zhang HG, 2010, MACH VISION APPL, V21, P577, DOI 10.1007/s00138-009-0213-z; Zhang ZM, 2016, LECT NOTES COMPUT SC, V9911, P533, DOI 10.1007/978-3-319-46478-7_33; Zhang ZM, 2015, IEEE I CONF COMP VIS, P4166, DOI 10.1109/ICCV.2015.474; ZHANG ZM, 2016, PROC CVPR IEEE, P6034, DOI DOI 10.1109/CVPR.2016.649; Zhao S., 2015, ARXIV151102126; Zheng ZL, 2007, SIGNAL PROCESS, V87, P2473, DOI 10.1016/j.sigpro.2007.03.006	69	77	83	1	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2017	124	3					356	383		10.1007/s11263-017-1027-5	http://dx.doi.org/10.1007/s11263-017-1027-5			28	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	FE1ER		Green Submitted			2022-12-18	WOS:000407961700006
J	Martinelli, A				Martinelli, Agostino			Closed-Form Solution of Visual-Inertial Structure from Motion	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Sensor fusion; Structure from motion; Inertial sensors; Robotics	FUSION; VISION; PERCEPTION	This paper investigates the visual-inertial structure from motion problem. A simple closed form solution to this problem is introduced. Special attention is devoted to identify the conditions under which the problem has a finite number of solutions. Specifically, it is shown that the problem can have a unique solution, two distinct solutions and infinite solutions depending on the trajectory, on the number of point-features and on their layout and on the number of camera images. The investigation is also performed in the case when the inertial data are biased, showing that, in this latter case, more images and more restrictive conditions on the trajectory are required for the problem resolvability.	INRIA Rhone Alpes, Grenoble, France		Martinelli, A (corresponding author), INRIA Rhone Alpes, Grenoble, France.	agostino.martinelli@inria.fr						Armesto L, 2007, INT J ROBOT RES, V26, P577, DOI 10.1177/0278364907079283; BERTHOZ A, 1975, EXP BRAIN RES, V23, P471; Bryson M, 2008, IEEE T AERO ELEC SYS, V44, P261, DOI 10.1109/TAES.2008.4517003; Chiuso A, 2002, IEEE T PATTERN ANAL, V24, P523, DOI 10.1109/34.993559; Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049; Dokka K, 2011, J VISION, V11, DOI 10.1167/11.13.2; Dong-Si T.C, 2012, P IEEE RSJ INT C INT, P1064; Farrell J, 2008, AIDED NAVIGATION SYS, P393; Fetsch CR, 2010, EUR J NEUROSCI, V31, P1721, DOI 10.1111/j.1460-9568.2010.07207.x; Gemeiner P, 2007, INT J ROBOT RES, V26, P591, DOI 10.1177/0278364907080058; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; HUNT BR, 1992, B AM MATH SOC, V27, P217, DOI 10.1090/S0273-0979-1992-00328-2; Jones ES, 2011, INT J ROBOT RES, V30, P407, DOI 10.1177/0278364910388963; Kelly J, 2011, INT J ROBOT RES, V30, P56, DOI 10.1177/0278364910382802; Kim J, 2007, ROBOT AUTON SYST, V55, P62, DOI 10.1016/j.robot.2006.06.006; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Martinelli A, 2012, IEEE T ROBOT, V28, P44, DOI 10.1109/TRO.2011.2160468; Merfeld DM, 1999, NATURE, V398, P615, DOI 10.1038/19303; Meyer CD., 2000, MATRIX ANAL APPL LIN; Nister D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17; Strelow D, 2004, INT J ROBOT RES, V23, P1157, DOI 10.1177/0278364904045593; Veth Major M., 2007, Navigation. Journal of the Institute of Navigation, V54, P11; Weiss S.M., 2012, VISION BASED NAVIGAT; Weiss S, 2011, J FIELD ROBOT, V28, P854, DOI 10.1002/rob.20412; Woodman  O.J., 2007, TECHNICAL REPORT	25	77	87	3	33	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2014	106	2					138	152		10.1007/s11263-013-0647-7	http://dx.doi.org/10.1007/s11263-013-0647-7			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	290UR		Green Submitted			2022-12-18	WOS:000329784300002
J	Batra, D; Kowdle, A; Parikh, D; Luo, JB; Chen, T				Batra, Dhruv; Kowdle, Adarsh; Parikh, Devi; Luo, Jiebo; Chen, Tsuhan			Interactively Co-segmentating Topically Related Images with Intelligent Scribble Guidance	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Interactive segmentation; Co-segmentation; Scribbles; Energy minimization		We present an algorithm for Interactive Co-segmentation of a foreground object from a group of related images. While previous works in co-segmentation have focussed on unsupervised co-segmentation, we use successful ideas from the interactive object-cutout literature. We develop an algorithm that allows users to decide what foreground is, and then guide the output of the co-segmentation algorithm towards it via scribbles. Interestingly, keeping a user in the loop leads to simpler and highly parallelizable energy functions, allowing us to work with significantly more images per group. However, unlike the interactive single-image counterpart, a user cannot be expected to exhaustively examine all cutouts (from tens of images) returned by the system to make corrections. Hence, we propose iCoseg, an automatic recommendation system that intelligently recommends where the user should scribble next. We introduce and make publicly available the largest co-segmentation dataset yet, the CMU-Cornell iCoseg dataset, with 38 groups, 643 images, and pixelwise hand-annotated groundtruth. Through machine experiments and real user studies with our developed interface, we show that iCoseg can intelligently recommend regions to scribble on, and users following these recommendations can achieve good quality cutouts with significantly lower time and effort than exhaustively examining all cutouts.	[Batra, Dhruv] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA; [Kowdle, Adarsh; Chen, Tsuhan] Cornell Univ, Ithaca, NY USA; [Parikh, Devi] Toyota Technol Inst, Chicago, IL USA; [Luo, Jiebo] Eastman Kodak Co, Rochester, NY USA	Carnegie Mellon University; Cornell University; Toyota Technological Institute - Chicago; Eastman Kodak	Batra, D (corresponding author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.	batradhruv@cmu.edu; apk64@cornell.edu; dparikh@ttic.edu; jiebo.luo@kodak.com; tsuhan@ece.cornell.edu	Luo, Jiebo/AAI-7549-2020	Chen, Tsuhan/0000-0003-3951-7931; Luo, Jiebo/0000-0002-4516-9729				Bagon S., 2006, MATLAB WRAPPER GRAPH; Bai X., 2007, ICCV; Batra D., 2010, CVPR; Batra D., 2009, INTERACTIVE COSEGMEN; BATRA D, 2008, BMVC; Bouman CA., 1997, CLUSTER UNSUPERVISED; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Burr Settles, 2009, COMPUTER SCI TECHNIC; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; Chen ZQ, 2008, ICMH 2008: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON MATERIAL HANDLING, P1; Collins Brendan, 2008, ECCV; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Criminisi Antonio, 2008, ECCV, P2; CUI J, 2008, CVPR; Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269; Fang YH, 2003, PATTERN RECOGN LETT, V24, P1279, DOI 10.1016/S0167-8655(02)00370-7; FITZGIBBON AW, 1998, P SMILE WORKSH STRUC, V1560, P154; Forbes K, 2006, LECT NOTES COMPUT SC, V3952, P165; Franco J.-S., 2003, BRIT MACH VIS C BMVC, V1, P329, DOI [DOI 10.5244/C.17.32, 10.5244/C.17.32]; Gallagher A., 2008, CVPR; Hochbaum D.S., 2009, ICCV; Hoiem Derek, 2005, CVPR; Jolly M., 2001, ICCV; Kapoor A., 2007, ICCV, P2; Kohli P, 2008, COMPUT VIS IMAGE UND, V112, P30, DOI 10.1016/j.cviu.2008.07.002; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; KOWDLE A, 2010, WORKSH REC MOD LARG; Lee Y. J., 2010, CVPR; LEUNG T, 1998, ECCV; Levoy M, 2000, COMP GRAPH, P131, DOI 10.1145/344779.344849; LI Y, 2004, SIGGRAPH; Mu Y., 2007, ACCV; Mukherjee L., 2009, CVPR; Rother C., 2004, SIGGRAPH; Rother Carsten, 2006, CVPR; SCHNITMAN Y, 2006, ACCV; Seung H. S., 1992, COLT; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; Starck J, 2007, IEEE COMPUT GRAPH, V27, P21, DOI 10.1109/MCG.2007.68; SZELISKI R, 1993, CVGIP-IMAG UNDERSTAN, V58, P23, DOI 10.1006/ciun.1993.1029; Vicente Sara, 2010, ECCV; Vijayanarasimhan Sudheendra, 2009, CVPR; Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696; Yan R., 2003, ICCV; Zhang L, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P24, DOI 10.1109/TDPVT.2002.1024035	46	77	84	0	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2011	93	3					273	292		10.1007/s11263-010-0415-x	http://dx.doi.org/10.1007/s11263-010-0415-x			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	746ND					2022-12-18	WOS:000289253100001
J	OKUTOMI, M; KANADE, T				OKUTOMI, M; KANADE, T			A LOCALLY ADAPTIVE WINDOW FOR SIGNAL MATCHING	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article								This article resents a signal matching algorithm that can select an appropriate window size adaptively so as to obtain both precise and stable estimation of correspondences. Matching two signals by calculating the sum of squared differences (SSD) over a certain window is a basic technique in computer vision. Given the signals and a window, there are two factors that determine the difficulty of obtaining precise matching. The first is the variation of the signal within the window, which must be large enough, relative to noise, that the SSD values exhibit a clear and sharp minimum at the correct disparity. The second factor is the variation of disparity within the window, which must be small enough that signals of corresponding positions are duly compared. These two factors present conflicting requirements to the size of the matching window, since a larger window tends to increase the signal variation, but at the same time tends to include points of different disparity. A window size must be adaptively selected depending on local variations of signal and disparity in order to compute a most-certain estimate of disparity at each point. There has been little work on a systematic method for automatic window-size selection. The major difficulty is that, while the signal variation is measurable from the input, the disparity variation is not, since disparities are what we wish to calculate. We introduce here a statistical model of disparity variation within a window, and employ it to establish a link between the window size and the uncertainty of the computed disparity. This allows us to choose the window size that minimizes uncertainty in the disparity computed at each point. This article presents a theory for the model and the resultant algorithm, together with analytical and experimental results that demonstrate their effectiveness.	CARNEGIE MELLON UNIV,SCH COMP SCI,PITTSBURGH,PA 15213	Carnegie Mellon University				Okutomi, Masatoshi/0000-0001-5787-0742				Besl P. J., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P591, DOI 10.1109/CCV.1988.590039; Blake A., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P62; BOULT T, 1986, THESIS COLUMBIA U; de Coulon F, 1986, SIGNAL THEORY PROCES, V1st. ed.; Forstner W., 1986, PATTERN RECOGN, P57; KANADE T, 1990, APR P INT C ROB AUT, P1088; MANDELBROT BB, 1968, SIAM REV, V10, P422, DOI 10.1137/1010093; MARROQUIN JL, 1984, MIT792 TECH REP AI M; MATTHIES L, 1988, JUN P IEEE COMP SOC, P366; MATTHIES L, 1989, SPIE SENSOR FUSION 2, V2; MORI K, 1973, COMPUT GRAPHICS IMAG, V2, P292; PRAZDNY K, 1985, BIOL CYBERN, V52, P93, DOI 10.1007/BF00363999; RYAN TW, 1980, OPT ENG, V19, P312, DOI 10.1117/12.7972515; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; VOSS RF, 1987, COURSE NOTE FRACTALS; WOOD GA, 1983, PHOTOGRAMM ENG REM S, V49, P537; Yagi, 1973, COMPUT VISION GRAPH, V2, P131	17	77	81	0	6	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	1992	7	2					143	162		10.1007/BF00128133	http://dx.doi.org/10.1007/BF00128133			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	HK110					2022-12-18	WOS:A1992HK11000004
J	Pizarro, D; Bartoli, A				Pizarro, Daniel; Bartoli, Adrien			Feature-Based Deformable Surface Detection with Self-Occlusion Reasoning	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Deformable surfaces; Image registration; Feature-based registration; Pixel-based refinement; Robust feature correspondence	REGISTRATION; WARPS	This paper presents a method for detecting a textured deformed surface in an image. It uses (wide-baseline) point matches between a template and the input image. The main contribution of the paper is twofold. First, we propose a robust method based on local surface smoothness capable of discarding outliers from the set of point matches. Our method handles large proportions of outliers (beyond 70% with less than 15% of false positives) even when the surface self-occludes. Second, we propose a method to estimate a self-occlusion resistant warp from point matches. Our method allows us to realistically retexture the input image. A pixel-based (direct) registration approach is also proposed. Bootstrapped by our robust point-based method, it finely tunes the warp parameters using the value (intensity or color) of all the visible surface pixels. The proposed framework was tested with simulated and real data. Convincing results are shown for the detection and retexturing of deformed surfaces in challenging images.	[Pizarro, Daniel] Univ Alcala, Alcala De Henares, Spain; [Bartoli, Adrien] Clermont Univ, Clermont Ferrand, France	Universidad de Alcala	Pizarro, D (corresponding author), Univ Alcala, Alcala De Henares, Spain.	pizarro@depeca.uah.es; adrien.bartoli@gmail.com		Pizarro, Daniel/0000-0003-0622-4884	Spanish Ministry of Science and Innovation [TIN2009-08984, TIN2008-06856-C05-05]; French ANR through the HFIBMR	Spanish Ministry of Science and Innovation(Ministry of Science and Innovation, Spain (MICINN)Spanish Government); French ANR through the HFIBMR(French National Research Agency (ANR))	This work has been partly supported by the Spanish Ministry of Science and Innovation under projects VISNU (ref. TIN2009-08984) and SDTEAM-UAH (ref. TIN2008-06856-C05-05) and the French ANR through the HFIBMR Project. We thank the anonymous reviewers for their constructive feedback and helpful suggestions.	[Anonymous], [No title captured]; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Bartoli A, 2008, J MATH IMAGING VIS, V31, P133, DOI 10.1007/s10851-007-0062-1; Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; DeCarlo D., 1998, INT C COMP VIS, V39, P380; DUCHON J, 1976, REV FR AUTOMAT INFOR, V10, P5; Gay-Bellile V, 2010, IEEE T PATTERN ANAL, V32, P87, DOI 10.1109/TPAMI.2008.265; Hilsmann A, 2009, LECT NOTES COMPUT SC, V5496, P94, DOI 10.1007/978-3-642-01811-4_9; Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188; Lischinski D., 1994, GRAPHICS GEMS, P47; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Pilet J, 2008, INT J COMPUT VISION, V76, P109, DOI 10.1007/s11263-006-0017-9; Pizarro D., 2010, EL P 5 INT S 3D DAT; Pizarro D, 2008, PROC CVPR IEEE, P2409; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284	17	76	79	0	15	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2012	97	1					54	70		10.1007/s11263-011-0452-0	http://dx.doi.org/10.1007/s11263-011-0452-0			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	897SD					2022-12-18	WOS:000300675300005
J	Subakan, ON; Vemuri, BC				Subakan, Oezlem N.; Vemuri, Baba C.			A Quaternion Framework for Color Image Smoothing and Segmentation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Color image smoothing; Color image segmentation; Quaternions; Quaternion Gabor filter; Continuous mixture models; Directional distributions; Watson distribution; von Mises distribution; Matrix-Fisher distribution	FOURIER-TRANSFORMS; ACTIVE CONTOURS; HYPERCOMPLEX; TEXTURE; RESTORATION; MODEL	In this paper, we present feature/detail preserving models for color image smoothing and segmentation using the Hamiltonian quaternion framework. First, we introduce a novel quaternionic Gabor filter (QGF) which can combine the color channels and the orientations in the image plane. We show that these filters are optimally localized both in the spatial and frequency domains and provide a good approximation to quaternionic quadrature filters. Using the QGFs, we extract the local orientation information in the color images. Second, in order to model this derived orientation information, we propose continuous mixtures of appropriate exponential basis functions and derive analytic expressions for these models. These analytic expressions take the form of spatially varying kernels which, when convolved with a color image or the signed distance function of an evolving contour (placed in the color image), yield a detail preserving smoothing and segmentation, respectively. Several examples on widely used image databases are shown to depict the performance of our algorithms.	[Subakan, Oezlem N.; Vemuri, Baba C.] Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA	State University System of Florida; University of Florida	Vemuri, BC (corresponding author), Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA.	ons@cise.ufl.edu; vemuri@cise.ufl.edu			NSF [IOS-0920145]; Direct For Biological Sciences [0920145] Funding Source: National Science Foundation	NSF(National Science Foundation (NSF)); Direct For Biological Sciences(National Science Foundation (NSF)NSF - Directorate for Biological Sciences (BIO))	This research was in part funded by the NSF grant IOS-0920145.	ALFSMANN D, 2007, P 15 EUR SIGN PROC C, P1322; Arbelaez PA, 2006, INT J COMPUT VISION, V69, P119, DOI 10.1007/s11263-006-6857-5; Bar L, 2007, IEEE T IMAGE PROCESS, V16, P1101, DOI 10.1109/TIP.2007.891805; Bertelli L, 2008, IEEE T PATTERN ANAL, V30, P1400, DOI 10.1109/TPAMI.2007.70785; Blomgren P, 1998, IEEE T IMAGE PROCESS, V7, P304, DOI 10.1109/83.661180; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Brook A, 2003, J MATH IMAGING VIS, V18, P247, DOI 10.1023/A:1022895410391; Brox T, 2003, LECT NOTES COMPUT SC, V2756, P353; Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38; Bulow T., 1997, Algebraic Frames for the Perception-Action Cycle. International Workshop, AFPAC'97. Proceedings, P148, DOI 10.1007/BFb0017865; Bulow T., 1997, MUSTERERKENNUNG 1997, P351, DOI [10.1007/978-3-642-60893-3_37, DOI 10.1007/978-3-642-60893-3_37]; Bulow T., 1999, THESIS U KIEL; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685; Chan TE, 2000, J VIS COMMUN IMAGE R, V11, P130, DOI 10.1006/jvci.1999.0442; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; DELSUC MA, 1988, J MAGN RESON, V77, P119, DOI 10.1016/0022-2364(88)90036-4; ELL TA, 1993, PROCEEDINGS OF THE 32ND IEEE CONFERENCE ON DECISION AND CONTROL, VOLS 1-4, P1830, DOI 10.1109/CDC.1993.325510; Ell TA, 2007, IEEE T IMAGE PROCESS, V16, P22, DOI 10.1109/TIP.2006.884955; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Galatsanos N. P., 2005, HDB IMAGE VIDEO PROC; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; HERZ CS, 1955, ANN MATH, V61, P474, DOI 10.2307/1969810; Hui W, 2006, IEEE IMAGE PROC, P745, DOI 10.1109/ICIP.2006.312504; Jian B, 2007, IEEE T MED IMAGING, V26, P1464, DOI 10.1109/TMI.2007.907552; Jian B, 2007, LECT NOTES COMPUT SC, V4584, P384; Jian B, 2007, NEUROIMAGE, V37, P164, DOI 10.1016/j.neuroimage.2007.03.074; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855; Kimmel R, 2000, INT J COMPUT VISION, V39, P111, DOI 10.1023/A:1008171026419; Kuipers J. B., 2002, QUATERNIONS ROTATION; Lawson C. L., 1974, SOLVING LEAST SQUARE; Lukac R, 2005, IEEE SIGNAL PROC MAG, V22, P74, DOI 10.1109/MSP.2005.1407717; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; Mardia K.V., 2000, DIRECTIONAL STAT; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Moxey CE, 2003, IEEE T SIGNAL PROCES, V51, P1941, DOI 10.1109/TSP.2003.812734; Mumford D., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P22; Paragios N., 2005, HDB MATH MODELS COMP; Pei SC, 1996, ISCAS 96: 1996 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - CIRCUITS AND SYSTEMS CONNECTING THE WORLD, VOL 2, P684, DOI 10.1109/ISCAS.1996.541817; PRENTICE MJ, 1986, J ROY STAT SOC B MET, V48, P214; Rousson M, 2008, INT J COMPUT VISION, V76, P231, DOI 10.1007/s11263-007-0054-z; Sangwine SJ, 1998, ELECTRON LETT, V34, P969, DOI 10.1049/el:19980697; Sangwine SJ, 1996, ELECTRON LETT, V32, P1979, DOI 10.1049/el:19961331; Sangwine SJ, 2000, IEE P-VIS IMAGE SIGN, V147, P89, DOI 10.1049/ip-vis:20000211; SANGWINE SJ, 2000, IMAGE PROCESSING, V2, P430; Sapiro G, 1997, COMPUT VIS IMAGE UND, V68, P247, DOI 10.1006/cviu.1997.0562; Schoenemann T., 2009, IEEE T PATTERN ANAL, V99; Sethuraman BA, 2003, IEEE T INFORM THEORY, V49, P2596, DOI 10.1109/TIT.2003.817831; Shi LL, 2007, COMPUT VIS IMAGE UND, V107, P88, DOI 10.1016/j.cviu.2006.11.014; Shoemaker K., 1985, Computer Graphics, V19, P245, DOI 10.1145/325165.325242; Subakan O. N., 2008, IEEE C COMP VIS PATT; Subakan O, 2007, IEEE I CONF COMP VIS, P708; Tang B, 2001, IEEE T IMAGE PROCESS, V10, P701, DOI 10.1109/83.918563; Tsai A, 2001, PROC CVPR IEEE, P463; Tschumperle D., 2008, GREYCSTORATION; Tschumperle D, 2006, INT J COMPUT VISION, V68, P65, DOI 10.1007/s11263-006-5631-z; Weickert J., 1997, P 7 NAT S PATT REC I, VI, P239; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	61	76	84	1	20	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	FEB	2011	91	3					233	250		10.1007/s11263-010-0388-9	http://dx.doi.org/10.1007/s11263-010-0388-9			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	711RY					2022-12-18	WOS:000286610300001
J	Oh, SM; Rehg, JM; Balch, T; Dellaert, F				Oh, Sang Min; Rehg, James M.; Balch, Tucker; Dellaert, Frank			Learning and inferring motion patterns using parametric segmental Switching Linear Dynamic Systems	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						probabilistic graphical models; time-series; trajectory analysis; behavior recognition; MCMC; biology	HIDDEN MARKOV-MODELS; STATE ESTIMATION; MONTE-CARLO; MCMC; TRACKING	Switching Linear Dynamic System (SLDS) models are a popular technique for modeling complex nonlinear dynamic systems. An SLDS can describe complex temporal patterns more concisely and accurately than an HMM by using continuous hidden states. However, the use of SLDS models in practical applications is challenging for three reasons. First, exact inference in SLDS models is computationally intractable. Second, the geometric duration model induced in standard SLDSs limits their representational power. Third, standard SLDSs do not provide a principled way to interpret systematic variations governed by higher order parameters. The contributions in this paper address all of these three challenges. First, we present a data-driven MCMC (DD-MCMC) sampling method for approximate inference in SLDSs. We show DD-MCMC provides an efficient method for estimation and learning in SLDS models. Second, we present segmental SLDSs (S-SLDS), where the geometric distributions of the switching state durations are replaced with arbitrary duration models. Third, we extend the standard SLDS model with additional global parameters that can capture systematic temporal and spatial variations. The resulting parametric SLDS model (P-SLDS) uses EM to robustly interpret parametrized motions by incorporating additional global parameters that underly systematic variations of the overall motion. The overall development of the extensions for SLDSs provide a principled framework to interpret complex motions. The framework is applied to the honey bee dance interpretation task in the context of the on-going BioTracking project at the Georgia Institute of Technology. The experimental results suggest that the enhanced models provide an effective framework for a wide range of motion analysis applications.	[Oh, Sang Min; Rehg, James M.; Balch, Tucker; Dellaert, Frank] Georgia Inst Technol, Coll Comp, GVU Ctr, Atlanta, GA 30332 USA	University System of Georgia; Georgia Institute of Technology	Oh, SM (corresponding author), Georgia Inst Technol, Coll Comp, GVU Ctr, Atlanta, GA 30332 USA.	sangmin@cc.gatech.edu; rehg@cc.gatech.edu; tucker@cc.gatech.edu; dellaert@cc.gatech.edu	Rehg, James/AAM-6888-2020	Rehg, James/0000-0003-1793-5462; Dellaert, Frank/0000-0002-5532-3566				Andrieu C, 2003, MACH LEARN, V50, P5, DOI 10.1023/A:1020281327116; Balch T., 2001, Proceedings of the Fifth International Conference on Autonomous Agents, P521, DOI 10.1145/375735.376434; Balch T, 2006, P IEEE, V94, P1445, DOI 10.1109/JPROC.2006.876969; Barbu A, 2005, IEEE T PATTERN ANAL, V27, P1239, DOI 10.1109/TPAMI.2005.161; BARSHALOM Y, 1975, AUTOMATICA, V11, P451, DOI 10.1016/0005-1098(75)90021-7; BARSSHALOM Y, 1993, ESTIMATION TRACKING; BARSSHALOM Y, 1988, TRACKING DATA ASS; Brand M, 2000, COMP GRAPH, P183, DOI 10.1145/344779.344865; Branson K, 2005, PROC CVPR IEEE, P1039; Bregler C, 1997, PROC CVPR IEEE, P568, DOI 10.1109/CVPR.1997.609382; Carter CK, 1996, BIOMETRIKA, V83, P589, DOI 10.1093/biomet/83.3.589; Casella G, 1996, BIOMETRIKA, V83, P81, DOI 10.1093/biomet/83.1.81; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Djuric PM, 2002, IEEE T SIGNAL PROCES, V50, P1113, DOI 10.1109/78.995067; DOLLAR SP, 2005, MEASURING BEHAV, P70; Doucet A, 2001, IEEE T SIGNAL PROCES, V49, P1216, DOI 10.1109/78.923304; Doucet A, 2001, IEEE T SIGNAL PROCES, V49, P613, DOI 10.1109/78.905890; Feldman A, 2004, ADAPT BEHAV, V12, P241, DOI 10.1177/105971230401200309; Ferguson JD, 1980, P S APPL HIDD MARK M, P143; Frey BJ, 2003, IEEE T PATTERN ANAL, V25, P1, DOI 10.1109/TPAMI.2003.1159942; Frisch K. v., 1967, DANCE LANGUAGE ORIEN; GE X, 2000, INT C KNOWL DISC DAT, P81; Ghahramani Z, 1998, NEURAL COMPUT, V12, P963; GILKS WR, 1996, M CHAIN M CARLO PRAC; HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.2307/2334940; HOWARD A, 2004, P UNC ART INT, P260; Khan Z, 2004, PROC CVPR IEEE, P980; Khan Z, 2006, IEEE T PATTERN ANAL, V28, P1960, DOI 10.1109/TPAMI.2006.247; KIM CJ, 1994, J ECONOMETRICS, V60, P1, DOI 10.1016/0304-4076(94)90036-1; Kim S, 2006, J MACH LEARN RES, V7, P945; Lee MW, 2006, IEEE T PATTERN ANAL, V28, P905, DOI 10.1109/TPAMI.2006.110; Lerner U, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P531; Lerner U., 2001, P 17 ANN C UNC ART I, P310; LEVITZKI A, 1990, MOL PHARM CELL REGUL, V1, P1; LI Y, 2002, SIGGRAPH P C COMP GR; Maybeck P. S., 1979, MATH SCI ENG; MCLACHLAN G, 1997, WILEY SERIES PROBABI; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Neal R., 1998, VIEW EM ALGORITHM JU; North B, 2000, IEEE T PATTERN ANAL, V22, P1016, DOI 10.1109/34.877523; Oh SK, 2005, KOREAN J CHEM ENG, V22, P949, DOI 10.1007/BF02705681; OH SM, 2005, P 10 IEE INT C COMP, V2, P1161; OH SM, 2005, GITGVU0516 COLL COMP; Ostendorf M, 1996, IEEE T SPEECH AUDI P, V4, P360, DOI 10.1109/89.536930; Pavlovic V., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P94, DOI 10.1109/ICCV.1999.791203; PAVLOVIC V., 2000, ADV NEURAL INFORM PR, V13, P981; PAVLOVIC V, 2000, P C COMP VIS PATT RE, V1, P788; RANGANATHAN A, 2005, ROBOTICS SCI SYSTEMS, V1, P209; Ren L, 2005, ACM T GRAPHIC, V24, P1090, DOI 10.1145/1073204.1073316; Rosti AVI, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P809; Roweis S, 1999, NEURAL COMPUT, V11, P305, DOI 10.1162/089976699300016674; RUSSELL M, 1993, P INT C AC SPEECH SI, P499; SHUMWAY RH, 1991, J AM STAT ASSOC, V86, P763, DOI 10.2307/2290410; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; Vidal R, 2002, IEEE DECIS CONTR P, P3614; Wilson AD, 1999, IEEE T PATTERN ANAL, V21, P884, DOI 10.1109/34.790429; Zoeter O, 2003, IEEE T PATTERN ANAL, V25, P1202, DOI 10.1109/TPAMI.2003.1233895	57	76	78	0	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2008	77	1-3					103	124		10.1007/s11263-007-0062-z	http://dx.doi.org/10.1007/s11263-007-0062-z			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	267RE		Green Submitted			2022-12-18	WOS:000253526100007
J	Gennery, DB				Gennery, Donald B.			Generalized camera calibration including fish-eye lenses	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						camera calibration; lens distortion; fish-eye lens; entrance pupil; camera model; CAHVOR; CAHVORE; Mars rovers	MODEL	A method is described for accurately calibrating cameras including radial lens distortion, by using known points such as those measured from a calibration fixture. Both the intrinsic and extrinsic parameters are calibrated in a single least-squares adjustment, but provision is made for including old values of the intrinsic parameters in the adjustment. The distortion terms are relative to the optical axis, which is included in the model so that it does not have to be orthogonal to the image sensor plane. These distortion terms represent corrections to the basic lens model, which is a generalization that includes the perspective projection and the ideal fish-eye lens as special cases. The position of the entrance pupil point as a function of off-axis angle also is included in the model. (The complete camera model including all of these effects often is called CAHVORE.) A way of adding decentering distortion also is described. A priori standard deviations can be used to apply weight to given initial approximations (which can be zero) for the distortion terms, for the difference between the optical axis and the perpendicular to the sensor plane, and for the terms representing movement of the entrance pupil, so that the solution for these is well determined when there is insufficient information in the calibration data. For the other parameters, initial approximations needed for the nonlinear least-squares adjustment are obtained in a simple manner from the calibration data and other known information. (Weight can be given to these also, if desired.) Outliers among the calibration points that disagree excessively with the other data are removed by means of automatic editing based on analysis of the residuals. The use of the camera model also is described, including partial derivatives for propagating both from object space to image space and vice versa. These methods were used to calibrate the cameras on the Mars Exploration Rovers.			Gennery, DB (corresponding author), 1881 Alpha Rd 17, Glendale, CA 91208 USA.	dgennery@earthlink.net						Bard Y., 1974, NONLINEAR PARAMETER; BROWN DC, 1971, PHOTOGRAMM ENG, V37, P855; Brown Duane C, 1966, PHOTOGRAMMETRIC ENG, P2, DOI DOI 10.1234/12345678; Carpino M, 2003, ICARUS, V166, P248, DOI 10.1016/S0019-1035(03)00051-4; Clarke TA, 1998, PHOTOGRAMM REC, V16, P51, DOI 10.1111/0031-868X.00113; Eisenman A, 2001, P SOC PHOTO-OPT INS, V4540, P288, DOI 10.1117/12.450671; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fraser CS, 2001, SPRINGER SERIES INFO, V34, P95; Gennery D. B., 1987, Proceedings of the 1987 IEEE International Conference on Robotics and Automation (Cat. No.87CH2413-3), P311; Gennery DB, 2001, SPRINGER SERIES INFO, V34, P123; GENNERY DB, 1986, TECHNIQUES 3D MACHIN, P53; GENNERY DB, 1980, AIM339 STANF U COMP; GENNERY DB, 1991, D8580 JPL; GENNERY DB, 1977, P INT JOINT C ART IN, P576; Grossman R, 2001, MASSIVE COMP, V2, P115; Gruen A, 2001, SPRINGER SERIES INFO, V34, P163; GRUEN A, 2001, CALIBRATION ORIENTAT; Heikkila J, 2000, IEEE T PATTERN ANAL, V22, P1066, DOI 10.1109/34.879788; Jenkins F. A., 2001, FUNDAMENTALS OPTICS, V4th; KENEFICK JF, 1972, PHOTOGRAMM ENG, V38, P1117; Laikin M., 2001, LENS DESIGN; Maki JN, 2003, J GEOPHYS RES-PLANET, V108, DOI 10.1029/2003JE002077; Mikhail E.M., 1976, OBSERVATIONS LEAST S; MIKHAIL EM, 1970, PHOTOGRAMM ENG, V36, P1277; MIYAMOTO K, 1964, J OPT SOC AM, V54, P1060, DOI 10.1364/JOSA.54.001060; Pope A.J., 1976, 65 NOAA NOS; Ryan T. P., 1997, MODERN REGRESSION ME; Shah S, 1996, PATTERN RECOGN, V29, P1775, DOI 10.1016/0031-3203(96)00038-6; Smith GH, 2001, P SOC PHOTO-OPT INS, V4441, P118, DOI 10.1117/12.449558; Stein GP, 1997, PROC CVPR IEEE, P602, DOI 10.1109/CVPR.1997.609387; STEVENSON E, 1995, 9507 U IOW COMP SCI; Swaminathan R, 2000, IEEE T PATTERN ANAL, V22, P1172, DOI 10.1109/34.879797; Swaminathan R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P2, DOI 10.1109/ICCV.2001.937581; Willson RG, 2001, SPRINGER SERIES INFO, V34, P137; YAKIMOVSKY Y, 1978, COMPUT VISION GRAPH, V7, P195, DOI 10.1016/0146-664X(78)90112-0; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718	36	76	87	0	22	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2006	68	3					239	266		10.1007/s11263-006-5168-1	http://dx.doi.org/10.1007/s11263-006-5168-1			28	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	064NU					2022-12-18	WOS:000239097200002
J	ROTHWELL, CA; ZISSERMAN, A; FORSYTH, DA; MUNDY, JL				ROTHWELL, CA; ZISSERMAN, A; FORSYTH, DA; MUNDY, JL			PLANAR OBJECT RECOGNITION USING PROJECTIVE SHAPE REPRESENTATION	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							MOTION; IMAGES; POSE	We describe a model based recognition system, called LEWIS, for the identification of planar objects based on a projectively invariant representation of shape. The advantages of this shape description include simple model acquisition (direct from images), no need for camera calibration or object pose computation, and the use of index functions. We describe the feature construction and recognition algorithms in detail and provide an analysis of the combinatorial advantages of using index functions. Index functions are used to select models from a model base and are constructed from projective invariants based on algebraic curves and a canonical projective coordinate frame. Examples are given of object recognition from images of real scenes, with extensive object libraries. Successful recognition is demonstrated despite partial occlusion by unmodelled objects, and realistic lighting conditions.	UNIV IOWA,DEPT COMP SCI,IOWA CITY,IA 52242; GE CO,CTR RES & DEV,SCHENECTADY,NY 12345	University of Iowa; General Electric	ROTHWELL, CA (corresponding author), UNIV OXFORD,DEPT ENGN SCI,ROBOT RES GRP,PARKS RD,OXFORD OX1 3PJ,ENGLAND.							[Anonymous], 1985, PERCEPTUAL ORG VISUA; AYACHE N, 1986, IEEE T PATTERN ANAL, V8, P44, DOI 10.1109/TPAMI.1986.4767751; AYACHE N, 1987, P IJCAI 87 MILAN, P808; BINFORD TO, 1981, ARTIF INTELL, V17, P205, DOI 10.1016/0004-3702(81)90025-4; BINFORD TO, 1993, P DARPA IM UND WORKS, P819; Bolles RC, 1987, 3 DIMENSIONAL MACHIN, P399; BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V9, P56, DOI 10.1016/0146-664X(79)90082-0; BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107; BROOKS RA, 1983, PATTERN ANAL MACHINE, V5; CALIFANO A, 1992, VISUAL FORM, P190; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CARLSSON S, 1992, GEOMETRIC INVARIANCE; CASS TA, 1992, P EUR C COMP VIS, P834; CLEMENS DT, 1991, IEEE T PATTERN ANAL, V13, P1007, DOI 10.1109/34.99235; COX IJ, 1992, 2ND P EUR C COMP VIS, P72; DEMEY S, 1992, P BRIT MACH VIS C LE, P49; Duda R.O., 1973, J ROYAL STAT SOC SER; ETTINGER GJ, 1988, IEEE C COMP VIS PATT, P32; FAUGERAS OD, 1992, P 2 EUR C COMP VIS S, P563; Fisher R.B., 1989, SURFACES OBJECTS COM, V7; FORSYTH D, 1991, IEEE T PATTERN ANAL, V13, P971, DOI 10.1109/34.99233; FORSYTH D, 1992, P EUR C COMP VIS SAN, P639; FORSYTH DA, 1993, P INT C COMP VIS BER, P476; GOAD C, 1983, P DARPA IUW, P371; Grimson W. E. L., 1990, OBJECT RECOGNITION C; GRIMSON WEL, 1987, IEEE T PATTERN ANAL, V9, P469, DOI 10.1109/TPAMI.1987.4767935; Gueziec A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P703, DOI 10.1109/CVPR.1993.341020; Hartley R., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P761, DOI 10.1109/CVPR.1992.223179; Huttenlocher D. P., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P263, DOI 10.1109/CVPR.1991.139699; HUTTENLOCHER DP, 1988, THESIS MIT; Jacobs D. W., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P439, DOI 10.1109/CVPR.1992.223153; KALVIN A, 1986, INT J ROBOT RES, V5, P38, DOI 10.1177/027836498600500403; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; LAMDAN Y, 1988, JUN P CVPR C ANN ARB, P335; Liu J., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P123, DOI 10.1109/CVPR.1993.341000; LOWE DG, 1987, INT J COMPUT VISION, V1, P57, DOI 10.1007/BF00128526; Marr D., 1982, VISION; MAYBANK SJ, 1993, SPRINGER VERLAG LECT, V825, P453; Mundy J., 1992, GEOMETRIC INVARIANCE; MUNDY JL, 1994, P DARPA IM UND WORKS, P1393; MURRAY DW, 1987, IMAGE VISION COMPUT, V5, P85, DOI 10.1016/0262-8856(87)90032-1; NAYAR SK, 1993, P 4 INT C COMP VIS, P280; NIELSEN L, 1988, AUTOMATICA, V24, P135, DOI 10.1016/0005-1098(88)90023-4; POLLARD SB, 1989, INT J ROBOT RES, V8, P132; QUAN L, 1991, P BMVC, P71; REID I, 1991, THESIS OXFORD U OXFO; RIGOUTSOS I, 1991, P WORKSH DIR AUT CAD, P76; Rothwell C.A., 1995, OBJECT RECOGNITION I; ROTHWELL CA, 1993, 2ND P ARPA NSF ESPRI, V825, P397; ROTHWELL CA, 1993, P IEEE INT C COMPUTE, P573; SCHWARTZ JT, 1987, INT J ROBOT RES, V6, P29, DOI 10.1177/027836498700600203; Semple J.G, 1952, ALGEBRAIC PROJECTIVE; SHAASHUA A, 1988, P 2 INT C COMP VIS, P321, DOI DOI 10.1109/CCV.1988.590008; SINCLAIR D, 1993, IMAGE VISION COMPUT, V11, P229, DOI 10.1016/0262-8856(93)90040-N; Slama CC., 1980, MANUAL PHOTOGRAMMETR, V4th edn; STEIN F, 1992, IEEE T PATTERN ANAL, V14, P1198, DOI 10.1109/34.177385; STOCKMAN G, 1987, COMPUT VISION GRAPH, V40, P361, DOI 10.1016/S0734-189X(87)80147-0; TAUBIN G, 1991, IBM TRRC17387 WATS R; Thompson D. W., 1987, Proceedings of the 1987 IEEE International Conference on Robotics and Automation (Cat. No.87CH2413-3), P208; Van Gool L., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P454, DOI 10.1109/CVPR.1991.139735; Wayner P. C., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P473, DOI 10.1109/CVPR.1991.139738; WEISS I, 1988, P IMAGE UNDERSTANDIN, P1125; WOLFSON HJ, 1992, P INVARIANCE WORKSHO; [No title captured]	64	76	84	0	3	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	1995	16	1					57	99		10.1007/BF01428193	http://dx.doi.org/10.1007/BF01428193			43	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	RW852					2022-12-18	WOS:A1995RW85200003
J	TSOTSOS, JK				TSOTSOS, JK			ON THE RELATIVE COMPLEXITY OF ACTIVE VS PASSIVE VISUAL-SEARCH	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							ATTENTION	Here, this author attempts to tie the concept of active perception to attentive processing in general and to the complexity level analysis of visual search described previously; the aspects of active vision as they have been currently described form a subset of the full spectrum of attentional capabilities. Our approach is motivated by the search requirements of vision tasks and thus we cast the problem as one of search preceding the application of methods for shape-from-X, optical flow, etc., and recognition in general. This perspective permits a dimension of analysis not found in current formulations of the active perception problem, that of computational complexity. This article describes where the active perception paradigm does and does not provide computational benefits along this dimension. A formalization of the search component of active perception is presented in order to accomplish this. The link to attentional mechanisms is through the control of data acquisition and processing by the active process. It should be noted that the analysis performed here applies to the general hypothesize-and-test search strategy, to time-varying scenes as well as to the general problem of integration of successive fixations. Finally, an argument is presented as to why this framework is an extension of the behaviorist approaches to active vision.	CANADIAN INST ADV RES,TORONTO M5S 1A1,ONTARIO,CANADA; UNIV TORONTO,DEPT COMP SCI,TORONTO M5S 1A1,ONTARIO,CANADA	Canadian Institute for Advanced Research (CIFAR); University of Toronto			Tsotsos, John/N-1131-2019; Tsotsos, John K/G-3436-2011	Tsotsos, John/0000-0002-8621-9147; 				Abbott A. L., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P532, DOI 10.1109/CCV.1988.590034; ALOIMONOS J, 1987, 1ST P INT C COMP VIS, P35; Bajcsy R., 1985, P IEEE WORKSHOP COMP, P55; Ballard D. H., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P524, DOI 10.1109/CCV.1988.590033; BALLARD DH, 1989, 11TH P INT JOINT C A; BALLARD DH, 1987, P WORKSHOP SPATIAL R, P188; BALLARD DH, 1985, P IEEE WORKSH COMP V, P3; BANDOPADHAY A, 1986, MAY P WORKSH MOT REP, P23; BROOKS RA, 1986, IEEE T ROBOTIC AUTOM, V2, P14, DOI 10.1109/JRA.1986.1087032; Clark J. J., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P514, DOI 10.1109/CCV.1988.590032; CONNELL JH, 1989, THESIS MIT; FRUEDER E, 1976, THESIS MIT; Garey M.R., 1979, COMPUTERS INTRACTABI; Gibson J., 1979, ECOLOGICAL APPROACH; Grimson W. E. L., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P218, DOI 10.1109/CCV.1988.589993; KROTKOV E, 1987, INT J COMPUT VISION, V1, P223, DOI 10.1007/BF00127822; LABERGE DL, 1990, PSYCHOL SCI, V1, P156, DOI 10.1111/j.1467-9280.1990.tb00188.x; Leeper R, 1935, PEDAGOG SEMIN J GEN, V46, P41; Marr D., 1982, VISION; METZGER W, 1974, HDB PERCEPTION, V1, P109; NAKAYAMA K, 1989, VISION RES, V29, P1631, DOI 10.1016/0042-6989(89)90144-2; Parasuraman R., 1984, VARIETIES ATTENTION; PAUL R, 1987, GRASP LAB97 U PENNSY; RABBITT P, 1978, HDB PERCEPTION PERCE, V9; STEINMAN RM, 1986, VISION RES, V26, P1389, DOI 10.1016/0042-6989(86)90163-X; TREISMAN A, 1988, Q J EXP PSYCHOL-A, V40, P201, DOI 10.1080/02724988843000104; TSOTSOS J, 1988, INT J COMPUT VISION, V1, P303; TSOTSOS JK, 1991, BEHAV BRAIN SCI, V14, P770, DOI 10.1017/S0140525X00072484; TSOTSOS JK, 1990, BEHAV BRAIN SCI, V13, P423, DOI 10.1017/S0140525X00079577; TSOTSOS JK, 1990, BEHAV BRAIN SCI, V13, P459; TSOTSOS JK, 1989, 11TH P INT C ART INT, P1571; UHR L, 1990, BEHAV BRAIN SCI, V13, P455, DOI 10.1017/S0140525X00079711; VERVILLE E, 1946, PEDAGOGICAL SEMINARY, V68, P149; VONHELMHOLTZ H, 1925, HDB PHYSL DETIK	34	76	76	0	0	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	1992	7	2					127	141		10.1007/BF00128132	http://dx.doi.org/10.1007/BF00128132			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	HK110					2022-12-18	WOS:A1992HK11000003
J	ONN, R; BRUCKSTEIN, A				ONN, R; BRUCKSTEIN, A			INTEGRABILITY DISAMBIGUATES SURFACE RECOVERY IN 2-IMAGE PHOTOMETRIC STEREO	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article									CORNELL UNIV,DEPT ELECT ENGN,ITHACA,NY 14853; TECHNION ISRAEL INST TECHNOL,DEPT COMP SCI,HAIFA,ISRAEL	Cornell University; Technion Israel Institute of Technology								Ballard D.H., 1982, COMPUTER VISION; BRUCKSTEIN AM, 1988, COMPUT VISION GRAPH, V44, P139, DOI 10.1016/S0734-189X(88)80002-1; Do Carmo M.P., 2016, DIFFERENTIAL GEOMETR, Vsecond; Horn Berthold K. P., 1975, PSYCHOL COMPUTER VIS, P115; HORN BKP, 1977, ARTIF INTELL, V8, P201, DOI 10.1016/0004-3702(77)90020-0; HORN BKP, 1986, COMPUT VISION GRAPH, V33, P174, DOI 10.1016/0734-189X(86)90114-3; HORN BKP, 1981, P IEEE; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; IKEUCHI K, 1987, INT ROBOTICS RES; Marr D., 1982, VISION; PONG TC, 1984, 2ND P WORKSH COMP VI; Rosenfeld A., 1982, DIGITAL PICTURE PROC, V1; ROSENFELD A, 1982, DIGITAL PICTURE PROC, V2; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; WOODHAM RJ, 1981, ARTIF INTELL, V17, P117, DOI 10.1016/0004-3702(81)90022-9	15	76	77	0	2	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	1990	5	1					105	113		10.1007/BF00056773	http://dx.doi.org/10.1007/BF00056773			9	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	EC482					2022-12-18	WOS:A1990EC48200004
J	Zhang, L; Wei, W; Zhang, YN; Shen, CH; van den Hengel, A; Shi, QF				Zhang, Lei; Wei, Wei; Zhang, Yanning; Shen, Chunhua; van den Hengel, Anton; Shi, Qinfeng			Cluster Sparsity Field: An Internal Hyperspectral Imagery Prior for Reconstruction	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Structured sparsity; Spatial similarity; Hyperspectral denoising; Compressive sensing	ALGORITHM; FILTER	Hyperspectral images (HSIs) have significant advantages over more traditional image types for a variety of computer vision applications dues to the extra information available. The practical reality of capturing and transmitting HSIs however, means that they often exhibit large amounts of noise, or are undersampled to reduce the data volume. Methods for combating such image corruption are thus critical to many HSIs applications. Here we devise a novel cluster sparsity field (CSF) based HSI reconstruction framework which explicitly models both the intrinsic correlation between measurements within the spectrum for a particular pixel, and the similarity between pixels due to the spatial structure of the HSI. These two priors have been shown to be effective previously, but have been always considered separately. By dividing pixels of the HSI into a group of spatial clusters on the basis of spectrum characteristics, we define CSF, a Markov random field based prior. In CSF, a structured sparsity potential models the correlation between measurements within each spectrum, and a graph structure potential models the similarity between pixels in each spatial cluster. Then, we integrate the CSF prior learning and image reconstruction into a unified variational framework for optimization, which makes the CSF prior image-specific, and robust to noise. It also results in more accurate image reconstruction compared with existing HSI reconstruction methods, thus combating the effects of noise corruption or undersampling. Extensive experiments on HSI denoising and HSI compressive sensing demonstrate the effectiveness of the proposed method.	[Zhang, Lei; Wei, Wei; Zhang, Yanning] Northwestern Polytech Univ, Sch Comp Sci, Xian, Shaanxi, Peoples R China; [Zhang, Lei; Shen, Chunhua; van den Hengel, Anton; Shi, Qinfeng] Univ Adelaide, Sch Comp Sci, Adelaide, SA, Australia	Northwestern Polytechnical University; University of Adelaide	Wei, W (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian, Shaanxi, Peoples R China.	weiweinwpu@nwpu.edu.cn		van den Hengel, Anton/0000-0003-3027-8364	National Natural Science Foundation of China [61671385, 61231016, 61571354]; Natural Science Basis Research Plan in Shaanxi Province of China [2017JM6021]; Innovation Foundation for Doctoral Dissertation of Northwestern Polytechnical University [CX201521]; Australian Research Council [FT120100969]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Basis Research Plan in Shaanxi Province of China; Innovation Foundation for Doctoral Dissertation of Northwestern Polytechnical University; Australian Research Council(Australian Research Council)	This work is supported in part by the National Natural Science Foundation of China (Nos. 61671385, 61231016, 61571354), Natural Science Basis Research Plan in Shaanxi Province of China (No. 2017JM6021), Innovation Foundation for Doctoral Dissertation of Northwestern Polytechnical University (No. CX201521) and Australian Research Council Grant (No. FT120100969). Lei Zhang's contribution was made when he was a visiting student at the University of Adelaide.	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Akbari H, 2010, IEEE T BIO-MED ENG, V57, P2011, DOI 10.1109/TBME.2010.2049110; August Y, 2013, OPT LETT, V38, P4996, DOI 10.1364/OL.38.004996; August Y, 2013, APPL OPTICS, V52, pD46, DOI 10.1364/AO.52.000D46; Boyd S, 2011, TRENDS MACH LEARN, V3, P1, DOI DOI 10.1561/2200000016; Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38; Chen C., 2012, ADV NEURAL INFORM PR, P1115; Chen F, 2015, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2015.76; Cotter SF, 2005, IEEE T SIGNAL PROCES, V53, P2477, DOI 10.1109/TSP.2005.849172; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; Dong WS, 2011, IEEE I CONF COMP VIS, P1259, DOI 10.1109/ICCV.2011.6126377; Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067; Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57; Foster DH, 2006, J OPT SOC AM A, V23, P2359, DOI 10.1364/JOSAA.23.002359; Fu Y, 2017, INT J COMPUT VISION, V122, P228, DOI 10.1007/s11263-016-0921-6; Greer JB, 2012, IEEE T IMAGE PROCESS, V21, P219, DOI 10.1109/TIP.2011.2160189; Huang JZ, 2011, J MACH LEARN RES, V12, P3371; Ji SH, 2008, IEEE T SIGNAL PROCES, V56, P2346, DOI 10.1109/TSP.2007.914345; Kerekes JP, 2005, IEEE T GEOSCI REMOTE, V43, P571, DOI 10.1109/TGRS.2004.841428; Li BH, 2015, PROC CVPR IEEE, P2094, DOI 10.1109/CVPR.2015.7298821; Lin DH, 2012, PROC CVPR IEEE, P2176, DOI 10.1109/CVPR.2012.6247925; Liu L, 2017, IEEE T RELIAB, V99, P1; Liu XF, 2012, IEEE T GEOSCI REMOTE, V50, P3717, DOI 10.1109/TGRS.2012.2187063; Lu CY, 2012, LECT NOTES COMPUT SC, V7578, P347, DOI 10.1007/978-3-642-33786-4_26; Maggioni M, 2013, IEEE T IMAGE PROCESS, V22, P119, DOI 10.1109/TIP.2012.2210725; Maggioni M, 2012, IEEE T IMAGE PROCESS, V21, P3952, DOI 10.1109/TIP.2012.2199324; Martin G, 2015, IEEE T GEOSCI REMOTE, V53, P2819, DOI 10.1109/TGRS.2014.2365534; Nasrabadi NM, 2014, IEEE SIGNAL PROC MAG, V31, P34, DOI 10.1109/MSP.2013.2278992; Peng Y, 2014, PROC CVPR IEEE, P2949, DOI 10.1109/CVPR.2014.377; Qian YT, 2013, IEEE J-STARS, V6, P499, DOI 10.1109/JSTARS.2012.2232904; Qian YT, 2012, INT GEOSCI REMOTE SE, P1345, DOI 10.1109/IGARSS.2012.6351287; Rasti B, 2013, INT GEOSCI REMOTE SE, P457, DOI 10.1109/IGARSS.2013.6721191; Renard N, 2008, IEEE GEOSCI REMOTE S, V5, P138, DOI 10.1109/LGRS.2008.915736; Schmidt U, 2014, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR.2014.349; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; Van Nguyen H., 2010, P IEEE COMP VIS PATT, P44; Wang, 2012, LOCALLY LINEAR EMBED; Wang P, 2016, PROC CVPR IEEE, P1573, DOI 10.1109/CVPR.2016.174; Wang P, 2017, IEEE T CIRC SYST VID, V27, P2613, DOI 10.1109/TCSVT.2016.2576761; Wang ZY, 2015, IEEE T GEOSCI REMOTE, V53, P1161, DOI 10.1109/TGRS.2014.2335177; Wei W, 2017, IEEE T GEOSCI REMOTE, V55, P6860, DOI 10.1109/TGRS.2017.2735488; Wipf DP, 2011, IEEE T INFORM THEORY, V57, P6236, DOI 10.1109/TIT.2011.2162174; Yasuma F, 2010, IEEE T IMAGE PROCESS, V19, P2241, DOI 10.1109/TIP.2010.2046811; Yuan QQ, 2012, IEEE T GEOSCI REMOTE, V50, P3660, DOI 10.1109/TGRS.2012.2185054; Zhang HY, 2014, IEEE T GEOSCI REMOTE, V52, P4729, DOI 10.1109/TGRS.2013.2284280; Zhang L., 2017, ARXIV170801008; Zhang L, 2016, IEEE T GEOSCI REMOTE, V54, P7223, DOI 10.1109/TGRS.2016.2598577; Zhang L, 2016, IEEE T IMAGE PROCESS, V25, P4974, DOI 10.1109/TIP.2016.2598652; Zhang L, 2015, IEEE I CONF COMP VIS, P3550, DOI 10.1109/ICCV.2015.405; Zhang Liliang, 2016, EUR C COMP VIS; Zhang ZL, 2011, IEEE J-STSP, V5, P912, DOI 10.1109/JSTSP.2011.2159773; Zhao Q, 2014, PR MACH LEARN RES, V32, P55	52	75	75	1	12	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2018	126	8					797	821		10.1007/s11263-018-1080-8	http://dx.doi.org/10.1007/s11263-018-1080-8			25	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	GL5ZB					2022-12-18	WOS:000437253500002
J	Shao, L; Liu, L; Yu, MY				Shao, Ling; Liu, Li; Yu, Mengyang			Kernelized Multiview Projection for Robust Action Recognition	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Human action recognition; Sequential distance learning; Multiple view fusion; Dimensionality reduction; Spectral coding	DESCRIPTORS	Conventional action recognition algorithms adopt a single type of feature or a simple concatenation of multiple features. In this paper, we propose to better fuse and embed different feature representations for action recognition using a novel spectral coding algorithm called Kernelized Multiview Projection (KMP). Computing the kernel matrices from different features/views via time-sequential distance learning, KMP can encode different features with different weights to achieve a low-dimensional and semantically meaningful subspace where the distribution of each view is sufficiently smooth and discriminative. More crucially, KMP is linear for the reproducing kernel Hilbert space, which allows it to be competent for various practical applications. We demonstrate KMP's performance for action recognition on five popular action datasets and the results are consistently superior to state-of-the-art techniques.	Northumbria Univ, Dept Comp Sci & Digital Technol, Newcastle Upon Tyne NE1 8ST, Tyne & Wear, England; [Shao, Ling; Liu, Li; Yu, Mengyang] Northumbria Univ, Dept Comp Sci & Digital Technol, Newcastle Upon Tyne NE1 8ST, Tyne & Wear, England	Northumbria University; Northumbria University	Shao, L (corresponding author), Northumbria Univ, Dept Comp Sci & Digital Technol, Newcastle Upon Tyne NE1 8ST, Tyne & Wear, England.	ling.shao@ieee.org; li2.liu@northumbria.ac.uk; m.y.yu@ieee.org	Shao, Ling/D-3535-2011	Shao, Ling/0000-0002-8264-6117				Ahonen T., 2004, EUR C COMPUTERVISION; Belkin M, 2002, ADV NEUR IN, V14, P585; Berndt DJ, 1994, KDD WORKSH, V10, P359; Bezdek J. C., 2002, AFSS INT C FUZZ SYST; Bhatia R., 1997, MATRIX ANAL; Bhattacharya S, 2011, PROC CVPR IEEE; Bickel S., 2004, INT C DAT MIN BRIGHT; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Brendel W., 2010, EUR C COMP VIS HER; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Dollar P., 2005, P IEEE INT WORKSH VI, P65, DOI [DOI 10.1109/VSPETS.2005.1570899, 10.1109/VSPETS.2005.1570899]; Gilbert A, 2011, IEEE T PATTERN ANAL, V33, P883, DOI 10.1109/TPAMI.2010.144; Gonen M, 2011, J MACH LEARN RES, V12, P2211; Hardy G.H., 1934, INEQUALITIES; He XF, 2004, ADV NEUR IN, V16, P153; Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407; Jhuang H., 2007, INT C COMP VIS; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Jiang Y. G., 2012, EUR C COMP VIS FLOR; Kihl O, 2015, PATTERN RECOGN, V48, P1174, DOI 10.1016/j.patcog.2014.11.013; Klaser Alexander, 2008, BMVC; Kovashka A., 2010, IEEE C COMP VIS PATT; Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496; Liu JG, 2009, PROC CVPR IEEE, P461, DOI 10.1109/CVPRW.2009.5206845; Liu L, 2013, PATTERN RECOGN, V46, P1810, DOI 10.1016/j.patcog.2012.10.004; Long B., 2008, INT C DAT MIN NEW YO; Marszalek M., 2009, IEEE C COMP VIS PATT; O'Hara S., 2012, IEEE C COMP VIS PATT; Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727; Sapienza M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.123; Schindler K., 2008, IEEE C COMP VIS PATT; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Scovanner P., 2007, INT C MULT BULG; Shao L, 2014, IEEE T CYBERNETICS, V44, P817, DOI 10.1109/TCYB.2013.2273174; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Sun L, 2014, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2014.336; Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096; Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11; Vrigkas M, 2014, COMPUT VIS IMAGE UND, V119, P27, DOI 10.1016/j.cviu.2013.11.007; Wang H., 2009, BRIT MACH VIS C NEW; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Wu X., 2011, IEEE C COMP VIS PATT; Xia TA, 2010, IEEE T SYST MAN CY B, V40, P1438, DOI 10.1109/TSMCB.2009.2039566; Xu C, 2015, IEEE T PATTERN ANAL, V37, P2531, DOI 10.1109/TPAMI.2015.2417578; Xu C, 2014, IEEE T PATTERN ANAL, V36, P1559, DOI 10.1109/TPAMI.2013.2296528; Yao A, 2010, PROC CVPR IEEE, P2061, DOI 10.1109/CVPR.2010.5539883; Yu M., 2015, ARXIV150800430; Zhang Z, 2012, IEEE T PATTERN ANAL, V34, P436, DOI 10.1109/TPAMI.2011.157; Zhao Z., 2008, J MACH LEARN RES, V4, P36; Zien A., 2007, INT C MACH LEARN NEW	54	75	75	1	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2016	118	2			SI		115	129		10.1007/s11263-015-0861-6	http://dx.doi.org/10.1007/s11263-015-0861-6			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	DO0OE		hybrid, Green Accepted			2022-12-18	WOS:000377477400002
J	Durrleman, S; Pennec, X; Trouve, A; Braga, J; Gerig, G; Ayache, N				Durrleman, Stanley; Pennec, Xavier; Trouve, Alain; Braga, Jose; Gerig, Guido; Ayache, Nicholas			Toward a Comprehensive Framework for the Spatiotemporal Statistical Analysis of Longitudinal Shape Data	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Longitudinal data; Statistics; Growth; Shape regression; Spatiotemporal registration; Time warp	BRAIN GROWTH; REGISTRATION; DEFORMATION; DIFFEOMORPHISMS; PATTERN; AUTISM; MOTION; MODEL	This paper proposes an original approach for the statistical analysis of longitudinal shape data. The proposed method allows the characterization of typical growth patterns and subject-specific shape changes in repeated time-series observations of several subjects. This can be seen as the extension of usual longitudinal statistics of scalar measurements to high-dimensional shape or image data. The method is based on the estimation of continuous subject-specific growth trajectories and the comparison of such temporal shape changes across subjects. Differences between growth trajectories are decomposed into morphological deformations, which account for shape changes independent of the time, and time warps, which account for different rates of shape changes over time. Given a longitudinal shape data set, we estimate a mean growth scenario representative of the population, and the variations of this scenario both in terms of shape changes and in terms of change in growth speed. Then, intrinsic statistics are derived in the space of spatiotemporal deformations, which characterize the typical variations in shape and in growth speed within the studied population. They can be used to detect systematic developmental delays across subjects. In the context of neuroscience, we apply this method to analyze the differences in the growth of the hippocampus in children diagnosed with autism, developmental delays and in controls. Result suggest that group differences may be better characterized by a different speed of maturation rather than shape differences at a given age. In the context of anthropology, we assess the differences in the typical growth of the endocranium between chimpanzees and bonobos. We take advantage of this study to show the robustness of the method with respect to change of parameters and perturbation of the age estimates.	[Durrleman, Stanley; Gerig, Guido] Sci Comp & Imaging SCI Inst, Salt Lake City, UT 84112 USA; [Durrleman, Stanley; Pennec, Xavier; Ayache, Nicholas] INRIA Sophia Antipolis, Asclepios Team Project, F-06902 Sophia Antipolis, France; [Durrleman, Stanley; Trouve, Alain] CNRS ENS Cachan, CMLA, F-94235 Cachan, France; [Braga, Jose] Univ Toulouse 3, CNRS, Lab Paleoanthropol Assistee Ordinateur, F-37073 Toulouse, France	Centre National de la Recherche Scientifique (CNRS); UDICE-French Research Universities; Universite Paris Saclay; Centre National de la Recherche Scientifique (CNRS); Universite de Toulouse; Universite Toulouse III - Paul Sabatier	Durrleman, S (corresponding author), Sci Comp & Imaging SCI Inst, 72 S Cent Dr, Salt Lake City, UT 84112 USA.	stanley.durrleman@gmail.com	Pennec, Xavier/L-2537-2013; Braga, Jose/A-4025-2010	Pennec, Xavier/0000-0002-6617-7664; Braga, Jose/0000-0002-8483-076X; Gerig, Guido/0000-0002-9547-6233	INRIA ARC 3D-Morphine (PI: Sylvain Prima); European IP Project Health-e-child [IST-2004-027749]; Microsoft Research; EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN DEVELOPMENT [R01HD055741, R01HD067731] Funding Source: NIH RePORTER; NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING [U54EB005149] Funding Source: NIH RePORTER; NATIONAL INSTITUTE OF MENTAL HEALTH [R01MH061696] Funding Source: NIH RePORTER; NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND STROKE [U01NS082086] Funding Source: NIH RePORTER	INRIA ARC 3D-Morphine (PI: Sylvain Prima); European IP Project Health-e-child; Microsoft Research(Microsoft); EUNICE KENNEDY SHRIVER NATIONAL INSTITUTE OF CHILD HEALTH & HUMAN DEVELOPMENT(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National Institute of Child Health & Human Development (NICHD)); NATIONAL INSTITUTE OF BIOMEDICAL IMAGING AND BIOENGINEERING(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB)); NATIONAL INSTITUTE OF MENTAL HEALTH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Mental Health (NIMH)); NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND STROKE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Neurological Disorders & Stroke (NINDS))	We would like to thank B. Combes (IRISA, France) for preprocessing the endocast data, J. Piven, director of Carolina Institute for Developmental Disabilities at UNC Chapel Hill, for providing imaging data related to autism research, and M. Styner (Psychiatry UNC Chapel Hill) for processing the subcortical structures. We thank W. Van Neer and E. Gilissen the previous and current curator of the "Musee de l'Afrique Centrale" at Tervuren (Belgium). We are indebted to Chems Touati for his help for creating figures and movies and James Fishbaugh for his kind proofreading of the manuscript, both at the Scientific Computing and Imaging Institute, University of Utah. This work has been funded in part by the INRIA ARC 3D-Morphine (PI: Sylvain Prima), the European IP Project Health-e-child (IST-2004-027749) and Microsoft Research.	Aljabar P, 2008, NEUROIMAGE, V39, P348, DOI 10.1016/j.neuroimage.2007.07.067; Allassonniere S, ESAIM PROBA IN PRESS; Chandrashekara R, 2003, LECT NOTES COMPUT SC, V2732, P599; Courchesne E, 2011, BRAIN RES, V1380, P138, DOI 10.1016/j.brainres.2010.09.101; Davis BC, 2010, INT J COMPUT VISION, V90, P255, DOI 10.1007/s11263-010-0367-1; De Craene M, 2009, LECT NOTES COMPUT SC, V5528, P437, DOI 10.1007/978-3-642-01932-6_47; Declerck J, 1998, MED IMAGE ANAL, V4, P1; DEWAAL FBM, 1995, SCI AM, V272, P82, DOI 10.1038/scientificamerican0395-82; Dupuis P, 1998, Q APPL MATH, V56, P587, DOI 10.1090/qam/1632326; Durrleman S, 2011, NEUROIMAGE, V55, P1073, DOI 10.1016/j.neuroimage.2010.11.056; Durrleman S, 2009, LECT NOTES COMPUT SC, V5761, P297, DOI 10.1007/978-3-642-04268-3_37; Durrleman S, 2009, MED IMAGE ANAL, V13, P793, DOI 10.1016/j.media.2009.07.007; Durrleman Stanley, 2010, THESIS U NICE SOPHIA; Ehrhardt J, 2008, EUR WORKSH VIS COMP, P69; Fishbaugh J, 2011, LNCS IN PRESS; Gerber S, 2010, MED IMAGE ANAL, V14, P643, DOI 10.1016/j.media.2010.05.008; Gerig G, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P1041; Glaunes J., 2005, THESIS U PARIS 13, V13; Gogtay N, 2008, P NATL ACAD SCI USA, V105, P15979, DOI 10.1073/pnas.0806485105; Grenander U, 2007, IEEE T MED IMAGING, V26, P648, DOI 10.1109/TMI.2006.891500; Hart G, 2010, P INT WORKSH SPAT IM; Hazlett HC, 2005, ARCH GEN PSYCHIAT, V62, P1366, DOI 10.1001/archpsyc.62.12.1366; Hazlett HC, 2011, ARCH GEN PSYCHIAT, V68, P467, DOI 10.1001/archgenpsychiatry.2011.39; Jian B, 2005, IEEE I CONF COMP VIS, P1246; Joshi SC, 2000, IEEE T IMAGE PROCESS, V9, P1357, DOI 10.1109/83.855431; Kan T., 1992, LAST APE PYGMY CHIMP; Khan AR, 2008, I S BIOMED IMAGING, P1521, DOI 10.1109/ISBI.2008.4541298; Kinzey W. G., 1984, DENTITION PYGMY CHIM; Kuroda S., 1989, DEV RETARDATION BEHA; Mansi T, 2009, LECT NOTES COMPUT SC, V5761, P214, DOI 10.1007/978-3-642-04268-3_27; Miller MI, 2006, J MATH IMAGING VIS, V24, P209, DOI 10.1007/s10851-005-3624-0; Miller MI, 2002, ANNU REV BIOMED ENG, V4, P375, DOI 10.1146/annurev.bioeng.4.092101.125733; Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z; Perperidis D, 2005, MED IMAGE ANAL, V9, P441, DOI 10.1016/j.media.2005.05.004; Peyrat JM, 2008, LECT NOTES COMPUT SC, V5242, P972, DOI 10.1007/978-3-540-85990-1_117; Qiu A, 2008, NEUROIMAGE, V40, P68, DOI 10.1016/j.neuroimage.2007.11.041; Qiu AQ, 2009, NEUROIMAGE, V45, pS51, DOI 10.1016/j.neuroimage.2008.10.039; SHEA BT, 1989, YEARB PHYS ANTHROPOL, V32, P69; Thompson PM, 2000, NATURE, V404, P190, DOI 10.1038/35004593; Trouve A, 1998, INT J COMPUT VISION, V28, P213, DOI 10.1023/A:1008001603737; Trouve A., 2010, Q APPL MATH IN PRESS; Vaillant M, 2004, NEUROIMAGE, V23, pS161, DOI 10.1016/j.neuroimage.2004.07.023; Xie YC, 2010, PROC CVPR IEEE, P2933, DOI 10.1109/CVPR.2010.5540035; Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015	44	75	75	0	22	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2013	103	1					22	59		10.1007/s11263-012-0592-x	http://dx.doi.org/10.1007/s11263-012-0592-x			38	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	137CV	23956495	Green Accepted, Green Submitted			2022-12-18	WOS:000318413500002
J	Kohli, P; Rihan, J; Bray, M; Torr, PHS				Kohli, Pushmeet; Rihan, Jonathan; Bray, Matthieu; Torr, Philip H. S.			Simultaneous segmentation and pose estimation of humans using dynamic graph cuts	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						pose estimation; segmentation; energy minimization	PRIORS	This paper presents a novel algorithm for performing integrated segmentation and 3D pose estimation of a human body from multiple views. Unlike other state of the art methods which focus on either segmentation or pose estimation individually, our approach tackles these two tasks together. Our method works by optimizing a cost function based on a Conditional Random Field (CRF). This has the advantage that all information in the image (edges, background and foreground appearances), as well as the prior information on the shape and pose of the subject can be combined and used in a Bayesian framework. Optimizing such a cost function would have been computationally infeasible. However, our recent research in dynamic graph cuts allows this to be done much more efficiently than before. We demonstrate the efficacy of our approach on challenging motion sequences. Although we target the human pose inference problem in the paper, our method is completely generic and can be used to segment and infer the pose of any rigid, deformable or articulated object.	[Kohli, Pushmeet; Rihan, Jonathan; Bray, Matthieu; Torr, Philip H. S.] Oxford Brookes Univ, Dept Comp, Oxford OX33 1HX, England	Oxford Brookes University	Kohli, P (corresponding author), Oxford Brookes Univ, Dept Comp, Oxford OX33 1HX, England.	pushmeet.kohli@brookes.ac.uk; philiptorr@brookes.ac.uk			Engineering and Physical Sciences Research Council [GR/T21790/01] Funding Source: researchfish	Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))		Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21; AGARWAL A, 2004, CVPR, V2, P882; BLAKE A, 2004, ECCV, P428; Boykov Y.Y., 2001, ICCV, V1, P105, DOI DOI 10.1109/ICCV.2001.937505; BRAY M, 2006, ECCV, V2, P642; Cremers D, 2006, INT J COMPUT VISION, V69, P335, DOI 10.1007/s11263-006-7533-5; DEUTSCHER J, 2001, COMPUTER VISION PATT, V2, P669; EK C, 2007, 4 JOINT WORKSH MULT; Felzenszwalb P. F., 2000, CVPR; Felzenszwalb P. F., 2004, TR20041963 CORN U; FREEDMAN D, 2005, CVPR, V1, P755; GAVRILA D, 1996, CVPR, P73; HUANG R, 2004, CVPR, V2, P739; KEHL R, 2005, CVPR, V2, P129; KOHLI P, 2005, ICCV; KOLMOGOROV V, 2002, ECCV, V3; KOLMOGOROV V, 2005, CVPR, V2, P407; KUMAR MP, 2005, CVPR, V1, P18; Lafferty J., 2001, P 18 INT C MACHINE L, P282, DOI DOI 10.5555/645530.655813; Lan XY, 2005, IEEE I CONF COMP VIS, P470; LEVENTON ME, 2000, CVPR, P1316; MORI G, 2004, CVPR, V2, P326; Press WH, 1988, NUMERICAL RECIPES C; Ramanan D., 2007, CVPR; RAMANAN D, 2003, CVPR, V2, P467; RIHAN J, 2006, ICVGIP, P576; SHAKHNAROVICH G, 2003, ICCV, P750; Sidenbladh H., 2000, LNCS, V2, P702; Sminchisescu C., 2004, ICML; SMINCHISESCU C, 2001, CVPR, P447; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; STENGER B, 2003, ICCV, P1063; SUN Y, 2006, ICVGIP, P882; Urtasun R, 2005, IEEE I CONF COMP VIS, P403; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Zhao L, 2005, IEEE I CONF COMP VIS, P454	36	75	82	0	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2008	79	3					285	298		10.1007/s11263-007-0120-6	http://dx.doi.org/10.1007/s11263-007-0120-6			14	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	310KW		Green Submitted			2022-12-18	WOS:000256529500005
J	Antonini, G; Martinez, SV; Bierlaire, M; Thiran, JP				Antonini, Gianluca; Martinez, Santiago Venegas; Bierlaire, Michel; Thiran, Jean Phillppe			Behavioral priors for detection and tracking of pedestrians in video sequences	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							DEFORMABLE MODELS; ROUTE CHOICE; SURVEILLANCE; CONSTRAINTS; MOVEMENT; PATTERNS	In this paper we address the problem of detection and tracking of pedestrians in complex scenarios. The inclusion of prior knowledge is more and more crucial in scene analysis to guarantee flexibility and robustness, necessary to have reliability in complex scenes. We aim to combine image processing methods with behavioral models of pedestrian dynamics, calibrated on real data. We introduce Discrete Choice Models (DCM) for pedestrian behavior and we discuss their integration in a detection and tracking context. The obtained results show how it is possible to combine both methodologies to improve the performances of such systems in complex sequences.	Ecole Polytech Fed Lausanne, Signal Proc Inst, STI, ITS,LTS5, CH-1015 Lausanne, Switzerland	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Antonini, G (corresponding author), Ecole Polytech Fed Lausanne, Signal Proc Inst, STI, ITS,LTS5, CH-1015 Lausanne, Switzerland.	Gianluca.Antonini@epfl.ch; Santiago.Venegas@epfl.ch; Michel.Bierlaire@epfl.ch; JP.Thiran@epfl.ch	Bierlaire, Michel/G-1707-2011	Thiran, Jean-Philippe/0000-0003-2938-9657; Bierlaire, Michel/0000-0002-5275-7692				AlGadhi SAH, 2002, PEDESTRIAN AND EVACUATION DYNAMICS, P3; Antonini G., 2004, ADV CONCEPTS INTELLI; ANTONINI G, 2004, IN PRESS TRANSPORT B; Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374; Ben-Akiva M., 1984, P 9 INT S TRANSP TRA, P299; Ben-Akiva M.E., 1985, DISCRETE CHOICE ANAL, V9; Bierlaire M., 2003, MOVING NETS PHYS SOC, P1; BIERLAIRE M, 2001, IN PRESS ANN OPERATI; Bierlaire M, 2002, P 2 SWISS TRANSP RES; BIERLAIRE M, 2003, INTRO BIOGEME VERSIO; BILIOTTI D, 2005, IEEE MOTION 2005; Blue VJ, 2001, TRANSPORT RES B-METH, V35, P293, DOI 10.1016/S0191-2615(99)00052-1; BORGERS A, 1986, GEOGR ANAL, V18, P115; BORGERS A, 1986, SOCIO ECON PLAN SCI, V20, P25, DOI 10.1016/0038-0121(86)90023-6; Bottom J, 1999, TRANSPORTATION AND TRAFFIC THEORY, P577; BREGLER C, 1997, P IEEE C COMP VIS PA; CAMPBELL LW, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P624, DOI 10.1109/ICCV.1995.466880; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CASCETTA E, 1992, P 2 INT CAPR SEM URB; COHEN LD, 2000, INT C COMP VIS ICCV; Collins RT, 2001, P IEEE, V89, P1456, DOI 10.1109/5.959341; Conroy R.A., 2001, THESIS U COLL LONDON; DALY AJ, 2001, 559 ITS U LEEDS; DeCarlo D, 2000, INT J COMPUT VISION, V38, P99, DOI 10.1023/A:1008122917811; Ferryman JM, 2000, INT J COMPUT VISION, V37, P187, DOI 10.1023/A:1008155721192; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; GEMAN D, 1990, IEEE T PATTERN ANAL, V12, P609, DOI 10.1109/34.56204; Haklay M, 2001, ENVIRON PLANN B, V28, P343, DOI 10.1068/b2758t; Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683; Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023; Helbing D, 2002, PEDESTRIAN AND EVACUATION DYNAMICS, P21; HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282; Hensher D., 1981, APPL DISCRETE CHOICE; HESS S, 2005, 84 ANN M TRANSP RES; Hoogendoorn Serge P., 2003, 10 INT C TRAV BEH RE; Hoogendoorn SP, 2002, PEDESTRIAN AND EVACUATION DYNAMICS, P123; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; ISARD M, 1996, EUR C COMP VIS, V1, P343; Johnson N, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P583; Jurie F, 2001, PROC CVPR IEEE, P791; Kakadiaris I.A., 1994, C COMP VIS PATT REC, P980; Kaneko T, 2003, PROC CVPR IEEE, P796; Kitagawa Genshiro, 2021, J COMPUT GRAPH STAT, V5, P1, DOI [DOI 10.2307/1390750, 10.2307/1390750]; Klupfel H, 2001, THEORETICAL AND PRACTICAL ISSUES ON CELLULAR AUTOMATA, P63; KONING RH, 1994, J ECONOMETRICS, V63, P389, DOI 10.1016/0304-4076(93)01557-3; KONING RH, 1991, 414 GRON U DEP EC; LAWRENCE CT, 1997, TR9416RL U MAR I SYS; Luce R, 1959, INDIVIDUAL CHOICE BE; McFadden D., 1997, EC HOUSING, V1, P531; McFadden D., 1981, ECONOMETRIC MODELS P; Mendels F, 2002, INT C PATT RECOG, P326, DOI 10.1109/ICPR.2002.1047462; Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897; Nummiaro K, 2003, LECT NOTES COMPUT SC, V2781, P591; NUMMIARO K, 2002, S PATT REC DAGM, P353; Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684; Penn A, 2002, PEDESTRIAN AND EVACUATION DYNAMICS, P99; RAMMING MS, 2001, THESIS MIT; Rosales R., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P117, DOI 10.1109/CVPR.1999.784618; Schadschneider A, 2002, PEDESTRIAN AND EVACUATION DYNAMICS, P75; SENIOR A, 2002, P ECCV WORKSH PERF E, P48; SHRECKENBERG M, 2002, PEDESTRIAN EVACUATIO; SMALL KA, 1987, ECONOMETRICA, V55, P409, DOI 10.2307/1913243; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; THAYANANTHAN A, 2003, P BRIT MACH VIS C, V2, P589; Toledo T, 2003, THESIS MIT; Train K, 2003, DISCRETE CHOICE METH; Turner A, 2001, ENVIRON PLANN B, V28, P103, DOI 10.1068/b2684; VENEGAS S, 2004, EUR SIGN PROC C EUSI; VOVSHA P, 1997, 76 ANN M WASH DC JAN; Walker J.L., 2001, EXTENDED DISCRETE CH; Wang XR, 2003, INT J OCCUP ENV HEAL, V9, P320, DOI 10.1179/oeh.2003.9.4.320; Wen CH, 2001, TRANSPORT RES B-METH, V35, P627, DOI 10.1016/S0191-2615(00)00045-X; WREN CR, 1998, FG 98, P22	74	75	78	1	12	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2006	69	2					159	180		10.1007/s11263-005-4797-0	http://dx.doi.org/10.1007/s11263-005-4797-0			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	065LW		Green Submitted			2022-12-18	WOS:000239162400001
J	Cheung, KM; Baker, S; Kanade, T				Cheung, KM; Baker, S; Kanade, T			Shape-from-silhouette across time part I: Theory and algorithms	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						3D reconstruction; Shape-From-Silhouette; Visual Hull; across time; stereo; temporal alignment; alignment ambiguity; visibility	3D OBJECTS; MOTION; CONSTRUCTION; REGISTRATION	Shape-From-Silhouette (SFS) is a shape reconstruction method which constructs a 3D shape estimate of an object using silhouette images of the object. The output of a SFS algorithm is known as the Visual Hull (VH). Traditionally SFS is either performed on static objects, or separately at each time instant in the case of videos of moving objects. In this paper we develop a theory of performing SFS across time: estimating the shape of a dynamic object (with unknown motion) by combining all of the silhouette images of the object over time. We first introduce a one dimensional element called a Bounding Edge to represent the Visual Hull. We then show that aligning two Visual Hulls using just their silhouettes is in general ambiguous and derive the geometric constraints (in terms of Bounding Edges) that govern the alignment. To break the alignment ambiguity, we combine stereo information with silhouette information and derive a Temporal SFS algorithm which consists of two steps: (1) estimate the motion of the objects over time (Visual Hull Alignment) and (2) combine the silhouette information using the estimated motion (Visual Hull Refinement). The algorithm is first developed for rigid objects and then extended to articulated objects. In the Part II of this paper we apply our temporal SFS algorithm to two human-related applications: (1) the acquisition of detailed human kinematic models and (2) marker-less motion tracking.	Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Cheung, KM (corresponding author), Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.	german+@cs.cmu.edu; simonb@cs.cmu.edu; tk@cs.cmu.edu						AGGARWAL JK, 1994, P IEEE COMP SOC WORK, P16; AHUJA N, 1989, IEEE T PATTERN ANAL, V11, P137, DOI 10.1109/34.16710; Baumgart B.G., 1974, THESIS STANFORD U; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BOTTINO A, 2000, P 4 WORLD MULT SYST, P23; BUEHLER C, 2001, P 12 EUR WORKSH REND; Buehler C., 1999, MITLCSTR780; CHEUNG G, 2003, P IEEE C COMP VIS PA; CHEUNG G, 2003, THESIS CARNEGIE MELL; DELAMARRE Q, 1999, P INT C COMP VIS ICC; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Dennis J.E., 1983, NUMERICAL METHODS UN; IRANI M, 2002, P EUR C COMP VIS ECC, P883; Jain A. K., 1989, FUNDAMENTALS DIGITAL; Joshi T., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P166, DOI 10.1109/MNRAO.1994.346240; JOSHI T, 1995, UIUCBIAIRCV9502; Kakadiaris IA, 1998, INT J COMPUT VISION, V30, P191, DOI 10.1023/A:1008071332753; KE Q, 2001, P IEEE C COMP VIS PA; KIM YC, 1986, IEEE T ROBOTIC AUTOM, V2, P127; KRAHNSTOEVER N, 2003, IN PRESS MACHINE VIS; KRAHNSTOEVER N, 2001, P IEEE C COMP VIS PA; Kurazume R., 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P99; Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954; LAURENTINI A, 1995, IEEE T PATTERN ANAL, V17, P188, DOI 10.1109/34.368170; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; Laurentini A., 1991, P 7 SCAND C IM AN, P993; LAURENTINI A, 1999, P INT C COMP VIS ICC; LAZEBNIK S, 2001, P IEEE C COMP VIS PA; MARTIN WN, 1983, IEEE T PATTERN ANAL, V5, P150, DOI 10.1109/TPAMI.1983.4767367; MATUSIK W, 2000, COMPUTER GRAPHICS AN; MATUSIK W, 2001, THESIS MIT; MEDONCA P, 2000, P EUR C COMP VIS ECC, P864; Mendonca PRS, 2001, IEEE T PATTERN ANAL, V23, P604, DOI 10.1109/34.927461; MOEZZI S, 1997, IEEE COMPUTER SOC MU, V4; NOBORIO H, 1988, IEEE T PATTERN ANAL, V10, P769, DOI 10.1109/34.9101; OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955; POELMAN C, 1992, CMUCSTR92208; POTMESIL M, 1987, COMPUT VISION GRAPH, V40, P1, DOI 10.1016/0734-189X(87)90053-3; Press WH., 1993, NUMERICAL RECIPES C; Quan L, 1996, PROC CVPR IEEE, P803, DOI 10.1109/CVPR.1996.517164; Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423; Sawhney HS, 1996, IEEE T PATTERN ANAL, V18, P814, DOI 10.1109/34.531801; SHANMUKH K, 1991, PATTERN RECOGN LETT, V12, P165, DOI 10.1016/0167-8655(91)90045-N; SZELISKI R, 1993, CVGIP-IMAG UNDERSTAN, V58, P23, DOI 10.1006/ciun.1993.1029; Szeliski R, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P517, DOI 10.1109/ICCV.1998.710766; SZELISKI R, 1994, 942 CRL COMP; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Vijayakumar B, 1996, PROC CVPR IEEE, P327, DOI 10.1109/CVPR.1996.517093; WONG K, 2001, P INT C COMP VIS ICC; WONG KYK, 2001, P INT WORKSH VIS FOR; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149; [No title captured]	52	75	77	2	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY-JUN	2005	62	3					221	247		10.1007/s11263-005-4881-5	http://dx.doi.org/10.1007/s11263-005-4881-5			27	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	906ME		Green Submitted			2022-12-18	WOS:000227645500002
J	Roy, S				Roy, S			Stereo without epipolar lines: A maximum-flow formulation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						stereo correspondence; maximum-flow; multiple cameras; range estimation; 3-d reconstruction		This paper describes a new algorithm for solving the stereo correspondence problem with a global 2-d optimization by transforming it into a maximum-flow problem in a graph. This transformation effectively removes explicit use of epipolar geometry, thus allowing direct use of multiple cameras with arbitrary geometries. The maximum-flow, solved both efficiently and globally, yields a minimum-cut that corresponds to a disparity surface for the whole image at once. This global and efficient approach to stereo analysis allows the reconstruction to proceed in an arbitrary volume of space and provides a more accurate and coherent depth map than the traditional stereo algorithms. In particular, smoothness is applied uniformly instead of only along epipolar lines, while the global optimality of the depth surface is guaranteed. Results show improved depth estimation as well as better handling of depth discontinuities. While the worst case running time is O(n(1.5) d(1.5) log(nd)), the observed average running time is O(n(1.2) d(1.3)) for an image size of n pixels and depth resolution d.	NEC Res Inst, Princeton, NJ 08540 USA	NEC Corporation	Roy, S (corresponding author), NEC Res Inst, 4 Independence Way, Princeton, NJ 08540 USA.	sebastien@research.nj.nec.com						Belhumeur PN, 1996, INT J COMPUT VISION, V19, P237, DOI 10.1007/BF00055146; Cormen T.H., 1990, INTRO ALGORITHMS 2 V; Cox IJ, 1996, COMPUT VIS IMAGE UND, V63, P542, DOI 10.1006/cviu.1996.0040; COX IJ, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P733, DOI 10.1109/CVPR.1994.323889; GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x; KANG SB, 1994, CMUCS94167; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; YANG YB, 1995, ARTIF INTELL, V78, P121, DOI 10.1016/0004-3702(95)00028-3; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]	16	75	78	0	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	1999	34	2-3					147	161		10.1023/A:1008192004934	http://dx.doi.org/10.1023/A:1008192004934			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	265NF					2022-12-18	WOS:000084249700005
J	Wolff, LB; Nayar, SK; Oren, M				Wolff, LB; Nayar, SK; Oren, M			Improved diffuse reflection models for computer vision	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						reflectance and appearance rendering; shape-from-reflectance; shape-from-shading; physics-based vision	SCATTERING; SURFACES	There are many computational vision techniques that fundamentally rely upon assumptions about the nature of diffuse reflection from object surfaces consisting of commonly occurring nonmetallic materials. Probably the most prevalent assumption made about diffuse reflection by computer vision researchers is that its reflected radiance distribution is described by the Lambertian model, whether the surface is rough or smooth. While computationally and mathematically a relatively simple model, in physical reality the Lambertian model is deficient in accurately describing the reflected radiance distribution for both rough and smooth nonmetallic surfaces. Recently, in computer vision diffuse reflectance models have been proposed separately for rough, and, smooth nonconducting dielectric surfaces each of these models accurately predicting salient non-Lambertian phenomena that have important bearing on computer vision methods relying upon assumptions about diffuse reflection. Together these reflectance models are complementary in their respective applicability to rough and smooth surfaces. A unified treatment is presented here detailing important deviations from Lambertian behavior for both rough and smooth surfaces. Some speculation is given as to how these separate diffuse reflectance models may be combined.	Johns Hopkins Univ, Dept Comp Sci, Comp Vis Lab, Baltimore, MD 21218 USA; Columbia Univ, Dept Comp Sci, Ctr Res Intelligent Syst, New York, NY 10027 USA; MIT, Artificial Intelligence Lab, Cambridge, MA 02139 USA	Johns Hopkins University; Columbia University; Massachusetts Institute of Technology (MIT)	Wolff, LB (corresponding author), Johns Hopkins Univ, Dept Comp Sci, Comp Vis Lab, Baltimore, MD 21218 USA.							BAHAR E, 1987, J GEOPHYS RES-OCEANS, V92, P5209, DOI 10.1029/JC092iC05p05209; Beckmann Petr, 1987, SCATTERING ELECTROMA, P4; BUHL D, 1968, J GEOPHYS RES, V73, P5281, DOI 10.1029/JB073i016p05281; Cabral B., 1987, COMPUT GRAPH, V21, P273; Chandrasekhar S., 1960, RAD TRANSFER; FRESNEL AJ, 1966, COMPLETE WORKS FRESN, V1, P767; Gondek J. S., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P213, DOI 10.1145/192161.192202; GRIMSON WEL, 1984, COMPUT VISION GRAPH, V28, P19, DOI 10.1016/0734-189X(84)90137-3; Hanrahan P., 1993, Computer Graphics Proceedings, P165, DOI 10.1145/166117.166139; HAPKE B, 1963, J GEOPHYS RES, V68, P4545, DOI 10.1029/JZ068i015p04545; HAPKE BW, 1993, SCIENCE, V260, P509, DOI 10.1126/science.260.5107.509; HEALEY G, 1989, J OPT SOC AM A, V6, P920, DOI 10.1364/JOSAA.6.000920; HERING RG, 1970, AIAA PROGR ASTRONAUT, V23, P337; Horn B.K.P., 1989, SHAPE SHADING; HORN BKP, 1977, ARTIF INTELL, V8, P201, DOI 10.1016/0004-3702(77)90020-0; KAJIYA JT, 1991, ACM COMPUTER GRAPHIC, V25, P175; Kubelka P., 1931, Z TECH PHYS, V12, P593, DOI DOI 10.4236/MSCE.2014.28004; KUGA Y, 1984, J OPT SOC AM A, V1, P831, DOI 10.1364/JOSAA.1.000831; Lambert J.H., 1760, PHOTOMETRIA SIVE MEN; Minnaert M, 1941, ASTROPHYS J, V93, P403, DOI 10.1086/144279; NAYAR SK, 1995, SCIENCE, V267, P1153, DOI 10.1126/science.7855592; NAYAR SK, 1991, IEEE T PATTERN ANAL, V13, P611, DOI 10.1109/34.85654; Nicodemus FE, 1977, NBS MONOGRAPH, V160; OETKING P, 1966, J GEOPHYS RES, V71, P2505, DOI 10.1029/JZ071i010p02505; OPIK E, 1924, PUBLICATIONS OBSERVA, V26, P1; ORCHARD SE, 1969, J OPT SOC AM, V59, P1584, DOI 10.1364/JOSA.59.001584; OREN M, 1995, INT J COMPUT VISION, V14, P227, DOI 10.1007/BF01679684; OREN M, 1993, P DARPA IM UND WORKS, P1025; Oren M., 1993, P IEEE C COMP VIS PA; Oren M., 1994, P ECCV, P269, DOI DOI 10.1007/BFB0028360; OREN M, 1992, CUCS05792; ORLOVA NS, 1956, ASTRON ZH, V33, P93; Poulin P., 1990, Computer Graphics, V24, P273, DOI 10.1145/97880.97909; REICHMAN J, 1973, APPL OPTICS, V12, P1811, DOI 10.1364/AO.12.001811; Siegal R., 1981, THERMAL RAD HEAT TRA, V2; SMITH BG, 1967, J GEOPHYS RES, V72, P4059, DOI 10.1029/JZ072i016p04059; Smith G. B., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence, P689; TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105; TSANG L, 1984, J OPT SOC AM A, V1, P836, DOI 10.1364/JOSAA.1.000836; WESTIN SH, 1992, COMP GRAPH, V26, P255, DOI 10.1145/142920.134075; Wolff L. B., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P472, DOI 10.1109/CVPR.1992.223148; Wolff L. B., 1992, P SOC PHOTO-OPT INS, V1822, P60; WOLFF LB, 1994, J OPT SOC AM A, V11, P2956, DOI 10.1364/JOSAA.11.002956; WOLFF LB, 1994, OPT ENG, V33, P285, DOI 10.1117/12.149144; WOLFF LB, 1993, P DARPA IM UND WORKS, P1031; WOLFF LB, 1991, CS9118 J HOPK; WOLFF LB, 1993, SPIE P OPTICAL SCATT, V2, P26	47	75	79	0	7	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	OCT	1998	30	1					55	71		10.1023/A:1008017513536	http://dx.doi.org/10.1023/A:1008017513536			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	152CC					2022-12-18	WOS:000077757100004
J	Lasenby, J; Fitzgerald, WJ; Lasenby, AN; Doran, CJL				Lasenby, J; Fitzgerald, WJ; Lasenby, AN; Doran, CJL			New geometric methods for computer vision: An application to structure and motion estimation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						physics-based vision; structure and motion estimation; geometry	CLOSED-FORM SOLUTION; ALGEBRA; QUATERNIONS	We discuss a coordinate-free approach to the geometry of computer vision problems. The technique we use to analyse the three-dimensional transformations involved will be that of geometric algebra: a framework based on the algebras of Clifford and Grassmann. This is not a system designed specifically for the task in hand, but rather a framework for all mathematical physics. Central to the power of this approach is the way in which the formalism deals with rotations; for example, if we have two arbitrary sets of vectors, known to be related via a 3D rotation, the rotation is easily recoverable if the vectors are given. Extracting the rotation by conventional means is not as straightforward. The calculus associated with geometric algebra is particularly powerful, enabling one, in a very natural way, to take derivatives with respect to any multivector (general element of the algebra). What this means in practice is that we can minimize with respect to rotors representing rotations, vectors representing translations, or any other relevant geometric quantity. This has important implications for many of the least-squares problems in computer vision where one attempts to find optimal rotations, translations etc., given observed vector quantities. We will illustrate this by analysing the problem of estimating motion from a pair of images, looking particularly at the more difficult case in which we have available only 2D information and no information on range. While this problem has already been much discussed in the literature, we believe the present formulation to be the only one in which least-squares estimates of the motion and structure are derived simultaneously using analytic derivatives.	Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England; Univ Cambridge, Cavendish Lab, Mullard Radio Astron Observ, Cambridge CB3 0HE, England	University of Cambridge; University of Cambridge	Lasenby, J (corresponding author), Univ Cambridge, Dept Engn, Trumpington St, Cambridge CB2 1PZ, England.	jl@eng.cam.ac.uk; wjf@eng.cam.ac.uk; anthony@mrao.cam.ac.uk; cjld1@mrao.cam.ac.uk	Lasenby, Anthony/ABC-7691-2021	Lasenby, Anthony/0000-0002-8208-6332; Lasenby, Joan/0000-0002-0571-0218				ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965; BAYROCORROCHANO E, 1995, P EUR CHIN WORKSH GE; BAYROCORROCHANO E, 1996, P ICPR 96 VIENN; CHEVALIER DP, 1991, MECH MACH THEORY, V26, P350; CLIFFORD WK, 1878, AM J MATH, V236, P613; CSURKA G, 1995, P EUR CHIN WORKSH GE; DORAN C, 1993, J MATH PHYS, V34, P3642, DOI 10.1063/1.530050; Doran CJL, 1994, THESIS U CAMBRIDGE; DORAN CJL, 1993, 3 INT C CLIFF ALG TH, P375; DORAN CJL, 1996, ADV ELECT ELECT PHYS, V95, P272; FAUGERAS O, 1995, P EUR CHIN WORKSH GE; Faugeras O. D., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P25; Faugeras O. D., 1983, P INT JOINT C ART IN, V8, P996; Grassmann H., 1877, MATH ANN, V12, P375; GULL S, 1993, FOUND PHYS, V23, P1175, DOI 10.1007/BF01883676; HESTENES D, 1991, ACTA APPL MATH, V23, P25, DOI 10.1007/BF00046919; HESTENES D, 1994, NEURAL NETWORKS, V7, P79, DOI 10.1016/0893-6080(94)90057-4; Hestenes D, 1966, SPACE TIME ALGEBRA; Hestenes D, 2012, CLIFFORD ALGEBRA GEO; Hestenes D, 1986, CLIFFORD ALGEBRAS TH, P1; Hestenes D., 1986, NEW FDN CLASSICAL ME; HORN BKP, 1988, J OPT SOC AM A, V5, P1127, DOI 10.1364/JOSAA.5.001127; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; HUANG TS, 1994, P IEEE, V82, P252, DOI 10.1109/5.265351; HUANG TS, 1986, HDB PATTERN RECOGNIT, pCH14; LASENBY A, 1993, J MATH PHYS, V34, P3683, DOI 10.1063/1.530053; LASENBY AN, 1994, P 1994 INT SCH ASTR, P359; LASENBY AN, 1997, IN PRESS PHIL T RO A; LASENBY J, 1996, P ICPR 96 VIENN; LASENBY J, 1996, GEOMETRIC CLIFFORD A; Lin Z., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P194; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; MITCHIE A, 1986, HDB PATTERN RECOGNIT; SABATA B, 1991, CVGIP-IMAG UNDERSTAN, V54, P309, DOI 10.1016/1049-9660(91)90032-K; WALKER MW, 1991, CVGIP-IMAG UNDERSTAN, V54, P358, DOI 10.1016/1049-9660(91)90036-O; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779; [No title captured]	37	75	81	0	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	FEB-MAR	1998	26	3					191	213		10.1023/A:1007901028047	http://dx.doi.org/10.1023/A:1007901028047			23	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	ZD490					2022-12-18	WOS:000072691200002
J	DUBUISSON, MP; JAIN, AK				DUBUISSON, MP; JAIN, AK			CONTOUR EXTRACTION OF MOVING-OBJECTS IN COMPLEX OUTDOOR SCENES	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							OPTICAL-FLOW; PICTURE SEGMENTATION; IMAGE SEQUENCES; EDGE-DETECTION; MOTION; COMPUTATION; INFORMATION; VELOCITY; PHASE; VIEWS	This paper presents a new approach to the extraction of the contour of a moving object. The method is based on the fusion of a motion segmentation technique using image subtraction and a color segmentation technique based on the split-and-merge paradigm and edge information obtained from using the Canny edge detector. The advantages of this method are the following: it can detect large moving objects, the background can be arbitrarily complicated and contain many nonmoving objects, and it requires only three images frames that need not be consecutive provided that the moving object is entirely contained in the three frames. It is assumed that there is only one moving object in the image and the objects are not blurred by their motion so that the edges in the image are sharp. The method was applied to road images containing a moving vehicle, and the results show that the contour was correctly extracted in 18 of the 20 cases. We show that this contour extraction method gives good results for other types of moving objects as well. We also describe how the extracted contour can be used to classify a given vehicle into five generic categories. In this study, 19 out of the 20 vehicles were correctly classified. These results demonstrate that integration of multiple cues obtained from relatively simple image analysis techniques leads to a robust extraction of the object of interest in complex outdoor scenes.			DUBUISSON, MP (corresponding author), MICHIGAN STATE UNIV, DEPT COMP SCI, E LANSING, MI 48824 USA.							Amini A. A., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P294, DOI 10.1109/WVM.1991.212772; AMINI AA, 1990, IEEE T PATTERN ANAL, V12, P855, DOI 10.1109/34.57681; Ballard D.H., 1982, COMPUTER VISION; BASRI R, 1988, P IEEE INT C COMPUTE, P482; BEVERIDGE JR, 1989, INT J COMPUT VISION, V2, P311, DOI 10.1007/BF00158168; BOUTHEMY P, 1993, INT J COMPUT VISION, V10, P157, DOI 10.1007/BF01420735; CAFFORIO C, 1976, IEEE T INFORM THEORY, V22, P573, DOI 10.1109/TIT.1976.1055602; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; COUTANCE V, 1991, COULEUR VISION ORDIN; CUMANI A, 1991, PATTERN RECOGN, V24, P661, DOI 10.1016/0031-3203(91)90033-2; DU L, 1993, P 4 INT C COMP VIS I, P632; Dubuisson M.-P., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P471, DOI 10.1109/CVPR.1993.341088; DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272; DUNCAN JH, 1992, IEEE T PATTERN ANAL, V14, P346, DOI 10.1109/34.120329; ETOH M, 1993, P 4 INT C COMP VIS, P192; FARROKHNIA F, 1991, JUN P IEEE C COMP VI, P364; FENNEMA CL, 1979, COMPUT VISION GRAPH, V9, P301, DOI 10.1016/0146-664X(79)90097-2; FLEET DJ, 1990, INT J COMPUT VISION, V5, P77, DOI 10.1007/BF00056772; FRAZIER J, 1990, P DARPA IMAGE UNDERS, P348; HEEGER DJ, 1987, INT J COMPUT VISION, V1, P279, DOI 10.1007/BF00133568; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HOROWITZ SL, 1976, J ACM, V23, P368, DOI 10.1145/321941.321956; HSU YZ, 1984, COMPUT VISION GRAPH, V26, P73, DOI 10.1016/0734-189X(84)90131-2; JAIN A., 1993, ALGORITHMS CLUSTERIN; Jain A. K., 1988, ALGORITHMS CLUSTERIN, V6; JAIN AK, 1993, 3D OBJECT RECOGNITIO; JAIN R, 1979, COMPUT VISION GRAPH, V11, P13, DOI 10.1016/0146-664X(79)90074-1; JAIN R, 1979, IEEE T PATTERN ANAL, V1, P206, DOI 10.1109/TPAMI.1979.4766907; KASS M, 1988, INT J COMPUT VISION, P321, DOI DOI 10.1007/BF00133570; KILGER M, 1992, P IEEE WORKSHOP APPL; KLUGE K, 1990, VISION NAVIGATION CA, P95; KOLLER D, 1991, JUN IEEE C COMP VIS, P90; MAO JC, 1992, PATTERN RECOGN, V25, P173, DOI 10.1016/0031-3203(92)90099-5; MILGRAM DL, 1979, COMPUT VISION GRAPH, V11, P1, DOI 10.1016/0146-664X(79)90073-X; MILLER KS, 1993, P TRANSPORTATION RES; Nagel H., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P1174; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; NAKANISHI T, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL I, P500, DOI 10.1109/ICPR.1992.201609; NOLL D, 1993, P IEEE INT C COMPUTE, P286; OHLANDER R, 1978, COMPUT VISION GRAPH, V8, P313, DOI 10.1016/0146-664X(78)90060-6; OHTA Y, 1980, COMPUT VISION GRAPH, V13, P222, DOI 10.1016/0146-664X(80)90047-7; PAVLIDIS T, 1990, IEEE T PATTERN ANAL, V12, P225, DOI 10.1109/34.49050; Pentland A., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P288, DOI 10.1109/WVM.1991.212773; Rom H., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P49, DOI 10.1109/CVPR.1992.223228; SEIBERT M, 1992, IEEE T PATTERN ANAL, V14, P107, DOI 10.1109/34.121784; SETHI IK, 1991, P C VEHICLE NAVIGATI, P193; SHIO A, 1991, IEEE WORKSH VIS MOT, P325; Stein F., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P13, DOI 10.1109/ICPR.1990.118057; THOMPSON WB, 1981, COMPUTER, V14, P20, DOI 10.1109/C-M.1981.220559; THOMPSON WB, 1987, 1ST P INT C COMP VIS, P201; WENG J, 1993, INT J COMPUT VISION, V11, P211, DOI 10.1007/BF01469343; WENG JY, 1992, IEEE T PATTERN ANAL, V14, P806, DOI 10.1109/34.149592; ZIMMERMANN G, 1988, REAL TIME OBJECT MEA, P215; 1991, TRB232 NAT RES COUNC	55	75	95	0	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	1995	14	1					83	105		10.1007/BF01421490	http://dx.doi.org/10.1007/BF01421490			23	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	QG479					2022-12-18	WOS:A1995QG47900005
J	RIMEY, RD; BROWN, CM				RIMEY, RD; BROWN, CM			CONTROL OF SELECTIVE PERCEPTION USING BAYES NETS AND DECISION-THEORY	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							BELIEF NETWORKS; PROPAGATION; VISION; FUSION	A selective vision system sequentially collects evidence to answer a specific question with a desired level of confidence. Efficiency comes from processing the scene only where necessary, to the level of detail necessary, and with only the necessary operators. Knowledge representation and sequential decision making are central issues for selective vision, which takes advantage of prior knowledge of a domain's abstract and geometrical structure (e.g., ''part-of'' and ''adjacent'' relationships), and also uses information from a scene instance gathered during analysis. The TEA-1 selective vision system uses Bayes nets for representation, benefit-cost analysis for control of visual and nonvisual actions; and its data structures and decision-making algorithms provide a general, reusable framework. TEA-1 solves the T-world problem, an abstraction of a large set of scene domains and tasks. Some factors that affect the success of selective perception are analyzed by using TEA-1 to solve ensembles of randomly produced, simulated T-world problems. Experimental results with a real-world T-world problem, dinner table scenes, are also presented.	UNIV ROCHESTER, DEPT COMP SCI, ROCHESTER, NY 14627 USA	University of Rochester	RIMEY, RD (corresponding author), MARTIN MARIETTA ASTRONAUT, POB 179, DENVER, CO 80201 USA.							AGOSTA JM, 1991, THESIS STANFORD U; ANDERSEN SK, 1989, 11TH P INT JOINT C A, P1080; BALLARD DH, 1992, CVGIP-IMAG UNDERSTAN, V56, P3, DOI 10.1016/1049-9660(92)90081-D; BOLLE RM, 1990, P IEEE INTERN C PATT, P1; BOLLES RC, 1977, 5TH P INT JOINT C AR, P569; BURT PJ, 1988, P IEEE, V76, P1006, DOI 10.1109/5.5971; CHARNIAK E, 1991, AI MAG, V12, P50; CHEN CH, 1992, CVGIP-IMAG UNDERSTAN, V55, P170, DOI 10.1016/1049-9660(92)90015-U; CHOU PB, 1990, INT J COMPUT VISION, V4, P185, DOI 10.1007/BF00054995; Clark J. J., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P514, DOI 10.1109/CCV.1988.590032; Clemen, 1991, MAKING HARD DECISION; COOPER GF, 1990, ARTIF INTELL, V42, P393, DOI 10.1016/0004-3702(90)90060-D; DEAN T, 1990, P DARPA IMAGE UNDERS, P889; DEAN TL, 1991, PLANNING CONTROL; Durrant-Whyte HF, 1988, INTEGRATION COORDINA; ELFES A, 1992, 1992 IEEE INTERNATIONAL CONF ON ROBOTICS AND AUTOMATION : PROCEEDINGS, VOLS 1-3, P2561, DOI 10.1109/ROBOT.1992.220056; FELDMAN J, 1977, COGNITIVE SCI, V1, P1588; GARVEY T, 1976, 117 SRI ATI CTR TECH; Hager G.D., 1990, TASK DIRECTED SENSOR; HECKERMAN D, 1993, IEEE T PATTERN ANAL, V15, P292, DOI 10.1109/34.204912; Henrion M., 1990, UNCERTAINTY ARTIFICI, V5, P129; HUTCHINSON SA, 1989, IEEE T ROBOTIC AUTOM, V5, P765, DOI 10.1109/70.88098; Jensen F. V., 1990, Computational Statistics Quarterly, V5, P269; JENSNE FV, 1992, P APPL AI, V10; Krotkov EP, 1989, ACTIVE COMPUTER VISI; LAURITZEN SL, 1988, J ROY STAT SOC B MET, V50, P157; LEVITT T, 1908, P DARPA IMAGE UNDERS, P355; LEVITT TS, 1986, UNCERTAINITY AI, P347; MANN WB, 1992, P DARPA IM UND WORKS, P793; PEARL J, 1986, ARTIF INTELL, V29, P241, DOI 10.1016/0004-3702(86)90072-X; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; PEOT MA, 1991, ARTIF INTELL, V48, P299, DOI 10.1016/0004-3702(91)90030-N; REECE DA, 1992, P DARPA IMAGE UNDERS, P953; RIMEY RD, 1991, INT J COMPUT VISION, V7, P47, DOI 10.1007/BF00130489; RIMEY RD, 1992, ACTIVE VISION, P217; RIMEY RD, 1993, THESIS U ROCHESTER; SARKAR S, 1993, IEEE T PATTERN ANAL, V15, P256, DOI 10.1109/34.204907; SHACHTER RD, 1986, OPER RES, V34, P871, DOI 10.1287/opre.34.6.871; TARABANIS K, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P76, DOI 10.1109/ROBOT.1991.131556; Verma T., 1990, READINGS UNCERTAIN R; VONKAENEL P, 1993, GOAL ORIENTED DYNAMI; WIXSON LE, 1994, INT J COMPUT VISION, V12, P209, DOI 10.1007/BF01421203; WU HL, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P563; Yarbus A. L., 1967, EYE MOVEMENTS VISION, P171	44	75	75	0	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	1994	12	2-3					173	207		10.1007/BF01421202	http://dx.doi.org/10.1007/BF01421202			35	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	NL558					2022-12-18	WOS:A1994NL55800003
J	Luiten, J; Osep, A; Dendorfer, P; Torr, P; Geiger, A; Leal-Taixe, L; Leibe, B				Luiten, Jonathon; Osep, Aljosa; Dendorfer, Patrick; Torr, Philip; Geiger, Andreas; Leal-Taixe, Laura; Leibe, Bastian			HOTA: A Higher Order Metric for Evaluating Multi-object Tracking	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Multi-object tracking; Evaluation metrics; Visual tracking	PERFORMANCE-MEASURES; MULTITARGET; ALGORITHM; FILTERS; TARGET	Multi-object tracking (MOT) has been notoriously difficult to evaluate. Previous metrics overemphasize the importance of either detection or association. To address this, we present a novel MOT evaluation metric, higher order tracking accuracy (HOTA), which explicitly balances the effect of performing accurate detection, association and localization into a single unified metric for comparing trackers. HOTA decomposes into a family of sub-metrics which are able to evaluate each of five basic error types separately, which enables clear analysis of tracking performance. We evaluate the effectiveness of HOTA on the MOTChallenge benchmark, and show that it is able to capture important aspects of MOT performance not previously taken into account by established metrics. Furthermore, we show HOTA scores better align with human visual evaluation of tracking performance.	[Luiten, Jonathon; Leibe, Bastian] Rhein Westfal TH Aachen, Aachen, Germany; [Osep, Aljosa; Dendorfer, Patrick; Leal-Taixe, Laura] Tech Univ Munich, Munich, Germany; [Torr, Philip] Univ Oxford, Oxford, England; [Geiger, Andreas] Max Planck Inst Intelligent Syst, Tubingen, Germany; [Geiger, Andreas] Univ Tubingen, Tubingen, Germany	RWTH Aachen University; Technical University of Munich; University of Oxford; Max Planck Society; Eberhard Karls University of Tubingen	Luiten, J (corresponding author), Rhein Westfal TH Aachen, Aachen, Germany.	luiten@vision.rwth-aachen.de; aljosa.osep@tum.de; patrick.dendorfer@tum.de; phst@robots.ox.ac.uk; andreas.geiger@tue.mpg.de; leal.taixe@tum.de; leibe@vision.rwth-aachen	Leal-Taixe, Laura/HFZ-8079-2022; Leibe, Bastian/E-5499-2017	Leal-Taixe, Laura/0000-0001-8709-1133; Osep, Aljosa/0000-0001-8105-4737; Leibe, Bastian/0000-0003-4225-0051; Luiten, Jonathon/0000-0002-4133-7764	Projekt DEAL; EPSRC [EP/N019474/1] Funding Source: UKRI	Projekt DEAL; EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	Open Access funding provided by Projekt DEAL.	Akopyan F, 2006, INT SYMP ASYNCHRON C, P12, DOI 10.1109/ASYNC.2006.5; Andriluka M, 2018, PROC CVPR IEEE, P5167, DOI 10.1109/CVPR.2018.00542; Babaee M, 2019, NEUROCOMPUTING, V368, P69, DOI 10.1016/j.neucom.2019.08.008; Baisa NL, 2019, 2019 22ND INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION 2019); Baisa NL, 2018, PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2018), VOL 5: VISAPP, P429, DOI 10.5220/0006564504290438; Baisa NL, 2019, J VIS COMMUN IMAGE R, V59, P257, DOI 10.1016/j.jvcir.2019.01.026; Ben Shitrit H, 2011, IEEE I CONF COMP VIS, P137, DOI 10.1109/ICCV.2011.6126235; Bento J., 2016, ARXIV160103094; Bergmann P, 2019, IEEE I CONF COMP VIS, P941, DOI 10.1109/ICCV.2019.00103; Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309; Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003; Bochinski E, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS); Caesar Holger, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11618, DOI 10.1109/CVPR42600.2020.01164; Carletta J, 2005, LECT NOTES COMPUT SC, V3869, P28; Chen JH, 2017, IEEE COMPUT SOC CONF, P2143, DOI 10.1109/CVPRW.2017.266; Chen L, 2018, IEEE INT CON MULTI; Dave Achal, 2020, ECCV; Dendorfer P., 2019, ARXIV190604567CS; Dendorfer P., 2020, MOT20 BENCHMARK MULT, pabs/2003.09003; Eiselein V, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P325, DOI 10.1109/AVSS.2012.59; Ellis A., 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P135, DOI 10.1109/AVSS.2010.89; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fu Z., 2018, IEEE ACCESS; Fu ZY, 2019, IEEE T MULTIMEDIA, V21, P2277, DOI 10.1109/TMM.2019.2902480; Fujita O, 2013, JPN J IND APPL MATH, V30, P1, DOI 10.1007/s13160-012-0089-6; Gao XZ, 2009, IN C IND ENG ENG MAN, P2295, DOI 10.1109/IEEM.2009.5373040; Geiger A., 2012, P IEEE COMP SOC C CO; Gordon C, 2019, RHEUMATOL ADV PRACT, V3, DOI 10.1093/rap/rkz021; Henschel Roberto, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Proceedings, P770, DOI 10.1109/CVPRW.2019.00105; Henschel R, 2018, IEEE COMPUT SOC CONF, P1509, DOI 10.1109/CVPRW.2018.00192; Kao EK, 2009, IEEE I CONF COMP VIS, P1523, DOI 10.1109/ICCV.2009.5459275; Karunasekera H, 2019, IEEE ACCESS, V7, P104423, DOI 10.1109/ACCESS.2019.2932301; KASTURI R, 2006, PERFORMANCE EVALUATI; Keuper M, 2020, IEEE T PATTERN ANAL, V42, P140, DOI 10.1109/TPAMI.2018.2876253; Kirillov A, 2019, PROC CVPR IEEE, P9396, DOI 10.1109/CVPR.2019.00963; Kutschbach Tino, 2017, 2017 14 IEEE INT C A, P1, DOI DOI 10.1109/AVSS.2017.8078517; Layne R., 2017, P IEEE C COMP VIS PA, P47; Leal-Taixe Laura, 2017, ARXIV170402781; Lee C, 2019, ICCAD-IEEE ACM INT; Lee S, 2019, IEEE ACCESS, V7, P8181, DOI 10.1109/ACCESS.2018.2889442; Lee SH, 2018, IEEE ACCESS, V6, P67316, DOI 10.1109/ACCESS.2018.2879535; Leichter I, 2013, IEEE T PATTERN ANAL, V35, P2553, DOI 10.1109/TPAMI.2013.70; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu QK, 2019, IEEE ACCESS, V7, P76489, DOI 10.1109/ACCESS.2019.2921975; Luiten J, 2019, IEEE INT CONF COMP V, P709, DOI 10.1109/ICCVW.2019.00088; Luiten J, 2020, IEEE ROBOT AUTOM LET, V5, P1803, DOI 10.1109/LRA.2020.2969183; Milan A., 2016, MOT16 BENCHMARK MULT; Milan A, 2013, IEEE COMPUT SOC CONF, P735, DOI 10.1109/CVPRW.2013.111; Naphade M, 2017, 2017 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTED, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI); Nghiem AT, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P476, DOI 10.1109/AVSS.2007.4425357; Rahmathullah A.S., 2016, ARXIV160501177; REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177; Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sanchez-Matilla R, 2019, IEEE IMAGE PROC, P2189, DOI 10.1109/ICIP.2019.8803140; Sanchez-Matilla R, 2016, LECT NOTES COMPUT SC, V9914, P84, DOI 10.1007/978-3-319-48881-3_7; Sheng H., 2018, IEEE T CIRCUITS SYST; SINGER RA, 1974, IEEE T INFORM THEORY, V20, P423, DOI 10.1109/TIT.1974.1055256; Smith K., 2005, COMP VIS PATT REC WO, P36, DOI DOI 10.1109/CVPR.2005.453; SMITH P, 1975, IEEE T AUTOMAT CONTR, VAC20, P101, DOI 10.1109/TAC.1975.1100851; Song Y., 2016, P IEEE INT C CONS EL, P1, DOI DOI 10.1109/ICVES.2016.7548171; STEIN JJ, 1975, IEEE T AERO ELEC SYS, V11, P1207, DOI 10.1109/TAES.1975.308178; Stiefelhagen R, 2007, LECT NOTES COMPUT SC, V4122, P1; Sun P, 2020, PROC CVPR IEEE, P2443, DOI 10.1109/CVPR42600.2020.00252; Voigtlaender P, 2019, PROC CVPR IEEE, P7934, DOI 10.1109/CVPR.2019.00813; Waibel A, 2009, HUM-COMPUT INT-SPRIN, P3, DOI 10.1007/978-1-84882-054-8_1; Wang GA, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P482, DOI 10.1145/3343031.3350853; Wang XY, 2020, PROC CVPR IEEE, P3265, DOI 10.1109/CVPR42600.2020.00333; Wen LY, 2020, COMPUT VIS IMAGE UND, V193, DOI 10.1016/j.cviu.2020.102907; Wu B., 2006, 2006 IEEE COMP SOC C, V1, P951, DOI [10.1109/CVPR.2006.312, DOI 10.1109/CVPR.2006.312]; Wu C, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (CIT), P1, DOI 10.1109/CIT.2017.11; Xing J., 2014, ARXIV PREPRINT ARXIV; Xu JR, 2019, IEEE I CONF COMP VIS, P3987, DOI 10.1109/ICCV.2019.00409; Yang LJ, 2019, IEEE I CONF COMP VIS, P5187, DOI 10.1109/ICCV.2019.00529; Yoon K, 2020, IEEE ACCESS, V8, P38060, DOI 10.1109/ACCESS.2020.2975912; Yoon YC, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P91; Young D. P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P317; Yu F, 2020, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR42600.2020.00271; YU SI, 2016, PROC CVPR IEEE, P3871, DOI DOI 10.1109/CVPR.2016.420; Zhu P., 2020, ABS200106303 CORR, P1	89	74	74	5	22	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	FEB	2021	129	2					548	578		10.1007/s11263-020-01375-2	http://dx.doi.org/10.1007/s11263-020-01375-2		OCT 2020	31	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	QH2HF	33642696	Green Published, hybrid, Green Submitted			2022-12-18	WOS:000576696300001
J	Lee, YJ; Grauman, K				Lee, Yong Jae; Grauman, Kristen			Predicting Important Objects for Egocentric Video Summarization	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Egocentric vision; Video summarization; Category discovery; Saliency detection	ATTENTION	We present a video summarization approach for egocentric or "wearable" camera data. Given hours of video, the proposed method produces a compact storyboard summary of the camera wearer's day. In contrast to traditional keyframe selection techniques, the resulting summary focuses on the most important objects and people with which the camera wearer interacts. To accomplish this, we develop region cues indicative of high-level saliency in egocentric video-such as the nearness to hands, gaze, and frequency of occurrence-and learn a regressor to predict the relative importance of any new region based on these cues. Using these predictions and a simple form of temporal event detection, our method selects frames for the storyboard that reflect the key object-driven happenings. We adjust the compactness of the final summary given either an importance selection criterion or a length budget; for the latter, we design an efficient dynamic programming solution that accounts for importance, visual uniqueness, and temporal displacement. Critically, the approach is neither camera-wearer-specific nor object-specific; that means the learned importance metric need not be trained for a given user or context, and it can predict the importance of objects and people that have never been seen previously. Our results on two egocentric video datasets show the method's promise relative to existing techniques for saliency and summarization.	[Lee, Yong Jae] Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA; [Grauman, Kristen] Univ Texas Austin, Dept Comp Sci, Austin, TX 78712 USA	University of California System; University of California Davis; University of Texas System; University of Texas Austin	Lee, YJ (corresponding author), Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA.	yjlee@cs.ucdavis.edu; grauman@cs.utexas.edu						Aghazadeh O., 2011, CVPR; Alexe B., 2010, CVPR; Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143; Carreira J., 2010, CVPR; Caspi Y, 2006, VISUAL COMPUT, V22, P642, DOI 10.1007/s00371-006-0046-y; Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414; Clarkson B., 1999, ICASSP; Doherty A., 2008, INT C COMP INF TECHN; Doherty A., 2008, CIVR; Endres I., 2010, ECCV; Fathi A., 2011, ICCV; Fathi Alircza, 2012, CVPR; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; GAO D, 2007, NIPS; Goldman D., 2006, SIGGRAPH; Healey J., 1998, WEARABLE COMPUTERS; Hodges S., 2006, UBICOMP; Hodges S, 2011, MEMORY, V19, P685, DOI 10.1080/09658211.2011.605591; Huynh T., 2008, UBICOMP; Hwang S. J., 2010, BMVC; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Jojic N., 2010, NIPS; Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198; Kitani K. M., 2011, CVPR; Kolsch M., 2004, FG; Lee M., 2007, ACM SIGACCESS C COMP; Lee Y. J., 2012, CVPR; Lee Y. J., 2011, ICCV; Li C., 2013, P IEEE C COMP VIS PA; Li Y., 2013, ICCV; Lin Wei-Hao, 2006, IS T SPIE S EL IM; Liu D., 2009, TPAMI; Liu T., 2002, ECCV; Liu T., 2007, CVPR; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu Z., 2013, CVPR; Mann S., 1998, WEARABLE COMPUTERS; Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002; Ng H. W., 2002, ICME; Perona P., 1998, ECCV; Pirsiavash H., 2012, CVPR; Pritch Yael, 2007, ICCV; Rav-Acha A, 2006, MAKING LONG VIDEO SH, DOI [10.1109/CVPR.2006.179, DOI 10.1109/CVPR.2006.179]; Ren Xiaofeng, 2010, CVPR; Ryoo M. S., 2013, CVPR; Simakov Denis, 2008, CVPR; Spain M., 2008, ECCV; Spriggs E., 2009, CVPR WORKSH EG VIS; Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811; Starner T., 1998, ISWC; Viola P., 2001, P 2001 IEEE COMP SOC, pI, DOI [10.1109/CVPR.2001.990517, DOI 10.1109/CVPR.2001.990517]; Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001; Weng F., 2009, ICME; Wolf W, 1996, ICASSP; Zhang H. J, 1997, PATTERN RECOGNITION; [No title captured]	56	74	76	1	18	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2015	114	1					38	55		10.1007/s11263-014-0794-5	http://dx.doi.org/10.1007/s11263-014-0794-5			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	CO1UF		Green Submitted			2022-12-18	WOS:000358940300003
J	Hoffman, J; Rodner, E; Donahue, J; Kulis, B; Saenko, K				Hoffman, Judy; Rodner, Erik; Donahue, Jeff; Kulis, Brian; Saenko, Kate			Asymmetric and Category Invariant Feature Transformations for Domain Adaptation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Object recognition; Domain adaptation; Transformation learning		We address the problem of visual domain adaptation for transferring object models from one dataset or visual domain to another. We introduce a unified flexible model for both supervised and semi-supervised learning that allows us to learn transformations between domains. Additionally, we present two instantiations of the model, one for general feature adaptation/alignment, and one specifically designed for classification. First, we show how to extend metric learning methods for domain adaptation, allowing for learning metrics independent of the domain shift and the final classifier used. Furthermore, we go beyond classical metric learning by extending the method to asymmetric, category independent transformations. Our framework can adapt features even when the target domain does not have any labeled examples for some categories, and when the target and source features have different dimensions. Finally, we develop a joint learning framework for adaptive classifiers, which outperforms competing methods in terms of multi-class accuracy and scalability. We demonstrate the ability of our approach to adapt object recognition models under a variety of situations, such as differing imaging conditions, feature types, and codebooks. The experiments show its strong performance compared to previous approaches and its applicability to large-scale scenarios.	[Hoffman, Judy; Donahue, Jeff] Univ Calif Berkeley, Berkeley, CA 94704 USA; [Rodner, Erik] Univ Jena, Jena, Germany; [Kulis, Brian] Ohio State Univ, Columbus, OH 43210 USA; [Saenko, Kate] Univ Massachusetts, Lowell, MA USA	University of California System; University of California Berkeley; Friedrich Schiller University of Jena; University System of Ohio; Ohio State University; University of Massachusetts System; University of Massachusetts Lowell	Hoffman, J (corresponding author), Univ Calif Berkeley, Berkeley, CA 94704 USA.	jhoffman@eecs.berkeley.edu; erik.rodner@uni-jena.de; jdonahue@cs.berkeley.edu; kulis@cse.ohio-state.edu; saenko@cs.uml.edu						[Anonymous], 2007, P 15 ACM INT C MULTI; Argyriou A, 2010, J MACH LEARN RES, V11, P935; Aytar Y, 2011, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2011.6126504; Ben-David Shai, 2007, NEURIPS, P7; Bergamo A., 2010, ADV NEURAL INFORM PR, P181; Blitzer J., P 45 ANN M ASS COMP, P440, DOI DOI 10.1109/IRPS.2011.5784441; Chopra S., 2013, ICML WORKSHOP CHALLE, DOI DOI 10.5555/3045118.3045244; Dai W., 2008, NIPS, P353; Daume III Hal, 2007, P 45 ANN M ASS COMP, P256, DOI DOI 10.48550/ARXIV.0907.1815; Diethe T, 2010, LECT NOTES ARTIF INT, V6321, P328, DOI 10.1007/978-3-642-15880-3_27; Donahue J, 2014, PR MACH LEARN RES, V32; Donahue J, 2013, PROC CVPR IEEE, P668, DOI 10.1109/CVPR.2013.92; Duan L., 2012, P INT C MACH LEARN, V1, P711; Duan LX, 2012, IEEE T PATTERN ANAL, V34, P1667, DOI 10.1109/TPAMI.2011.265; Duan LX, 2009, PROC CVPR IEEE, P1375, DOI [10.1109/CVPR.2009.5206747, 10.1109/CVPRW.2009.5206747]; Farhadi A, 2008, LECT NOTES COMPUT SC, V5302, P154, DOI 10.1007/978-3-540-88682-2_13; Farquhar JDR, 2005, ADV NEURAL INFORM PR, P355, DOI 10.5555/2976248.2976293; Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911; Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344; Hoffman Judy, 2013, ARXIV13013224; Jhuo IH, 2012, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2012.6247924; Jiang J., 2008, LIT SURV DOMAIN ADAP; Jiang W, 2008, IEEE IMAGE PROC, P161, DOI 10.1109/ICIP.2008.4711716; Kan MN, 2012, LECT NOTES COMPUT SC, V7572, P808, DOI 10.1007/978-3-642-33718-5_58; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702; Kulis B, 2009, IEEE T PATTERN ANAL, V31, P2143, DOI 10.1109/TPAMI.2009.151; Li RN, 2012, PROC CVPR IEEE, P2855, DOI 10.1109/CVPR.2012.6248011; Li X., 2007, THESIS U WASHINGTON; Quadrianto N., 2011, P 28 INT C MACHINE L; Rodner  E., 2013, ABS13084200 CORR; Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16; Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; Zhai, 2007, ANN M ASS COMP LING, P264, DOI [DOI 10.1145/1273496.1273558, DOI 10.1039/B610011B]	36	74	74	1	19	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2014	109	1-2			SI		28	41		10.1007/s11263-014-0719-3	http://dx.doi.org/10.1007/s11263-014-0719-3			14	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AI7QY					2022-12-18	WOS:000337091700003
J	Su, Y; Jurie, F				Su, Yu; Jurie, Frederic			Improving Image Classification Using Semantic Attributes	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Image classification; Bag-of-words model; Semantic attribute; Visual words disambiguation		The Bag-of-Words (BoW) model-commonly used for image classification-has two strong limitations: on one hand, visual words are lacking of explicit meanings, on the other hand, they are usually polysemous. This paper proposes to address these two limitations by introducing an intermediate representation based on the use of semantic attributes. Specifically, two different approaches are proposed. Both approaches consist in predicting a set of semantic attributes for the entire images as well as for local image regions, and in using these predictions to build the intermediate level features. Experiments on four challenging image databases (PASCAL VOC 2007, Scene-15, MSRCv2 and SUN-397) show that both approaches improve performance of the BoW model significantly. Moreover, their combination achieves the state-of-the-art results on several of these image databases.	[Su, Yu; Jurie, Frederic] Univ Caen, GREYC CNRS UMR6072, F-14032 Caen, France	Centre National de la Recherche Scientifique (CNRS); Universite de Caen Normandie	Su, Y (corresponding author), Univ Caen, GREYC CNRS UMR6072, F-14032 Caen, France.	yu.su@unicaen.fr; frederic.jurie@unicaen.fr			OSEO, French State agency for innovation	OSEO, French State agency for innovation	This work was partly realized under the Quaero Programme, funded by OSEO, French State agency for innovation.	Bosch A., 2006, ECCV; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646; Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678; Delaitre V., 2010, BMVC, DOI DOI 10.5244/C.24.97; Deselaers T., 2011, CVPR; Everingham M., 2007, PASCAL VISUAL OBJECT, DOI DOI 10.1007/S11263-014-0733-5; Farhadi Ali, 2009, CVPR; Fei-Fei L, 2005, PROC CVPR IEEE, P524; Gehler P. V., 2009, ICCV; Griffin Gregory, 2007, CALTECH 256 OBJECT C; Harzallah H, 2009, IEEE I CONF COMP VIS, P237, DOI 10.1109/ICCV.2009.5459257; Hofmann T., 1999, P UNC ART INT; Ji R., 2010, CVPR; jia Li L., 2010, NIPS, DOI [10.1184/R1/6475985.v1, DOI 10.1184/R1/6475985.V1]; Khan F. S., 2009, ICCV; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250; Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; Li L.J., 2010, CVPR; Liu JG, 2009, PROC CVPR IEEE, P1996; MOOSMANN F, 2007, NIPS; Morioka N., 2010, ECCV; Perronnin F, 2010, PROC CVPR IEEE, P3384, DOI 10.1109/CVPR.2010.5540009; ROSCH E, 1976, COGNITIVE PSYCHOL, V8, P382, DOI 10.1016/0010-0285(76)90013-X; Saghafi B., 2010, BMVC; Sivic J, 2005, IEEE I CONF COMP VIS, P370; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Sivic J., 2008, CVPR; Su Y., 2010, BMVC; Su Y., 2011, VISUAL WORD DISAMBIG; Torresani L, 2010, LECT NOTES COMPUT SC, V6311, P776, DOI 10.1007/978-3-642-15549-9_56; Ullah M.M., 2010, BMVC; van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132; Vogel J, 2007, INT J COMPUT VISION, V72, P133, DOI 10.1007/s11263-006-8614-1; Wang G., 2009, ICCV; Winn J, 2005, IEEE I CONF COMP VIS, P1800; Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970; Yang JJ, 2009, IEEE I CONF COMP VIS, P436, DOI 10.1109/ICCV.2009.5459172; Yuan J, 2007, PROC CVPR IEEE, P1930, DOI 10.1109/CVPR.2007.383222; Zhang Y., 2009, CVPR; Zheng Y., 2008, CVPR; Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11	45	74	81	0	28	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	OCT	2012	100	1					59	77		10.1007/s11263-012-0529-4	http://dx.doi.org/10.1007/s11263-012-0529-4			19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	962SH		Green Submitted			2022-12-18	WOS:000305564800004
J	Nir, T; Bruckstein, AM; Kimmel, R				Nir, Tal; Bruckstein, Alfred M.; Kimmel, Ron			Over-parameterized variational optical flow	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	Conference on Computer Vision and Pattern Recognition	JUN 20-25, 2005	San Diego, CA	IEEE Comp Soc		optical flow; variational methods; L-1 regularization; over-parametrization	MOTION; SEGMENTATION; COMPUTATION; FORMULATION	A novel optical flow estimation process based on a spatio-temporal model with varying coefficients multiplying a set of basis functions at each pixel is introduced. Previous optical flow estimation methodologies did not use such an over parameterized representation of the flow field as the problem is ill-posed even without introducing any additional parameters: Neighborhood based methods of the Lucas-Kanade type determine the flow at each pixel by constraining the flow to be described by a few parameters in small neighborhoods. Modern variational methods represent the optic flow directly via the flow field components at each pixel. The benefit of over-parametrization becomes evident in the smoothness term, which instead of directly penalizing for changes in the optic flow, accumulates a cost of deviating from the assumed optic flow model. Our proposed method is very general and the classical variational optical flow techniques are special cases of it, when used in conjunction with constant basis functions. Experimental results with the novel flow estimation process yield significant improvements with respect to the best results published so far.	[Nir, Tal; Bruckstein, Alfred M.; Kimmel, Ron] Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Technion Israel Institute of Technology	Nir, T (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	taln@cs.technion.ac.il; freddy@cs.technion.ac.il; ron@cs.technion.ac.il		Bruckstein, Alfred/0000-0001-5669-0037				ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; AMAIZ T, 2007, PATTERN RECOGN, V40, P2496; AMIAZ T, 2005, P ICIP 2005 GEN IT S, V3, P1264; ARI RB, 2006, P IEEE C COMP VIS PA, V1, P529; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; BLACK MJ, 1991, P 1991 IEEE COMP SOC, P292; Borzi A, 2002, SIAM J SCI COMPUT, V24, P818, DOI 10.1137/S1064827501386481; Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3; Brox T, 2006, LECT NOTES COMPUT SC, V3951, P471; Bruhn A, 2005, INT J COMPUT VISION, V61, P211, DOI 10.1023/B:VISI.0000045324.43199.43; Cremers D, 2005, INT J COMPUT VISION, V62, P249, DOI 10.1007/s11263-005-4882-4; DERICHE R, 1995, P 2 AS C COMP VIS AC, V2, P290; Farneback G, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P171, DOI 10.1109/ICCV.2001.937514; Farneback G, 2000, INT C PATT RECOG, P135; Govindu VM, 2006, LECT NOTES COMPUT SC, V3953, P177, DOI 10.1007/11744078_14; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Irani M., 1993, Computer Analysis of Images and Patterns. 5th International Conference, CAIP '93 Proceedings, P371; Irani M, 1997, IEEE T PATTERN ANAL, V19, P268, DOI 10.1109/34.584105; Ju SX, 1996, PROC CVPR IEEE, P307, DOI 10.1109/CVPR.1996.517090; Liu HY, 2003, IEEE T IMAGE PROCESS, V12, P1170, DOI 10.1109/TIP.2003.815296; Lucas B.D., 1981, ITERATIVE IMAGE REGI, P674; Memin E, 2002, INT J COMPUT VISION, V46, P129, DOI 10.1023/A:1013539930159; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; NAGEL HH, 1990, LECT NOTES COMPUT SC, V427, P139; NIR T, 2005, CIS200503; Papenberg N, 2006, INT J COMPUT VISION, V67, P141, DOI 10.1007/s11263-005-3960-y; ROTH S, 2005, P IEEE INT C COMP VI, V1, P42; Sekkati H, 2006, COMPUT VIS IMAGE UND, V103, P89, DOI 10.1016/j.cviu.2005.11.002; SEKKATI H, 2003, P ICIAP 03; Szeliski R, 1997, INT J COMPUT VISION, V22, P199, DOI 10.1023/A:1007996332012; Vazquez C, 2006, IEEE T PATTERN ANAL, V28, P782, DOI 10.1109/TPAMI.2006.97; Weickert J, 2001, J MATH IMAGING VIS, V14, P245, DOI 10.1023/A:1011286029287	33	74	79	2	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	FEB	2008	76	2					205	216		10.1007/s11263-007-0051-2	http://dx.doi.org/10.1007/s11263-007-0051-2			12	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	255VH					2022-12-18	WOS:000252685400009
J	Okatani, T; Deguchi, K				Okatani, Takayuki; Deguchi, Koichiro			On the Wiberg algorithm for matrix factorization in the presence of missing components	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						matrix factorization; singular value decomposition; principal component analysis with missing data (PCAMD); structure from motion; numerical algorithm	MOTION	This paper considers the problem of factorizing a matrix with missing components into a product of two smaller matrices, also known as principal component analysis with missing data (PCAMD). The Wiberg algorithm is a numerical algorithm developed for the problem in the community of applied mathematics. We argue that the algorithm has not been correctly understood in the computer vision community. Although there are many studies in our community, almost every one of which refers to the Wiberg study, as far as we know, there is no literature in which the performance of the Wiberg algorithm is investigated or the detail of the algorithm is presented. In this paper, we present derivation of the algorithm along with a problem in its implementation that needs to be carefully considered, and then examine its performance. The experimental results demonstrate that the Wiberg algorithm shows a considerably good performance, which should contradict the conventional view in our community, namely that minimization-based algorithms tend to fail to converge to a global minimum relatively frequently. The performance of the Wiberg algorithm is such that even starting with random initial values, it converges in most cases to a correct solution, even when the matrix has many missing components and the data are contaminated with very strong noise. Our conclusion is that the Wiberg algorithm can also be used as a standard algorithm for the problems of computer vision.	Tohoku Univ, Grad Sch Informat Sci, Sendai, Miyagi 9808579, Japan	Tohoku University	Okatani, T (corresponding author), Tohoku Univ, Grad Sch Informat Sci, Aramaki Aza Aoba 6-6-1, Sendai, Miyagi 9808579, Japan.	okatani@fractal.is.tohoku.ac.jp	Okatani, Takayuki/AAE-3339-2019					Belhumeur PN, 1998, INT J COMPUT VISION, V28, P245, DOI 10.1023/A:1008005721484; BUCHANAN AM, 2004, INVESTIGATION MATRIX; BUCHANAN AM, 2005, P IEEE COMP VIS PATT; Chen P, 2004, IEEE T PATTERN ANAL, V26, P1051, DOI 10.1109/TPAMI.2004.52; EPSTEIN R, 1996, SPRINGER LECT NOTES, V1144, P179; HAYAKAWA H, 1994, J OPT SOC AM A, V11, P3079, DOI 10.1364/JOSAA.11.003079; Jacobs DW, 2001, COMPUT VIS IMAGE UND, V82, P57, DOI 10.1006/cviu.2001.0906; RUHE A, 1980, SIAM REV, V22, P318, DOI 10.1137/1022057; SHUM H, 1995, IEEE T PATTERN ANAL, V17, P855; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Wiberg T, 1976, P 2 S COMP STAT, P229	11	74	85	0	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2007	72	3					329	337		10.1007/s11263-006-9785-5	http://dx.doi.org/10.1007/s11263-006-9785-5			9	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	133MW					2022-12-18	WOS:000244018000006
J	Kimia, BB; Frankel, I; Popescu, AM				Kimia, BB; Frankel, I; Popescu, AM			Euler spiral for shape completion	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							FORM	In this paper we address the curve completion problem, e.g., the geometric continuation of boundaries of objects which are temporarily interrupted by occlusion. Also known as the gap completion or shape completion problem, this problem is a significant element of perceptual grouping of edge elements and has been approached by using cubic splines or biarcs which minimize total curvature squared (elastica), as motivated by a physical analogy. Our approach is motivated by railroad design methods of the early 1900's which connect two rail segments by "transition curves", and by the work of Knuth on mathematical typography. We propose that in using an energy minimizing solution completion curves should not penalize curvature as in elastica but curvature variation. The minimization of total curvature variation leads to an Euler Spiral solution, a curve whose curvature varies linearly with arclength. The construction of this curve from a pair of points and tangents at these points is reduced to a nonlinear system of equations involving Fresnel Integrals, whose solution relies on optimization from a suitable initial condition constrained to satisfy given boundary conditions. Since the choice of an appropriate initial curve is critical in this optimization, we analytically derive an optimal solution in the class of biarc curves, which is then used as the initial curve. The resulting interpolations yield intuitive interpolation across gaps and occlusions, and are extensible, in contrast to scale invariant elastica. In addition, Euler Spiral segments can be used in other applications of curve completions, e.g., modeling boundary segments between curvature extrema or skeletal branch geometry.										Abramowitz M., 1972, HDB MATH FUNCTIONS F; Ahlberg J.H., 1967, THEORY SPLINES THEIR; BALDWIN A, 1996, TEARDROP CLOTHOID LO; BIRKHOFF G, 1965, APPROXIMATIONS FUNCT; Brady M, 1980, AAAI, P15; BRYANT R, 1986, AM J MATH, V108, P525, DOI 10.2307/2374654; CESARO E, 1886, NOUVELLES ANN MATH, V3, P511; COMU A, 1874, J PHYSIQUE THEORIQUE; DHANDAPANI R, IN PRESS P IEEE INT; Euler L., 1744, METHODUS INVENIENDI; Farin G, 1996, COMPUTER SCI SCI COM; GROSSBERG S, 1985, PSYCHOL REV, V92, P173, DOI 10.1037/0033-295X.92.2.173; GUY G, 1992, INT C PATT REC HAG N, P99; HERAULT L, 1993, IEEE T PATTERN ANAL, V15, P899, DOI 10.1109/34.232076; HIGGINS A, 1921, TRANSITION SPIRAL IT; HOFFMAN DD, 1984, COGNITION, V18, P65, DOI 10.1016/0010-0277(84)90022-2; HOM BKP, 1983, ACM T MATH SOFTWARE, V9, P442; JOHANNES MS, 2001, WORKSH PERC ORG COMP, P41; KANIZSA G, 1979, ORG VISION ESSAYS; KNUTH DE, 1979, B AM MATH SOC, V1, P337, DOI 10.1090/S0273-0979-1979-14598-1; KURTZ C, 1945, TRACK TURNOUT ENG; LEONARD IE, 1988, AM MATH MON, V95, P431, DOI 10.2307/2322478; Love A.E.H., 1892, NATURE; Mumford D., 1994, ALGEBRAIC GEOMETRY I, V5681, P491, DOI DOI 10.1007/978-1-4612-2628-4_31; Nitzberg M., 1993, FILTERING SEGMENTATI; ONN R, 1990, INT J COMPUT VISION, V5, P105, DOI 10.1007/BF00056773; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; Press WH., 1993, NUMERICAL RECIPES C; RUTKOWSKI WS, 1979, COMPUT VISION GRAPH, V9, P89, DOI 10.1016/0146-664X(79)90086-8; SARKAR S, 1992, CVPR92, P251; SHAASHUA A, 1988, 2 INT C COMP VIS TAM; SHARON E, IN PRESS COMPLETION; SIDDIQI K, 1995, IEEE T PATTERN ANAL, V17, P239, DOI 10.1109/34.368189; SOKOLNIKOFF JS, 1956, MATH THEORY ELASTICI; Spanier J., 1987, ATLAS FUNCTIONS; Talbot A. N, 1927, RAILWAY TRANSITION S; ULLMAN S, 1976, BIOL CYBERN, V25, P1; WEISS I, 1988, COMPUT VISION GRAPH, V41, P80, DOI 10.1016/0734-189X(88)90118-1; WEISSTEIN EW, 1998, FRENCH CURVE; WILLIAMS L, 1998, ECCV98, V1407, P432; Williams LR, 1999, INT J COMPUT VISION, V34, P81, DOI 10.1023/A:1008187804026; Williams LR, 1997, NEURAL COMPUT, V9, P837, DOI 10.1162/neco.1997.9.4.837; WILLIAMS LR, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P408, DOI 10.1109/ICCV.1995.466910; 1918, AM MATH MONTHLY, V25	44	74	74	0	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG-SEP	2003	54	1-2					157	180		10.1023/A:1023713602895	http://dx.doi.org/10.1023/A:1023713602895			24	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	678EA					2022-12-18	WOS:000182851000008
J	Sidenbladh, H; Black, MJ				Sidenbladh, H; Black, MJ			Learning the statistics of people in images and video	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							TRACKING; RECOGNITION; MODEL	This paper address the problems of modeling the appearance of humans and distinguishing human appearance from the appearance of general scenes. We seek a model of appearance and motion that is generic in that it accounts for the ways in which people's appearance varies and, at the same time, is specific enough to be useful for tracking people in natural scenes. Given a 3D model of the person projected into an image we model the likelihood of observing various image cues conditioned on the predicted locations and orientations of the limbs. These cues are taken to be steered filter responses corresponding to edges, ridges, and motion-compensated temporal differences. Motivated by work on the statistics of natural scenes, the statistics of these filter responses for human limbs are learned from training images containing hand-labeled limb regions. Similarly, the statistics of the filter responses in general scenes are learned to define a "background" distribution. The likelihood of observing a scene given a predicted pose of a person is computed, for each limb, using the likelihood ratio between the learned foreground (person) and background distributions. Adopting a Bayesian formulation allows cues to be combined in a principled way. Furthermore, the use of learned distributions obviates the need for hand-tuned image noise models and thresholds. The paper provides a detailed analysis of the statistics of how people appear in scenes and provides a connection between work on natural image statistics and the Bayesian tracking of people.	Brown Univ, Dept Comp Sci, Providence, RI 02912 USA; KTH, Dept Numer Anal & Comp Sci, Computat Vis & Act Percept Lab, SE-10044 Stockholm, Sweden	Brown University; Royal Institute of Technology	Sidenbladh, H (corresponding author), Swedish Def Res Agcy, FOI, Dept Data & Informat Fus, SE-17290 Stockholm, Sweden.	hedvig@nada.kth.se; black@cs.brown.edu						Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581; CHAM TJ, 1999, IEEE C COMP VIS PATT, V1, P239; Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761; Darrell T, 2000, INT J COMPUT VISION, V37, P175, DOI 10.1023/A:1008103604354; DeCarlo D, 1996, PROC CVPR IEEE, P231, DOI 10.1109/CVPR.1996.517079; Deutscher J, 2000, PROC CVPR IEEE, P126, DOI 10.1109/CVPR.2000.854758; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; GAVRILA DM, 1996, THESIS U MARYLAND CO; Geman D, 1996, IEEE T PATTERN ANAL, V18, P1, DOI 10.1109/34.476006; Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683; HOGG D, 1983, IMAGE VISION COMPUT, V1, P5, DOI DOI 10.1016/0262-8856(83)90003-3; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Jepson AD, 2001, PROC CVPR IEEE, P415; Ju SX, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P38, DOI 10.1109/AFGR.1996.557241; KALIATH T, 1951, IEEE T COMMUN, V15, P52; Konishi S., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P573, DOI 10.1109/CVPR.1999.786996; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Lee AB, 2001, INT J COMPUT VISION, V41, P35, DOI 10.1023/A:1011109015675; Lindeberg T, 1998, INT J COMPUT VISION, V30, P117, DOI 10.1023/A:1008097225773; Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897; Nestares O, 2001, PROC CVPR IEEE, P358; Olshausen BA, 1996, NETWORK-COMP NEURAL, V7, P333, DOI 10.1088/0954-898X/7/2/014; Ormoneit D, 2001, ADV NEUR IN, V13, P894; Rasmussen C, 2001, IEEE T PATTERN ANAL, V23, P560, DOI 10.1109/34.927458; REHG JM, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P612, DOI 10.1109/ICCV.1995.466882; RITTSCHER J, 2000, ECCV, P336; ROHR K, 1994, CVGIP-IMAG UNDERSTAN, V59, P94, DOI 10.1006/ciun.1994.1006; ROHR K, 1997, MOTION BASED RECOGNI, P171; RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006; Ruderman DL, 1997, VISION RES, V37, P3385, DOI 10.1016/S0042-6989(97)00008-4; Sidenbladh H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P709, DOI 10.1109/ICCV.2001.937696; SIDENBLADH H, 2000, INT C AUT FAC GEST R, P368; Sidenbladh H., 2002, EUR C COMP VIS ECCV; Sidenbladh H., 2000, LNCS, V2, P702; SIDENBLADH H, 2001, TRITANA0114; Simoncelli Eero, 1997, AS C SIGN SYST COMP; SIMONCELLI EP, 1991, IEEE C COMP VIS PATT, P310, DOI 10.1109/CVPR.1991.139707; Sminchisescu C, 2001, PROC CVPR IEEE, P447; Sullivan J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1068, DOI 10.1109/ICCV.1999.790391; SULLIVAN J, 2000, ECCV, V2, P307; Wachter S, 1999, COMPUT VIS IMAGE UND, V74, P174, DOI 10.1006/cviu.1999.0758; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236; Yacoob Y, 1999, COMPUT VIS IMAGE UND, V73, P232, DOI 10.1006/cviu.1998.0726; Zhu SC, 1997, IEEE T PATTERN ANAL, V19, P1236, DOI 10.1109/34.632983	49	74	76	0	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG-SEP	2003	54	1-2					181	207		10.1023/A:1023765619733	http://dx.doi.org/10.1023/A:1023765619733			27	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	678EA					2022-12-18	WOS:000182851000009
J	Toyama, K; Blake, A				Toyama, K; Blake, A			Probabilistic tracking with exemplars in a metric space	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						probabilistic tracking; exemplar-based tracking		A new, exemplar-based, probabilistic paradigm for visual tracking is presented. Probabilistic mechanisms are attractive because they handle fusion of information, especially temporal fusion, in a principled manner. Exemplars are selected representatives of raw training data, used here to represent probabilistic mixture distributions of object configurations. Their use avoids tedious hand-construction of object models, and problems with changes of topology. Using exemplars in place of a parameterized model poses several challenges, addressed here with what we call the "Metric Mixture" (M-2) approach, which has a number of attractions. Principally, it provides alternatives to standard learning algorithms by allowing the use of metrics that are not embedded in a vector space. Secondly, it uses a noise model that is learned from training data. Lastly, it eliminates any need for an assumption of probabilistic pixelwise independence. Experiments demonstrate the effectiveness of the M-2 model in two domains: tracking walking people using "chamfer" distances on binary edge images, and tracking mouth movements by means of a shuffle distance.	Microsoft Corp, Res, Redmond, WA 98052 USA; Microsoft Res Ltd, Cambridge, England	Microsoft; Microsoft	Toyama, K (corresponding author), Microsoft Corp, Res, Redmond, WA 98052 USA.	kentoy@microsoft.com; ablake@microsoft.com		Toyama, Kentaro/0000-0002-9128-2255				AMINI AA, 1988, P 2 INT C COMP VIS, P95; Bartels RH, 1987, INTRO SPLINES USE CO; BASCLE B, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P302, DOI 10.1109/ICCV.1995.466925; BLACK MJ, 1996, P EUR C COMP VIS, P329; Blake A., 1998, ACTIVE CONTOURS, DOI [10.1007/978-1-4471-1555-7, DOI 10.1007/978-1-4471-1555-7]; Brand M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1237, DOI 10.1109/ICCV.1999.790422; COOTES TF, 1998, P EUR C COMP VIS, V2, P484; Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; FREEMAN WT, 1999, ADV NEURAL INFORMATI, V11; FREY B, 2000, P C UNC ART INT; GAVRILA DM, 1999, P IEEE INT C COMP VI, P87, DOI DOI 10.1109/ICCV.1999.791202; Gelb A., 1974, APPL OPTIMAL ESTIMAT; HAGER G, 1996, P 4 EUR C COMP VIS, P507; HUTTENLOCHER DP, 1993, P 4 INT C COMP VIS, P93; ISARD M, 1996, P EUR C COMP VIS, P343; KASS M, 1987, P 1 INT C COMP VIS, V1, P259; KUTULAKOS K, 2000, P EUR C COMP VIS, V1, P67; Mumford D., 1996, PERCEPTION BAYESIAN, P25; NEVEN H, 2000, SIGGRAPH DEMO SESSIO; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Ripley BD., 1996; STORVIK G, 1994, IEEE T PATTERN ANAL, V16, P976, DOI 10.1109/34.329011; Terzopoulos D., 1992, ACTIVE VISION, P3; VETTER T, 1996, P 4 EUR C COMP VIS C, P652; WEI LY, 2000, P ACM SIGGR ACM NEW	27	74	75	0	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2002	48	1					9	19		10.1023/A:1014899027014	http://dx.doi.org/10.1023/A:1014899027014			11	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	534UM					2022-12-18	WOS:000174606100003
J	ROHR, K				ROHR, K			RECOGNIZING CORNERS BY FITTING PARAMETRIC MODELS	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							EDGE-DETECTION	The parametric model of a certain class of characteristic intensity variations in Rohr (1990, 1992), which is the superposition of elementary model functions, is employed to identify corners in images. Estimates of the searched model parameters characterizing completely single grey-value structures are determined by a least-squares fit of the model to the observed image intensities applying the minimization method of Levenberg-Marquardt. In particular, we develop an analytical approximation of our model in such a way that function values can be calculated without numerical integration. Assuming the blur of the imaging system to be describable by Gaussian convolution our approach permits subpixel localization of the corner position of the unblurred grey-value structures, that is, to reverse the blur of the imaging system. By fitting our model to the original as well as to the smoothed original-image cues can be obtained for finding out whether the underlying model is an adequate description or not. Results are shown for real image data.	UNIV HAMBURG,FACHBEREICH INFORMAT,ARBEITSBEREICH KOGNIT SYST,W-2000 HAMBURG 50,GERMANY	University of Hamburg								ABRAMOWITZ M., 1965, HDB MATH FUNCTIONS; BEAUDET PR, 1978, NOV P INT JOINT C PA, P579; BERGHOLM F, 1987, IEEE T PATTERN ANAL, V9, P726, DOI 10.1109/TPAMI.1987.4767980; BERGHOLM F, TRITANAP9105 ROY I T; BERGHOLM F, 1991, 10262 FRAUNH I INF D; BERZINS V, 1984, COMPUT VISION GRAPH, V27, P195, DOI 10.1016/S0734-189X(84)80043-2; BEYMER DJ, 1991, JUN P C COMP VIS PAT, P720; BRONSTEIN IN, 1981, TASCHENBUCH MATH; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; DEMICHELI E, 1989, IEEE T PATTERN ANAL, V11, P1106, DOI 10.1109/34.42841; DERICHE R, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P66; DRESCHLER L, 1982, COMPUT VISION GRAPH, V20, P199, DOI 10.1016/0146-664X(82)90081-8; DRESCHLER L, 1981, 7TH P INT JOINT C AR, P692; Forstner W., 1986, S INT SOC PHOT REM S, V26, P150; Giraudon G., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P650, DOI 10.1109/CVPR.1991.139768; GUIDUCCI A, 1988, PATTERN RECOGN LETT, V8, P311, DOI 10.1016/0167-8655(88)90080-3; HUCKEL MH, 1973, J ASSOC COMPUT MACH, V20, P634; HUECKEL MH, 1971, J ACM, V18, P113, DOI 10.1145/321623.321635; Kitchen L, 1982, PATTERN RECOGN LETT, V1, P95, DOI 10.1016/0167-8655(82)90020-4; KORN AF, 1988, IEEE T PATTERN ANAL, V10, P610, DOI 10.1109/34.6770; LI D, 1989, 5TH P ALV VIS C READ, P121; MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; NAWA VS, 1986, IEEE T PATTERN ANAL, V8, P699; NOBLE JA, 1987, 3RD P ALV VIS C CAMB, P267; POWELL MJD, 1964, COMPUT J, V7, P155, DOI 10.1093/comjnl/7.2.155; Press W. H., 1988, NUMERICAL RECIPES; RANGARAJAN K, 1989, COMPUT VISION GRAPH, V48, P230, DOI 10.1016/S0734-189X(89)80039-8; ROHR K, 1992, IMAGE VISION COMPUT, V10, P66, DOI 10.1016/0262-8856(92)90001-J; ROHR K, 1992, FBIHHM24292 U HAMB F; ROHR K, 1990, 12 DAGM S MUST, P217; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19; ZHANG W, 1991, 7TH SCAND C IM AN AA; Zuniga O. A., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P30	34	74	76	0	2	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	1992	9	3					213	230		10.1007/BF00133702	http://dx.doi.org/10.1007/BF00133702			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	KC414					2022-12-18	WOS:A1992KC41400003
J	Zaharescu, A; Boyer, E; Horaud, R				Zaharescu, Andrei; Boyer, Edmond; Horaud, Radu			Keypoints and Local Descriptors of Scalar Functions on 2D Manifolds	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						3D shape; Meshed surfaces; Riemannian manifold; Scale space; 3D keypoint detection; Local shape descriptors; Shape matching	RECOGNITION	This paper addresses the problem of describing surfaces using local features and descriptors. While methods for the detection of interest points in images and their description based on local image features are very well understood, their extension to discrete manifolds has not been well investigated. We provide a methodological framework for analyzing real-valued functions defined over a 2D manifold, embedded in the 3D Euclidean space, e.g., photometric information, local curvature, etc. Our work is motivated by recent advancements in multiple-camera reconstruction and image-based rendering of 3D objects: there is a growing need for describing object surfaces, matching two surfaces, or tracking them over time. Considering polygonal meshes, we propose a new methodological framework for the scale-space representations of scalar functions defined over such meshes. We propose a local feature detector (MeshDOG) and region descriptor (MeshHOG). Unlike the standard image features, the proposed surface features capture both the local geometry of the underlying manifold and the scale-space differential properties of the real-valued function itself. We provide a thorough experimental evaluation. The repeatability of the feature detector and the robustness of feature descriptor are tested, by applying a large number of deformations to the manifold or to the scalar function.	[Zaharescu, Andrei] Aimetis Corp, Waterloo, ON, Canada; [Boyer, Edmond; Horaud, Radu] INRIA Grenoble Rhone Alpes, Montbonnot St Martin, France		Zaharescu, A (corresponding author), Aimetis Corp, Waterloo, ON, Canada.	Andrei.Zaharescu@aimetis.com; Edmond.Boyer@inria.fr; Radu.Horaud@inria.fr	Horaud, Radu/AAR-5982-2021	Horaud, Radu/0000-0001-5232-024X				Ahmed N., 2008, P IEEE C COMP VIS PA; [Anonymous], 2010, P EUROGRAPHICS WORKS; [Anonymous], 2010, EUR WORKSH 3D OBJ RE, DOI DOI 10.2312/3DOR/3DOR10/007-014; Bariya P, 2010, PROC CVPR IEEE, P1657, DOI 10.1109/CVPR.2010.5539774; Barth T. J., 1993, LECT NOTE PHYS, P240; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Bolles R. C., 1982, INT J ROBOT RES, V1, P57; BOLLES RC, 1986, INT J ROBOT RES, V5, P3, DOI 10.1177/027836498600500301; Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405; Bustos B, 2005, ACM COMPUT SURV, V37, P345, DOI 10.1145/1118890.1118893; Cagniart C., 2010, P EUR C COMP VIS; Castellani U, 2008, COMPUT GRAPH FORUM, V27, P643, DOI 10.1111/j.1467-8659.2008.01162.x; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; de Aguiar E, 2007, LECT NOTES COMPUT SC, V4814, P1; Dong C.S., 2005, J ZHEJIANG UNIVER SC, V6, P128, DOI [10.1631/jzus.2005.AS0128, DOI 10.1631/JZUS.2005.AS0128]; Dufournaud YE, 2004, COMPUT VIS IMAGE UND, V93, P175, DOI 10.1016/j.cviu.2003.07.003; Frome A., 2004, P EUR C COMP VIS; Furukawa Y., 2008, P IEEE C COMP VIS PA; Horn RA., 1994, MATRIX ANAL; Hou T., 2010, P EUR C COMP VIS; Hua J, 2008, IEEE T VIS COMPUT GR, V14, P1643, DOI 10.1109/TVCG.2008.134; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; Kimmel R, 1998, P NATL ACAD SCI USA, V95, P8431, DOI 10.1073/pnas.95.15.8431; Klaser A, 2008, BMVC 2008, P271; Kortgen M., 2003, CENTR EUR SEM COMP G, P2; Kovnatsky A., 2011, P C SCAL SPAC VAR ME; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; LAY DC, 1996, LINEAR ALGEBRA ITS A, P50401; Lee C., 2005, P SIGGRAPH; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Luo C., 2009, P EUR S GEOM PROC; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006; MAVRIPLIS DJ, 2003, P 16 AIAA COMP FLUID; MEYER M, 2002, P VISMATH; Mian A, 2010, INT J COMPUT VISION, V89, P348, DOI 10.1007/s11263-009-0296-z; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Mukherjee S, 2010, BERNOULLI, V16, P181, DOI 10.3150/09-BEJ206; NOVATNACK J, 2007, P INT C COMP VIS; Novatnack J, 2008, LECT NOTES COMPUT SC, V5304, P440, DOI 10.1007/978-3-540-88690-7_33; Rothganger F, 2006, INT J COMPUT VISION, V66, P231, DOI 10.1007/s11263-005-3674-1; Ruggeri MR, 2010, INT J COMPUT VISION, V89, P248, DOI 10.1007/s11263-009-0250-0; SCHLATTMANN M., 2008, J WSCG, P16; Seitz S.M., 2006, P IEEE COMPUTER SOC, P519; Shilane P., 2008, SHAPE MODELING INT; Sibson R, 1981, INTERPRETING MULTIVA, P21, DOI DOI 10.1007/3-540-26772-7_8; Smith E. R., 2011, INT J COMPUTER VISIO; Starck J., 2007, P INT C COMP VIS; Sun Jian, 2009, P S GEOM PROC; Surazhsky V., 2005, P SIGGRAPH; Tangelder JWH, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P145, DOI 10.1109/SMI.2004.1314502; VARANASI K, 2008, P EUR C COMP VIS; Wong S., 2007, P INT C COMP VIS; Wu C., 2008, P IEEE C COMP VIS PA; Xu GL, 2004, GEOMETRIC MODELING AND PROCESSING 2004, PROCEEDINGS, P195; Zaharescu A, 2011, IEEE T PATTERN ANAL, V33, P823, DOI 10.1109/TPAMI.2010.116; Zaharescu A, 2009, PROC CVPR IEEE, P373, DOI 10.1109/CVPRW.2009.5206748; Zhong Y., 2009, IEEE INT C COMP VIS	59	73	75	0	31	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	OCT	2012	100	1					78	98		10.1007/s11263-012-0528-5	http://dx.doi.org/10.1007/s11263-012-0528-5			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	962SH		Green Submitted			2022-12-18	WOS:000305564800005
J	Shi, QF; Cheng, L; Wang, L; Smola, A				Shi, Qinfeng; Cheng, Li; Wang, Li; Smola, Alex			Human Action Segmentation and Recognition Using Discriminative Semi-Markov Models	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Action segmentation and recognition; Large-margin method; Semi-Markov model		A challenging problem in human action understanding is to jointly segment and recognize human actions from an unseen video sequence, where one person performs a sequence of continuous actions. In this paper, we propose a discriminative semi-Markov model approach, and define a set of features over boundary frames, segments, as well as neighboring segments. This enable us to conveniently capture a combination of local and global features that best represent each specific action type. To efficiently solve the inference problem of simultaneous segmentation and recognition, a Viterbi-like dynamic programming algorithm is utilized, which in practice is able to process 20 frames per second. Moreover, the model is discriminatively learned from large margin principle, and is formulated as an optimization problem with exponentially many constraints. To solve it efficiently, we present two different optimization algorithms, namely cutting plane method and bundle method, and demonstrate that each can be alternatively deployed in a "plug and play" fashion. From its theoretical aspect, we also analyze the generalization error of the proposed approach and provide a PAC-Bayes bound. The proposed approach is evaluated on a variety of datasets, and is shown to perform competitively to the state-of-the-art methods. For example, on KTH dataset, it achieves 95.0% recognition accuracy, where the best known result on this dataset is 93.4% (Reddy and Shah in ICCV, 2009).	[Cheng, Li] ASTAR, Bioinformat Inst, Singapore, Singapore; [Shi, Qinfeng] Univ Adelaide, Adelaide, SA, Australia; [Wang, Li] Nanjing Forestry Univ, Nanjing, Peoples R China; [Smola, Alex] Yahoo Res, Santa Clara, CA USA	Agency for Science Technology & Research (A*STAR); A*STAR - Bioinformatics Institute (BII); University of Adelaide; Nanjing Forestry University	Cheng, L (corresponding author), ASTAR, Bioinformat Inst, Singapore, Singapore.	qinfeng.shi@ieee.org; chengli@bii.a-star.edu.sg; wang.li.seu.nj@gmail.com; alex@smola.org	Cheng, Li/AAU-6734-2020; Wang, Li/G-7123-2015	Cheng, Li/0000-0003-3261-3533; Wang, Li/0000-0002-5079-8992				Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Brand M, 1997, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.1997.609450; CHENG L, 2006, IEEE INT C ADV VID S; DOLLAR P, 2005, VS PETS WORKSH; Ferguson JD, 1980, P S APPL HIDD MARK M, P143; Fox E., 2009, NIPS; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; GERMAIN P, 2009, ICML, P353; Gross R, 2001, CMURITR0118; Jhuang H., 2007, ICCV; Kale A, 2004, IEEE T IMAGE PROCESS, V13, P1163, DOI 10.1109/TIP.2004.832865; KE Y, 2005, ICCV, V1, P166; KIMELDORF G, 1971, J MATH ANAL APPL, V33, P82, DOI 10.1016/0022-247X(71)90184-3; Langford J, 2004, J MACH LEARN RES, V5, P529; LANGFORD J, 2002, NIPS, P439; LANGFORD J, 2001, ICML, P290; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lv F, 2006, LECT NOTES COMPUT SC, V3954, P359; McAllester D, 2003, LECT NOTES ARTIF INT, V2777, P203, DOI 10.1007/978-3-540-45167-9_16; McAllester D. A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P230, DOI 10.1145/279943.279989; McAllester DA, 2003, MACH LEARN, V51, P5, DOI 10.1023/A:1021840411064; Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002; Niebles JC, 2007, PROC CVPR IEEE, P1235; Nowozin S., 2007, ICCV; Ostendorf M, 1996, IEEE T SPEECH AUDI P, V4, P360, DOI 10.1109/89.536930; Phillips JA, 2002, VIS COGN, V9, P662, DOI 10.1080/13506280143000610; RATSCH G, 2006, NIPS, P1161; Reddy K. K., 2009, ICCV; Sarawagi S., 2004, ADV NEURAL INFORM PR, V17; SCHINDLER K, 2008, COMPUTER VISION PATT; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Shi Q., 2008, CVPR; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Sminchisescu C, 2005, IEEE I CONF COMP VIS, P1808; Smola A., 2007, NIPS; Taskar B, 2004, ADV NEUR IN, V16, P25; Teo C. H., 2007, KDD; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; Wang L, 2007, 2007 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN SECURITY AND DEFENSE APPLICATIONS, P1; WONG S, 2007, CVPR07, P1; Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161	42	73	80	1	13	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2011	93	1					22	32		10.1007/s11263-010-0384-0	http://dx.doi.org/10.1007/s11263-010-0384-0			11	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	738WJ					2022-12-18	WOS:000288673000002
J	Fua, P				Fua, P			Regularized bundle-adjustment to model heads from image sequences without calibration data	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						structure from motion; facial reconstruction; uncalibrated; bundle-adjustment	MOTION; RECONSTRUCTION	We address the structure-from-motion problem in the context of head modeling from video sequences for which calibration data is not available. This task is made challenging by the fact that correspondences are difficult to establish due to lack of texture and that a quasi-euclidean representation is required for realism. We have developed an approach based on regularized bundle-adjustment. It takes advantage of our rough knowledge of the head's shape, in the form of a generic face model. It allows us to recover relative head-motion and epipolar geometry accurately and consistently enough to exploit a previously-developed stereo-based approach to head modeling. In this way, complete and realistic head models can be acquired with a cheap and entirely passive sensor, such as an ordinary video camera, with minimal manual intervention. We chose to demonstrate and evaluate our technique mainly in the context of head-modeling. We do so because it is the application for which all the tools required to perform the complete reconstruction are available to us. We will, however, argue that the approach is generic and could be applied to other tasks, such as body modeling, for which generic facetized models exist.	Swiss Fed Inst Technol, Comp Graph Lab, CH-1015 Lausanne, Switzerland	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Fua, P (corresponding author), Swiss Fed Inst Technol, Comp Graph Lab, CH-1015 Lausanne, Switzerland.	Pascal.Fua@epfl.ch		Fua, Pascal/0000-0002-6702-9970				BARATOFF G, 1998, EUR C COMP VIS FREIB, P188; Beardsley PA, 1997, INT J COMPUT VISION, V23, P235, DOI 10.1023/A:1007923216416; BEATON AE, 1974, TECHNOMETRICS, V16, P147, DOI 10.2307/1267936; Blanz V., 1999, SIGGRAPH P LOS ANG C, P71; BOULIC R, 1995, EUROGRAPHICS, P337; DeCarlo D, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P113, DOI 10.1109/ICCV.1998.710708; DEVERNAY F, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P208, DOI 10.1109/CVPR.1994.323831; FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P321; FITZGIBBON AW, 1998, ECCV, P311; Fua P, 1999, COMPUT VIS IMAGE UND, V75, P247, DOI 10.1006/cviu.1999.0778; Fua P., 1993, Machine Vision and Applications, V6, P35, DOI 10.1007/BF01212430; FUA P, 1995, INT J COMPUT VISION, V16, P35, DOI 10.1007/BF01428192; Fua P., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P188, DOI 10.1007/BFb0055667; GRUEN A, 1992, CALIBRATION ORIENTAT; Hartley R., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P761, DOI 10.1109/CVPR.1992.223179; Jebara TS, 1997, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.1997.609312; KALRA P, 1992, EUROGRAPHICS; KANG SB, 1997, 976 CRL; LANITIS A, 1995, INT C COMP VIS CAMBR, P975; LECLERC YG, 1991, C COMP VIS PATT REC; LEE WS, 1998, 31A; LEE Y, 1995, SIGGRAPH P, P191; Luong QT, 1996, COMPUT VIS IMAGE UND, V64, P193, DOI 10.1006/cviu.1996.0055; PIGHIN F, 1998, SIGGRAPH P, V26, P75; Pollefeys M, 1998, INT C COMP VIS; Press WH, 1986, NUMERICAL RECIPES C, V818; PROESMANS M, 1996, INT C IM PROC LAUS S; Samaras D, 1998, PROC CVPR IEEE, P322, DOI 10.1109/CVPR.1998.698626; Sturm P, 1997, PROC CVPR IEEE, P1100, DOI 10.1109/CVPR.1997.609467; TANG L, 1996, ICIP 3, V94, P98; TAREL JP, 1996, 0196 INRIA; Thalmann D, 1996, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P166, DOI 10.1109/CGI.1996.511798; Triggs B, 1997, PROC CVPR IEEE, P609, DOI 10.1109/CVPR.1997.609388; ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4; Zienkiewicz OC, 2014, FINITE ELEMENT METHO; ZISSERMAN A, 1998, PHILOS T MATH PHYS A, V356, P11931	36	73	76	0	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2000	38	2					153	171		10.1023/A:1008105802790	http://dx.doi.org/10.1023/A:1008105802790			19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	345GP		Green Submitted			2022-12-18	WOS:000088808500003
J	Kakadiaris, IA; Metaxas, D				Kakadiaris, IA; Metaxas, D			Three-dimensional human body model acquisition from multiple views	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						human body model; three-dimensional model acquisition; motion-based part segmentation; integration of multiple views; articulated objects; physics-based modeling; deformable models; physics-based modeling	MOTION	We present a novel approach to the three-dimensional human body model acquisition from three mutually orthogonal views. Our technique is based on the spatiotemporal analysis of the deforming apparent contour of a human moving according to a protocol of movements. For generality and robustness our technique does not use a prior model of the human body and a prior body part segmentation is not assumed. Therefore, our technique applies to humans of any anthropometric dimension. 70 parameterize and segment over time a deforming apparent contour, we introduce a new shape representation technique based on primitive composition. The composed deformable model allows us to represent large local deformations and their evolution in a compact and intuitive way. In addition, this representation allows us to hypothesize an underlying part structure and test this hypothesis against the relative motion (due to forces exerted from the image data) of the defining primitives of the composed model. Furthermore, we develop a Human Body Part Decomposition Algorithm (HBPDA) that recovers all the body parts of a subject by monitoring the changes over time to the shape of the deforming silhouette. In addition, we modularize the process of simultaneous two-dimensional part determination and shape estimation by employing the Supervisory Control Theory of Discrete Event Systems. Finally, we present a novel algorithm which selectively integrates the (segmented by the HBPDA) apparent contours from three mutually orthogonal viewpoints to obtain a three-dimensional model of the subject's body parts. The effectiveness of the approach is demonstrated through a series of experiments where a subject performs a set of movements according to a protocol that reveals the structure of the human body.	Univ Penn, Dept Comp & Informat Sci, Philadelphia, PA 19104 USA	University of Pennsylvania	Kakadiaris, IA (corresponding author), Univ Houston, Dept Comp Sci, MS CSC 3475, Houston, TX 77204 USA.	ioannisk@grip.cis.upenn.edu; dnm@central.cis.upenn.edu		Kakadiaris, Ioannis/0000-0002-0591-1079				AKITA K, 1984, PATTERN RECOGN, V17, P73, DOI 10.1016/0031-3203(84)90036-0; AZUOLA F, 1994, P IMAGE 7 SOC C TUCS; Barr A. H., 1981, IEEE Computer Graphics and Applications, V1, P11, DOI 10.1109/MCG.1981.1673799; Barr A. H., 1984, Computers & Graphics, V18, P21; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Gavrila DM, 1996, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.1996.517056; GONCALVES L, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P764, DOI 10.1109/ICCV.1995.466861; HOGG D, 1983, IMAGE VISION COMPUT, V1, P5, DOI DOI 10.1016/0262-8856(83)90003-3; Kakadiaris I, 1997, COMPUT VIS IMAGE UND, V65, P129, DOI 10.1006/cviu.1996.0580; Kakadiaris IA, 1996, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.1996.517057; KAKADIARIS IA, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P618, DOI 10.1109/ICCV.1995.466881; KAKADIARIS IA, 1997, THESIS U PENNSYLVANI; KAKADIARIS IA, 1994, IEEE COMP SOC C COMP, P980; LEUNG MK, 1987, PATTERN RECOGN, V20, P321, DOI 10.1016/0031-3203(87)90007-0; LEUNG MK, 1995, IEEE T PATTERN ANAL, V17, P359, DOI 10.1109/34.385981; LEUNG MK, 1987, PATTERN RECOGN, V20, P55, DOI 10.1016/0031-3203(87)90017-3; MANN R, 1996, LECT NOTES COMPUTER, V2, P528; METAXAS D, 1993, IEEE T PATTERN ANAL, V15, P580, DOI 10.1109/34.216727; NASA, 1978, NASA ANTHR SOURC BOO; OROURKE J, 1980, IEEE T PATTERN ANAL, V2, P522, DOI 10.1109/TPAMI.1980.6447699; PITO RA, 1996, IEEE INT C IM PROC V, V2, P397; PRASAD M, 1991, GRAPHICS GEMS, V2; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; RAMADGE PJG, 1989, P IEEE, V77, P81, DOI 10.1109/5.21072; REGH JM, 1995, P INT C COMP VIS, P612; REHG M, 1994, P 3 EUR C COMP VIS S, P35; ROHR K, 1994, CVGIP-IMAG UNDERSTAN, V59, P94, DOI 10.1006/ciun.1994.1006; RUSSELL K, 1995, IJCAI 95 WORKSH ENT; [No title captured]	30	73	76	1	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	1998	30	3					191	218		10.1023/A:1008071332753	http://dx.doi.org/10.1023/A:1008071332753			28	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	156FL					2022-12-18	WOS:000077990900003
J	Kollnig, H; Nagel, HM				Kollnig, H; Nagel, HM			3D pose estimation by directly matching polyhedral models to gray value gradients	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							IMAGE SEQUENCES; TRACKING; OBJECTS; SCENES	This contribution addresses the problem of pose estimation and tracking of vehicles in image sequences from traffic scenes recorded by a stationary camera. In a new algorithm, the vehicle pose is estimated by directly matching polyhedral vehicle models to image gradients without an edge segment extraction process. The new approach is significantly more robust than approaches that rely on feature extraction since the new approach exploits more information from the image data. We successfully tracked vehicles that were partially occluded by textured objects, e.g., foliage, where a previous approach based on edge segment extraction failed. Moreover, the new pose estimation approach is also used to determine the orientation and position of the road relative to the camera by matching an intersection model directly to image gradients. Results from various experiments with real world traffic scenes are presented.	FRAUNHOFER INST INFORMAT & DATENVERARBT, D-76131 KARLSRUHE, GERMANY	Fraunhofer Gesellschaft	Kollnig, H (corresponding author), UNIV KARLSRUHE, FAK INFORMAT, INST ALGORITHMEN & KOGNIT SYST, POSTFACH 6980, D-76128 KARLSRUHE, GERMANY.							Bar-Shalom Y., 1988, TRACKING DATA ASS; BLAKE A, 1993, INT J COMPUT VISION, V11, P127, DOI 10.1007/BF01469225; CEDRAS C, 1995, IMAGE VISION COMPUT, V13, P129, DOI 10.1016/0262-8856(95)93154-K; DERICHE R, 1990, IMAGE VISION COMPUT, V8, P261, DOI 10.1016/0262-8856(90)80002-B; DU L, 1993, P 4 INT C COMP VIS I, P632; DUBUISSON MP, 1995, INT J COMPUT VISION, V14, P83, DOI 10.1007/BF01421490; Gelb A., 1974, APPL OPTIMAL ESTIMAT; GENNERY DB, 1992, INT J COMPUT VISION, V7, P243, DOI 10.1007/BF00126395; Grimson W. E. L., 1990, OBJECT RECOGNITION C; HENRICSSON O, 1994, LECT NOTES COMPUTER, V801, P371; Horn B., 1986, ROBOT VISION, P1; KANADE T, 1980, ARTIF INTELL, V13, P279, DOI 10.1016/0004-3702(80)90004-1; KANADE T, 1978, P 4 INT JOINT C PATT, P105; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kilger M., 1992, Proceedings. IEEE Workshop on Applications of Computer Vision (Cat. No.92TH0446-5), P11, DOI 10.1109/ACV.1992.240332; Kilger M., 1993, Proceedings of the 8th Scandinavian Conference on Image Analysis, P1077; KOLLER D, 1993, INT J COMPUT VISION, V10, P257, DOI 10.1007/BF01539538; KOLLER D, 1994, LECT NOTES COMPUTER, V1, P189; KOLLER D, 1992, DISKI, V13; KOLLNIG H, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P569, DOI 10.1109/ICCV.1995.466888; KOLLNIG H, 1994, LECT NOTES COMPUTER, V801, P338; KOLLNIG H, 1995, DISKI, V88; KUMAR R, 1994, CVGIP-IMAG UNDERSTAN, V60, P313, DOI 10.1006/ciun.1994.1060; LOWE DG, 1992, INT J COMPUT VISION, V8, P113, DOI 10.1007/BF00127170; MUCK K, 1994, ENTWICKLUNG IMPLEMEN; NAGEL HH, 1994, ARTIF INTELL REV, V8, P189, DOI 10.1007/BF00849074; OTTE M, 1995, ARTIF INTELL, V78, P5, DOI 10.1016/0004-3702(95)00033-X; OTTE M, 1994, DISKI, V63; Rehg J.M., 1994, LNCS, V801, P35, DOI DOI 10.1007/BFB0028333; ROBERTS J, 1993, P BRIT MACH VIS C GU, P459; TAN TN, 1994, LECT NOTES COMPUTER, V800, P501; TAN TN, 1994, P 5 BRIT MACH VIS C, P85; VONHOLT V, 1994, INTELLIGENT VEHICLES, P314; WORRALL AD, 1994, LECT NOTES COMPUTER, V800, P341; ZHANG X, 1993, P BRIT MACH VIS C GU, P489; ZHANG Z, 1992, 3D DYNAMIC SCENE ANA	36	73	76	0	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN-JUL	1997	23	3					283	302		10.1023/A:1007927317325	http://dx.doi.org/10.1023/A:1007927317325			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	XN801					2022-12-18	WOS:A1997XN80100005
J	SZELISKI, R				SZELISKI, R			BAYESIAN MODELING OF UNCERTAINTY IN LOW-LEVEL VISION	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Review							EDGE-DETECTION; RELAXATION; MOTION; STEREO; REGULARIZATION; ORGANIZATION; COMPUTATION; ALGORITHM; SPLINE; SCALE	The need for error modeling, multisensor fusion, and robust algorithms is becoming increasingly recognized in computer vision. Bayesian modeling is a powerful, practical, and general framework for meeting these requirements. This article develops a Bayesian model for describing and manipulating the dense fields, such as depth maps, associated with low-level computer vision. Our model consists of three components: a prior model, a sensor model, and a posterior model. The prior model captures a priori information about the structure of the field. We construct this model using the smoothness constraints from regularization to define a Markov Random Field. The sensor model describes the behavior and noise characteristics of our measurement system. We develop a number of sensor models for both sparse and dense measurements. The posterior model combines the information from the prior and sensor models using Bayes' rule. We show how to compute optimal estimates from the posterior model and also how to compute the uncertainty (variance) in these estimates. To demonstrate the utility of our Bayesian frame-work, we present three examples of its application to reveal vision problems. The first application is the on-line extraction of depth from motion. Using a two-dimensional generalization of the Kalman filter, we develop an incremental algorithm that provides a dense on-line estimate of depth whose accuracy improves over time. In the second application, we use a Bayesian model to determine observer motion from sparse depth (range) measurements. In the third application, we use the Bayesian interpretation of regularization to choose the optimal smoothing parameter for interpolation. The uncertainty modeling techniques that we develop, and the utility of these techniques in various applications, support our claim that Bayesian modeling is a powerful and practical framework for low-level vision.	DIGITAL EQUIPMENT CORP, CAMBRIDGE RES LAB, CAMBRIDGE, MA 02139 USA									ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; ALOIMONOS J, 1987, 1ST P INT C COMP VIS, P35; ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167; ANANDAN P, 1985, P IEEE WORKSHOP COMP, P186; [Anonymous], 1985, PERCEPTUAL ORG VISUA; [Anonymous], 1975, PSYCHOL COMPUTER VIS; BAKER HH, 1989, INT J COMPUT VISION, V3, P33, DOI 10.1007/BF00054837; BARNARD ST, 1989, INT J COMPUT VISION, V3, P17, DOI 10.1007/BF00054836; BARNARD ST, 1982, ACM COMPUT SURV, V14, P553, DOI DOI 10.1145/356893.356896; Barrow H., 1978, COMPUT VIS SYST, V2, P2; BERTERO M, 1987, ASI924 MIT MEM; Bierman G.J., 1977, FACTORIZATION METHOD; BOLLES RC, 1987, INT J COMPUT VISION, V1, P7, DOI 10.1007/BF00128525; BOULT T, 1986, THESIS COLUMBIA U; BRACEWELL RN, 1978, FOURIER TRANSFORM IT; Briggs W., 1987, MULTIGRID TUTORIAL; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Chen L. H., 1988, P DARPA IMAGE UNDERS, P166; CHOI DJ, 1987, P DARPA IMAGE UNDERS, P639; CHRIST JP, 1987, THESIS CARNEGIE MELL; CRAVEN P, 1979, NUMER MATH, V31, P377, DOI 10.1007/BF01437407; CROWLEY JL, 1982, CMURITR8218 CARN MEL; DEV P, 1974, COINS74C5 U MASS AMH; Duda R.O., 1973, J ROYAL STAT SOC SER; DURBIN R, 1987, NATURE, V326, P689, DOI 10.1038/326689a0; Durbin R, 1989, NEURAL COMPUT, V1, P348, DOI 10.1162/neco.1989.1.3.348; DURRANTWHYTE HF, 1987, INT J ROBOT RES, V6, P3, DOI 10.1177/027836498700600301; ELFES A, 1987, P IEEE C DECISION CO; Faugeras O. D, 1987, 3 DIMENSIONAL MACHIN, P301; FAUGERAS OD, 1986, APR P IEEE C ROB AUT, P1433; GAMBLE E, 1987, AI970 MIT ART INT LA; GEIGER D, 1989, P DARPA IMAGE UNDERS, P617; Gelb A., 1974, APPL OPTIMAL ESTIMAT; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GEMAN S, 1987, 46TH P SESS INT STAT; GRIMSON WEL, 1983, COMPUT VISION GRAPH, V22, P39, DOI 10.1016/0734-189X(83)90095-6; GRIMSON WEL, 1981, IMAGES SURFACES; HACKBUSCH W., 1985, SPRINGER SER COMPUT, V4; HEEGER DJ, 1987, 1ST P INT C COMP VIS, P181; HEEL J, 1989, P DARPA IM UND WORKS, P702; Hinton G. E., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P448; HINTON GE, 1977, THESIS U EDINBURGH; Hoff W., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P516; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HORN BKP, 1977, ARTIF INTELL, V8, P201, DOI 10.1016/0004-3702(77)90020-0; HORN BKP, 1986, COMPUT VISION GRAPH, V33, P174, DOI 10.1016/0734-189X(86)90114-3; HUECKEL MH, 1971, J ACM, V18, P113, DOI 10.1145/321623.321635; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; JULESZ B, 1971, F CYCLOPEAN PERCEPTI; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KIMELDOR.GS, 1970, ANN MATH STAT, V41, P495, DOI 10.1214/aoms/1177697089; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; KOCH C, 1986, P NATL ACAD SCI USA, V83, P4263, DOI 10.1073/pnas.83.12.4263; Konrad J., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P354, DOI 10.1109/CCV.1988.590012; LECLERC YG, 1989, INT J COMPUT VISION, V3, P73, DOI 10.1007/BF00054839; Mandelbrot, 1982, FRACTAL GEOMETRY NAT, P394; MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Marr D., 1978, COMPUTER VISION SYST, P61; Marr D., 1982, VISION COMPUTATIONAL; MARROQUIN JL, 1984, AI792 MIT ART INT LA; MARROQUIN JL, 1985, THESIS MASSACHUSETTS; MATTHIES L, 1987, IEEE T ROBOTIC AUTOM, V3, P239, DOI 10.1109/JRA.1987.1087097; MATTHIES L, 1989, INT J COMPUT VISION, V3, P209, DOI 10.1007/BF00133032; MCDERMOTT D, 1980, 173 YAL U DEP COMP S; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; MORAVEC HP, 1988, AI MAG, V9, P61; PENTLAND AP, 1986, ARTIF INTELL, V28, P293, DOI 10.1016/0004-3702(86)90052-4; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; POGGIO T, 1985, AI833 MIT ART INT LA; POGGIO T, 1988, P DARPA IMAGE UNDERS, P177; RENSINK RA, 1986, THESIS U BRIT COLUMB; RIVES P, 1987, P IEEE INT C ROBOTIC; RIVES P, 1986, P C INTELL AUTONOMOU, P522; Roberts L, 1965, MACHINE PERCEPTION 3; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; ROSENFELD A, 1984, MULTIRESOLUTION IMAG; ROSENFELD A, 1980, 5TH P INT C PATT REC, P802; Szeliski R., 1989, Computer Graphics, V23, P51, DOI 10.1145/74334.74338; SZELISKI R, 1990, IEEE T PATTERN ANAL, V12, P513, DOI 10.1109/34.56188; Szeliski R., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P207, DOI 10.1109/CCV.1988.589992; SZELISKI R, 1990, 1ST P EUR C COMP VIS, P359; SZELISKI R, 1989, BAYESIAN MODELING UN; SZELISKI R, 1986, CMUCS86133 CARN MELL; SZELISKI R, 1987, 6TH P AAAI 87 NATL C, P749; SZELISKI R, 1989, 4 COPP MOUNT C MULT, P383; TERZOPOULOS D, 1983, COMPUT VISION GRAPH, V24, P52, DOI 10.1016/0734-189X(83)90020-8; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P129, DOI 10.1109/TPAMI.1986.4767767; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; TERZOPOULOS D, 1987, INT J COMPUT VISION, V1, P211, DOI 10.1007/BF00127821; Terzopoulos D., 1987, Topical Meeting on Machine Vision. Technical Digest Series Vol.12 (papers in summary form only received), P164; Tikhonov A.N., 1977, SOLUTION ILL POSED P; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; VANESSEN DC, 1983, TRENDS NEUROSCI, V6, P370, DOI 10.1016/0166-2236(83)90167-4; Voss R. F., 1985, FUNDAMENTAL ALGORITH; WAHBA G, 1983, J ROY STAT SOC B MET, V45, P133; WITKIN A, 1987, INT J COMPUT VISION, V1, P133, DOI 10.1007/BF00123162; YSERENTANT H, 1986, NUMER MATH, V49, P379, DOI 10.1007/BF01389538	103	73	75	0	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	1990	5	3					271	301		10.1007/BF00126502	http://dx.doi.org/10.1007/BF00126502			31	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	EZ751		Green Published			2022-12-18	WOS:A1990EZ75100003
J	Long, SB; He, X; Yao, C				Long, Shangbang; He, Xin; Yao, Cong			Scene Text Detection and Recognition: The Deep Learning Era	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Scene text; Optical character recognition; Detection; Recognition; Deep learning; Survey	OBJECT DETECTION; NEURAL-NETWORK; IMAGES; LOCALIZATION; EXTRACTION; VIDEO	With the rise and development of deep learning, computer vision has been tremendously transformed and reshaped. As an important research area in computer vision, scene text detection and recognition has been inevitably influenced by this wave of revolution, consequentially entering the era of deep learning. In recent years, the community has witnessed substantial advancements in mindset, methodology and performance. This survey is aimed at summarizing and analyzing the major changes and significant progresses of scene text detection and recognition in the deep learning era. Through this article, we devote to: (1) introduce new insights and ideas; (2) highlight recent techniques and benchmarks; (3) look ahead into future trends. Specifically, we will emphasize the dramatic differences brought by deep learning and remaining grand challenges. We expect that this review paper would serve as a reference book for researchers in this field. Related resources are also collected in our Github repository (https://github.com/Jyouhou/SceneTextPapers).	[Long, Shangbang] Carnegie Mellon Univ, Sch Comp Sci, Machine Learning Dept, Pittsburgh, PA 15213 USA; [He, Xin] ByteDance Ltd, Beijing, Peoples R China; [Yao, Cong] MEGVII Inc Face, Beijing, Peoples R China	Carnegie Mellon University	Long, SB (corresponding author), Carnegie Mellon Univ, Sch Comp Sci, Machine Learning Dept, Pittsburgh, PA 15213 USA.	shangbal@cs.cmu.edu; hexin7257@gmail.com; yaocong2010@gmail.com						Almazan J, 2014, IEEE T PATTERN ANAL, V36, P2552, DOI 10.1109/TPAMI.2014.2339814; [Anonymous], 2013, INT J COMPUT APPL; [Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.322; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Baek J, 2019, IEEE I CONF COMP VIS, P4714, DOI 10.1109/ICCV.2019.00481; Baek Y, 2019, PROC CVPR IEEE, P9357, DOI 10.1109/CVPR.2019.00959; Bai F, 2018, PROC CVPR IEEE, P1508, DOI 10.1109/CVPR.2018.00163; Bao L, 2018, IEEE INT CONF BIG DA, P181, DOI 10.1109/BigData.2018.8622018; Bartz C., 2017, ARXIV171205404; Bissacco A, 2013, IEEE I CONF COMP VIS, P785, DOI 10.1109/ICCV.2013.102; Borisyuk F, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P71, DOI 10.1145/3219819.3219861; Busta M, 2017, IEEE I CONF COMP VIS, P2223, DOI 10.1109/ICCV.2017.242; Busta M, 2015, IEEE I CONF COMP VIS, P1206, DOI 10.1109/ICCV.2015.143; Cao J, 2017, IEEE ICC; Ch'ng CK, 2017, PROC INT CONF DOC, P935, DOI 10.1109/ICDAR.2017.157; Chen XL, 2004, IEEE T IMAGE PROCESS, V13, P87, DOI 10.1109/TIP.2003.819223; Cheng Z., 2017, CVPR; Cheng ZZ, 2017, IEEE I CONF COMP VIS, P5086, DOI 10.1109/ICCV.2017.543; Coates A, 2011, PROC INT CONF DOC, P440, DOI 10.1109/ICDAR.2011.95; Dai Y., 2017, ARXIV170903272; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Deli Yu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12110, DOI 10.1109/CVPR42600.2020.01213; Deng D, 2018, AAAI CONF ARTIF INTE, P6773; DeSouza GN, 2002, IEEE T PATTERN ANAL, V24, P237, DOI 10.1109/34.982903; Dollar P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479; Dzmitry Bahdanau, 2016, Arxiv, DOI arXiv:1409.0473; Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Fu C. -Y., 2017, ARXIV170106659; Gao Y., 2017, ARXIV170904303; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Goldberg AV, 1997, J ALGORITHM, V22, P1, DOI 10.1006/jagm.1995.0805; Gordo A, 2015, PROC CVPR IEEE, P2956, DOI 10.1109/CVPR.2015.7298914; Graves A., 2008, ADV NEURAL INFORM PR, V20, P1; Graves A., 2006, P 23 INT C MACH LEAR, P369; Gupta A, 2016, PROC CVPR IEEE, P2315, DOI 10.1109/CVPR.2016.254; HAM YK, 1995, OPT ENG, V34, P102, DOI 10.1117/12.184094; Havosha, 2009, U.S. Patent, Patent No. [11 998 931, 11998931]; He DF, 2017, PROC CVPR IEEE, P474, DOI 10.1109/CVPR.2017.58; He P, 2017, IEEE I CONF COMP VIS, P3066, DOI 10.1109/ICCV.2017.331; He P, 2016, AAAI CONF ARTIF INTE, P3501; He T, 2018, PROC CVPR IEEE, P5020, DOI 10.1109/CVPR.2018.00527; He WH, 2017, IEEE I CONF COMP VIS, P745, DOI 10.1109/ICCV.2017.87; He ZW, 2005, IEEE T INTELL TRANSP, V6, P72, DOI 10.1109/TITS.2004.838509; Hochreiter S., 1997, STUD COMPUT INTELL, V9, P1735, DOI DOI 10.1007/978-3-642-24797-2; Hu H, 2017, INT CONF ASIC, P179; Huang WL, 2013, IEEE I CONF COMP VIS, P1241, DOI 10.1109/ICCV.2013.157; Huang WL, 2014, LECT NOTES COMPUT SC, V8692, P497, DOI 10.1007/978-3-319-10593-2_33; Jaderberg M., 2015, ADV NEURAL INFORM PR, P2017, DOI DOI 10.1038/NBT.3343; Jaderberg M., 3 INT C LEARN REPR S, P7; Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z; Jaderberg M, 2014, LECT NOTES COMPUT SC, V8692, P512, DOI 10.1007/978-3-319-10593-2_34; Jaderberg Max, 2014, P BRIT MACH VIS C, P2, DOI DOI 10.5244/C.28.88; Jain AK, 1998, PATTERN RECOGN, V31, P2055, DOI 10.1016/S0031-3203(98)00067-3; Jiang Y., 2017, ARXIV170609579; Jung K, 2004, PATTERN RECOGN, V37, P977, DOI 10.1016/j.patcog.2003.10.012; Kang L, 2014, PROC CVPR IEEE, P4034, DOI 10.1109/CVPR.2014.514; Karatzas D, 2004, INT C PATT RECOG, P634, DOI 10.1109/ICPR.2004.1334328; Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942; Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221; Kipf TN, 2016, P INT C LEARN REPR; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Lee CY, 2016, PROC CVPR IEEE, P2231, DOI 10.1109/CVPR.2016.245; Lee JJ, 2011, PROC INT CONF DOC, P429, DOI 10.1109/ICDAR.2011.93; Lee S, 2013, IMAGE VISION COMPUT, V31, P823, DOI 10.1016/j.imavis.2013.08.007; Li H, 2019, AAAI CONF ARTIF INTE, P8610; Li R, 2017, PROC INT CONF DOC, P324, DOI 10.1109/ICDAR.2017.61; Liao M., 2019, ARXIV190706007; Liao MH, 2019, AAAI CONF ARTIF INTE, P8714; Liao MH, 2018, PROC CVPR IEEE, P5909, DOI 10.1109/CVPR.2018.00619; Liao MH, 2018, IEEE T IMAGE PROCESS, V27, P3676, DOI 10.1109/TIP.2018.2825107; Liao MH, 2017, AAAI CONF ARTIF INTE, P4161; Liu FY, 2015, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2015.7299152; Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Liu Wei, 2016, BMVC, V2, P7, DOI DOI 10.5244/C.30.43; Liu WT, 2018, AAAI CONF ARTIF INTE, P7170; Liu XQ, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATIONS, VOLS 1-4, CONFERENCE PROCEEDINGS, P701; Liu XQ, 2005, P SOC PHOTO-OPT INS, V5672, P139, DOI 10.1117/12.594572; Liu Y., 2017, DEEP MATCHING PRIOR; Liu YL, 2019, PROC CVPR IEEE, P9604, DOI 10.1109/CVPR.2019.00984; Liu Yuliang, 2017, ARXIV171202170; Liu ZC, 2018, PROC CVPR IEEE, P6936, DOI 10.1109/CVPR.2018.00725; Liu Zichuan, 2018, 32 AAAI C ART INT; Long S., 2019, ARXIV190811834; Long SB, 2020, INT CONF ACOUST SPEE, P2458, DOI 10.1109/ICASSP40776.2020.9054135; Long SB, 2018, LECT NOTES COMPUT SC, V11206, P19, DOI 10.1007/978-3-030-01216-8_2; Long Shangbang, 2020, ARXIV200310608, P5488; Lyu PY, 2018, PROC CVPR IEEE, P7553, DOI 10.1109/CVPR.2018.00788; Lyu PY, 2018, LECT NOTES COMPUT SC, V11218, P71, DOI 10.1007/978-3-030-01264-9_5; Ma JQ, 2018, IEEE T MULTIMEDIA, V20, P3111, DOI 10.1109/TMM.2018.2818020; Mammeri A., 2014, P IEEE VEH TECHN C V, P1, DOI DOI 10.1109/VTCFALL.2014.6966161; Mammeri A, 2016, 2016 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATION (ISCC), P1218, DOI 10.1109/ISCC.2016.7543902; Mishra A., 2011, ICDAR INT C DOC AN R; Mishra A, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.127; Neumann L, 2013, PROC INT CONF DOC, P523, DOI 10.1109/ICDAR.2013.110; Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097; Neumann L, 2011, LECT NOTES COMPUT SC, V6494, P770, DOI 10.1007/978-3-642-19318-7_60; Nomura S, 2005, PATTERN RECOGN, V38, P1961, DOI 10.1016/j.patcog.2005.01.026; Pombo, 2016, U.S. Patent, Patent No. [9 507 772, 9507772]; Qin SY, 2019, IEEE I CONF COMP VIS, P4703, DOI 10.1109/ICCV.2019.00480; Qiu WC, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1221, DOI 10.1145/3123266.3129396; Redmon J., 2016, IEEE C COMPUTER VISI, DOI [10.1109/CVPR.2017.690, DOI 10.1109/CVPR.2017.690]; Redmon J, 2016, YOU ONLY LOOK ONCE U, DOI [DOI 10.1109/CVPR.2016.91, 10.1109/CVPR.2016.91]; Ren S., 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.169; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rodriguez-Serrano JA, 2015, INT J COMPUT VISION, V113, P193, DOI 10.1007/s11263-014-0793-6; Rodriguez-Serrano JA, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.5; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Roy P. P., 2009, 10 INT C DOC AN REC; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Schroth G., 2011, Proceedings of the 2011 IEEE International Symposium on Multimedia (ISM 2011), P77, DOI 10.1109/ISM.2011.21; Schulz R, 2015, IEEE INT CONF ROBOT, P1100, DOI 10.1109/ICRA.2015.7139313; Sheshadri K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.13; Shi BG, 2017, PROC CVPR IEEE, P3482, DOI 10.1109/CVPR.2017.371; Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371; Shi BG, 2016, PROC CVPR IEEE, P4168, DOI 10.1109/CVPR.2016.452; Shi Baoguang, 2018, IEEE T PATTERN ANAL; Shi CZ, 2013, PROC CVPR IEEE, P2961, DOI 10.1109/CVPR.2013.381; Shivakumara P., 2011, 2011 INT C DOC AN RE; Su B, 2014, INT C INTEL HUM MACH, P300, DOI 10.1109/IHMSC.2014.80; Sun YP, 2019, IEEE I CONF COMP VIS, P9085, DOI 10.1109/ICCV.2019.00918; Sutskever I., 2014, ARXIV14093215, DOI DOI 10.1007/S10107-014-0839-0; Tian SX, 2017, IEEE I CONF COMP VIS, P1501, DOI 10.1109/ICCV.2017.166; Tian SX, 2015, IEEE I CONF COMP VIS, P4651, DOI 10.1109/ICCV.2015.528; Tian Z, 2016, LECT NOTES COMPUT SC, V9912, P56, DOI 10.1007/978-3-319-46484-8_4; Tian ZT, 2019, PROC CVPR IEEE, P4229, DOI 10.1109/CVPR.2019.00436; Phan TQ, 2013, IEEE I CONF COMP VIS, P569, DOI 10.1109/ICCV.2013.76; Tsai SS, 2011, IEEE IMAGE PROC, DOI 10.1109/ICIP.2011.6116198; Uchida S., 2014, HDB DOCUMENT IMAGE P, P843, DOI DOI 10.1007/978-0-85729-859-1_28; Wachenfeld S, 2006, INT C PATT RECOG, P1086; Wakahara T, 2011, PROC INT CONF DOC, P274, DOI 10.1109/ICDAR.2011.63; Wang C, 2017, PROC INT CONF DOC, P929, DOI 10.1109/ICDAR.2017.156; Wang FF, 2018, PROC CVPR IEEE, P1381, DOI 10.1109/CVPR.2018.00150; Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402; Wang T, 2012, INT C PATT RECOG, P3304; Wang WG, 2019, PROC CVPR IEEE, P1448, DOI 10.1109/CVPR.2019.00154; Wang XB, 2019, PROC CVPR IEEE, P6442, DOI 10.1109/CVPR.2019.00661; WEI MH, 2019, PROGNOST SYST HEALT; Weinman JJ, 2007, PROC INT CONF DOC, P979; Wolf C, 2006, INT J DOC ANAL RECOG, V8, P280, DOI 10.1007/s10032-006-0014-0; Wu L, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1500, DOI 10.1145/3343031.3350929; Wu Y, 2017, IEEE I CONF COMP VIS, P5010, DOI 10.1109/ICCV.2017.535; Xia Yingce, 2017, ADV NEURAL INFORM PR, P1784; Xing LJ, 2019, IEEE I CONF COMP VIS, P9125, DOI 10.1109/ICCV.2019.00922; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Xue CH, 2018, LECT NOTES COMPUT SC, V11220, P370, DOI 10.1007/978-3-030-01270-0_22; Yang Q., 2020, ARXIV200308152; Yang X, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3280; Yao C., 2016, ARXIV160609002; Yao C, 2014, PROC CVPR IEEE, P4042, DOI 10.1109/CVPR.2014.515; Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787; Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765; Ye QX, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P802; Yi Chucai, 2011, IEEE Trans Image Process, V20, P2594, DOI 10.1109/TIP.2011.2126586; Yin F., 2017, ARXIV170901727; Yin XC, 2016, IEEE T IMAGE PROCESS, V25, P2752, DOI 10.1109/TIP.2016.2554321; Yin XC, 2014, IEEE T PATTERN ANAL, V36, P970, DOI 10.1109/TPAMI.2013.182; Yuan TL, 2018, ARXIV PREPRINT ARXIV; Zhan F., 2018, VERISIMILAR IMAGE SY; Zhan FN, 2019, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2019.00216; Zhang C, 2019, PROC CVPR IEEE, P5312, DOI 10.1109/CVPR.2019.00546; Zhang D., 2003, COMPUTER VISION PATT; Zhang S.X., 2020, P IEEE CVF C COMP VI, P9699, DOI DOI 10.1109/CVPR42600.2020.00972; Zhang S, 2018, INT CONF INSTR MEAS, P201, DOI 10.1109/IMCCC.2018.00050; Zhang ZM, 2016, PROC CVPR IEEE, P6034, DOI 10.1109/CVPR.2016.649; Zhao, 1975, OLD BOOK OF TANG; Zhiwei Zhou, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P133, DOI 10.1109/ICPR.2010.41; Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283; Zhu YY, 2016, FRONT COMPUT SCI-CHI, V10, P19, DOI 10.1007/s11704-015-4488-0; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	173	72	76	13	65	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2021	129	1								10.1007/s11263-020-01369-0	http://dx.doi.org/10.1007/s11263-020-01369-0		AUG 2020	24	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	PU0KV		Green Submitted			2022-12-18	WOS:000565043600001
J	Rebecq, H; Gallego, G; Mueggler, E; Scaramuzza, D				Rebecq, Henri; Gallego, Guillermo; Mueggler, Elias; Scaramuzza, Davide			EMVS: Event-Based Multi-View Stereo3D Reconstruction with an Event Camera in Real-Time	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Multi-view stereo; Event cameras; Event-based vision; 3D reconstruction		Event cameras are bio-inspired vision sensors that output pixel-level brightness changes instead of standard intensity frames. They offer significant advantages over standard cameras, namely a very high dynamic range, no motion blur, and a latency in the order of microseconds. However, because the output is composed of a sequence of asynchronous events rather than actual intensity images, traditional vision algorithms cannot be applied, so that a paradigm shift is needed. We introduce the problem of event-based multi-view stereo (EMVS) for event cameras and propose a solution to it. Unlike traditional MVS methods, which address the problem of estimating dense 3D structure from a set of known viewpoints, EMVS estimates semi-dense 3D structure from an event camera with known trajectory. Our EMVS solution elegantly exploits two inherent properties of an event camera: (1) its ability to respond to scene edgeswhich naturally provide semi-dense geometric information without any pre-processing operationand (2) the fact that it provides continuous measurements as the sensor moves. Despite its simplicity (it can be implemented in a few lines of code), our algorithm is able to produce accurate, semi-dense depth maps, without requiring any explicit data association or intensity estimation. We successfully validate our method on both synthetic and real data. Our method is computationally very efficient and runs in real-time on a CPU.	[Rebecq, Henri; Gallego, Guillermo; Mueggler, Elias; Scaramuzza, Davide] Univ Zurich, Dept Informat, Robot & Percept Grp, Zurich, Switzerland; [Rebecq, Henri; Gallego, Guillermo; Mueggler, Elias; Scaramuzza, Davide] Univ Zurich, Dept Neuroinformat, Robot & Percept Grp, Zurich, Switzerland; [Rebecq, Henri; Gallego, Guillermo; Mueggler, Elias; Scaramuzza, Davide] Swiss Fed Inst Technol, Zurich, Switzerland	University of Zurich; University of Zurich; Swiss Federal Institutes of Technology Domain; ETH Zurich	Rebecq, H (corresponding author), Univ Zurich, Dept Informat, Robot & Percept Grp, Zurich, Switzerland.; Rebecq, H (corresponding author), Univ Zurich, Dept Neuroinformat, Robot & Percept Grp, Zurich, Switzerland.; Rebecq, H (corresponding author), Swiss Fed Inst Technol, Zurich, Switzerland.	rebecq@ifi.uzh.ch	Gallego, Guillermo/I-7131-2012	Gallego, Guillermo/0000-0002-2672-9241; Mueggler, Elias/0000-0002-8008-443X; Rebecq, Henri/0000-0002-6577-9735	DARPA FLA Program; National Center of Competence in Research (NCCR) Robotics through the Swiss National Science Foundation; SNSF-ERC Starting Grant	DARPA FLA Program; National Center of Competence in Research (NCCR) Robotics through the Swiss National Science Foundation; SNSF-ERC Starting Grant	This research was funded by the DARPA FLA Program, the National Center of Competence in Research (NCCR) Robotics through the Swiss National Science Foundation and the SNSF-ERC Starting Grant.	BARDOW P, 2016, PROC CVPR IEEE, P884, DOI DOI 10.1109/CVPR.2016.102; Benosman R, 2014, IEEE T NEUR NET LEAR, V25, P407, DOI 10.1109/TNNLS.2013.2273537; Benosman R, 2012, NEURAL NETWORKS, V27, P32, DOI 10.1016/j.neunet.2011.11.001; Brandli C, 2014, IEEE J SOLID-ST CIRC, V49, P2333, DOI 10.1109/JSSC.2014.2342715; Brandli C, 2014, IEEE INT SYMP CIRC S, P686, DOI 10.1109/ISCAS.2014.6865228; Camunas-Mesa LA, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00048; Censi A., 2014, IEEE INT C ROB AUT I, DOI [10. 1109/IROS. 2016. 7758089., DOI 10.1109/IR0S.2016.7758089]; Collins RT, 1996, PROC CVPR IEEE, P358, DOI 10.1109/CVPR.1996.517097; Cook M, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P770, DOI 10.1109/IJCNN.2011.6033299; Delbruck T, 2007, IEEE INT SYMP CIRC S, P845, DOI 10.1109/ISCAS.2007.378038; Delbruck T, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00223; Delbruckl T, 2016, PROC EUR S-STATE DEV, P7, DOI 10.1109/ESSDERC.2016.7599576; Drazen D, 2011, EXP FLUIDS, V51, P1465, DOI 10.1007/s00348-011-1207-y; Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577; Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54; Forster C, 2014, IEEE INT CONF ROBOT, P15, DOI 10.1109/ICRA.2014.6906584; Gallego G, 2018, IEEE T PATTERN ANAL, V40, P2402, DOI 10.1109/TPAMI.2017.2769655; Hartley R., 2003, MULTIPLE VIEW GEOMET; Kim H, 2016, LECT NOTES COMPUT SC, V9910, P349, DOI 10.1007/978-3-319-46466-4_21; Kim Hanme, 2014, BRIT MACH VIS C BMVC, DOI [10.5244/C.28.26, DOI 10.5244/C.28.26]; Kogler Jurgen, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P674; Kogler J., 2011, ADV THEORY APPL STER; Kueng B, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P16, DOI 10.1109/IROS.2016.7758089; Lagorce X, 2017, IEEE T PATTERN ANAL, V39, P1346, DOI 10.1109/TPAMI.2016.2574707; Lee J., 2012, IEEE INT S CIRC SYST, DOI [10.1109/ISCAS.2012.6272144, DOI 10.1109/ISCAS.2012.6272144]; Lee JH, 2014, IEEE T NEUR NET LEAR, V25, P2250, DOI 10.1109/TNNLS.2014.2308551; Lichtsteiner P, 2008, IEEE J SOLID-ST CIRC, V43, P566, DOI 10.1109/JSSC.2007.914337; Litzenberger M., 2006, 2006 IEEE INT TRANSP, P653, DOI DOI 10.1109/ITSC.2006.1706816; Matsuda N, 2015, IEEE INT CONF COMPUT; Mueggler E, 2017, INT J ROBOT RES, V36, P142, DOI 10.1177/0278364917691115; Mueggler E, 2014, IEEE INT C INT ROBOT, P2761, DOI 10.1109/IROS.2014.6942940; Orchard G, 2015, IEEE T PATTERN ANAL, V37, P2028, DOI 10.1109/TPAMI.2015.2392947; Piatkowska E, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P45, DOI 10.1109/ICCVW.2013.13; Piatkowska Ewa, 2012, 2012 IEEE COMP SOC C, P35; Pizzoli M, 2014, IEEE INT CONF ROBOT, P2609, DOI 10.1109/ICRA.2014.6907233; Rebecq H., 2016, BRIT MACH VIS C BMVC, DOI [10.5244/C.30.63, DOI 10.5244/C.30.63]; Rebecq H, 2017, IEEE ROBOT AUTOM LET, V2, P593, DOI 10.1109/LRA.2016.2645143; Reinbacher C., 2016, BRIT MACH VIS C BMVC, DOI [10.5244/C.30.9, DOI 10.5244/C.30.9]; Rogister P, 2012, IEEE T NEUR NET LEAR, V23, P347, DOI 10.1109/TNNLS.2011.2180025; Rueckauer B, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00176; Schraml S, 2015, PROC CVPR IEEE, P466, DOI 10.1109/CVPR.2015.7298644; Schraml S, 2010, IEEE INT SYMP CIRC S, P1409, DOI 10.1109/ISCAS.2010.5537289; Seitz S.M., 2006, P IEEE COMPUTER SOC, P519; Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187; Szeliski R., 2010, COMPUTER VISION ALGO, DOI DOI 10.1007/978-3-030-34372-9; Vogiatzis G, 2011, IMAGE VISION COMPUT, V29, P434, DOI 10.1016/j.imavis.2011.01.006; Weikersdorfer David, 2013, Computer Vision Systems. 9th International Conference, ICVS 2013. Proceedings: LNCS 7963, P133, DOI 10.1007/978-3-642-39402-7_14; Weikersdorfer D., 2012, Proceedings of the 2012 IEEE International Conference on Robotics and Biomimetics (ROBIO), P866, DOI 10.1109/ROBIO.2012.6491077; Wiesmann G., 2012, 2012 IEEE COMPUTER S, P76, DOI [10.1109/CVPRW.2012.6238898, DOI 10.1109/CVPRW.2012.6238898]; Wolberg G, 1990, DIGITAL IMAGE WARPIN; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718	52	72	75	6	32	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	2018	126	12			SI		1394	1414		10.1007/s11263-017-1050-6	http://dx.doi.org/10.1007/s11263-017-1050-6			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	GZ3KT		Green Accepted			2022-12-18	WOS:000449286200009
J	Mayer, N; Ilg, E; Fischer, P; Hazirbas, C; Cremers, D; Dosovitskiy, A; Brox, T				Mayer, Nikolaus; Ilg, Eddy; Fischer, Philipp; Hazirbas, Caner; Cremers, Daniel; Dosovitskiy, Alexey; Brox, Thomas			What Makes Good Synthetic Training Data for Learning Disparity and Optical Flow Estimation?	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Deep learning; Data generation; Synthetic ground truth; FlowNet; DispNet	ACCURACY	The finding that very large networks can be trained efficiently and reliably has led to a paradigm shift in computer vision from engineered solutions to learning formulations. As a result, the research challenge shifts from devising algorithms to creating suitable and abundant training data for supervised learning. How to efficiently create such training data? The dominant data acquisition method in visual recognition is based on web data and manual annotation. Yet, for many computer vision problems, such as stereo or optical flow estimation, this approach is not feasible because humans cannot manually enter a pixel-accurate flow field. In this paper, we promote the use of synthetically generated data for the purpose of training deep networks on such tasks. We suggest multiple ways to generate such data and evaluate the influence of dataset properties on the performance and generalization properties of the resulting networks. We also demonstrate the benefit of learning schedules that use different types of data at selected stages of the training process.	[Mayer, Nikolaus; Ilg, Eddy; Fischer, Philipp; Dosovitskiy, Alexey; Brox, Thomas] Univ Freiburg, Freiburg, Germany; [Hazirbas, Caner; Cremers, Daniel] Tech Univ Munich, Munich, Germany	University of Freiburg; Technical University of Munich	Mayer, N (corresponding author), Univ Freiburg, Freiburg, Germany.	mayern@cs.uni-freiburg.de; ilg@cs.uni-freiburg.de; fischer@cs.uni-freiburg.de; hazirbas@in.tum.de; cremers@in.tum.de; dosovits@cs.uni-freiburg.de; brox@cs.uni-freiburg.de		Mayer, Nikolaus/0000-0002-5732-0561	ERC Starting Grant VideoLearn; ERC Consolidator Grant "3D Reloaded"; DFG [BR-3815/7-1, CR 250/17-1]; EU Horizon2020 project TrimBot2020	ERC Starting Grant VideoLearn; ERC Consolidator Grant "3D Reloaded"; DFG(German Research Foundation (DFG)); EU Horizon2020 project TrimBot2020	We acknowledge funding by the ERC Starting Grant VideoLearn, the ERC Consolidator Grant "3D Reloaded", the DFG Grant BR-3815/7-1, the DFG Grant CR 250/17-1, and the EU Horizon2020 project TrimBot2020. We thank Benjamin Ummenhofer for code that kick-started the creation of our 3D datasets.	Aubry M, 2014, PROC CVPR IEEE, P3762, DOI 10.1109/CVPR.2014.487; Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Bengio Yoshua., 2009, P 26 ANN INT C MACHI, P41, DOI 10.1145/ 1553374.1553380; Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3; Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143; Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44; Chang Angel X., 2015, arXiv; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261; de Souza Cesar Roberto, 2017, CVPR, DOI DOI 10.1109/CVPR.2017.278; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dosovitskiy A., 2017, C ROBOT LEARNING, P1; Dosovitskiy A, 2015, PROC CVPR IEEE, P1538, DOI 10.1109/CVPR.2015.7298761; Dwibedi D, 2017, IEEE I CONF COMP VIS, P1310, DOI 10.1109/ICCV.2017.146; Eigen David, 2014, NEURIPS; ELMAN JL, 1993, COGNITION, V48, P71, DOI 10.1016/0010-0277(93)90058-4; Gaidon A, 2016, PROC CVPR IEEE, P4340, DOI 10.1109/CVPR.2016.470; Geiger A., 2012, P IEEE COMP SOC C CO; Handa A, 2016, PROC CVPR IEEE, P4077, DOI 10.1109/CVPR.2016.442; Handa A, 2014, IEEE INT CONF ROBOT, P1524, DOI 10.1109/ICRA.2014.6907054; HEEGER DJ, 1987, J OPT SOC AM A, V4, P1455, DOI 10.1364/JOSAA.4.001455; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Huguet F, 2007, IEEE I CONF COMP VIS, P1342, DOI 10.1109/iccv.2007.4409000; Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179; Klein G, 2010, IEEE T VIS COMPUT GR, V16, P369, DOI 10.1109/TVCG.2009.210; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Mac Aodha O, 2013, IEEE T PATTERN ANAL, V35, P1107, DOI 10.1109/TPAMI.2012.171; Mac Aodha O, 2010, PROC CVPR IEEE, P1054, DOI 10.1109/CVPR.2010.5540099; Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438; McCane B, 2001, COMPUT VIS IMAGE UND, V84, P126, DOI 10.1006/cviu.2001.0930; McCormac J, 2017, IEEE I CONF COMP VIS, P2697, DOI 10.1109/ICCV.2017.292; Meister S, 2011, 2011 14 ITG C EL MED, P1; Menze Moritz, 2015, CVPR; Movshovitz-Attias Y., 2016, ECCV WORKSH; Onkarappa N, 2014, IEEE T INTELL TRANSP, V15, P136, DOI 10.1109/TITS.2013.2274760; OTTE M, 1995, ARTIF INTELL, V78, P5, DOI 10.1016/0004-3702(95)00033-X; Qiu WC, 2016, LECT NOTES COMPUT SC, V9915, P909, DOI 10.1007/978-3-319-49409-8_75; Richter SR, 2017, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2017.243; Richter SR, 2016, LECT NOTES COMPUT SC, V9906, P102, DOI 10.1007/978-3-319-46475-6_7; ROS G, 2016, PROC CVPR IEEE, P3234, DOI DOI 10.1109/CVPR.2016.352; Scharstein D., 2014, PATTERN RECOGNITION; Silberman Nathan, 2012, EUR C COMP VIS, DOI 10.1007/978-3-642-33715-4_54; Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28; Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773; Su H, 2015, IEEE INT CON MULTI; Taylor Geoffrey R., 2007, IEEE COMPUTER SOC C, DOI [DOI 10.1109/CVPR.2007.383518, 10.1109/CVPR.2007.383518]; Vaudrey T., 2008, INT C IM VIS COMP; Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801; Wulff J., 2012, ECCV WORKSH UNS PROB; Xiao JX, 2013, IEEE I CONF COMP VIS, P1625, DOI 10.1109/ICCV.2013.458; Zhang Y., 2016, TECH REP; Zhang Yuting, 2017, CVPR	53	72	75	2	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2018	126	9			SI		942	960		10.1007/s11263-018-1082-6	http://dx.doi.org/10.1007/s11263-018-1082-6			19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	GQ3HQ		Green Submitted			2022-12-18	WOS:000441553300004
J	Lombaert, H; Grady, L; Pennec, X; Ayache, N; Cheriet, F				Lombaert, Herve; Grady, Leo; Pennec, Xavier; Ayache, Nicholas; Cheriet, Farida			Spectral Log-Demons: Diffeomorphic Image Registration with Very Large Deformations	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Image registration; Atlas construction; Spectral correspondence; Graph Laplacian	NONRIGID REGISTRATION; ALGORITHM; ATLAS; FRAMEWORK	This paper presents a new framework for capturing large and complex deformations in image registration and atlas construction. This challenging and recurrent problem in computer vision and medical imaging currently relies on iterative and local approaches, which are prone to local minima and, therefore, limit present methods to relatively small deformations. Our general framework introduces to this effect a new direct feature matching technique that finds global correspondences between images via simple nearest-neighbor searches. More specifically, very large image deformations are captured in Spectral Forces, which are derived from an improved graph spectral representation. We illustrate the benefits of our framework through a new enhanced version of the popular Log-Demons algorithm, named the Spectral Log-Demons, as well as through a groupwise extension, named the Groupwise Spectral Log-Demons, which is relevant for atlas construction. The evaluations of these extended versions demonstrate substantial improvements in accuracy and robustness to large deformations over the conventional Demons approaches.	[Lombaert, Herve] McGill Univ, Montreal, PQ, Canada; [Grady, Leo] HeartFlow Inc, Redwood City, CA USA; [Pennec, Xavier; Ayache, Nicholas] INRIA, Asclepios Team, Sophia Antipolis, France; [Cheriet, Farida] Ecole Polytech, Montreal, PQ H3C 3A7, Canada	McGill University; Inria; Universite de Montreal; Polytechnique Montreal	Lombaert, H (corresponding author), McGill Univ, Montreal, PQ, Canada.	herve.lombaert@mail.mcgill.ca	Pennec, Xavier/L-2537-2013	Pennec, Xavier/0000-0002-6617-7664	National Science and Engineering Research Council of Canada (NSERC); Fonds de Recherche du Quebec-descent (FQRNT)	National Science and Engineering Research Council of Canada (NSERC)(Natural Sciences and Engineering Research Council of Canada (NSERC)); Fonds de Recherche du Quebec-descent (FQRNT)	The authors wish to thank Pierre Croisille for the ex vivo cardiac images as well as Marco Lorenzi and Christof Seiler for constructive comments. We are also grateful to the anonymous reviewers for their suggestions. The project was supported financially by the National Science and Engineering Research Council of Canada (NSERC) and the Fonds de Recherche du Quebec-descent (FQRNT)	Allassonniere S, 2007, J R STAT SOC B, V69, P3; Avants B, 2004, NEUROIMAGE, V23, pS139, DOI 10.1016/j.neuroimage.2004.07.010; Beg MF, 2006, I S BIOMED IMAGING, P1116; Beg MF, 2005, INT J COMPUT VISION, V61, P139, DOI 10.1023/B:VISI.0000043755.93987.aa; Bhatia KK, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 AND 2, P908; Bossa M, 2007, LECT NOTES COMPUT SC, V4791, P667; Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143; Brox T, 2009, PROC CVPR IEEE, P41, DOI 10.1109/CVPRW.2009.5206697; Cachier P, 2003, COMPUT VIS IMAGE UND, V89, P272, DOI 10.1016/S1077-3142(03)00002-X; Carcassoni M, 2003, PATTERN RECOGN, V36, P193, DOI 10.1016/S0031-3203(02)00054-7; Carcassoni M, 2000, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2000.855881; Chui HL, 2000, PROC CVPR IEEE, P44, DOI 10.1109/CVPR.2000.854733; Chung F., 1997, AM MATH SOC, DOI 10.1090/cbms/092; Crum WR, 2004, BRIT J RADIOL, V77, pS140, DOI 10.1259/bjr/25329214; Ding C., 2004, ICML; Drineas P, 2005, J MACH LEARN RES, V6, P2153; Durrleman S, 2011, NEUROIMAGE, V55, P1073, DOI 10.1016/j.neuroimage.2010.11.056; Egozi A, 2010, IEEE T IMAGE PROCESS, V19, P1319, DOI 10.1109/TIP.2010.2040448; Fischl B, 1999, HUM BRAIN MAPP, V8, P272, DOI 10.1002/(SICI)1097-0193(1999)8:4<272::AID-HBM10>3.0.CO;2-4; Glocker B, 2011, ANNU REV BIOMED ENG, V13, P219, DOI 10.1146/annurev-bioeng-071910-124649; Grady L.J., 2010, DISCRETE CALCULUS AP; Guimond A, 2000, COMPUT VIS IMAGE UND, V77, P192, DOI 10.1006/cviu.1999.0815; JAIN V., 2006, INT C SHAP MOD APPL; Joshi S, 2004, NEUROIMAGE, V23, pS151, DOI 10.1016/j.neuroimage.2004.07.068; Konukoglu E, 2013, IEEE T PATTERN ANAL, V35, P2284, DOI 10.1109/TPAMI.2012.275; Liu C, 2008, LECT NOTES COMPUT SC, V5304, P28, DOI 10.1007/978-3-540-88690-7_3; Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147; Lombaert H., 2012, ECCV; Lombaert H., 2011, P 22 INT C INF PROC, P660; Lombaert H., 2012, MICCAI MCV; Lombaert Herve, 2013, Inf Process Med Imaging, V23, P376, DOI 10.1007/978-3-642-38868-2_32; Lombaert H, 2013, IEEE T PATTERN ANAL, V35, P2143, DOI 10.1109/TPAMI.2012.276; Lombaert H, 2012, IEEE T MED IMAGING, V31, P1436, DOI 10.1109/TMI.2012.2192743; Lombaert H, 2011, LECT NOTES COMPUT SC, V6666, P171, DOI 10.1007/978-3-642-21028-0_22; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Magnin I, 2011, LECT NOTES COMPUTER, P207; Magnus JR., 1985, ECONOMET THEOR, V1, P179, DOI [10.1017/S0266466600011129, DOI 10.1017/S0266466600011129]; Mansi T, 2011, INT J COMPUT VISION, V92, P92, DOI 10.1007/s11263-010-0405-z; Marsland S, 2003, LECT NOTES COMPUT SC, V2879, P771; Mateus D., 2008, PROC CVPR IEEE, P1, DOI DOI 10.1109/CVPR.2008.4587538; Meila M., 2000, NIPS; Miller MI, 2002, ANNU REV BIOMED ENG, V4, P375, DOI 10.1146/annurev.bioeng.4.092101.125733; Pennec X, 1999, LECT NOTES COMPUT SC, V1679, P597; Peyrat JM, 2007, IEEE T MED IMAGING, V26, P1500, DOI 10.1109/TMI.2007.907286; Ranjan S.R., 2011, AIPR, P1; Rapacchi S., 2010, ISMRM; Reuter M, 2010, INT J COMPUT VISION, V89, P287, DOI 10.1007/s11263-009-0278-1; Risser L, 2011, IEEE T MED IMAGING, V30, P1746, DOI 10.1109/TMI.2011.2146787; Robles-Kelly A, 2005, LECT NOTES COMPUT SC, V3691, P661; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284; SCOTT GL, 1991, P ROY SOC B-BIOL SCI, V244, P21, DOI 10.1098/rspb.1991.0045; SHAPIRO LS, 1992, IMAGE VISION COMPUT, V10, P283, DOI 10.1016/0262-8856(92)90043-3; Shekhovtsov A., 2007, P IEEE C COMP VIS PA, P1; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Studholme C, 2004, PATTERN RECOGN LETT, V25, P1191, DOI 10.1016/j.patrec.2004.03.015; Tlusty T, 2007, ELECTRON J LINEAR AL, V16, P315; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; van Kaick O, 2011, COMPUT GRAPH FORUM, V30, P1681, DOI 10.1111/j.1467-8659.2011.01884.x; Vercauteren T, 2008, LECT NOTES COMPUT SC, V5241, P754, DOI 10.1007/978-3-540-85988-8_90; Vercauteren T, 2009, NEUROIMAGE, V45, pS61, DOI 10.1016/j.neuroimage.2008.10.040; Vereauteren T, 2007, LECT NOTES COMPUT SC, V4792, P319; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Weiss Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P975, DOI 10.1109/ICCV.1999.790354; Wilson RC, 2010, PROC CVPR IEEE, P1903, DOI 10.1109/CVPR.2010.5539863; Wu GR, 2011, NEUROIMAGE, V56, P1968, DOI 10.1016/j.neuroimage.2011.03.050; Yeo BTT, 2010, IEEE T MED IMAGING, V29, P650, DOI 10.1109/TMI.2009.2030797; Zhang H, 2010, COMPUT GRAPH FORUM, V29, P1865, DOI 10.1111/j.1467-8659.2010.01655.x; Zikic D, 2011, IEEE I CONF COMP VIS, P49, DOI 10.1109/ICCV.2011.6126224; Zikic D, 2010, MED IMAGE ANAL, V14, P550, DOI 10.1016/j.media.2010.04.003; Zollei L., 2005, ICCV CVBIA	70	72	81	1	35	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2014	107	3					254	271		10.1007/s11263-013-0681-5	http://dx.doi.org/10.1007/s11263-013-0681-5			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AD6IU		Green Submitted			2022-12-18	WOS:000333362600003
J	Cruz-Mota, J; Bogdanova, I; Paquier, B; Bierlaire, M; Thiran, JP				Cruz-Mota, Javier; Bogdanova, Iva; Paquier, Benoit; Bierlaire, Michel; Thiran, Jean-Philippe			Scale Invariant Feature Transform on the Sphere: Theory and Applications	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Omnidirectional vision; (Spherical) image processing; Feature extraction; Object detection; SIFT; Matching	VISION; LOCALIZATION	A SIFT algorithm in spherical coordinates for omnidirectional images is proposed. This algorithm can generate two types of local descriptors, Local Spherical Descriptors and Local Planar Descriptors. With the first ones, point matching between two omnidirectional images can be performed, and with the second ones, the same matching process can be done but between omnidirectional and planar images. Furthermore, a planar to spherical mapping is introduced and an algorithm for its estimation is given. This mapping allows to extract objects from an omnidirectional image given their SIFT descriptors in a planar image. Several experiments, confirming the promising and accurate performance of the system, are conducted.	[Cruz-Mota, Javier; Bierlaire, Michel] Ecole Polytech Fed Lausanne, Transport & Mobil Lab TRANSP OR, CH-1015 Lausanne, Switzerland; [Bogdanova, Iva] Ecole Polytech Fed Lausanne, Pattern Recognit Lab PARLAB, CH-2000 Neuchatel, Switzerland; [Paquier, Benoit; Thiran, Jean-Philippe] Ecole Polytech Fed Lausanne, Signal Proc Lab 5, CH-1015 Lausanne, Switzerland	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Cruz-Mota, J (corresponding author), Ecole Polytech Fed Lausanne, Transport & Mobil Lab TRANSP OR, CH-1015 Lausanne, Switzerland.	javier.cruz@epfl.ch; iva.bogdanova@epfl.ch; benoit.paquier@epfl.ch; michel.bierlaire@epfl.ch; jp.thiran@epfl.ch		Bierlaire, Michel/0000-0002-5275-7692; Thiran, Jean-Philippe/0000-0003-2938-9657	Swiss National Science Foundation [200021-117823]	Swiss National Science Foundation(Swiss National Science Foundation (SNSF)European Commission)	This work is partly supported by the Swiss National Science Foundation under grant number 200021-117823. The authors would like to acknowledge the three unknown referees for their comments and suggestions, which considerably improved the quality of the paper.	Barut A., 1986, THEORY GROUP REPRESE; Baumberg A, 2000, PROC CVPR IEEE, P774, DOI 10.1109/CVPR.2000.855899; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Bogdanova I, 2007, IEEE T IMAGE PROCESS, V16, P1888, DOI 10.1109/TIP.2007.899008; Boult TE, 2001, P IEEE, V89, P1382, DOI 10.1109/5.959337; Brox T, 2010, IEEE T PATTERN ANAL, V32, P402, DOI 10.1109/TPAMI.2009.32; Bulow T, 2004, IEEE T PATTERN ANAL, V26, P1650, DOI 10.1109/TPAMI.2004.129; Bur A, 2006, INT C PATT RECOG, P695; Chen CH, 2008, IEEE T CIRC SYST VID, V18, P1052, DOI 10.1109/TCSVT.2008.928223; DRISCOLL JR, 1994, ADV APPL MATH, V15, P202, DOI 10.1006/aama.1994.1008; Ehlgen T, 2008, IEEE T INTELL TRANSP, V9, P657, DOI 10.1109/TITS.2008.2006815; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Geyer C, 2001, INT J COMPUT VISION, V45, P223, DOI 10.1023/A:1013610201135; Goedeme T., 2005, WORKSH OMN VIS CAM N; Hadj-Abdelkader H., 2008, WORKSH OMN VIS CAM N; Hansen P., 2007, P IEEE RSJ INT C INT, P1668, DOI [10.1109/IROS.2007.4399266, DOI 10.1109/IROS.2007.4399266]; Hansen P, 2007, IEEE I CONF COMP VIS, P512; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; Mauthner T., 2006, P COMP VIS WINT WORK; Menegatti E, 2006, IEEE T ROBOT, V22, P523, DOI 10.1109/TRO.2006.875495; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Rodrigues B. O., 1840, J MATH PURE APPL, V5, P380; Scaramuzza D, 2008, IEEE T ROBOT, V24, P1015, DOI 10.1109/TRO.2008.2004490; Sirmacek B, 2009, IEEE T GEOSCI REMOTE, V47, P1156, DOI 10.1109/TGRS.2008.2008440; Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710; Tamimi H, 2006, ROBOT AUTON SYST, V54, P758, DOI 10.1016/j.robot.2006.04.018; Tosic I, 2009, MULTI-CAMERA NETWORKS: PRINCIPLES AND APPLICATIONS, P239, DOI 10.1016/B978-0-12-374633-7.00010-0; Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017; Tygert M, 2008, J COMPUT PHYS, V227, P4260, DOI 10.1016/j.jcp.2007.12.019; VALGREN C, 2007, P EUR C MOB ROB ECMR; Van Gool L., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P642, DOI 10.1007/BFb0015574; Vedaldi A., 2008, VLFEAT OPEN PORTABLE; Vincenty T., 1975, SURV REV, V23, P88, DOI [10.1179/sre.1975.23.176.88, DOI 10.1179/SRE.1975.23.176.88]; Yuen DCK, 2005, IEEE T ROBOT, V21, P217, DOI 10.1109/TRO.2004.835452; Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345	40	72	80	1	19	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2012	98	2					217	241		10.1007/s11263-011-0505-4	http://dx.doi.org/10.1007/s11263-011-0505-4			25	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	934NH		Green Submitted			2022-12-18	WOS:000303450500006
J	Chandrasekhar, V; Takacs, G; Chen, DM; Tsai, SS; Reznik, Y; Grzeszczuk, R; Girod, B				Chandrasekhar, Vijay; Takacs, Gabriel; Chen, David M.; Tsai, Sam S.; Reznik, Yuriy; Grzeszczuk, Radek; Girod, Bernd			Compressed Histogram of Gradients: A Low-Bitrate Descriptor	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	Computer Vision and Pattern Recognition (CVPR)	JUN 22-24, 2009	Miami Beach, FL			CHoG; Feature descriptor; Mobile visual search; Content-based image retrieval; Histogram-of-gradients; Low bitrate		Establishing visual correspondences is an essential component of many computer vision problems, which is often done with local feature-descriptors. Transmission and storage of these descriptors are of critical importance in the context of mobile visual search applications. We propose a framework for computing low bit-rate feature descriptors with a 20x reduction in bit rate compared to state-of-the-art descriptors. The framework offers low complexity and has significant speed-up in the matching stage. We show how to efficiently compute distances between descriptors in the compressed domain eliminating the need for decoding. We perform a comprehensive performance comparison with SIFT, SURF, BRIEF, MPEG-7 image signatures and other low bit-rate descriptors and show that our proposed CHoG descriptor outperforms existing schemes significantly over a wide range of bitrates. We implement the descriptor in a mobile image retrieval system and for a database of 1 million CD, DVD and book covers, we achieve 96% retrieval accuracy using only 4 KB of data per query image.	[Chandrasekhar, Vijay; Takacs, Gabriel; Chen, David M.; Tsai, Sam S.; Reznik, Yuriy; Grzeszczuk, Radek; Girod, Bernd] Stanford Univ, Stanford, CA 94305 USA	Stanford University	Chandrasekhar, V (corresponding author), Stanford Univ, Stanford, CA 94305 USA.	vijayc@stanford.edu						[Anonymous], 2005, THESIS MIT CAMBRIDGE; Banerjee A, 2004, SIAM PROC S, P234; Bay H., 2006, ECCV; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Brasnett Paul, 2007, P IET VIS INF ENG C; Calonder M., 2010, P EUR C COMP VIS ECC, P6; Chandrasekhar J, 2010, IEEE ICC; Chandrasekhar V., 2009, P IEEE C COMP VIS PA; Chandrasekhar V., 2009, P VIS COMM IM PROC C; Chandrasekhar V., 2010, P IEEE INT WORKSH MO; CHOU PA, 1989, IEEE T ACOUSTICS SPE, V37; CONWAY JH, 1982, IEEE T INFORM THEORY, V28, P227, DOI 10.1109/TIT.1982.1056484; Cover T.M, 2006, WILEY SERIES TELECOM; Dalal N., 2005, HISTOGRAMS ORIENTED; Erol B., 2008, P 16 ACM MULT C NEW; Freeman W. T., 1994, P INT WORKSH AUT FAC, P296; Gagie T, 2006, INFORM PROCESS LETT, V97, P133, DOI 10.1016/j.ipl.2005.10.006; Girod B., 2010, IEEE SIGNAL IN PRESS; Girod B., 2010, P INT MOB MULT WORKS; Google, 2009, GOOGL GOOGL; Graham J., 2008, P CHI 08 HUM FACT CO; Hua G., 2007, P INT C COMP VIS ICC; Hull J. J., 2007, P 17 INT C ART REAL; Jegou H, 2008, P EUR C COMP VIS ECC; Jegou H., 2010, IEEE T PATT IN PRESS; Johnson M, 2010, P BRIT MACH VIS C BM; Ke Y, 2004, PROC CVPR IEEE, P506; KULLBACK S, 1987, AM STAT, V41, P340; Lowe D. G., 1999, P IEEE C COMP VIS PA; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Makar M., 2009, P IEEE INT C AC SPEE; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Nister D., 2006, P 2006 IEEE COMP SOC; Nokia, 2006, NOK POINT FIND; Philbin J., 2008, P IEEE C COMP VIS PA; Rebollo-Monedero D., 2007, THESIS STANFORD U; Reznik Y., 2010, P SPIE WORKSH APPL D; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Shao H., 2003, 260 ETH; Sommerville D., 1958, INTRO GEOMETRY N DIM; Takacs G., 2008, P ACM INT C MULT INF; Tola E., 2008, P 2008 IEEE C COMP V, P1, DOI DOI 10.1109/CVPR.2008.4587673; Torralba A., 2008, P IEEE C COMP VIS PA; Tsai S. S., 2010, P ACM MULT ACM MM FL; Weiss Y., 2008, P NEUR INF PROC SYST; Winder S., 2009, P COMP VIS PATT REC; Winder SAJ, 2007, PROC CVPR IEEE, P17; Yeo C., 2008, P IEEE INT C IM PROC	49	72	88	0	20	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	FEB	2012	96	3					384	399		10.1007/s11263-011-0453-z	http://dx.doi.org/10.1007/s11263-011-0453-z			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	885HK					2022-12-18	WOS:000299769400007
J	Tsiamyrtzis, P; Dowdall, J; Shastri, D; Pavlidis, IT				Tsiamyrtzis, P.; Dowdall, J.; Shastri, D.; Pavlidis, I. T.			Imaging facial physiology for the detection of deceit	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	3rd Workshop on Object Tracking and Classification Beyond the Visible Spectrum	JUN 22, 2006	New York, NY	IEEE		deception detection; polygraph; thermography; facial tracking; contact-free physiological monitoring	TRACKING; CATCH; FACE	Previous work has demonstrated the correlation of increased blood perfusion in the orbital muscles and stress levels for human beings. It has also been suggested that this periorbital perfusion can be quantified through the processing of thermal video. The idea has been based on the fact that skin temperature is heavily modulated by superficial blood flow. Proof of this concept was established for two different types of stress inducing experiments: startle experiments and mock-crime polygraph interrogations. However, the polygraph interrogation scenarios were simplistic and highly constrained. In the present paper, we report results derived from a large and realistic mock-crime interrogation experiment. The interrogation is free flowing and no restrictions have been placed on the subjects. Additionally, we propose a new methodology to compute the mean periorbital temperature signal. The present approach addresses the deficiencies of the earlier methodology and is capable of coping with the challenges posed by the realistic setting. Specifically, it features a tandem CONDENSATION tracker to register the periorbital area in the context of a moving face. It operates on the raw temperature signal and tries to improve the information content by suppressing the noise level instead of amplifying the signal as a whole. Finally, a pattern recognition method classifies stressful (Deceptive) from non-stressful (Non-Deceptive) subjects based on a comparative measure between the entire interrogation signal (baseline) and a critical subsection of it (transient response). The successful classification rate is 87.2% for 39 subjects. This is on par with the success rate achieved by highly trained psycho-physiological experts and opens the way for automating lie detection in realistic settings.	Athens Univ Econ & Business, Dept Stat, Athens 10434, Greece; Univ Houston, Dept Comp Sci, Houston, TX 77204 USA; SUNY Buffalo, Sch Informat, Dept Commun, Buffalo, NY 14260 USA; Univ Calif San Francisco, Dept Psychiat, San Francisco, CA 94143 USA	Athens University of Economics & Business; University of Houston System; University of Houston; State University of New York (SUNY) System; State University of New York (SUNY) Buffalo; University of California System; University of California San Francisco	Tsiamyrtzis, P (corresponding author), Athens Univ Econ & Business, Dept Stat, 76 Patiss St, Athens 10434, Greece.	pt@aueb.gr; jbdowdal@central.uh.edu; djshastr@bayou.uh.edu; ipavlidi@central.uh.edu	Tsiamyrtzis, Panagiotis/AAE-8878-2022; Pavlidis, Ioannis/AAH-3817-2019	Tsiamyrtzis, Panagiotis/0000-0002-3180-4090; Pavlidis, Ioannis/0000-0001-8025-2600				Baker S, 2001, PROC CVPR IEEE, P1090; *COMM REV SCI EV P, 2003, POL LIE DET; COOLEY JW, 1965, MATH COMPUT, V19, P297, DOI 10.2307/2003354; Doucet A., 2001, SEQUENTIAL MONTE CAR; DRUMMOND PD, 1987, BRAIN, V110, P793, DOI 10.1093/brain/110.3.793; DUPROS F, 2004, UHCS0402; EKMAN P, 1991, AM PSYCHOL, V46, P913, DOI 10.1037/0003-066X.46.9.913; Ekman P, 1996, SOC RES, V63, P801; Ekman P., 2001, TELLING LIES CLUES D, V3rd; EKMAN P, 1986, TELLING LIES; Eveland CK, 2003, IMAGE VISION COMPUT, V21, P579, DOI 10.1016/S0262-8856(03)00056-8; Frank MG, 1997, J PERS SOC PSYCHOL, V72, P1429, DOI 10.1037/0022-3514.72.6.1429; Garbey M, 2004, PROC CVPR IEEE, P356; Inbau F.E., 2011, CRIMINAL INTERROGATI; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594; ISARD M, 1998, P 5 EUR C COMP VIS, V1, P893; John M., 2000, LECT NOTES COMPUTER, P3, DOI DOI 10.1007/3-540-45053-X1; KLEINMUNTZ B, 1984, AM PSYCHOL, V39, P766, DOI 10.1037/0003-066X.39.7.766; Knight J, 2004, NATURE, V428, P692, DOI 10.1038/428692a; Kolsch M., 2004, IEEE WORKSH REAL TIM, P158, DOI DOI 10.1109/CVPR.2004.345; MacCormick J, 2000, INT J COMPUT VISION, V39, P57, DOI 10.1023/A:1008122218374; Martini F., 2001, FUNDAMENTALS ANATOMY; Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16; Pavlidis I, 2002, NATURE, V415, P35, DOI 10.1038/415035a; Pavlidis I, 2000, IEEE WORKSHOP ON COMPUTER VISION BEYOND THE VISIBLE SPECTRUM: METHODS AND APPLICATIONS, PROCEEDINGS, P104, DOI 10.1109/CVBVS.2000.855255; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; Smith S.W, 1999, SCI ENG GUIDE DIGITA; Sokolov EN, 1997, ATTENTION AND ORIENTING: SENSORY AND MOTIVATIONAL PROCESSES, P1; Verma RC, 2003, IEEE T PATTERN ANAL, V25, P1215, DOI 10.1109/TPAMI.2003.1233896; Yankee W., 1965, POLICE, V9, P12	31	72	80	1	31	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	FEB	2007	71	2					197	214		10.1007/s11263-006-6106-y	http://dx.doi.org/10.1007/s11263-006-6106-y			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	098DN					2022-12-18	WOS:000241501300006
J	Criminisi, A; Blake, A; Rother, C; Shotton, J; Torr, PHS				Criminisi, A.; Blake, A.; Rother, C.; Shotton, J.; Torr, P. H. S.			Efficient dense stereo with occlusions for new view-synthesis by four-state dynamic programming	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						dense stereo; image-based rendering; video-conferencing; gaze correction		A new algorithm is proposed for efficient stereo and novel view synthesis. Given the video streams acquired by two synchronized cameras the proposed algorithm synthesises images from a virtual camera in arbitrary position near the physical cameras. The new technique is based on an improved, dynamic-programming, stereo algorithm for efficient novel view generation. The two main contributions of this paper are: (i) a new four state matching graph for dense stereo dynamic programming, that supports accurate occlusion labelling; (ii) a compact geometric derivation for novel view synthesis by direct projection of the minimum cost surface. Furthermore, the paper presents an algorithm for the temporal maintenance of a background model to enhance the rendering of occlusions and reduce temporal artefacts (flicker); and a cost aggregation algorithm that acts directly in the three-dimensional matching cost space. The proposed algorithm has been designed to work with input images with large disparity range, a common practical situation. The enhanced occlusion handling capabilities of the new dynamic programming algorithm are evaluated against those of the most powerful state-of-the-art dynamic programming and graph-cut techniques. Four-state DP is also evaluated against the disparity-based Middlebury error metrics and its performance found to be amongst the best of the efficient algorithms. A number of examples demonstrate the robustness of four-state DP to artefacts in stereo video streams. This includes demonstrations of cyclopean view synthesis in extended conversational sequences, synthesis from a freely translating virtual camera and, finally, basic 3D scene editing.	Microsoft Res Ltd, Cambridge, England; Univ Cambridge, Cambridge, England; Oxford Brookes Univ, Oxford OX3 0BP, England	Microsoft; University of Cambridge; Oxford Brookes University	Criminisi, A (corresponding author), Microsoft Res Ltd, 7 JJ Thomson Ave, Cambridge, England.							Belhumeur P. N., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P506, DOI 10.1109/CVPR.1992.223143; BUEHLER C, 2002, P EUR C COMP VIS COP; Chen S. E., 1993, Computer Graphics Proceedings, P279, DOI 10.1145/166117.166153; COX I, 1993, Patent No. 5359362; Cox IJ, 1996, COMPUT VIS IMAGE UND, V63, P542, DOI 10.1006/cviu.1996.0040; CRIMINISI A, 2003, P INT C COMP VIS NIC; GEMMELL J, 2000, IEEE MULTIMEDIA, V7; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; ISHIKAWA H, 1998, EUR C COMP VIS, P232; Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668; KOLMOGOROV V, 2006, IN PERSS PATTERN ANA; KOLMOGOROV V, 2005, COMPUTER VISION PATT; KOLMOGOROV V, 2002, P EUR C COMP VIS, P82; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Scharstein D, 1999, LECT NOTES COMPUTER, V1583; SUN J, 2002, P EUR C COMP VIS COP; Szeliski R., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P781, DOI 10.1109/ICCV.1999.790301; Vetter T, 1998, INT J COMPUT VISION, V28, P103, DOI 10.1023/A:1008058932445; YANG R, 2002, P EUR C COMP VIS COP, V2, P479	20	72	84	0	14	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2007	71	1					89	110		10.1007/s11263-006-8525-1	http://dx.doi.org/10.1007/s11263-006-8525-1			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	094GT					2022-12-18	WOS:000241228600004
J	Swaminathan, R; Grossberg, MD; Nayar, SK				Swaminathan, R; Grossberg, MD; Nayar, SK			Non-single viewpoint catadioptric cameras: Geometry and analysis	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						catadoptric system; conic section; non-single viewpoint; caustics; viewpoint surface; self-calibration; sensor resolution		Conventional vision systems and algorithms assume the imaging system to have a single viewpoint. However, these imaging systems need not always maintain a single viewpoint. For instance, an incorrectly aligned catadioptric system could cause non-single viewpoints. Moreover, a lot of flexibility in imaging system design can be achieved by relaxing the need for imaging systems to have a single viewpoint. Thus, imaging systems with non-single viewpoints can be designed for specific imaging tasks, or image characteristics such as field of view and resolution. The viewpoint locus of such imaging systems is called a caustic. In this paper, we present an in-depth analysis of caustics of catadioptric cameras with conic reflectors. We use a simple parametric model for both, the reflector and the imaging system, to derive an analytic solution for the caustic surface. This model completely describes the imaging system and provides a map from pixels in the image to their Corresponding viewpoints and viewing direction. We use the model to analyze the imaging system's properties such as field of view, resolution and other geometric properties of the caustic itself. In addition, we present a simple technique to calibrate the class of conic catadioptric cameras and estimate their caustics from known camera motion. The analysis and results we present in this paper are general and can be applied to any catadioptric imaging system whose reflector has a parametric form.	Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Columbia University	Swaminathan, R (corresponding author), Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.	srahul@cs.columbia.edu; mdog@cs.columbia.edu; nayar@cs.columbia.edu		Swaminathan, Rahul/0000-0003-1647-6313				Arnold VI., 1989, MATH METHODS CLASSIC, V2, DOI [10.1007/978-1-4757-1693-1, 10.1007/978-1-4757-2063-1, DOI 10.1007/978-1-4757-2063-1]; Baker S, 1999, INT J COMPUT VISION, V35, P175, DOI 10.1023/A:1008128724364; Baker S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P35, DOI 10.1109/ICCV.1998.710698; BOGNER S, 1995, IEEE SMC C, V54, P3100; BOLLES RC, 1997, DARPA IUW, P41; Born M., 1968, PRINCIPLES OPTICS; BRUCE JW, 1981, AM MATH MON, V88, P651, DOI 10.2307/2320669; BURKHARD DG, 1973, J OPT SOC AM, V63, P299, DOI 10.1364/JOSA.63.000299; Chahl JS, 1997, APPL OPTICS, V36, P8275, DOI 10.1364/AO.36.008275; CHARLES J, 1987, ASTRONOMY MAGAZINE; Derrien S., 2000, INT C ROB AUT, P3932; GACHTER S, 2001, OVERVIEWS WORKSH OMN, P99; Gaspar J, 2002, THIRD WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P27, DOI 10.1109/OMNVIS.2002.1044487; GLUCKMAN J, 1999, P CVPR, P1; Grossberg MD, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P108, DOI 10.1109/ICCV.2001.937611; GYEER C, 1999, P ICCV, P398; Hamilton W.R., 1828, T ROYAL IRISH ACAD, V15, P69; HICKS A, 2002, DIFFERENTIAL METHODS; HICKS R, 2000, P IEEE INT C COMP VI, V1, P545, DOI DOI 10.1109/CVPR.2000.855867; Hicks RA, 2002, THIRD WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P13, DOI 10.1109/OMNVIS.2002.1044485; HONG JW, 1990, DARPA IUW, P782; Kang SB, 2000, PROC CVPR IEEE, P201, DOI 10.1109/CVPR.2000.855820; MURPHY J, 1997, IEEE SMC C, V36, P3117; NALWA V, 1996, TRUE MONIDIRECTIONAL; Nayar SK, 1997, PROC CVPR IEEE, P482, DOI 10.1109/CVPR.1997.609369; NAYAR SK, P CVPR, P388; Pajdla T, 2002, INT J COMPUT VISION, V47, P161, DOI 10.1023/A:1014593824520; PAJDLA T, 2001, COMP VIS WINT WORKSH, P223; Peleg S, 2000, PROC CVPR IEEE, P208, DOI 10.1109/CVPR.2000.855821; PERI VN, 1997, DARPA IUW, P1; Rees D. W., 1970, US Patent, Patent No. 3505465; SEITZ, 2001, P ICCV, P1; SRINIVASAN M, 2003, P OMNIVIS; Swaminathan R, 2003, PROC CVPR IEEE, P594; Swaminathan R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P2, DOI 10.1109/ICCV.2001.937581; SWAMINATHAN R, 2001, CUCS00401 DEP COMP S; Weinshall D, 2002, LECT NOTES COMPUT SC, V2350, P614; YAGI Y, 1994, IEEE T ROBOTIC AUTOM, V10, P11, DOI 10.1109/70.285581; Yagi Y., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P160, DOI 10.1109/CVPR.1991.139681; YAMAZAWA K, 1993, IROS 93 : PROCEEDINGS OF THE 1993 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOL 1-3, P1029, DOI 10.1109/IROS.1993.583287	40	72	79	1	13	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2006	66	3					211	229		10.1007/s11263-005-3220-1	http://dx.doi.org/10.1007/s11263-005-3220-1			19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	028GP		Green Submitted			2022-12-18	WOS:000236475400001
J	Zhao, WY; Chellappa, R				Zhao, WY; Chellappa, R			Symmetric shape-from-shading using self-ratio image	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						shape-from-shading (SFS); Lambertian model with varying albedo; self-ratio image; symmetric SFS; symmetric source-from-shading	ILLUMINANT DIRECTION; RECONSTRUCTION; INTEGRABILITY; SURFACES	In this paper, we present a symmetric shape-from-shading (SFS) approach to recover both shape and albedo for symmetric objects. Lambertian surfaces with unknown varying albedo and orthographic projections are assumed. In our formulation of symmetric SFS, we have two image irradiance equations. One is the standard equation used in SFS, and the other is a self-ratio image irradiance equation. This new image irradiance equation relates the self-ratio image which is defined as the ratio of two-halves of the input image to light source and surface shape. The introduction of the self-ratio image facilitates the direct use of symmetry cue. Based on the self-ratio image, a new model-based symmetric source-from-shading algorithm is also presented. We then propose symmetric SFS algorithms to recover both shape and albedo from a single image and present experimental results. The new symmetric SFS scheme has one important property: the existence of a unique (global) solution which consists of unique (local) solutions at each point simultaneously obtained using the intensity information at that point and the surrounding local region and the assumption of a C-2 surface. Proofs for the existence of a unique solution in the cases of unknown constant and non-constant albedos are provided.	Sarnoff Corp, Princeton, NJ 08540 USA; Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA	Sarnoff Corporation; University System of Maryland; University of Maryland College Park	Zhao, WY (corresponding author), Sarnoff Corp, 201 Washington Rd, Princeton, NJ 08540 USA.		Chellappa, Rama/B-6573-2012; Chellappa, Rama/AAJ-1504-2020; Chellappa, Rama/AAV-8690-2020					Atick JJ, 1996, NEURAL COMPUT, V8, P1321, DOI 10.1162/neco.1996.8.6.1321; BERTERO M, 1987, 924 MIT ART INT LAB; Berthold KP Horn, 1970, SHAPE SHADING METHOD, P1; Bichsel M., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P459, DOI 10.1109/CVPR.1992.223150; BRUSS AR, 1982, J MATH PHYS, V23, P890, DOI 10.1063/1.525441; Dupuis P., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P453, DOI 10.1109/CVPR.1992.223151; FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909; Horn B.K.P., 1989, SHAPE SHADING; HORN BKP, 1990, INT J COMPUT VISION, V5, P37, DOI 10.1007/BF00056771; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; Jacobs DW, 1998, PROC CVPR IEEE, P610, DOI 10.1109/CVPR.1998.698668; LEE CH, 1989, SHAPE SHADING, P323; NAYAR SK, 1991, IEEE T PATTERN ANAL, V13, P611, DOI 10.1109/34.85654; OLIENSIS J, 1991, INT J COMPUT VISION, V6, P75, DOI 10.1007/BF00128151; ONN R, 1990, INT J COMPUT VISION, V5, P105, DOI 10.1007/BF00056773; PENTLAND AP, 1982, J OPT SOC AM, V72, P448, DOI 10.1364/JOSA.72.000448; Riklin-Raviv T., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P566, DOI 10.1109/CVPR.1999.784968; SAXBERG BVH, 1989, 1117 MIT ART INT LAB; Shimshoni I, 2000, INT J COMPUT VISION, V39, P97, DOI 10.1023/A:1008118909580; TSAI PS, 1994, IMAGE VISION COMPUT, V12, P487, DOI 10.1016/0262-8856(94)90002-7; Wei GQ, 1997, IEEE T PATTERN ANAL, V19, P353, DOI 10.1109/34.588016; WOLF M, 1994, DRUS ISTRAZ, V3, P247; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284; ZHAO W, 1999, THESIS U MARYLAND; Zhao WY, 2000, PROC CVPR IEEE, P286, DOI 10.1109/CVPR.2000.855831; ZHENG QF, 1991, IEEE T PATTERN ANAL, V13, P680, DOI 10.1109/34.85658	27	72	74	0	1	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	OCT	2001	45	1					55	75		10.1023/A:1012369907247	http://dx.doi.org/10.1023/A:1012369907247			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	487JN					2022-12-18	WOS:000171872100004
J	Boutin, M				Boutin, M			Numerically invariant signature curves	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						curvature; torsion; object recognition; differential invariant; joint invariant; signature curve; Euclidean group; equi-affine group; numerical approximation		Corrected versions of the numerically invariant expressions for the affine and Euclidean signature of a planar curve introduced by Calabi et al. in (Int. J. Comput. Vision, 26: 107-135, 1998) are presented. The new formulas are valid for fine but otherwise arbitrary partitions of the curve. We also give numerically invariant expressions for the four differential invariants parameterizing the three dimensional version of the Euclidean signature curve, namely the curvature, the torsion and their derivatives with respect to arc length.	Univ Minnesota, Minneapolis, MN 55455 USA	University of Minnesota System; University of Minnesota Twin Cities	Boutin, M (corresponding author), Univ Minnesota, Minneapolis, MN 55455 USA.			Boutin, Mireille/0000-0002-0837-6577				Calabi E, 1998, INT J COMPUT VISION, V26, P107, DOI 10.1023/A:1007992709392; CARTAN E, 1935, EXPOSES GEOMETRIE, V5; Do Carmo M.P., 2016, DIFFERENTIAL GEOMETR, Vsecond; EVES H, 1965, SURVEY GEOMETRY, V2; Friedman M., 1993, FUNDAMENTALS COMPUTE	5	72	72	0	4	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	2000	40	3					235	248		10.1023/A:1008139427340	http://dx.doi.org/10.1023/A:1008139427340			14	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	399MK					2022-12-18	WOS:000166816800004
J	Ivanov, Y; Bobick, A				Ivanov, Y; Bobick, A			Fast lighting independent background subtraction	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	1st IEEE Workshop on Visual Surveillance	JAN 02, 1998	BOMBAY, INDIA	IEEE Comp Soc		background subtraction; image segmentation; stereo; disparity warp	TRACKING	This paper describes a simple method of fast background subtraction based upon disparity verification that is invariant to arbitrarily rapid run-time changes in illumination. Using two or more cameras, the method requires the off-line construction of disparity fields mapping the primary background images. At runtime, segmentation is performed by checking background image to each of the additional auxiliary color intensity values at corresponding pixels. If more than two cameras are available, more robust segmentation can be achieved and, in particular, the occlusion shadows can be generally eliminated as well. Because the method only assumes fixed background geometry, the technique allows for illumination variation at runtime. Since no disparity search is performed, the algorithm is easily implemented in real-time on conventional hardware.	MIT, Media Lab, Cambridge, MA 02139 USA; Georgia Inst Technol, Coll Comp, Atlanta, GA 30332 USA	Massachusetts Institute of Technology (MIT); University System of Georgia; Georgia Institute of Technology	Ivanov, Y (corresponding author), MIT, Media Lab, 20 Ames St,E15-368A, Cambridge, MA 02139 USA.							BRILL FZ, 1998, IM UND WORKSH MONT C, P267; Darrell T., 1994, Proceedings of the Workshop on Visual Behaviors, P68, DOI 10.1109/VL.1994.365599; GASPAR J, 1994, INT WORKSH INT ROB S; Intille SS, 1997, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.1997.609402; KANADE T, 1995, P IM UND WORKSH PALM, P805; OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955; OLIVER N, 1999, P ICVS 99 GRAN CAN S; PINHANEZ CS, 1999, P ACM MULT 98 WORKSH, P22; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236; [No title captured]	11	72	74	0	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2000	37	2					199	207		10.1023/A:1008107805263	http://dx.doi.org/10.1023/A:1008107805263			9	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	341FD					2022-12-18	WOS:000088579600006
J	ZHANG, ZY; FAUGERAS, OD				ZHANG, ZY; FAUGERAS, OD			3-DIMENSIONAL MOTION COMPUTATION AND OBJECT SEGMENTATION IN A LONG SEQUENCE OF STEREO FRAMES	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							IMAGE SEQUENCES; FEATURE POINTS; ALGORITHM; PARAMETERS; TRACKING; FLOW	We address the problem of computing the three-dimensional motions of objects in a long sequence of stereo frames. Our approach is bottom-up and consists of two levels. The first level deals with the tracking of 3D tokens from frame to frame and the estimation of their kinematics. The processing is completely parallel for each token. The second level groups tokens into objects based on their kinematic parameters, controls the processing at the low level to cope with problems such as occlusion, disappearance, and appearance of tokens, and provides information to other components of the system. We have implemented this approach using 3D line segments obtained from stereo as the tokens. We use classical kinematics and derive closed-form solutions for some special, but useful, cases of motions. The motion computation problem is then formulated as a tracking problem in order to apply the extended Kalman filter. The tracking is performed in a prediction-matching-update loop in which multiple matches can be handled. Tokens are labeled by a number called its support of existence which measures their adequation to the measurements. If this number goes beyond a threshold, the token disappears. The individual line segments can be grouped into rigid objects according to the similarity of their kinematic parameters. Experiments using synthetic and real data have been carried out and the results found to be quite good.	IST NATL RECH INFORMAT & AUTOMAT SOPHIA ANTIPOLIS, F-06565 VALBONNE, FRANCE									AGGARWAL JK, 1987, MAR P INT C ROB AUT, P1275; AYACHE N, 1989, IEEE T ROBOTIC AUTOM, V5, P804, DOI 10.1109/70.88101; AYACHE N, 1987, 1ST P INT C COMP VIS, P422; AYACHE N, 1987, 1ST P INT C COMP VIS, P73; AYACHE N, 1988, THESIS U PARIS 11 PA; AYACHE N, INRIA789 REP; AYACHE N, 1987, 4TH INT S ROB RES SA; BAKER HH, 1981, 7TH P INT JOINT C AR, P631; Bar-Shalom Y., 1988, TRACKING DATA ASS; BROIDA TJ, 1986, MAY P IEEE WORKSH MO, P95; BROIDE T, 1989, MAR P IEEE WORKSH VI, P21; Crowley J. L., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P658, DOI 10.1109/CCV.1988.590047; DERICHE R, 1990, P 1 EUR C COMP VIS, P259; Dickmanns E.D., 1988, MACH VISION APPL, V1, P241; DICKMANNS ED, 1987, P 4 ROB RES, P73; DICKMANNS ED, 1988, MACH VISION APPL, V1, P223; Durrant-Whyte HF, 1988, INTEGRATION COORDINA; Faugeras O. D., 1988, Proceedings of IAPR Workshop on Computer Vision: Special Hardware and Industrial Applications, P35; Faugeras O. D., 1988, 9th International Conference on Pattern Recognition (IEEE Cat. No.88CH2614-6), P242, DOI 10.1109/ICPR.1988.28214; FAUGERAS OD, 1990, INT J COMPUT VISION, V4, P225, DOI 10.1007/BF00054997; FAUGERAS OD, 1991, IN PRESS 3 DIMENSION; FAUGERAS OD, 1990, 1ST P ECCV, P107; FAUGERAS OD, 1990, ARTIF INTELL J, V44; FAUGERAS OD, 1986, JUN P IEEE C COMP VI, P15; FAUGERAS OD, INRIA788 TECHN REP; FAUGERAS OD, INRIA1157 TECHN REP; GAMBOTTO JP, 1989, MAR P IEEE WORKSH VI, P38; GENNERY DB, 1982, P AM ASS ARTIF INTEL; Gibson James J., 1950, PERCEPTION VISUAL WO, P3; GORDON GL, 1989, MAR P IEEE WORKSH VI, P13; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615; GRIMSON WEL, 1981, IMAGES SURFACES; HILDRETH C, 1984, MEASUREMENT VISUAL M; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HUANG TS, 1981, IMAGE SEQUENCE PROCE; HWANG VSS, 1989, PATTERN RECOGN, V22, P247, DOI 10.1016/0031-3203(89)90073-3; JENKIN M, 1986, COMPUT VISION GRAPH, V33, P16, DOI 10.1016/0734-189X(86)90219-7; KIM YC, 1987, IEEE T ROBOTIC AUTOM, V3, P599; Kitamura Y., 1990, Advanced Robotics, V4, P29, DOI 10.1163/156855390X00035; KOENDERINK JJ, 1975, OPT ACTA, V22, P773, DOI 10.1080/713819112; KOENDERINK JJ, 1986, VISION RES, V26, P161, DOI 10.1016/0042-6989(86)90078-7; KOENDERINK JJ, 1978, AMBULANT OBSERVER CA; LIU YC, 1988, COMPUT VISION GRAPH, V44, P35, DOI 10.1016/S0734-189X(88)80030-6; LIU YC, 1986, MAY P IEEE WORKSH MO, P47; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Lowerre B., 1980, TRENDS SPEECH RECOGN; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482; Maybeck P. S., 1982, STOCHASTIC MODELS ES, V2; Maybeck P. S., 1982, STOCHASTIC MODELS ES; Nagel H., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P1174; NAGEL HH, 1983, COMPUT VISION GRAPH, V21, P85, DOI 10.1016/S0734-189X(83)80030-9; NISHIHARA HK, 1984, AI780 MIT TECHN REP; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; POLLARD SB, 1985, PERCEPTION, V14, P449, DOI 10.1068/p140449; ROACH JW, 1979, IEEE T PATTERN ANAL, V1, P127, DOI 10.1109/TPAMI.1979.4766898; ROBERTS K, 1988, JUN P IEEE C COMP VI, P635; Rodrigues O., 1840, J MATH PURE APPL, V5, P380; SETHI IK, 1987, IEEE T PATTERN ANAL, V9, P56, DOI 10.1109/TPAMI.1987.4767872; TSAI RY, 1981, IEEE T ACOUST SPEECH, V29, P1147, DOI 10.1109/TASSP.1981.1163710; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; WEBB JA, 1982, ARTIF INTELL, V19, P107, DOI 10.1016/0004-3702(82)90023-6; WENG JY, 1987, IEEE T PATTERN ANAL, V9, P370, DOI 10.1109/TPAMI.1987.4767920; YACHIDA M, 1986, ROBOTICS RES, P11; YEN BL, 1983, JUN P C COMP VIS PAT, P267; Young G.-S., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P710, DOI 10.1109/CVPR.1988.196312; Zhang Z., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P38, DOI 10.1109/ICPR.1990.118061; ZHANG Z, 1988, 2ND P INT C COMP VIS, P177; ZHANG Z, 1990, 9TH P EUR C ART INT, P747; ZHANG Z, 1990, THESIS U PARIS SUD O; ZHANG Z, 1992, IN PRESS IEEE T PATT; ZHANG ZY, 1991, IMAGE VISION COMPUT, V9, P10, DOI 10.1016/0262-8856(91)90043-O; ZHUANG X, 1985, JUN P IEEE C COMP VI, P686; [No title captured]	75	72	73	0	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	1992	7	3					211	241		10.1007/BF00126394	http://dx.doi.org/10.1007/BF00126394			31	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	HX401		Green Submitted			2022-12-18	WOS:A1992HX40100003
J	Sharan, L; Liu, C; Rosenholtz, R; Adelson, EH				Sharan, Lavanya; Liu, Ce; Rosenholtz, Ruth; Adelson, Edward H.			Recognizing Materials Using Perceptually Inspired Features	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Material recognition; Material classification; Texture classification; Mechanical Turk; Perception	COLOR-PERCEPTION; IMAGE STATISTICS; REFLECTANCE; MODEL; TEXTURE; ILLUMINATION; GLOSS; APPEARANCE	Our world consists not only of objects and scenes but also of materials of various kinds. Being able to recognize the materials that surround us (e.g., plastic, glass, concrete) is important for humans as well as for computer vision systems. Unfortunately, materials have received little attention in the visual recognition literature, and very few computer vision systems have been designed specifically to recognize materials. In this paper, we present a system for recognizing material categories from single images. We propose a set of low and mid-level image features that are based on studies of human material recognition, and we combine these features using an SVM classifier. Our system outperforms a state-of-the-art system (Varma and Zisserman, TPAMI 31(11):2032-2047, 2009) on a challenging database of real-world material categories (Sharan et al., J Vis 9(8):784-784a, 2009). When the performance of our system is compared directly to that of human observers, humans outperform our system quite easily. However, when we account for the local nature of our image features and the surface properties they measure (e.g., color, texture, local shape), our system rivals human performance. We suggest that future progress in material recognition will come from: (1) a deeper understanding of the role of non-local surface properties (e.g., extended highlights, object identity); and (2) efforts to model such non-local surface properties in images.	[Sharan, Lavanya; Rosenholtz, Ruth; Adelson, Edward H.] MIT, Dept Brain & Cognit Sci, Cambridge, MA 02139 USA; [Liu, Ce] Microsoft Res New England, Cambridge, MA 02142 USA	Massachusetts Institute of Technology (MIT); Microsoft	Sharan, L (corresponding author), MIT, Dept Brain & Cognit Sci, E25-618, Cambridge, MA 02139 USA.	lavanya@csail.mit.edu; celiu@microsoft.com; rruth@mit.edu; adelson@csail.mit.edu			NATIONAL EYE INSTITUTE [R01EY019262, R21EY019741] Funding Source: NIH RePORTER	NATIONAL EYE INSTITUTE(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Eye Institute (NEI))		Adelson EH, 2001, PROC SPIE, V4299, P1, DOI 10.1117/12.429489; BAE S, 2006, ACM SIGGRAPH; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Berzhanskaya J, 2005, PERCEPTION, V34, P565, DOI 10.1068/p5401; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bloj MG, 1999, NATURE, V402, P877, DOI 10.1038/47245; Boivin S, 2001, COMP GRAPH, P107, DOI 10.1145/383259.383270; Boyaci H, 2003, J VISION, V3, P541, DOI 10.1167/3.8.2; BRAINARD DH, 2003, COLOUR PERCEPTION MI, P307; Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Caputo B, 2005, IEEE I CONF COMP VIS, P1597, DOI 10.1109/iccv.2005.54; Caputo B., 2007, CLASSIFYING MAT REAL; Cula OG, 2004, IEEE T BIO-MED ENG, V51, P2148, DOI 10.1109/TBME.2004.836520; Cula OG, 2004, INT J COMPUT VISION, V59, P33, DOI 10.1023/B:VISI.0000020670.05764.55; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Dana KJ, 1998, PROC CVPR IEEE, P618, DOI 10.1109/CVPR.1998.698669; Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778; Debevec P, 2000, COMP GRAPH, P145, DOI 10.1145/344779.344855; Debevec P., 2004, ICTTR06 U SO CAL; DROR R, 2001, IEEE WORKSH ID OBJ V; DURAND F, 2002, ACM SIGGRAPH; Efros A. A., 2001, ACM SIGGRAPH; Fei-Fei L, 2005, PROC CVPR IEEE, P524; Fellbaum C., 1998, WORDNET ELECT LEXICA; Fleming RW, 2004, J VISION, V4, P798, DOI 10.1167/4.9.10; Fleming RW, 2003, J VISION, V3, P347, DOI 10.1167/3.5.3; Fleming RW., 2005, ACM T APPL PERCEPT, V2, P346, DOI [10.1145/1077399.1077409, DOI 10.1145/1077399.1077409]; Forsyth DA, 1999, INT J COMPUT VISION, V32, P63, DOI 10.1023/A:1008145029462; Fritz M., 2009, ADV NEURAL INFORM PR; Gilchrist A, 1999, PSYCHOL REV, V106, P795, DOI 10.1037/0033-295X.106.4.795; HE XD, 1991, COMP GRAPH, V25, P175, DOI 10.1145/127719.122738; Ho YX, 2008, PSYCHOL SCI, V19, P196, DOI 10.1111/j.1467-9280.2008.02067.x; Hu D., 2011, BMVC; Jensen HW, 2001, COMP GRAPH, P511, DOI 10.1145/383259.383319; Khan EA, 2006, ACM T GRAPHIC, V25, P654, DOI 10.1145/1141911.1141937; Koenderink JJ, 1999, INT J COMPUT VISION, V31, P129, DOI 10.1023/A:1008061730969; KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; Liu C., 2010, CVPR; LIU CJ, 2009, CVPR; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maloney L, 2003, COLOUR CONNECTING MI, P335; Marschner S., 1999, P 10 EUR WORKSH REND, P139; Marschner SR, 2005, ACM T GRAPHIC, V24, P727, DOI 10.1145/1073204.1073254; Matusik W., 2000, ACM T GRAPHIC, P759; McHenry K, 2005, PROC CVPR IEEE, P973; McHenry K., 2005, CVPR, V1, P1038; Motoyoshi I, 2007, NATURE, V447, P206, DOI 10.1038/nature05724; NICODEMUS FE, 1965, APPL OPTICS, V4, P767, DOI DOI 10.1364/AO.4.000767; Nillius P, 2004, LECT NOTES COMPUT SC, V2034, P366; Nishida S, 1998, J OPT SOC AM A, V15, P2951, DOI 10.1364/JOSAA.15.002951; Nishino K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P599, DOI 10.1109/ICCV.2001.937573; OREN M, 1995, INT J COMPUT VISION, V14, P227, DOI 10.1007/BF01679684; PARIKH D, 2010, CVPR; Pellacini F, 2000, COMP GRAPH, P55, DOI 10.1145/344779.344812; PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839; Pont SC, 2005, INT J COMPUT VISION, V62, P17, DOI 10.1007/s11263-005-4633-6; Ramamoorthi R, 2001, COMP GRAPH, P117, DOI 10.1145/383259.383271; Robilotto R, 2004, J VISION, V4, P779, DOI 10.1167/4.9.9; Romeiro F, 2008, LECT NOTES COMPUT SC, V5305, P859, DOI 10.1007/978-3-540-88693-8_63; Romeiro F, 2010, LECT NOTES COMPUT SC, V6311, P45, DOI 10.1007/978-3-642-15549-9_4; Rosch E., 1978, PRINCIPLES CATEGORIZ; Sato Y., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P379, DOI 10.1145/258734.258885; SAVARESE S, 2004, CLASSIFICATION FOLDE; Sharan L, 2010, J VISION, V9, P784; Sharan L, 2008, J OPT SOC AM A, V25, P846, DOI 10.1364/JOSAA.25.000846; Todd JT, 2004, PSYCHOL SCI, V15, P33, DOI 10.1111/j.0963-7214.2004.01501006.x; Tominaga S, 2000, IEEE COMPUT GRAPH, V20, P58, DOI 10.1109/38.865881; Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4; Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182; WARD GJ, 1992, COMP GRAPH, V26, P265, DOI 10.1145/142920.134078; Xiao B, 2008, VISUAL NEUROSCI, V25, P371, DOI 10.1017/S0952523808080267; Yu YZ, 1999, COMP GRAPH, P215	74	71	73	2	38	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2013	103	3					348	371		10.1007/s11263-013-0609-0	http://dx.doi.org/10.1007/s11263-013-0609-0			24	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	155WJ		Green Accepted, Green Submitted			2022-12-18	WOS:000319778800004
J	Hospedales, T; Gong, SG; Xiang, T				Hospedales, Timothy; Gong, Shaogang; Xiang, Tao			Video Behaviour Mining Using a Dynamic Topic Model	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Behaviour profiling; Video behaviour mining; Topic models; Learning for vision; Bayesian methods; Probabilistic modelling	MOTION	This paper addresses the problem of fully automated mining of public space video data, a highly desirable capability under contemporary commercial and security considerations. This task is especially challenging due to the complexity of the object behaviors to be profiled, the difficulty of analysis under the visual occlusions and ambiguities common in public space video, and the computational challenge of doing so in real-time. We address these issues by introducing a new dynamic topic model, termed a Markov Clustering Topic Model (MCTM). The MCTM builds on existing dynamic Bayesian network models and Bayesian topic models, and overcomes their drawbacks on sensitivity, robustness and efficiency. Specifically, our model profiles complex dynamic scenes by robustly clustering visual events into activities and these activities into global behaviours with temporal dynamics. A Gibbs sampler is derived for offline learning with unlabeled training data and a new approximation to online Bayesian inference is formulated to enable dynamic scene understanding and behaviour mining in new video data online in real-time. The strength of this model is demonstrated by unsupervised learning of dynamic scene models for four complex and crowded public scenes, and successful mining of behaviors and detection of salient events in each.	[Hospedales, Timothy; Gong, Shaogang; Xiang, Tao] Queen Mary Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England	University of London; Queen Mary University London	Hospedales, T (corresponding author), Queen Mary Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England.	tmh@eecs.qmul.ac.uk; sgg@eecs.qmul.ac.uk; txiang@eecs.qmul.ac.uk		Hospedales, Timothy/0000-0003-4867-7486	Engineering and Physical Sciences Research Council [EP/E028594/1] Funding Source: researchfish; EPSRC [EP/E028594/1] Funding Source: UKRI	Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))		Ali S., 2008, EUR C COMP VIS; Basharat A., 2008, IEEE C COMP VIS PATT; Benezeth Y., 2009, IEEE C COMP VIS PATT; Berclaz J., 2008, EUR C COMP VIS; Bishop C.M, 2006, PATTERN RECOGN; Blei D., 2006, INT C MACH LEARN; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; BLEI DM, 2007, NEURAL INFORM PROCES; Boiman O, 2007, INT J COMPUT VISION, V74, P17, DOI 10.1007/s11263-006-0009-9; Chang SF, 2008, IEEE T CIRC SYST VID, V18, P1469, DOI 10.1109/TCSVT.2008.2007023; Dee H., 2004, BRIT MACH VIS C; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; Duong T., 2005, IEEE C COMP VIS PATT; Gilks W. R., 1995, MARKOV CHAIN MONTE C, DOI 10.1201/b14835; Griffiths T., 2007, NEURAL INFORM PROCES; Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101; Gruber Amit, 2007, ARTIFICIAL INTELLIGE; HOSDB, 2006, IEEE C CRIM SEC; Hospedales T, 2009, IEEE I CONF COMP VIS, P1165, DOI 10.1109/ICCV.2009.5459342; Hu WM, 2006, IEEE T PATTERN ANAL, V28, P1450, DOI 10.1109/TPAMI.2006.176; Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274; Hu Z., 2009, P TRECVID; Inoue Nakamasa, 2009, P TRECVID; Johnson N, 1996, IMAGE VISION COMPUT, V14, P609, DOI 10.1016/0262-8856(96)01101-8; Kapoor A., 2007, INT JOINT C ART INT; Kim J, 2009, IEEE C COMP VIS PATT; Li J., 2008, BRIT MACH VIS C; Mang T, 2008, PATTERN RECOGN, V41, P2309, DOI 10.1016/j.patcog.2007.11.024; Meng J., 1996, SPIE C STOR RETR IM; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; *NIST, TREC VID RETR EV; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Pritch Y, 2008, IEEE T PATTERN ANAL, V30, P1971, DOI 10.1109/TPAMI.2008.29; Rosen-Zvi M., 2004, UNCERTAINTY ARTIFICI; Saleemi I, 2009, IEEE T PATTERN ANAL, V31, P1472, DOI 10.1109/TPAMI.2008.175; Scovanner P., 2007, ACM INT C MULT; Sillito R.R, 2008, BRIT MACH VIS C; Smith K., 2006, PERF EV TRACK SURV P; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; Wallach Hanna, 2009, INT C MACH LEARN; Wallach HM, 2006, INT C MACH LEARN; Wang X., 2006, EUR C COMP VIS; Wang XG, 2009, IEEE T PATTERN ANAL, V31, P539, DOI 10.1109/TPAMI.2008.87; Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1762, DOI 10.1109/TPAMI.2009.43; Xiang T, 2006, INT J COMPUT VISION, V67, P21, DOI 10.1007/s11263-006-4329-6; Xiang T, 2008, IEEE T PATTERN ANAL, V30, P893, DOI 10.1109/TPAMI.2007.70731; Xie LX, 2008, P IEEE, V96, P623, DOI 10.1109/JPROC.2008.916362; yu Chen Ming, 2009, P TRECVID; Zhong H, 2004, PROC CVPR IEEE, P819	49	71	74	3	39	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2012	98	3					303	323		10.1007/s11263-011-0510-7	http://dx.doi.org/10.1007/s11263-011-0510-7			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	934NI					2022-12-18	WOS:000303450600004
J	Stamos, I; Liu, LY; Chen, C; Wolberg, G; Yu, G; Zokai, S				Stamos, Ioannis; Liu, Lingyun; Chen, Chao; Wolberg, George; Yu, Gene; Zokai, Siavash			Integrating automated range registration with multiview geometry for the photorealistic modeling of large-scale scenes	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						range segmentation; range-to-range registration; range-to-image registration; multiview geometry; structure from motion; photorealistic modeling	OBJECT RECOGNITION; 3D; ALIGNMENT; VIDEO; POSE	The photorealistic modeling of large-scale scenes, such as urban structures, requires a fusion of range sensing technology and traditional digital photography. This paper presents a system that integrates automated 3D-to-3D and 2D-to-3D registration techniques, with multiview geometry for the photorealistic modeling of urban scenes. The 3D range scans are registered using our automated 3D-to-3D registration method that matches 3D features (linear or circular) in the range images. A subset of the 2D photographs are then aligned with the 3D model using our automated 2D-to-3D registration algorithm that matches linear features between the range scans and the photographs. Finally, the 2D photographs are used to generate a second 3D model of the scene that consists of a sparse 3D point cloud, produced by applying a multiview geometry (structure-from-motion) algorithm directly on a sequence of 2D photographs. The last part of this paper introduces a novel algorithm for automatically recovering the rotation, scale, and translation that best aligns the dense and sparse models. This alignment is necessary to enable the photographs to be optimally texture mapped onto the dense model. The contribution of this work is that it merges the benefits of multiview geometry with automated registration of 3D range scans to produce photorealistic models with minimal human interaction. We present results from experiments in large-scale urban scenes.	[Stamos, Ioannis; Liu, Lingyun; Chen, Chao] CUNY Hunter Coll, Dept Comp Sci, New York, NY 10021 USA; [Wolberg, George; Yu, Gene] CUNY City Coll, Dept Comp Sci, New York, NY 10031 USA; [Zokai, Siavash] Brainstorm Technol LLC, New York, NY USA	City University of New York (CUNY) System; Hunter College (CUNY); City University of New York (CUNY) System; City College of New York (CUNY)	Stamos, I (corresponding author), CUNY Hunter Coll, Dept Comp Sci, New York, NY 10021 USA.	istamos@hunter.cuny.edu; lingyun77@gmail.com; cchen@gc.cuny.edu; wolberg@cs.ccny.cuny.edu						AMBLER AP, 1970, 3 INT JOINT C ART IN; Beardsley PA, 1997, INT J COMPUT VISION, V23, P235, DOI 10.1023/A:1007923216416; Bellon ORP, 2002, IEEE SIGNAL PROC LET, V9, P43, DOI 10.1109/97.991134; Bernardini F, 2002, COMPUT GRAPH FORUM, V21, P149, DOI 10.1111/1467-8659.00574; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; BESL PJ, 1992, IEEE T PATT AN MACH, V14; Cass TA, 1997, INT J COMPUT VISION, V21, P37, DOI 10.1023/A:1007971405872; CHEN C, 2007, THESIS CITY U NEW YO; CHEN C, 2006, INT S 3D PROC VIS TR; CHEN C, 2005, 5 INT C 3D DIG IM MO, P254; Christy S, 1999, COMPUT VIS IMAGE UND, V73, P137, DOI 10.1006/cviu.1998.0717; FAUGERAS O, 1996, 3 DIMENSIONAL COMPUT; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fruh C, 2003, IEEE COMPUT GRAPH, V23, P52, DOI 10.1109/MCG.2003.1242382; Hartley R., 2003, MULTIPLE VIEW GEOMET; Hausler G, 1999, COMPUT VIS IMAGE UND, V73, P64, DOI 10.1006/cviu.1998.0704; Heyden A., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P339, DOI 10.1109/ICPR.1996.546045; HORAUD R, 1997, INT J COMPUTER VISIO, V22; Huber DF, 2003, IMAGE VISION COMPUT, V21, P637, DOI 10.1016/S0262-8856(03)00060-X; HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921; IKEUCHI K, 2003, IEEE ISMARO3; Jacobs DW, 1997, INT J COMPUT VISION, V21, P123, DOI 10.1023/A:1007927623619; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; Jurie F, 1999, COMPUT VIS IMAGE UND, V73, P357, DOI 10.1006/cviu.1998.0735; Liu L., 2007, THESIS CITY U NEW YO; Liu L., 2006, P IEEE COMP SOC C CO, V2, P2293; LIU L, 2007, VIRTUAL REPRESENTATI; Liu LY, 2005, PROC CVPR IEEE, P137; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Ma Y., 2003, INVITATION 3D VISION; Marshall D, 2001, IEEE T PATTERN ANAL, V23, P304, DOI 10.1109/34.910883; OBERKAMPF D, 1996, COMPUTER VISION GRAP, V63; Pollefeys M, 2004, INT J COMPUT VISION, V59, P207, DOI 10.1023/B:VISI.0000025798.50602.3a; Pollefeys M, 1997, PROC CVPR IEEE, P407, DOI 10.1109/CVPR.1997.609357; Pulli K, 1998, INT C PATT RECOG, P11, DOI 10.1109/ICPR.1998.711067; PULLI K, 1993, P SCAND C IM AN; QUAN L, 1999, IEEE T PATT AN MACH, V21; RUSINKIEWICZ S, 2001, 3 INT C 3D DIG IM MO; Schaffalitzky F, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P636, DOI 10.1109/ICCV.2001.937686; Sequeira V, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P776, DOI 10.1109/TDPVT.2002.1024159; Stamos I, 2003, PROC CVPR IEEE, P555; Stamos I, 2002, COMPUT VIS IMAGE UND, V88, P94, DOI 10.1006/cviu.2002.0963; Stamos I, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P731, DOI 10.1109/ICCV.2001.937699; Triggs B, 1996, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.1996.517170; TROCCOLI A, 2004, 2 IEEE WORKSH VID IM; Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8; WANI MA, 1994, IEEE T PATTERN ANAL, V16, P314, DOI 10.1109/34.276131; Wells WM, 1997, INT J COMPUT VISION, V21, P63, DOI 10.1023/A:1007923522710; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718; Zhao HJ, 2003, MACH VISION APPL, V14, P35, DOI 10.1007/s00138-002-0099-5; Zhao WY, 2005, IEEE T PATTERN ANAL, V27, P1305, DOI 10.1109/TPAMI.2005.152	52	71	80	0	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2008	78	2-3					237	260		10.1007/s11263-007-0089-1	http://dx.doi.org/10.1007/s11263-007-0089-1			24	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	275RK		Green Submitted			2022-12-18	WOS:000254089100008
J	Yezzi, A; Soatto, S				Yezzi, A; Soatto, S			Stereoscopic segmentation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						variational methods; Mumford-Shah functional; image segmentation; multi-frame stereo reconstruction; level set methods	SHAPE; MODELS; SNAKES; FLOWS	We cast the problem of multiframe stereo reconstruction of a smooth surface as the global region segmentation of a collection of images of the scene. Dually, the problem of segmenting multiple calibrated images of an object becomes that of estimating the solid shape that gives rise to such images. We assume that the radiance of the scene results in piecewise homogeneous image statistics. This simplifying assumption covers Lambertian scenes with constant albedo as well as fine homogeneous textures, which are known challenges to stereo algorithms based on local correspondence. We pose the segmentation problem within a variational framework, and use fast level set methods to find the optimal solution numerically. Our algorithm does not work in the presence of strong photometric features, where traditional reconstruction algorithms do. It enjoys significant robustness to noise under the assumptions it is designed for.	Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA; Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA	University System of Georgia; Georgia Institute of Technology; University of California System; University of California Los Angeles	Yezzi, A (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.	ayezzi@ece.gatech.edu; soatto@ucla.edu	Yezzi, Anthony/AAB-4235-2020					Blake A., 1992, ACTIVE VISION; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685; Chakraborty A, 1999, IEEE T PATTERN ANAL, V21, P12, DOI 10.1109/34.745730; Chan T, 1999, LECT NOTES COMPUT SC, V1682, P141; CIPOLLA R, 1992, INT J COMPUTER VISIO, V9; CRANDALL MG, 1992, B AM MATH SOC, V27, P1, DOI 10.1090/S0273-0979-1992-00266-5; FAUGERAS O, 1996, INRIA TECHNICAL REPO, V3021, P1; Faugeras Olivier, 1993, 3 DIMENSIONAL VISION, P2; Fleming W. H., 2006, CONTROLLED MARKOV PR; Horn B.K.P., 1989, SHAPE SHADING; JIN H, 2003, IN PRESS J COMP PHYS; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kichenassamy S, 1996, ARCH RATION MECH AN, V134, P275, DOI 10.1007/BF00379537; KUTULAKOS K, 1998, P INT C COMP VIS; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; LECLERC YG, 1989, INT J COMPUT VISION, V3, P73, DOI 10.1007/BF00054839; LeVeque RJ., 1992, LECT MATH ETH ZURICH, V2nd; Lions P. L., 1982, GEN SOLUTIONS HAMILT; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; MUMFORD D., 1985, P IEEE C COMP VIS PA; OSHER S, 1984, SIAM J NUMER ANAL, V21, P217, DOI 10.1137/0721016; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; PARAGIOS N, 2000, P ECCV DUBL IR; PARAGIOS N, 1999, P ICCV CORF GREEC; RONFARD R, 1994, INT J COMPUT VISION, V13, P229, DOI 10.1007/BF01427153; ROSENHOLTZ R, 1993, 93775 UCBCSD; SAMSON C, 1999, INT C SCAL SPAC THEO, P306; Sethian JA, 1996, LEVEL SET METHODS EV; Siddiqi K, 1998, IEEE T IMAGE PROCESS, V7, P433, DOI 10.1109/83.661193; SZELISKI R, 2002, P 7 EUR C COMP VIS C; TEK H, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P156, DOI 10.1109/ICCV.1995.466792; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; TSAI R, 2002, 0206 CAM; YEZZI A, 1999, P ICCV; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343; ZHU SC, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P416, DOI 10.1109/ICCV.1995.466909	40	71	72	0	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2003	53	1					31	43		10.1023/A:1023079624234	http://dx.doi.org/10.1023/A:1023079624234			13	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	668CV					2022-12-18	WOS:000182273500002
J	Irani, M				Irani, M			Multi-frame correspondence estimation using subspace constraints	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						correspondence estimation; optical-flow; direct (gradient-based) methods; subspace constraints; factorization	MOTION; ALGORITHM	When a rigid scene is imaged by a moving camera, the set of all displacements of all points across multiple frames often resides in a low-dimensional linear subspace. Linear subspace constraints have been used successfully in the past for recovering 3D structure and 3D motion information from multiple frames (e.g., by using the factorization method of Tomasi and Kanade (1992, International Journal of Computer Vision, 9:137-154)). These methods assume that the 2D correspondences have been precomputed. However, correspondence estimation is a fundamental problem in motion analysis. In this paper we show how the multi-frame subspace constraints can be used for constraining the 2D correspondence estimation process itself. We show that the multi-frame subspace constraints are valid not only for affine cameras, but also for a variety of imaging models, scene models, and motion models. The multi-frame subspace constraints are first translated from constraints on correspondences to constraints directly on image measurements (e.g., image brightness quantities). These brightness-based subspace constraints are then used for estimating the correspondences, by requiring that all corresponding points across all video frames reside in the appropriate low-dimensional linear subspace. The multi-frame subspace constraints are geometrically meaningful, and are {not} violated at depth discontinuities, nor when the camera-motion changes abruptly. These constraints can therefore replace {heuristic} constraints commonly used in optical-flow estimation, such as spatial or temporal smoothness.	Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel	Weizmann Institute of Science	Irani, M (corresponding author), Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel.							ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167; Anandan P, 2000, LECT NOTES COMPUT SC, V1842, P907; Barron J. L., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P236, DOI 10.1109/CVPR.1992.223269; BERGEN JR, 1992, IEEE T PATTERN ANAL, V14, P886, DOI 10.1109/34.161348; BERGEN JR, 1992, EUR C COMP VIS, P237; Black M. J., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P296, DOI 10.1109/CVPR.1991.139705; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; CRIMINISI A, 1998, EUR C COMP VIS FREIB; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Hanna K. J., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P156, DOI 10.1109/WVM.1991.212812; Hanna K. J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P357, DOI 10.1109/ICCV.1993.378192; HEEGER DJ, 1992, INT J COMPUT VISION, V7, P95, DOI 10.1007/BF00128130; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; IRANI M, 1994, INT J COMPUT VISION, V12, P5, DOI 10.1007/BF01420982; Irani M, 1997, IEEE T PATTERN ANAL, V19, P268, DOI 10.1109/34.584105; Irani M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P626, DOI 10.1109/ICCV.1999.791283; Irani M, 1998, IEEE T PATTERN ANAL, V20, P577, DOI 10.1109/34.683770; IRANI M, 1996, EUR C COMP VIS, P17; IRANI M, 1998, EUR C COMP VIS FREIB; IRANI M, 1999, VIS ALG 99 CORF; IRANI M, 2000, ECCV, P539; KUMAR R, 1994, INT C PATT RECOG, P685, DOI 10.1109/ICPR.1994.576402; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; SAWHNEY H, 1994, IEEE C COMP VIS PATT; SHAPIRO LS, 1995, AFFINE ANAL IMAGE SE; SHASHUA A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P483, DOI 10.1109/CVPR.1994.323870; Stein GP, 1997, PROC CVPR IEEE, P400, DOI 10.1109/CVPR.1997.609356; SZELISKI R, 1990, INT J COMPUT VISION, V5, P271, DOI 10.1007/BF00126502; SZELISKI R, 1995, WORKSH REPR VIS SCEN; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torr PHS, 1998, PHILOS T R SOC A, V356, P1321, DOI 10.1098/rsta.1998.0224; Zelnik-Manor L, 2000, IEEE T PATTERN ANAL, V22, P1105, DOI 10.1109/34.879791	34	71	73	0	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL-AUG	2002	48	3					173	194		10.1023/A:1016372015744	http://dx.doi.org/10.1023/A:1016372015744			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	573BJ					2022-12-18	WOS:000176809200002
J	Kan, MN; Wu, JT; Shan, SG; Chen, XL				Kan, Meina; Wu, Junting; Shan, Shiguang; Chen, Xilin			Domain Adaptation for Face Recognition: Targetize Source Domain Bridged by Common Subspace	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Face recognition; Domain adaptation; Common subspace learning; Targetize the sourece domain	COVARIATE SHIFT; CLASSIFICATION; SUPPORT	In many applications, a face recognition model learned on a source domain but applied to a novel target domain degenerates even significantly due to the mismatch between the two domains. Aiming at learning a better face recognition model for the target domain, this paper proposes a simple but effective domain adaptation approach that transfers the supervision knowledge from a labeled source domain to the unlabeled target domain. Our basic idea is to convert the source domain images to target domain (termed as targetize the source domain hereinafter), and at the same time keep its supervision information. For this purpose, each source domain image is simply represented as a linear combination of sparse target domain neighbors in the image space, with the combination coefficients however learnt in a common subspace. The principle behind this strategy is that, the common knowledge is only favorable for accurate cross-domain reconstruction, but for the classification in the target domain, the specific knowledge of the target domain is also essential and thus should be mostly preserved (through targetization in the image space in this work). To discover the common knowledge, specifically, a common subspace is learnt, in which the structures of both domains are preserved and meanwhile the disparity of source and target domains is reduced. The proposed method is extensively evaluated under three face recognition scenarios, i.e., domain adaptation across view angle, domain adaptation across ethnicity and domain adaptation across imaging condition. The experimental results illustrate the superiority of our method over those competitive ones.	[Kan, Meina; Wu, Junting; Shan, Shiguang; Chen, Xilin] Chinese Acad Sci, ICT, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China	Chinese Academy of Sciences	Shan, SG (corresponding author), Chinese Acad Sci, ICT, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.	kanmeina@ict.ac.cn; junting.wu@vipl.ict.ac.cn; sgshan@ict.ac.cn; xlchen@ict.ac.cn		Shan, Shiguang/0000-0002-8348-392X	Natural Science Foundation of China [61025010, 61173065, 61222211]	Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work is partially supported by Natural Science Foundation of China under contracts nos. 61025010, 61173065, and 61222211. The authors would like to thank the guest editors and the reviewers for their valuable comments and suggestions. The authors also would like to thank the Edwin Zinan Zeng for his advices about the writing.	[Anonymous], 2009, PROC AUAI 2009; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Ben-David Shai, 2007, NEURIPS, P7; Bickel S, 2009, J MACH LEARN RES, V10, P2137; Blitzer J., 2006, P 2006 C EMP METH NA, P120, DOI DOI 10.3115/1610075.1610094; Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57; Chen YS, 2003, PATTERN RECOGN LETT, V24, P1845, DOI 10.1016/S0167-8655(03)00008-4; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Duan LX, 2012, IEEE T PATTERN ANAL, V34, P1667, DOI 10.1109/TPAMI.2011.265; Duan LX, 2009, PROC CVPR IEEE, P1375, DOI [10.1109/CVPR.2009.5206747, 10.1109/CVPRW.2009.5206747]; Dudik Miroslav, 2005, ADV NEURAL INF PROCE, V18, P323; Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067; Gao XB, 2011, PATTERN RECOGN, V44, P2358, DOI 10.1016/j.patcog.2010.06.013; Geng B, 2011, IEEE T IMAGE PROCESS, V20, P2980, DOI 10.1109/TIP.2011.2134107; Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911; Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344; Gretton A, 2009, NEURAL INF PROCESS S, P131; Gross R., 2007, TECH REP; He XF, 2004, ADV NEUR IN, V16, P153; Huang J., 2006, ADV NEURAL INFORM PR; Huang K., 2007, ADV NEURAL INFORM PR, V19, P609; Jhuo IH, 2012, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2012.6247924; Jia YQ, 2009, IEEE T NEURAL NETWOR, V20, P729, DOI 10.1109/TNN.2009.2015760; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; Mehrotra R., 2012, P 21 ACM INT C INF K, P2395; Messer K., 1999, 2 INT C AUDIO VIDEO, P965; Pan S.J., 2008, AAAI; Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281; Pan SJ, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1187; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Phillips PJ, 2005, PROC CVPR IEEE, P947; Qiu Q, 2012, LECT NOTES COMPUT SC, V7575, P631, DOI 10.1007/978-3-642-33765-9_45; Raina R, 2007, 24 ANN INT C MACH LE, V227, P759, DOI [10.1145/1273496.1273592, DOI 10.1145/1273496.1273592]; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Shao M, 2012, IEEE DATA MINING, P1104, DOI 10.1109/ICDM.2012.102; Shi Yuan, 2012, ICML; Shimodaira H, 2000, J STAT PLAN INFER, V90, P227, DOI 10.1016/S0378-3758(00)00115-4; Si S, 2011, IEEE T SYST MAN CY B, V41, P921, DOI 10.1109/TSMCB.2010.2100042; Si S, 2010, IEEE T KNOWL DATA EN, V22, P929, DOI 10.1109/TKDE.2009.126; Soteriou V, 2007, PR IEEE COMP DESIGN, P134; Su Y, 2009, IEEE T IMAGE PROCESS, V18, P1885, DOI 10.1109/TIP.2009.2021737; Sugiyama M., 2008, NIPS, P1433; Sugiyama M, 2007, J MACH LEARN RES, V8, P985; Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758; Uribe D., 2010, 2010 Ninth International Conference on Machine Learning and Applications (ICMLA 2010), P857, DOI 10.1109/ICMLA.2010.133; Wang Z, 2008, LECT NOTES ARTIF INT, V5212, P550, DOI 10.1007/978-3-540-87481-2_36; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Xue Y, 2007, J MACH LEARN RES, V8, P35; Zadrozny B., 2004, P INT C MACH LEARN	49	70	74	1	24	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2014	109	1-2			SI		94	109		10.1007/s11263-013-0693-1	http://dx.doi.org/10.1007/s11263-013-0693-1			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AI7QY					2022-12-18	WOS:000337091700007
J	Chen, J; Chen, BQ				Chen, Jie; Chen, Baoquan			Architectural modeling from sparsely scanned range data	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						3D scanning; range image; geometry reconstruction		We present a pipeline to reconstruct complete geometry of architectural buildings from point clouds obtained by sparse range laser scanning. Due to limited accessibility of outdoor environments, complete and sufficient scanning of every face of an architectural building is often impossible. Our pipeline deals with architectures that are made of planar faces and faithfully constructs a polyhedron of low complexity based on the incomplete scans. The pipeline first recognizes planar regions based on point clouds, then proceeds to compute plane intersections and corners (in this paper, we use the informal terms corner or vertex corner to stand for a polyhedron vertex. See the Overview section for notation declarations), and finally produces a complete polyhedron. Within the pipeline, several algorithms based on the polyhedron geometry assumption are designed to perform data clustering, boundary detection, and face extraction. Our system offers a convenient user interface but minimizes the necessity of user intervention. We demonstrate the capability and advantage of our system by modeling real-life buildings.	[Chen, Jie; Chen, Baoquan] Univ Minnesota Twin Cities, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA	University of Minnesota System; University of Minnesota Twin Cities	Chen, J (corresponding author), Univ Minnesota Twin Cities, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA.	jchen@cs.umn.edu; baoquan@cs.umn.edu						BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; Bernardini F, 1999, IEEE T VIS COMPUT GR, V5, P349, DOI 10.1109/2945.817351; BRUNACCI FA, 1988, EUR J OPER RES, V34, P231, DOI 10.1016/0377-2217(88)90357-8; Debevec P. E, 1996, P SIGGRAPH 96; FISHER R, 2003, P 4 INT C 3D DIG IM; Fleishman S, 2005, ACM T GRAPHIC, V24, P544, DOI 10.1145/1073204.1073227; Grnbaum B., 1967, CONVEX POLYTOPES; Jiang XY, 1999, COMPUT VIS IMAGE UND, V73, P183, DOI 10.1006/cviu.1998.0715; LEVOY M, 2000, P SIGGRAPH 00; PAULY M, 2005, EUR S GEOM PROC JUL; PODOLAK J, 2005, EUR S GEOM PROC JUL; Sharf A, 2004, ACM T GRAPHIC, V23, P878, DOI 10.1145/1015706.1015814; Shum HY, 1998, P CVPR 98; Stamos I, 2002, COMPUT VIS IMAGE UND, V88, P94, DOI 10.1006/cviu.2002.0963; XU H, 2004, P 3 INT S NONPH AN R; ZIOU D, 1998, INT J PATTERN RECOGN, V8, P537	17	70	79	0	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2008	78	2-3					223	236		10.1007/s11263-007-0105-5	http://dx.doi.org/10.1007/s11263-007-0105-5			14	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	275RK					2022-12-18	WOS:000254089100007
J	Xu, C; Govindarajan, LN; Zhang, Y; Stewart, J; Bichler, Z; Jesuthasan, S; Claridge-Chang, A; Mathuru, AS; Tang, WL; Zhu, PX; Cheng, L				Xu, Chi; Govindarajan, Lakshmi Narasimhan; Zhang, Yu; Stewart, James; Bichler, Zoe; Jesuthasan, Suresh; Claridge-Chang, Adam; Mathuru, Ajay Sriram; Tang, Wenlong; Zhu, Peixin; Cheng, Li			Lie-X: Depth Image Based Articulated Object Pose Estimation, Tracking, and Action Recognition on Lie Groups	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Depth images; Pose estimation; Fish; Mouse; Human hand; Lie group	HUMAN MOTION ANALYSIS; 2D	Pose estimation, tracking, and action recognition of articulated objects from depth images are important and challenging problems, which are normally considered separately. In this paper, a unified paradigm based on Lie group theory is proposed, which enables us to collectively address these related problems. Our approach is also applicable to a wide range of articulated objects. Empirically it is evaluated on lab animals including mouse and fish, as well as on human hand. On these applications, it is shown to deliver competitive results compared to the state-of-the-arts, and non-trivial baselines including convolutional neural networks and regression forest methods. Moreover, new sets of annotated depth data of articulated objects are created which, together with our code, are made publicly available.	[Xu, Chi; Govindarajan, Lakshmi Narasimhan; Zhang, Yu; Cheng, Li] ASTAR, Bioinformat Inst, Singapore, Singapore; [Stewart, James; Jesuthasan, Suresh; Claridge-Chang, Adam; Mathuru, Ajay Sriram] ASTAR, Inst Mol & Cell Biol, Singapore, Singapore; [Bichler, Zoe] Natl Neurosci Inst, Singapore, Singapore; [Jesuthasan, Suresh] Nanyang Technol Univ, Lee Kong Chian Sch Med, Singapore, Singapore; [Claridge-Chang, Adam] Duke NUS Med Sch, Singapore, Singapore; [Claridge-Chang, Adam] Natl Univ Singapore, Dept Physiol, Singapore, Singapore; [Mathuru, Ajay Sriram] Yale NUS Coll, Singapore, Singapore; [Tang, Wenlong; Zhu, Peixin] Novartis Inst BioMed Res, Cambridge, MA USA; [Tang, Wenlong; Zhu, Peixin] Harvard Univ, Dept Stem Cells & Regenerat Biol, Cambridge, MA 02138 USA; [Cheng, Li] Natl Univ Singapore, Sch Comp, Singapore, Singapore	Agency for Science Technology & Research (A*STAR); A*STAR - Bioinformatics Institute (BII); Agency for Science Technology & Research (A*STAR); A*STAR - Institute of Molecular & Cell Biology (IMCB); National Neuroscience Institute (NNI); Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; National University of Singapore; National University of Singapore; Yale NUS College; Novartis; Harvard University; National University of Singapore	Cheng, L (corresponding author), ASTAR, Bioinformat Inst, Singapore, Singapore.; Cheng, L (corresponding author), Natl Univ Singapore, Sch Comp, Singapore, Singapore.	xuchi@bii.a-star.edu.sg; lakshming@bii.a-star.edu.sg; zhangyu@bii.a-star.edu.sg; jcstewart@imcb.a-star.edu.sg; zoe_bichler@nni.com.sg; sureshjj@imcb.a-star.edu.sg; acchang@imcb.a-star.edu.sg; ajaym@imcb.a-star.edu.sg; wenlong.tang@novartis.com; peixin.zhu@novartis.com; chengli@bii.a-star.edu.sg	Jesuthasan, Suresh/B-7870-2016; Cheng, Li/AAU-6734-2020; Mathuru, Ajay S./T-8787-2019	Jesuthasan, Suresh/0000-0002-5733-6555; Cheng, Li/0000-0003-3261-3533; Govindarajan, Lakshmi Narasimhan/0000-0002-0936-2919; Claridge-Chang, Adam/0000-0002-4583-3650; Xu, Chi/0000-0002-5301-9376	A*STAR JCO [1431AFG120, 15302FG149]	A*STAR JCO(Agency for Science Technology & Research (A*STAR))	The project is partially supported by A*STAR JCO Grants 1431AFG120 and 15302FG149. Mouse and fish images are acquired with the help of Zoe Bichler, James Stewart, Suresh Jesuthasan, and Adam Claridge-Chang. Zilong Wang helps with the annotation of mouse data, while Wei Gao and Ashwin Nanjappa help with implementing the mouse baseline method.	Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21; Ali K., 2009, ICCV; Altafini C., 2000, NONLINEAR CONTROL YE, P1; Andriluka M, 2008, PROC CVPR IEEE, P1873, DOI 10.1109/CVPR.2008.4587583; Andrychowicz M., 2016, LEARNING LEARN GRADI, P1; Arnold V. I., 1989, GRAD TEXTS MATH, V60; Ballan L, 2012, LECT NOTES COMPUT SC, V7577, P640, DOI 10.1007/978-3-642-33783-3_46; Barsoum E., 2016, ARXIV160406195; BOOKSTEIN FL, 1977, MATH BIOSCI, V34, P177, DOI 10.1016/0025-5564(77)90101-8; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Branson K., 2005, CVPR; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006; Chenxue Xu, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457903; Chris Burges T.S., 2005, P 22 INT MACH LEARN, DOI 10.1145/1102351.1102363; Dollar P., 2005, IEEE WORKSH PETS; Dollar P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Fleuret F, 2008, J MACH LEARN RES, V9, P2549; Gall J, 2011, IEEE T PATTERN ANAL, V33, P2188, DOI 10.1109/TPAMI.2011.70; Hinterstoisser S., 2010, CVPR; Hough, 1959, P INT C HIGH EN ACC, V590914, P554; Hsu E. P., 2002, GRAD STUD MATH, V38; Huang C, 2016, PROC CVPR IEEE, P5375, DOI 10.1109/CVPR.2016.580; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Kalueff AV, 2013, ZEBRAFISH, V10, P70, DOI 10.1089/zeb.2012.0861; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Lee J.M, 2012, INTRO SMOOTH MANIFOL; Leibe B., 2004, EUROPEAN C COMPUTER, P17; Mahasseni B, 2016, CVPR; Manton JH, 2013, IEEE J-STSP, V7, P681, DOI 10.1109/JSTSP.2013.2264798; Mikic I, 2003, INT J COMPUT VISION, V53, P199, DOI 10.1023/A:1023012723347; Murray R. M., 1994, MATH INTRO ROBOTIC M, V1; Nie X., 2015, CVPR; Oberweger M., 2015, COMP VIS WORKSH; Oberweger M, 2015, IEEE I CONF COMP VIS, P3316, DOI 10.1109/ICCV.2015.379; Oikonomidis N., 2011, BMVC; Perez-Sala X, 2014, SENSORS-BASEL, V14, P4189, DOI 10.3390/s140304189; Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016; Procesi C., 2007, GROUPS APPROACH INVA; Qian Chen, 2014, P IEEE C COMP VIS PA; Rahmani H, 2016, PROC CVPR IEEE, P1506, DOI 10.1109/CVPR.2016.167; SHOTTON J, 2013, IEEE T PATTERN ANAL, V35, P2821, DOI DOI 10.1109/TPAMI.2012.241; Sinha A., 2016, CVPR; Srivastava A, 2012, IMAGE VISION COMPUT, V30, P398, DOI 10.1016/j.imavis.2012.03.006; Sun X, 2015, PROC CVPR IEEE, P824, DOI 10.1109/CVPR.2015.7298683; Tan D., 2016, CVPR; Tang D., 2015, ICCV; Tompson J., 2014, SIGGRAPH; Tompson J.J., 2014, ADV NEURAL INFORM PR, V27, P1799; Tuzel O., 2008, CVPR; Vemulapalli R, 2016, PROC CVPR IEEE, P4471, DOI 10.1109/CVPR.2016.484; Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82; Wiltschko AB, 2015, NEURON, V88, P1121, DOI 10.1016/j.neuron.2015.11.031; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Xu C., 2013, ICCV; Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741; Zhou X., 2016, ARXIV160606854	58	69	72	5	27	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2017	123	3					454	478		10.1007/s11263-017-0998-6	http://dx.doi.org/10.1007/s11263-017-0998-6			25	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	EX9EO		Green Submitted			2022-12-18	WOS:000403559600008
J	Eslami, SMA; Heess, N; Williams, CKI; Winn, J				Eslami, S. M. Ali; Heess, Nicolas; Williams, Christopher K. I.; Winn, John			The Shape Boltzmann Machine: A Strong Model of Object Shape	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Shape; Generative; Deep Boltzmann machine; Sampling	RANDOM-FIELDS; IMAGE; EXPERTS	A good model of object shape is essential in applications such as segmentation, detection, inpainting and graphics. For example, when performing segmentation, local constraints on the shapes can help where object boundaries are noisy or unclear, and global constraints can resolve ambiguities where background clutter looks similar to parts of the objects. In general, the stronger the model of shape, the more performance is improved. In this paper, we use a type of deep Boltzmann machine (Salakhutdinov and Hinton, International Conference on Artificial Intelligence and Statistics, 2009) that we call a Shape Boltzmann Machine (SBM) for the task of modeling foreground/background (binary) and parts-based (categorical) shape images. We show that the SBM characterizes a strong model of shape, in that samples from the model look realistic and it can generalize to generate samples that differ from training examples. We find that the SBM learns distributions that are qualitatively and quantitatively better than existing models for this task.	[Eslami, S. M. Ali; Williams, Christopher K. I.] Univ Edinburgh, Sch Informat, Edinburgh, Midlothian, Scotland; [Heess, Nicolas] UCL, Gatsby Computat Neurosci Unit, London, England; [Winn, John] Microsoft Res, Cambridge, England	University of Edinburgh; University of London; University College London; Microsoft	Eslami, SMA (corresponding author), Univ Edinburgh, Sch Informat, Edinburgh, Midlothian, Scotland.	s.m.eslami@sms.ed.ac.uk; nheess@gatsby.ucl.ac.uk; ckiw@inf.ed.ac.uk; jwinn@microsoft.com			Carnegie Trust; SORSAS scheme; European Community [IST-2007-216886, 270327]; Gatsby Charitable foundation	Carnegie Trust(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of Science); SORSAS scheme; European Community(European Commission); Gatsby Charitable foundation	The majority of this work was performed whilst AE and NH were at Microsoft Research in Cambridge. Thanks to Charless Fowlkes and Vittorio Ferrari for access to datasets, and to Pushmeet Kohli for valuable discussions. AE acknowledges funding from the Carnegie Trust, the SORSAS scheme, and the IST Programme of the European Community under the PASCAL2 Network of Excellence (IST-2007-216886). NH acknowledges funding from the European Community's Seventh Framework Programme (FP7/2007-2013) under Grant agreement no. 270327, and from the Gatsby Charitable foundation. We finally thank the anonymous referees for their comments which helped improve the paper.	ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226; Alexe B, 2010, LECT NOTES COMPUT SC, V6315, P380, DOI 10.1007/978-3-642-15555-0_28; Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207; Bertozzi AL, 2007, IEEE T IMAGE PROCESS, V16, P285, DOI 10.1109/TIP.2006.887728; Blaschko MB, 2008, PROC CVPR IEEE, P93, DOI 10.1109/cvpr.2008.4587586; Bo YH, 2011, PROC CVPR IEEE; Borenstein E., 2004, CVPR WORKSH PERC ORG; Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505; Bridle J. S., 1990, PROC 2 INT C NEURAL, P211, DOI [10.5555/2969830, DOI 10.5555/2969830]; Cemgil AT, 2005, PROC CVPR IEEE, P1158; Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P436, DOI 10.1006/jvci.2001.0487; Chen F, 2013, PROC CVPR IEEE, P1870, DOI 10.1109/CVPR.2013.244; Desjardins G., 2008, 1327 U MONTR DEP INF; Eslami S.M.A, 2012, ADV NEURAL INFORM PR, V25, P100; Eslami SMA, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.18; Fei-Fei L., 2004, IEEE C COMP VIS PATT; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Freund Y., 1994, UNSUPERVISED LEARNIN; Frey BJ, 2003, PROC CVPR IEEE, P45; Friedman J, 2010, J STAT SOFTW, V33, P1, DOI 10.18637/jss.v033.i01; Gavrila DM, 2007, IEEE T PATTERN ANAL, V29, P1408, DOI 10.1109/TPAMI.2007.1062; Harzallah H., 2009, INT C COMP VIS; Heess N, 2011, LECT NOTES COMPUT SC, V6792, P9, DOI 10.1007/978-3-642-21738-8_2; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Jojic N, 2004, PROC CVPR IEEE, P212; Jojic N, 2009, PROC CVPR IEEE, P2044, DOI 10.1109/CVPRW.2009.5206581; Kapoor A, 2006, LECT NOTES COMPUT SC, V3953, P302, DOI 10.1007/11744078_24; Kohli P., 2007, IEEE C COMP VIS PATT; Kohli P, 2009, INT J COMPUT VISION, V82, P302, DOI 10.1007/s11263-008-0202-0; Komodakis Nikos, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2985, DOI 10.1109/CVPRW.2009.5206846; Kumar MP, 2005, PROC CVPR IEEE, P18; Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510; Le Roux N, 2011, NEURAL COMPUT, V23, P593, DOI 10.1162/NECO_a_00086; Lee H., 2009, P ANN INT C MACH LEA, P609; Morris R. D., 1996, P IEEE DIG SIGN PROC; Murray I., 2009, ADV NEURAL INFORM PR, V21; NEAL RM, 1992, ARTIF INTELL, V56, P71, DOI 10.1016/0004-3702(92)90065-6; Neal RM, 2001, STAT COMPUT, V11, P125, DOI 10.1023/A:1008923215028; Norouzi Mohammad, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2735, DOI 10.1109/CVPRW.2009.5206577; Nowozin S, 2009, PROC CVPR IEEE, P818, DOI 10.1109/CVPRW.2009.5206567; Raina R., 2009, P 26 ANN INT C MACH, P873; Ranzato M., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2857, DOI 10.1109/CVPR.2011.5995710; Ranzato M., 2010, ADV NEURAL INFORM PR, V23; ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586; Roth S, 2005, PROC CVPR IEEE, P860; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Rother C, 2009, PROC CVPR IEEE, P1382, DOI 10.1109/CVPRW.2009.5206739; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Salakhutdinov R., 2009, P 12 INT C ART INT S, P448; Salakhutdinov R., 2008, INT C MACH LEARN 200; Schneiderman H., 2000, THESIS CARNEGIE MELL; Shekhovtsov Alexander, 2012, Pattern Recognition. Proceedings Joint 34th DAGM and 36th OAGM Symposium, P41, DOI 10.1007/978-3-642-32717-9_5; Thomas A, 2009, INT J ROBOT RES, V28, P976, DOI 10.1177/0278364909340444; Tieleman T., 2008, P 25 INT C MACHINE L, P1064, DOI DOI 10.1145/1390156.1390290; Tjelmeland H, 1998, SCAND J STAT, V25, P415, DOI 10.1111/1467-9469.00113; Williams CKI, 2004, NEURAL COMPUT, V16, P1039, DOI 10.1162/089976604773135096; Winn J, 2005, IEEE I CONF COMP VIS, P756; YOUNES L, 1989, PROBAB THEORY REL, V82, P625, DOI 10.1007/BF00341287; Younes L., 1999, STOCHASTICS STOCHAST, V65, P177, DOI DOI 10.1080/17442509908834179	63	69	77	1	44	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	2014	107	2			SI		155	176		10.1007/s11263-013-0669-1	http://dx.doi.org/10.1007/s11263-013-0669-1			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AD3QP		Green Accepted			2022-12-18	WOS:000333161200005
J	Ringaby, E; Forssen, PE				Ringaby, Erik; Forssen, Per-Erik			Efficient Video Rectification and Stabilisation for Cell-Phones	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Cell-phone; Rolling shutter; CMOS; Video stabilisation	IMAGE; DISTORTION	This article presents a method for rectifying and stabilising video from cell-phones with rolling shutter (RS) cameras. Due to size constraints, cell-phone cameras have constant, or near constant focal length, making them an ideal application for calibrated projective geometry. In contrast to previous RS rectification attempts that model distortions in the image plane, we model the 3D rotation of the camera. We parameterise the camera rotation as a continuous curve, with knots distributed across a short frame interval. Curve parameters are found using non-linear least squares over inter-frame correspondences from a KLT tracker. By smoothing a sequence of reference rotations from the estimated curve, we can at a small extra cost, obtain a high-quality image stabilisation. Using synthetic RS sequences with associated ground-truth, we demonstrate that our rectification improves over two other methods. We also compare our video stabilisation with the methods in iMovie and Deshaker.	[Ringaby, Erik; Forssen, Per-Erik] Linkoping Univ, Dept Elect Engn, S-58183 Linkoping, Sweden	Linkoping University	Ringaby, E (corresponding author), Linkoping Univ, Dept Elect Engn, S-58183 Linkoping, Sweden.	ringaby@isy.liu.se			CENIIT organisation at Linkoping Institute of Technology; Swedish Research Council	CENIIT organisation at Linkoping Institute of Technology; Swedish Research Council(Swedish Research CouncilEuropean Commission)	We would like to thank SonyEricsson Research Centre in Lund for providing us with a SonyEricsson Xperia X10, and Anders Nilsson at Computer Engineering for lending us the equipment for readout time calibration. This work is funded by the CENIIT organisation at Linkoping Institute of Technology, and by the Swedish Research Council.	Ait-Aider O., 2007, CVPR 07 MINN US; Ait-Aider O, 2009, IEEE I CONF COMP VIS, P1835, DOI 10.1109/ICCV.2009.5459408; Apple Inc, 2010, IMOVIE 09 VID STAB; Baker S., 2007, IEEE INT C COMP VIS; Baker S., 2010, IEEE C COMP VIS PATT; Bernstein J, 2003, SENSORS MAGAZINE; Buehler C, 2001, PROC CVPR IEEE, P609; Chang L. W., 2005, INT S COMM ISCOM05; Cho WH, 2007, IEEE T CONSUM ELECTR, V53, P979, DOI 10.1109/TCE.2007.4341576; Cho WH, 2007, IEEE T CONSUM ELECTR, V53, P833, DOI 10.1109/TCE.2007.4341553; Chun JB, 2008, IEEE T CONSUM ELECTR, V54, P1479, DOI 10.1109/TCE.2008.4711190; El Gamal Abbas, 2005, IEEE CIRCUITS DEVICE; Forssen P.-E., 2010, IEEE C COMP VIS PATT; Geyer C., 2005, 6 OMNIVIS WS; Gramkow C, 2001, INT J COMPUT VISION, V42, P7, DOI 10.1023/A:1011129215388; Green R., 1983, US Patent, Patent No. [4,403,256, 4403256]; Harris C. G., 1988, P 4 ALV VIS C, V15, P10, DOI [10.5244/C.2.23, DOI 10.5244/C.2.23]; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Liang CK, 2008, IEEE T IMAGE PROCESS, V17, P1323, DOI 10.1109/TIP.2008.925384; Liu F., 2011, SUBSPACE VIDEO STA S; Liu F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899408; Liu F, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531350; LUCAS BD, 1981, IJCAI, V81, P674; Morimoto C, 1997, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.1997.609396; Nicklin SP, 2007, LECT NOTES ARTIF INT, V4434, P402; Park FC, 1997, ACM T GRAPHIC, V16, P277, DOI 10.1145/256157.256160; Ringaby E, 2010, ROLLING SHUTTER DATA; Shi J., 1994, IEEE C COMP VIS PATT, P593; Shoemaker K., 1985, Computer Graphics, V19, P245, DOI 10.1145/325165.325242; Thalin G., 2010, DESHAKER VIDEO STABI; Whyte O., 2010, IEEE C COMP VIS PATT; Yao YS, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pA191; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718	33	69	72	0	20	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	FEB	2012	96	3					335	352		10.1007/s11263-011-0465-8	http://dx.doi.org/10.1007/s11263-011-0465-8			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	885HK		Green Submitted			2022-12-18	WOS:000299769400005
J	Ryoo, MS; Aggarwal, JK				Ryoo, M. S.; Aggarwal, J. K.			Stochastic Representation and Recognition of High-Level Group Activities	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Human activity recognition; Group activity recognition; Description-based event detection; Stochastic grammar	EVENT RECOGNITION	This paper describes a stochastic methodology for the recognition of various types of high-level group activities. Our system maintains a probabilistic representation of a group activity, describing how individual activities of its group members must be organized temporally, spatially, and logically. In order to recognize each of the represented group activities, our system searches for a set of group members that has the maximum posterior probability of satisfying its representation. A hierarchical recognition algorithm utilizing a Markov chain Monte Carlo (MCMC)-based probability distribution sampling has been designed, detecting group activities and finding the acting groups simultaneously. The system has been tested to recognize complex activities such as 'a group of thieves stealing an object from another group' and 'a group assaulting a person'. Videos downloaded from YouTube as well as videos that we have taken are tested. Experimental results show that our system recognizes a wide range of group activities more reliably and accurately, as compared to previous approaches.	[Ryoo, M. S.] Elect & Telecommun Res Inst, Robot Res Dept, Taejon 305606, South Korea; [Ryoo, M. S.; Aggarwal, J. K.] Univ Texas Austin, Comp & Vis Res Ctr, Austin, TX 78712 USA	Electronics & Telecommunications Research Institute - Korea (ETRI); University of Texas System; University of Texas Austin	Ryoo, MS (corresponding author), Elect & Telecommun Res Inst, Robot Res Dept, Taejon 305606, South Korea.	mryoo@etri.re.kr; aggarwaljk@mail.utexas.edu			Korea Ministry of Knowledge and Economy (MKE); Korea Evaluation Institute of Industrial Technology (KEIT) [10035354, 2008-S-031-01]; Texas Higher Education Coordinating Board [003658-0140-2007]	Korea Ministry of Knowledge and Economy (MKE)(Ministry of Trade, Industry & Energy (MOTIE), Republic of Korea); Korea Evaluation Institute of Industrial Technology (KEIT); Texas Higher Education Coordinating Board	This work was supported partly by the R&D program of the Korea Ministry of Knowledge and Economy (MKE) and the Korea Evaluation Institute of Industrial Technology (KEIT) [10035354 The Development of Autonomous Navigation Systems for a Robot Vehicle in Urban Environment] [2008-S-031-01, Hybrid u-Robot Service System Technology Development for Ubiquitous City], and partly by the Texas Higher Education Coordinating Board under award no. 003658-0140-2007.	Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744; Allen J. E., 1994, Journal of Logic and Computation, V4, P531, DOI 10.1093/logcom/4.5.531; ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434; Cupillard F, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P177, DOI 10.1109/ACV.2002.1182178; Francois ARJ, 2005, IEEE MULTIMEDIA, V12, P76, DOI 10.1109/MMUL.2005.87; Gong SG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P742, DOI 10.1109/ICCV.2003.1238423; Hakeem A, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P263; Hongeng S, 2004, COMPUT VIS IMAGE UND, V96, P129, DOI 10.1016/j.cviu.2004.02.005; Intille SS, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P518; Ivanov YA, 2000, IEEE T PATTERN ANAL, V22, P852, DOI 10.1109/34.868686; KHAN SM, 2005, ACM MULTIMEDIA; Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223; Liao L, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P773; Milch B, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P1352; Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684; Park S, 2004, MULTIMEDIA SYST, V10, P164, DOI 10.1007/s00530-004-0148-1; Pinhanez CS, 1998, PROC CVPR IEEE, P898, DOI 10.1109/CVPR.1998.698711; Ryoo MS, 2008, PROC CVPR IEEE, P1758; Ryoo MS, 2008, 2008 IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING, P95; Ryoo MS, 2009, INT J COMPUT VISION, V82, P1, DOI 10.1007/s11263-008-0181-1; Siskind JM, 2001, J ARTIF INTELL RES, V15, P31, DOI 10.1613/jair.790; Song X., 2004, P IEEE WORKSH MOT VI; Taskar B., 2002, P 18 C UNCERTAINTY A, P485; Tran SD, 2008, LECT NOTES COMPUT SC, V5303, P610, DOI 10.1007/978-3-540-88688-4_45; Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594; Vaswani N, 2003, PROC CVPR IEEE, P633; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Vu VT, 2003, IJCAI, P1295; Zhang D, 2006, IEEE T MULTIMEDIA, V8, P509, DOI 10.1109/TMM.2006.870735	30	69	72	0	12	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2011	93	2					183	200		10.1007/s11263-010-0355-5	http://dx.doi.org/10.1007/s11263-010-0355-5			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	740PD					2022-12-18	WOS:000288806000005
J	Szeliski, R; Golland, P				Szeliski, R; Golland, P			Stereo matching with transparency and matting	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	6th International Conference on Computer Vision	JAN 04-07, 1998	BOMBAY, INDIA	IEEE Comp Soc		stereo correspondence; 3D reconstruction; 3D representations; matting problem; occlusions; transparency	MOTION; ALGORITHM; DISPARITY; DEPTH	This paper formulates and solves a new variant of the stereo correspondence problem: simultaneously recovering the disparities, true colors, and opacities of visible surface elements. This problem arises in newer applications of stereo reconstruction, such as view interpolation and the layering of real imagery with synthetic graphics for special effects and virtual studio applications. While this problem is intrinsically more difficult than traditional stereo correspondence, where only the disparities are being recovered, it provides a principled way of dealing with commonly occurring problems such as occlusions and the handling of mixed (foreground/background) pixels near depth discontinuities. It also provides a novel means for separating foreground and background objects (matting), without the use of a special blue screen. We formulate the problem as the recovery of colors and opacities in a generalized 3D (x, y, d) disparity space, and solve the problem using a combination of initial evidence aggregation followed by iterative energy minimization.	Microsoft Corp, Res, Redmond, WA 98052 USA; MIT, Artificial Intelligence Lab, Cambridge, MA 02139 USA	Microsoft; Massachusetts Institute of Technology (MIT)	Szeliski, R (corresponding author), Microsoft Corp, Res, 1 Microsoft Way, Redmond, WA 98052 USA.	szeliski@microsoft.com; polina@ai.mit.edu	chen, mingang/C-7691-2011					ADELSON EH, 1993, SCIENCE, V262, P2042, DOI 10.1126/science.8266102; ADELSON EH, 1990, AAAI 90 WORKSH QUAL, P77; ARNOLD RD, 1983, AIM351 STANF U ART I; Baker H.H., 1980, P DARPA IMAGE UNDERS, P168; BAKER S, 1998, IEEE COMP SOC C COMP; BARNARD ST, 1989, INT J COMPUT VISION, V3, P17, DOI 10.1007/BF00054836; BARNARD ST, 1982, ACM COMPUT SURV, V14, P553, DOI DOI 10.1145/356893.356896; BELHUMEUR PN, 1992, COMPUTER VISION PATT, P506; BERGEN JR, 1992, IEEE T PATTERN ANAL, V14, P886, DOI 10.1109/34.161348; BLINN JF, 1994, IEEE COMPUT GRAPH, V14, P78, DOI 10.1109/38.291534; BLINN JF, 1994, IEEE COMPUT GRAPH, V14, P83, DOI 10.1109/38.310740; Blonde L, 1996, IEEE MULTIMEDIA, V3, P18, DOI 10.1109/93.502291; BOLLES RC, 1987, INT J COMPUT VISION, V1, P7, DOI 10.1007/BF00128525; Collins RT, 1996, PROC CVPR IEEE, P358, DOI 10.1109/CVPR.1996.517097; COX IJ, 1994, IEEE COMP SOC C COMP, P733; DARREL T, 1991, IEEE WORKSH VIS MOT, P173; DHOND UR, 1989, IEEE T SYST MAN CYB, V19, P1489, DOI 10.1109/21.44067; Fua P., 1993, Machine Vision and Applications, V6, P35, DOI 10.1007/BF01212430; GEIGER D, 1992, 2 EUR C COMP VIS ECC, P425; GOLLAND P, 1995, 9513 CS DEP IS LAB; Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200; Huber P., 1981, ROBUST STAT; INTILLE SS, 1994, P 3 EUR C COMP VIS E; JENKIN MRM, 1991, CVGIP-IMAG UNDERSTAN, V53, P14, DOI 10.1016/1049-9660(91)90002-7; JONES DG, 1992, 2 EUR C COMP VIS ECC, P397; JU S, 1996, IEEE C COMP VIS PATT, P307; KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690; KANADE T, 1996, IEEE COMP SOC C COMP, P196; KANG SB, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P88, DOI 10.1109/ICCV.1995.466802; Lacroute P., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P451, DOI 10.1145/192161.192283; LEVOY M, 1990, ACM T GRAPHIC, V9, P245, DOI 10.1145/78964.78965; Lucas B D, 1981, P 7 INT JOINT C ARTI, P674; MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482; MATTHIES L, 1989, INT J COMPUT VISION, V3, P209, DOI 10.1007/BF00133032; McMillan L., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P39, DOI 10.1145/218380.218398; Mitsunaga T., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P265, DOI 10.1145/218380.218450; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955; PAKER Y, 1994, P EUR WORKSH COMB RE; POLLARD SB, 1985, PERCEPTION, V14, P449, DOI 10.1068/p140449; PRAZDNY K, 1985, BIOL CYBERN, V52, P93, DOI 10.1007/BF00363999; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; RYAN TW, 1980, OPT ENG, V19, P312, DOI 10.1117/12.7972515; Sawhney HS, 1996, IEEE T PATTERN ANAL, V18, P814, DOI 10.1109/34.531801; SCHARSTEIN D, 1996, IEEE COMP SOC C COMP, P343; SEITZ SM, 1997, IEEE COMP SOC C COMP, P1067; SHADE J, 1998, COMP GRAPH SIGGRAPH; SHIZAWA M, 1991, IEEE C COMP VIS PATT, P289; SHIZAWA M, 1991, IEEE WORKSH VIS MOT, P164; Smith A. R., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P259, DOI 10.1145/237170.237263; SZELISKI R, 1985, IEEE COMP SOC C COMP, P284; SZELISKI R, 1995, IEEE WORKSH REPR VIS, P26; TIAN Q, 1986, COMPUT VISION GRAPH, V35, P220, DOI 10.1016/0734-189X(86)90028-9; VLAHOS P, 1993, AM CINEMATOGRAPHER M, P430; WANG J, 1993, IEEE C COMP VIS PATT, P361; WEINSHALL D, 1989, NATURE, V341, P737, DOI 10.1038/341737a0; WEISS Y, 1996, IEEE C COMP VIS PATT, P321; WOOD GA, 1983, PHOTOGRAMM ENG REM S, V49, P537; YANG Y, 1993, IEEE COMP SOC C COMP, P274, DOI DOI 10.1109/CVPR.1993.340969; YUILLE AL, 1984, 777 MIT AI	61	69	74	0	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	1999	32	1					45	61		10.1023/A:1008192912624	http://dx.doi.org/10.1023/A:1008192912624			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	237NW					2022-12-18	WOS:000082663800004
J	Neuenschwander, WM; Fua, P; Iverson, L; Szekely, G; Kubler, O				Neuenschwander, WM; Fua, P; Iverson, L; Szekely, G; Kubler, O			Ziplock snakes	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							MODELS	We propose a snake-based approach that allows a user to specify only the distant end points of the curve he wishes to delineate without having to supply an almost complete polygonal approximation. This greatly simplifies the initialization process and yields excellent convergence properties. This is achieved by using the image information around the end points to provide boundary conditions and by introducing an optimization schedule that allows a snake to take image information into account first only near its extremities and then, progressively, toward its center. In effect, the snakes are clamped onto the image contour in a manner reminiscent of a ziplock being closed. These snakes can be used to alleviate the often repetitive task practitioners face when segmenting images by eliminating the need to sketch a feature of interest in its entirety, that is, to perform a painstaking, almost complete, manual segmentation.	ECOLE POLYTECH FED LAUSANNE, SWISS FED INST TECHNOL, COMP GRAPH LAB, CH-1015 LAUSANNE, SWITZERLAND; SRI INT, CTR ARTIFICIAL INTELLIGENCE, MENLO PK, CA 94025 USA	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; SRI International	Neuenschwander, WM (corresponding author), ETH ZURICH, COMMUN TECHNOL LAB, CH-8092 ZURICH, SWITZERLAND.		Szekely, Gabor/A-3880-2008	Fua, Pascal/0000-0002-6702-9970				Arnol'd V I, 1973, ORDINARY DIFFERENTIA; BASCLE B, 1993, INT C COMP VIS BERL, P421; Berger M.-O., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P847, DOI 10.1109/ICPR.1990.118228; BERGER MO, 1991, THESIS CTR RECH INF; Bush A. W, 1992, PERTURBATION METHODS; COURANT R, 1989, METHODS MATH PHYSICS, V1; Davatzikos C., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P524, DOI 10.1109/CVPR.1993.341080; Fua P., 1990, Machine Vision and Applications, V3, P45, DOI 10.1007/BF01211451; HENRICSSON O, 1994, INT C PATT RECOG, P68, DOI 10.1109/ICPR.1994.576228; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; LEYMARIE F, 1993, IEEE T PATTERN ANAL, V15, P617, DOI 10.1109/34.216733; NEUENSCHWANDER W, 1995, THESIS SWISS FEDERAL; TERZOPOULOS D, 1987, INT J COMPUT VISION, V1, P211, DOI 10.1007/BF00127821; TERZOPOULOS D, 1987, TECHNICAL DIGEST SER, V12, P160; Terzopoulos D., 1992, ACTIVE VISION	17	69	74	0	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	1997	25	3					191	201		10.1023/A:1007924018415	http://dx.doi.org/10.1023/A:1007924018415			11	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	YK778					2022-12-18	WOS:A1997YK77800001
J	Valada, A; Mohan, R; Burgard, W				Valada, Abhinav; Mohan, Rohit; Burgard, Wolfram			Self-Supervised Model Adaptation for Multimodal Semantic Segmentation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Semantic segmentation; Multimodal fusion; Scene understanding; Model adaptation; Deep learning	NETWORKS; RGB	Learning to reliably perceive and understand the scene is an integral enabler for robots to operate in the real-world. This problem is inherently challenging due to the multitude of object types as well as appearance changes caused by varying illumination and weather conditions. Leveraging complementary modalities can enable learning of semantically richer representations that are resilient to such perturbations. Despite the tremendous progress in recent years, most multimodal convolutional neural network approaches directly concatenate feature maps from individual modality streams rendering the model incapable of focusing only on the relevant complementary information for fusion. To address this limitation, we propose a mutimodal semantic segmentation framework that dynamically adapts the fusion of modality-specific features while being sensitive to the object category, spatial location and scene context in a self-supervised manner. Specifically, we propose an architecture consisting of two modality-specific encoder streams that fuse intermediate encoder representations into a single decoder using our proposed self-supervised model adaptation fusion mechanism which optimally combines complementary features. As intermediate representations are not aligned across modalities, we introduce an attention scheme for better correlation. In addition, we propose a computationally efficient unimodal segmentation architecture termed AdapNet++ that incorporates a new encoder with multiscale residual units and an efficient atrous spatial pyramid pooling that has a larger effective receptive field with more than 10x\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$10\,\times $$\end{document} fewer parameters, complemented with a strong decoder with a multi-resolution supervision scheme that recovers high-resolution details. Comprehensive empirical evaluations on Cityscapes, Synthia, SUN RGB-D, ScanNet and Freiburg Forest benchmarks demonstrate that both our unimodal and multimodal architectures achieve state-of-the-art performance while simultaneously being efficient in terms of parameters and inference time as well as demonstrating substantial robustness in adverse perceptual conditions.	[Valada, Abhinav; Mohan, Rohit; Burgard, Wolfram] Univ Freiburg, Freiburg, Germany; [Burgard, Wolfram] Toyota Res Inst, Los Altos, CA USA	University of Freiburg; Toyota Motor Corporation	Valada, A (corresponding author), Univ Freiburg, Freiburg, Germany.	valada@cs.uni-freiburg.de; mohan@cs.uni-freiburg.de; burgard@cs.uni-freiburg.de	Valada, Abhinav/ABE-8411-2021	Valada, Abhinav/0000-0003-4710-3114; Burgard, Wolfram/0000-0002-5680-6500				Abadi M, 2015, P 12 USENIX S OPERAT; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 1999, ALGORITHM THEOR BASI; Anwar S, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3005348; Audebert N, 2018, ISPRS J PHOTOGRAMM, V140, P20, DOI 10.1016/j.isprsjprs.2017.11.011; Badrinarayanan V., 2015, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2016.2644615; Berg A.C., 2015, ARXIV150604579; Boniardi F., 2019, ARXIV190301804; Brostow G. J., 2008, P EUR C COMP VIS; Bul S. R., 2018, P C COMP VIS PATT RE; Chattopadhyay Aditya, 2017, ARXIV171011063; CHEN LC, 2016, ARXIV 1606 00915 CS, V1606, P915, DOI DOI 10.1109/TPAMI.2017.2699184; Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49; Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Cichy RM, 2016, CEREB CORTEX, V26, P3563, DOI 10.1093/cercor/bhw135; Cipoll Roberto, 2008, PROC CVPR IEEE, P1; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Couprie C., 2013, ARXIV13013572, P1; Cun YL., 1990, ADV NEURAL INF PROCE, P598, DOI DOI 10.5555/109230.109298; Dai A, 2018, LECT NOTES COMPUT SC, V11214, P458, DOI 10.1007/978-3-030-01249-6_28; Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Eitel A, 2015, IEEE INT C INT ROBOT, P681, DOI 10.1109/IROS.2015.7353446; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Farabet Clement, 2012, P INT C MACH LEARN; Fei-Fei L., 2004, J VISION, V4, P863, DOI DOI 10.1167/4.8.863; Fulkerson B., 2009, P INT C COMP VIS; Ghiasi G, 2016, LECT NOTES COMPUT SC, V9907, P519, DOI 10.1007/978-3-319-46487-9_32; Grangier D., 2009, ICML WORKSH DEEP LEA; Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23; Hazirbas C, 2017, LECT NOTES COMPUT SC, V10111, P213, DOI 10.1007/978-3-319-54181-5_14; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; Hermans A, 2014, IEEE INT CONF ROBOT, P2631, DOI 10.1109/ICRA.2014.6907236; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Janoch A., 2013, CONSUMER DEPTH CAMER, P141, DOI DOI 10.1007/978-1-4471-4640-7_8; Jie H., 2017, P IEEE C COMP VIS PA, P99; Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90; Kim D. K., 2017, FIELD SERVICE ROBOTI; Kohli P, 2009, INT J COMPUT VISION, V82, P302, DOI 10.1007/s11263-008-0202-0; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Ku J, 2018, 2018 15TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P16, DOI 10.1109/CRV.2018.00013; Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562; Li Z., 2016, P EUR C COMP VIS; LiangChieh C., 2015, P INT C LEARN REPR; Lin G., 2017, P C COMP VIS PATT RE; Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1017/S1368980013002176, 10.1109/PLASMA.2013.6634954]; Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Molchanov P., 2017, P INT C LEARN REPR I, P1; Munoz D., 2012, P EUR C COMP VIS; Noh H, 2017, IEEE I CONF COMP VIS, P3476, DOI 10.1109/ICCV.2017.374; Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178; Paszke A., 2016, ARXIV PREPRINT ARXIV; Pinheiro PO, 2014, PR MACH LEARN RES, V32; Plath N., 2009, P INT C MACH LEARN; Qi XJ, 2017, IEEE I CONF COMP VIS, P5209, DOI 10.1109/ICCV.2017.556; Radwan N, 2018, ARXIV180806887; Radwan N, 2018, IEEE ROBOT AUTOM LET, V3, P4407, DOI 10.1109/LRA.2018.2869640; Ren X., 2012, P C COMP VIS PATT RE; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Ros G, 2016, PROC CVPR IEEE, P3234, DOI 10.1109/CVPR.2016.352; Running S. W., 1999, MODIS DAILY PHOTOSYN; Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474; Schneider L, 2017, LECT NOTES COMPUT SC, V10269, P98, DOI 10.1007/978-3-319-59126-1_9; Silberman Nathan, 2012, EUR C COMP VIS, DOI 10.1007/978-3-642-33715-4_54; Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655; Sturgess P., 2009, P BRIT MACH VIS C; Torres HR, 2016, IEEE INT CONF SERIOU; Valada Abhinav, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4644, DOI 10.1109/ICRA.2017.7989540; Valada A., 2016, ROBOTICS; Valada A., 2016, P INT S EXP ROB; VALADA A, 2016, IEEE RSJ INT C INT R; Wen W, 2016, ADV NEUR IN, V29; Xiang Y, 2017, ROBOTICS: SCIENCE AND SYSTEMS XIII; Xiao J., 2013, P INT C COMP VIS; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388; Yu F, 2016, INT NANOELECTR CONF; Zhang C., 2010, P EUR C COMP VIS; Zhao H., 2017, P C COMP VIS PATT RE; Zhou B., 2014, CORR, V1412, P6856; Zhuang YQ, 2018, IEEE IMAGE PROC, P3698, DOI 10.1109/ICIP.2018.8451830	88	68	74	8	39	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2020	128	5					1239	1285		10.1007/s11263-019-01188-y	http://dx.doi.org/10.1007/s11263-019-01188-y			47	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	LL3BW		Green Submitted			2022-12-18	WOS:000531431500011
J	Lee, YJ; Grauman, K				Lee, Yong Jae; Grauman, Kristen			Foreground Focus: Unsupervised Learning from Partially Matching Images	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Object recognition; Feature selection; Unsupervised learning; Feature descriptor		We present a method to automatically discover meaningful features in unlabeled image collections. Each image is decomposed into semi-local features that describe neighborhood appearance and geometry. The goal is to determine for each image which of these parts are most relevant, given the image content in the remainder of the collection. Our method first computes an initial image-level grouping based on feature correspondences, and then iteratively refines cluster assignments based on the evolving intra-cluster pattern of local matches. As a result, the significance attributed to each feature influences an image's cluster membership, while related images in a cluster affect the estimated significance of their features. We show that this mutual reinforcement of object-level and feature-level similarity improves unsupervised image clustering, and apply the technique to automatically discover categories and foreground regions in images from benchmark datasets.	[Lee, Yong Jae] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA; [Grauman, Kristen] Univ Texas Austin, Dept Comp Sci, Austin, TX 78712 USA	University of Texas System; University of Texas Austin; University of Texas System; University of Texas Austin	Lee, YJ (corresponding author), Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.	yjlee0222@mail.utexas.edu; grauman@cs.utexas.edu			National Science Foundation [0747356, EIA- 0303609,]; Microsoft Research New Faculty Fellowship; Texas Higher Education Coordinating Board; Henry Luce Foundation; Div Of Information & Intelligent Systems [0747356] Funding Source: National Science Foundation	National Science Foundation(National Science Foundation (NSF)); Microsoft Research New Faculty Fellowship(Microsoft); Texas Higher Education Coordinating Board; Henry Luce Foundation; Div Of Information & Intelligent Systems(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	The authors would like to thank the anonymous reviewers for providing excellent suggestions, and Delbert Dueck, David Liu, and Till Quack for sharing their experimental data and results. We also gratefully acknowledge support for this research provided in part by National Science Foundation CAREER Award 0747356, a Microsoft Research New Faculty Fellowship, Texas Higher Education Coordinating Board, National Science Foundation EIA- 0303609, and the Henry Luce Foundation.	AGARWAL A, 2006, EUR C COMP VIS; CHUM O, 2007, C COMP VIS PATT REC; Dhillon I.S., 2004, ACM SIGKDD INT C KNO; DORKO G, 2003, INT C COMP VIS; Dueck D., 2007, INT C COMP VIS; Dy JG, 2004, J MACH LEARN RES, V5, P845; Everingham M., 2006, PASCAL VISUAL OBJECT; Fanti C, 2004, ADV NEUR IN, V16, P1603; Fei-Fei L, 2005, PROC CVPR IEEE, P524; FEIFEI L, 2004, CALTECH 101 IMAGE DA; FERGUS R, 2005, INT C COMP VIS; Grauman K, 2005, IEEE I CONF COMP VIS, P1458; GRAUMAN K, 2006, C COMP VIS PATT REC; GRAUMAN K, 2004, C COMP VIS PATT REC; GRIFFIN G, 2007, CALTECH 256 IMAGE DA; LAZEBNIK S, 2003, C COMP VIS PATT REC; Lazebnik S., 2006, C COMP VIS PATT REC; LAZEBNIK S, 2004, BRIT MACH VIS C; LEE YJ, 2008, DISCOVERING MULTIASP; LEE YJ, 2008, BRIT MACH VIS C; LEIBE B, 2004, WKSHP STAT LEARN COM; Ling H., 2007, INT C COMP VIS; LIU D, 2007, INT C COMP VIS; LIU D, 2006, CVPR WKSHOP PATCH; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MARSZALEK M, 2006, C COMP VIS PATT REC; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490; OPELT A, 2006, T PATTERN ANAL MACHI, V28; QUACK T, 2007, INT C COMP VIS; QUELHAS P, 2005, INT C COMP VIS BEIJ; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; RUSSELL B, 2006, C COMP VIS PATT REC; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; SIVIC J, 2004, C COMP VIS PATT REC; Sivic Josef, 2005, INT C COMP VIS; WEBER M, 2000, EUR C COMP VIS; Winn J., 2005, INT C COMP VIS	38	68	70	0	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	2009	85	2					143	166		10.1007/s11263-009-0252-y	http://dx.doi.org/10.1007/s11263-009-0252-y			24	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	488JD					2022-12-18	WOS:000269344500002
J	Bronstein, AM; Bronstein, MM; Bruckstein, AM; Kimmel, R				Bronstein, Alexander M.; Bronstein, Michael M.; Bruckstein, Alfred M.; Kimmel, Ron			Analysis of two-dimensional non-rigid shapes	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						non-rigid shapes; partial similarity; Pareto optimum; multidimensional scaling; GMDS; Gromov-Hausdorff distance; intrinsic geometry	OBJECT RECOGNITION; INVARIANT; REPRESENTATIONS; CLASSIFICATION; SIMILARITY; FRAMEWORK; DISTANCES; SURFACES; MODELS	Analysis of deformable two-dimensional shapes is an important problem, encountered in numerous pattern recognition, computer vision and computer graphics applications. In this paper, we address three major problems in the analysis of non-rigid shapes: similarity, partial similarity, and correspondence. We present an axiomatic construction of similarity criteria for deformation-invariant shape comparison, based on intrinsic geometric properties of the shapes, and show that such criteria are related to the Gromov-Hausdorff distance. Next, we extend the problem of similarity computation to shapes which have similar parts but are dissimilar when considered as a whole, and present a construction of set-valued distances, based on the notion of Pareto optimality. Finally, we show that the correspondence between non-rigid shapes can be obtained as a byproduct of the non-rigid similarity problem. As a numerical framework, we use the generalized multidimensional scaling (GMDS) method, which is the numerical core of the three problems addressed in this paper.	[Bronstein, Alexander M.; Bronstein, Michael M.; Bruckstein, Alfred M.; Kimmel, Ron] Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Technion Israel Institute of Technology	Bronstein, AM (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	bronstein@ieee.org; alexbron@ieee.org; freddy@cs.technion.ac.il; ron@cs.technion.ac.il	Bronstein, Michael/G-5415-2010	Bronstein, Michael/0000-0002-1262-7252; Bruckstein, Alfred/0000-0001-5669-0037				Bajcsy R., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P231; Basri R, 1998, VISION RES, V38, P2365, DOI 10.1016/S0042-6989(98)00043-1; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BERG A, 2005, P CVPR; BIEDERMAN I, 1985, COMPUT VISION GRAPH, V32, P29, DOI 10.1016/0734-189X(85)90002-7; BINFORD TO, 1987, P IEEE C SYST CONTR, P231; Black MJ, 1993, P 4 INT C COMP VIS, P231, DOI DOI 10.1109/ICCV.1993.378214; Borg I., 1997, MODERN MULTIDIMENSIO; Bronstein A.M., 2005, P IEEE INT C IM PROC, V3, P756; Bronstein AM, 2007, IEEE T VIS COMPUT GR, V13, P902, DOI 10.1109/TVCG.2007.1041; Bronstein AM, 2006, LECT NOTES COMPUT SC, V3953, P396, DOI 10.1007/11744078_31; Bronstein AM, 2006, LECT NOTES COMPUT SC, V4069, P38; Bronstein AM, 2006, LECT NOTES COMPUT SC, V4069, P48; Bronstein AM, 2006, SIAM J SCI COMPUT, V28, P1812, DOI 10.1137/050639296; Bronstein AM, 2008, MONOGR COMPUT SCI, P1, DOI 10.1007/978-0-387-73301-2_1; Bronstein AM, 2006, P NATL ACAD SCI USA, V103, P1168, DOI 10.1073/pnas.0508601103; Bronstein AM, 2005, LECT NOTES COMPUT SC, V3459, P622; Bronstein AM, 2005, INT J COMPUT VISION, V64, P5, DOI 10.1007/s11263-005-1085-y; Bronstein AM, 2003, LECT NOTES COMPUT SC, V2688, P62; BRONSTEIN AM, 2007, IN PRESS ACM T GRAPH; Bronstein MM, 2006, NUMER LINEAR ALGEBR, V13, P149, DOI 10.1002/nla.475; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; Bruckstein AM, 1998, IEEE T IMAGE PROCESS, V7, P1583, DOI 10.1109/83.725365; Burago D., 2001, GRADUATE STUDIES MAT, V33, DOI 10.1090/gsm/033; BURR DJ, 1981, IEEE T PATTERN ANAL, V3, P708, DOI 10.1109/TPAMI.1981.4767176; Charpiat G, 2007, INT J COMPUT VISION, V73, P325, DOI 10.1007/s11263-006-9966-2; Cheng SW, 2001, COMP GEOM-THEOR APPL, V19, P205, DOI 10.1016/S0925-7721(01)00020-7; COHEN I, 1992, LECT NOTES COMPUT SC, V588, P458; CONNELL JH, 1987, ARTIF INTELL, V31, P159, DOI 10.1016/0004-3702(87)90018-X; DEROOIJ S, 2006, UNPUB IEEE T INFORM; Elad A, 2001, PROC CVPR IEEE, P168; ELAD A, 2002, LECT NOTES COMPUTER, V2191; Eldar Y, 1997, IEEE T IMAGE PROCESS, V6, P1305, DOI 10.1109/83.623193; Everson RM, 2006, PATTERN RECOGN LETT, V27, P918, DOI 10.1016/j.patrec.2005.10.016; Felzenszwalb P.F., 2007, P CVPR; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Felzenszwalb PF, 2005, IEEE T PATTERN ANAL, V27, P208, DOI 10.1109/TPAMI.2005.35; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Forsyth David A, 2012, COMPUTER VISION MODE; Gdalyahu Y, 1999, IEEE T PATTERN ANAL, V21, P1312, DOI 10.1109/34.817410; Geiger D, 2003, IEEE T PATTERN ANAL, V25, P86, DOI 10.1109/TPAMI.2003.1159948; GELFAND N, 2005, P S GEOM PROC SGP; Grenander U., 1991, HANDS PATTERN THEORE; GROMOV M., 1981, TEXTES MATH, V1; Hampel FR., 2011, WILEY SERIES PROBABI; HELOR Y, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P39, DOI 10.1109/CVPR.1994.323808; HILDRETH E, 1983, MEASUREMENT VISUAL M; HOFFMAN D, 1984, PARTS RECOGNITION; Huber P.J., 2004, ROBUST STAT; JACOBS D, 2005, P ICCV; Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197; Jain AK, 1996, IEEE T PATTERN ANAL, V18, P267, DOI 10.1109/34.485555; Kass M., 1987, International Journal of Computer Vision, V1, P321, DOI 10.1007/BF00133570; Kimmel R, 1998, P NATL ACAD SCI USA, V95, P8431, DOI 10.1073/pnas.95.15.8431; Klir G.J., 1994, FUZZY SETS FUZZY LOG; KOENDERINK JJ, 1982, PERCEPTION, V11, P129, DOI 10.1068/p110129; KUPEEV KY, 1994, INT C PATT RECOG, P227, DOI 10.1109/ICPR.1994.576262; LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173; Latecki LJ, 2000, IEEE T PATTERN ANAL, V22, P1185, DOI 10.1109/34.879802; Latecki LJ, 2005, IMAGE VISION COMPUT, V23, P227, DOI 10.1016/j.imavis.2004.06.015; LING H, 2005, P CVPR; Memoli F, 2005, FOUND COMPUT MATH, V5, P313, DOI 10.1007/s10208-004-0145-y; MICHOR PW, 2003, MATHDG0312384; Mio W, 2007, INT J COMPUT VISION, V73, P307, DOI [10.1007/s11263-006-9968-0, 10.1007/s11263-006-996S-0]; MUMFORD D, 1991, P C 1570 SOC PHOT IN, P2; Pareto Vilfredo., 1906, MANUALE EC POLITICA, V13th ed; Pentland A. P., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P612; Platel B, 2005, LECT NOTES COMPUT SC, V3753, P211, DOI 10.1007/11577812_19; RIVLIN E, 1992, P CVPR, P267; SALUKWADZE ME, 1979, VECTRO VALUED OPTIMI; SETHIAN JA, 1996, ACTA NUMER, P309; Siddiqi K, 1996, PROC CVPR IEEE, P507, DOI 10.1109/CVPR.1996.517119; Spira A, 2004, INTERFACE FREE BOUND, V6, P315; STARK L, 1991, IEEE T PAMI, V10, P992; TAPPERT CC, 1982, IBM J RES DEV, V26, P765, DOI 10.1147/rd.266.0765; ULLMAN S, 1989, COGNITION, V32, P193, DOI 10.1016/0010-0277(89)90036-X; Walter J. A., 2002, P 8 ACM SIGKDD INT C, P123; YEZZI A, 2004, MATHDG0412454; Yuille A. L., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P104, DOI 10.1109/CVPR.1989.37836; Zadeh L. A., 1978, Fuzzy Sets and Systems, V1, P3, DOI 10.1016/0165-0114(78)90029-5; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; Zhang JY, 2004, PROC CVPR IEEE, P342; Zimmermann H.J., 2001, FUZZY SET THEORY ITS, DOI [10.1007/978-94-010-0646-0_7, DOI 10.1007/978-94-010-0646-0]	83	68	72	0	16	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2008	78	1					67	88		10.1007/s11263-007-0078-4	http://dx.doi.org/10.1007/s11263-007-0078-4			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	270YE		Green Submitted			2022-12-18	WOS:000253755300005
J	Orbanz, P; Buhmann, JM				Orbanz, Peter; Buhmann, Joachim M.			Nonparametric Bayesian image segmentation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Markov random fields; nonparametric Bayesian methods; Dirichlet process mixtures; image segmentation; clustering; spatial statistics; Markov chain; Monte Carlo	DIRICHLET PROCESS PRIOR; DISTRIBUTIONS; RESTORATION	Image segmentation algorithms partition the set of pixels of an image into a specific number of different, spatially homogeneous groups. We propose a nonparametric Bayesian model for histogram clustering which automatically determines the number of segments when spatial smoothness constraints on the class assignments are enforced by a Markov Random Field. A Dirichlet process prior controls the level of resolution which corresponds to the number of clusters in data with a unique cluster structure. The resulting posterior is efficiently sampled by a variant of a conjugate-case sampling algorithm for Dirichlet process mixture models. Experimental results are provided for real-world gray value images, synthetic aperture radar images and magnetic resonance imaging data.	[Orbanz, Peter; Buhmann, Joachim M.] ETH, Inst Computat Sci, ETH Zentrum, CH-8092 Zurich, Switzerland	Swiss Federal Institutes of Technology Domain; ETH Zurich; Universita della Svizzera Italiana	Orbanz, P (corresponding author), ETH, Inst Computat Sci, ETH Zentrum, Univ Str 6,CAB G 84-1, CH-8092 Zurich, Switzerland.	porbanz@inf.ethz.ch	Buhmann, Joachim/AAU-4760-2020					ANTONIAK CE, 1974, ANN STAT, V2, P1152, DOI 10.1214/aos/1176342871; Bach FR, 2004, ADV NEUR IN, V16, P305; BESAG J, 1986, J R STAT SOC B, V48, P259; Blei D. M., 2004, THESIS; Blei DM, 2006, BAYESIAN ANAL, V1, P121, DOI 10.1214/06-BA104; BRECKENRIDGE JN, 1989, MULTIVAR BEHAV RES, V24, P147, DOI 10.1207/s15327906mbr2402_1; Devroye L., 1986, NONUNIFORM RANDOM VA, P61; DUDOIT S, 2002, GENOME, V3; ESCOBAR MD, 1994, J AM STAT ASSOC, V89, P268, DOI 10.2307/2291223; FERGUSON T, 1973, ANN STAT, V1; Fischer B, 2003, IEEE T PATTERN ANAL, V25, P1411, DOI 10.1109/TPAMI.2003.1240115; GEMAN D, 1990, IEEE T PATTERN ANAL, V12, P609, DOI 10.1109/34.56204; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Hermes L, 2002, LECT NOTES COMPUT SC, V2352, P577; Hofmann T, 1998, IEEE T PATTERN ANAL, V20, P803, DOI 10.1109/34.709593; Kotz S., 2000, CONTINUOUS MULTIVARI, V2nd ed., DOI 10.1002/0471722065; Lange T, 2004, NEURAL COMPUT, V16, P1299, DOI 10.1162/089976604773717621; Lehmann E., 2005, TESTING STAT HYPOTHE, V3rd; LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115; MACEACHERN SN, 1994, COMMUN STAT SIMULAT, V23, P727, DOI 10.1080/03610919408813196; MACEACHERN SN, 1998, LECT NOTES STAT, V133; MACEACHERN SN, 2000, ROBUST BAYESIAN ANAL, P295; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; MCAULIFFE JD, 2004, NONPARAMETRIC EMPIRI; Morel J.-M., 1995, VARIATIONAL METHODS; Muller P, 2004, STAT SCI, V19, P95, DOI 10.1214/088342304000000017; Neal RM, 2000, J COMPUT GRAPH STAT, V9, P249, DOI 10.2307/1390653; Puzicha J, 1999, PATTERN RECOGN LETT, V20, P899, DOI 10.1016/S0167-8655(99)00056-2; RISSANEN J, 1983, ANN STAT, V11, P416, DOI 10.1214/aos/1176346150; Robert C.P., 1996, MARKOV CHAIN MONTE C, P441; Roth V, 2003, IEEE T PATTERN ANAL, V25, P1540, DOI 10.1109/TPAMI.2003.1251147; Samson C, 2000, IEEE T PATTERN ANAL, V22, P460, DOI 10.1109/34.857003; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; Walker SG, 1999, J R STAT SOC B, V61, P485, DOI 10.1111/1467-9868.00190; Winkler G., 2003, IMAGE ANAL RANDOM FI; ZARAGOZA H, 2003, P SIGIR 2003; [No title captured]	38	68	74	0	12	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2008	77	1-3					25	45		10.1007/s11263-007-0061-0	http://dx.doi.org/10.1007/s11263-007-0061-0			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	267RE		Green Submitted, Green Published			2022-12-18	WOS:000253526100003
J	Ogale, AS; Aloimonos, Y				Ogale, AS; Aloimonos, Y			Shape and the stereo correspondence problem	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							DISPARITY; SLANT; ANISOTROPY; ALGORITHM; WINDOW	We examine the implications of shape on the process of finding dense correspondence and half-occlusions for a stereo pair of images. The desired property of the disparity map is that it should be a piece-wise continuous function which is consistent with the images and which has the minimum number of discontinuities. To zeroth order, piecewise continuity becomes piecewise constancy. Using this approximation, we first discuss an approach for dealing with such a fronto-parallel shapeless world, and the problems involved therein. We then introduce horizontal and vertical slant to create a first order approximation to piecewise continuity. In particular, we emphasize the following geometric fact: a horizontally slanted surface (i.e., having depth variation in the direction of the separation of the two cameras) will appear horizontally stretched in one image as compared to the other image. Thus, while corresponding two images, N pixels on a scanline in one image may correspond to a different number of pixels M in the other image. This leads to three important modifications to existing stereo algorithms: (a) due to unequal sampling, existing intensity matching metrics must be modified, (b) unequal numbers of pixels in the two images must be allowed to correspond to each other, and (c) the uniqueness constraint, which is often used for detecting occlusions, must be changed to an interval uniqueness constraint. We also discuss the asymmetry between vertical and horizontal slant, and the central role of non-horizontal edges in the context of vertical slant. Using experiments, we discuss cases where existing algorithms fail, and how the incorporation of these new constraints provides correct results.	Univ Maryland, Dept Comp Sci, Comp Vis Lab, Inst Adv Comp Studies, College Pk, MD 20742 USA	University System of Maryland; University of Maryland College Park	Ogale, AS (corresponding author), Univ Maryland, Dept Comp Sci, Comp Vis Lab, Inst Adv Comp Studies, College Pk, MD 20742 USA.		Aloimonos, Yiannis/AAI-2969-2020	Aloimonos, Yiannis/0000-0002-8152-4281				BARNEBY RC, 1989, INTERMOUNTAIN FLOR B, V3, P1; Birchfield S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P489, DOI 10.1109/ICCV.1999.791261; Birchfield S, 1998, IEEE T PATTERN ANAL, V20, P401, DOI 10.1109/34.677269; Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y, 1998, IEEE T PATTERN ANAL, V20, P1283, DOI 10.1109/34.735802; CAGENELLO R, 1993, VISION RES, V33, P2189, DOI 10.1016/0042-6989(93)90099-I; DEVERNAY F, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P208, DOI 10.1109/CVPR.1994.323831; Egnal G, 2002, IEEE T PATTERN ANAL, V24, P1127, DOI 10.1109/TPAMI.2002.1023808; Faugeras O. D., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, P485, DOI 10.1142/S0218001488000285; Fusiello A, 1997, PROC CVPR IEEE, P858, DOI 10.1109/CVPR.1997.609428; GEIGER D, 1992, LECT NOTES COMPUT SC, V588, P425; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GILLAM B, 1992, PERCEPTION, V21, P427, DOI 10.1068/p210427; Hillis JM, 2004, J VISION, V4, P967, DOI 10.1167/4.12.1; KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690; Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668; LIN M, 2003, P IEEE C COMP VIS PA, V1, P710; MARR D, 1979, P ROY SOC LOND B BIO, V204, P328; MITCHISON GJ, 1990, VISION RES, V30, P1781, DOI 10.1016/0042-6989(90)90159-I; Mulligan J, 2000, LECT NOTES COMPUT SC, V1842, P220; OGALE A, 2005, P IEEE C ROB AUT; Ogale AS, 2004, PROC CVPR IEEE, P568; OGALE AS, 2004, THESIS U MARYLAND CO; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955; Okutomi M, 2002, INT J COMPUT VISION, V47, P261, DOI 10.1023/A:1014510328154; ROGERS BJ, 1983, SCIENCE, V221, P1409, DOI 10.1126/science.6612351; Roy S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P492, DOI 10.1109/ICCV.1998.710763; RYAN C, 1994, PERCEPTION, V23, P645, DOI 10.1068/p230645; SCHARSTEIN, INT J COMPUTER VISIO, V47, P7; Scharstein D, 1998, INT J COMPUT VISION, V28, P155, DOI 10.1023/A:1008015117424; SZELISKI R, 1990, INT J COMPUT VISION, V5, P271, DOI 10.1007/BF00126502; Tao H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P532, DOI 10.1109/ICCV.2001.937562	34	68	75	1	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	2005	65	3					147	162		10.1007/s11263-005-3672-3	http://dx.doi.org/10.1007/s11263-005-3672-3			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	999ZE					2022-12-18	WOS:000234429900002
J	WALLACE, RS; ONG, PW; BEDERSON, BB; SCHWARTZ, EL				WALLACE, RS; ONG, PW; BEDERSON, BB; SCHWARTZ, EL			SPACE-VARIANT IMAGE-PROCESSING	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							SCALE; ROTATION	This paper describes a graph-based approach to image processing, intended for use with images obtained from sensors having space variant sampling grids. The connectivity graph (CG) is presented as a fundamental framework for posing image operations in any kind of space variant sensor. Partially motivated by the observation that human vision is strongly space variant, a number of research groups have been experimenting with spade variant sensors. Such systems cover wide solid angles yet maintain high acuity in their central regions. Implementation of space variant systems pose at least two outstanding problems. First, such a system must be active, in order to utilize its high acuity region; second, there are significant image processing problems introduced by the nonuniform pixel size, shape and connectivity. Familiar image processing operations such as connected components, convolution, template matching, and even image translation, take on new and different forms when defined on space variant images. The present paper provides a general method for space variant image processing, based on a connectivity graph which represents the neighbor-relations in an arbitrarily structured sensor. We illustrate this approach with the following applications: (1) Connected components is reduced to its graph theoretic counterpart. We illustrate this on a logmap sensor, which possesses a difficult topology due to the branch cut associated with the complex logarithm function. (2) We show how to write local image operators in the connectivity graph that are independent of the sensor geometry. (3) We relate the connectivity graph to pyramids over irregular tessalations, and implement a local binarization operator in a 2-level pyramid. (4) Finally, we expand the connectivity graph into a structure we call a transformation graph, which represents the effects of geometric transformations in space variant image sensors. Using the transformation graph, we define an efficient algorithm for matching in the logmap images and solve the template matching problem for space variant images. Because of the very small number of pixels typical of logarithmic structured space variant arrays, the connectivity graph approach to image processing is suitable for real-time implementation, and provides a generic solution to a wide range of image processing applications with space variant sensors.	AT&T BELL LABS,MIDDLETOWN,NJ 07748; BELL COMMUN RES INC,MORRISTOWN,NJ; BOSTON UNIV,DEPT COGNIT & NEURAL SYST,BOSTON,MA 02215	AT&T; Telcordia Technologies; Boston University	WALLACE, RS (corresponding author), NYU,COURANT INST MATH SCI,NEW YORK,NY, USA.			Bederson, Benjamin/0000-0002-3247-779X				AIJAZ A, 1990, INT JOINT C NEURAL N, P723; Ballard D.H., 1982, COMPUTER VISION; BEDERSON B, 1992, THESIS NEW YORK U; BEDERSON BB, 1992, 11TH INT C PATT REC; BEDERSON BB, 1992, NOV SPIE C INT ROB C; BEDERSON BB, 1992, NYU264 COUR I TECHN; BEDERSON BB, 1992, MAY IEEE INT C ROB A; BEDERSON BB, 1991, 255 NEW YORK U TECHN; BENJAMIN B, 1992, 266 NEW YORK U TECHN; BRACCINI C, 1982, BIOL CYBERN, P57; CASASENT D, 1976, APPL OPTICS, V15, P1795, DOI 10.1364/AO.15.001795; CHAIKIN GM, 1981, Patent No. 4267573; DEO N, 1974, GRAPH THEORY APPLICA; FRANZBLAU MS, 1991, THESIS NEW YORK U; FRAZIER J, 1992, MAY IEEE INT C ROB A; Horn B., 1986, ROBOT VISION, P1; HURLBERT A, 1986, NATURE, V321, P651, DOI 10.1038/321651a0; KREIDER G, 1990, SPIE, V1242; LEVOY M, 1991, COMPUT GRAPH, V24, P217; MESSNER RA, 1985, COMPUT VISION GRAPH, V31, P50, DOI 10.1016/S0734-189X(85)80075-X; MONTANVERT A, 1991, IEEE T PATTERN ANAL, V13, P307, DOI 10.1109/34.88566; Narathong C., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P411, DOI 10.1109/CVPR.1988.196268; ONG PW, 1992, 11TH INT C PATT REC; ONG PW, 1992, THESIS NEW YORK U; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; ROJER AS, 1990, 10 INT C PATT REC, V2; ROJER AS, 1989, THESIS NEW YORK U; ROSENFELD A, 1970, J ACM, V17, P146, DOI 10.1145/321556.321570; Rosenfeld A., 1982, DIGITAL PICTURE PROC; SAMET H, 1980, COMMUN ACM, V23, P163, DOI 10.1145/358826.358836; SANDINI G, 1989, 5TH INT S ROB RES; SANDINI G, 1989, P OSA TOPICAL M IMAG; SCHWARTZ EL, 1977, BIOL CYBERNETICS, V25; SCHWARTZ EL, 1988, IEEE COMPUTER GRAPHI, V8; SHIO A, 1989, CH27524 IEEE, P632; SWAIN MJ, 1991, PROMISING DIRECTIONS; TONOMO A, 1989, SPIE OPTICS, V1194; TWEED DB, 1990, NEURAL NETWORKS, V3, P75, DOI 10.1016/0893-6080(90)90046-N; VANDERSPIEGEL J, 1989, ANALOG VLSI IMPLEMEN; WALLACE RS, 1991, 256 NEW YORK U TECHN; WALLACE RS, 1992, NEURAL NETWORKS ROBO, P347; WALLACE RS, 1992, NOV P IEEE WORKSH AP; WALLACE RS, 1991, VAL1 VIS APPL INC TE; WEIMAN C, 1979, COMPUTER GRAPHICS IM, V11; WEIMAN CFR, 1989, SPIE INTELLIGENT ROB, V8, P832; WEIMAN CFR, 1988, APR SPIE C DIG OPT S; YAMAGUCHI H, 1990, ITEJ TECHNICAL REPOR, V14; YAMAGUCHI H, 1989, SPIE OPTICS, V1194; YORIZAWA I, 1991, 1991 P EL INF COMM S	49	68	73	0	4	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	1994	13	1					71	90		10.1007/BF01420796	http://dx.doi.org/10.1007/BF01420796			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	PK120					2022-12-18	WOS:A1994PK12000004
J	GUEZIEC, A; AYACHE, N				GUEZIEC, A; AYACHE, N			SMOOTHING AND MATCHING OF 3-D SPACE-CURVES	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							MODEL-BASED RECOGNITION; CROSS-VALIDATION; NOISY DATA; SPLINE	We present a new approach to the problem of matching 3-D curves. The approach has a low algorithmic complexity in the number of models, and can operate in the presence of noise and partial occlusions. Our method builds upon the seminal work of Kishon et al. (1990), where curves are first smoothed using B-splines, with matching based on hashing using curvature and torsion measures. However, we introduce two enhancements. We make use of nonuniform B-spline approximations, which permits us to better retain information at high curvature locations. The spline approximations are controlled (i.e., regularized) by making use of normal vectors to the surface in 3-D on which the curves lie, and by an explicit minimization of a bending energy. These measures allow a more accurate estimation of position, curvature, torsion, and Frenet frames along the curve. The computational complexity of the recognition process is relatively independent of the number of models and is considerably decreased with explicit use of the Frenet frame for hypotheses generation. As opposed to previous approaches, the method better copes with partial occlusion. Moreover, following a statistical study of the curvature and torsion covariances, we optimize the hash table discretization and discover improved invariants for recognition, different than the torsion measure. Finally, knowledge of invariant uncertainties is used to compute an optimal global transformation using an extended Kalman filter. We present experimental results using synthetic data and also using characteristic curves extracted from 3-D medical images. An earlier version of this article was presented at the 2nd European Conference on Computer Vision in Italy.	INRIA,EPIDAURE PROJECT,F-06902 SOPHIA ANTIPOLIS,FRANCE	Inria								[Anonymous], 1986, LONDON ACAD PRESS; ARBOGAST E, 1990, RR115 LIFIA TECH REP; AYACHE N, 1986, IEEE T PATTERN ANAL, V8, P44, DOI 10.1109/TPAMI.1986.4767751; AYACHE N, 1989, COMPUTER AIDED RADIO; AYACHE N, 1990, NATO ASI SER, P107; Ayache N, 1991, ARTIFICIAL VISION MO; Bartels RH, 1987, INTRO SPLINES USE CO; BENAYOUN S, 1992, 11TH P C COMP APPL R; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BOHM W, 1984, SURVEY CURVE SURFACE, P1; CINQUIN P, 1981, THESIS U ST ETIENNE; CINQUIN P, 1987, THESIS; COHEN I, 1991, JUN P C COMP VIS PAT; COHEN LD, 1990, 3RD P INT C COMP VIS; CRAVEN P, 1979, NUMER MATH, V31, P377, DOI 10.1007/BF01437407; CUTTING CB, 1989, 3D IMAGING MED; De Boor C., 1978, PRACTICAL GUIDE SPLI, V27; de Hoog FR, 1987, NUMER MATH, V50, P311, DOI 10.1007/BF01390708; Do Carmo M.P., 2016, DIFFERENTIAL GEOMETR, Vsecond; Duda R.O., 1973, J ROYAL STAT SOC SER; FARIN C, 1988, CURVES SURFACES COMP; GIRARD DA, 1989, NUMER MATH, V56, P1, DOI 10.1007/BF01395775; GRIMSON WEL, 1991, IEEE T PATTERN ANAL, V13, P1201, DOI 10.1109/34.106994; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; GROSSMAN M, 1971, COMPUT J, V14, P169, DOI 10.1093/comjnl/14.2.169; GUEZIEC A, 1993, 4TH P INT C COMP VIS; GUEZIEC A, 1992, 2ND P EUR C COMP VIS; HERLIN IL, 1992, 2ND P EUR C COMP VIS; Holladay JC., 1957, MATH TABLES OTHER AI, V11, P233, DOI [10.2307/2001941, DOI 10.2307/2001941]; KISHON E, 1990, 1ST P EUR C COMP VIS; MALANDAIN G, 1991, JUN P C COMP VIS PAT; MARIN SP, 1984, J APPROX THEORY, V41, P64, DOI 10.1016/0021-9045(84)90121-7; MONGA O, 1991, COMPUT VIS GRAPH IMA; MONGA O, 1991, JUN P C COMP VIS PAT; MONGA O, 1992, JUN P C COMP VIS PAT; NILSON EN, 1967, THEORY SPLINES THEIR; Pavlidis T., 1977, STRUCTURAL PATTERN R; PLASS M, 1983, SIGGRAPH, P229; REINSCH CH, 1971, NUMER MATH, V16, P451, DOI 10.1007/BF02169154; REINSCH CH, 1967, NUMER MATH, V10, P177, DOI 10.1007/BF02162161; RIGOUTSOS I, 1991, 8TH P ISR C ART INT; RIGOUTSOS I, 1992, THESIS NEW YORK U; SAINTMARC P, 1990, 1ST P EUR C COMP VIS; SCHWARTZ JT, 1987, INT J ROBOT RES, V6, P229; SILVERMAN BW, 1984, J AM STAT ASSOC, V79, P584, DOI 10.2307/2288404; STEIN F, 1991, JUN P INT C COMP VIS; THIRION JP, 1992, 14TH P ANN INT C IEE; THIRION JP, 1993, INRIA1881 TECH REPT; THIRION JP, 1992, INRIA1672 TECH REPT; THOMPSON DW, 1987, IEEE J ROBOTIC AUTOM, P208; WANG, 1990, UNPUB AUTOMATIC DATA; ZHANG ZY, 1992, INRIA1658 TECH REPT	52	68	72	0	3	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	FEB	1994	12	1					79	104		10.1007/BF01420985	http://dx.doi.org/10.1007/BF01420985			26	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	MV217		Green Submitted			2022-12-18	WOS:A1994MV21700004
J	Gaidon, A; Harchaoui, Z; Schmid, C				Gaidon, Adrien; Harchaoui, Zaid; Schmid, Cordelia			Activity representation with motion hierarchies	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Action recognition; Video analysis; Motion decomposition; Spectral clustering; Kernel methods		Complex activities, e.g. pole vaulting, are composed of a variable number of sub-events connected by complex spatio-temporal relations, whereas simple actions can be represented as sequences of short temporal parts. In this paper, we learn hierarchical representations of activity videos in an unsupervised manner. These hierarchies of mid-level motion components are data-driven decompositions specific to each video. We introduce a spectral divisive clustering algorithm to efficiently extract a hierarchy over a large number of tracklets (i.e. local trajectories). We use this structure to represent a video as an unordered binary tree. We model this tree using nested histograms of local motion features. We provide an efficient positive definite kernel that computes the structural and visual similarity of two hierarchical decompositions by relying on models of their parent-child relations. We present experimental results on four recent challenging benchmarks: the High Five dataset (Patron-Perez et al., High five: recognising human interactions in TV shows, 2010), the Olympics Sports dataset (Niebles et al., Modeling temporal structure of decomposable motion segments for activity classification, 2010), the Hollywood 2 dataset (Marszalek et al., Actions in context, 2009), and the HMDB dataset (Kuehne et al., HMDB: A large video database for human motion recognition, 2011). We show that per-video hierarchies provide additional information for activity recognition. Our approach improves over unstructured activity models, baselines using other motion decomposition algorithms, and the state of the art.	[Gaidon, Adrien] Xerox Res Ctr Europe, Meylan, France; [Harchaoui, Zaid; Schmid, Cordelia] INRIA Grenoble Rhne Alpes, LEAR Team, F-38330 Montbonnot St Martin, France	Xerox	Gaidon, A (corresponding author), Xerox Res Ctr Europe, Meylan, France.	adrien.gaidon@xrce.xerox.com; zaid.harchaoui@inria.fr; cordelia.schmid@inria.fr			MSR/INRIA joint project; European integrated project AXES; PASCAL 2 Network of Excellence; Gargantua project under program Mastodons of CNRS; LabEx PERSYVAL-Lab [ANR-11-LABX-0025]; ERC advanced grant ALLEGRO	MSR/INRIA joint project; European integrated project AXES; PASCAL 2 Network of Excellence; Gargantua project under program Mastodons of CNRS; LabEx PERSYVAL-Lab; ERC advanced grant ALLEGRO	This work was partially funded by the MSR/INRIA joint project, the European integrated project AXES, the PASCAL 2 Network of Excellence, the Gargantua project under program Mastodons of CNRS, the LabEx PERSYVAL-Lab (ANR-11-LABX-0025), and the ERC advanced grant ALLEGRO.	[Anonymous], 2002, LEARNING KERNELS; Bilen H., 2011, BMVC BRIST; Bradski G., 2008, LEARNING OPENCV COMP; Brendel W., 2011, ICCV BOST; Brox T., 2010, ECCV CARLT; Dalal N., 2006, ECCV BERL; De Castro E., 1987, PAMI PORT LA PRAIR; DIESTEL R, 2005, GRAPH THEORY; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Dupe F., 2008, STRUCTURAL SYNTACTIC; Farneback G., 2003, IMAGE ANAL LOWA; Felzenszwalb P.F., 2010, PAMI PORT LA PRAIR; Foster L., 2009, JMLR LAS VEG; Fowlkes C., 2004, PAMI LOND; Fradet M., 2009, CVMP LOND; Gaidon A., 2011, CVPR PROV; Gaidon A., 2012, BMVC BRIST; Gilbert A., 2010, PAMI PORT LA PRAIR; Grundmann M., 2008, ICPR DELH; Hastie T., 2008, ELEMENTS STAT LEARNI; Hongeng S., 2003, ICCV BOST; Ikizler-Cinbis N., 2010, ECCV CARLT; Jiang Y., 2012, ECCV CARLT; Jiang Z., 2012, PAMI PORT LA PRAIR; Kliper-Gross O., 2012, ECCV CARLT; Kovashka A., 2010, CVPR PROV; Kuehne H., 2011, ICCV NEW YORK; Laptev I., 2005, IJCV ROS; Laptev I., 2008, CVPR PROV; Laxton B., 2007, CVPR PROV; Lezama J., 2011, CVPR PROV; Liu J., 2011, CVPR PROV; Lowe D.G., 2004, IJCV HO CHI MINH; Maji S., 2008, CVPR PROV; Marszalek M., 2009, CVPR PROV; Matikainen P., 2010, ECCV CARLT; Mikolajczyk K., 2008, CVPR PROV; Niebles J.C., 2007, CVPR PROV; Niebles J.C., 2010, ECCV CARLT; Oliver N.M., 2000, PAMI PORT LA PRAIR; Pablo A., 2011, PAMI PORT LA PRAIR; Patron-Perez A., 2010, BMVC BRIST; Prest A., 2012, PAMI PORT LA PRAIR; Raptis M., 2012, CVPR PROV; Reddy K. K., 2009, CVPR PROV; Sadanand S., 2012, CVPR NEW YORK; Sapienza M., 2012, BMVC BRIST; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; Sculley D, 2010, WWW NEW YORK; Shawe-Taylor J, 2004, CRISTIANINI; Shi J., 1994, CVPR PROV; Shi J., 1998, ICCV IEEE BEIJ; Shi J., 2000, PAMI LOND; Suard F., 2007, EUR S ART NEUR NETW, P1; Szeliski R., 2010, COMPUTER VISION ALGO, DOI DOI 10.1007/978-3-030-34372-9; Tang K., 2012, CVPR PROV; Todorovic S., 2012, ECCV CARLT; Vig E., 2012, ECCV CARLT; Wang H., 2013, IJCV DUBL; Wang Y., 2011, PROBABILISTIC VERSUS; Williams C., 2001, NIPS ALL; Yu G, 2012, LECT NOTES COMPUT SC, V7574, P693, DOI 10.1007/978-3-642-33712-3_50	62	67	68	0	25	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2014	107	3					219	238		10.1007/s11263-013-0677-1	http://dx.doi.org/10.1007/s11263-013-0677-1			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AD6IU		Green Submitted			2022-12-18	WOS:000333362600001
J	Rodola, E; Albarelli, A; Bergamasco, F; Torsello, A				Rodola, Emanuele; Albarelli, Andrea; Bergamasco, Filippo; Torsello, Andrea			A Scale Independent Selection Process for 3D Object Recognition in Cluttered Scenes	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Object recognition; Partial surface registration; Game theory; Object in clutter	AUTOMATIC REGISTRATION; REPRESENTATION; SIGNATURES; IMAGES; SETS	During the last years a wide range of algorithms and devices have been made available to easily acquire range images. The increasing abundance of depth data boosts the need for reliable and unsupervised analysis techniques, spanning from part registration to automated segmentation. In this context, we focus on the recognition of known objects in cluttered and incomplete 3D scans. Locating and fitting a model to a scene are very important tasks in many scenarios such as industrial inspection, scene understanding, medical imaging and even gaming. For this reason, these problems have been addressed extensively in the literature. Several of the proposed methods adopt local descriptor-based approaches, while a number of hurdles still hinder the use of global techniques. In this paper we offer a different perspective on the topic: We adopt an evolutionary selection algorithm that seeks global agreement among surface points, while operating at a local level. The approach effectively extends the scope of local descriptors by actively selecting correspondences that satisfy global consistency constraints, allowing us to attack a more challenging scenario where model and scene have different, unknown scales. This leads to a novel and very effective pipeline for 3D object recognition, which is validated with an extensive set of experiments and comparisons with recent techniques at the state of the art.	[Rodola, Emanuele; Albarelli, Andrea; Bergamasco, Filippo; Torsello, Andrea] Univ Ca Foscari Venezia, Dipartimento Sci Ambientali Informat & Stat, Venice, Italy	Universita Ca Foscari Venezia	Rodola, E (corresponding author), Univ Ca Foscari Venezia, Dipartimento Sci Ambientali Informat & Stat, Venice, Italy.	rodola@dsi.unive.it; albarell@unive.it; bergamasco@dsi.unive.it; torsello@dais.unive.it	Torsello, Andrea/K-6352-2016; Rodola, Emanuele/M-4137-2016	Torsello, Andrea/0000-0001-9189-4924; Bergamasco, Filippo/0000-0001-6668-1556; Rodola, Emanuele/0000-0003-0091-7241; Albarelli, Andrea/0000-0002-3659-5099	Future and Emerging Technology (FET) Programme within the Seventh Framework Programme for Research of the European Commission, under FET-Open project SIMBAD Grant [213250]	Future and Emerging Technology (FET) Programme within the Seventh Framework Programme for Research of the European Commission, under FET-Open project SIMBAD Grant	We wish to thank Dr. Samuele Salti for contributing code to compute SHOT descriptors, Prof. Ajmal S. Mian and Dr. Prabin Bariya for providing us with the experimental results used to compare our approach with their methods. We acknowledge the financial support of the Future and Emerging Technology (FET) Programme within the Seventh Framework Programme for Research of the European Commission, under FET-Open project SIMBAD Grant No. 213250.	Aiger D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360684; Akagunduz E, 2009, IEEE IMAGE PROC, P413, DOI 10.1109/ICIP.2009.5414445; Albarelli A., 2011, 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), P252, DOI 10.1109/3DIMPVT.2011.39; Albarelli A., 2009, ICCV 2009; Albarelli A, 2012, INT J COMPUT VISION, V97, P36, DOI 10.1007/s11263-011-0432-4; Albarelli A, 2010, PROC CVPR IEEE, P430, DOI 10.1109/CVPR.2010.5540183; Albarelli A, 2010, LECT NOTES COMPUT SC, V6315, P519, DOI 10.1007/978-3-642-15555-0_38; Bariya P, 2010, PROC CVPR IEEE, P1657, DOI 10.1109/CVPR.2010.5539774; Borrmann D, 2008, ROBOT AUTON SYST, V56, P130, DOI 10.1016/j.robot.2007.07.002; Bul`o S. R., 2009, ADV NEURAL INFORM PR, P1571; Bulo SR, 2011, GAME ECON BEHAV, V71, P193, DOI 10.1016/j.geb.2010.06.004; Chen CS, 1999, IEEE T PATTERN ANAL, V21, P1229, DOI 10.1109/34.809117; Chen H, 2007, PATTERN RECOGN LETT, V28, P1252, DOI 10.1016/j.patrec.2007.02.009; Chua CS, 1997, INT J COMPUT VISION, V25, P63, DOI 10.1023/A:1007981719186; Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221; Frome A, 2004, LECT NOTES COMPUT SC, V3023, P224; Ghosh D, 2010, COMPUT GRAPH FORUM, V29, P1681, DOI 10.1111/j.1467-8659.2010.01777.x; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mian A, 2010, INT J COMPUT VISION, V89, P348, DOI 10.1007/s11263-009-0296-z; Mian AS, 2006, IEEE T PATTERN ANAL, V28, P1584, DOI 10.1109/TPAMI.2006.213; Morgenstern O., 1953, THEORY GAMES EC BEHA; NEWMAN TS, 1995, PATTERN RECOGN, V28, P1555, DOI 10.1016/0031-3203(95)00028-X; Novatnack J, 2008, LECT NOTES COMPUT SC, V5304, P440, DOI 10.1007/978-3-540-88690-7_33; Pelillo M, 2006, NEURAL COMPUT, V18, P1215, DOI 10.1162/neco.2006.18.5.1215; Pottmann H, 2009, COMPUT AIDED GEOM D, V26, P37, DOI 10.1016/j.cagd.2008.01.002; Salti S., 2011, 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), P236, DOI 10.1109/3DIMPVT.2011.37; Shashua A, 2006, LECT NOTES COMPUT SC, V3954, P595; Sun YY, 2003, IEEE T SYST MAN CY B, V33, P712, DOI 10.1109/TSMCB.2003.814295; Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1_26; Weibull J.W., 1997, EVOLUTIONARY GAME TH; Yang-Keun Ahn, 2009, WSEAS Transactions on Information Science and Applications, V6, P1433	34	67	67	0	39	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2013	102	1-3					129	145		10.1007/s11263-012-0568-x	http://dx.doi.org/10.1007/s11263-012-0568-x			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	097VO		Green Submitted			2022-12-18	WOS:000315501800009
J	Mittal, A; Davis, LS				Mittal, Anurag; Davis, Larry S.			A general method for sensor planning in multi-sensor systems: Extension to random occlusion	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						sensor planning; surveillance; camera networks; camera placement; multi-camera vision	SENSING STRATEGIES; OBJECTS; ERROR	Systems utilizing multiple sensors are required in many domains. In this paper, we specifically concern ourselves with applications where dynamic objects appear randomly and the system is employed to obtain some user-specified characteristics of such objects. For such systems, we deal with the tasks of determining measures for evaluating their performance and of determining good sensor configurations that would maximize such measures for better system performance. We introduce a constraint in sensor planning that has not been addressed earlier: visibility in the presence of random occluding objects. occlusion causes random loss of object capture from certain necessitates the use of other sensors that have visibility of this object. Two techniques are developed to analyze such visibility constraints: a probabilistic approach to determine "average" visibility rates and a deterministic approach to address worst-case scenarios. Apart from this constraint, other important constraints to be considered include image resolution, field of view, capture orientation, and algorithmic constraints such as stereo matching and background appearance. Integration of such constraints is performed via the development of a probabilistic framework that allows one to reason about different occlusion events and integrates different multi-view capture and visibility constraints in a natural way. Integration of the thus obtained capture quality measure across the region of interest yields a measure for the effectiveness of a sensor configuration and maximization of such measure yields sensor configurations that are best suited for a given scenario. The approach can be customized for use in many multi-sensor applications and our contribution is especially significant for those that involve randomly occurring objects capable of occluding each other. These include security systems for surveillance in public places, industrial automation and traffic monitoring. Several examples illustrate such versatility by application of our approach to a diverse set of different and sometimes multiple system objectives.	[Mittal, Anurag] Indian Inst Technol, Dept Comp Sci & Engn, Madras 600036, Tamil Nadu, India; [Davis, Larry S.] Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA	Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Madras; University System of Maryland; University of Maryland College Park	Mittal, A (corresponding author), Indian Inst Technol, Dept Comp Sci & Engn, Madras 600036, Tamil Nadu, India.	amittal@cse.iitm.emet.in; lsd@cs.umd.edu						Abrams S, 1999, INT J ROBOT RES, V18, P267, DOI 10.1177/02783649922066204; Aggarwal A., 1984, THESIS JOHNS HOPKINS; ANDERSON D, 1982, COMPUT GRAPH-UK, V9, P407; ARMSTRONG P, 2000, EUR C COMP VIS DUBL, V2, P182; BLOSTEIN SD, 1987, IEEE T PATTERN ANAL, V9, P752, DOI 10.1109/TPAMI.1987.4767982; Cai Q, 1999, IEEE T PATTERN ANAL, V21, P1241, DOI 10.1109/34.809119; CAMERON A, 1990, INT J ROBOT RES, V9, P70, DOI 10.1177/027836499000900505; CHIN WP, 1988, INFORM PROCESS LETT, V28, P39, DOI 10.1016/0020-0190(88)90141-X; CHVATAL V, 1975, J COMB THEORY B, V18, P39, DOI 10.1016/0095-8956(75)90061-1; Collins RT, 2001, P IEEE, V89, P1456, DOI 10.1109/5.959341; Cook DJ, 1996, IEEE T PATTERN ANAL, V18, P1013, DOI 10.1109/34.541410; COWAN CK, 1988, IEEE T PATTERN ANAL, V10, P407, DOI 10.1109/34.3905; COWAN CK, 1989, PROCEEDINGS - 1989 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOL 1-3, P509, DOI 10.1109/ROBOT.1989.100037; COWAN CK, 1988, INT C ROB AUT, P900; Culberson J. C., 1988, 29th Annual Symposium on Foundations of Computer Science (IEEE Cat. No.88CH2652-6), P601, DOI 10.1109/SFCS.1988.21976; Danner T., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P971, DOI 10.1109/ROBOT.2000.844726; Darrell T, 1998, PROC CVPR IEEE, P601, DOI 10.1109/CVPR.1998.698667; Darrell T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P628, DOI 10.1109/ICCV.2001.937685; Deinzer F, 2003, LECT NOTES COMPUT SC, V2756, P65; Duda R.O., 2001, PATTERN CLASSIFICATI, V20; Durand B, 1999, NONL PHEN COMPL SYST, V3, P1; DURAND F, 1997, 9 CAN C COMP GEOM; EDELSBRUNNER H, 1984, CVGIP, P167; Elgammal AM, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P145, DOI 10.1109/ICCV.2001.937617; Georgis N, 1998, IEEE T PATTERN ANAL, V20, P366, DOI 10.1109/34.677262; GHOSH S, 1987, CAN INF PROC SOC C; GIGUS Z, 1990, IEEE T PATTERN ANAL, V12, P113, DOI 10.1109/34.44399; GIGUS Z, 1991, IEEE T PATTERN ANAL, V13, P542, DOI 10.1109/34.87341; Gonzalez-Banos H. H., 1998, Robotics Research. Eighth International Symposium, P95; Gonzalez-Banos HH, 1998, AAAI FALL S; GONZALEZBANOS H, 2001, SCG; Greiffenhagen M, 2000, PROC CVPR IEEE, P335, DOI 10.1109/CVPR.2000.854840; GRIMSON W, 1998, IEEE INT C COMP VIS; GRIMSON WEL, 1986, IEEE J ROBOT AUTOM, V2, P196, DOI 10.1109/JRA.1986.1087057; HAGER G, 1991, INT J ROBOT RES, V10, P285, DOI 10.1177/027836499101000401; HUTCHINSON SA, 1989, IEEE T ROBOTIC AUTOM, V5, P765, DOI 10.1109/70.88098; IKEUCHI K, 1991, IEEE T ROBOTIC AUTOM, V7, P771, DOI 10.1109/70.105386; INGBER L, 1989, MATH COMPUT MODEL, V12, P967, DOI 10.1016/0895-7177(89)90202-1; Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594; Isler V, 2004, IEEE T PATTERN ANAL, V26, P667, DOI 10.1109/TPAMI.2004.1273987; KAMGARPARSI B, 1989, IEEE T PATTERN ANAL, V11, P929, DOI 10.1109/34.35496; Kang SB, 2000, PROC CVPR IEEE, P195, DOI 10.1109/CVPR.2000.854780; KAY DC, 1970, ISRAEL J MATH, V8, P39, DOI 10.1007/BF02771549; Kelly P. H, 1995, P ACM C MULT, P201; KETTNAKER V, 1999, ICMCS, V2, P253; Khan S, 2003, IEEE T PATTERN ANAL, V25, P1355, DOI 10.1109/TPAMI.2003.1233912; Khan S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P331, DOI 10.1109/ICCV.2001.937537; KIM HS, 1985, IEEE T ROBOTIC AUTOM, P28; KITAMURA Y, 1990, INT C PATT REC, V1, P771; Kleinrock L, 1975, QUEUING SYSTEMS, V1; Krishnan A, 1996, PROC CVPR IEEE, P379, DOI 10.1109/CVPR.1996.517100; KRUMM J, 2000, VISUAL SURVEILLANCE; KUTULAKOS KN, 1994, INT J COMPUT VISION, V12, P113, DOI 10.1007/BF01421200; LEE DT, 1986, IEEE T INFORM THEORY, V32, P276, DOI 10.1109/TIT.1986.1057165; LEHEL P, 1999, IEEE INT C COMP VIS, V2, P306; LINGAS A, 1982, 9TH P ACM S COMP GEO, P369; MacCormick J, 2000, INT J COMPUT VISION, V39, P57, DOI 10.1023/A:1008122218374; MAGEE M, 1987, WORKSH SPAT REAS MUL, P262; MASEK W, 1978, SOME NP COMPLETE SET; MAVER J, 1993, IEEE T PATTERN ANAL, V15, P417, DOI 10.1109/34.211463; Mittal A, 2003, INT J COMPUT VISION, V51, P189, DOI 10.1023/A:1021849801764; MITTAL A, 2002, EUR C COMP VIS COP D, V1, P18; MITTAL A, 2004, EUR C COMP VIS PRAG, V3, P543; MIURA J, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1106, DOI 10.1109/ICCV.1995.466811; Mulligan J, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P558, DOI 10.1109/ICCV.2001.937675; NAYAR SK, 1997, IEEE INT C COMP VIS; NOVINI A, 1988, OPTICS ILLUMINATION, P1005; O'Rourke J., 1987, ART GALLERY THEOREMS; ORourke J., 1982, 20 ANN ALL C COMM CO, P75; Paragios N, 2001, PROC CVPR IEEE, P1034; Peleg S, 2001, IEEE T PATTERN ANAL, V23, P279, DOI 10.1109/34.910880; PETITJEAN S, 1992, INT J COMPUT VISION, V9, P231, DOI 10.1007/BF00133703; Pito R, 1999, IEEE T PATTERN ANAL, V21, P1016, DOI 10.1109/34.799908; RACZKOWSKY J, 1989, COMPUTER GRAPHICS AP, P16; Reed MK, 2000, IEEE T PATTERN ANAL, V22, P1460, DOI 10.1109/34.895979; RODRIGUEZ JJ, 1990, IEEE T PATTERN ANAL, V12, P467, DOI 10.1109/34.55106; Roy SD, 2004, PATTERN RECOGN, V37, P429, DOI 10.1016/j.patcog.2003.01.002; ROY SD, 2001, ICCV 2001, V2, P276; Sakane S., 1992, Advanced Robotics, V6, P461, DOI 10.1163/156855392X00295; Sakane S., 1987, Advanced Robotics, V2, P149, DOI 10.1163/156855387X00138; SHANG Y, 1997, THESIS U ILLINOIS UR; SHERMER TC, 1992, P IEEE, V80, P1384, DOI 10.1109/5.163407; Slavik P, 1997, J ALGORITHM, V25, P237, DOI 10.1006/jagm.1997.0887; SPLETZER J, 2001, CVPR; Stamos I, 1998, PROC CVPR IEEE, P489, DOI 10.1109/CVPR.1998.698650; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; Stuerzlinger W, 1999, PROC GRAPH INTERF, P115; Tarabanis K, 1996, IEEE T PATTERN ANAL, V18, P279, DOI 10.1109/34.485556; TARABANIS K, 1991, IEEE COMP SOC C COMP, P152; TARABANIS KA, 1995, IEEE T ROBOTIC AUTOM, V11, P86, DOI 10.1109/70.345940; TARABANIS KA, 1995, IEEE T ROBOTIC AUTOM, V11, P72, DOI 10.1109/70.345939; URRUTIA J, 1997, HDB COMPUTATIONAL GE, P387; WIXSON L, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P800, DOI 10.1109/CVPR.1994.323902; Ye YM, 1999, COMPUT VIS IMAGE UND, V73, P145, DOI 10.1006/cviu.1998.0736; YI SK, 1995, COMPUT VIS IMAGE UND, V61, P122, DOI 10.1006/cviu.1995.1009; Zhao T, 2004, PROC CVPR IEEE, P406; Zhao T, 2003, PROC CVPR IEEE, P459, DOI 10.1109/NSSMIC.2003.1352083; Zhao T, 2001, PROC CVPR IEEE, P194	98	67	68	0	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2008	76	1					31	52		10.1007/s11263-007-0057-9	http://dx.doi.org/10.1007/s11263-007-0057-9			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	248VS					2022-12-18	WOS:000252185800003
J	Davis, JW; Sharma, V				Davis, James W.; Sharma, Vinay			Background-subtraction in thermal imagery using contour saliency	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	3rd Workshop on Object Tracking and Classification Beyond the Visible Spectrum	JUN 22, 2006	New York, NY	IEEE		backcrround subtraction; thermal imagery; infrared; FLIR; contour saliency map; CSM; video surveillance and monitoring; person detection	WATERSHED CONTOURS; GEODESIC SALIENCY; TRACKING	We present a new contour-based background-subtraction technique to extract foreground objects in widely varying thermal imagery. Statistical background-subtraction is first used to identify local regions-of-interest. Within each region, input and background gradient information are combined to form a Contour Saliency Map. After thinning, an A* path-con strained search along watershed boundaries is used to complete and close any broken contour segments. Lastly, the contour image is flood-filled to produce silhouettes. Results of our approach are presented for several difficult thermal sequences and compared to alternate approaches. We quantify the results using manually segmented thermal imagery to demonstrate the robustness of the approach.	Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA	University System of Ohio; Ohio State University	Davis, JW (corresponding author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.	jwdavis@cse.ohio-state.edu; sharmav@cse.ohio-state.edu						BHANU B, 1990, IEEE T AERO ELEC SYS, V26, P2, DOI 10.1109/7.53409; Bhanu B, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P208, DOI 10.1109/ACV.2002.1182183; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Couprie M, 1997, P SOC PHOTO-OPT INS, V3168, P136, DOI 10.1117/12.292778; Cutler R., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P326, DOI 10.1109/CVPR.1999.784652; DANKER AJ, 1981, IEEE T PATTERN ANAL, V3, P79, DOI 10.1109/TPAMI.1981.4767053; DAVIS J, 2005, P WKSHP APPL COMP VI; Davis J., 2004, IEEE INT WKSHP OBJ T; Davis JW, 2004, INT C PATT RECOG, P713, DOI 10.1109/ICPR.2004.1333872; GAVRILA DM, 2000, P EUR C COMP VIS, P37; Haritaoglu I, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P222, DOI 10.1109/AFGR.1998.670952; Harville M, 2002, LECT NOTES COMPUT SC, V2352, P543; Harwood D., 2000, EUR C COMP VIS, P751, DOI DOI 10.1007/3-540-45053-X_48; Hoist G.C., 2000, COMMON SENSE APPROAC; Iwasawa S, 1997, PROC CVPR IEEE, P15, DOI 10.1109/CVPR.1997.609290; Javed O, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P22, DOI 10.1109/MOTION.2002.1182209; KUMMER S, 2003, OE MAGAZINE, V3, P22; Lemarechal C, 1998, IEEE T PATTERN ANAL, V20, P762, DOI 10.1109/34.689307; LIPTON A, 1998, P WKSHP APPL COMP VI; Masoud O, 2001, IEEE T VEH TECHNOL, V50, P1267, DOI 10.1109/25.950328; Mittal A, 2004, PROC CVPR IEEE, P302; Monnet A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1305; Najman L, 1996, IEEE T PATTERN ANAL, V18, P1163, DOI 10.1109/34.546254; NANDA H, 2002, P INT VEH S IEEE; Oren M, 1997, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.1997.609319; PANDYA N, 2004, OE MAGAZINE, V4, P28; Russell SJ, 1995, ARTIF INTELL, V4th; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; TOYAMA K, 1999, P INT C COMP VIS, P49; VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344; Viola P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P734; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236; XU F, 2002, P INT VEH S IEEE; Yilmaz A, 2003, IMAGE VISION COMPUT, V21, P623, DOI 10.1016/S0262-8856(03)00059-3; Zhong J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P44, DOI 10.1109/ICCV.2003.1238312	35	67	74	0	18	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	FEB	2007	71	2					161	181		10.1007/s11263-006-4121-7	http://dx.doi.org/10.1007/s11263-006-4121-7			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	098DN		Green Submitted			2022-12-18	WOS:000241501300004
J	Tankus, A; Sochen, N; Yeshurun, Y				Tankus, A; Sochen, N; Yeshurun, Y			Shape-from-shading under perspective projection	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						perspective shape-from-shading; fast marching methods	IMAGE	Shape-from-Shading (SfS) is a fundamental problem in Computer Vision. A very common assumption in this field is that image projection is orthographic. This paper re-examines the basis of SfS, the image irradiance equation, under a perspective projection assumption. The resultant equation does not depend on the depth function directly, but rather, on its natural logarithm. As such, it is invariant to scale changes of the depth function. A reconstruction method based on the perspective formula is then suggested; it is a modification of the Fast Marching method of Kimmel and Sethian. Following that, a comparison of the orthographic Fast Marching, perspective Fast Marching and the perspective algorithm of Prados and Faugeras on synthetic images is presented. The two perspective methods show better reconstruction results than the orthographic. The algorithm of Prados and Faugeras equates with the perspective Fast Marching. Following that, a comparison of the orthographic and perspective versions of the Fast Marching method on endoscopic images is introduced. The perspective algorithm outperformed the orthographic one. These findings suggest that the more realistic set of assumptions of perspective SfS improves reconstruction significantly with respect to orthographic SfS. The findings also provide evidence that perspective SfS can be used for real-life applications in fields such as endoscopy.	Tel Aviv Univ, Sch Comp Sci, IL-69978 Tel Aviv, Israel; Tel Aviv Univ, Sch Math, IL-69978 Tel Aviv, Israel	Tel Aviv University; Tel Aviv University	Tankus, A (corresponding author), Tel Aviv Univ, Sch Comp Sci, IL-69978 Tel Aviv, Israel.	arielt@post.tau.ac.il; sochen@post.tau.ac.il; hezy@post.tau.ac.il						Bichsel M., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P459, DOI 10.1109/CVPR.1992.223150; BROOKS MJ, 1994, INT C PATT RECOG, P114, DOI 10.1109/ICPR.1994.576240; Horn B., 1986, ROBOT VISION, P1; HORN B, 1975, COMPUTER SCI SERIES, P115; Horn B.K.P., 1989, SHAPE SHADING; HORN BKP, 1977, ARTIF INTELL, V8, P201, DOI 10.1016/0004-3702(77)90020-0; ISHII H, 1987, P AM MATH SOC, V100, P247, DOI 10.2307/2045953; Kimmel R, 2001, J MATH IMAGING VIS, V14, P237, DOI 10.1023/A:1011234012449; KIMMEL R, 1995, COMPUT VIS IMAGE UND, V62, P360, DOI 10.1006/cviu.1995.1060; LEE CH, 1985, ARTIF INTELL, V26, P125, DOI 10.1016/0004-3702(85)90026-8; Lee KM, 1997, COMPUT VIS IMAGE UND, V67, P143, DOI 10.1006/cviu.1997.0522; LEE KM, 1993, IEEE T PATTERN ANAL, V15, P815, DOI 10.1109/34.236247; Levin D, 2004, MATH VISUAL, P37; LIONS PL, 1982, GENERALIZED SOLUTION; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; PENNA MA, 1989, IEEE T PATTERN ANAL, V11, P545, DOI 10.1109/34.24790; PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P170, DOI 10.1109/TPAMI.1984.4767501; Prados E, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P826; PRADOS E, 2002, 7 EUR C COMP VIS, V2, P790; ROBLESKELLY A, 2002, 2 INT WORKSH ART MOT, P43; ROUY E, 1992, SIAM J NUMER ANAL, V29, P867, DOI 10.1137/0729053; SAMARAS D, 2003, IEEE T PATT AN MACH; SEONG I, 1997, IEEE COMP SOC C COMP, P413; Sethian J.A., 1999, LEVEL SET METHODS FA, V2nd; Sethian JA, 1996, P NATL ACAD SCI USA, V93, P1591, DOI 10.1073/pnas.93.4.1591; Shiu Yin Yuen, 2002, Proceedings of Second IASTED International Conference Visualization, Imaging, and Image Processing, P584; Tankus A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P862; TANKUS A, 2004, THESIS TEL AVIV U; TSAI PS, 1994, IMAGE VISION COMPUT, V12, P487, DOI 10.1016/0262-8856(94)90002-7; Weiss I., 1997, P DARPA IMAGE UNDERS, V2, P1393; Yamany SM, 1999, LECT NOTES COMPUT SC, V1679, P778; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284; ZHAO WY, 2000, P IEEE C COMP VIS PA, V1, P286; ZHENG QF, 1991, IEEE T PATTERN ANAL, V13, P680, DOI 10.1109/34.85658	34	67	71	0	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2005	63	1					21	43		10.1007/s11263-005-4945-6	http://dx.doi.org/10.1007/s11263-005-4945-6			23	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	907WS					2022-12-18	WOS:000227749400002
J	LOWE, DG				LOWE, DG			ORGANIZATION OF SMOOTH IMAGE CURVES AT MULTIPLE SCALES	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article									UNIV BRITISH COLUMBIA,DEPT COMP SCI,VANCOUVER V6T 1W5,BC,CANADA	University of British Columbia								[Anonymous], 1985, PERCEPTUAL ORG VISUA; ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; BALLARD DH, 1981, COMMUN ACM, V24, P310, DOI 10.1145/358645.358661; BINFORD TO, 1981, ARTIF INTELL, V17, P205, DOI 10.1016/0004-3702(81)90025-4; BOLLES RC, 1983, 8TH P INT JOINT C AR, P1116; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; HORN BKP, 1986, IEEE T PATTERN ANAL, V8, P665, DOI 10.1109/TPAMI.1986.4767839; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; LOWE DG, 1983, 3RD P NAT C ART INT, P225; MACKWORTH AK, 1984, 5TH P CAN SOC COMP S, P114; MACKWORTH AK, 1988, JUN P IEEE C COMP VI; MARIMONT DH, 1984, 4TH P NAT C ART INT, P237; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750; PARENT P, 1985, CIM863 MCGILL U COMP; Pavlidis T., 1977, STRUCTURAL PATTERN R; PRIDMORE AP, 1987, IMAGE VISION COMPUT, V5, P132, DOI 10.1016/0262-8856(87)90040-0; ROBERTS LG, 1966, OPTICAL ELECTRO OPTI, P159; SHIRAI Y, 1985, P INT JOINT C ARTIF, V75, P674; Tenenbaum Jay M, 1983, HUMAN MACHINE VISION, P481; Witkin AP, 1983, 8 INT JOINT C ART IN, P1019; Zucker S. W., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P568, DOI 10.1109/CCV.1988.590037	22	67	74	0	2	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	1989	3	2					119	130		10.1007/BF00126428	http://dx.doi.org/10.1007/BF00126428			12	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AH264					2022-12-18	WOS:A1989AH26400002
J	Rohrbach, A; Torabi, A; Rohrbach, M; Tandon, N; Pal, C; Larochelle, H; Courville, A; Schiele, B				Rohrbach, Anna; Torabi, Atousa; Rohrbach, Marcus; Tandon, Niket; Pal, Christopher; Larochelle, Hugo; Courville, Aaron; Schiele, Bernt			Movie Description	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Movie description; Video description; Video captioning; Video understanding; Movie description dataset; Movie description challenge; Long short-term; memory network; Audio description; LSMDC		Audio description (AD) provides linguistic descriptions of movies and allows visually impaired people to follow a movie along with their peers. Such descriptions are by design mainly visual and thus naturally form an interesting data source for computer vision and computational linguistics. In this work we propose a novel dataset which contains transcribed ADs, which are temporally aligned to full length movies. In addition we also collected and aligned movie scripts used in prior work and compare the two sources of descriptions. We introduce the Large Scale Movie Description Challenge (LSMDC) which contains a parallel corpus of 128,118 sentences aligned to video clips from 200 movies (around 150 h of video in total). The goal of the challenge is to automatically generate descriptions for the movie clips. First we characterize the dataset by benchmarking different approaches for generating video descriptions. Comparing ADs to scripts, we find that ADs are more visual and describe precisely what is shown rather than what should happen according to the scripts created prior to movie production. Furthermore, we present and compare the results of several teams who participated in the challenges organized in the context of two workshops at ICCV 2015 and ECCV 2016.	[Rohrbach, Anna; Tandon, Niket; Schiele, Bernt] Max Planck Inst Informat, Saarland Informat Campus, Saarbrucken, Germany; [Rohrbach, Marcus] Univ Calif Berkeley, ICSI, Berkeley, CA USA; [Rohrbach, Marcus] Univ Calif Berkeley, EECS, Berkeley, CA USA; [Torabi, Atousa] Disney Res, Pittsburgh, PA USA; [Pal, Christopher] Ecole Polytech Montreal, Montreal, PQ, Canada; [Larochelle, Hugo] Univ Sherbrooke, Sherbrooke, PQ, Canada; [Courville, Aaron] Univ Montreal, Montreal, PQ, Canada	Max Planck Society; University of California System; University of California Berkeley; University of California System; University of California Berkeley; Universite de Montreal; Polytechnique Montreal; University of Sherbrooke; Universite de Montreal	Rohrbach, A (corresponding author), Max Planck Inst Informat, Saarland Informat Campus, Saarbrucken, Germany.	arohrbach@mpi-inf.mpg.de			Max Planck Society; German Academic Exchange Service (DAAD)	Max Planck Society(Max Planck SocietyFoundation CELLEX); German Academic Exchange Service (DAAD)(Deutscher Akademischer Austausch Dienst (DAAD))	Open access funding provided by Max Planck Society. Marcus Rohrbach was supported by a fellowship within the FITweltweit-Program of the German Academic Exchange Service (DAAD).	Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Baker C. F., 1998, P ANN M ASS COMP LIN; Ballas Nicolas, 2016, ICLR; Barbu A., 2012, P C UNC ART INT UAI; Bojanowski P., 2013, INT C COMP VIS ICCV; Bojanowski P., 2014, EUR C COMP VIS ECCV; Bruni M., 2016, P ACM MULT C MM, P645; Chen David, 2011, P 49 ANN M ASS COMP, P190; Chen X, 2015, CORR, V1504, P325; Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856; Cour T., 2009, C COMP VIS PATT REC; Cour T., 2008, EUR C COMP VIS ECCV; Das D., 2012, P ANN M ASS COMP LIN; Das P., 2013, C COMP VIS PATT REC; de Melo G., 2016, SIGWEB NEWSLETTER, DOI [10.1145/2903513.2903517, DOI 10.1145/2903513.2903517]; Del Corro L., 2013, P INT WORLD WID WEB; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Denkowski Michael, 2014, P 9 WORKSH STAT MACH, P376, DOI DOI 10.3115/V1/W14-3348; Devlin J., 2015, P ANN M ASS COMP LIN; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Duchenne O., 2009, INT C COMP VIS ICCV; Elliott Desmond, 2013, P 2013 C EMP METH NA, P1292; Everingham M., 2006, P BRIT MACH VIS C BM; Fang H., 2015, C COMP VIS PATT REC; Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2; Fellbaum Christiane, 1998, WORDNET ELECT DATABA; Gagnon L., 2010, P IEEE C COMP VIS PA; Guadarrama S., 2013, INT C COMP VIS ICCV; Hendricks L. A., 2016, C COMP VIS PATT REC; Hinton GE, 2012, IMPROVING NEURAL NET, DOI DOI 10.9774/GLEAF.978-1-909493-38-4_2; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hoffman J., 2014, C NEUR INF PROC SYST; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Kipper K., 2006, P INT C LANG RES EV; Kiros R., 2015, T ASS COMPUT LINGUIS; Kiros R., 2014, INT C MACH LEARN ICM; Klein B., 2015, C COMP VIS PATT REC; Koehn P, 2007, 45 ANN M ASS COMP LI, P177, DOI DOI 10.3115/1557769.1557821; Kojima A, 2002, INT J COMPUT VISION, V50, P171, DOI 10.1023/A:1020346032608; Krizhevsky A., 2012, C NEUR INF PROC SYT; Kulkarni G., 2011, C COMP VIS PATT REC; Kuznetsova P., 2012, P ANN M ASS COMP LIN; Kuznetsova P., 2014, P T ASS COMP LING TA; Lakritz J., 2006, TECHNICAL REPORT; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Lev G., 2015, EUR C COMP VIS ECCV; Li G., 2015, P 23 ANN ACM C MULT; Li S., 2011, P 15 C COMPUTATIONAL, P220; Li YC, 2016, PROC CVPR IEEE, P4641, DOI 10.1109/CVPR.2016.502; Liang C, 2011, PROC CVPR IEEE; Lin Chin-Yew, 2004, TEXT SUMMARIZATION B, P74, DOI DOI 10.2307/3105454; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Mao J., 2015, INT C LEARN REPRESEN; Marszalek M., 2009, C COMP VIS PATT REC; Mitchell M., 2012, P C EUR CHAP ASS COM; Ordonez V., 2011, C NEUR INF PROC SYST; Over P., 2012, P TRECVID 2012; Pan P., 2016, C COMP VIS PATT REC; Pan Y., 2016, C COMP VIS PATT REC; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Ramanathan V., 2014, EUR C COMP VIS ECCV; Regneri M., 2013, TACL, V1, P25, DOI DOI 10.1162/TACL_A_00207; Rohrbach A., 2014, P GERM C PATT REC GC; Rohrbach A., 2015, P GERM C PATT REC GC; Rohrbach A., 2015, ARXIV150601698; Rohrbach A., 2015, C COMP VIS PATT REC; Rohrbach M., 2013, INT C COMP VIS ICCV; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Salway A., 2007, P ACM INT C IM VID R; Salway Andrew, 2007, MEDIA ALL SUBTITLING, P151, DOI DOI 10.1163/9789401209564_012; Schuler K. K., 2009, P C N AM CHAPT ASS C; Shetty R., 2015, ARXIV151202949; Shetty R., 2016, P 2016 ACM MULT C, P1073, DOI DOI 10.1145/2964284.2984062; Sivic Josef, 2009, C COMP VIS PATT REC; Socher R., 2014, J T ASS COMPUT LINGU, V2, P207, DOI DOI 10.1162/TACL_A_00177; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Tandon N., 2015, P 24 ACM INT C INF K, P223; Tapaswi M, 2016, PROC CVPR IEEE, P4631, DOI 10.1109/CVPR.2016.501; Tapaswi Makarand, 2012, C COMP VIS PATT REC; Thomason J., 2014, P INT C COMP LING CO; Torabi A., 2015, ARXIV150301070V1; Torabi Atousa, 2016, ARXIV160908124; Toutanova K., 2003, NAACL 03; VEDANTAM R, 2015, PROC CVPR IEEE, P4566, DOI DOI 10.1109/CVPR.2015.7299087; Venugopalan, 2016, ARXIV160401729; Venugopalan S., 2015, ARXIV150500487V2; Venugopalan S., 2015, INT C COMP VIS ICCV; Venugopalan S., 2015, P C N AM CHAP ASS CO; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Xiao Jianxiong, 2010, C COMP VIS PATT REC; Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Xu R., 2015, C ART INT AAAI; Yao L., 2015, INT C COMP VIS ICCV; Yao L., 2016, INT C LEARN REPR ICL; Young P., 2014, P TACL, V2, P67, DOI 10.1162/tacl_a_00166; Yu H., 2016, C COMP VIS PATT REC; Yu Youngjae, 2016, ARXIV PREPRINT ARXIV, V6; Zeng Kuo-Hao, 2016, EUR C COMP VIS; Zhong Z., 2010, ACL; Zhou Bolei, 2014, ADV NEURAL INFORM PR, P7, DOI DOI 10.5555/2968826.2968881; Zhu L., 2015, ARXIV151104670; Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11	106	66	68	6	25	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2017	123	1			SI		94	120		10.1007/s11263-016-0987-1	http://dx.doi.org/10.1007/s11263-016-0987-1			27	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	ET4SY		Green Accepted, Green Published			2022-12-18	WOS:000400276400005
J	Marin-Jimenez, MJ; Zisserman, A; Eichner, M; Ferrari, V				Marin-Jimenez, M. J.; Zisserman, A.; Eichner, M.; Ferrari, V.			Detecting People Looking at Each Other in Videos	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Person interactions; Video search; Action recognition; Head pose estimation	POSE ESTIMATION; HEAD POSE	The objective of this work is to determine if people are interacting in TV video by detecting whether they are looking at each other or not. We determine both the temporal period of the interaction and also spatially localize the relevant people. We make the following four contributions: (i) head detection with implicit coarse pose information (front, profile, back); (ii) continuous head pose estimation in unconstrained scenarios (TV video) using Gaussian process regression; (iii) propose and evaluate several methods for assessing whether and when pairs of people are looking at each other in a video shot; and (iv) introduce new ground truth annotation for this task, extending the TV human interactions dataset (Patron-Perez et al. 2010) The performance of the methods is evaluated on this dataset, which consists of 300 video clips extracted from TV shows. Despite the variety and difficulty of this video material, our best method obtains an average precision of 87.6 % in a fully automatic manner.	[Marin-Jimenez, M. J.] Univ Cordoba, Maimonides Inst Biomed Res IMIBIC, Dept Comp & Numer Anal, Cordoba, Spain; [Zisserman, A.] Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England; [Eichner, M.] ETH, Zurich, Switzerland; [Ferrari, V.] Univ Edinburgh, Sch Informat, Edinburgh, Midlothian, Scotland	Universidad de Cordoba; University of Oxford; Swiss Federal Institutes of Technology Domain; ETH Zurich; University of Edinburgh	Marin-Jimenez, MJ (corresponding author), Univ Cordoba, Maimonides Inst Biomed Res IMIBIC, Dept Comp & Numer Anal, Cordoba, Spain.	mjmarin@uco.es; az@robots.ox.ac.uk; marcin.eichner@vision.ee.ethz.ch; vferrari@staffmail.ed.ac.uk	Marin-Jimenez, Manuel J./AAS-9152-2020	Marin-Jimenez, Manuel J./0000-0001-9294-6714	Swiss National Science Foundation; ERC Grant VisRec [228180];  [TIN2012-32952]	Swiss National Science Foundation(Swiss National Science Foundation (SNSF)European Commission); ERC Grant VisRec; 	We are grateful to the Spanish Minister (projects TIN2012-32952 and BROCA) and for financial support from the Swiss National Science Foundation and ERC Grant VisRec No. 228180. We also thank the reviewers for their helpful comments.	ANDRILUKA M, 2009, P IEEE C COMP VIS PA; [Anonymous], 2010, DEF PARTS MOD COD; [Anonymous], 2011, LAEO ANN; [Anonymous], 2008, P IEEE C COMP VIS PA; [Anonymous], 2011, LAEO PROJ; [Anonymous], 2011, GPML MATL COD; [Anonymous], 2005, INRIA PERSON DATASET; Ba S., 2005, P IEEE INT C MULT EX; Ba SO, 2009, IEEE T SYST MAN CY B, V39, P16, DOI 10.1109/TSMCB.2008.927274; Benfold B., 2008, P BRIT MACH VIS C; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Bourdev L., 2010, P EUR C COMP VIS; Cour T., 2009, P IEEE C COMP VIS PA; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3; Everingham M., 2005, P INT C COMP VIS; Everingham M, 2006, P BRIT MACHINE VISIO, V4, P6; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fathi A., 2012, P IEEE C COMP VIS PA; Ferrari V., 2001, P IEEE C COMP VIS PA; Ferrari V., 2009, P IEEE C COMP VIS PA; Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468; Jones M., 2003, TR200325 MITS EL RES; Kim WH, 2009, I SYMP CONSUM ELECTR, P961; Klaser A., 2012, P EUR C COMP VIS, V6553, P219; Liu J., 2009, P IEEE C COMP VIS PA; Lovegrove S, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.93; Marin-Jimenez M., 2012, PATTERN ANAL APPL; Marin-Jimenez MJ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.22; Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106; Osadchy M, 2007, J MACH LEARN RES, V8, P1197; PARK S, 2004, ASS COMPUTING MACHIN; Patron-Perez A, 2012, IEEE T PATTERN ANAL, V34, P2441, DOI 10.1109/TPAMI.2012.24; Raptis M., 2012, P IEEE C COMP VIS PA; Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1; Sadanand S., 2012, P IEEE C COMP VIS PA; Sapp B., 2010, P EUR C COMP VIS; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154; Sivic J., 2009, P IEEE C COMP VIS PA; Sivic J, 2005, P ACM INT C IM VID R; Tang SY, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.9; Waltisberg W., 2010, P INT C PATT REC ICP; Yang Y., 2012, P IEEE C COMP VIS PA; Z Tu, 2005, P INT C COMP VIS; Zhu X., 2012, P IEEE C COMP VIS PA	47	66	66	0	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	FEB	2014	106	3			SI		282	296		10.1007/s11263-013-0655-7	http://dx.doi.org/10.1007/s11263-013-0655-7			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AA3DC		Green Submitted, Green Accepted			2022-12-18	WOS:000330972100005
J	Raviv, D; Bronstein, AM; Bronstein, MM; Kimmel, R				Raviv, Dan; Bronstein, Alexander M.; Bronstein, Michael M.; Kimmel, Ron			Full and Partial Symmetries of Non-rigid Shapes	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Symmetry; Intrinsic; Self-similarity; Non-rigid; Partiality	RECOGNITION; SIMILARITY; PERCEPTION; FRAMEWORK; OBJECTS	Symmetry and self-similarity are the cornerstone of Nature, exhibiting themselves through the shapes of natural creations and ubiquitous laws of physics. Since many natural objects are symmetric, the absence of symmetry can often be an indication of some anomaly or abnormal behavior. Therefore, detection of asymmetries is important in numerous practical applications, including crystallography, medical imaging, and face recognition, to mention a few. Conversely, the assumption of underlying shape symmetry can facilitate solutions to many problems in shape reconstruction and analysis. Traditionally, symmetries are described as extrinsic geometric properties of the shape. While being adequate for rigid shapes, such a description is inappropriate for non-rigid ones: extrinsic symmetry can be broken as a result of shape deformations, while its intrinsic symmetry is preserved. In this paper, we present a generalization of symmetries for non-rigid shapes and a numerical framework for their analysis, addressing the problems of full and partial exact and approximate symmetry detection and classification.	[Raviv, Dan; Bronstein, Alexander M.; Bronstein, Michael M.; Kimmel, Ron] Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Technion Israel Institute of Technology	Raviv, D (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	darav@cs.technion.ac.il; bron@cs.technion.ac.il; mbron@cs.technion.ac.il; ron@cs.technion.ac.il	Bronstein, Michael/G-5415-2010; Raviv, Dan/AAZ-2851-2020	Bronstein, Michael/0000-0002-1262-7252; 	Israel Science Foundation [ISF 623/08]; United States-Israel Bi-national Science Foundation [BSF 2004274]; USA Office of Naval Research (ONR); New York metropolitan research fund	Israel Science Foundation(Israel Science Foundation); United States-Israel Bi-national Science Foundation(US-Israel Binational Science Foundation); USA Office of Naval Research (ONR)(Office of Naval Research); New York metropolitan research fund	This research was supported in part by the Israel Science Foundation (grant no. ISF 623/08), by The United States-Israel Bi-national Science Foundation (grant no. BSF 2004274), the USA Office of Naval Research (ONR), and by the New York metropolitan research fund.	ALT H, 1988, DISCRETE COMPUT GEOM, V3, P237, DOI 10.1007/BF02187910; ANGUELOV D, 2005, P NIPS; ATALLAH MJ, 1985, IEEE T COMPUTERS C, V34; Borg I., 1997, MODERN MULTIDIMENSIO; Bronstein AM, 2008, INT J COMPUT VISION, V78, P67, DOI 10.1007/s11263-007-0078-4; Bronstein AM, 2009, INT J COMPUT VISION, V84, P163, DOI 10.1007/s11263-008-0147-3; Bronstein AM, 2006, P NATL ACAD SCI USA, V103, P1168, DOI 10.1073/pnas.0508601103; BRONSTEIN AM, 2008, P NONR SHAP AN DEF I; BRONSTEIN AM, 2009, INT J COMPU IN PRESS; BRONSTEIN AM, 2007, P INT C COMP VIS ICC; CHEUNG KT, 1998, P INT C PATT REC ICP, V2, P1473; Coifman RR, 2006, APPL COMPUT HARMON A, V21, P5, DOI 10.1016/j.acha.2006.04.006; Cornelius H, 2006, INT C PATT RECOG, P292; DENATALE FGB, 1997, P INT C DIG SIGN PRO, V2, P521; Derrode S, 2004, SIGNAL PROCESS, V84, P25, DOI 10.1016/j.sigpro.2003.07.006; Elad A, 2003, IEEE T PATTERN ANAL, V25, P1285, DOI 10.1109/TPAMI.2003.1233902; Gal R, 2007, IEEE T VIS COMPUT GR, V13, P261, DOI 10.1109/TVCG.2007.45; Gelfand N., 2005, P 3 EUR S GEOM PROC, V2, P5; HAMZA AB, 2005, P IEEE INT C IM PROC, V1, P1041; Haraguchi S, 2002, ANGLE ORTHOD, V72, P28; HOCHBAUM DS, 1985, MATH OPER RES, V10, P180, DOI 10.1287/moor.10.2.180; Huisinga-Fischer CE, 2004, J CRANIOFAC SURG, V15, P128, DOI 10.1097/00001665-200401000-00033; Kazhdan M, 2004, ALGORITHMICA, V38, P201, DOI 10.1007/s00453-003-1050-5; Kepler J., 1611, STRENA SEU NIVE SEXA; Kimmel R, 1998, P NATL ACAD SCI USA, V95, P8431, DOI 10.1073/pnas.95.15.8431; Kiryati N., 1996, P INT C PATT REC ICP, VI, P951; Lasowski R, 2009, P INT C COMP VIS ICC; Levy B, 2006, INT C SHAP MOD APPL; Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41; Liu R, 2009, COMPUT GRAPH FORUM, V28, P397, DOI 10.1111/j.1467-8659.2009.01379.x; Liu YX, 2004, IEEE T PATTERN ANAL, V26, P354, DOI 10.1109/TPAMI.2004.1262332; Loy G, 2006, LECT NOTES COMPUT SC, V3952, P508; Mahmoudi M, 2009, GRAPH MODELS, V71, P22, DOI 10.1016/j.gmod.2008.10.002; Mancas M, 2005, INT CONF ACOUST SPEE, P725; MAROLA G, 1989, IEEE T PATTERN ANAL, V11, P104, DOI 10.1109/34.23119; MATEUS D, 2008, P COMP VIS PATT REC; Mealey L, 1999, J PERS SOC PSYCHOL, V76, P151, DOI 10.1037/0022-3514.76.1.151; Memoli F, 2005, FOUND COMPUT MATH, V5, P313, DOI 10.1007/s10208-004-0145-y; Memoli F., 2008, P NONR SHAP AN DEF I; Mitra NJ, 2006, ACM T GRAPHIC, V25, P560, DOI 10.1145/1141911.1141924; Moenning C, 2003, P INT C VIS IM IM PR; MUMFORD D, 1990, P INT C COMP VIS ICC; Ovsjanikov M, 2008, P EUR S GEOM PROC SG, V27; Peyre G, 2006, INT J COMPUT VISION, V69, P145, DOI 10.1007/s11263-006-6859-3; Pinkall U., 1993, EXPT MATH, V2, P15, DOI DOI 10.1080/10586458.1993.10504266; Raviv D, 2007, P NONR REG TRACK NRT; REISFELD D, 1992, P INT C PATT REC HAG, V1, P117; Reuter M, 2006, COMPUT AIDED DESIGN, V38, P342, DOI 10.1016/j.cad.2005.10.011; Riklin-Raviv T, 2009, IEEE T PATTERN ANAL, V31, P1458, DOI 10.1109/TPAMI.2008.160; Rustamov Raif M, 2007, P 5 EUR S GEOM PROC, P225, DOI DOI 10.2312/SGP/SGP07/225-233; Shimshoni I, 2000, INT J COMPUT VISION, V39, P97, DOI 10.1023/A:1008118909580; Sun CM, 1997, IEEE T PATTERN ANAL, V19, P164, DOI 10.1109/34.574800; Weyl H., 1983, SYMMETRY; Wolter J., 1985, VISUAL COMPUT, V1, P37; Xu K, 2009, P SIGGRAPH AS; Yang XW, 2008, LECT NOTES COMPUT SC, V5359, P561, DOI 10.1007/978-3-540-89646-3_55; ZABRODSKY H, 1995, IEEE T PATTERN ANAL, V17, P1154, DOI 10.1109/34.476508	57	66	70	1	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2010	89	1					18	39		10.1007/s11263-010-0320-3	http://dx.doi.org/10.1007/s11263-010-0320-3			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	584RF					2022-12-18	WOS:000276769500002
J	Hernandez, M; Bossa, MN; Olmos, S				Hernandez, Monica; Bossa, Matias N.; Olmos, Salvador			Registration of Anatomical Images Using Paths of Diffeomorphisms Parameterized with Stationary Vector Field Flows	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Computational Anatomy; LDDMM; Efficient; Diffeomorphic registration; Infinite dimensional; Riemannian manifold; Stationary parameterization	DEFORMATION; STATISTICS; DEMENTIA; SHAPE	Computational Anatomy aims for the study of variability in anatomical structures from images. Variability is encoded by the spatial transformations existing between anatomical images and a template selected as reference. In the absence of a more justified model for inter-subject variability, transformations are considered to belong to a convenient family of diffeomorphisms which provides a suitable mathematical setting for the analysis of anatomical variability. One of the proposed paradigms for diffeomorphic registration is the Large Deformation Diffeomorphic Metric Mapping (LDDMM). In this framework, transformations are characterized as end points of paths parameterized by time-varying flows of vector fields defined on the tangent space of a Riemannian manifold of diffeomorphisms and computed from the solution of the non-stationary transport equation associated to these flows. With this characterization, optimization in LDDMM is performed on the space of non-stationary vector field flows resulting into a time and memory consuming algorithm. Recently, an alternative characterization of paths of diffeomorphisms based on constant-time flows of vector fields has been proposed in the literature. With this parameterization, diffeomorphisms constitute solutions of stationary ODEs. In this article, the stationary parameterization is included for diffeomorphic registration in the LDDMM framework. We formulate the variational problem related to this registration scenario and derive the associated Euler-Lagrange equations. Moreover, the performance of the non-stationary vs the stationary parameterizations in real and simulated 3D-MRI brain datasets is evaluated. Compared to the non-stationary parameterization, our proposal provides similar results in terms of image matching and local differences between the diffeomorphic transformations while drastically reducing memory and time requirements.	[Hernandez, Monica] Univ Zaragoza, Dept Comp Sci & Syst, GTC, Aragon Inst Engn Res 13A, E-50009 Zaragoza, Spain	University of Zaragoza	Hernandez, M (corresponding author), Univ Zaragoza, Dept Comp Sci & Syst, GTC, Aragon Inst Engn Res 13A, E-50009 Zaragoza, Spain.	mhg@unizar.es	Hernandez, Monica/A-9855-2013; Olmos, Salvador/B-6935-2015; Bossa Bossa, Matias Nicolas/B-6865-2012	Olmos Gasso, Salvador/0000-0002-1869-7227; Bossa Bossa, Matias Nicolas/0000-0001-5127-2573	MEC [TEC2006-13966-C03-02]; FIS [PI04/1795]	MEC(European Commission); FIS(Instituto de Salud Carlos III)	The authors would like to acknowledge to Dr. C. Junque from Clinic Hospital, Barcelona, Spain for providing the MRI brain datasets. This work has been partially supported by research grants MEC TEC2006-13966-C03-02 and FIS PI04/1795. Finally, the authors would like to acknowledge to the anonymous reviewers for their useful comments and suggestions that contributed to the improvement of this manuscript.	[Anonymous], 1999, NUMERICAL OPTIMIZATI; Arnold V. I., 1989, GRAD TEXTS MATH, V60; ARSIGNY V, 2006, RR5885 INRIA SOPH AN; Arsigny V, 2006, LECT NOTES COMPUT SC, V4190, P924; Avants B, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 AND 2, P595; Avants BB, 2008, MED IMAGE ANAL, V12, P26, DOI 10.1016/j.media.2007.06.004; Avants BB, 2006, MED IMAGE ANAL, V10, P397, DOI 10.1016/j.media.2005.03.005; Beg M F, 2003, THESIS J HOPKINS U U; Beg MF, 2006, I S BIOMED IMAGING, P1116; Beg MF, 2005, INT J COMPUT VISION, V61, P139, DOI 10.1023/B:VISI.0000043755.93987.aa; Beg MF, 2007, IEEE T MED IMAGING, V26, P1179, DOI 10.1109/TMI.2007.898813; Christensen GE, 1999, LECT NOTES COMPUT SC, V1613, P224; Christensen GE, 1996, IEEE T IMAGE PROCESS, V5, P1435, DOI 10.1109/83.536892; Cotter C. J., 2006, P 1 INT WORKSH MATH, P18; Csernansky JG, 2004, NEUROIMAGE, V23, pS56, DOI 10.1016/j.neuroimage.2004.07.025; DAVIS B, 2007, P 11 IEEE INT C COMP; do Carmo M. P., 1992, RIEMANNIAN GEOMETRY; Dogdas B, 2005, HUM BRAIN MAPP, V26, P273, DOI 10.1002/hbm.20159; Dupuis P, 1998, Q APPL MATH, V56, P587, DOI 10.1090/qam/1632326; EBIN DG, 1970, ANN MATH, V92, P102, DOI 10.2307/1970699; Garcin L, 2006, J MATH IMAGING VIS, V25, P329, DOI 10.1007/s10851-006-6729-1; Gerig G, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P1041; GRABOWSKI J, 1988, FUND MATH, V131, P103, DOI 10.4064/fm-131-2-103-121; Grenander U, 1994, GEN PATTERN THEORY; HERNANDEZ M, 2008, THESIS U ZARAGOZA SP; Holm DD, 2004, NEUROIMAGE, V23, pS170, DOI 10.1016/j.neuroimage.2004.07.017; Joshi S, 2004, NEUROIMAGE, V23, pS151, DOI 10.1016/j.neuroimage.2004.07.068; Leow AD, 2006, NEUROIMAGE, V31, P627, DOI 10.1016/j.neuroimage.2005.12.013; Lepore N, 2006, LECT NOTES COMPUT SC, V4190, P191; Lorenzen P, 2006, MED IMAGE ANAL, V10, P440, DOI 10.1016/j.media.2005.03.002; MICHOR PW, 2006, APPL COMPUTATIONAL H, V23, P74; Miller MI, 2006, J MATH IMAGING VIS, V24, P209, DOI 10.1007/s10851-005-3624-0; Miller MI, 2004, NEUROIMAGE, V23, pS19, DOI 10.1016/j.neuroimage.2004.07.021; Modersitzki J, 2004, NUMER MATH SCI COMP; Noether E, 1918, NACHR GES WISS GOTT, V1918, P235, DOI DOI 10.1080/00411457108231446; Qiu A, 2008, NEUROIMAGE, V40, P68, DOI 10.1016/j.neuroimage.2007.11.041; SCHMID R, 2004, J GEOM SYMMETRY PHYS, V1, P54, DOI DOI 10.7546/JGSP-1-2004-54-120; STANIFORTH A, 1991, MON WEATHER REV, V119, P2206, DOI 10.1175/1520-0493(1991)119<2206:SLISFA>2.0.CO;2; Thompson PM, 2000, NATURE, V404, P190, DOI 10.1038/35004593; Thompson PM, 2001, CEREB CORTEX, V11, P1, DOI 10.1093/cercor/11.1.1; Wang L, 2003, NEUROIMAGE, V20, P667, DOI 10.1016/S1053-8119(03)00361-6; Wang L, 2007, IEEE T MED IMAGING, V26, P462, DOI 10.1109/TMI.2006.887380; Younes L, 2007, Q APPL MATH, V65, P113, DOI 10.1090/S0033-569X-07-01027-5	43	66	67	1	12	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	2009	85	3					291	306		10.1007/s11263-009-0219-z	http://dx.doi.org/10.1007/s11263-009-0219-z			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	502CO					2022-12-18	WOS:000270432200007
J	Fleet, DJ; Black, MJ; Yacoob, Y; Jepson, AD				Fleet, DJ; Black, MJ; Yacoob, Y; Jepson, AD			Design and use of linear models for image motion analysis	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						optical flow; motion discontinuities; occlusion; steerable filters; learning; eigenspace methods; motion-based recognition; non-rigid and articulated motion	OPTICAL-FLOW; PARAMETERIZED MODELS; ROBUST ESTIMATION; EARLY VISION; TRACKING; COMPUTATION; FIELDS; LAYERS; SEGMENTATION; ALGORITHM	Linear parameterized models of optical flow, particularly affine models, have become widespread in image motion analysis. The linear model coefficients are straightforward to estimate, and they provide reliable estimates of the optical flow of smooth surfaces. Here we explore the use of parameterized motion models that represent much more varied and complex motions. Our goals are threefold: to construct linear bases for complex motion phenomena; to estimate the coefficients of these linear models; and to recognize or classify image motions from the estimated coefficients. We consider two broad classes of motions: i) generic "motion features" such as motion discontinuities and moving bars; and ii) non-rigid, object-specific, motions such as the motion of human mouths. For motion features we construct a basis of steerable flow fields that approximate the motion features. For object-specific motions we construct basis flow fields from example motions using principal component analysis. In both cases, the model coefficients can be estimated directly from spatiotemporal image derivatives with a robust, multi-resolution scheme. Finally, we show how these model coefficients can be use to detect and recognize specific motions such as occlusion boundaries and facial expressions.	Queens Univ, Dept Comp & Informat Sci, Kingston, ON K7L 3N6, Canada; Xerox Corp, Palo Alto Res Ctr, Palo Alto, CA 94304 USA; Univ Maryland, Comp Vis Lab, College Pk, MD 20742 USA; Univ Toronto, Dept Comp Sci, Toronto, ON M5S 1A4, Canada	Queens University - Canada; Xerox; University System of Maryland; University of Maryland College Park; University of Toronto	Fleet, DJ (corresponding author), Queens Univ, Dept Comp & Informat Sci, Kingston, ON K7L 3N6, Canada.	fleet@cs.queensu.ca; black@parc.xerox.com; yaser@cs.umd.du; jepson@vis.toronto.edu		/0000-0003-0734-7114				AYER S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P777, DOI 10.1109/ICCV.1995.466859; Bab-Hadiashar A, 1998, INT J COMPUT VISION, V29, P59, DOI 10.1023/A:1008090730467; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; BAUMBERG A, 1994, LECT NOTES COMPUTER, V800, P299; Beauchemin SS, 2000, IEEE T PATTERN ANAL, V22, P200, DOI 10.1109/34.825758; Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1; BERGEN JR, 1992, IEEE T PATTERN ANAL, V14, P886, DOI 10.1109/34.161348; BERGEN JR, 1992, P EUR C COMP VIS, P237; Beymer D, 1996, PROC CVPR IEEE, P921, DOI 10.1109/CVPR.1996.517181; BLACK M, 1998, AAAI SPRING S INT EN, P1; Black M. J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P551, DOI 10.1109/ICCV.1999.791271; Black MJ, 1997, PROC CVPR IEEE, P561, DOI 10.1109/CVPR.1997.609381; Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436; Black MJ, 1997, INT J COMPUT VISION, V25, P23, DOI 10.1023/A:1007977618277; Black MJ, 2000, COMPUT VIS IMAGE UND, V78, P8, DOI 10.1006/cviu.1999.0825; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; BLACK MJ, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P1060; BLACK MJ, 1998, LECT NOTES COMPUTER, V1406, P909; Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581; BREGLER C, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P494, DOI 10.1109/ICCV.1995.466899; Burt P. J., 1989, Proceedings. Workshop on Visual Motion (IEEE Cat. No.89CH2716-9), P2, DOI 10.1109/WVM.1989.47088; CHOU GT, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1050, DOI 10.1109/ICCV.1995.466818; COOTES TF, 1995, LNCS SERIES, V1406, P484; DARRELL T, 1995, IEEE T PATTERN ANAL, V17, P474, DOI 10.1109/34.391395; Ezzat T, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P116, DOI 10.1109/AFGR.1996.557252; FENNEMA CL, 1979, COMPUT VISION GRAPH, V9, P301, DOI 10.1016/0146-664X(79)90097-2; FLEET DJ, 1990, INT J COMPUT VISION, V5, P77, DOI 10.1007/BF00056772; FLEET DJ, 1994, VISION RES, V34, P3057, DOI 10.1016/0042-6989(94)90278-X; Fleet DJ, 1992, MEASUREMENT IMAGE VE; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; GEMAN S, 1987, B INT STAT I, V4, P5; Golub G.H., 2013, MATRIX COMPUTATIONS, P357; Hager GD, 1996, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.1996.517104; HALLINAN P, 1995, THESIS HARVARD U CAM; HARRIS JG, 1990, INT J COMPUT VISION, V4, P211, DOI 10.1007/BF00054996; HEITZ F, 1993, IEEE T PATTERN ANAL, V15, P1217, DOI 10.1109/34.250841; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; JEPSON A, 1993, PARTITIONING DATA SE, P271; Ju SX, 1996, PROC CVPR IEEE, P307, DOI 10.1109/CVPR.1996.517090; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; NASTAR C, 1996, LNCS SERIES, V1064, P589; Nayar SK, 1996, PROC CVPR IEEE, P471, DOI 10.1109/CVPR.1996.517114; NELSON RC, 1992, CVGIP-IMAG UNDERSTAN, V56, P78, DOI 10.1016/1049-9660(92)90087-J; NIYOGI SA, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1044, DOI 10.1109/ICCV.1995.466819; Ong EP, 1999, INT J COMPUT VISION, V31, P51, DOI 10.1023/A:1008046826441; PERONA P, 1995, IEEE T PATTERN ANAL, V17, P488, DOI 10.1109/34.391394; POTTER JL, 1980, IEEE T SMC, V5, P390; Sclaroff S., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P158, DOI 10.1109/MNRAO.1994.346241; Sclaroff S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1146, DOI 10.1109/ICCV.1998.710860; Shulman D., 1989, Proceedings. Workshop on Visual Motion (IEEE Cat. No.89CH2716-9), P81, DOI 10.1109/WVM.1989.47097; Spoerri A., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P209; Szeliski R, 1997, INT J COMPUT VISION, V22, P199, DOI 10.1023/A:1007996332012; Szeliski R, 1996, IEEE T PATTERN ANAL, V18, P1199, DOI 10.1109/34.546257; THOMPSON WB, 1985, IEEE T PATTERN ANAL, V7, P374, DOI 10.1109/TPAMI.1985.4767677; Vasconcelos N, 1998, PROC CVPR IEEE, P361, DOI 10.1109/CVPR.1998.698631; Vetter T, 1997, PROC CVPR IEEE, P40, DOI 10.1109/CVPR.1997.609295; Vetter T, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P22, DOI 10.1109/AFGR.1996.557239; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; WAXMAN AM, 1985, INT J ROBOT RES, V4, P95, DOI 10.1177/027836498500400307; Weiss Y, 1997, PROC CVPR IEEE, P520, DOI 10.1109/CVPR.1997.609375; Weiss Y, 1996, PROC CVPR IEEE, P321, DOI 10.1109/CVPR.1996.517092; Wu YT, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P992, DOI 10.1109/ICCV.1998.710837; Yamamoto M, 1998, PROC CVPR IEEE, P2, DOI 10.1109/CVPR.1998.698580	64	66	73	0	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	FEB	2000	36	3					171	193		10.1023/A:1008156202475	http://dx.doi.org/10.1023/A:1008156202475			23	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	315LD					2022-12-18	WOS:000087114500001
J	OLIENSIS, J				OLIENSIS, J			UNIQUENESS IN SHAPE FROM SHADING	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article								For general images of smooth objects wholly contained in the field of view, and for illumination symmetric around the viewing direction, it is proven that shape is uniquely determined by shading. Thus, shape from shading is a well-posed problem under these illumination conditions; and regularization is unnecessary for surface reconstruction and should be avoided. Generic properties of surfaces and images are established. Questions of existence are also discussed. Under the conditions above, it is argued that most images are effectively impossible, with no corresponding physically reasonable surface, and that any image can be rendered effectively impossible by a small perturbation of its intensities. This is explicitly illustrated for a synthetic image. The proofs are based on ideas of dynamical systems theory and global analysis.	UNIV MASSACHUSETTS,AMHERST,MA 01003	University of Massachusetts System; University of Massachusetts Amherst								ABRAHAM RH, 1983, DYNAMICS GEOMETRY 3; Arnol'd V I, 1973, ORDINARY DIFFERENTIA; BRUSS AR, 1982, J MATH PHYS, V23, P890, DOI 10.1063/1.525441; Elliot R. J., 1987, VISCOSITY SOLUTIONS; GIBLIN P, 1987, 1ST P INT C COMP VIS, P136; Horn B.K.P., 1989, SHAPE SHADING; Horn Berthold K. P., 1975, PSYCHOL COMPUTER VIS, P115; HORN BKP, 1990, INT J COMPUT VISION, V5, P37, DOI 10.1007/BF00056771; HORN BKP, 1990, UNPUB IEEE T PATT AN; OLIENSIS J, 1989, EXISTENCE UNIQUENESS; OLIENSIS J, 1990, IN PRESS COMPUT VISI; PALIS J, 1968, JUL P S PUR MATH BER, V15, P223; Palis J., 1982, GEOMETRIC THEORY DYN; SAXBERG BVH, 1989, MAY P DARPA IM UND W, P1089; SAXBERG BVH, 1989, MODERN DIFFERENTIAL; W Hirsch M., 1989, DIFF EQUAT+	16	66	67	0	0	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	1991	6	2					75	104		10.1007/BF00128151	http://dx.doi.org/10.1007/BF00128151			30	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	FW779					2022-12-18	WOS:A1991FW77900001
J	Agrawal, A; Lu, JS; Antol, S; Mitchell, M; Zitnick, CL; Parikh, D; Batra, D				Agrawal, Aishwarya; Lu, Jiasen; Antol, Stanislaw; Mitchell, Margaret; Zitnick, C. Lawrence; Parikh, Devi; Batra, Dhruv			VQA: Visual Question Answering	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Visual Question Answering		We propose the task of free-form and open-ended Visual Question Answering (VQA). Given an image and a natural language question about the image, the task is to provide an accurate natural language answer. Mirroring real-world scenarios, such as helping the visually impaired, both the questions and answers are open-ended. Visual questions selectively target different areas of an image, including background details and underlying context. As a result, a system that succeeds at VQA typically needs a more detailed understanding of the image and complex reasoning than a system producing generic image captions. Moreover, VQA is amenable to automatic evaluation, since many open-ended answers contain only a few words or a closed set of answers that can be provided in a multiple-choice format. We provide a dataset containing similar to 0.25 M images, similar to 0.76 M questions, and similar to 10 M answers (www.visuaiqa.org) and discuss the information it provides. Numerous baselines and methods for VQA are provided and compared with human performance. Our VQA demo is available on CloudCV (http://cloudcv.org/vqa).	[Agrawal, Aishwarya; Lu, Jiasen; Antol, Stanislaw] Virginia Tech, Blacksburg, VA 24061 USA; [Mitchell, Margaret] Microsoft Res, Redmond, WA USA; [Zitnick, C. Lawrence] Facebook AI Res, Menlo Pk, CA USA; [Parikh, Devi; Batra, Dhruv] Georgia Inst Technol, Blacksburg, VA USA	Virginia Polytechnic Institute & State University; Microsoft; Facebook Inc; University System of Georgia; Georgia Institute of Technology	Agrawal, A (corresponding author), Virginia Tech, Blacksburg, VA 24061 USA.	aish@vt.edu; jiasenlu@vt.edu; santol@vt.edu; memitc@microsoft.com; zitnick@fb.com; parikh@vt.edu; dbatra@vt.edu			Paul G. Allen Family Foundation; National Science Foundation CAREER award; Army Research Office YIP Award; Office of Naval Research grant; ICTAS at Virginia Tech; Google Faculty Research Awards	Paul G. Allen Family Foundation; National Science Foundation CAREER award(National Science Foundation (NSF)); Army Research Office YIP Award; Office of Naval Research grant(Office of Naval Research); ICTAS at Virginia Tech; Google Faculty Research Awards(Google Incorporated)	We would like to acknowledge the countless hours of effort provided by the workers on Amazon Mechanical Turk. This work was supported in part by the The Paul G. Allen Family Foundation via an award to D.P., ICTAS at Virginia Tech via awards to D.B. and D.P., Google Faculty Research Awards to D.P. and D.B., the National Science Foundation CAREER award to D.B., the Army Research Office YIP Award to D.B., and a Office of Naval Research grant to D.B.	Agrawal H, 2015, MOBILE CLOUD VISUAL, P265; [Anonymous], 2010, AAAI; Antol S., 2014, ECCV; Bigham J. P., 2010, P INFUS; Bollacker K., 2008, INT C MAN DAT, DOI [10.1145/1376616.1376746, DOI 10.1145/1376616.1376746]; Chen X., 2013, ICCV; Chen X., 2015, P IEEE INT C COMP VI; Chen X., 2015, ARXIV150400325 CORR; Coppersmith G., 2014, ACL WORKSH INT LANG; Deng J., 2011, CVPR; Donahue J., 2015, CVPR; Elliott Desmond, 2014, ACL; Fader A., 2014, INT C KNOWL DISC DAT; Fader A., 2013, ACL; Fang H., 2015, C COMP VIS PATT REC; Farhadi A., 2010, ECCV; Gao H., 2015, NIPS; Geman D., 2014, PNAS; Gordon J., 2013, P 3 WORKSH KNOWL EXT; Guadarrama S., 2013, INT C COMP VIS; Gupta S., 2015, COMPUTER SCI; Jia Y., P ACM MULT, P675; Karpathy A., 2015, CVPR; Kazemzadeh Sahar, 2014, EMNLP; Kiros R., 2015, ARXIV150606726; Kiros Ryan, 2015, ARXIV14112539; Kong C., 2014, CVPR TEXT TO IMAGE C; Krizhevsky A., 2012, ADV NEURAL INF PROCE; Kulkarni G., 2011, P 24 CVPR CIT; Lenat D. B., 1989, BUILDING LARGE KNOWL; Lin T.-Y., 2014, EUR C COMP VIS, P740, DOI 10.1007/978-3-319-10602-1_48; Lin X., 2015, CVPR; Liu H, 2004, BT TECHNOL J, V22, P211, DOI 10.1023/B:BTTJ.0000047600.45421.6d; Malinowski M., 2015, P INT C COMP VIS; Malinowski M., 2014, NIPS; Mao J, 2014, ARXIV14101090 CORR; Mikolov T., 2013, ADV NEURAL INF PROCE, V26; Mitchell M., 2013, HLT NAACL; Mitchell M., 2013, PRE COGSCI; Mitchell M., 2012, ACL; Ramanathan V., 2014, ECCV; Ren M., 2015, NIPS; Richardson M., 2013, EMNLP; Rohrbach M., 2013, ICCV; Sadeghi F., 2015, CVPR; Simonyan K., 2015, ARXIV PREPRINT ARXIV; Toutanova K., 2003, ACL; Vedantam R., 2015, CVPR; Vendantam R., 2015, ICCV; Vinyals O., 2015, CVPR; Weston J., 2015, ARXIV150205698 CORR; Yu L, 2015, IEEE INT C COMP VIS; Zhang P., 2015, ARXIV151105099 CORR; Zitnick C. L., 2013, ICCV; Zitnick C. L., 2013, CVPR; Zitnick CL, 2016, IEEE T PATTERN ANAL, V38, P627, DOI 10.1109/TPAMI.2014.2366143	58	65	68	7	48	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2017	123	1			SI		4	31		10.1007/s11263-016-0966-6	http://dx.doi.org/10.1007/s11263-016-0966-6			28	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	ET4SY		Green Submitted			2022-12-18	WOS:000400276400002
J	Zhou, Y; Bai, X; Liu, WY; Latecki, LJ				Zhou, Yu; Bai, Xiang; Liu, Wenyu; Latecki, Longin Jan			Similarity Fusion for Visual Tracking	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Visual tracking; Similarity measure; Fusion	OBJECT TRACKING; ROBUST	Multiple features' integration and context structure of unlabeled data have proven their effectiveness in enhancing similarity measures in many applications of computer vision. However, in similarity based object tracking, integration of multiple features has been rarely studied. In contrast to conventional tracking approaches that utilize pairwise similarity for template matching, our approach contributes in two different aspects. First, multiple features are integrated into a unified similarity to enhance the discriminative ability of similarity measurements. Second, the neighborhood context of the samples in forthcoming frame are employed to further improve the measurements. We utilize a diffusion process on a tensor product graph to achieve these goals. The obtained approach is validated on numerous challenging video sequences, and the experimental results demonstrate that it outperforms state-of-the-art t racking methods.	[Zhou, Yu; Bai, Xiang; Liu, Wenyu] Huazhong Univ Sci & Technol, Wuhan 430074, Peoples R China; [Latecki, Longin Jan] Temple Univ, Philadelphia, PA 19122 USA; [Zhou, Yu] Beijing Univ Posts & Telecommun, Beijing 100088, Peoples R China	Huazhong University of Science & Technology; Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University; Beijing University of Posts & Telecommunications	Bai, X (corresponding author), Huazhong Univ Sci & Technol, Wuhan 430074, Peoples R China.	yuzhou@hust.edu.cn; xiang.bai@gmail.com; liuwy@hust.edu.cn; latecki@temple.edu	Liu, Wenyu/AAG-1426-2019	Liu, Wenyu/0000-0002-4582-7488; Latecki, Longin Jan/0000-0002-5102-8244	National Natural Science Foundation of China (NSFC) [61222308, 61572207, 61573160, 61173120]; Program for New Century Excellent Talents in University [NCET-12-0217]; NSF [OIA-1027897, IIS-1302164]; China 973 Program [2012CB316300]; National Natural Science Foundation of China (NSFC) [61222308, 61572207, 61573160, 61173120]; Program for New Century Excellent Talents in University [NCET-12-0217]; NSF [OIA-1027897, IIS-1302164]; China 973 Program [2012CB316300]	National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Program for New Century Excellent Talents in University(Program for New Century Excellent Talents in University (NCET)); NSF(National Science Foundation (NSF)); China 973 Program(National Basic Research Program of China); National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Program for New Century Excellent Talents in University(Program for New Century Excellent Talents in University (NCET)); NSF(National Science Foundation (NSF)); China 973 Program(National Basic Research Program of China)	This work was primarily supported by National Natural Science Foundation of China (NSFC) (Nos. 61222308, 61572207, and 61573160), and in part by Program for New Century Excellent Talents in University (No. NCET-12-0217), NSF grants OIA-1027897 and IIS-1302164, China 973 Program under Grant No. 2012CB316300, National Natural Science Foundation of China (NSFC) (No. 61173120).	Adam A., 2006, IEEE C COMP VIS PATT; Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53; Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35; Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226; Badrinarayanan V., 2007, P IEEE INT C COMP VI; Bai X, 2010, IEEE T PATTERN ANAL, V32, P861, DOI 10.1109/TPAMI.2009.85; Bao C., 2012, PROCEEDINGS OF IEEE; Belkin M, 2004, MACH LEARN, V56, P209, DOI 10.1023/B:MACH.0000033120.25363.1e; Bischof H., 2006, BMVC, P47; Cehovin L, 2013, IEEE T PATTERN ANAL, V35, P941, DOI 10.1109/TPAMI.2012.145; Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Fan J., 2010, P EUR C COMP VIS ECC; Fan JL, 2012, IEEE T PATTERN ANAL, V34, P1633, DOI 10.1109/TPAMI.2011.257; Fan Z., 2006, P IEEE C COMP VIS PA; Fanti C, 2004, ADV NEUR IN, V16, P1603; Gao H, 2013, IEEE SYMP COMMUN VEH; Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19; Hong ZB, 2013, IEEE I CONF COMP VIS, P649, DOI 10.1109/ICCV.2013.86; Hu WM, 2011, INT J COMPUT VISION, V91, P303, DOI 10.1007/s11263-010-0399-6; Jia X., 2012, P IEEE C COMP VIS PA; Jiang N., 2012, P IEEE C COMP VIS PA; Jiang N, 2011, IEEE T IMAGE PROCESS, V20, P2288, DOI 10.1109/TIP.2011.2114895; Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239; Kwon J., 2010, P IEEE C COMP VIS PA; Kwon J., 2011, P IEEE INT C COMP VI; Kwon J, 2013, IEEE T PATTERN ANAL, V35, P2427, DOI 10.1109/TPAMI.2013.32; Leichter I, 2012, IEEE T PATTERN ANAL, V34, P695, DOI 10.1109/TPAMI.2011.167; Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039; Li X, 2013, IEEE T IMAGE PROCESS, V22, P3028, DOI 10.1109/TIP.2013.2253478; Li X, 2013, IEEE T PATTERN ANAL, V35, P863, DOI 10.1109/TPAMI.2012.166; Liu B., 2012, IEEE T PATTERN ANAL, V32, P861; Ma JY, 2015, IEEE T SIGNAL PROCES, V63, P1115, DOI 10.1109/TSP.2014.2388434; Ma JY, 2014, IEEE T IMAGE PROCESS, V23, P1706, DOI 10.1109/TIP.2014.2307478; Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66; Mei Xue, 2011, P IEEE C COMP VIS PA; Moreno-Noguer F, 2008, IEEE T PATTERN ANAL, V30, P670, DOI 10.1109/TPAMI.2007.70727; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Santner J., 2010, P IEEE C COMP VIS PA; Sinha K., 2009, ADV NEURAL INFORM PR; Spengler M, 2003, MACH VISION APPL, V14, P50, DOI 10.1007/s00138-002-0095-9; Stenger B., 2009, P IEEE C COMP VIS PA; Tsagkatakis G, 2011, IEEE T CIRC SYST VID, V21, P1810, DOI 10.1109/TCSVT.2011.2133970; Tuzel O., 2006, P IEEE C COMP VIS PA; Vishwanathan SVN, 2010, J MACH LEARN RES, V11, P1201; Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677; Wang JQ, 2008, IEEE T IMAGE PROCESS, V17, P235, DOI 10.1109/TIP.2007.914150; Wang M, 2011, IEEE T INTELL TRANSP, V12, P1195, DOI 10.1109/TITS.2011.2148717; Wang Q, 2012, IEEE T IMAGE PROCESS, V21, P4454, DOI 10.1109/TIP.2012.2205700; Wang S, 2011, P IEEE INT C COMP VI; Wang X., 2010, P EUR C COMP VIS ECC; WU Y, 2009, P IEEE C COMP VIS PA; Wu Y, 2012, IEEE T IMAGE PROCESS, V21, P2824, DOI 10.1109/TIP.2011.2182521; Yang M., 2007, P IEEE C COMP VIS PA; Yang M, 2009, IEEE T PATTERN ANAL, V31, P1195, DOI 10.1109/TPAMI.2008.146; Yang X., 2011, P IEEE C COMP VIS PA; Yang XW, 2013, IEEE T PATTERN ANAL, V35, P28, DOI 10.1109/TPAMI.2012.60; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; Yoon J. H., 2012, P EUR C COMP VIS ECC; Zhang K. H., 2012, P EUR C COMP VIS ECC; Zhang TZ, 2013, INT J COMPUT VISION, V101, P367, DOI 10.1007/s11263-012-0582-z; Zhong W., 2012, P IEEE C COMP VIS PA; Zhou, 2012, PROC ADV NEURAL INF, P1; Zhou D., 2004, ADV NEURAL INFORM PR; Zhu X., 2006, 1530 U WISC DEP COMP	68	65	70	0	57	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2016	118	3					337	363		10.1007/s11263-015-0879-9	http://dx.doi.org/10.1007/s11263-015-0879-9			27	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	DP9AM					2022-12-18	WOS:000378789100004
J	Yang, B; Nevatia, R				Yang, Bo; Nevatia, Ramakant			Multi-Target Tracking by Online Learning a CRF Model of Appearance and Motion Patterns	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Multi-target tracking; Online learned CRF; Appearance and motion patterns; Association based tracking	ASSOCIATION	We introduce an online learning approach for multi-target tracking. Detection responses are gradually associated into tracklets in multiple levels to produce final tracks. Unlike most previous approaches which only focus on producing discriminative motion and appearance models for all targets, we further consider discriminative features for distinguishing difficult pairs of targets. The tracking problem is formulated using an online learned CRF model, and is transformed into an energy minimization problem. The energy functions include a set of unary functions that are based on motion and appearance models for discriminating all targets, as well as a set of pairwise functions that are based on models for differentiating corresponding pairs of tracklets. The online CRF approach is more powerful at distinguishing spatially close targets with similar appearances, as well as in tracking targets in presence of camera motions. An efficient algorithm is introduced for finding an association with low energy cost. We present results on four public data sets, and show significant improvements compared with several state-of-art methods.	[Yang, Bo; Nevatia, Ramakant] Univ So Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA	University of Southern California	Yang, B (corresponding author), Univ So Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA.	yangbo@usc.edu; nevatia@usc.edu			Office of Naval Research [N00014-10-1-0517]; Army Research Laboratory [W911NF-10-2-0063]	Office of Naval Research(Office of Naval Research); Army Research Laboratory(United States Department of DefenseUS Army Research Laboratory (ARL))	Research was sponsored, in part, by Office of Naval Research under Grant number N00014-10-1-0517 and by the Army Research Laboratory and was accomplished under Cooperative Agreement Number W911NF-10-2-0063. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Army Research Laboratory or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation herein.	Ben Shitrit H, 2011, IEEE I CONF COMP VIS, P137, DOI 10.1109/ICCV.2011.6126235; Breitenstein MD, 2011, IEEE T PATTERN ANAL, V33, P1820, DOI 10.1109/TPAMI.2010.232; Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761; Duan GQ, 2012, LECT NOTES COMPUT SC, V7574, P129, DOI 10.1007/978-3-642-33712-3_10; Ess A, 2009, IEEE T PATTERN ANAL, V31, P1831, DOI 10.1109/TPAMI.2009.109; Grabner H, 2010, PROC CVPR IEEE, P1285, DOI 10.1109/CVPR.2010.5539819; HAMMER PL, 1984, MATH PROGRAM, V28, P121, DOI 10.1007/BF02612354; Holzer S, 2012, LECT NOTES COMPUT SC, V7572, P470, DOI 10.1007/978-3-642-33718-5_34; Huang C, 2008, LECT NOTES COMPUT SC, V5303, P788, DOI 10.1007/978-3-540-88688-4_58; Huang C, 2010, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2010.5540230; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231; Kuo CH, 2011, PROC CVPR IEEE, P1217, DOI 10.1109/CVPR.2011.5995384; Kuo CH, 2010, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2010.5540148; National institute of standards and technology, TRECV 2008 EV SURV E; PEARL J, 1998, PROBABILISTIC REASON; Perera A. A., 2006, 2006 IEEE COMPUTER S, V1, P666; Song B, 2010, LECT NOTES COMPUT SC, V6311, P605, DOI 10.1007/978-3-642-15549-9_44; Stalder S, 2010, LECT NOTES COMPUT SC, V6311, P369, DOI 10.1007/978-3-642-15549-9_27; Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385; Xing JL, 2011, IEEE T IMAGE PROCESS, V20, P1652, DOI 10.1109/TIP.2010.2102045; Xing JL, 2009, PROC CVPR IEEE, P1200, DOI 10.1109/CVPRW.2009.5206745; Yang B, 2012, LECT NOTES COMPUT SC, V7572, P484, DOI 10.1007/978-3-642-33718-5_35; Yang B, 2011, PROC CVPR IEEE, P1233, DOI 10.1109/CVPR.2011.5995587; Yu Q, 2007, PROC CVPR IEEE, P170; Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62; Zhang L, 2008, INT C WAVEL ANAL PAT, P11, DOI 10.1109/ICWAPR.2008.4635742; Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908	34	65	72	0	29	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	2014	107	2			SI		203	217		10.1007/s11263-013-0666-4	http://dx.doi.org/10.1007/s11263-013-0666-4			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AD3QP					2022-12-18	WOS:000333161200008
J	Lalonde, JF; Efros, AA; Narasimhan, SG				Lalonde, Jean-Francois; Efros, Alexei A.; Narasimhan, Srinivasa G.			Estimating the Natural Illumination Conditions from a Single Outdoor Image	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Illumination estimation; Data-driven methods; Shadow detection; Scene understanding; Image synthesis	MODEL	Given a single outdoor image, we present a method for estimating the likely illumination conditions of the scene. In particular, we compute the probability distribution over the sun position and visibility. The method relies on a combination of weak cues that can be extracted from different portions of the image: the sky, the vertical surfaces, the ground, and the convex objects in the image. While no single cue can reliably estimate illumination by itself, each one can reinforce the others to yield a more robust estimate. This is combined with a data-driven prior computed over a dataset of 6 million photos. We present quantitative results on a webcam dataset with annotated sun positions, as well as quantitative and qualitative results on consumer-grade photographs downloaded from Internet. Based on the estimated illumination, we show how to realistically insert synthetic 3-D objects into the scene, and how to transfer appearance across images while keeping the illumination consistent.	[Lalonde, Jean-Francois; Efros, Alexei A.; Narasimhan, Srinivasa G.] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Lalonde, JF (corresponding author), Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.	jlalonde@cs.cmu.edu; efros@cs.cmu.edu; srinivas@cs.cmu.edu		Efros, Alexei A./0000-0001-5720-8070; Lalonde, Jean-Francois/0000-0002-6583-2364	NSF [CCF-0541230, IIS-0546547, IIS-0643628]; ONR [N00014-08-10330]; Microsoft Fellowship	NSF(National Science Foundation (NSF)); ONR(Office of Naval Research); Microsoft Fellowship(Microsoft)	This work has been partially supported by a Microsoft Fellowship to J.-F. Lalonde, and by NSF grants CCF-0541230, IIS-0546547, IIS-0643628 and ONR grant N00014-08-10330. A. Efros is grateful to the WILLOW team at ENS Paris for their hospitality. Parts of the results presented in this paper have previously appeared in Lalonde et al. (2009).	Basri R, 2007, INT J COMPUT VISION, V72, P239, DOI 10.1007/s11263-006-8815-7; BIRD RE, 1984, SOL ENERGY, V32, P461, DOI 10.1016/0038-092X(84)90260-3; Bitouk D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360638; Blinn J. F., 1976, P ACM SIGGRAPH 1976; Buluswar SD, 2002, COMPUT VIS IMAGE UND, V85, P71, DOI 10.1006/cviu.2001.0950; Cavanagh P, 2005, NATURE, V434, P301, DOI 10.1038/434301a; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; Chen HF, 2000, PROC CVPR IEEE, P254, DOI 10.1109/CVPR.2000.855827; Chong HY, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360660; Collins M., 2002, MACH LEARN, V48, P158; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Dale K., 2009, INT C COMP VIS; Debevec P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P189, DOI 10.1145/280814.280864; Debevec P., 1997, P ACM SIGGRAPH 1997, DOI [DOI 10.1145/258734.258884, 10.1145/258734.258884]; Debevec P., 2004, ACM T GRAPHIC, V1, P1; Dror R, 2004, J VISION, V4, P821, DOI 10.1167/4.9.11; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Finlayson G., 1993, INT C COMP VIS; Finlayson G. D., 2004, EUR C COMP VIS; Finlayson G. D., 2002, EUR C COMP VIS; Finlayson G, 2007, IEEE I CONF COMP VIS, P2041; Hays James, 2008, CVPR, DOI DOI 10.1109/CVPR.2008.4587784; Healey G, 1999, IEEE T GEOSCI REMOTE, V37, P2706, DOI 10.1109/36.803418; Hill Roger D., 1994, P227; Hoiem D, 2005, ACM T GRAPHIC, V24, P577, DOI 10.1145/1073204.1073232; Hoiem D, 2007, IEEE I CONF COMP VIS, P1229; Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y; Jacobs N, 2007, IEEE I CONF COMP VIS, P1305; JUDD DB, 1964, J OPT SOC AM, V54, P1031, DOI 10.1364/JOSA.54.001031; Junejo IN, 2008, LECT NOTES COMPUT SC, V5302, P318, DOI 10.1007/978-3-540-88682-2_25; KASTEN F, 1989, APPL OPTICS, V28, P4735, DOI 10.1364/AO.28.004735; Ke Yan, 2006, 2006 IEEE COMPUTER S, V1, P419, DOI DOI 10.1109/CVPR.2006.303; Khan EA, 2006, ACM T GRAPHIC, V25, P654, DOI 10.1145/1141911.1141937; Kim T, 2005, IEEE I CONF COMP VIS, P266; Koenderink JJ, 2004, PERCEPTION, V33, P1405, DOI 10.1068/p5287; Kosecka J., 2002, EUR C COMP VIS; Lalonde J.-F., 2010, GROUND SHADOW BOUNDA; Lalonde J.-F., 2007, ACM T GRAPH SIGGRAPH; Lalonde JF, 2010, LECT NOTES COMPUT SC, V6312, P322, DOI 10.1007/978-3-642-15552-9_24; Lalonde JF, 2009, IEEE I CONF COMP VIS, P183, DOI 10.1109/ICCV.2009.5459163; Lalonde JF, 2010, INT J COMPUT VISION, V88, P24, DOI 10.1007/s11263-009-0291-4; Lalonde JF, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618477; Langer MS, 2001, PERCEPTION, V30, P403, DOI 10.1068/p3178; Li Y., 2003, IEEE INT C COMP VIS; Manduchi R, 2006, IEEE T PATTERN ANAL, V28, P1713, DOI 10.1109/TPAMI.2006.231; Maxwell BA, 2008, PROC CVPR IEEE, P1150; Mills D, 2004, SOL ENERGY, V76, P19, DOI 10.1016/S0038-092X(03)00102-6; Narasimhan SG, 2005, IEEE I CONF COMP VIS, P420; Park D, 2010, LECT NOTES COMPUT SC, V6314, P241, DOI 10.1007/978-3-642-15561-1_18; PEREZ R, 1993, SOL ENERGY, V50, P235, DOI 10.1016/0038-092X(93)90017-I; Platt JC, 2000, ADV NEUR IN, P61; Preetham AJ, 1999, COMP GRAPH, P91, DOI 10.1145/311535.311545; Ramamoorthi R., 2001, P ACM SIGGRAPH 2001; Reda I., 2005, NRELTP56034302; Reinhart CF, 2006, LEUKOS, V3, P7, DOI 10.1582/LEUKOS.2006.03.01.001; Romeiro F., 2010, EUR C COMP VIS; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Sato I, 2003, IEEE T PATTERN ANAL, V25, P290, DOI 10.1109/TPAMI.2003.1182093; Sato Y., 1995, Proceedings of the Workshop on Physics-Based Modeling in Computer Vision (Cat. No.95TB8038), P180, DOI 10.1109/PBMCV.1995.514684; Slater D, 1998, J OPT SOC AM A, V15, P2913, DOI 10.1364/JOSAA.15.002913; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; Stumpfel J., 2004, P AFRIGRAPH, P145, DOI DOI 10.1145/1185657.1185687; Sun M., 2009, IEEE INT WORKSH 3 D; Sunkavalli K, 2008, PROC CVPR IEEE, P541; Tian JD, 2009, IEEE T IMAGE PROCESS, V18, P2355, DOI 10.1109/TIP.2009.2026682; Tsin Y, 2001, PROC CVPR IEEE, P1132; Ward G., 1994, P ACM SIGGRAPH 1994; Weiss Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P68, DOI 10.1109/ICCV.2001.937606; Wu TP, 2005, IEEE I CONF COMP VIS, P480; Yu Y., 1998, P ACM SIGGRAPH 1998; Zhu JJ, 2010, PROC CVPR IEEE, P223, DOI 10.1109/CVPR.2010.5540209; Zickler T., 2006, IEEE C COMP VIS PATT	73	65	73	2	23	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2012	98	2					123	145		10.1007/s11263-011-0501-8	http://dx.doi.org/10.1007/s11263-011-0501-8			23	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	934NH					2022-12-18	WOS:000303450500001
J	Perriollat, M; Hartley, R; Bartoli, A				Perriollat, Mathieu; Hartley, Richard; Bartoli, Adrien			Monocular Template-based Reconstruction of Inextensible Surfaces	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Structure-from-Motion; 3D reconstruction; Surface; Deformable; Nonrigid; Template	STRUCTURE-FROM-MOTION; WARPS; SHAPE	We present a monocular 3D reconstruction algorithm for inextensible deformable surfaces. It uses point correspondences between a single image of the deformed surface taken by a camera with known intrinsic parameters and a template. The main assumption we make is that the surface shape as seen in the template is known. Since the surface is inextensible, its deformations are isometric to the template. We exploit the distance preservation constraints to recover the 3D surface shape as seen in the image. Though the distance preservation constraints have already been investigated in the literature, we propose a new way to handle them. Spatial smoothness priors are easily incorporated, as well as temporal smoothness priors in the case of reconstruction from a video. The reconstruction can be used for 3D augmented reality purposes thanks to a fast implementation. We report results on synthetic and real data. Some of them are compared to stereo-based 3D reconstructions to demonstrate the efficiency of our method.	[Bartoli, Adrien] Univ Auvergne, Clermont Ferrand, France; [Perriollat, Mathieu] VI Technol, Grenoble, France; [Hartley, Richard] ANU NICTA, RSISE, Canberra, ACT, Australia	Universite Clermont Auvergne (UCA); Australian National University	Bartoli, A (corresponding author), Univ Auvergne, Clermont Ferrand, France.	Adrien.Bartoli@gmail.com		Hartley, Richard/0000-0002-5005-0191	Australian Government; Australian Research Council through the ICT Centre of Excellence	Australian Government(Australian GovernmentCGIAR); Australian Research Council through the ICT Centre of Excellence(Australian Research Council)	NICTA is funded by the Australian Government as represented by the Department of Broadband, Communications and the Digital Economy and the Australian Research Council through the ICT Centre of Excellence program.	Bartoli A., 2008, INT C COMP VIS PATT; Bartoli A, 2008, J MATH IMAGING VIS, V31, P133, DOI 10.1007/s10851-007-0062-1; Bartoli A, 2010, INT J COMPUT VISION, V88, P85, DOI 10.1007/s11263-009-0303-4; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; Bouguet J. Y., 2008, CAMERA CALIBRATION T; BRAND M, 2005, INT C COMP VIS PATT; BREGLER C, 2000, INT C COMP VIS PATT; Bronstein AM, 2005, INT J COMPUT VISION, V64, P5, DOI 10.1007/s11263-005-1085-y; DELBUE A, 2008, INT C COMP VIS PATT; Ecker A., 2008, EUR C COMP VIS; FERREIRA R, 2009, INT C AC SPEECH SIGN; Gay-Bellile V., 2006, INT C IM PROC; Gay-Bellile V, 2010, IEEE T PATTERN ANAL, V32, P87, DOI 10.1109/TPAMI.2008.265; Gumerov N., 2004, EUR C COMP VIS; Hartley R., 2004, ROBOTICA; Hartley RI, 1997, COMPUT VIS IMAGE UND, V68, P146, DOI 10.1006/cviu.1997.0547; Hartley RI, 1998, INT J COMPUT VISION, V26, P41, DOI 10.1023/A:1007984508483; Liang J, 2008, IEEE T PATTERN ANAL, V30, P591, DOI 10.1109/TPAMI.2007.70724; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Olsen SI, 2008, J MATH IMAGING VIS, V31, P233, DOI 10.1007/s10851-007-0060-3; PENNA MA, 1992, CVGIP-IMAG UNDERSTAN, V56, P366, DOI 10.1016/1049-9660(92)90048-8; PERRIOLLAT M, 2007, WORKSH BENCHM AUT CA; Perriollat M., 2008, BRIT MACH VIS C; Pilet J, 2008, INT J COMPUT VISION, V76, P109, DOI 10.1007/s11263-006-0017-9; PRASAD M, 2006, INT C COMP VIS PATT; Salzmann M., 2008, EUR C COMP VIS; SALZMANN M, 2008, INT C COMP VIS PATT; Salzmann M, 2007, IEEE T PATTERN ANAL, V29, P1481, DOI 10.1109/TPAMI.2007.1080; Shen S., 2009, AS C COMP VIS; SHI J, 1994, INT C COMP VIS PATT; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; VIDAL R, 2006, EUR C COMP VIS; Xiao J, 2006, INT J COMPUT VISION, V67, P233, DOI 10.1007/s11263-005-3962-9	33	65	69	1	15	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	2011	95	2					124	137		10.1007/s11263-010-0352-8	http://dx.doi.org/10.1007/s11263-010-0352-8			14	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	815YN		Green Submitted			2022-12-18	WOS:000294566000002
J	Chi, C; Yoo, H; Ben-Ezra, M				Chi, Cui; Yoo, Hyunjin; Ben-Ezra, Moshe			Multi-Spectral Imaging by Optimized Wide Band Illumination	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	Workshop on Photometric Analysis for Computer Vision held in Conjunction with the 11th International Conference on Computer Vision Conference	OCT 04, 2007	Rio de Janeiro, BRAZIL			Multi-spectral imaging; Multiplexed illumination	SPECTROSCOPY	We present a novel active imaging approach that uses optimized wide band filtered illumination to obtain multi-spectral reflectance information. Our optimization algorithm utilizes light source and camera spectral information in order to maximize the signal strength and the robustness to noise. Through the use of active wide band illumination, our system can obtain material reflectance information in the presence of moderate (indoor) unknown ambient illumination. Our method is very simple and does not require special equipment. It can be used by photographers to obtain material properties in uncontrolled environment and to synthesize captured scenes under arbitrary illumination.	[Ben-Ezra, Moshe] Microsoft Res Asia, Beijing, Peoples R China; [Chi, Cui] Tsinghua Univ, Beijing 100084, Peoples R China; [Yoo, Hyunjin] Gwangju Inst Sci & Technol, Kwangju, South Korea	Microsoft; Microsoft Research Asia; Tsinghua University; Gwangju Institute of Science & Technology (GIST)	Ben-Ezra, M (corresponding author), Microsoft Res Asia, Beijing, Peoples R China.	cch2000@umd.edu; hjyoo@gist.ac.kr; mosheb@microsoft.com						ABRARDO A, 1999, P IEEE INT C IM PROC, V3, P570; Connah D, 2004, INT C IM PROC ICIP 0, V3, P1497; FINLAYSON GD, 1995, THESIS S FRASER U CA; Gat N, 2000, P SOC PHOTO-OPT INS, V4056, P50, DOI 10.1117/12.381686; Grossberg MD, 2004, IEEE T PATTERN ANAL, V26, P1272, DOI 10.1109/TPAMI.2004.88; HANSEN P, 1999, LECT NOTES EARTH SCI, V92; Imai F. H, 2001, P 3 INT C MULT COL S, P13; IMAI FH, 2002, IEEE T PATTERN ANAL, V24, P17; JAASKELAINEN T, 1990, J OPT SOC AM A, V7, P725, DOI 10.1364/JOSAA.7.000725; Koza J.R., 1998, ENCY COMPUTER SCI TE, V39, P29; MALONEY L, 1987, READINGS COMPUTER VI; MONNET G, 1995, ASTR SOC P, V71, P12; NAYAR S, 2006, SIGGRAPH 06, P935; Nayar S. K., 2006, ACM T GRAPH; Novati G, 2005, INT J DIGIT LIBRARIE, V5, P167, DOI 10.1007/s00799-004-0103-y; PARK MH, 2007, ICCV; Schechner YY, 2004, PROC CVPR IEEE, P197; Schechner YY, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P808; Schechner YY, 2002, IEEE T PATTERN ANAL, V24, P1334, DOI 10.1109/TPAMI.2002.1039205; SLATER D, 1999, P COMP VIS PATT REC, V2, P268; Stokman HMG, 2000, COMPUT VIS IMAGE UND, V79, P236, DOI 10.1006/cviu.2000.0860; VILLEMAIRE A, 1998, P SPIE; WELLMAN JB, 1981, P SOC PHOTO-OPT INST, V268, P64, DOI 10.1117/12.959926	23	65	71	0	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2010	86	2-3			SI		140	151		10.1007/s11263-008-0176-y	http://dx.doi.org/10.1007/s11263-008-0176-y			12	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	534NA					2022-12-18	WOS:000272903200003
J	Nguyen, HT; Smeulders, AWM				Nguyen, Hieu T.; Smeulders, Arnold W. M.			Robust tracking using foreground-background texture discrimination	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						visual tracking; forearound/background discrimination; texture; linear discriminant analysis		This paper conceives of tracking as the developing distinction of a foreground against the background. In this manner, fast changes in the object or background appearance can be dealt with. When modelling the target alone (and not its distinction from the background), changes of lighting or changes of viewpoint can invalidate the internal target model. As the main contribution, we propose a new model for the detection of the target using fore around/back around texture discrimination. The background is represented as a set of texture patterns. During tracking, the algorithm maintains a set of discriminant functions each distinguishing one pattern in the object region from background patterns in the neighborhood of the obect. The idea is to train the foreground/background discrimination dynamically, that is while the tracking develops. In our case, the discriminant functions are efficiently trained online using a differential version of Linear Discriminant Analysis (LDA). Object detection is performed by maximizing the sum of all discriminant functions. The method employs two complementary sources of information: it searches for the image region similar to the target object, and simultaneously it seeks to avoid background patterns seen before. The detection result is therefore less sensitive to sudden changes in the appearance of the object than in methods relying solely on similarity to the target. The experiments show robust performance under severe changes of viewpoint or abrupt changes of lighting.	Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA; Univ Amsterdam, Fac Sci, Intelligent Sensory Informat Syst, NL-1098 SJ Amsterdam, Netherlands	Rensselaer Polytechnic Institute; University of Amsterdam	Nguyen, HT (corresponding author), Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA.	nguyeh2@rpi.edu; smeulders@science.uva.nl						Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53; BLACK MJ, 1996, P EUR C COMP VIS, P329; Chen HT, 2004, INT C PATT RECOG, P736; Chomat O., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P104, DOI 10.1109/CVPR.1999.784616; CHOMAT O, 2003, P IEEE C COMP VIS, P346; Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761; Cootes TF, 2002, IMAGE VISION COMPUT, V20, P657, DOI 10.1016/S0262-8856(02)00055-0; DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676; DAVON D, 1977, COGNITIVE PSYCHOL, V9, P353; Duda P.E.H.R.O., 2001, PATTERN CLASSIFICATI; FIREDMAN N, 1997, P 13 C UNC ART INT, P175; Gong SG, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P265, DOI 10.1109/AFGR.1996.557275; Hayman E, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P67; Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594; JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S; Jepson AD, 2001, PROC CVPR IEEE, P415; Jojic N, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P34; Lucas B.D., 1981, P INT JOINT C ART IN, P121, DOI DOI 10.5334/JORS.BL; Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16; Nguyen HT, 2004, LECT NOTES COMPUT SC, V3022, P446; Nguyen HT, 2004, IEEE T PATTERN ANAL, V26, P1099, DOI 10.1109/TPAMI.2004.45; Ravela S, 1996, IMAGE UNDERSTANDING WORKSHOP, 1996 PROCEEDINGS, VOLS I AND II, P1345; Rittscher J., 2000, PROC EUR C COMPUT VI, P336; ROSS D, 2004, P 8 EUR C COMP VIS, V2, P470; Roth S, 2004, PROC CVPR IEEE, P886; Sidenbladh H, 2003, INT J COMPUT VISION, V54, P181, DOI 10.1023/A:1023765619733; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; SULLIVAN J, 2000, P EUR C COMP VIS, P307; Tao H, 2000, PROC CVPR IEEE, P134, DOI 10.1109/CVPR.2000.854760; TORRALBA A, 2001, P IEEE C COMP VIS; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236; Wu Y, 2000, PROC CVPR IEEE, P133, DOI 10.1109/CVPR.2000.855810	32	65	81	0	12	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2006	69	3					277	293		10.1007/s11263-006-7067-x	http://dx.doi.org/10.1007/s11263-006-7067-x			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	067YM					2022-12-18	WOS:000239338700002
J	Sarti, A; Malladi, R; Sethian, JA				Sarti, A; Malladi, R; Sethian, JA			Subjective surfaces: A geometric model for boundary completion	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						subjective surfaces; segmentation; perceptual contours; level sets; differential geometry; Riemannian geometry; surface evolution	MINIMAL-SURFACES; CURVATURE; SHAPE	We present a geometric model and a computational method for segmentation of images with missing boundaries. In many situations, the human visual system fills in missing gaps in edges and boundaries, building and completing information that is not present, Boundary completion presents a considerable challenge in computer vision, since most algorithms attempt to exploit existing data. A large body of work concerns, completion models, which postulate how to construct missing data; these models are often trained and specific to particular images. In this paper, we take the following, alternative perspective: we consider a given reference point within the image, and then develop an algorithm which tries to build missing information on the basis of the given point of view and the available information as boundary data to the algorithm. Starting from this point of view, a surface is constructed. It is then evolved with the mean curvature flow in the metric induced by the image until a piecewise constant solution is reached. We test the computational model on modal completion, amodal completion, and texture segmentation. We extend the geometric model and the algorithm to 3D in order to extract shapes from low signal/noise ratio ultrasound image volumes. Results in 3D echocardiography and 3D fetal echography are also presented.	Univ Bologna, DEIS, I-40126 Bologna, Italy; Univ Calif Berkeley, Lawrence Berkeley Lab, Dept Math, Berkeley, CA 94720 USA	University of Bologna; United States Department of Energy (DOE); Lawrence Berkeley National Laboratory; University of California System; University of California Berkeley	Sarti, A (corresponding author), Univ Bologna, DEIS, I-40126 Bologna, Italy.	asarti@deis.unibo.it; malladi@euphrates.lbl.gov; sethian@math.berkeley.edu						Caselles V, 1997, IEEE T PATTERN ANAL, V19, P394, DOI 10.1109/34.588023; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685; CHAN TF, 1998, 9853 CAM UCLA DEP MA; Do Carmo M., 1976, DIFFERENTIAL GEOMETR; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; GIAQUINTA M., 1996, CALCULUS VARIATIONS, V1-2; GREGORY RL, 1972, NATURE, V238, P51, DOI 10.1038/238051a0; JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0; KANIZSA G, 1976, SCI AM, V234, P48, DOI 10.1038/scientificamerican0476-48; Kanizsa G., 1979, ORG VISION; KANIZSA G, 1980, GRAMMATICA VEDERE, V2; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kimmel R, 2000, INT J COMPUT VISION, V39, P111, DOI 10.1023/A:1008171026419; Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406; LEVEQUE RJ, 1992, NUMERICAL METHOD CON; MALIK J, 1999, INT C COMP VIS SEPT; MALIK J, 2000, PERCEPTUAL ORG ARTIF; Malladi R, 1996, GRAPH MODEL IM PROC, V58, P127, DOI 10.1006/gmip.1996.0011; Malladi R, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P304, DOI 10.1109/ICCV.1998.710735; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; MALLADI R, 1993, SPIE P GEOM METH COM, V2, P246; Marr D., 1982, VISION; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; MUMFORD D., 1993, ALGEBRAIC GEOMETRY I; NISHIKAWA S, 1996, GEOMETRIC VARIATIONA; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; PERONA P, 1995, IEEE T PATTERN ANAL, V17, P488, DOI 10.1109/34.391394; PERONA P, 1987, P IEEE COMP SOC WORK; Romeny B.M., 1994, GEOMETRY DRIVEN DIFF; Sarti A, 1999, IEEE T MED IMAGING, V18, P453, DOI 10.1109/42.781012; Sarti A, 2000, P NATL ACAD SCI USA, V97, P6258, DOI 10.1073/pnas.110135797; Sarti A, 2000, IEEE T BIO-MED ENG, V47, P1600, DOI 10.1109/10.887941; SARTI A, UNPUB ELASTIC SUBJEC; SARTI A, 2002, LBNL44442; SARTI A, 1999, GEOMETRIC METHODS BI; SAUND E, 1999, PERCEPTUAL ORG OCCLU; Sethian J. A., 1999, LEVEL SET METHODS FA; Sethian J.A., 1987, VARIATIONAL METHODS; SETHIAN JA, 1985, COMMUN MATH PHYS, V101, P487, DOI 10.1007/BF01210742; Sochen N, 1998, IEEE T IMAGE PROCESS, V7, P310, DOI 10.1109/83.661181; Williams LR, 1997, NEURAL COMPUT, V9, P859, DOI 10.1162/neco.1997.9.4.859; Williams LR, 1997, NEURAL COMPUT, V9, P837, DOI 10.1162/neco.1997.9.4.837	43	65	65	0	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	FEB-MAR	2002	46	3					201	221		10.1023/A:1014028906229	http://dx.doi.org/10.1023/A:1014028906229			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	536MN					2022-12-18	WOS:000174706700002
J	Meijering, EHW; Zuiderveld, KJ; Viergever, MA				Meijering, EHW; Zuiderveld, KJ; Viergever, MA			Image registration for digital subtraction angiography	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						digital subtraction angiography; motion correction; registration; matching; warping	SIMILARITY MEASURES; SUBPIXEL ACCURACY; MAPPING FUNCTIONS; ALGORITHM; CRITERION	In clinical practice, Digital Subtraction Angiography (DSA) is a powerful technique for the visualization of blood vessels in the human body. The diagnostic relevance of the images is often reduced by artifacts which arise from the misalignment of successive images in the sequence, due to patient motion. In order to improve the quality of the subtraction images, several registration techniques have been proposed. However, because of the required computation times, it has never led to algorithms that are fast enough so as to be acceptable for integration in clinical applications. In this paper, a new approach to the registration of digital angiographic images is proposed. It involves an edge-based selection of control points for which the displacement is computed by means of template matching, and from which the complete displacement vector field is constructed by means of interpolation. The final warping of the images according to the calculated displacement vector field is performed real-time by graphics hardware. Experimental results with several clinical data sets show that the proposed algorithm is both effective and very fast.	Univ Utrecht Hosp, Image Sci Inst, NL-3508 GA Utrecht, Netherlands	Utrecht University; Utrecht University Medical Center	Meijering, EHW (corresponding author), Univ Utrecht Hosp, Image Sci Inst, HP E01-334,POB 85500, NL-3508 GA Utrecht, Netherlands.	erik@isi.uu.nl; karel@vitalimages.com; max@isi.uu.nl	Viergever, Max A/J-1215-2014; Meijering, Erik/AAL-8143-2020					AGGARWAL JK, 1988, P IEEE, V76, P917, DOI 10.1109/5.5965; Althof RJ, 1997, IEEE T MED IMAGING, V16, P308, DOI 10.1109/42.585765; BARNEA DI, 1972, IEEE T COMPUT, VC 21, P179, DOI 10.1109/TC.1972.5008923; BEIER T, 1992, COMP GRAPH, V26, P35, DOI 10.1145/142920.134003; BRODY WR, 1982, IEEE T NUCL SCI, V29, P1176, DOI 10.1109/TNS.1982.4336336; BRODY WR, 1981, RADIOLOGY, V139, P297, DOI 10.1148/radiology.139.2.7012922; BRODY WR, 1981, RADIOLOGY, V141, P828, DOI 10.1148/radiology.141.3.7029620; BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374; Buzug TM, 1997, LECT NOTES COMPUT SC, V1205, P203, DOI 10.1007/BFb0029239; Buzug TM, 1996, INT CONGR SER, V1124, P145; BUZUG TM, 1997, LECT NOTES COMPUTER, V1296, P106; CANNY JF, 1986, PAMI, V8, P6, DOI DOI 10.1109/TPAMI.1986.4767851; CHIANG JY, 1993, IEEE T MED IMAGING, V12, P30, DOI 10.1109/42.222663; CHILCOTE WA, 1981, RADIOLOGY, V139, P287, DOI 10.1148/radiology.139.2.7012921; Cox G., 1995, REV TEMPLATE MATCHIN; COX GS, 1994, PROC SPIE, V2167, P188; DAVIS LS, 1983, COMPUT VISION GRAPH, V23, P313, DOI 10.1016/0734-189X(83)90029-4; FITZPATRICK JM, 1988, COMPUT VISION GRAPH, V44, P155, DOI 10.1016/S0734-189X(88)80003-3; FITZPATRICK JM, 1988, INFORMATION PROCESSI, P415; FLUSSER J, 1992, PATTERN RECOGN, V25, P45, DOI 10.1016/0031-3203(92)90005-4; FOGEL SV, 1991, CVGIP-IMAG UNDERSTAN, V53, P253, DOI 10.1016/1049-9660(91)90015-H; Foley J. D., 1990, SYSTEMS PROGRAMMING; GOSHTASBY A, 1986, PATTERN RECOGN, V19, P459, DOI 10.1016/0031-3203(86)90044-0; GOSHTASBY A, 1986, IEEE T GEOSCI REMOTE, V24, P390, DOI 10.1109/TGRS.1986.289597; GOSHTASBY A, 1987, PATTERN RECOGN, V20, P525, DOI 10.1016/0031-3203(87)90079-3; HECKBERT PS, 1986, IEEE COMPUT GRAPH, V6, P56, DOI 10.1109/MCG.1986.276672; HILDRETH EC, 1983, COMPUT VISION GRAPH, V22, P1, DOI 10.1016/0734-189X(83)90093-2; HILDRETH EC, 1984, PROC R SOC SER B-BIO, V221, P189, DOI 10.1098/rspb.1984.0030; HILLMAN BJ, 1981, RADIOLOGY, V139, P277, DOI 10.1148/radiology.139.2.7012919; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HUA P, 1993, P SOC PHOTO-OPT INS, V1898, P24, DOI 10.1117/12.154515; KRUGER RA, 1977, RADIOLOGY, V125, P243, DOI 10.1148/125.1.243; KRUGER RA, 1983, RADIOLOGY, V147, P863, DOI 10.1148/radiology.147.3.6342037; KRUGER RA, 1982, RADIOLOGY, V145, P315, DOI 10.1148/radiology.145.2.6753015; KRUGER RA, 1984, RADIOLOGY, V152, P805, DOI 10.1148/radiology.152.3.6379747; Lawson CL, 1977, MATH SOFTWARE, P161, DOI [10.1016/B978-0-12-587260-7.50011-X, DOI 10.1016/B978-0-12-587260-7.50011-X]; LEE DT, 1980, INT J COMPUT INF SCI, V9, P219, DOI 10.1007/BF00977785; Maintz J B, 1998, Med Image Anal, V2, P1, DOI 10.1016/S1361-8415(01)80026-8; MANDAVA VR, 1989, IEEE T MED IMAGING, V8, P251, DOI 10.1109/42.34714; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MISTRETTA CA, 1973, INVEST RADIOL, V8, P402, DOI 10.1097/00004424-197311000-00006; NEIDER J, 1995, OPENGL PROGRAMMING G; OUNG H, 1984, P SOC PHOTO-OPT INST, V515, P336; OUSTERHOUT JK, 1994, PROFESSIONAL COMPUTI; POTEL MJ, 1983, IEEE FRONTIERS ENG C, P166; POWELL MJD, 1964, COMPUT J, V7, P155, DOI 10.1093/comjnl/7.2.155; PRATT WK, 1974, IEEE T AERO ELEC SYS, VAE10, P353, DOI 10.1109/TAES.1974.307828; RUPRECHT D, 1995, IEEE COMPUT GRAPH, V15, P37, DOI 10.1109/38.365004; RUPRECHT D, 1994, THESIS U DORTMUND; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; STOCKMAN G, 1982, IEEE T PATTERN ANAL, V4, P229, DOI 10.1109/TPAMI.1982.4767240; STROUSTRUP B, 1991, CPLUSPLUS PROGRAMMIN; Szeliski R, 1997, INT J COMPUT VISION, V22, P199, DOI 10.1023/A:1007996332012; Tomasi C., 1991, CMUCS91132 SCH COMP; VANDENELSEN PA, 1993, IEEE ENG MED BIOL, V12, P26, DOI 10.1109/51.195938; VANTRAN L, 1992, IEEE T MED IMAGING, V11, P407, DOI 10.1109/42.158945; VENOT A, 1984, COMPUT VISION GRAPH, V28, P176, DOI 10.1016/S0734-189X(84)80020-1; VENOT A, 1994, IEEE T MED IMAGING, V13, P565, DOI 10.1109/42.310889; Venot A, 1984, IEEE Trans Med Imaging, V3, P179, DOI 10.1109/TMI.1984.4307678; VERHOEVEN LAJ, 1985, THESIS DELFT U TECHN; WATSON DF, 1984, COMPUT VISION GRAPH, V26, P217, DOI 10.1016/0734-189X(84)90184-1; WATSON DF, 1981, COMPUT J, V24, P167, DOI 10.1093/comjnl/24.2.167; Wolberg G, 1990, DIGITAL IMAGE WARPIN; YANAGISAWA M, 1984, P 7 INT C PATT REC, V2, P1288; ZUIDERVELD KJ, 1989, P SOC PHOTO-OPT INS, V1137, P22, DOI 10.1117/12.961712	65	65	89	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	1999	31	2-3					227	246		10.1023/A:1008074100927	http://dx.doi.org/10.1023/A:1008074100927			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	209NA					2022-12-18	WOS:000081053100009
J	Cheng, MM; Fan, DP				Cheng, Ming-Ming; Fan, Deng-Ping			Structure-Measure: A New Way to Evaluate Foreground Maps	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						S-measure; Structure measure; Foreground maps; Evaluation; Salient object detection	SALIENT OBJECT DETECTION; IMAGE; MODEL; RETRIEVAL	Foreground map evaluation is crucial for gauging the progress of object segmentation algorithms, in particular in the field of salient object detection where the purpose is to accurately detect and segment the most salient object in a scene. Several measures (e.g., area-under-the-curve, F1-measure, average precision, etc.) have been used to evaluate the similarity between a foreground map and a ground-truth map. The existing measures are based on pixel-wise errors and often ignore the structural similarities. Behavioral vision studies, however, have shown that the human visual system is highly sensitive to structures in scenes. Here, we propose a novel, efficient (0.005 s per image), and easy to calculate measure known as S-measure (structural measure) to evaluate foreground maps. Our new measure simultaneously evaluates region-aware and object-aware structural similarity between a foreground map and a ground-truth map. We demonstrate superiority of our measure over existing ones using 4 meta-measures on 5 widely-used benchmark datasets. Furthermore, we conduct a behavioral judgment study over a new database. Data from 45 subjects shows that on average they preferred the saliency maps chosen by our measure over the saliency maps chosen by the state-of-the-art measures. Our experimental results offer new insights into foreground map evaluation where current measures fail to truly examine the strengths and weaknesses of models. Code: https://github.com/DengPingFan/S-measure.	[Cheng, Ming-Ming; Fan, Deng-Ping] Nankai Univ, Coll Comp Sci, Tianjin, Peoples R China	Nankai University	Cheng, MM (corresponding author), Nankai Univ, Coll Comp Sci, Tianjin, Peoples R China.	cmm@nankai.edu.cn; dengpfan@gmail.com	Cheng, Ming-Ming/A-2527-2009; Fan, Deng-Ping/ABD-4052-2020	Cheng, Ming-Ming/0000-0001-5550-8758; Fan, Deng-Ping/0000-0002-5245-7518	National Key Research and Development Program of China [2018AAA0100400]; NSFC [61922046]; S&T innovation project from Chinese Ministry of Education	National Key Research and Development Program of China; NSFC(National Natural Science Foundation of China (NSFC)); S&T innovation project from Chinese Ministry of Education	This research was supported by the National Key Research and Development Program of China under Grant No. 2018AAA0100400, NSFC (61922046), and S&T innovation project from Chinese Ministry of Education.	Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596; Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Best D. J., 1975, Applied Statistics, V24, P377, DOI 10.2307/2347111; Borji A, 2015, IEEE T IMAGE PROCESS, V24, P742, DOI 10.1109/TIP.2014.2383320; Borji A, 2013, VISION RES, V91, P62, DOI 10.1016/j.visres.2013.07.016; Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727; Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89; Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30; Bylinskii Z, 2015, MIT SALIENCY BENCHMA; Chang KY, 2011, IEEE I CONF COMP VIS, P914, DOI 10.1109/ICCV.2011.6126333; Chen H, 2018, PROC CVPR IEEE, P3051, DOI 10.1109/CVPR.2018.00322; Chen TS, 2016, IEEE T NEUR NET LEAR, V27, P1135, DOI 10.1109/TNNLS.2015.2506664; Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI 10.1007/s11263-021-01490-8; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fan D.-P., 2021, SCI SINICA INFORM, V6, DOI [10.1360/SSI-2020-0370, DOI 10.1360/SSI-2020-0370]; Fan D-P, ARXIV PREPRINT ARXIV; Fan DP, 2021, IEEE T PATTERN ANAL, V44, P4339, DOI 10.1109/TPAMI.2021.3060412; Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406; FENG D, 2016, PROC CVPR IEEE, P2343, DOI DOI 10.1109/CVPR.2016.257; Fu KR, 2022, IEEE T PATTERN ANAL, V44, P5541, DOI 10.1109/TPAMI.2021.3073689; Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272; Gorji S, 2018, PROC CVPR IEEE, P7501, DOI 10.1109/CVPR.2018.00783; Guanghai Liu, 2013, 2013 International Conference on Information Science and Cloud Computing Companion (ISCC-C), P728, DOI 10.1109/ISCC-C.2013.21; Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969; Huang Q, 2020, AAAI C ART INT; Islam MA, 2018, PROC CVPR IEEE, P7142, DOI 10.1109/CVPR.2018.00746; Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657; Ji YZ, 2021, IEEE T NEUR NET LEAR, V32, P2676, DOI 10.1109/TNNLS.2020.3007534; Jiang HZ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.110; Jiang Y, 2020, ARXIVABS201004968; Jirong Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P653, DOI 10.1007/978-3-030-58452-8_38; Kanan C, 2010, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2010.5539947; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78; Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820; Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005; Li GB, 2018, PROC CVPR IEEE, P3243, DOI 10.1109/CVPR.2018.00342; Li GB, 2017, PROC CVPR IEEE, P247, DOI 10.1109/CVPR.2017.34; Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58; Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184; Li L, 2013, IEEE MULTIMEDIA, V20, P13, DOI 10.1109/MMUL.2013.15; Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370; Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43; Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005; Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326; Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80; Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70; Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1937, DOI 10.1109/TIP.2014.2307434; Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39; Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Mei HY, 2021, PROC CVPR IEEE, P8768, DOI 10.1109/CVPR46437.2021.00866; PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J; Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7; Piao YR, 2020, AAAI CONF ARTIF INTE, V34, P11865; Pont-Tuset J, 2013, PROC CVPR IEEE, P2131, DOI 10.1109/CVPR.2013.277; Rutishauser U., 2004, P 2004 IEEE COMP SOC, DOI [DOI 10.1109/CVPR.2004.1315142, 10.1109/cvpr.2004.1315142]; Shao L., 2021, ARXIV PREPRINT ARXIV; Shao L, IEEE C COMP VIS PATT; Shao L., ARXIV210107663; Tai Y. W, IEEE C COMP VIS PATT; Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50; Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330; Wang WG, 2018, PROC CVPR IEEE, P1711, DOI 10.1109/CVPR.2018.00184; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Xiaoqi Zhao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P646, DOI 10.1007/978-3-030-58542-6_39; Xie YL, 2013, IEEE T IMAGE PROCESS, V22, P1689, DOI 10.1109/TIP.2012.2216276; Yu QH, 2018, PROC CVPR IEEE, P8280, DOI 10.1109/CVPR.2018.00864; Zeng Y, 2019, IEEE I CONF COMP VIS, P7233, DOI 10.1109/ICCV.2019.00733; Zeng Y, 2018, PROC CVPR IEEE, P1644, DOI 10.1109/CVPR.2018.00177; Zhai Q, 2021, PROC CVPR IEEE, P12992, DOI 10.1109/CVPR46437.2021.01280; Zhang J, 2022, IEEE T PATTERN ANAL, V44, P5761, DOI 10.1109/TPAMI.2021.3073564; Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187; Zhang M, 2019, ADV NEUR IN, V32; ZHANG PP, 2017, IEEE I CONF COMP VIS, P202, DOI DOI 10.1109/ICCV.2017.31; Zhang Q, 2020, IEEE T IMAGE PROCESS, V29, P3321, DOI 10.1109/TIP.2019.2959253; Zhang Qijian, 2020, ADV NEURAL INFORM PR, V1; Zhang W, 2018, IEEE CONF COMPUT; Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081; Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887; Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731; Zhou T, 2021, COMPUT VIS MEDIA, V7, P37, DOI 10.1007/s41095-020-0199-z	86	64	67	6	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2021	129	9					2622	2638		10.1007/s11263-021-01490-8	http://dx.doi.org/10.1007/s11263-021-01490-8		JUN 2021	17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	TS1RN		Green Submitted			2022-12-18	WOS:000667120500001
J	Jin, YH; Mishkin, D; Mishchuk, A; Matas, J; Fua, P; Yi, KM; Trulls, E				Jin, Yuhe; Mishkin, Dmytro; Mishchuk, Anastasiia; Matas, Jiri; Fua, Pascal; Yi, Kwang Moo; Trulls, Eduard			Image Matching Across Wide Baselines: From Paper to Practice	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Benchmark; Dataset; Stereo; Structure from motion; Local features; 3D reconstruction	PERFORMANCE	We introduce a comprehensive benchmark for local features and robust estimation algorithms, focusing on the downstream task-the accuracy of the reconstructed camera pose-as our primary metric. Our pipeline's modular structure allows easy integration, configuration, and combination of different methods and heuristics. This is demonstrated by embedding dozens of popular algorithms and evaluating them, from seminal works to the cutting edge of machine learning research. We show that with proper settings, classical solutions may still outperform the perceived state of the art. Besides establishing the actual state of the art, the conducted experiments reveal unexpected properties of structure from motion pipelines that can help improve their performance, for both algorithmic and learned methods. Data and code are online (https://github.com/ubcvision/image-matching-benchmark), providing an easy-to-use and flexible framework for the benchmarking of local features and robust estimation methods, both alongside and against top-performing methods. This work provides a basis for the Image Matching Challenge (https://image-matching-challenge.github.io).	[Jin, Yuhe; Yi, Kwang Moo] Univ British Columbia, Vancouver, BC, Canada; [Mishkin, Dmytro; Matas, Jiri] Czech Tech Univ, Visual Recognit Grp, Fac Elect Engn, Prague, Czech Republic; [Mishchuk, Anastasiia; Fua, Pascal] Ecole Polytech Fed Lausanne, Comp Vis Lab, Lausanne, Switzerland; [Trulls, Eduard] Google Res, Zurich, Switzerland	University of British Columbia; Czech Technical University Prague; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Google Incorporated	Trulls, E (corresponding author), Google Res, Zurich, Switzerland.	yuhejin@cs.ubc.ca; ducha.aiki@gmail.com; anastasiia.mishchuk@epfl.ch; matas@fel.cvut.cz; pascal.fua@epfl.ch; kmyi@cs.ubc.ca; trulls@google.com	, Matas/AAW-3282-2020; Mishkin, Dmytro/GSI-5311-2022	Mishkin, Dmytro/0000-0001-8205-6718; Trulls, Eduard/0000-0002-1425-7881	Natural Sciences and Engineering Research Council of Canada (NSERC) Discovery Grant "Deep Visual Geometry Machines" [RGPIN-2018-03788]; Google's Visual Positioning Service; OP VVV [CZ.02.1.01/0.0/0.0/16 019/0000765]; CTU [SGS17/185/OHK3/3T/13]; Austrian Ministry for Transport, Innovation and Technology; Federal Ministry for Digital and Economic Affairs; Province of Upper Austria; Swiss National Science Foundation	Natural Sciences and Engineering Research Council of Canada (NSERC) Discovery Grant "Deep Visual Geometry Machines"(Natural Sciences and Engineering Research Council of Canada (NSERC)); Google's Visual Positioning Service(Google Incorporated); OP VVV; CTU; Austrian Ministry for Transport, Innovation and Technology; Federal Ministry for Digital and Economic Affairs; Province of Upper Austria; Swiss National Science Foundation(Swiss National Science Foundation (SNSF)European Commission)	This work was partially supported by the Natural Sciences and Engineering Research Council of Canada (NSERC) Discovery Grant "Deep Visual Geometry Machines" (RGPIN-2018-03788), by systems supplied by Compute Canada, and by Google's Visual Positioning Service. DM and JM were supported by OP VVV funded Project CZ.02.1.01/0.0/0.0/16 019/0000765 "Research Center for Informatics". DM was also supported by CTU student Grant SGS17/185/OHK3/3T/13 and by the Austrian Ministry for Transport, Innovation and Technology, the Federal Ministry for Digital and Economic Affairs, and the Province of Upper Austria in the frame of the COMET center SCCH. AM was supported by the Swiss National Science Foundation.	Aanaes H., 2002, ESTIMATION DEFORMABL; Aanaes H, 2012, INT J COMPUT VISION, V97, P18, DOI 10.1007/s11263-011-0473-8; Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148; Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715; Alcantarilla PF, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.13; Aldana-Iuit J, 2019, SADDLE FAST REPEATAB, V97, P3807, DOI [10.1016/j.imavis.2019.08.011, DOI 10.1016/J.IMAVIS.2019.08.011]; ARANDJELOVIC R, 2016, C COMP VIS PATT REC; Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018; Badino Hernan, 2011, CMU VISUAL LOCALIZAT; Balntas V., 2018, SILDA MULTITASK DATA; Balntas V, 2018, LECT NOTES COMPUT SC, V11218, P782, DOI 10.1007/978-3-030-01264-9_46; Balntas V, 2017, PROC CVPR IEEE, P3852, DOI 10.1109/CVPR.2017.410; Balntas Vassileios, 2016, BMVC, V2, DOI DOI 10.5244/C.30.119; Barath D, 2019, PROC CVPR IEEE, P10189, DOI 10.1109/CVPR.2019.01044; Barath D, 2018, PROC CVPR IEEE, P6733, DOI 10.1109/CVPR.2018.00704; Barroso-Laguna A, 2019, IEEE I CONF COMP VIS, P5835, DOI 10.1109/ICCV.2019.00593; Baumberg A, 2000, PROC CVPR IEEE, P774, DOI 10.1109/CVPR.2000.855899; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Beaudet P. R., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition, P579; Bellavia F, 2020, INT J COMPUT VISION, V128, P1847, DOI 10.1007/s11263-020-01297-z; Bian J.-W., 2019, PROC BRIT MACH VIS C; Brachmann E, 2019, IEEE I CONF COMP VIS, P4321, DOI 10.1109/ICCV.2019.00442; Bradski G, 2000, DR DOBBS J, V25, P120; Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3; Brown M, 2011, IEEE T PATTERN ANAL, V33, P43, DOI 10.1109/TPAMI.2010.54; Bui M, 2019, IEEE INT CONF COMP V, P3778, DOI 10.1109/ICCVW.2019.00470; Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221; Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236; Cui HN, 2017, PROC CVPR IEEE, P2393, DOI 10.1109/CVPR.2017.257; Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693; Dang Z, 2018, LECT NOTES COMPUT SC, V11209, P792, DOI 10.1007/978-3-030-01228-1_47; Detone D., 2017, PREPRINT ARXIV170707; DeTone D, 2018, IEEE COMPUT SOC CONF, P337, DOI 10.1109/CVPRW.2018.00060; Dey S, 2018, PROC INT CONF RECON; Dong JM, 2015, PROC CVPR IEEE, P5097, DOI 10.1109/CVPR.2015.7299145; Dusmanu M, 2019, PROC CVPR IEEE, P8084, DOI 10.1109/CVPR.2019.00828; Ebel P, 2019, IEEE I CONF COMP VIS, P253, DOI 10.1109/ICCV.2019.00034; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Gay P, 2017, IEEE I CONF COMP VIS, P3094, DOI 10.1109/ICCV.2017.334; Geiger A., 2012, P IEEE COMP SOC C CO; HARTLEY RI, 1994, IEEE T PATTERN ANAL, V16, P1036, DOI 10.1109/34.329005; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; He K, 2018, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2018.00069; Heinly J, 2015, PROC CVPR IEEE, P3287, DOI 10.1109/CVPR.2015.7298949; Jacobs N, 2007, IEEE I CONF COMP VIS, P1305; Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336; Krishna Murthy J., 2019, GRADSLAM DENSE SLAM; Lenc K., 2011, VLBENCHMARKS; Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542; Li HP, 2019, INT CONF IMAG VIS; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; LUO Z, 2019, C COMP VIS PATT REC; Luo ZX, 2018, LECT NOTES COMPUT SC, V11213, P170, DOI 10.1007/978-3-030-01240-3_11; Lynen S., 2019, PREPRINT; Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498; Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mikolajczyk K, 2004, LECT NOTES COMPUT SC, V3021, P69; Mishchuk Anastasiya, 2017, ADV NEURAL INFORM PR; Mishkin D, 2018, LECT NOTES COMPUT SC, V11213, P287, DOI 10.1007/978-3-030-01240-3_18; Mishkin D, 2015, COMPUT VIS IMAGE UND, V141, P81, DOI 10.1016/j.cviu.2015.08.005; Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331; Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671; Nister D, 2003, PROC CVPR IEEE, P195; Noh H, 2017, IEEE I CONF COMP VIS, P3476, DOI 10.1109/ICCV.2017.374; Ono Y, 2018, ADV NEUR IN, V31; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X; Pritchett P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P754, DOI 10.1109/ICCV.1998.710802; Pultar M., 2019, COMP VIS WINT WORKSH; Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0_1; Ranftl R, 2018, LECT NOTES COMPUT SC, V11205, P292, DOI 10.1007/978-3-030-01246-5_18; Revaud J, 2019, ADV NEUR IN, V32; Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275; Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544; Sarlin PE, 2020, PROC CVPR IEEE, P4937, DOI 10.1109/CVPR42600.2020.00499; Sattler T, 2019, PROC CVPR IEEE, P3297, DOI 10.1109/CVPR.2019.00342; Sattler T, 2018, PROC CVPR IEEE, P8601, DOI 10.1109/CVPR.2018.00897; Sattler T, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.76; Sattler T, 2012, LECT NOTES COMPUT SC, V7572, P752, DOI 10.1007/978-3-642-33718-5_54; Savinov N, 2017, PROC CVPR IEEE, P3929, DOI 10.1109/CVPR.2017.418; Schonberger JL, 2017, PROC CVPR IEEE, P6959, DOI 10.1109/CVPR.2017.736; Schonberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445; Schonberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31; Shi Y., 2019, PREPRINT; Simo-Serra E, 2015, IEEE I CONF COMP VIS, P118, DOI 10.1109/ICCV.2015.22; Strecha C, 2008, PROC CVPR IEEE, P2838; Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773; Sun W., 2020, P IEEECVF C COMPUTER, P11286; Taira H, 2021, IEEE T PATTERN ANAL, V43, P1293, DOI 10.1109/TPAMI.2019.2952114; Tang Chengzhou, 2019, P ICLR; Tateno K, 2017, PROC CVPR IEEE, P6565, DOI 10.1109/CVPR.2017.695; Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802; Tian YR, 2019, PROC CVPR IEEE, P11008, DOI 10.1109/CVPR.2019.01127; Tian YR, 2017, PROC CVPR IEEE, P6128, DOI 10.1109/CVPR.2017.649; Tolias G, 2016, INT J COMPUT VISION, V116, P247, DOI 10.1007/s11263-015-0810-4; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298; Vedaldi Andrea, 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249; Verdie Y, 2015, PROC CVPR IEEE, P5279, DOI 10.1109/CVPR.2015.7299165; Vijayanarasimhan Sudheendra, 2017, ARXIV170407804; Wei X, 2018, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2018.00200; Wu CC, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P127, DOI 10.1109/3DV.2013.25; Xingkui Wei, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P230, DOI 10.1007/978-3-030-58452-8_14; Yi KM, 2018, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2018.00282; Yi KM, 2016, LECT NOTES COMPUT SC, V9910, P467, DOI 10.1007/978-3-319-46466-4_28; Yoo AB, 2003, LECT NOTES COMPUT SC, V2862, P44; ZAGORUYKO S, 2015, 2015 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2015.7299064; Zhang JH, 2019, IEEE I CONF COMP VIS, P5844, DOI 10.1109/ICCV.2019.00594; Zhao C, 2019, PROC CVPR IEEE, P215, DOI 10.1109/CVPR.2019.00030; Zhou QJ, 2020, IEEE INT CONF ROBOT, P3319, DOI 10.1109/ICRA40945.2020.9196607; Zhu SY, 2018, PROC CVPR IEEE, P4568, DOI 10.1109/CVPR.2018.00480; Zitnick CL, 2011, IEEE I CONF COMP VIS, P359, DOI 10.1109/ICCV.2011.6126263	115	64	63	4	20	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	FEB	2021	129	2					517	547		10.1007/s11263-020-01385-0	http://dx.doi.org/10.1007/s11263-020-01385-0		OCT 2020	31	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	QH2HF		Green Submitted			2022-12-18	WOS:000577443300001
J	Plummer, BA; Wang, LW; Cervantes, CM; Caicedo, JC; Hockenmaier, J; Lazebnik, S				Plummer, Bryan A.; Wang, Liwei; Cervantes, Chris M.; Caicedo, Juan C.; Hockenmaier, Julia; Lazebnik, Svetlana			Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Computer vision; Language; Region phrase correspondence; Datasets; Crowdsourcing		The Flickr30k dataset has become a standard benchmark for sentence-based image description. This paper presents Flickr30k Entities, which augments the 158k captions from Flickr30k with 244k coreference chains, linking mentions of the same entities across different captions for the same image, and associating them with 276k manually annotated bounding boxes. Such annotations are essential for continued progress in automatic image description and grounded language understanding. They enable us to define a new benchmark for localization of textual entity mentions in an image. We present a strong baseline for this task that combines an image-text embedding, detectors for common objects, a color classifier, and a bias towards selecting larger objects. While our baseline rivals in accuracy more complex state-of-the-art models, we show that its gains cannot be easily parlayed into improvements on such tasks as image-sentence retrieval, thus underlining the limitations of current methods and the need for further research.	[Plummer, Bryan A.; Wang, Liwei; Cervantes, Chris M.; Hockenmaier, Julia; Lazebnik, Svetlana] Univ Illinois, Urbana, IL 61801 USA; [Caicedo, Juan C.] Broad Inst MIT & Harvard, Boston, MA USA	University of Illinois System; University of Illinois Urbana-Champaign; Harvard University; Massachusetts Institute of Technology (MIT); Broad Institute	Plummer, BA (corresponding author), Univ Illinois, Urbana, IL 61801 USA.	bplumme2@illinois.edu			National Science Foundation [1053856, 1205627, 1405883, 1228082, 1302438, 1563727]; Xerox UAC; Sloan Foundation; Division Of Computer and Network Systems [1405883] Funding Source: National Science Foundation	National Science Foundation(National Science Foundation (NSF)); Xerox UAC; Sloan Foundation(Alfred P. Sloan Foundation); Division Of Computer and Network Systems(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	This material is based upon work supported by the National Science Foundation under Grants No. 1053856, 1205627, 1405883, 1228082, 1302438, 1563727, as well as support from Xerox UAC and the Sloan Foundation. We thank the NVIDIA Corporation for the generous donation of the GPUs used for our experiments.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Devlin J, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P100; Dodge J., 2012, P 2012 C N AM CHAPT, P762; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Everingham M., 2012, PASCAL VISUAL OBJECT; Everingham M., 2008, PASCAL VISUAL OBJECT; Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754; Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2; Fidler S., 2013, CVPR; Fukui Akira, 2016, ARXIV160601847; Gao H., 2015, NIPS; Girshick R., 2015, ICCV; Gong YC, 2014, LECT NOTES COMPUT SC, V8692, P529, DOI 10.1007/978-3-319-10593-2_35; Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4; Grubinger M., 2006, INT WORKSHOP ONTOIMA, V2; Hodosh M., 2010, P 14 C COMP NAT LANG, P162; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; Hu RH, 2016, PROC CVPR IEEE, P4555, DOI 10.1109/CVPR.2016.493; Jingna Mao, 2015, 2015 IEEE Biomedical Circuits and Systems Conference (BioCAS), P1, DOI 10.1109/BioCAS.2015.7348279; Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494; Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Kazemzadeh Sahar, 2014, P 2014 C EMP METH NA, P787, DOI DOI 10.3115/V1/D14-1086; Kiros R, 2014, PR MACH LEARN RES, V32, P595; Klein B, 2015, P IEEE CVF C COMP VI, P4437; Kong C, 2014, PROC CVPR IEEE, P3558, DOI 10.1109/CVPR.2014.455; Krishna Ranjay, 2016, ARXIV160207332; Lebret R, 2015, PR MACH LEARN RES, V37, P2085; Lev G, 2016, LECT NOTES COMPUT SC, V9910, P833, DOI 10.1007/978-3-319-46466-4_50; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Ma L, 2015, IEEE I CONF COMP VIS, P2623, DOI 10.1109/ICCV.2015.301; Malinowski M., 2014, ADV NEURAL INFORM PR, V27, P1682; Mao JH, 2016, PROC CVPR IEEE, P11, DOI 10.1109/CVPR.2016.9; McCarthy J. F., 1995, USING DECISION TREES; Mikolov T., 2013, ARXIV; Ordonez Vicente, 2011, ADV NEURAL INFORM PR, P1143; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303; Ramanathan V., 2014, ECCV; Rashtchian C., 2010, P NAACL HLT 2010 WOR, V2010, P139, DOI DOI 10.1002/ACP.3140; Ren M., 2015, ADV NEURAL INFORM PR, V28, P2953; Rohrbach A, 2016, LECT NOTES COMPUT SC, V9905, P817, DOI 10.1007/978-3-319-46448-0_49; Silberman Nathan, 2012, EUR C COMP VIS, DOI 10.1007/978-3-642-33715-4_54; Soon WM, 2001, COMPUT LINGUIST, V27, P521, DOI 10.1162/089120101753342653; Sorokin A., 2008, INT VIS WORKSH; Su H., 2012, AAAI TECHN REP; Tommasi T., 2016, BMVC; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Wang LM, 2016, PROC CVPR IEEE, P2708, DOI 10.1109/CVPR.2016.296; Wang MZ, 2016, LECT NOTES COMPUT SC, V9912, P696, DOI 10.1007/978-3-319-46484-8_42; Weinberger KQ, 2014, ADV NEURAL INFORM PR, P1889; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Yao BZ, 2010, P IEEE, V98, P1485, DOI 10.1109/JPROC.2010.2050411; Young P., 2014, P TACL, V2, P67, DOI 10.1162/tacl_a_00166; Yu LC, 2015, IEEE I CONF COMP VIS, P2461, DOI 10.1109/ICCV.2015.283; Zhang Jianming, 2016, ECCV, V5, P6; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26; Zitnick CL, 2013, PROC CVPR IEEE, P3009, DOI 10.1109/CVPR.2013.387	64	64	67	3	14	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2017	123	1			SI		74	93		10.1007/s11263-016-0965-7	http://dx.doi.org/10.1007/s11263-016-0965-7			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	ET4SY		Green Submitted			2022-12-18	WOS:000400276400004
J	Basha, T; Moses, Y; Kiryati, N				Basha, Tali; Moses, Yael; Kiryati, Nahum			Multi-view Scene Flow Estimation: A View Centered Variational Approach	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						3D structure; Scene flow; Multiple view	MOTION	We present a novel method for recovering the 3D structure and scene flow from calibrated multi-view sequences. We propose a 3D point cloud parametrization of the 3D structure and scene flow that allows us to directly estimate the desired unknowns. A unified global energy functional is proposed to incorporate the information from the available sequences and simultaneously recover both depth and scene flow. The functional enforces multi-view geometric consistency and imposes brightness constancy and piecewise smoothness assumptions directly on the 3D unknowns. It inherently handles the challenges of discontinuities, occlusions, and large displacements. The main contribution of this work is the fusion of a 3D representation and an advanced variational framework that directly uses the available multi-view information. This formulation allows us to advantageously bind the 3D unknowns in time and space. Different from optical flow and disparity, the proposed method results in a nonlinear mapping between the images' coordinates, thus giving rise to additional challenges in the optimization process. Our experiments on real and synthetic data demonstrate that the proposed method successfully recovers the 3D structure and scene flow despite the complicated nonconvex optimization problem.	[Basha, Tali; Kiryati, Nahum] Tel Aviv Univ, Sch Elect Engn, IL-69978 Tel Aviv, Israel; [Moses, Yael] Interdisciplinary Ctr, Efi Arazi Sch Comp Sci, IL-46150 Herzliyya, Israel	Tel Aviv University; Reichman University	Basha, T (corresponding author), Tel Aviv Univ, Sch Elect Engn, IL-69978 Tel Aviv, Israel.	talib@eng.tau.ac.il			A.M.N. foundation	A.M.N. foundation	The authors are grateful to the A.M.N. foundation for its generous financial support.	Ayvaci A., 2010, ADV NEURAL INFORM PR, P100; Basha T, 2010, PROC CVPR IEEE, P1506, DOI 10.1109/CVPR.2010.5539791; BENARI R, 2007, IEEE 11 INT C COMP V, P1, DOI DOI 10.1109/ICCV.2007.4408996; Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3; Courchay Jerome, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P11; Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4; Furukawa Y., 2008, P IEEE C COMP VIS PA; Huguet F, 2007, IEEE I CONF COMP VIS, P1342, DOI 10.1109/iccv.2007.4409000; Isard M, 2006, LECT NOTES COMPUT SC, V3852, P32; Li R, 2008, COMPUT VIS IMAGE UND, V110, P75, DOI 10.1016/j.cviu.2007.04.002; Min D, 2006, INT C PATT RECOG, P74; Neumann J, 2002, INT J COMPUT VISION, V47, P181, DOI 10.1023/A:1014597925429; Pock T, 2008, LECT NOTES COMPUT SC, V5304, P792, DOI 10.1007/978-3-540-88690-7_59; Pons JP, 2007, INT J COMPUT VISION, V72, P179, DOI 10.1007/s11263-006-8671-5; Robert L., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P439, DOI 10.1007/BFb0015556; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Scharstein D, 2003, PROC CVPR IEEE, P195; Scharstein D, MIDDLEBURY STEREO VI; Strecha C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1194; Vedula S, 2005, IEEE T PATTERN ANAL, V27, P475, DOI 10.1109/TPAMI.2005.63; Vedula S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P722, DOI 10.1109/ICCV.1999.790293; VEDULA S, 2000, P IEEE C COMP VIS PA, V2; Wedel A, 2008, LECT NOTES COMPUT SC, V5302, P739, DOI 10.1007/978-3-540-88682-2_56; Wedel A, 2011, INT J COMPUT VISION, V95, P29, DOI 10.1007/s11263-010-0404-0; Woodford O, 2009, IEEE T PATTERN ANAL, V31, P2115, DOI 10.1109/TPAMI.2009.131; YOUNG D, 1954, T AM MATH SOC, V76, P92, DOI 10.2307/1990745; Zhang Y, 2001, PROC CVPR IEEE, P778; Zhang Y, 2000, PROC CVPR IEEE, P674, DOI 10.1109/CVPR.2000.854939	28	64	67	0	23	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2013	101	1					6	21		10.1007/s11263-012-0542-7	http://dx.doi.org/10.1007/s11263-012-0542-7			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	080XV		Green Submitted			2022-12-18	WOS:000314278500001
J	Ladicky, L; Sturgess, P; Russell, C; Sengupta, S; Bastanlar, Y; Clocksin, W; Torr, PHS				Ladicky, Lubor; Sturgess, Paul; Russell, Chris; Sengupta, Sunando; Bastanlar, Yalin; Clocksin, William; Torr, Philip H. S.			Joint Optimization for Object Class Segmentation and Dense Stereo Reconstruction	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Object class segmentation; Dense stereo reconstruction; Random fields		The problems of dense stereo reconstruction and object class segmentation can both be formulated as Random Field labeling problems, in which every pixel in the image is assigned a label corresponding to either its disparity, or an object class such as road or building. While these two problems are mutually informative, no attempt has been made to jointly optimize their labelings. In this work we provide a flexible framework configured via cross-validation that unifies the two problems and demonstrate that, by resolving ambiguities, which would be present in real world data if the two problems were considered separately, joint optimization of the two problems substantially improves performance. To evaluate our method, we augment the Leuven data set (http://cms.brookes.ac.uk/research/visiongroup/files/Leuven.zip), which is a stereo video shot from a car driving around the streets of Leuven, with 70 hand labeled object class and disparity maps. We hope that the release of these annotations will stimulate further work in the challenging domain of street-view analysis. Complete source code is publicly available (http://cms.brookes.ac.uk/staff/Philip-Torr/ale.htm).	[Ladicky, Lubor] Univ Oxford, Oxford, England; [Sturgess, Paul; Sengupta, Sunando; Torr, Philip H. S.] Oxford Brookes Univ, Oxford OX3 0BP, England; [Russell, Chris] Univ London, London, England; [Bastanlar, Yalin] Izmir Inst Technol, Izmir, Turkey; [Clocksin, William] Univ Hertfordshire, Hatfield AL10 9AB, Herts, England	University of Oxford; Oxford Brookes University; University of London; Izmir Institute of Technology; University of Hertfordshire	Ladicky, L (corresponding author), Univ Oxford, Oxford, England.	lubor@robots.ox.ac.uk; paul.sturgess@brookes.ac.uk; chrisr@eecs.qmul.ac.uk; ssengupta@brookes.ac.uk; yalinbastanlar@iyte.edu.tr; wfc@clocksin.com; philiptorr@brookes.ac.uk	Bastanlar, Yalin/AAA-7114-2022	Bastanlar, Yalin/0000-0002-3774-6872; Russell, Chris/0000-0003-1665-1759	EPSRC; HMGCC; IST Programme of the European Community under the PASCAL2 Network of Excellence [IST-2007-216886]; Royal Society; European Research Council [204871-HUMANIS]	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); HMGCC; IST Programme of the European Community under the PASCAL2 Network of Excellence; Royal Society(Royal Society of London); European Research Council(European Research Council (ERC)European Commission)	This work is supported by EPSRC research grants, HMGCC, the IST Programme of the European Community, under the PASCAL2 Network of Excellence, IST-2007-216886. P. H. S. Torr is in receipt of Royal Society Wolfson Research Merit Award. Chris Russell was partially funded by the European Research Council under the ERC Starting Grant agreement 204871-HUMANIS.	Alahari K., 2010, C COMP VIS PATT REC; Batra D., 2008, C COMP VIS PATT REC; Bleyer M., 2011, C COMP VIS PATT REC; Boykov Y., 2001, T PATTERN ANAL MACHI; Boykov Y., 2004, T PATTERN ANAL MACHI; Boykov Y., 2001, INT C COMP VIS; Brostow G., 2008, EUR C COMP VIS; Comaniciu D., 2002, T PATTERN ANAL MACHI; Dick A. R., 2004, INT J COMPUTER VISIO; Fischler M. A., 1981, COMMUNICATIONS ACM; Gould S., 2009, INT C COMP VIS; Hoiem D., 2007, C COMP VIS PATT REC; Hoiem D., 2006, C COMP VIS PATT REC; Hoiem Derek, 2005, ACM T GRAPHICS; Kohli Pushmeet, 2008, C COMP VIS PATT REC; Kohli Pushmeet, 2007, C COMP VIS PATT REC; Kolmogorov V., 2001, ICCV; Kumar M. P., 2011, J MACHINE LEARNING R; Ladicky L., 2009, INT C COMP VIS; Leibe B., 2007, C COMP VIS PATT REC; Liu B., 2010, C COMP VIS PATT REC; LOWE DG, 2004, INT J COMPUTER VISIO; Rabinovich A., 2007, INT C COMP VIS; Ramalingam S., 2008, C COMP VIS PATT REC; Rother C., 2004, SIGGRAPH; Scharstein Daniel, 2002, INT J COMPUTER VISIO; Shi J., 2000, T PATTERN ANAL MACHI; Shotton J., 2006, EUR C COMP VIS; Sturgess P., 2009, P BMVC BRIT MACH VIS; Taskar B., 2004, INT C MACH LEARN; Torr P. H. S., 1997, INT J COMPUTER VISIO; Torr P. H. S., 2010, UNCERTAINTY ARTIFICI; Torralba A., 2004, C COMP VIS PATT REC; TSOCHANTARIDIS I, 2005, J MACHINE LEARNING R; Woodford O., 2008, C COMP VIS PATT REC; Yotta, 2011, YOTT DCL HOR	36	64	66	0	16	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	2012	100	2					122	133		10.1007/s11263-011-0489-0	http://dx.doi.org/10.1007/s11263-011-0489-0			12	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	000CQ		Green Submitted			2022-12-18	WOS:000308364500002
J	Cremers, D; Sochen, N; Schnorr, C				Cremers, D; Sochen, N; Schnorr, C			A multiphase dynamic labeling model for variational recognition-driven image segmentation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						image segmentation; shape priors; variational methods; level set methods; dynamic labeling; recognition modeling	ACTIVE CONTOURS; SHAPE PRIORS; MUMFORD; COMPETITION; STATISTICS; KNOWLEDGE; SNAKES	We propose a variational framework for the integration of multiple competing shape priors into level set based segmentation schemes. By optimizing an appropriate cost functional with respect to both a level set function and a (vector-valued) labeling function, we jointly generate a segmentation (by the level set function) and a recognition-driven partition of the image domain (by the labeling function) which indicates where to enforce certain shape priors. Our framework fundamentally extends previous work on shape priors in level set segmentation by directly addressing the central question of where to apply which prior. It allows for the seamless integration of numerous shape priors such that-while segmenting both multiple known and unknown objects-the level set process may selectively use specific shape knowledge for simultaneously enhancing segmentation and recognizing shape.	Univ Bonn, Dept Comp Sci, D-5300 Bonn, Germany; Tel Aviv Univ, Dept Appl Math, IL-69978 Tel Aviv, Israel; Univ Mannheim, Dept Math & Comp Sci, D-6800 Mannheim 1, Germany	University of Bonn; Tel Aviv University; University of Mannheim	Cremers, D (corresponding author), Univ Bonn, Dept Comp Sci, D-5300 Bonn, Germany.	cremers@cs.ucla.edu						Brox T, 2004, LECT NOTES COMPUT SC, V3022, P578; CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685; CASELLES V, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P694, DOI 10.1109/ICCV.1995.466871; Chan T., 2003, 0366 UCLA COMP APPL; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Charpiat G, 2005, FOUND COMPUT MATH, V5, P1, DOI 10.1007/s10208-003-0094-x; Chen YM, 2002, INT J COMPUT VISION, V50, P315, DOI 10.1023/A:1020878408985; Cootes T. F., 1992, BMVC92. Proceedings of the British Machine Vision Conference, P9; Cootes TF, 1999, IMAGE VISION COMPUT, V17, P567, DOI 10.1016/S0262-8856(98)00175-9; Cremers D, 2005, INT J COMPUT VISION, V62, P249, DOI 10.1007/s11263-005-4882-4; Cremers D, 2004, LECT NOTES COMPUT SC, V3175, P36; Cremers D, 2003, LECT NOTES COMPUT SC, V2695, P388; Cremers D, 2003, PATTERN RECOGN, V36, P1929, DOI 10.1016/S0031-3203(03)00056-6; Cremers D, 2002, INT J COMPUT VISION, V50, P295, DOI 10.1023/A:1020826424915; CREMERS D, 2004, IN PRESS; Cremers D., 2003, IEEE 2 INT WORKSH VA, P169; CREMERS D, 2004, LNCS, V3024, P74; DERVIEUX A, 1979, SPRINGER LECT NOTES, V771, P145; DERVIEUX A, 1981, LECT NOTE PHYS, V11, P158; Heiler M, 2005, INT J COMPUT VISION, V63, P5, DOI 10.1007/s11263-005-4944-7; KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855; Leventon ME, 2000, PROC CVPR IEEE, P316, DOI 10.1109/CVPR.2000.855835; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068; RAKLINRAVIV T, 2004, LNCS, V3024, P50; Rousson M, 2004, LECT NOTES COMPUT SC, V3216, P209; Rousson M, 2002, LECT NOTES COMPUT SC, V2351, P78; Rousson M, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P56, DOI 10.1109/MOTION.2002.1182214; ROUSSON M, 2005, IN PRESS MICCAI; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Sagiv C, 2001, LECT NOTES COMPUT SC, V2106, P344; SUSSMAN M, 1994, J COMPUT PHYS, V114, P146, DOI 10.1006/jcph.1994.1155; Tsai A, 2001, PROC CVPR IEEE, P463; Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033; Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	38	64	71	0	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2006	66	1					67	81		10.1007/s11263-005-3676-z	http://dx.doi.org/10.1007/s11263-005-3676-z			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	010MM		Green Submitted			2022-12-18	WOS:000235198800004
J	Moghaddam, B; Tian, Q; Lesh, N; Shen, C; Huang, TS				Moghaddam, B; Tian, Q; Lesh, N; Shen, C; Huang, TS			Visualization and user-modeling for browsing personal photo libraries	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						CBIR; visualization; subspace analysis; PCA; estimation		We present a user-centric system for visualization and layout for content-based image retrieval. Image features (visual and/or semantic) are used to display retrievals as thumbnails in a 2-D spatial layout or "configuration" which conveys all pair-wise mutual similarities. A graphical optimization technique is used to provide maximally uncluttered and informative layouts. Moreover, a novel subspace feature weighting technique can be used to modify 2-D layouts in a variety of context-dependent ways. An efficient computational technique for subspace weighting and re-estimation leads to a simple user-modeling framework whereby the system can learn to display query results based on layout examples (or relevance feedback) provided by the user. The resulting retrieval, browsing and visualization can adapt to the user's (time-varying) notions of content, context and preferences in style and interactive navigation. Monte Carlo simulations with machine-generated layouts as well as pilot user studies have demonstrated the ability of this framework to model or "mimic" users, by automatically generating layouts according to their preferences.	Mitsubishi Electr Corp, Res Labs, Cambridge, MA 02139 USA; Univ Illinois, Beckman Inst, Urbana, IL 61801 USA	University of Illinois System; University of Illinois Urbana-Champaign	Moghaddam, B (corresponding author), Mitsubishi Electr Corp, Res Labs, Cambridge, MA 02139 USA.	baback@merl.com; qitian@ifp.uiuc.edu; lesh@merl.com; shen@merl.com; huang@ifp.uiuc.edu						BALABANOVIC M, 2000, P CHI2000 APR HAG NE; DIETZ P, 2001, P ACM UIST 01 NOV OR; HOORIKE A, 2000, P IEEE INT C MULT EX, V2, P769; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Kang H., 2000, P IEEE INT C MULT EX; Lesh N., 2002, P WORK C ADV VIS INT, P257, DOI DOI 10.1145/1556262.1556305; Moghaddam B, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P901, DOI 10.1109/ICME.2002.1035928; MOGHADDAM B, 2001, P IEEE INT C MULT EX; NAKAZATO M, 2001, P IEEE INT C MULT EX; POPESCU M, 1998, SPIE C STOR RETR IM, V7; RUBNER Y, 1999, THESIS STANFORD U; Santini S, 2000, IEEE MULTIMEDIA, V7, P26, DOI 10.1109/93.879766; Santini S, 1999, IEEE T PATTERN ANAL, V21, P871, DOI 10.1109/34.790428; Santini S, 2001, IEEE T KNOWL DATA EN, V13, P337, DOI 10.1109/69.929893; SHEN C, 2002, ACM C COMP SUPP COOP; SHEN C, 2003, ACM INTERACTIONS MAR; SHEN C, 2001, P EXT ABSTR CHI 2001, P29; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; SMITH JR, 1994, IEEE IMAGE PROC, P407, DOI 10.1109/ICIP.1994.413817; Squire DM, 1999, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES (CBAIVL'99) - PROCEEDINGS, P45, DOI 10.1109/IVL.1999.781122; Stricker M, 1995, P SPIE STOR RETR IM; Swets DL, 1999, IEEE T PATTERN ANAL, V21, P386, DOI 10.1109/34.765652; Tian Q, 2002, LECT NOTES COMPUT SC, V2383, P7; TIAN Q, 2001, 2 INT WORKSH MULT DA, P167; TORGESON WS, 1958, THEORY METHODS SCALI; ZHOU SX, 1999, P IEEE INT C IM P; Zwillinger D., 1995, AFFINE TRANSFORMATIO, P265	27	64	67	0	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN-FEB	2004	56	1-2			SI		109	130		10.1023/B:VISI.0000004834.62090.74	http://dx.doi.org/10.1023/B:VISI.0000004834.62090.74			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	745MJ					2022-12-18	WOS:000186692200008
J	Ferryman, JM; Maybank, SJ; Worrall, AD				Ferryman, JM; Maybank, SJ; Worrall, AD			Visual surveillance for moving vehicles	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	1st IEEE Workshop on Visual Surveillance	JAN 02, 1998	BOMBAY, INDIA	IEEE Comp Soc		model-based vision; surveillance; traffic scene analysis; vehicle tracking; filtering	IMAGE; RECOGNITION; TRACKING; OBJECT	An overview is given of a vision system for locating, recognising and tracking multiple vehicles, using an image sequence taken by a single camera mounted on a moving vehicle. The camera motion is estimated by matching features on the ground plane from one image to the next. Vehicle detection and hypothesis generation are performed using template correlation and a 3D wire frame model of the vehicle is fitted to the image. Once detected and identified, vehicles are tracked using dynamic filtering. A separate batch mode filter obtains the 3D trajectories of nearby vehicles over an extended time. Results are shown for a motorway image sequence.	Univ Reading, Dept Comp Sci, Computat Vis Grp, Reading RG6 6AY, Berks, England	University of Reading	Ferryman, JM (corresponding author), Univ Reading, Dept Comp Sci, Computat Vis Grp, Reading RG6 6AY, Berks, England.	j.m.ferryman@reading.ac.uk						Bertozzi M, 1996, PROCEEDINGS OF THE 1996 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P213, DOI 10.1109/IVS.1996.566380; Betke M, 1996, PROCEEDINGS OF THE 1996 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P351, DOI 10.1109/IVS.1996.566405; Beymer D, 1996, PROCEEDINGS OF THE 1996 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P130, DOI 10.1109/IVS.1996.566366; Dellaert F, 1998, IEEE INT CONF ROBOT, P1889, DOI 10.1109/ROBOT.1998.680587; Dickmanns ED, 1997, INT JOINT CONF ARTIF, P1577; DICKMANNS ED, 1992, IEEE T PATTERN ANAL, V14, P199, DOI 10.1109/34.121789; FERRYMAN JM, 1995, P INT S INT ROB SYST, P295; FISCHER S, 1981, BROOKINGS PAP ECO AC, P381; GENNERY DB, 1992, INT J COMPUT VISION, V7, P243, DOI 10.1007/BF00126395; Giachetti A., 1994, Computer Vision - ECCV'94. Third European Conference on Computer Vision. Proceedings. Vol.I, P146; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; HARRIS C, 1992, ACTIVE VISION; KANATANI K, 1993, OXFORD ENG SCI SERIE, V37; Koller D., 1994, Proceedings of the Intelligent Vehicles '94 Symposium (Cat. No.94TH8011), P201, DOI 10.1109/IVS.1994.639503; LUONG QT, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P52, DOI 10.1109/ICCV.1995.466807; MATTHEWS ND, 1995, VEHICLE DETECTION RE; MAYBANK SJ, 1996, P 7 BRIT MACH VIS C, V2, P615; Press WH., 1980, NUMERICAL RECIPES FO; SCHMID M, 1994, P INT C INT ROB SYST, P3; SMITH SM, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P237, DOI 10.1109/ICCV.1995.466780; SULLIVAN G, 1994, REAL TIME COMPUTER V; SULLIVAN GD, 1994, PHIL T R SOC LON B, V337, P361; Tan TN, 1996, PROC CVPR IEEE, P397, DOI 10.1109/CVPR.1996.517103; THOMANEK F, 1992, P INT C ROB AUT ICRA, P1399; Tian TY, 1996, PROC CVPR IEEE, P315, DOI 10.1109/CVPR.1996.517091; WEBER J, 1995, P INT SOC OPT ENG, V2595; WOLFRAM S, 1996, MATH BOOK; WORRALL AD, 1989, IMAGE VISION COMPUT, V7, P17, DOI 10.1016/0262-8856(89)90015-2; WORRALL AD, 1994, P 5 BRIT MACH VIS C, P781; WORRALL AD, 1993, P 4 BRIT MACH VIS C, P559; WU JJ, 1989, INT J COMPUT VISION, V2, P373, DOI 10.1007/BF00133556; Zhao L, 1998, PROC CVPR IEEE, P496, DOI 10.1109/CVPR.1998.698651	32	64	74	0	13	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2000	37	2					187	197		10.1023/A:1008155721192	http://dx.doi.org/10.1023/A:1008155721192			11	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	341FD					2022-12-18	WOS:000088579600005
J	IKEUCHI, K				IKEUCHI, K			GENERATING AN INTERPRETATION TREE FROM A CAD MODEL FOR 3D-OBJECT RECOGNITION IN BIN-PICKING TASKS	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article									CARNEGIE MELLON UNIV,DEPT COMP SCI,PITTSBURGH,PA 15213	Carnegie Mellon University								AYACHE N, 1984, P INT C PATTERN RECO, P837; BAIRD M, 1977, 5TH INT JOINT C ART, P694; BAUMGART BG, 1972, STANCS320 STANF U AI; Besl P., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P226; BINFORD TO, 1971, P IEEE SYSTEMS SCI C; BIRK JR, 1981, IEEE T SYST MAN CYB, V11, P151, DOI 10.1109/TSMC.1981.4308640; Bolles R. C., 1982, INT J ROBOT RES, V1, P57; BRADY M, 1985, 2ND P INT S ROB RES; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; BROU P, 1983, INT J ROBOT RES, V3, P89; BROWN CM, 1979, COMPUT GRAPH, V4, P77, DOI 10.1016/0097-8493(79)90010-4; CHAKRAVARTY I, 1982, P SOC PHOTO-OPT INST, V336, P37, DOI 10.1117/12.933609; Fukada Y., 1984, Robotica, V2, P147, DOI 10.1017/S0263574700000849; GRIMSON WEL, 1984, INT J ROBOT RES, V3, P3, DOI 10.1177/027836498400300301; HEBERT M, 1985, JUN P IEEE COMP SOC; HERMAN M, 1984, CMUCS84102 REP; HERMAN M, 1985, JUN P IEEE COMP SOC; HORN BKP, 1984, P IEEE, V72, P1671, DOI 10.1109/PROC.1984.13073; HORN BKP, 1984, SCI AM, V251, P100, DOI 10.1038/scientificamerican0884-100; IKEUCHI K, 1987, INT J ROBOT RES, V6, P15, DOI 10.1177/027836498700600102; IKEUCHI K, 1986, INT J ROBOT RES, V5, P46, DOI 10.1177/027836498600500103; IKEUCHI K, 1981, 7TH P INT JOINT C AR, P595; IKEUCHI K, 1983, MIT AI714 ART INT LA; IKEUCHI K, 1984, 1ST P INT S ROB RES; KIMURA F, 1977, PROGRAM PACKAGE GEOM; KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644; Koshikawa K., 1985, Proceedings of '85 International Conference on Advanced Robotics, P185; KOSHIKAWA K, 1984, SOLVER REFERENCE MAN; LITTLE JJ, 1985, 9TH P IJCAI, P960; LOZANOPEREZ T, 1981, IEEE T SYST MAN CYB, V11, P681, DOI 10.1109/TSMC.1981.4308589; Oshima M., 1985, Proceedings of '85 International Conference on Advanced Robotics, P191; PERKINS WA, 1977, 5TH P INT JOINT C AR, P678; SHAFER S, 1983, CMUCS83105 CARN MELL; SMITH D, 1979, MIT AI451 ART INT LA; SUGIHARA K, 1979, 6TH P INT JOINT C AR, P859; THORPE C, 1983, 8TH P INT JOINT C AR, P959; TSUJI S, 1977, 5TH P INT JOINT C AR, P569; TSUJI S, 1975, 4TH P INT JOINT C AR, P881; WOODHAM RJ, 1978, MIT AITR457 ART INT; YACHIDA M, 1975, 4TH P INT JOINT C AR, P819; [No title captured]	41	64	67	0	5	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.		1987	1	2					145	165		10.1007/BF00123163	http://dx.doi.org/10.1007/BF00123163			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	M2049					2022-12-18	WOS:A1987M204900003
J	Yao, A; Gall, J; Van Gool, L				Yao, Angela; Gall, Juergen; Van Gool, Luc			Coupled Action Recognition and Pose Estimation from Multiple Views	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Human pose estimation; Human action recognition; Tracking; Stochastic optimization; Hough transform	MOTION CAPTURE; MODELS	Action recognition and pose estimation are two closely related topics in understanding human body movements; information from one task can be leveraged to assist the other, yet the two are often treated separately. We present here a framework for coupled action recognition and pose estimation by formulating pose estimation as an optimization over a set of action-specific manifolds. The framework allows for integration of a 2D appearance-based action recognition system as a prior for 3D pose estimation and for refinement of the action labels using relational pose features based on the extracted 3D poses. Our experiments show that our pose estimation system is able to estimate body poses with high degrees of freedom using very few particles and can achieve state-of-the-art results on the HumanEva-II benchmark. We also thoroughly investigate the impact of pose estimation and action recognition accuracy on each other on the challenging TUM kitchen dataset. We demonstrate not only the feasibility of using extracted 3D poses for action recognition, but also improved performance in comparison to action recognition using low-level appearance features.	[Yao, Angela; Gall, Juergen; Van Gool, Luc] Swiss Fed Inst Technol, Comp Vis Lab, CH-8092 Zurich, Switzerland; [Gall, Juergen] Max Planck Inst Intelligent Syst, D-72076 Tubingen, Germany; [Van Gool, Luc] Katholieke Univ Leuven, Dept Elect Engn IBBT, B-3001 Heverlee, Belgium	Swiss Federal Institutes of Technology Domain; ETH Zurich; Max Planck Society; KU Leuven	Yao, A (corresponding author), Swiss Fed Inst Technol, Comp Vis Lab, Sternwartstr 7, CH-8092 Zurich, Switzerland.	yaoa@vision.ee.ethz.ch; jgall@tue.mpg.de; luc.vangool@esat.kuleuven.be			Swiss National Foundation NCCR [IM2]; EC project IURO; EC project TANGO; EC project RADHAR; NSERC Canada	Swiss National Foundation NCCR; EC project IURO; EC project TANGO; EC project RADHAR; NSERC Canada(Natural Sciences and Engineering Research Council of Canada (NSERC))	This work has been supported by funding from the Swiss National Foundation NCCR project IM2 as well as the EC projects IURO, TANGO and RADHAR. Angela Yao was also supported by funding from NSERC Canada.	Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21; Aggarwal J., 2010, ACM COMPUT SURV; Ali S, 2007, IEEE I CONF COMP VIS, P1703; Andriluka M, 2010, PROC CVPR IEEE, P623, DOI 10.1109/CVPR.2010.5540156; Baak A, 2009, IEEE I CONF COMP VIS, P1428, DOI 10.1109/ICCV.2009.5459291; Baumberg A. M., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P194, DOI 10.1109/MNRAO.1994.346236; Belkin M, 2002, ADV NEUR IN, V14, P585; Bergtholdt Martin, 2010, International Journal of Computer Vision, V87, P93, DOI 10.1007/s11263-009-0209-1; Blank M, 2005, IEEE I CONF COMP VIS, P1395; Bo LF, 2010, INT J COMPUT VISION, V87, P28, DOI 10.1007/s11263-008-0204-y; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3; Brubaker MA, 2010, INT J COMPUT VISION, V87, P140, DOI 10.1007/s11263-009-0274-5; CAMPBELL LW, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P624, DOI 10.1109/ICCV.1995.466880; Corazza S, 2010, INT J COMPUT VISION, V87, P156, DOI 10.1007/s11263-009-0284-3; Darby J, 2010, PATTERN RECOGN, V43, P3042, DOI 10.1016/j.patcog.2010.03.018; Del Moral P., 2004, PROB APPL S; Deutscher J, 2005, INT J COMPUT VISION, V61, P185, DOI 10.1023/B:VISI.0000043757.18370.9c; Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65; Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726; Elgammal A, 2004, PROC CVPR IEEE, P681; Forsyth D. A., 2006, FDN TRENDS COMPUTER, V1, P77; GALL J, 2010, LECT NOTES COMPUT SC, V6313, P425; Gall J, 2008, PROC CVPR IEEE, P1681; Gall J, 2011, IEEE T PATTERN ANAL, V33, P2188, DOI 10.1109/TPAMI.2011.70; Gall J, 2008, COMPUT IMAGING VIS, V36, P319; Gall J, 2009, PROC CVPR IEEE, P1746, DOI 10.1109/CVPRW.2009.5206755; Gall J, 2010, INT J COMPUT VISION, V87, P75, DOI 10.1007/s11263-008-0173-1; Gavrila D, 1995, INT WORKSH AUT FAC G, P272; Geiger A, 2009, PROC CVPR IEEE, P880, DOI 10.1109/CVPRW.2009.5206672; Hou S, 2007, IEEE I CONF COMP VIS, P928; Husz ZL, 2011, EURASIP J IMAGE VIDE, DOI 10.1155/2011/365307; Jaeggli T, 2009, INT J COMPUT VISION, V83, P121, DOI 10.1007/s11263-008-0158-0; Jenkins OC, 2007, INT J HUM ROBOT, V4, P365, DOI 10.1142/S0219843607001060; Jhuang H, 2007, IEEE I CONF COMP VIS, P1253; Jixu Chen, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2655, DOI 10.1109/CVPRW.2009.5206580; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; Klaser A., 2012, P EUR C COMP VIS, V6553, P219; Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760; Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Lawrence N, 2005, J MACH LEARN RES, V6, P1783; Lee CS, 2010, INT J COMPUT VISION, V87, P118, DOI 10.1007/s11263-009-0266-5; Li R, 2007, IEEE I CONF COMP VIS, P1687; Li R, 2010, INT J COMPUT VISION, V87, P170, DOI 10.1007/s11263-009-0283-4; Lin RS, 2006, LECT NOTES COMPUT SC, V3952, P245; Liu JG, 2009, PROC CVPR IEEE, P1996; Lv F., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383131; Maji S., 2011, CVPR, DOI DOI 10.1109/CVPR.2011.5995631; Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280; Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002; Moon K., 2006, P CVPR, V1, P198; Muller M, 2005, ACM T GRAPHIC, V24, P677, DOI 10.1145/1073204.1073247; Natarajan P, 2010, PROC CVPR IEEE, P2006, DOI 10.1109/CVPR.2010.5539876; PAVLOVIC V., 2000, ADV NEURAL INFORM PR, V13, P981; Peursum P, 2010, INT J COMPUT VISION, V87, P53, DOI 10.1007/s11263-009-0205-5; Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014; Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748; Raskin L, 2011, COMPUT VIS IMAGE UND, V115, P503, DOI 10.1016/j.cviu.2010.12.002; Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727; Rosales R., 2001, NIPS; Rosenhahn B, 2007, PROC CVPR IEEE, P1203; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Schindler K, 2008, PROC CVPR IEEE, P3025; Schmaltz C., 2011, MACH VISION APPL, V23, P557; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Seeger Matthias, 2004, Int J Neural Syst, V14, P69, DOI 10.1142/S0129065704001899; Shaheen M., 2009, IEEE WORKSH APPL COM; Sidenbladh H, 2002, LECT NOTES COMPUT SC, V2350, P784; Sidenbladh H., 2000, LNCS, V2, P702; Sminchisescu C., 2004, ICML; Sminchisescu C, 2007, IEEE T PATTERN ANAL, V29, P2030, DOI 10.1109/TPAMI.2007.1111; Taycher L., 2006, P IEEE CVPR, V1, P222; Taylor GW, 2010, PROC CVPR IEEE, P631, DOI 10.1109/CVPR.2010.5540157; TENENBAUM JB, 2000, GLOBAL GEOMETRIC FRA; Tenorth Moritz, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1089, DOI 10.1109/ICCVW.2009.5457583; Thurau C., 2008, CVPR, P1; Ukita N., 2009, P INT C COMP VIS; Urtasun R, 2005, IEEE I CONF COMP VIS, P403; Urtasun R., 2006, 2006 IEEE COMP VIS P, P238, DOI DOI 10.1109/CVPR.2006.15; Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167; Weinland D, 2008, PROC CVPR IEEE, P3033; Weinland D, 2007, IEEE I CONF COMP VIS, P170; WILLEMS G, 2009, P BRIT MACH VIS C; Yacoob Y, 1999, COMPUT VIS IMAGE UND, V73, P232, DOI 10.1006/cviu.1998.0726; Yang WL, 2010, PROC CVPR IEEE, P2030, DOI 10.1109/CVPR.2010.5539879; Yao A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.67; Yao A, 2010, PROC CVPR IEEE, P2061, DOI 10.1109/CVPR.2010.5539883; Yilmaz A., 2005, ICCV 2005	90	63	67	3	19	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	OCT	2012	100	1					16	37		10.1007/s11263-012-0532-9	http://dx.doi.org/10.1007/s11263-012-0532-9			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	962SH		Green Published, Green Submitted			2022-12-18	WOS:000305564800002
J	Ruggeri, MR; Patane, G; Spagnuolo, M; Saupe, D				Ruggeri, Mauro R.; Patane, Giuseppe; Spagnuolo, Michela; Saupe, Dietmar			Spectral-Driven Isometry-Invariant Matching of 3D Shapes	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Isometry-invariant matching; 3D model retrieval; Feature points; Local statistical shape descriptors; Laplace-Beltrami operator	GEODESICS; DISTANCE; SURFACES; SALIENCY	This paper presents a matching method for 3D shapes, which comprises a new technique for surface sampling and two algorithms for matching 3D shapes based on point-based statistical shape descriptors. Our sampling technique is based on critical points of the eigenfunctions related to the smaller eigenvalues of the Laplace-Beltrami operator. These critical points are invariant to isometries and are used as anchor points of a sampling technique, which extends the farthest point sampling by using statistical criteria for controlling the density and number of reference points. Once a set of reference points has been computed, for each of them we construct a point-based statistical descriptor (PSSD, for short) of the input surface. This descriptor incorporates an approximation of the geodesic shape distribution and other geometric information describing the surface at that point. Then, the dissimilarity between two surfaces is computed by comparing the corresponding sets of PSSDs with bipartite graph matching or measuring the L (1)-distance between the reordered feature vectors of a proximity graph. Here, the reordering is given by the Fiedler vector of a Laplacian matrix associated to the proximity graph. Our tests have shown that both approaches are suitable for online retrieval of deformed objects and our sampling strategy improves the retrieval performances of isometry-invariant matching methods. Finally, the approach based on the Fiedler vector is faster than using the bipartite graph matching and it has a similar retrieval effectiveness.	[Ruggeri, Mauro R.; Saupe, Dietmar] Univ Konstanz, Dept Comp & Informat Sci, Constance, Germany; [Patane, Giuseppe; Spagnuolo, Michela] CNR, Ist Matemat Applicata & Tecnol Informat, Rome, Italy	University of Konstanz; Consiglio Nazionale delle Ricerche (CNR); Istituto di Matematica Applicata e Tecnologie Informatiche "Enrico Magenes" (IMATI-CNR)	Ruggeri, MR (corresponding author), Univ Konstanz, Dept Comp & Informat Sci, Constance, Germany.	mauro.ruggeri@uni-konstanz.de; patane@ge.imati.cnr.it; spagnuolo@ge.imati.cnr.it; dietmar.saupe@uni-konstanz.de	Spagnuolo, Michela/ABA-1927-2021; Spagnuolo, Michela/F-5068-2013; Patane', Giuseppe/O-1322-2013	Spagnuolo, Michela/0000-0002-5682-6990; Spagnuolo, Michela/0000-0002-5682-6990; Patane', Giuseppe/0000-0002-2276-9553	DFG; FOCUS K3D Coordination Action; SHALOM	DFG(German Research Foundation (DFG)); FOCUS K3D Coordination Action; SHALOM	At the University of Konstanz this research was supported by the DFG Graduiertenkolleg 1042 "Explorative Analysis and Visualization of Large Information Spaces". Giuseppe Patane and Michela Spagnuolo have been partially supported by the FOCUS K3D Coordination Action and the Italy-Israel bilateral project SHALOM. We also acknowledge the use of the Edmonds' blossom algorithm, kindly provided by W. Cook (University of Texas at Austin). Models are courtesy of Ron Kimmel (Technion-Israel), Robert W. Sumner (ETH-Zurich), and Jovan Popovic (MIT-Boston) (Sumner and Popovic 2004). We thank the anonymous reviewers for their comments and suggestions.	BALOCH S, 2005, P IEEE INT C IM PROC, P796; BANCHOFF T, 1967, J DIFFER GEOM, V1, P245; Ben Hamza A, 2003, LECT NOTES COMPUT SC, V2886, P378; BIASOTTI S, 2008, 82008 IMATICNR; Biasotti S, 2006, COMPUT AIDED DESIGN, V38, P1002, DOI 10.1016/j.cad.2006.07.003; Bremer PT, 2004, IEEE T VIS COMPUT GR, V10, P385, DOI 10.1109/TVCG.2004.3; Bronstein AM, 2006, SIAM J SCI COMPUT, V28, P1812, DOI 10.1137/050639296; BRONSTEIN AM, 2009, COMPUTER VISION APPL, V1, P105; Brunelli R, 2001, PATTERN RECOGN, V34, P1625, DOI 10.1016/S0031-3203(00)00054-6; Brusco MJ., 2005, BRANCH AND BOUND APP; Bustos B, 2005, ACM COMPUT SURV, V37, P345, DOI 10.1145/1118890.1118893; Castellani U, 2008, COMPUT GRAPH FORUM, V27, P643, DOI 10.1111/j.1467-8659.2008.01162.x; Chung F., 1997, AM MATH SOC, DOI 10.1090/cbms/092; Cook W, 1999, INFORMS J COMPUT, V11, P138, DOI 10.1287/ijoc.11.2.138; Darom T, 2006, SIGNAL PROCESS-IMAGE, V21, P770, DOI 10.1016/j.image.2006.07.003; Elad A, 2003, IEEE T PATTERN ANAL, V25, P1285, DOI 10.1109/TPAMI.2003.1233902; Elad M, 2002, SPRING EUROGRAP, P107; Eldar Y, 1997, IEEE T IMAGE PROCESS, V6, P1305, DOI 10.1109/83.623193; FIEDLER M, 1975, CZECH MATH J, V25, P619; FOMENKO A, 1997, TOPOLOGICAL MODELLIN; FUNKHOUSER T, 2006, P 4 EUR S GEOM PROC, P131; Gal R, 2006, ACM T GRAPHIC, V25, P130, DOI 10.1145/1122501.1122507; Gal R, 2007, IEEE T VIS COMPUT GR, V13, P261, DOI 10.1109/TVCG.2007.45; Gelfand N., 2005, P 3 EUR S GEOM PROC, V2, P5; Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282; Isenburg M, 2005, IEEE Visualization 2005, Proceedings, P231; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Jain V, 2007, COMPUT AIDED DESIGN, V39, P398, DOI 10.1016/j.cad.2007.02.009; Katz S, 2003, ACM T GRAPHIC, V22, P954, DOI 10.1145/882262.882369; Kimmel R, 1998, P NATL ACAD SCI USA, V95, P8431, DOI 10.1073/pnas.95.15.8431; Koren Y, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P137, DOI 10.1109/INFVIS.2002.1173159; Lee CH, 2005, ACM T GRAPHIC, V24, P659, DOI 10.1145/1073204.1073244; Li XC, 2005, PROCEEDINGS OF THE 2005 CONFERENCE OF SYSTEM DYNAMICS AND MANAGEMENT SCIENCE, VOL 1, P217; LING H, 2006, P IEEE C COMP VIS PA, V1, P246, DOI DOI 10.1109/CVPR.2006.99; Liu Y.-S., 2007, P S SOL PHYS MOD, P277, DOI DOI 10.1145/1236246.1236285; Mateus D, 2007, IEEE I CONF COMP VIS, P39; Memoli F, 2005, FOUND COMPUT MATH, V5, P313, DOI 10.1007/s10208-004-0145-y; Memoli F, 2005, SIAM J APPL MATH, V65, P1227, DOI 10.1137/S003613990342877X; MEMOLI F., 2007, S POINT BAS GRAPH, P81, DOI DOI 10.2312/SPBG/SPBG07/081-090; Milnor J., 1963, ANN MATH STUD, V51; MOENNING C, 2003, COMPUTER GRAPHICS FO; Mortara M, 2004, ALGORITHMICA, V38, P227, DOI 10.1007/s00453-003-1051-4; MORTARA M, 2002, INT J SHAPE MODELLIN, V8, P245; Nehab D., 2004, EUR S POINT BAS GRAP, P49, DOI DOI 10.2312/SPBG/SPBG04/049-056; NI X, 2004, ACM SIGGRAPH, P613; Ohbuchi R, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P93, DOI 10.1109/SMI.2008.4547955; Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648; OVSJANIKOV M, 2008, EUR S GEOM PROC SGP; PATANE G, 2009, IEEE T VISU IN PRESS; Pauly M, 2003, ACM T GRAPHIC, V22, P641, DOI 10.1145/882262.882319; Press WH, 1994, NUMERICAL RECIPES C; Qiu HJ, 2003, LECT NOTES COMPUT SC, V2726, P178; RAVIV D, 2007, IEEE WORKSH NONR REG; Reuter M, 2006, COMPUT AIDED DESIGN, V38, P342, DOI 10.1016/j.cad.2005.10.011; REUTER M, 2009, COMPUTER GRAPHICS; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; RUGGERI MR, 2006, P S POINT BAS GRAPH, P85, DOI DOI 10.2312/SPBG/SPBG06/085-093; RUGGERI MR, 2008, P EUR WORKSH 3D OBJ; Rustamov Raif M, 2007, P 5 EUR S GEOM PROC, P225, DOI DOI 10.2312/SGP/SGP07/225-233; Schwartz J, 2005, LECT NOTES COMPUT SC, V3503, P476; Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736; Surazhsky V, 2005, ACM T GRAPHIC, V24, P553, DOI 10.1145/1073204.1073228; Tangelder JWH, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P145, DOI 10.1109/SMI.2004.1314502; TURK M, 1991, P IEEE C COMP VIS PA, P586, DOI DOI 10.1109/CVPR.1991.139758; Vallet B, 2008, COMPUT GRAPH FORUM, V27, P251, DOI 10.1111/j.1467-8659.2008.01122.x; Vygen J, 2011, COMBINATORIAL OPTIMI; ZHANG H, 2008, S GEOMETRY PROCESSIN, V27, P431; Zhang H, 2007, P EUR STAT OF THE AR, P1, DOI DOI 10.1109/IPDPS.2007.370248; Zhang H., 2005, PROC VISION MODELING, P429; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149	71	63	73	1	15	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2010	89	2-3			SI		248	265		10.1007/s11263-009-0250-0	http://dx.doi.org/10.1007/s11263-009-0250-0			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	594OS		Green Submitted			2022-12-18	WOS:000277547600008
J	Micusik, B; Kosecka, J				Micusik, Branislav; Kosecka, Jana			Multi-view Superpixel Stereo in Urban Environments	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						3D reconstruction; Multi-view stereo; Urban environment; Segmentation	RECONSTRUCTION	Urban environments possess many regularities which can be efficiently exploited for 3D dense reconstruction from multiple widely separated views. We present an approach utilizing properties of piecewise planarity and restricted number of plane orientations to suppress reconstruction and matching ambiguities causing failures of standard dense stereo methods. We formulate the problem of the 3D reconstruction in MRF framework built on an image pre-segmented into superpixels. Using this representation, we propose novel photometric and superpixel boundary consistency terms explicitly derived from superpixels and show that they overcome many difficulties of standard pixel-based formulations and handle favorably problematic scenarios containing many repetitive structures and no or low textured regions. We demonstrate our approach on several wide-baseline scenes demonstrating superior performance compared to previously proposed methods.	[Micusik, Branislav] AIT Austrian Inst Technol, Safety & Secur Dept, Vienna, Austria; [Kosecka, Jana] George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA	Austrian Institute of Technology (AIT); George Mason University	Micusik, B (corresponding author), AIT Austrian Inst Technol, Safety & Secur Dept, Vienna, Austria.	branislav.micusik@ait.ac.at; kosecka@cs.gmu.edu						Akbarzadeh A., 2006, P INT S 3D DAT PROC; Brostow G. J., 2008, P ECCV; CORNELIUS H, 2004, P SMVP WORKSH ECCV, P1; Coughlan JM, 2003, NEURAL COMPUT, V15, P1063, DOI 10.1162/089976603765202668; CULBERTSON B, 2002, P ICPR; Debevec P. E., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P11, DOI 10.1145/237170.237191; Dick AR, 2004, INT J COMPUT VISION, V60, P111, DOI 10.1023/B:VISI.0000029665.07652.61; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; FURUKAWA Y, 2007, P CVPR; Furukawa Y., 2009, P CVPR; FURUKAWA Y, 2009, P ICCV; GALLUP D, 2007, P CVPR; Hartley R., 2004, ROBOTICA; HOIEM D, 2007, INT J COMPUTER VISIO, V75; IRSCHARA A, 2007, ICCV WORKSH VIRT REP; Kanatani K, 2005, IEICE T INF SYST, VE88D, P2260, DOI 10.1093/ietisy/e88-d.10.2260; KERIVEN R, 2007, P ICCV; Klaus A, 2006, INT C PATT RECOG, P15; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200; Kosecka J, 2002, LECT NOTES COMPUT SC, V2353, P476; Leibe B., 2007, P CVPR; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800; Micusik B., 2009, P CVPR; Obdrzalek S, 2006, LECT NOTES COMPUT SC, V4170, P83; *PHOTOMODELER, EOSSYSTEMS; Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10; Rother C, 2002, IMAGE VISION COMPUT, V20, P647, DOI 10.1016/S0262-8856(02)00054-9; Russell B. C., 2006, P IEEE C COMP VIS PA, V2, P1605; SAXENA A, 2007, P VRML WORKSH ICCV; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Seitz S., 2006, P INT C COMP VIS PAT, P519, DOI DOI 10.1109/CVPR.2006.19; SINHA SN, 2009, P ICCV; Sun J, 2005, PROC CVPR IEEE, P399; Tao H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P532, DOI 10.1109/ICCV.2001.937562; Vergauwen M, 2006, MACH VISION APPL, V17, P411, DOI 10.1007/s00138-006-0027-1; Vogiatzis G, 2007, IEEE T PATTERN ANAL, V29, P2241, DOI 10.1109/TPAMI.2007.70712; Werner T, 2002, LECT NOTES COMPUT SC, V2351, P541; Werner T, 2007, IEEE T PATTERN ANAL, V29, P1165, DOI 10.1109/TPAMI.2007.1036; Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70; Zach C., 2008, P VIS MOD VIS WORKSH; Zebedin L, 2008, LECT NOTES COMPUT SC, V5305, P873, DOI 10.1007/978-3-540-88693-8_64; Zitnick CL, 2007, INT J COMPUT VISION, V75, P49, DOI 10.1007/s11263-006-0018-8; OXFORD VGG DATASET	44	63	72	0	19	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2010	89	1					106	119		10.1007/s11263-010-0327-9	http://dx.doi.org/10.1007/s11263-010-0327-9			14	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	584RF					2022-12-18	WOS:000276769500007
J	Fajen, BR; Warren, WH; Temizer, S; Kaelbling, LP				Fajen, BR; Warren, WH; Temizer, S; Kaelbling, LP			A dynamical model of visually-guided steering, obstacle avoidance, and route selection	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						visual control of locomotion; optic flow; obstacle avoidance; path planning; robot navigation	CONTROLLED LOCOMOTION; INFORMATION; BEHAVIOR; GUIDANCE; WALKING	Using a biologically-inspired model, we show how successful route selection through a cluttered environment can emerge from on-line steering dynamics, without explicit path planning. The model is derived from experiments on human walking performed in the Virtual Environment Navigation Lab (VENLab) at Brown. We find that goals and obstacles behave as attractors and repellors of heading, the direction of locomotion, for an observer moving at a constant speed. The influence of a goal on turning rate increases with its angle from the heading and decreases exponentially with its distance; the influence of an obstacle decreases exponentially with angle and distance. Linearly combining goal and obstacle terms allows us to simulate paths through arbitrarily complex scenes, based on information about obstacles in view near the heading direction and a few meters ahead. We simulated the model on a variety of scene configurations and observed generally efficient routes, and verified this behavior on a mobile robot. Discussion focuses on comparisons between dynamical models and other approaches, including potential field models and explicit path planning. Effective route selection can thus be performed on-line, in simple environments as a consequence of elementary behaviors for steering and obstacle avoidance.	Rensselaer Polytech Inst, Dept Cognit Sci, Troy, NY 12181 USA; Brown Univ, Dept Cognit & Linguist Sci, Providence, RI 02912 USA; MIT, Artificial Intelligence Lab, Cambridge, MA 02139 USA	Rensselaer Polytechnic Institute; Brown University; Massachusetts Institute of Technology (MIT)	Fajen, BR (corresponding author), Rensselaer Polytech Inst, Dept Cognit Sci, Troy, NY 12181 USA.	fajenb@rpi.edu; william_warren@brown.edu; temizer@ai.mit.edu; lpk@ai.mit.edu	Warren, William H./AAX-7781-2021					Aloimonos Y, 1993, ACTIVE PERCEPTION; ARKIN RC, 1989, INT J ROBOT RES, V8, P92, DOI 10.1177/027836498900800406; Beer RD, 1997, ROBOT AUTON SYST, V20, P257, DOI 10.1016/S0921-8890(96)00063-2; BEER RD, 1995, ARTIF INTELL, V72, P173, DOI 10.1016/0004-3702(94)00005-L; BROOKS RA, 1991, ARTIF INTELL, V47, P139, DOI 10.1016/0004-3702(91)90053-M; BROOKS RA, 1986, IEEE T ROBOTIC AUTOM, V2, P14, DOI 10.1109/JRA.1986.1087032; Duchon AP, 1998, ADAPT BEHAV, V6, P473, DOI 10.1177/105971239800600306; FAJEN B, 2001, UNPUB BEHAV DYNAMICS; FRANCESCHINI N, 1992, PHILOS T R SOC B, V337, P283, DOI 10.1098/rstb.1992.0106; Gibson J., 1979, ECOLOGICAL APPROACH; GIBSON JJ, 1958, BRIT J PSYCHOL, V49, P182, DOI 10.1111/j.2044-8295.1958.tb00656.x; Hildreth EC, 1998, HIGH LEVEL MOTION PR, P269; Kelso J.A.S., 1995, DYNAMIC PATTERNS SEL; KHATIB O, 1986, INT J ROBOT RES, V5, P90, DOI 10.1177/027836498600500106; KROGH BH, 1984, INT ROB RES C BETHL; Kugler P.N., 1987, INFORM NATURAL LAW S; Large EW, 1999, INT J ROBOT RES, V18, P37, DOI 10.1177/027836499901800103; LEE DN, 1980, TUTORIALS MOTOR BEHA, P281; MORAVEC H, 1981, P INT JOINT C ART IN, P785; Newman W. S., 1987, Proceedings of the 1987 IEEE International Conference on Robotics and Automation (Cat. No.87CH2413-3), P14; PFEIFFER F, 1994, INTELLIGENT AUTOMATI; Ritzmann RE, 2000, BIOSCIENCE, V50, P23, DOI 10.1641/0006-3568(2000)050[0023:IWABAR]2.3.CO;2; Rushton SK, 1998, CURR BIOL, V8, P1191, DOI 10.1016/S0960-9822(07)00492-7; Schoner G, 1995, ROBOT AUTON SYST, V16, P213, DOI 10.1016/0921-8890(95)00049-6; Schoner G., 1992, Robotics and Autonomous Systems, V10, P253, DOI 10.1016/0921-8890(92)90004-I; Srinivasan M. V., 1997, LIVING EYES SEEING M; Strogatz S.H., 1996, NONLINEAR DYNAMICS C; TEMIZER S, 2001, P PHOT BOST INT SYST; TEMIZER S, 2001, THESIS MIT CAMBRIDGE; THORPE CF, 1985, PATH RELAXATION PATH; TRESILIAN JR, 1990, PERCEPTION, V19, P223, DOI 10.1068/p190223; Warren W. H., 1998, HIGH LEVEL MOTION PR, P315; WARREN W H JR, 1988, P339; Warren WH, 2001, NAT NEUROSCI, V4, P213, DOI 10.1038/84054; Warren WH, 1998, ECOL PSYCHOL, V10, P177, DOI 10.1207/s15326969eco103&4_3; WARREN WH, 1987, J EXP PSYCHOL HUMAN, V13, P371, DOI 10.1037/0096-1523.13.3.371; Wood RM, 2000, CURR BIOL, V10, pR545, DOI 10.1016/S0960-9822(00)00606-0	37	63	67	1	22	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG-SEP	2003	54	1-2					13	34		10.1023/A:1023701300169	http://dx.doi.org/10.1023/A:1023701300169			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science	678EA					2022-12-18	WOS:000182851000002
J	Carceroni, RL; Kutulakos, KN				Carceroni, RL; Kutulakos, KN			Multi-view scene capture by surfel sampling: From video streams to non-rigid 3D motion, shape and reflectance	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						stereoscopic vision; 3D reconstruction; multiple-view geometry; multi-view stereo; space carving; motion analysis; multi-view motion estimation; direct estimation methods; image warping; deformation analysis; 3D motion capture; reflectance modeling; illumination modeling; Phong reflectance model	OPTICAL-FLOW; MODELS; STEREO; RECONSTRUCTION; ILLUMINATION; CONSTRAINTS; COMPUTATION	In this paper we study the problem of recovering the 3D shape, reflectance, and non-rigid motion properties of a dynamic 3D scene. Because these properties are completely unknown and because the scene's shape and motion may be non-smooth, our approach uses multiple views to build a piecewise-continuous geometric and radiometric representation of the scene's trace in space-time. A basic primitive of this representation is the dynamic surfel, which (1) encodes the instantaneous local shape, reflectance, and motion of a small and bounded region in the scene, and (2) enables accurate prediction of the region's dynamic appearance under known illumination conditions. We show that complete surfel-based reconstructions can be created by repeatedly applying an algorithm called Surfel Sampling that combines sampling and parameter estimation to fit a single surfel to a small, bounded region of space-time. Experimental results with the Phong reflectance model and complex real scenes (clothing, shiny objects, skin) illustrate our method's ability to explain pixels and pixel variations in terms of their underlying causes-shape, reflectance, motion, illumination, and visibility.	Univ Fed Minas Gerais, Dept Ciencia Computacao, BR-31270010 Belo Horizonte, MG, Brazil; Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3H5, Canada; Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA; Univ Rochester, Dept Dermatol, Rochester, NY 14627 USA	Universidade Federal de Minas Gerais; University of Toronto; University of Rochester; University of Rochester	Carceroni, RL (corresponding author), Univ Fed Minas Gerais, Dept Ciencia Computacao, BR-31270010 Belo Horizonte, MG, Brazil.	carceron@dcc.ufmg.br; kyros@cs.toronto.edu						Amenta N., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P415, DOI 10.1145/280814.280947; ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167; Avidan S, 2000, IEEE T PATTERN ANAL, V22, P348, DOI 10.1109/34.845377; Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821; Belhumeur PN, 1996, INT J COMPUT VISION, V19, P237, DOI 10.1007/BF00055146; Ben-Ezra M, 2000, COMPUT VIS IMAGE UND, V78, P32, DOI 10.1006/cviu.1999.0826; Bereziat D, 2000, PROC CVPR IEEE, P487, DOI 10.1109/CVPR.2000.854890; Black MJ, 2000, COMPUT VIS IMAGE UND, V78, P8, DOI 10.1006/cviu.1999.0825; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; BLACK MJ, 1999, P COMP VIS PATT REC, V1, P326; BLAKE A, 1991, PHILOS T R SOC B, V331, P237, DOI 10.1098/rstb.1991.0012; Blinn J.F., 1978, COMPUT GRAPH, DOI [10.1145/800248.507101, DOI 10.1145/965139.507101]; Bouguet JY, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P43, DOI 10.1109/ICCV.1998.710699; Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; BRODSKY T, 1999, P IEEE CCVPR FORT CO, V2, P146; CARCERONI RL, 1999, P COMP VIS PATT REC, V1, P192; CARCERONI RL, 1999, P 7 INT C COMP VIS, V1, P520; Caspi Y, 2000, PROC CVPR IEEE, P682, DOI 10.1109/CVPR.2000.854940; CHEN Q, 1999, P COMP VIS PATT REC, V1, P29; Collins RT, 1996, PROC CVPR IEEE, P358, DOI 10.1109/CVPR.1996.517097; Cook R. L., 1981, Computer Graphics, V15, P307, DOI 10.1145/965161.806819; DeCarlo D, 2000, INT J COMPUT VISION, V38, P99, DOI 10.1023/A:1008122917811; DeCarlo D, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P113, DOI 10.1109/ICCV.1998.710708; Delamarre Q., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P716, DOI 10.1109/ICCV.1999.790292; DEUTSCHER J, 2000, P IEEE C COMP VIS PA, V2, P126, DOI DOI 10.1109/CVPR.2000.854758; Do Carmo M., 1976, DIFFERENTIAL GEOMETR; DRUMMOND T, 2000, P 6 EUR C COMP VIS E, V2, P20; Faugeras O, 1998, IEEE T IMAGE PROCESS, V7, P336, DOI 10.1109/83.661183; FAUGERAS O, 1998, P 5 EUR C COMP VIS, P379; FLEET DJ, 1990, INT J COMPUT VISION, V5, P77, DOI 10.1007/BF00056772; FLEET DJ, 2000, INT J COMPUT VISION, V35, P169; FORSYTH D, 1991, IEEE T PATTERN ANAL, V13, P671, DOI 10.1109/34.85657; FUA P, 1995, INT J COMPUT VISION, V16, P35, DOI 10.1007/BF01428192; Fua P., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P46, DOI 10.1109/ICCV.1999.791196; Fua P, 1997, INT J COMPUT VISION, V24, P19, DOI 10.1023/A:1007918123901; GAUCHER L, 1999, P 7 INT C COMP VIS, V2, P695; Guenin BM, 1998, P IEEE SEMICOND THER, P55, DOI 10.1109/STHERM.1998.660387; Haussecker HW, 2000, PROC CVPR IEEE, P760, DOI 10.1109/CVPR.2000.854951; Horn B., 1986, ROBOT VISION, P1; IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L; Irani M, 1997, IEEE T PATTERN ANAL, V19, P268, DOI 10.1109/34.584105; Irani M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P626, DOI 10.1109/ICCV.1999.791283; JIN H, 2000, P COMP VIS PATT REC, V1, P169; Ju SX, 1996, PROC CVPR IEEE, P307, DOI 10.1109/CVPR.1996.517090; Kanatani K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P73, DOI 10.1109/ICCV.1999.791200; Koenderink J., 1990, SOLID SHAPE; Koenderink JJ, 1999, INT J COMPUT VISION, V31, P129, DOI 10.1023/A:1008061730969; KUTULAKOS K, 2000, P EUR C COMP VIS, V1, P67; Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954; LAFORTUNE EPF, 1997, P SIGGRAPH, P117; LANGER MS, 1994, J OPT SOC AM A, V11, P467, DOI 10.1364/JOSAA.11.000467; LIN S, 1999, P INT C COMP VIS, V2, P849; LIN S, 2000, P COMP VIS PATT REC, V1, P105; Loop C., 1999, 1999 IEEE COMP SOC C, V1, DOI [10.1109/CVPR.1999.786928, DOI 10.1109/CVPR.1999.786928]; LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043; Narayanan PJ, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P3, DOI 10.1109/ICCV.1998.710694; Nayar S. K., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P583, DOI 10.1109/CVPR.1993.341071; Negahdaripour S, 1998, IEEE T PATTERN ANAL, V20, P961, DOI 10.1109/34.713362; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; Oren M, 1997, INT J COMPUT VISION, V24, P105, DOI 10.1023/A:1007954719939; PAPIN C, 2000, P EUR C COMP VIS, V2, P428; Pratt W, 1991, DIGITAL IMAGE PROCES; Press, 1988, NUMERICAL RECIPIES C; Ramamoorthi R, 2001, COMP GRAPH, P117, DOI 10.1145/383259.383271; Rong Lu, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P2, DOI 10.1109/ICCV.1999.791189; Roy S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P492, DOI 10.1109/ICCV.1998.710763; Samaras D, 1998, PROC CVPR IEEE, P322, DOI 10.1109/CVPR.1998.698626; SATO Y, 1994, J OPT SOC AM A, V11, P2990, DOI 10.1364/JOSAA.11.002990; SATO Y, 1997, P SIGGRAPH 97, P379; Seitz SM, 1999, INT J COMPUT VISION, V35, P151, DOI 10.1023/A:1008176507526; Shashua A, 1992, THESIS MIT; Sidenbladh H., 2000, LNCS, V2, P702; SILVA C, 2000, P 6 EUR C COMP VIS, V1, P100; SMITH P, 2000, P 6 EUR C COMP VIS, V2, P396; Snow D, 2000, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2000.855839; Szeliski R, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P517, DOI 10.1109/ICCV.1998.710766; Szeliski R, 1996, IEEE COMPUT GRAPH, V16, P22, DOI 10.1109/38.486677; Szeliski R, 2000, PROC CVPR IEEE, P246, DOI 10.1109/CVPR.2000.855826; SZELISKI R, 1999, P CVPR, V1, P157; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105; Tzovaras D, 1997, IEEE T CIRC SYST VID, V7, P312, DOI 10.1109/76.564110; Vedula S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P722, DOI 10.1109/ICCV.1999.790293; Vedula S, 2000, PROC CVPR IEEE, P592, DOI 10.1109/CVPR.2000.854926; Wang J. Y. A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P361, DOI 10.1109/CVPR.1993.341105; Watt Alan, 2000, 3D COMPUTER GRAPHICS; WEXLER Y, 1999, P IEEE C COMP VIS PA, V1, P333; Wolff LB, 1998, INT J COMPUT VISION, V30, P55, DOI 10.1023/A:1008017513536; Wood DN, 2000, COMP GRAPH, P287, DOI 10.1145/344779.344925; Yacoob Y, 2000, INT J COMPUT VISION, V36, P5, DOI 10.1023/A:1008173322902; YE M, 2000, P IEEE C COMP VIS PA, V2, P623; Yu YZ, 1999, COMP GRAPH, P215; Zelnik-Manor L, 2000, IEEE T PATTERN ANAL, V22, P1105, DOI 10.1109/34.879791; Zhang Y, 2000, PROC CVPR IEEE, P674, DOI 10.1109/CVPR.2000.854939; Zhou L, 2000, PROC CVPR IEEE, P752, DOI 10.1109/CVPR.2000.854950; Zhou L, 2000, PROC CVPR IEEE, P744, DOI 10.1109/CVPR.2000.854949	99	63	64	0	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP-OCT	2002	49	2-3					175	214		10.1023/A:1020145606604	http://dx.doi.org/10.1023/A:1020145606604			40	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	590TA					2022-12-18	WOS:000177837100005
J	Capurro, C; Panerai, F; Sandini, G				Capurro, C; Panerai, F; Sandini, G			Dynamic vergence using log-polar images	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						log-polar; active vision; vergence; fusion; divergence	FUNCTIONAL ARCHITECTURE; CORTEX; MOTION; STRIATE; FIELD	Vergence provides robot vision systems with a crucial degree of freedom: it enables fixation of points in visual space at different distances from the observer. Vergence control, therefore, affects the performance of the stereo system as well as the results of motion estimation and tracking and, as such, must satisfy different requirements in order to be able to provide not only a stable fixation, but a stable binocular fusion, and a fast, smooth and accurate reaction to changes in the environment. To obtain this kind of performance the paper focuses specifically on the use of dynamic visual information to drive vergence control. In this context, moreover, the use of a space-variant, anthropomorphic sensor is described and some advantages in relation to vergence control are discussed to demonstrate the relevance of image plane geometry for this particular task. Expansion or contraction patterns and the temporal evolution of the degree of fusion measured in the log-polar domain are the inputs to the vergence control system and determine robust and accurate steering of the two cameras. Real-time experiments are presented to demonstrate the performance of the system covering different key situations.			Capurro, C (corresponding author), UNIV GENOA,DEPT COMMUN COMP & SYST SCI,LIRA LAB,GENOA,ITALY.							ALLMAN JM, 1971, BRAIN RES, V35, P89, DOI 10.1016/0006-8993(71)90596-8; BERNARDINO A, 1996, P INT C INT ROB SYST; CAPURRO C, 1995, P SPIE AER ORL FLOR; CAPURRO C, 1996, P INT C PATT REC VIE; Carpenter RHS, 1991, EYE MOVEMENTS; CIPOLLA R, 1992, P ECCV 92; COOMBS D, 1993, INT J COMPUT VISION, V11, P147, DOI 10.1007/BF01469226; COOMBS D, 1990, P 5 IEEE INT S INT C; COOMBS D, 1990, P AAAI 90 WORKSH QUA; COWEY A, 1964, J NEUROPHYSIOL, V27, P266; DANIEL PM, 1961, J PHYSIOL-LONDON, V159, P203, DOI 10.1113/jphysiol.1961.sp006803; DEBUSSCHERE I, 1989, P 5 INT SOL STAT SEN; FERRARI F, 1994, 1038 TID; Ferrari F., 1995, SENSOR REV, V15, P17; Fisher T. E., 1988, Proceedings of the SPIE - The International Society for Optical Engineering, V938, P122, DOI 10.1117/12.976584; GRISWOLD NC, 1992, COMPUTER VISION IMAG, P421; HORN BKP, 1986, ROBUST VISION; HUBEL DH, 1977, PROC R SOC SER B-BIO, V198, P1, DOI 10.1098/rspb.1977.0085; IRANI M, 1994, P IEEE CVPR SEATTL U; JENKIN M, 1991, CVGIP IMAGE UNDERSTA, V53; JUDGE SJ, 1991, EYE MOVEMENTS, P157; JULESZ B, 1986, VISION RES, V26, P1601, DOI 10.1016/0042-6989(86)90178-1; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; NEGAHDARIPOUR S, 1992, INT J COMPUT VISION, V9, P163, DOI 10.1007/BF00133700; NELSON RC, 1989, IEEE T PATTERN ANAL, V11, P1102, DOI 10.1109/34.42840; NIELSEN J, 1994, IEEE INT C SYST MAN; NORDLUND TUP, 1995, P 6 INT C COMP AN IM; Ogle K. N., 1964, RES BINOCULAR VISION; PAHLAVAN K, 1992, P 2 EUR C COMP VIS S, P526; QUESTA P, 1996, P INT C INT ROB SYST; ROJER AS, 1990, P INT C PATT REC PHI; SANGER TD, 1988, BIOL CYBERN, V59, P405, DOI 10.1007/BF00336114; SANTOSVICTOR J, 1995, P INT C INT AUT SYST; SCHEFFER D, 1996, P EUR BES; SCHWARTZ EL, 1980, BIOL CYBERN, V37, P63, DOI 10.1007/BF00364246; SCHWARTZ EL, 1977, BIOL CYBERN, V25, P181, DOI 10.1007/BF01885636; SHARKEY P, 1993, MECHATRONICS, V3; SUBBARAO M, 1986, COMPUT VISION GRAPH, V36, P208, DOI 10.1016/0734-189X(86)90076-9; SUNDERESWARAN V, 1991, P IEEE WORKSH VIS MO; THEIMER WM, 1992, P SPIE INTELLIGENT R, V11; TISTARELLI M, 1993, IEEE T PATTERN ANAL, V15, P401, DOI 10.1109/34.206959; TUNLEY H, 1994, P 3 EUR C COMP VIS; VLEESCHAUWER DD, 1993, CVGIP IMAGE UNDERSTA, V57; WEIMAN C, 1995, P SPIE AEROSENSE95 O; WEIMAN C, 1994, NAS918637 NASA; WEIMAN C, 1990, SPIE INT C INTELLIGE, V8, P843	46	63	63	0	3	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	1997	24	1					79	94		10.1023/A:1007974208880	http://dx.doi.org/10.1023/A:1007974208880			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	XV644					2022-12-18	WOS:A1997XV64400005
J	PEREZ, F; KOCH, C				PEREZ, F; KOCH, C			TOWARD COLOR IMAGE SEGMENTATION IN ANALOG VLSI - ALGORITHM AND HARDWARE	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							DETECTING DISCONTINUITIES; EARLY VISION; ILLUMINATION; CORTEX	Standard techniques for segmenting color images are based on finding normalized RGB discontinuities, color histogramming, or clustering techniques in RGB or CIE color spaces. The use of the psychophysical variable hue in HSI space has not been popular due to its numerical instability at low saturations. In this article, we propose the use of a simplified hue description suitable for implementation in analog VLSI. We demonstrate that if the integrated white condition holds, hue is invariant to certain types of highlights, shading, and shadows. This is due to the additive/shift invariance property, a property that other color variables lack. The more restrictive uniformly varying lighting model associated with the multiplicative/scale invariance property shared by both hue and normalized RGB allows invariance to transparencies, and to simple models of shading and shadows. Using binary hue discontinuities in conjunction with first-order type of surface interpolation, we demonstrate these invariant properties and compare them against the performance of RGB, normalized RGB, and CIE color spaces. We argue that working in HSI space offers an effective method for segmenting scenes in the presence of confounding cues due to shading, transparency, highlights, and shadows. Based on this work, we designed and fabricated for the first time an analog CMOS VLSI circuit with on-board phototransistor input that computes normalized color and hue.			PEREZ, F (corresponding author), CALTECH,COMPUTAT & NEURAL SYST PROGRAM,216-76,PASADENA,CA 91125, USA.			Koch, Christof/0000-0001-6482-8067				ABDOU IE, 1979, P IEEE, V67, P753, DOI 10.1109/PROC.1979.11325; BAJCSY R, 1990, 10TH P INT C PATT B, P785; Barth M., 1986, Proceedings 1986 IEEE International Conference on Robotics and Automation (Cat. No.86CH2282-2), P1242; Berlin B., 1969, BASIC COLOR TERMS; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CELENK M, 1990, COMPUT VISION GRAPH, V52, P145, DOI 10.1016/0734-189X(90)90052-W; Cook R. L., 1981, Computer Graphics, V15, P307, DOI 10.1145/965161.806819; Daily M. J., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P304, DOI 10.1109/CVPR.1989.37865; Delbruck T., 1993, THESIS CALTECH; DESIMONE R, 1985, VISION RES, V25, P441, DOI 10.1016/0042-6989(85)90069-0; DEVALOIS RL, 1975, HDB PERCEPTION, V5, P117; DILLON P, 1985, IEEE T ELECTRON DEV, V25, P97; GEIGER D, 1991, IEEE T PATTERN ANAL, V13, P401, DOI 10.1109/34.134040; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GENZ SE, 1990, IMAGE PROCESSING HDB, P56; GERSHON R, 1986, J OPT SOC AM A, V3, P1700, DOI 10.1364/JOSAA.3.001700; GERSHON R, 1985, COMPUT VIS GRAPH IMA, V32, P245; GILBERT B, 1975, ELECTRON LETT, V11, P14, DOI 10.1049/el:19750011; HARRIS JG, 1990, INT J COMPUT VISION, V4, P211, DOI 10.1007/BF00054996; HARRIS JG, 1990, SCIENCE, V248, P1209, DOI 10.1126/science.2349479; HEALEY G, 1989, J OPT SOC AM A, V6, P920, DOI 10.1364/JOSAA.6.000920; HEALEY G, 1987, P DARPA IMAGE UNDERS, P599; HURLBERT A, 1989, ADV NEURAL INFORMATI, V1, P297; INGLING CR, 1977, VISION RES, V17, P1075, DOI 10.1016/0042-6989(77)90013-X; Jain A. K., 1989, FUNDAMENTALS DIGITAL; Joblove GH, 1978, COMPUT GRAPH, V12, P20, DOI DOI 10.1145/965139.807362; KENDER JR, 1976, SATURATION HUE NORMA; KLINKER GJ, 1990, INT J COMPUT VISION, V4, P7, DOI 10.1007/BF00137441; KLINKER GJ, 1988, INT J COMPUT VISION, V2, P7, DOI 10.1007/BF00836279; KOCH C, 1991, OCT IEEE WORKSH VIS, P312; Koch C, 1989, NEURAL COMPUT, V1, P184, DOI 10.1162/neco.1989.1.2.184; LENNIE P, 1988, CRIT REV NEUROBIOL, V3, P333; Mead, 1989, ANALOG VLSI NEURAL S; NEVATIA R, 1977, IEEE T SYST MAN CYB, V7, P820; OHLANDER R, 1976, THESIS CARNEGIE MELL; OHTA Y, 1980, COMPUT VISION GRAPH, V13, P222, DOI 10.1016/0146-664X(80)90047-7; PEREZ FA, 1992, 4TH ROCKW ANN TECH C, P246; PEREZ FA, 1992, CNS20 CALTECH MEM; PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839; POGGIO T, 1988, SCIENCE, V242, P436, DOI 10.1126/science.3175666; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; RUBIN JM, 1982, BIOL CYBERN, V45, P215, DOI 10.1007/BF00336194; RUBIN JM, 1984, AI764 MIT MEM; SCHWARZ MW, 1987, ACM T GRAPHIC, V6, P123, DOI 10.1145/31336.31338; SEEVINK E, 1988, ANAL SYNTHESIS TRANS; SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409; SIVILOTTI MA, 1987, 1987 STANF C VLSI, P25; SMITH BT, 1978, PEDIATR RES, V12, P12, DOI 10.1203/00006450-197801000-00004; TERZOPOULOS D, 1985, AI800 MIT MEM; TOMINAGA S, 1987, PATTERN RECOGN LETT, V6, P77, DOI 10.1016/0167-8655(87)90052-3; TOMINAGA S, 1990, 10TH INT C PATT REC, P803; Toumazou C., 1990, ANALOGUE IC DESIGN C; Wolfe W., 1985, INFRARED HDB; WRIGHT WA, 1989, IMAGE VISION COMPUT, V7, P144, DOI 10.1016/0262-8856(89)90009-7; Wyszecki Gunter, 1982, COLOR SCI, V8; ZEKI S, 1983, NEUROSCIENCE, V9, P741, DOI 10.1016/0306-4522(83)90265-8	57	63	67	1	1	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	FEB	1994	12	1					17	42		10.1007/BF01420983	http://dx.doi.org/10.1007/BF01420983			26	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	MV217		Green Accepted			2022-12-18	WOS:A1994MV21700002
J	Lin, L; Wang, KZ; Zuo, WM; Wang, M; Luo, JB; Zhang, L				Lin, Liang; Wang, Keze; Zuo, Wangmeng; Wang, Meng; Luo, Jiebo; Zhang, Lei			A Deep Structured Model with Radius-Margin Bound for 3D Human Activity Recognition	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Human action and activity; RGB-depth analysis; Structured model; Deep learning	VIDEO; GRAMMAR; EVENTS	Understanding human activity is very challenging even with the recently developed 3D/depth sensors. To solve this problem, this work investigates a novel deep structured model, which adaptively decomposes an activity instance into temporal parts using the convolutional neural networks. Our model advances the traditional deep learning approaches in two aspects. First, we incorporate latent temporal structure into the deep model, accounting for large temporal variations of diverse human activities. In particular, we utilize the latent variables to decompose the input activity into a number of temporally segmented sub-activities, and accordingly feed them into the parts (i.e. sub-networks) of the deep architecture. Second, we incorporate a radius-margin bound as a regularization term into our deep model, which effectively improves the generalization performance for classification. For model training, we propose a principled learning algorithm that iteratively (i) discovers the optimal latent variables (i.e. the ways of activity decomposition) for all training instances, (ii) updates the classifiers based on the generated features, and (iii) updates the parameters of multi-layer neural networks. In the experiments, our approach is validated on several complex scenarios for human activity recognition and demonstrates superior performances over other state-of-the-art approaches.	[Lin, Liang; Wang, Keze] Sun Yat Sen Univ, Guangzhou 510275, Guangdong, Peoples R China; [Lin, Liang; Wang, Keze; Zhang, Lei] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China; [Zuo, Wangmeng] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China; [Wang, Meng] Hefei Univ Technol, Hefei, Peoples R China; [Luo, Jiebo] Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA	Sun Yat Sen University; Hong Kong Polytechnic University; Harbin Institute of Technology; Hefei University of Technology; University of Rochester	Zuo, WM (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.	linliang@ieee.org; cswmzuo@gmail.com; eric.mengwang@gmail.com; jluo@cs.rochester.edu; cslzhang@comp.polyu.edu.hk	Luo, Jiebo/AAI-7549-2020; Cataldi, Antonio/AAM-7411-2021; Zuo, Wangmeng/B-3701-2008; Wang, Keze/Z-3605-2019	Wang, Keze/0000-0002-7817-8306; Zhang, Lei/0000-0002-2078-4215; Luo, Jiebo/0000-0002-4516-9729	Hong Kong Scholar Program; HK PolyU's Joint Supervision Scheme; Chinese Mainland University [G-SB20]; Taiwan University [G-SB20]; Macao University [G-SB20]; Guangdong Natural Science Foundation [S2013010013432, S2013050014548]; Guangdong Science and Technology Program [2013B010406005]	Hong Kong Scholar Program; HK PolyU's Joint Supervision Scheme; Chinese Mainland University; Taiwan University; Macao University; Guangdong Natural Science Foundation(National Natural Science Foundation of Guangdong Province); Guangdong Science and Technology Program	This work was supported in part by the Hong Kong Scholar Program, and in part by the HK PolyU's Joint Supervision Scheme with the Chinese Mainland, Taiwan and Macao Universities (Grant no. G-SB20), in part by Guangdong Natural Science Foundation (Grant nos. S2013010013432 and S2013050014548), and in part by Guangdong Science and Technology Program (Grant no. 2013B010406005).	Amer MR, 2012, PROC CVPR IEEE, P1314, DOI 10.1109/CVPR.2012.6247816; [Anonymous], P 21 ACM INT C MULT, DOI DOI 10.1145/2502081.2502099; Bayer J., 2014, P ICLR; Brendel W, 2011, IEEE I CONF COMP VIS, P778, DOI 10.1109/ICCV.2011.6126316; Chapelle O, 2002, MACH LEARN, V46, P131, DOI 10.1023/A:1012450327387; Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013; Cheng Z, 2011, ACM MULTIMEDIA, P1401; Chung KM, 2003, NEURAL COMPUT, V15, P2643, DOI 10.1162/089976603322385108; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Do H., 2013, ICML; Do H, 2009, LECT NOTES ARTIF INT, V5781, P315, DOI 10.1007/978-3-642-04180-8_38; Donahue J., 2015, CVPR; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Huang Fu Jie, 2006, 2006 IEEE COMPUTER S, V1, P284, DOI 10.1109/CVPR.2006.164; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Karpathy A., 2014, CVPR; Koppula H., 2013, INT C MACHINE LEARNI, P792, DOI DOI 10.1177/0278364913478446; Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; LeCun Y., 1989, ADV NEURAL INF PROCE, V2; Liang Xiaodan, 2013, P 21 ACM INT C MULT, P263; Lin L, 2015, IEEE T PATTERN ANAL, V37, P959, DOI 10.1109/TPAMI.2014.2359888; Lin L, 2009, PATTERN RECOGN, V42, P1297, DOI 10.1016/j.patcog.2008.10.033; Lu Xia, 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233; Luo P., 2014, CVPR; Luo P, 2013, IEEE I CONF COMP VIS, P2864, DOI 10.1109/ICCV.2013.356; Ni B., 2013, IEEE INT C WORKSH AU, P1, DOI DOI 10.1109/FG.2013.6553756; Ni Bingbing, 2013, CONSUMER DEPTH CAMER, P193, DOI DOI 10.1007/978-1-4471-4640-7_10; Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98; Packer B, 2012, PROC CVPR IEEE, P1378, DOI 10.1109/CVPR.2012.6247824; Pei MT, 2011, IEEE I CONF COMP VIS, P487, DOI 10.1109/ICCV.2011.6126279; Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806; Scovanner P., 2007, ACM MM, P357; Sermanet P., 2013, CVPR; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591; Tang K, 2012, PROC CVPR IEEE, P1250, DOI 10.1109/CVPR.2012.6247808; Vapnik V.N, 1998, STAT LEARNING THEORY; Venugopalan S., 2015, N AM CHAPT ASS COMP; Wang CY, 2013, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2013.123; Wang J, 2013, IEEE I CONF COMP VIS, P2688, DOI 10.1109/ICCV.2013.334; Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813; Wang K., 2014, ACM MM; Wang Y, 2011, IEEE T PATTERN ANAL, V33, P1310, DOI 10.1109/TPAMI.2010.214; WU CFJ, 1983, ANN STAT, V11, P95, DOI 10.1214/aos/1176346060; Wu P., 2013, PROC 21 ACM INT C MU, P153, DOI [10.1145/2502081.2502112, DOI 10.1145/2502081.2502112]; Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365; Yang X., 2012, P 20 ACM INT C MULTI, P1057, DOI [10.1145/2393347.2396382, DOI 10.1145/2393347.2396382]; Yu K, 2011, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2011.5995732; Yun K., 2012, COMP VIS PATT REC WO; Zhao X., 2013, P ACM INT C MULT, P273; Zhou X., 2009, ACM MULTIMEDIA, P229; Zhu SC, 2006, FOUND TRENDS COMPUT, V2, P259, DOI 10.1561/0600000018	55	62	64	0	30	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2016	118	2			SI		256	273		10.1007/s11263-015-0876-z	http://dx.doi.org/10.1007/s11263-015-0876-z			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	DO0OE		Green Submitted			2022-12-18	WOS:000377477400009
J	Zhang, XQ; Hu, WM; Xie, NH; Bao, HJ; Maybank, S				Zhang, Xiaoqin; Hu, Weiming; Xie, Nianhua; Bao, Hujun; Maybank, Stephen			A Robust Tracking System for Low Frame Rate Video	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Low frame rate; Tracking; Dominant color; Bin-ratio matching metric; Particle swarm optimization	OBJECT TRACKING; PARTICLE; MODELS	Tracking in low frame rate (LFR) videos is one of the most important problems in the tracking literature. Most existing approaches treat LFR video tracking as an abrupt motion tracking problem. However, in LFR video tracking applications, LFR not only causes abrupt motions, but also large appearance changes of objects because the objects' poses and the illumination may undergo large changes from one frame to the next. This adds extra difficulties to LFR video tracking. In this paper, we propose a robust and general tracking system for LFR videos. The tracking system consists of four major parts: dominant color-spatial based object representation, bin-ratio based similarity measure, annealed particle swarm optimization (PSO) based searching, and an integral image based parameter calculation. The first two parts are combined to provide a good solution to the appearance changes, and the abrupt motion is effectively captured by the annealed PSO based searching. Moreover, an integral image of model parameters is constructed, which provides a look-up table for parameters calculation. This greatly reduces the computational load. Experimental results demonstrate that the proposed tracking system can effectively tackle the difficulties caused by LFR.	[Zhang, Xiaoqin] Wenzhou Univ, Inst Intelligent Syst & Decis, Hangzhou, Zhejiang, Peoples R China; [Hu, Weiming; Xie, Nianhua] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China; [Bao, Hujun] Zhejiang Univ, Dept Comp Sci, Hangzhou, Zhejiang, Peoples R China; [Maybank, Stephen] Birkbeck Coll, Dept Comp Sci & Informat Syst, London, England	Wenzhou University; Chinese Academy of Sciences; Institute of Automation, CAS; Zhejiang University; University of London; Birkbeck University London	Zhang, XQ (corresponding author), Wenzhou Univ, Inst Intelligent Syst & Decis, Hangzhou, Zhejiang, Peoples R China.	zhangxiaoqinnan@gmail.com; wmhu@nlpr.ia.ac.cn; nhxie@nlpr.ia.ac.cn; bao@cad.zju.edu.cn; sjmaybank@dcs.bbk.ac.uk						Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374; Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53; Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35; Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226; Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436; Bray M, 2007, IMAGE VISION COMPUT, V25, P352, DOI 10.1016/j.imavis.2005.10.009; Carrano C. J., 2009, P SOC PHOTO-OPT INS, V7445; CHOO K, 2001, P INT C COMP VIS; Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P281, DOI 10.1109/TPAMI.2003.1177159; de Freitas JFG, 2000, NEURAL COMPUT, V12, P955, DOI 10.1162/089976600300015664; DEUTSCHER J, 2000, P IEEE C COMP VIS PA, V2, P126, DOI DOI 10.1109/CVPR.2000.854758; Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; Grabner H., 2006, 2006 IEEE COMP SOC C, V1, P260; Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19; Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606; Hu WM, 2012, IEEE T PATTERN ANAL, V34, P2420, DOI 10.1109/TPAMI.2012.42; INGBER L, 1993, MATH COMPUT MODEL, V18, P29, DOI 10.1016/0895-7177(93)90204-C; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968; Leung A.P., 2007, P IEEE C COMP VIS PA; Levy A, 2000, IEEE T IMAGE PROCESS, V9, P1371, DOI 10.1109/83.855432; Li Y, 2008, IEEE T PATTERN ANAL, V30, P1728, DOI 10.1109/TPAMI.2008.73; Lim J., 2004, ADV NEURAL INFORM PR, P793; LIN RS, 2004, ADV NEURAL INFORM PR, P801; Merwe R., 2000, CUEDFINFENGTR380; Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4; Pavan M., 2004, ADV NEURAL INFORM PR, V17, P1057; Pavan M., 2003, P IEEE C COMP VIS PA, P3895; Pitt MK, 1999, J AM STAT ASSOC, V94, P590, DOI 10.2307/2670179; Porikli F, 2005, PROC SPIE, V5685, P72, DOI 10.1117/12.587907; Porikli F, 2006, P IEEE COMP SOC C CO, P728, DOI [10.1109/CVPR.2006.94, DOI 10.1109/CVPR.2006.94]; PUZICHA J, 1997, P IEEE C COMP VIS PA; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Saffari A., 2010, P IEEE INT C COMP VI, P1393; Stauffer C., 1999, P IEEE COMP SOC C CO, V2; SULLIVAN J, 2001, P INT C COMP VIS; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Tomasi C, 1991, CMUCS91132; Tuzel O., 2008, P IEEE C COMP VIS PA, P1; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang HZ, 2007, IEEE T PATTERN ANAL, V29, P1661, DOI [10.1109/TPAMI.2007.1112, 10.1109/TPAMl.2007.1112]; Xie N., 2010, P IEEE C COMP VIS PA; Zhang T, 2009, IEEE DECIS CONTR P, P2552, DOI 10.1109/CDC.2009.5400892; Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152	48	62	65	1	18	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	2015	115	3					279	304		10.1007/s11263-015-0819-8	http://dx.doi.org/10.1007/s11263-015-0819-8			26	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	CW6EH		Green Accepted			2022-12-18	WOS:000365089800003
J	Wang, W; Slepcev, D; Basu, S; Ozolek, JA; Rohde, GK				Wang, Wei; Slepcev, Dejan; Basu, Saurav; Ozolek, John A.; Rohde, Gustavo K.			A Linear Optimal Transportation Framework for Quantifying and Visualizing Variations in Sets of Images	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Optimal transportation; Linear embedding	EARTH-MOVERS-DISTANCE; NUCLEAR-STRUCTURE; KANTOROVICH; REGISTRATION; MORPHOMETRY; BRAIN; FLOWS	Transportation-based metrics for comparing images have long been applied to analyze images, especially where one can interpret the pixel intensities (or derived quantities) as a distribution of 'mass' that can be transported without strict geometric constraints. Here we describe a new transportation-based framework for analyzing sets of images. More specifically, we describe a new transportation-related distance between pairs of images, which we denote as linear optimal transportation (LOT). The LOT can be used directly on pixel intensities, and is based on a linearized version of the Kantorovich-Wasserstein metric (an optimal transportation distance, as is the earth mover's distance). The new framework is especially well suited for computing all pairwise distances for a large database of images efficiently, and thus it can be used for pattern recognition in sets of images. In addition, the new LOT framework also allows for an isometric linear embedding, greatly facilitating the ability to visualize discriminant information in different classes of images. We demonstrate the application of the framework to several tasks such as discriminating nuclear chromatin patterns in cancer cells, decoding differences in facial expressions, galaxy morphologies, as well as sub cellular protein distributions.	[Wang, Wei; Basu, Saurav] Carnegie Mellon Univ, Dept Biomed Engn, Ctr Bioimage Informat, Pittsburgh, PA 15213 USA; [Slepcev, Dejan] Carnegie Mellon Univ, Dept Math Sci, Pittsburgh, PA 15213 USA; [Ozolek, John A.] Childrens Hosp Pittsburgh, Dept Pathol, Pittsburgh, PA 15224 USA; [Rohde, Gustavo K.] Carnegie Mellon Univ, Ctr Bioimage Informat, Dept Biomed Engn, Dept Elect & Comp Engn,Lane Ctr Computat Biol, Pittsburgh, PA 15213 USA	Carnegie Mellon University; Carnegie Mellon University; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Carnegie Mellon University	Rohde, GK (corresponding author), Carnegie Mellon Univ, Ctr Bioimage Informat, Dept Biomed Engn, Dept Elect & Comp Engn,Lane Ctr Computat Biol, Pittsburgh, PA 15213 USA.	wwang2@andrew.cmu.edu; slepcev@math.cmu.edu; sauravb@andrew.cmu.edu; ozolekja@upmc.edu; gustavor@cmu.edu	Slepcev, Dejan/E-8177-2016	Slepcev, Dejan/0000-0002-7600-1144; Rohde, Gustavo/0000-0003-1703-9035	NIH [GM088816, GM090033]; NSF [DMS-0908415]; Center for Nonlinear Analysis (NSF) [DMS-0635983]; NSF PIRE [OISE-0967140]; NATIONAL INSTITUTE OF GENERAL MEDICAL SCIENCES [R01GM090033, R21GM088816] Funding Source: NIH RePORTER	NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NSF(National Science Foundation (NSF)); Center for Nonlinear Analysis (NSF); NSF PIRE(National Science Foundation (NSF)NSF - Office of the Director (OD)); NATIONAL INSTITUTE OF GENERAL MEDICAL SCIENCES(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of General Medical Sciences (NIGMS))	The authors wish to thank the anonymous reviewers for helping significantly improve this paper. W. Wang, S. Basu, and G. K. Rohde acknowledge support from NIH grants GM088816 and GM090033 (PI GKR) for supporting portions of this work. D. Slepcev was also supported by NIH grant GM088816, as well as NSF grant DMS-0908415. He is also grateful to the Center for Nonlinear Analysis (NSF grant DMS-0635983 and NSF PIRE grant OISE-0967140) for its support.	Angenent S, 2003, SIAM J MATH ANAL, V35, P61, DOI 10.1137/S0036141002410927; Barrett JW, 2009, INTERFACE FREE BOUND, V11, P201; Beg MF, 2005, INT J COMPUT VISION, V61, P139, DOI 10.1023/B:VISI.0000043755.93987.aa; Benamou JD, 2000, NUMER MATH, V84, P375, DOI 10.1007/s002119900117; Bengtsson E., 1999, Medical Imaging Technology, V17, P203; Bishop C.M, 2006, PATTERN RECOGN; Blum H., 1967, MODELS PERCEPTION SP, P362, DOI DOI 10.1142/S0218654308001154; Boland MV, 2001, BIOINFORMATICS, V17, P1213, DOI 10.1093/bioinformatics/17.12.1213; Chefd'hotel C, 2007, PROC SPIE, V6512, DOI 10.1117/12.709490; Delzanno GL, 2010, SIAM J SCI COMPUT, V32, P3524, DOI 10.1137/090749785; Dialynas GK, 2008, MUTAT RES-FUND MOL M, V647, P13, DOI 10.1016/j.mrfmmm.2008.09.007; do Carmo M. P., 1992, RIEMANNIAN GEOMETRY; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Gardner MK, 2010, CELL MOL BIOENG, V3, P163, DOI 10.1007/s12195-010-0101-7; GRAUMAN K, 2004, P 2004 IEEE COMP SOC; Haber E, 2010, SIAM J SCI COMPUT, V32, P197, DOI 10.1137/080730238; Haker S, 2004, INT J COMPUT VISION, V60, P225, DOI 10.1023/B:VISI.0000036836.66311.97; Jacobs D., 2008, P 2008 IEEE COMP SOC; Kong J, 2009, PATTERN RECOGN, V42, P1080, DOI 10.1016/j.patcog.2008.10.035; Ling H, 2007, IEEE T PATTERN ANAL, V29, P840, DOI 10.1109/TPAMI.2007.1058; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; Loo LH, 2007, NAT METHODS, V4, P445, DOI 10.1038/NMETH1032; Mehrotra S, 1992, SIAM J OPTIMIZ, V2, P575, DOI 10.1137/0802028; Miller MI, 2009, HUM BRAIN MAPP, V30, P2132, DOI 10.1002/hbm.20655; Moss TJ, 2007, MUTAT RES-FUND MOL M, V618, P163, DOI 10.1016/j.mrfmmm.2006.05.038; ORLIN JB, 1993, OPER RES, V41, P338, DOI 10.1287/opre.41.2.338; Pele O, 2009, IEEE I CONF COMP VIS, P460, DOI 10.1109/ICCV.2009.5459199; Pincus Z, 2007, J MICROSC-OXFORD, V227, P140, DOI 10.1111/j.1365-2818.2007.01799.x; Rohde GK, 2008, CYTOM PART A, V73A, P341, DOI 10.1002/cyto.a.20506; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Rueckert D, 2003, IEEE T MED IMAGING, V22, P1014, DOI 10.1109/TMI.2003.815865; Shamir L, 2009, MONTHLY NOTICES ROYA; Stegmann MB, 2003, IEEE T MED IMAGING, V22, P1319, DOI 10.1109/TMI.2003.817780; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Vaillant M, 2004, NEUROIMAGE, V23, pS161, DOI 10.1016/j.neuroimage.2004.07.023; Villani C., 2003, GRAD STUD MATH, V58; Villani C, 2009, GRUNDLEHR MATH WISS, V338, P5; Wang W, 2011, PATTERN RECOGN LETT, V32, P2128, DOI 10.1016/j.patrec.2011.08.010; Wang W, 2011, IEEE T MED IMAGING, V30, P621, DOI 10.1109/TMI.2010.2089693; Wang W, 2010, CYTOM PART A, V77A, P485, DOI 10.1002/cyto.a.20853; Werman M., 2008, ECCV; Yang L, 2009, IEEE T INF TECHNOL B, V13, P636, DOI 10.1109/TITB.2009.2020159	44	62	63	0	15	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2013	101	2					254	269		10.1007/s11263-012-0566-z	http://dx.doi.org/10.1007/s11263-012-0566-z			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	081BW	23729991	Green Accepted, Green Submitted			2022-12-18	WOS:000314291600002
J	Duits, R; Felsberg, M; Granlund, G; Romeny, BT				Duits, Remco; Felsberg, Michael; Granlund, Gosta; Ter Haar Romeny, Bart			Image analysis and reconstruction using a wavelet transform constructed from a reducible representation of the Euclidean motion group	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	Early Cognitive Vision Workshop	MAY 29-JUN 01, 2004	Isle Skye, SCOTLAND	ECOVISION			CORTEX	Inspired by the early visual system of many mammalians we consider the construction of-and reconstruction from-an orientation score U-f : R-2 X S-1 -> C as a local orientation representation of an image, f : R-2 -> R. The mapping f -> U-f is a wavelet transform W-psi corresponding to a reducible representation of the Euclidean motion group onto L-2(R-2) and oriented wavelet psi is an element of L-2(R-2). This wavelet transform is a special case of a recently developed generalization of the standard wavelet theory and has the practical advantage over the usual wavelet approaches in image analysis (constructed by irreducible representations of the similitude group) that it allows a stable reconstruction from one (single scale) orientation score. Since our wavelet transform is a unitary mapping with stable inverse, we directly relate operations on orientation scores to operations on images in a robust manner. Furthermore, by geometrical examination of the Euclidean motion group G = R-2 x T, which is the domain of our orientation scores, we deduce that an operator Phi on orientation scores must be left invariant to ensure that the corresponding operator W-psi(-1) Phi W-psi on images is Euclidean invariant. As an example we consider all linear second order left invariant evolutions on orientation scores corresponding to stochastic processes on G. As an application we detect elongated structures in (medical) images and automatically close the gaps between them. Finally, we consider robust orientation estimates by means of channel representations, where we combine robust orientation estimation and learning of wavelets resulting in an auto-associative processing of orientation features. Here linear averaging of the channel representation is equivalent to robust orientation estimation and an adaptation of the wavelet to the statistics of the considered image class leads to an auto-associative behavior of the system.	Eindhoven Univ Technol, Dept Biomed Engn, NL-5600 MB Eindhoven, Netherlands; Linkoping Univ, Dept Elect Engn, Comp Vis Lab, S-58183 Linkoping, Sweden	Eindhoven University of Technology; Linkoping University	Duits, R (corresponding author), Eindhoven Univ Technol, Dept Biomed Engn, POB 513, NL-5600 MB Eindhoven, Netherlands.	R.Duits@tue.nl; mfe@isy.liu.se; gosta@isy.liu.se; B.M.terHaarRomeny@tue.nl	Romenij, Bart M. ter Haar/A-5323-2013	Felsberg, Michael/0000-0002-6096-3648				Ali S.T., 1999, COHERENT STATES WAVE; ALI ST, 1998, J MATH PHYS, P39; Antonacopoulou E. P., 1999, INT J TRAINING DEV, V3, P14, DOI DOI 10.1111/1468-2419.00061; ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI 10.1090/s0002-9947-1950-0051437-7; AUGUST J, 2003, IEEE PAMI PATTERN RE, P25; Bosking WH, 1997, J NEUROSCI, V17, P2112; DUITS M, 2005, THESIS EINDHOVEN U T; DUITS M, 2004, THESIS EINDHOVEN U T; DUITS M, 2004, RANA72004 RANACASA D; Duits R, 2004, J MATH IMAGING VIS, V20, P267, DOI 10.1023/B:JMIV.0000024043.96722.aa; DUITS R, 2005, EXPLICIT SOLUTIONS L, P5; DUITS R, 2004, 0404 TUE DEP BIOM EN; Duits R., 2004, 7 INT C PATT REC IM, P193; DUNGEY N, 2003, ANAL LIE GROUPS POLY, V214; EIJNDHOVEN SJL, 1982, P KON AK WET A, V86, P77; Faraut J., 1984, 2 COURS ANAL HARMONI; Felsberg M, 2006, IEEE T PATTERN ANAL, V28, P209, DOI 10.1109/TPAMI.2006.29; FELSBERG M, 2004, LITHISYR2619; Florack LMJ, 1997, IMAGE STRUCTURE; Forssen P. E., 2004, THESIS LINKOPING U L; FORSSEN PE, 2000, LECT NOTES COMPUTER, V1888; GROSSMANN A, 1985, J MATH PHYS, V26, P2473, DOI 10.1063/1.526761; ISHAM CJ, 1991, J MATH PHYS, V32, P607, DOI 10.1063/1.529402; Kalitzin SN, 1999, INT J COMPUT VISION, V31, P145, DOI 10.1023/A:1008013815039; Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406; Louis A.K., 1997, WAVELETS THEORY APPL; MARTENS FJL, 2004, THESIS U TECHNOLOGY; Mumford D., 1994, ALGEBRAIC GEOMETRY I, V5681, P491, DOI DOI 10.1007/978-1-4612-2628-4_31; SUGIURA M, 1990, UNITARY REPRESENTATI, P44; Thornber KK, 1996, BIOL CYBERN, V75, P141, DOI 10.1007/s004220050282; TSO DY, 1990, SCIENCE, V249, P417, DOI 10.1126/science.2165630; van Ginkel M., 2002, THESIS DELFT U TECHN; VANALMSICK MA, 2005, P DSSCC WORKSH DEEP; VANDERPUT RW, 2005, BMIA0502 EINDH U TEC; Williams LR, 2003, BIOL CYBERN, V88, P2, DOI 10.1007/s00422-002-0370-x; [No title captured]	36	62	62	0	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	2007	72	1					79	102		10.1007/s11263-006-8894-5	http://dx.doi.org/10.1007/s11263-006-8894-5			24	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	122QR		Green Published			2022-12-18	WOS:000243242000006
J	Jones, MJ; Poggio, T				Jones, MJ; Poggio, T			Multidimensional morphable models: A framework for representing and matching object classes	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						object representations; image analysis; correspondence; object recognition	RECOGNITION	We describe a flexible model for representing images of objects of a certain class, known a priori, such as faces, and introduce a new algorithm for matching it to a novel image and thereby perform image analysis. The flexible model, known as a multidimensional morphable model, is learned from example images of objects of a class. In this paper we introduce an effective stochastic gradient descent algorithm that automatically matches a model to a novel image. Several experiments demonstrate the robustness and the broad range of applicability of morphable models. Our approach can provide novel solutions to several vision tasks, including the computation of image correspondence, object verification and image compression.	Digital Equipment Corp, Cambridge Res Lab, Cambridge, MA 02139 USA; MIT, Artificial Intelligence Lab, Cambridge, MA 02139 USA; MIT, Ctr Biol & Computat Learning, Cambridge, MA 02139 USA	Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT)	Jones, MJ (corresponding author), Digital Equipment Corp, Cambridge Res Lab, 1 Kendall Sq,Bldg 700, Cambridge, MA 02139 USA.	mjones@crl.dec.com; tp@ai.mit.edu						ATICK J, 1995, NEURAL COMPUTATION; BERGEN JR, 1990, HIERARCHICAL MOTION; BESL PJ, 1985, COMPUT SURV, V17, P75, DOI 10.1145/4078.4081; Beymer D, 1996, SCIENCE, V272, P1905, DOI 10.1126/science.272.5270.1905; BEYMER D, 1995, THESIS MIT; BEYMER D, 1995, 1536 AI MIT; BEYMER D, 1995, 1537 AI MIT; BEYMER D, 1993, 1431 AI MIT; Blake A., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P185, DOI 10.1145/192161.192197; BULTHOFF HH, 1995, CEREB CORTEX, V5, P247, DOI 10.1093/cercor/5.3.247; Burt P.J., 1984, MULTIRESOLUTION IMAG, P6; CHOI CS, 1991, P IEEE INT S CIRC SY, P2665; COOTES T, 1994, INT C PATT REC, P610; Cootes T. F., 1992, BMVC92. Proceedings of the British Machine Vision Conference, P9; Cootes T. F., 1992, BMVC92. Proceedings of the British Machine Vision Conference, P266; COOTES TF, 1994, INT C PATT RECOG, P63, DOI 10.1109/ICPR.1994.576227; Cootes TF, 1993, ICCV, P242; EDELMAN S, 1990, 1239 AI MIT; EZZAT T, 1996, THESIS MIT; HALLINAN P, 1995, THESIS HARVARD U; Hill A., 1992, BMVC92. Proceedings of the British Machine Vision Conference, P276; Jones MJ, 1997, CURR BIOL, V7, P991, DOI 10.1016/S0960-9822(06)00419-2; JONES MJ, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P531, DOI 10.1109/ICCV.1995.466894; KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390; LANITIS A, 1995, IEEE INT C COMP VIS, P368; LOGOTHETIS NK, 1995, CURR BIOL, V5, P552, DOI 10.1016/S0960-9822(95)00108-4; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; NASTAR C, 1996, ECCV; PAULS J, 1996, EARLY VISUAL LEARNIN; Poggio T, 1996, IEEE SPECTRUM, V33, P60, DOI 10.1109/6.490058; Poggio T., 1992, 1347 AI MIT; POGGIO T, 1992, 1354 AI MIT; POGGIO T, 1990, 1253 AI MIT; RIKERT T, 1998, UNPUB C FAC GEST REC; ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586; Shashua A, 1992, THESIS MIT; SHASHUA A, 1992, 1363 AI MIT; Sinha P, 1996, NATURE, V384, P460, DOI 10.1038/384460a0; Sinha P., 1995, THESIS MIT; Troje NF, 1996, VISION RES, V36, P1761, DOI 10.1016/0042-6989(95)00230-8; TURK M, 1991, P IEEE C COMP VIS PA, P586, DOI DOI 10.1109/CVPR.1991.139758; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; VETTER T, 1995, 1531 AI MIT; VETTER T, 1997, IEEE C COMP VIS PATT, P40; VIOLA P, 1995, THESIS MIT	46	62	67	0	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG-SEP	1998	29	2					107	131		10.1023/A:1008074226832	http://dx.doi.org/10.1023/A:1008074226832			25	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	127DL					2022-12-18	WOS:000076335200002
J	Boyer, E; Berger, MO				Boyer, E; Berger, MO			3D surface reconstruction using occluding contours	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						surface reconstruction; rims; occluding contours; epipolar correspondence; epipolar curve	OBJECT; CURVE	This paper addresses the problem of 3D surface reconstruction using image sequences. It has been shown that shape recovery from three or more occluding contours of the surface is possible given a known camera motion. Several algorithms, which have been recently proposed, allow such a reconstruction under the assumption of a linear camera motion. A new approach is presented which deals with the reconstruction problem directly from a discrete point of view. First, a theoretical study of the epipolar correspondence between occluding contours is achieved. A correct depth formulation is then derived from a local approximation of the surface up to order two. This allows the local shape to be estimated, given three consecutive contours, without any constraints on the camera motion. Experimental results are presented for both synthetic and real data.			Boyer, E (corresponding author), INST NATL RECH INFORMAT & AUTOMAT LORRAINE, CRIN, CNRS, BP 239, F-54506 VANDOEUVRE LES NANCY, FRANCE.							BERGER MO, 1994, P 12 INT C PATT REC, V1, P32; Bruce JW, 1984, CURVES SINGULARITIES; CIPOLLA R, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P269, DOI 10.1109/ICCV.1995.466775; CIPOLLA R, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P616; Do Carmo M., 1976, DIFFERENTIAL GEOMETR; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; FORSYTH DA, 1992, LECT NOTES COMPUT SC, V588, P639; GIBLIN P, 1987, 1ST P INT C COMP VIS, P136; GIBLIN PJ, 1995, IMAGE VISION COMPUT, V13, P33, DOI 10.1016/0262-8856(95)91466-Q; GLACHET R, 1992, LECT NOTES COMPUT SC, V588, P681; JOSHI T, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P290, DOI 10.1109/ICCV.1995.466927; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KOENDERINK JJ, 1984, PERCEPTION, V13, P321, DOI 10.1068/p130321; KRIEGMAN DJ, 1990, IEEE T PATTERN ANAL, V12, P1127, DOI 10.1109/34.62602; PONCE J, 1989, IEEE T PATTERN ANAL, V11, P951, DOI 10.1109/34.35498; PORRILL J, 1991, IMAGE VISION COMPUT, V9, P45, DOI 10.1016/0262-8856(91)90048-T; RIEGER JH, 1986, OPT LETT, V11, P123, DOI 10.1364/OL.11.000123; SEALES WB, 1995, COMPUT VIS IMAGE UND, V61, P308, DOI 10.1006/cviu.1995.1025; Szeliski R., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P666, DOI 10.1109/CVPR.1993.341037; VAILLANT R, 1992, IEEE T PATTERN ANAL, V14, P157, DOI 10.1109/34.121787; Zerroug M., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P96, DOI 10.1109/CVPR.1993.340973; ZHAO C, 1994, LECT NOTES COMPUTER, V801, P417; [No title captured]	23	62	67	0	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR-APR	1997	22	3					219	233		10.1023/A:1007978616082	http://dx.doi.org/10.1023/A:1007978616082			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	XD969		Green Submitted			2022-12-18	WOS:A1997XD96900002
J	WEEMS, CC; LEVITAN, SP; HANSON, AR; RISEMAN, EM; SHU, DB; NASH, JG				WEEMS, CC; LEVITAN, SP; HANSON, AR; RISEMAN, EM; SHU, DB; NASH, JG			THE IMAGE UNDERSTANDING ARCHITECTURE	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article									UNIV MASSACHUSETTS,DEPT COMP & INFORMAT SCI,AMHERST,MA 01003; HUGHES RES LABS,MALIBU,CA 90265	University of Massachusetts System; University of Massachusetts Amherst; HRL Laboratories								ANNARONTONE M, 1987, IEEE T COMPUT, V36; [Anonymous], 1986, CONNECTION MACHINE; ARVIND DK, 1983, P IEEE INT S CIRC SY, P405; BATCHER KE, 1980, IEEE T COMP, V29; BEVERIDGE JR, 1989, INT J COMPUTER VISIO, V2; BURNS JB, 1986, IEEE T PATTERN ANAL, V8, P425, DOI 10.1109/TPAMI.1986.4767808; Crowther W., 1985, Proceedings of the 1985 International Conference on Parallel Processing (Cat. No.85CH2140-2), P531; DAVIS R, 1984, ELECTRONIC DESI 1031, P207; DRAPER BA, 1987, P IMAGE UNDERSTANDIN; DRAPER BA, 1989, INT J COMPUTER VISIO, V2; Duff M.J.B., 1978, P NATIONAL COMPUTER, P1055; DUFF MJB, 1986, INTERMEDIATE LEVEL I; ERMAN LD, 1980, COMPUT SURV, V12, P213, DOI 10.1145/356810.356816; FLEXNER S, 1987, RANDOM HOUSE UNABRID; Foster C. C., 1976, CONTENT ADDRESSABLE; Hanson A., 1978, COMPUTER VISION SYST, P303; Hanson A. R., 1978, COMPUTER VISION SYST, P129; Hanson A.R., 1980, STRUCTURED COMPUTER; HANSON AR, 1974, COINS74C7 U MASS TEC; HANSON AR, 1987, COINS8712 U MASS TEC; HANSON AR, 1986, VISION BRAIN COOPERA; HUNT DJ, 1981, LANGUAGES ARCHITECTU; KUMAR VKP, 1985, 12TH P ANN INT S COM; LEHRER NB, 1987, JUN P INT C COMP VIS, P578; LEVITAN SP, 1987, CHARACTERISTICS PARA; LEVITAN SP, 1984, COINS8411 U MASS TEC; LI H, 1987, P INT C PARALLEL PRO; MILLER R, 1987, USC IRIS229 U SO CAL; NAGIN PA, 1982, IEEE T PATTERN ANAL, V4, P263, DOI 10.1109/TPAMI.1982.4767243; NII HP, 1986, AI MAG, V7, P38; PARMA CC, 1980, APR NATO ADV STUD I; Pfister G. F., 1985, Proceedings of the 1985 International Conference on Parallel Processing (Cat. No.85CH2140-2), P764; RATTNER J, 1985, P NATL COMPUT C; REYNOLDS G, 1984, APR P WORKSH COMP VI, P238; RISEMAN EM, 1989, INT J COMPUTER VISIO, V2; ROSENFELD A, J PARALLEL DISTRIBUT, V3, P404; ROSENFELD A, 1987, P DARPA IMAGE UNDERS; SEITZ L, 1985, COMMUNICATIONS ACM 2, P22; TANIMOTO SL, 1983, 10TH P ANN INT S COM; UHR L, 1972, IEEE T COMPUT, VC 21, P758, DOI 10.1109/T-C.1972.223579; UHR L, 1987, PARALLEL COMPUTER VI; WEEMS CC, 1988, JUN P IEEE C COMP VI; WEEMS CC, 1984, JUL P WORKSH ALG GUI, P329; WEEMS CC, 1984, COINS8414 U MASS TEC; WEEMS CC, 1985, OCT P ICCD NEW YORK, P500; WEYMOUTH TE, 1986, COINS8624 U MASS TEC; 1985, PROMOTIONAL LIT; 1986, SEQUENT COMPUTER SYS; 1986, PROMOTIONAL LIT	49	62	62	0	2	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	1989	2	3					251	282		10.1007/BF00158166	http://dx.doi.org/10.1007/BF00158166			32	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AC191					2022-12-18	WOS:A1989AC19100003
J	Koller, O; Zargaran, S; Ney, H; Bowden, R				Koller, Oscar; Zargaran, Sepehr; Ney, Hermann; Bowden, Richard			Deep Sign: Enabling Robust Statistical Continuous Sign Language Recognition via Hybrid CNN-HMMs	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Sign language recognition; Hybrid approach; CNN-HMM; Statistical approach; Sequence modelling	FRAMEWISE	This manuscript introduces the end-to-end embedding of a CNN into a HMM, while interpreting the outputs of the CNN in a Bayesian framework. The hybrid CNN-HMM combines the strong discriminative abilities of CNNs with the sequence modelling capabilities of HMMs. Most current approaches in the field of gesture and sign language recognition disregard the necessity of dealing with sequence data both for training and evaluation. With our presented end-to-end embedding we are able to improve over the state-of-the-art on three challenging benchmark continuous sign language recognition tasks by between 15 and 38% relative reduction in word error rate and up to 20% absolute. We analyse the effect of the CNN structure, network pretraining and number of hidden states. We compare the hybrid modelling to a tandem approach and evaluate the gain of model combination.	[Koller, Oscar; Zargaran, Sepehr; Ney, Hermann] Rhein Westfal TH Aachen, Human Language Technol & Pattern Recognit, Aachen, Germany; [Bowden, Richard] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford, Surrey, England	RWTH Aachen University; University of Surrey	Koller, O (corresponding author), Rhein Westfal TH Aachen, Human Language Technol & Pattern Recognit, Aachen, Germany.	koller@cs.rwth-aachen.de	Koller, Oscar/W-8720-2019; Bowden, Richard/AAF-8283-2019	Bowden, Richard/0000-0003-3285-8020				[Anonymous], 1989, NIPS 1989; Assael Y. M., 2016, ARXIV161101599CS; BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370; BAKIS R, 1976, J ACOUST SOC AM, V59, pS97, DOI 10.1121/1.2003011; Bengio Y, 1996, IEEE T NEURAL NETWOR, V7, P1231, DOI 10.1109/72.536317; Bierbrauer A, 2017, IEEE PAC RIM CONF CO; Bluche T, 2015, PROC INT CONF DOC, P81, DOI 10.1109/ICDAR.2015.7333730; Bourlard H., 1993, CONNECTIONIST SPEECH; Camgoz N. C., 2017, IEEE INT C COMP VIS, P22; Cui Runpeng, 2017, IEEE C COMP VIS PATT; Dreuw P, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P293; Escalera S, 2015, LECT NOTES COMPUT SC, V8925, P459, DOI 10.1007/978-3-319-16178-5_32; Forster J., 2013, P 4 WORKSH SPEECH LA, P41; Forster J, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1911; Forster J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3785; Forster J, 2013, LECT NOTES COMPUT SC, V7887, P89; Golik P, 2013, INTERSPEECH, P1755; Granger N, 2017, LECT NOTES COMPUT SC, V10635, P147, DOI 10.1007/978-3-319-70096-0_16; Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042; Gweth Y.L., 2012, PROC IEEE COMPUTER S, P55; Hermansky H, 2000, INT CONF ACOUST SPEE, P1635, DOI 10.1109/ICASSP.2000.862024; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Koller O, 2017, IEEE C COMP VIS PATT; Koller O., 2016, BRIT MACH VIS C; Koller O., 2013, IEEE INT C AUT FAC G, P1, DOI [10.1109/FG.2013.6553777, DOI 10.1109/FG.2013.6553777]; Koller O., 2015, 3 WORKSH ASS COMP VI; Koller O, 2016, PROC CVPR IEEE, P3793, DOI 10.1109/CVPR.2016.412; Koller O, 2015, COMPUT VIS IMAGE UND, V141, P108, DOI 10.1016/j.cviu.2015.09.013; Koller O, 2014, LECT NOTES COMPUT SC, V8689, P281, DOI 10.1007/978-3-319-10590-1_19; Krishnan R, 2015, PATTERN RECOGN, V48, P1302, DOI 10.1016/j.patcog.2014.10.026; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Le H.-S., 2015, ADV INTELLIGENT SYST, P299; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Ma WY, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SMART CITY/SOCIALCOM/SUSTAINCOM (SMARTCITY), P1, DOI [10.1109/SmartCity.2015.38, 10.1109/NEBEC.2015.7117114]; Marcel S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P456, DOI 10.1109/AFGR.2000.840674; Molchanov Pavlo, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P1, DOI 10.1109/CVPRW.2015.7301342; Neverova N, 2015, LECT NOTES COMPUT SC, V8925, P474, DOI 10.1007/978-3-319-16178-5_33; Ney H, 2000, P IEEE, V88, P1224, DOI 10.1109/5.880081; Ong EJ, 2014, PROC CVPR IEEE, P1931, DOI 10.1109/CVPR.2014.248; Pigou L, 2018, INT J COMPUT VISION, V126, P430, DOI 10.1007/s11263-016-0957-7; Rao YM, 2017, IEEE I CONF COMP VIS, P3951, DOI 10.1109/ICCV.2017.424; Richard MD, 1991, NEURAL COMPUT, V3, P461, DOI 10.1162/neco.1991.3.4.461; Rybach D., 2011, IEEE AUT SPEECH REC; Schluter R, 2012, IEEE T PATTERN ANAL, V34, P292, DOI 10.1109/TPAMI.2011.163; Schober M., 2017, IEEE C COMP VIS PATT; Stolcke A., C INT SPEECH COMMUNI; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; von Agris Ulrich, 2008, Universal Access in the Information Society, V6, P323, DOI 10.1007/s10209-007-0104-x; Von Agris U., 2008, P 8 IEEE INT C AUT F, P1; Wu D., 2014, COMP VIS ECCV 2014 W, P552; Wu D, 2016, IEEE T PATTERN ANAL, V38, P1583, DOI 10.1109/TPAMI.2016.2537340	51	61	62	3	33	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	2018	126	12			SI		1311	1325		10.1007/s11263-018-1121-3	http://dx.doi.org/10.1007/s11263-018-1121-3			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	GZ3KT		Green Published, hybrid			2022-12-18	WOS:000449286200004
J	Rohrbach, M; Rohrbach, A; Regneri, M; Amin, S; Andriluka, M; Pinkal, M; Schiele, B				Rohrbach, Marcus; Rohrbach, Anna; Regneri, Michaela; Amin, Sikandar; Andriluka, Mykhaylo; Pinkal, Manfred; Schiele, Bernt			Recognizing Fine-Grained and Composite Activities Using Hand-Centric Features and Script Data	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Activity recognition; Fine-grained recognition; Script data; Hand detection		Activity recognition has shown impressive progress in recent years. However, the challenges of detecting fine-grained activities and understanding how they are combined into composite activities have been largely overlooked. In this work we approach both tasks and present a dataset which provides detailed annotations to address them. The first challenge is to detect fine-grained activities, which are defined by low inter-class variability and are typically characterized by fine-grained body motions. We explore how human pose and hands can help to approach this challenge by comparing two pose-based and two hand-centric features with state-of-the-art holistic features. To attack the second challenge, recognizing composite activities, we leverage the fact that these activities are compositional and that the essential components of the activities can be obtained from textual descriptions or scripts. We show the benefits of our hand-centric approach for fine-grained activity classification and detection. For composite activity recognition we find that decomposition into attributes allows sharing information across composites and is essential to attack this hard task. Using script data we can recognize novel composites without having training data for them.	[Rohrbach, Marcus; Rohrbach, Anna; Amin, Sikandar; Andriluka, Mykhaylo; Schiele, Bernt] Max Planck Inst Informat, Saarbrucken, Germany; [Rohrbach, Marcus] UC Berkeley EECS, Berkeley, CA 94720 USA; [Rohrbach, Marcus] ICSI, Berkeley, CA 94704 USA; [Regneri, Michaela; Pinkal, Manfred] Univ Saarland, Dept Computat Linguist & Phonet, Saarbrucken, Germany; [Amin, Sikandar] Tech Univ Munich, Dept Informat, Munich, Germany; [Andriluka, Mykhaylo] Stanford Univ, Stanford, CA 94305 USA; [Regneri, Michaela] Univ Saarland, SPIEGEL Verlag, IT Dept, Hamburg, Germany	Max Planck Society; Saarland University; Technical University of Munich; Stanford University; Saarland University	Rohrbach, M (corresponding author), Max Planck Inst Informat, Saarbrucken, Germany.; Rohrbach, M (corresponding author), UC Berkeley EECS, Berkeley, CA 94720 USA.; Rohrbach, M (corresponding author), ICSI, Berkeley, CA 94704 USA.	rohrbach@mpi-inf.mpg.de		Regneri, Michaela/0000-0001-8644-7839	FITweltweit-Program of the German Academic Exchange Service (DAAD); Cluster of Excellence "Multimodal Computing and Interaction" of the German Excellence Initiative; Max Planck Center for Visual Computing and Communication	FITweltweit-Program of the German Academic Exchange Service (DAAD)(Deutscher Akademischer Austausch Dienst (DAAD)); Cluster of Excellence "Multimodal Computing and Interaction" of the German Excellence Initiative; Max Planck Center for Visual Computing and Communication	This work was supported by a fellowship within the FITweltweit-Program of the German Academic Exchange Service (DAAD), by the Cluster of Excellence "Multimodal Computing and Interaction" of the German Excellence Initiative and the Max Planck Center for Visual Computing and Communication.	Amin S, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.45; ANDRILUKA M, 2009, P IEEE C COMP VIS PA; Andriluka M, 2012, INT J COMPUT VISION, V99, P259, DOI 10.1007/s11263-011-0498-z; [Anonymous], 2008, P IEEE C COMP VIS PA; [Anonymous], 2013, P IEEE INT C COMP VI; Aubert O., 2007, MM; Baccouche Moez, 2011, Human Behavior Unterstanding. Proceedings Second International Workshop, HBU 2011, P29, DOI 10.1007/978-3-642-25446-8_4; Barr A, 1981, HDB ARTIFICIAL INTEL, VI; Bloem J., 2012, KONVENS; Bojanowski Piotr, 2014, P EUR C COMP VIS ECC; Brendel W., 2011, P IEEE INT C COMP VI; Campbell LW, 1995, P IEEE INT C COMP VI; Chakraborty B., 2011, P IEEE INT C COMP VI; Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013; Chen D., 2011, P ANN M ASS COMP LIN; Cherian A., 2014, P IEEE C COMP VIS PA; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N., 2006, P EUR C COMP VIS ECC; Divvala SK, 2012, LECT NOTES COMPUT SC, V7585, P31, DOI 10.1007/978-3-642-33885-4_4; Everingham M, 2011, INT J COMPUT VISION, V88, P303; Farhadi Ali, 2010, P IEEE C COMP VIS PA; Fathi A., 2011, P IEEE INT C COMP VI; Fellbaum Christiane, 1998, WORDNET ELECT DATABA; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468; Ferryman J, 2007, PETS; Fischler M. A., 1973, IEEE T COMPUT; Frome A., 2013, ADV NEURAL INFORM PR, P2121; Fu Y., 2013, IEEE T PATTERN ANAL, P99; Gkioxari G., 2013, P IEEE C COMP VIS PA; Guadarrama S., 2013, P IEEE INT C COMP VI; Gupta A., 2009, P IEEE C COMP VIS PA; Hodgins F., 2009, CMU RI T 08 22; Jhuang H., 2013, P IEEE INT C COMP VI; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Kantorov Vadim, 2014, P IEEE C COMP VIS PA; Karlinsky L., 2010, ADV NEURAL INFORM PR; Karpathy A., 2014, P IEEE C COMP VIS PA; Kliper-Gross O, 2012, IEEE T PATTERN ANAL, V34, P615, DOI 10.1109/TPAMI.2011.209; Kuehne H., 2011, P IEEE INT C COMP VI; Lampert C., 2013, IEEE T PATTERN ANAL, P99; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Laptev I., 2007, P IEEE INT C COMP VI; Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496; Lei Zhang, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P942, DOI 10.1109/ICCVW.2011.6130353; Li LJ, 2007, IEEE I CONF COMP VIS, P345; Liu J., 2011, P IEEE C COMP VIS PA; Liu J., 2009, P IEEE C COMP VIS PA; Liu JC, 2012, INT C PATT RECOG, P2314; Mallick T, 2013, NAT CONF COMPUT VIS; Marszalek M., 2009, P IEEE C COMP VIS PA; Marszalek M., 2010, P BRIT MACH VIS C BM; Messing R., 2009, P IEEE INT C COMP VI; Min Li, 2013, P IEEE INT C COMP VI; Mittal A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.75; Motwani TS, 2012, FRONT ARTIF INTEL AP, V242, P600, DOI 10.3233/978-1-61499-098-7-600; Natarajan P., 2008, P IEEE C COMP VIS PA; NIEBLES J, 2010, P EUR C COMP VIS ECC; Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47; Over P, 2012, P TRECVID 2012 NIST; Packer B., 2012, P IEEE C COMP VIS PA; Pirsiavash H., 2012, P IEEE C COMP VIS PA; Ramanan Deva, 2014, P IEEE C COMP VIS PA; Ramanathan V., 2013, P IEEE INT C COMP VI; Regneri M., 2010, P ANN M ASS COMP LIN; Regneri M., 2013, GROUNDING ACTION DES, V1; Rodriguez M.D., 2008, P 2008 IEEE C COMP V; Roggen D., 2010, INSS; Rohrbach A., 2015, P IEEE C COMP VIS PA; Rohrbach Anna, 2014, GERM C PATT REC GCPR; Rohrbach M, 2010, P IEEE C COMP VIS PA; ROHRBACH M, 2013, ADV NEURAL INFORM PR; Rohrbach M., 2013, P IEEE INT C COMP VI; Rohrbach M., 2011, P IEEE C COMP VIS PA; Rohrbach M., 2012, P EUR C COMP VIS ECC; Rohrbach Marcus, 2012, P IEEE C COMP VIS PA; Ryoo M., 2009, P IEEE INT C COMP VI; Saleh Babak, 2013, P IEEE INT C COMP VI; SALTON G, 1988, INFORM PROCESSING MA; Sapp B., 2010, CASCADED MODELS ARTI; Schank R., 1977, SCRIPTS PLANS GOALS; Schuldt C, 2004, ICPR; Senina A, 2014, ARXIV14036173; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Sigal Leonid, 2013, P IEEE C COMP VIS PA; Sill J, 2009, ARXIV09110460; Singh P., 2002, DOA COOPIS ODBASE; Singh V., 2011, P IEEE INT C COMP VI; Socher R., 2010, P IEEE C COMP VIS PA; Socher Richard, 2013, NEURIPS; Soomro K., 2012, COMPUT SCI; Stein S., 2013, UBICOMP; Sung J., 2011, ABS11070169 CORR; Tang K., 2013, P IEEE INT C COMP VI; Tang K., 2012, P IEEE C COMP VIS PA; Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11; Tenorth M., 2009, THEMIS; Teo CL, 2012, IEEE INT CONF ROBOT, P374, DOI 10.1109/ICRA.2012.6224589; TING KM, 1997, P INT JOINT C ART IN; Vedaldi A., 2010, P IEEE C COMP VIS PA; Wang H., 2009, P BRIT MACH VIS C BM; Wang H, 2011, PROC CVPR IEEE; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Wang JQ, 2009, PROCEEDINGS OF 2009 CONFERENCE ON SYSTEMS SCIENCE, MANAGEMENT SCIENCE & SYSTEM DYNAMICS, VOL 7, P1; Welinder P., 2010, CALTECH UCSD BIRDS 2; Yang W., 2011, P IEEE C COMP VIS PA; Yang Y., 2013, IEEE T PATTERN ANAL, V35; Yang Y., 2011, P IEEE C COMP VIS PA; Yao A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.67; Yao B., 2011, P IEEE INT C COMP VI; Yao BP, 2012, IEEE T PATTERN ANAL, V34, P1691, DOI 10.1109/TPAMI.2012.67; Yeffet L., 2009, P IEEE INT C COMP VI; Yuan J., 2009, P IEEE C COMP VIS PA; Zhou D., 2004, ADV NEURAL INFORM PR; Zinnen A., 2009, ISWC	116	61	65	1	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2016	119	3			SI		346	373		10.1007/s11263-015-0851-8	http://dx.doi.org/10.1007/s11263-015-0851-8			28	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	DS0FE		Green Submitted			2022-12-18	WOS:000380270000009
J	Collins, T; Bartoli, A				Collins, Toby; Bartoli, Adrien			Infinitesimal Plane-Based Pose Estimation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Plane; Pose; SfM; PnP; Homography	PERSPECTIVE	Estimating the pose of a plane given a set of point correspondences is a core problem in computer vision with many applications including Augmented Reality (AR), camera calibration and 3D scene reconstruction and interpretation. Despite much progress over recent years there is still the need for a more efficient and more accurate solution, particularly in mobile applications where the run-time budget is critical. We present a new analytic solution to the problem which is far faster than current methods based on solving Pose from Points (PnP) and is in most cases more accurate. Our approach involves a new way to exploit redundancy in the homography coefficients. This uses the fact that when the homography is noisy it will estimate the true transform between the model plane and the image better at some regions on the plane than at others. Our method is based on locating a point where the transform is best estimated, and using only the local transformation at that point to constrain pose. This involves solving pose with a local non-redundant 1st-order PDE. We call this framework Infinitesimal Plane-based Pose Estimation (IPPE), because one can think of it as solving pose using the transform about an infinitesimally small region on the surface. We show experimentally that IPPE leads to very accurate pose estimates. Because IPPE is analytic it is both extremely fast and allows us to fully characterise the method in terms of degeneracies, number of returned solutions, and the geometric relationship of these solutions. This characterisation is not possible with state-of-the-art PnP methods.	[Collins, Toby; Bartoli, Adrien] Univ Auvergne, UMR CNRS 6284, ALCoV ISIT, Clermont Ferrand, France	Universite Clermont Auvergne (UCA)	Collins, T (corresponding author), Univ Auvergne, UMR CNRS 6284, ALCoV ISIT, Clermont Ferrand, France.	toby.collins@gmail.com; adrien.bartoli@gmail.com	Collins, Toby/Q-8967-2019	Collins, Toby/0000-0002-9441-8306	EU FP7 ERC [307483]	EU FP7 ERC(European Commission)	This research has received funding from the EU FP7 ERC research Grant 307483 FLEXABLE. Code is available at http://www.tobycollins.net/research/IPPE.	Ansar A., 2003, PATTERN ANAL MACHINE, V25, P282; BARRETO J, 2009, BRIT MACH VIS C BMVC; Brown M, 2005, IEEE T VIS COMPUT GR, V11, P193, DOI 10.1109/TVCG.2005.27; Chen P, 2009, J MATH IMAGING VIS, V33, P281, DOI 10.1007/s10851-008-0113-2; Collins Toby, 2010, 3D DATA PROCESSING V; DHOME M, 1989, IEEE T PATTERN ANAL, V11, P1265, DOI 10.1109/34.41365; Fiore PD, 2001, IEEE T PATTERN ANAL, V23, P140, DOI 10.1109/34.908965; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Gao XS, 2003, IEEE T PATTERN ANAL, V25, P930, DOI 10.1109/TPAMI.2003.1217599; Geiger A, 2012, INT C ROB AUT ICRA; Haralick R., 1991, COMPUTER VISION PATT; HARALICK RM, 1994, INT J COMPUT VISION, V13, P331, DOI 10.1007/BF02028352; Harker M., 2005, BRIT COMP VIS C BMVC; Hartley R., 2004, ROBOTICA; Hesch J. a., 2011, INT C COMP VIS ICCV; Hilsmann A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.26; Horaud R, 1997, INT J COMPUT VISION, V22, P173, DOI 10.1023/A:1007940112931; Hung Y., 1984, TECHNICAL REPORT; Kato H., 1999, INT WORKSH AUGM REAL; Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6; Li S., 2012, PATTERN ANAL MACHINE; Lobay A, 2006, INT J COMPUT VISION, V67, P71, DOI 10.1007/s11263-006-4068-8; Lobay A., 2004, COMPUTER VISION PATT; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu CP, 2000, IEEE T PATTERN ANAL, V22, P610, DOI 10.1109/34.862199; Munoz-Salinas R, ARUCO AUGMENTED REAL; Oberkampf D, 1996, COMPUT VIS IMAGE UND, V63, P495, DOI 10.1006/cviu.1996.0037; Ohta Y., 1981, INT JOINT C ART INT; Poelman C., 1993, TECHNICAL REPORT; Quan L., 1999, PATTERN ANAL MACHINE; Schweighofer G, 2006, IEEE T PATTERN ANAL, V28, P2024, DOI 10.1109/TPAMI.2006.252; Sturm P, 2000, COMPUTER VISION PATT; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; Triggs B., 1999, INT C COMP VIS ICCV; Vedaldi A., VLFEAT OPEN PORTABLE; Zhang CX, 2005, J COMPUT SCI TECH-CH, V20, P836, DOI 10.1007/s11390-005-0836-0; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718	39	61	62	2	31	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2014	109	3					252	286		10.1007/s11263-014-0725-5	http://dx.doi.org/10.1007/s11263-014-0725-5			35	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AN1QL					2022-12-18	WOS:000340358600005
J	Furukawa, Y; Ponce, J				Furukawa, Yasutaka; Ponce, Jean			Carved Visual Hulls for Image-Based Modeling	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	9th European Conference on Computer Vision (ECCV 2006)	MAY 07-13, 2006	Graz, AUSTRIA	Adv Comp Vis, Graz Univ Technol, Univ Ljubljana		Visual hull; Graph cuts; Multi-view; Stereo; Rim; Silhouettes	SHAPE	This article presents a novel method for acquiring high-quality solid models of complex 3D shapes from multiple calibrated photographs. After the purely geometric constraints associated with the silhouettes found in each image have been used to construct a coarse surface approximation in the form of a visual hull, photoconsistency constraints are enforced in three consecutive steps: (1) the rims where the surface grazes the visual hull are first identified through dynamic programming; (2) with the rims now fixed, the visual hull is carved using graph cuts to globally optimize the photoconsistency of the surface and recover its main features; (3) an iterative (local) refinement step is finally used to recover fine surface details. The proposed approach has been implemented, and experiments with seven real data sets are presented, along with qualitative and quantitative comparisons with several state-of-the-art image-based-modeling algorithms.	[Furukawa, Yasutaka; Ponce, Jean] Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; [Furukawa, Yasutaka; Ponce, Jean] Univ Illinois, Beckman Inst, Urbana, IL 61801 USA; [Ponce, Jean] Ecole Normale Super, Dept Informat, F-75231 Paris, France	University of Illinois System; University of Illinois Urbana-Champaign; University of Illinois System; University of Illinois Urbana-Champaign; UDICE-French Research Universities; PSL Research University Paris; Ecole Normale Superieure (ENS)	Furukawa, Y (corresponding author), Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA.	yfurukaw@uiuc.edu; jean.ponce@ens.fr						Baumgart B.G., 1974, THESIS STANFORD U; Boykov Y, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P26; Cheung KMG, 2003, CVPR; DELINGETTE H, 1992, IMAGE VISION COMPUT, V10, P132, DOI 10.1016/0262-8856(92)90065-B; Diebel J., CVPR, V1, P519; Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016; Faugeras O, 1998, IEEE T IMAGE PROCESS, V7, P336, DOI 10.1109/83.661183; FURUKAWA Y, 2006, EUR C COMP VIS, V1, P564; Furukawa Y., 2007, CVPR; GOESELE M, 2006, CVPR, P2402; HABBECKE M, 2007, CVPR; Hoppe H., 1993, Computer Graphics Proceedings, P19, DOI 10.1145/166117.166119; HORNUNG A, 2006, CVPR, P503; KERIVEN R, 2002, 2002221 ENPC; Kolmogorov V, 2002, LECT NOTES COMPUT SC, V2352, P82; Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954; Lachaud J O, 1999, Med Image Anal, V3, P187, DOI 10.1016/S1361-8415(99)80012-7; Lazebnik S, 2007, INT J COMPUT VISION, V74, P137, DOI 10.1007/s11263-006-0008-x; MATUSIK W, 2002, SIGGRAPH; PARIS S, 2004, ACCV; PONS JP, 2005, CVPR, V2, P822; Roy S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P492, DOI 10.1109/ICCV.1998.710763; Schaffalitzky F., 2001, ICCV; Seitz SM, 1997, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.1997.609462; SEITZ SM, 2007, MULTIVIEW STEREO EVA; SINHA S, 2004, INT S 3D DAT PROC VI; Sinha S. N., 2005, ICCV; Soatto S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P974; Strecha C., 2006, CVPR; Tran S, 2006, LECT NOTES COMPUT SC, V3952, P219; UFFENKAMP V, 1993, 3 INT WORKSH ACC AL; VOGIATZIS G, 2005, CVPR, P391; Xu CY, 1997, PROC CVPR IEEE, P66, DOI 10.1109/CVPR.1997.609299	33	61	77	0	13	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2009	81	1					53	67		10.1007/s11263-008-0134-8	http://dx.doi.org/10.1007/s11263-008-0134-8			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	387RI					2022-12-18	WOS:000261968900004
J	Kahl, F; Agarwal, S; Chandraker, MK; Kriegman, D; Belongie, S				Kahl, Fredrik; Agarwal, Sameer; Chandraker, Manmohan Krishna; Kriegman, David; Belongie, Serge			Practical global optimization for multiview geometry	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						global optimization; multiple view geometry; triangulation; geometry; reconstruction; cameras; camera pose; branch and bound	RATIOS PROBLEM; SUM	This paper presents a practical method for finding the provably globally optimal solution to numerous problems in projective geometry including multiview triangulation, camera resectioning and homography estimation. Unlike traditional methods which may get trapped in local minima due to the non-convex nature of these problems, this approach provides a theoretical guarantee of global optimality. The formulation relies on recent developments in fractional programming and the theory of convex underestimators and allows a unified framework for minimizing the standard L(2)-norm of reprojection errors which is optimal under Gaussian noise as well as the more robust L(1)-norm which is less sensitive to outliers. Even though the worst case complexity of our algorithm is exponential, the practical efficacy is empirically demonstrated by good performance on experiments for both synthetic and real data. An open source MATLAB toolbox that implements the algorithm is also made available to facilitate further research.	[Kahl, Fredrik] Lund Univ, Ctr Math Sci, Lund, Sweden; [Agarwal, Sameer; Chandraker, Manmohan Krishna; Kriegman, David; Belongie, Serge] Univ Calif San Diego, Dept Comp Sci & Engn, San Diego, CA 92103 USA	Lund University; University of California System; University of California San Diego	Kahl, F (corresponding author), Lund Univ, Ctr Math Sci, Lund, Sweden.	fredrik@maths.lth.se	Chandraker, Manmohan/AAU-4762-2021	Belongie, Serge/0000-0002-0388-5217				AGARWAL S, 2006, EUR C COMP VIS, P592; Benson HP, 2002, J GLOBAL OPTIM, V22, P343, DOI 10.1023/A:1013869015288; Boyd S, 2004, CONVEX OPTIMIZATION; CHANDRAKER MK, 2007, INT C COMP VIS RIO J; Freund RW, 2001, J GLOBAL OPTIM, V19, P83, DOI 10.1023/A:1008316327038; Hartley R., 2004, ROBOTICA; Hartley RI, 1997, COMPUT VIS IMAGE UND, V68, P146, DOI 10.1006/cviu.1997.0547; Huber P., 1981, ROBUST STAT; JOSEPHSON K, 2007, SCAND C IM AN; Kahl F, 2005, IEEE I CONF COMP VIS, P978; KAHL F, 2007, IEEE T PATT IN PRESS; KE Q, 2005, CVPR, P739; Ke QF, 2005, IEEE I CONF COMP VIS, P986; Kotz S., 2001, LAPLACE DISTRIBUTION; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Schaible S, 2003, OPTIM METHOD SOFTW, V18, P219, DOI 10.1080/1055678031000105242; Stewenius H, 2005, IEEE I CONF COMP VIS, P686; Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766; Tawarmalani M, 2001, J GLOBAL OPTIM, V20, P137; Wolf L, 2002, INT J COMPUT VISION, V48, P53, DOI 10.1023/A:1014855311993	20	61	64	0	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2008	79	3					271	284		10.1007/s11263-007-0117-1	http://dx.doi.org/10.1007/s11263-007-0117-1			14	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	310KW		Green Submitted			2022-12-18	WOS:000256529500004
J	Ren, XF; Fowlkes, CC; Malik, J				Ren, Xiaofeng; Fowlkes, Charless C.; Malik, Jitendra			Learning probabilistic models for contour completion in natural images	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						grouping; natural images; boundary detection; scale invariance; conditional random fields; machine learning	GESTALT LAWS; STATISTICS; BOUNDARIES; SHAPE	Using a large set of human segmented natural images, we study the statistics of region boundaries. We observe several power law distributions which likely arise from both multi-scale structure within individual objects and from arbitrary viewing distance. Accordingly, we develop a scale-invariant representation of images from the bottom up, using a piecewise linear approximation of contours and constrained Delaunay triangulation to complete gaps. We model curvilinear grouping on top of this graphical/geometric structure using a conditional random field to capture the statistics of continuity and different junction types. Quantitative evaluations on several large datasets show that our contour grouping algorithm consistently dominates and significantly improves on local edge detection.	[Ren, Xiaofeng] Toyota Technol Inst Chicago, Chicago, IL 60637 USA; [Fowlkes, Charless C.] Univ Calif Irvine, Sch Informat & Comp Sci, Irvine, CA 92697 USA; [Malik, Jitendra] Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA	Toyota Technological Institute - Chicago; University of California System; University of California Irvine; University of California System; University of California Berkeley	Ren, XF (corresponding author), Toyota Technol Inst Chicago, 1427 E 60th St, Chicago, IL 60637 USA.	xren@tti-c.org; fowlkes@ics.uci.edu; malik@cs.berkeley.edu		Fowlkes, Charless/0000-0002-2990-1780				ALVAREZ L, 1999, SCALE SPACE THEORIES; [Anonymous], 1938, SOURCE BOOK GESTALT; ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663; August J, 1999, COMPUT VIS IMAGE UND, V76, P146, DOI 10.1006/cviu.1998.0795; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BORENSTEIN E, 2002, P EUR C COMP VIS ECC, V2, P109; BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; ELDER JH, 1996, P 4 EUR C COMP VIS, V1, P399; FELZENSZWALB P, 2001, P IEEE C COMP VIS PA; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; Geisler WS, 2001, VISION RES, V41, P711, DOI 10.1016/S0042-6989(00)00277-7; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; He XM, 2004, PROC CVPR IEEE, P695; Heitger F., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P32, DOI 10.1109/ICCV.1993.378238; Huang J G, 1999, P 1999 IEEE COMP VIS, P541; Huo X., 2002, LECT NOTES COMPUTATI, P149, DOI DOI 10.1007/978-3-642-56205-1; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; HUTTENLOCHER DP, 1992, INT J COMPUT VISION, V8, P7, DOI 10.1007/BF00126398; Jermyn IH, 2001, IEEE T PATTERN ANAL, V23, P1075, DOI 10.1109/34.954599; Kanizsa Gaetano, 1979, ORG VISION ESSAYS GE; KELLMAN PJ, 1991, COGNITIVE PSYCHOL, V23, P141, DOI 10.1016/0010-0285(91)90009-D; Konishi S., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P573, DOI 10.1109/CVPR.1999.786996; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; Kumar S, 2006, INT J COMPUT VISION, V68, P179, DOI 10.1007/s11263-006-7007-9; LAFFERTY J, 2001, P 18 INIT C MACH LEA; Lee AB, 2001, INT J COMPUT VISION, V41, P35, DOI 10.1023/A:1011109015675; LEUTTGEN M, 1993, SPECIAL ISSUE IEEE T, V41, P3377; Li S., 1995, MARKOV RANDOM FIELD, P1; MARTIN D, 2002, BERKELEY SEGMENTATIO; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Martin DR, 2003, PERCEPTION, V32, P55; Mori G, 2004, PROC CVPR IEEE, P326; Mumford D., 1994, ALGEBRAIC GEOMETRY I, V5681, P491, DOI DOI 10.1007/978-1-4612-2628-4_31; Murphy KP, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P467; Palmer S.E., 1999, VISION SCI PHOTONS P; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; REN X, 2005, P 10 INT C COMP VIS, V1, P824; Ren X., 2007, P IEEE C COMP VIS PA; RUDERMAN DL, 1994, PHYS REV LETT, V73, P814, DOI 10.1103/PhysRevLett.73.814; Ruderman DL, 1997, VISION RES, V37, P3385, DOI 10.1016/S0042-6989(97)00008-4; Sharon E, 2000, IEEE T PATTERN ANAL, V22, P1117, DOI 10.1109/34.879792; Shental N, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1243; Shewchuk J.R., 1996, 1 WORKSH APPL COMP G, P124; Sun J, 2002, LECT NOTES COMPUT SC, V2351, P510; Tu ZW, 2005, INT J COMPUT VISION, V63, P113, DOI 10.1007/s11263-005-6642-x; Ullman S., 1988, P 2 INT C COMP VIS, P321, DOI DOI 10.1109/CCV.1988.590008; VONDERHEYDT R, 1984, SCIENCE, V224, P1260, DOI 10.1126/science.6539501; Weiss Y, 2000, NEURAL COMPUT, V12, P1, DOI 10.1162/089976600300015880; Weiss Y, 1997, ADV NEUR IN, V9, P908; Williams LR, 1999, INT J COMPUT VISION, V34, P81, DOI 10.1023/A:1008187804026; Williams LR, 1997, NEURAL COMPUT, V9, P837, DOI 10.1162/neco.1997.9.4.837; Williams LR, 2001, NEURAL COMPUT, V13, P1683, DOI 10.1162/08997660152469305; Wu Q., 2003, DIGITAL IMAGE COMPUT, P957; YU S, 2002, ADV NEURAL INFORM PR, V16; Zhu SC, 1999, IEEE T PATTERN ANAL, V21, P1170, DOI 10.1109/34.809110; Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420	60	61	67	2	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2008	77	1-3					47	63		10.1007/s11263-007-0092-6	http://dx.doi.org/10.1007/s11263-007-0092-6			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	267RE					2022-12-18	WOS:000253526100004
J	Amit, Y; Trouve, A				Amit, Yali; Trouve, Alain			POP: Patchwork of parts models for object recognition	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						deformable models; model estimation; multi-object configurations; object detection	FACE DETECTION	We formulate a deformable template model for objects with an efficient mechanism for computation and parameter estimation. The data consists of binary oriented edge features, robust to photometric variation and small local deformations. The template is defined in terms of probability arrays for each edge type. A primary contribution of this paper is the definition of the instantiation of an object in terms of shifts of a moderate number local submodels-parts-which are subsequently recombined using a patchwork operation, to define a coherent statistical model of the data. Object classes are modeled as mixtures of patchwork of parts (POP) models that are discovered sequentially as more class data is observed. We define the notion of the support associated to an instantiation, and use this to formulate statistical models for multi-object configurations including possible occlusions. All decisions on the labeling of the objects in the image are based on comparing likelihoods. The combination of a deformable model with an efficient estimation procedure yields competitive results in a variety of applications with very small training sets, without need to train decision boundaries-only data from the class being trained is used. Experiments are presented on the MNIST database, reading zipcodes, and face detection.	Univ Chicago, Dept Stat, Chicago, IL 60637 USA; Univ Chicago, Dept Comp Sci, Chicago, IL 60637 USA; Ecole Normale Super, CMLA, Cachan, France	University of Chicago; University of Chicago; UDICE-French Research Universities; Universite Paris Saclay	Amit, Y (corresponding author), Univ Chicago, Dept Stat, Chicago, IL 60637 USA.	amit@marx.uchicago.edu						ALLASSONNIERE S, 2006, IN PRESS J ROYAL STA; Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545; Amit Y, 2004, IEEE T PATTERN ANAL, V26, P1606, DOI 10.1109/TPAMI.2004.111; Amit Y, 1999, NEURAL COMPUT, V11, P1691, DOI 10.1162/089976699300016197; Amit Y., 2002, 2D OBJECT DETECTION; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BERNSTEIN EJ, 2005, CVPR 2005; BORENSTEIN E, 2004, P CVPRW04, V4; BURL M, 1998, P 5 EUR C COMPU VIS, V98, P628; CRANDALL D, 2005, IN PRESS CVPR 2005; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; FEIFEI L, 2003, P INT C COMP VIS, V1; Geman S, 2002, Q APPL MATH, V60, P707, DOI 10.1090/qam/1939008; Ha TM, 1998, PATTERN RECOGN, V31, P257, DOI 10.1016/S0031-3203(97)00050-2; Hastie T., 1998, STAT SCI; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LECUN Y, 2004, MNIST DATABASE; LEIBE B, 2003, BMVC 03; LEUNG TK, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P637, DOI 10.1109/ICCV.1995.466878; LIEBE B, 2004, DAGM 04 ANN PATT REC, V3175, P145; PALUMBO P, 1996, INT J IMAGING SCI TE; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; Schneiderman H, 2004, INT J COMPUT VISION, V56, P151, DOI 10.1023/B:VISI.0000011202.85607.00; TORRALBA A, 2004, 2004008 MIT; TU ZW, 2004, IN PRESS INT J COMPU; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; WANG SC, 1998, THESIS U CHICAGO; Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235	29	61	62	0	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	2007	75	2					267	282		10.1007/s11263-006-0033-9	http://dx.doi.org/10.1007/s11263-006-0033-9			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	207LU					2022-12-18	WOS:000249253400004
J	Charpiat, G; Maurel, P; Pons, JP; Keriven, R; Faugeras, O				Charpiat, G.; Maurel, P.; Pons, J. -P.; Keriven, R.; Faugeras, O.			Generalized gradients: Priors on minimization flows	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						shape; gradient descent; active contours; minimization flow; inner product; sobolev; generalized gradient; rigidification; semi-local rigidification; shape warping; landmarks; Hausdorff distance; spatial coherence	LEVEL SET METHODS; IMPLICIT; MOTION	This paper tackles an important aspect of the variational problem underlying active contours: optimization by gradient flows. Classically, the definition of a gradient depends directly on the choice of an inner product structure. This consideration is largely absent from the active contours literature. Most authors, explicitely or implicitely, assume that the space of admissible deformations is ruled by the canonical L-2 inner product. The classical gradient flows reported in the literature are relative to this particular choice. Here, we investigate the relevance of using (i) other inner products, yielding other gradient descents, and (ii) other minimizing flows not deriving from any inner product. In particular, we show how to induce different degrees of spatial consistency into the minimizing flow, in order to decrease the probability of getting trapped into irrelevant local minima. We report numerical experiments indicating that the sensitivity of the active contours method to initial conditions, which seriously limits its applicability and efficiency, is alleviated by our application-specific spatially coherent minimizing flows. We show that the choice of the inner product can be seen as a prior on the deformation fields and we present an extension of the definition of the gradient toward more general priors.	ENS, NEPC, INRIA, Odyssee Lab, F-75230 Paris 05, France	Inria; UDICE-French Research Universities; PSL Research University Paris; Ecole Normale Superieure (ENS)	Charpiat, G (corresponding author), ENS, NEPC, INRIA, Odyssee Lab, 46 Rue Ulm, F-75230 Paris 05, France.	Guillaume.Charpiat@di.ens.fr; Pierre.Maurel@di.ens.fr; Jean-Philippe.Pons@sophia.inria.fr; Renaud.Keriven@certis.enpc.fr; Olivier.Faugeras@sophia.inria.fr		Maurel, Pierre/0000-0003-2539-7414				Akhiezer N I, 1981, THEORY LINEAR OPERAT; Bertalmio M, 2001, J COMPUT PHYS, V174, P759, DOI 10.1006/jcph.2001.6937; Bertalmio M, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P186, DOI 10.1109/VLSM.2001.938899; Bonnans J.F., 2002, NUMERICAL OPTIMIZATI; Boykov Y, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P26; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; Charpiat G, 2005, FOUND COMPUT MATH, V5, P1, DOI 10.1007/s10208-003-0094-x; CHARPIAT G, 2005, 10 INT C COMP VIS BE; DERVIEUX A, 1979, LECT NOTES MATH, V771, P145; Do Carmo M., 1976, DIFFERENTIAL GEOMETR; DUAN Y, 2004, EUR C COMP VIS, V3, P238; Faugeras O, 1998, IEEE T IMAGE PROCESS, V7, P336, DOI 10.1109/83.661183; GOLDLUCKE B, 2004, EUR C COMP VIS, V2, P366; Goldluecke B, 2004, PROC CVPR IEEE, P350; Jin HL, 2003, PROC CVPR IEEE, P171; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kolmogorov V, 2002, LECT NOTES COMPUT SC, V2352, P82; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Maurel P, 2006, INT C PATT RECOG, P69; MICHOR PW, 2005, RIEMANNIAN GEOMETRIE; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Osher S., 2002, LEVEL SET METHOD DYN; Osher S., 2003, GEOMETRIC LEVEL SET; OVERGAARD NC, 2005, INT C SCAL SPAC PDE, P480; Paragios N, 2005, COMPUT VIS IMAGE UND, V97, P259, DOI 10.1016/j.cviu.2003.04.001; Peng DP, 1999, J COMPUT PHYS, V155, P410, DOI 10.1006/jcph.1999.6345; PONS JP, 2003, INT C COMP VIS, V2, P894; Sethian J.A., 1999, LEVEL SET METHODS FA, V2nd; SOLEM J, 2005, INT C SCAL SPAC PDE, P419; SUNDARAMOORTHI G, 2005, IEEE WORKSH VAR LEV, P109; Trouve A, 1998, INT J COMPUT VISION, V28, P213, DOI 10.1023/A:1008001603737; YEZZI A, 2005, METRICS SPACE CURVES; Yezzi AJ, 2003, INT J COMPUT VISION, V53, P153, DOI 10.1023/A:1023048024042; Younes L, 1998, SIAM J APPL MATH, V58, P565, DOI 10.1137/S0036139995287685; Zhao HK, 2000, COMPUT VIS IMAGE UND, V80, P295, DOI 10.1006/cviu.2000.0875	36	61	61	0	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2007	73	3					325	344		10.1007/s11263-006-9966-2	http://dx.doi.org/10.1007/s11263-006-9966-2			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	155HB		Green Submitted			2022-12-18	WOS:000245567400005
J	Guillaumin, M; Kuttel, D; Ferrari, V				Guillaumin, Matthieu; Kuettel, Daniel; Ferrari, Vittorio			ImageNet Auto-Annotation with Segmentation Propagation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Figure-ground segmentation; ImageNet; Knowledge transfer; Object localization; Large-scale computer vision		ImageNet is a large-scale hierarchical database of object classes with millions of images. We propose to automatically populate it with pixelwise object-background segmentations, by leveraging existing manual annotations in the form of class labels and bounding-boxes. The key idea is to recursively exploit images segmented so far to guide the segmentation of new images. At each stage this propagation process expands into the images which are easiest to segment at that point in time, e. g. by moving to the semantically most related classes to those segmented so far. The propagation of segmentation occurs both (a) at the image level, by transferring existing segmentations to estimate the probability of a pixel to be foreground, and (b) at the class level, by jointly segmenting images of the same class and by importing the appearance models of classes that are already segmented. Through experiments on 577 classes and 500k images we show that our technique (i) annotates a wide range of classes with accurate segmentations; (ii) effectively exploits the hierarchical structure of ImageNet; (iii) scales efficiently, especially when implemented on superpixels; (iv) outperforms a baselineGrabCut (Rother et al. 2004) initialized on the image center, as well as segmentation transfer from a fixed source pool and run independently on each target image (Kuettel and Ferrari 2012). Moreover, our method also delivers state-of-the-art results on the recent iCoseg dataset for co-segmentation.	[Guillaumin, Matthieu; Kuettel, Daniel] ETH, D ITET, Comp Vis Lab, CH-8092 Zurich, Switzerland; [Ferrari, Vittorio] Univ Edinburgh, IPAB, Sch Informat, Edinburgh EH8 9AB, Midlothian, Scotland	Swiss Federal Institutes of Technology Domain; ETH Zurich; University of Edinburgh	Guillaumin, M (corresponding author), ETH, D ITET, Comp Vis Lab, Sternwartstr 7, CH-8092 Zurich, Switzerland.	guillaumin@vision.ee.ethz.ch; kuettel@vision.ee.ethz.ch; vferrari@staffmail.ed.ac.uk						Alexe B., 2010, P EUR C COMP VIS; Alexe B., 2010, P IEEE C COMP VIS PA; Arora H., 2007, P IEEE C COMP VIS PA; Aytar Y., 2011, P INT C COMP VIS; Aytar Y, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.79; Batra D, 2011, INT J COMPUT VISION, V93, P273, DOI 10.1007/s11263-010-0415-x; Batra D, 2010, PROC CVPR IEEE, P3169, DOI 10.1109/CVPR.2010.5540080; Bertelli L, 2011, PROC CVPR IEEE; Blake A., 2004, P 8 EUR C COMP VIS P; BORENSTEIN E., 2004, P IEEE C COMP VIS PA; Carreira J., 2010, P IEEE C COMP VIS PA; Chai Y., 2012, P EUR C COMP VIS; Chai YN, 2011, IEEE I CONF COMP VIS, P2579, DOI 10.1109/ICCV.2011.6126546; Cremers D., 2007, P 11 INT C COMP VIS; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Deng J., 2010, P EUR C COMP VIS; Deng J., 2012, P IEEE C COMP VIS PA; Deng J., 2012, ILSVRC2012; Deng J., 2009, 2009 IEEE C COMP VIS, P248, DOI [DOI 10.1109/CVPR.2009.5206848, 10.1109/CVPR.2009.5206848]; Deng J., 2011, ADV NEURAL INFORM PR; Deselaers T., 2011, P IEEE C COMP VIS PA; Deselaers T., 2010, P EUR C COMP VIS; Endres I., 2010, P EUR C COMP VIS; FEIFEI L, 2004, CVPR WORKSH GEN MOD; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; FERRARI V., 2012, P IEEE C COMP VIS PA; Gong YC, 2011, PROC CVPR IEEE; Guillaumin M., 2012, P IEEE C COMP VIS PA; Guillaumin Matthieu, 2009, P INT C COMP VIS; Hays J., 2007, P ACM SIGGRAPH C COM; JIANG H, 2009, P INT C COMP VIS; Jojic N., 2009, P IEEE C COMP VIS PA; Jolly M. P., 2001, P 8 INT C COMP VIS V; Joulin A, 2010, PROC CVPR IEEE, P1943, DOI 10.1109/CVPR.2010.5539868; Kim G, 2011, IEEE I CONF COMP VIS, P169, DOI 10.1109/ICCV.2011.6126239; Krizhevsky A, 2012, ADV NEURAL INFORM PR; Kuettel D., 2012, P EUR C COMP VIS; Ladicky L., 2009, P INT C COMP VIS; Lampert C. H., 2009, P IEEE C COMP VIS PA; Li F., 2010, P IEEE C COMP VIS PA; Lin Y., 2011, P IEEE C COMP VIS PA; Liu C., 2009, P IEEE C COMP VIS PA; Malisiewicz T., 2011, P INT C COMP VIS; Mukherjee L., 2012, P EUR C COMP VIS; Norouzi M., 2012, P IEEE C COMP VIS PA; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Ott P., 2011, P IEEE C COMP VIS PA; Quattoni A., 2008, P IEEE C COMP VIS PA; Rohrbach M, 2010, P IEEE C COMP VIS PA; Rother C., 2006, P IEEE C COMP VIS PA; Rother C., 2004, P ACM SIGGRAPH C COM; Russel B., 2007, ADV NEURAL INFORM PR; SALAKHUTDINOV R., 2011, P IEEE C COMP VIS PA; Shotton J., 2006, P ECCV; SHOTTON J, 2005, P INT C COMP VIS; Stark M., 2009, P INT C COMP VIS; Szummer M., 2008, P EUR C COMP VIS; Tighe J., 2010, P EUR C COMP VIS; Tommasi T., 2010, P IEEE C COMP VIS PA; Torralba A., 2008, P IEEE C COMP VIS PA; Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453; Tu ZW, 2005, INT J COMPUT VISION, V63, P113, DOI 10.1007/s11263-005-6642-x; Van de Sande K., 2011, P INT C COMP VIS; Veksler O, 2010, LECT NOTES COMPUT SC, V6315, P211, DOI 10.1007/978-3-642-15555-0_16; VERBEEK J., 2007, P IEEE C COMP VIS PA; Verbeek JJ, 2006, DATA MIN KNOWL DISC, V13, P291, DOI 10.1007/s10618-005-0033-3; Vicente S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2217, DOI 10.1109/CVPR.2011.5995530; Vicente S., 2008, P IEEE C COMP VIS PA; Wang J., 2005, P 10 INT C COMP VIS; Weinshall D., 2011, P INT C COMP VIS; Winn J. M., 2005, P INT C COMP VIS	71	60	62	2	19	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	2014	110	3			SI		328	348		10.1007/s11263-014-0713-9	http://dx.doi.org/10.1007/s11263-014-0713-9			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AT2HL		Green Accepted, Green Published, Green Submitted			2022-12-18	WOS:000344754500007
J	Hartley, RI				Hartley, RI			Chirality	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						chirality; projective invariant; quasi-affine reconstruction; projective reconstruction; oriented projective geometry		It is known that a set of points in three-dimensions is determined up to projectivity from two views with uncalibrated cameras. It is shown in this paper that this result may be improved by distinguishing between points in front of and behind the camera. Any point that lies in an image must lie in front of the camera producing that image. Using this idea, it is shown that the scene is determined from two views up to a more restricted class of mappings known as quasi-affine transformations, which are precisely those projectivities that preserve the convex hull of an object of interest. An invariant of quasi-affine transformation known as the chiral sequence of a set of points is defined and it is shown how the chiral sequence may be computed using two uncalibrated views. As demonstrated theoretically and by experiment the chiral sequence may distinguish between sets of points that are projectively equivalent. These results lead to necessary and sufficient conditions for a set of corresponding pixels in two images to be realizable as the images of a set of points in three dimensions. Using similar methods, a necessary and sufficient condition is given for the orientation of a set of points to be determined by two views. If the perspective centres are not separated from the point set by a plane, then the orientation of the set of points is determined from two views.	GE, Corp Res & Dev, Schenectady, NY 12301 USA	General Electric	Hartley, RI (corresponding author), GE, Corp Res & Dev, POB 8, Schenectady, NY 12301 USA.							FAUGERAS OD, 1992, LECTURE NOTES COMPUT, V588, P563; Hartley R., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P761, DOI 10.1109/CVPR.1992.223179; HARTLEY R, 1979, MATH ANN, V243, P63, DOI 10.1007/BF01420207; HARTLEY R, 1992, UNPUB INVARIATNS POI; HARTLEY R, 1993, P DARPA IM UND WORKS, P737; HARTLEY RI, 1993, P 2 EUR US WORKSH IN, P187; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Mohr R., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P543, DOI 10.1109/CVPR.1993.341077; MORIN L, 1993, THESIS I NATL POLYTE; MORIN L, 1995, P SYNT STRUCT PATT R; Press WH, 1988, NUMERICAL RECIPES C; ROBERT L, 1993, P INT C COMP VIS BER, P540; ROTHWELL CA, 1992, LECT NOTES COMPUT SC, V588, P757; SPARR G, 1992, LECT NOTES COMPUT SC, V588, P378, DOI 10.1016/0262-8856(92)90013-S; SUTHERLAND IE, 1980, 296 MIT LINC LAB; Wolfram S., 1988, MATH SYSTEM DOING MA	16	60	62	0	4	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	1998	26	1					41	61		10.1023/A:1007984508483	http://dx.doi.org/10.1023/A:1007984508483			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	ZC476					2022-12-18	WOS:000072583100003
J	Xu, X; Hospedales, T; Gong, SG				Xu, Xun; Hospedales, Timothy; Gong, Shaogang			Transductive Zero-Shot Action Recognition by Word-Vector Embedding	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Zero-shot action recognition; Zero-shot learning; Semantic embedding; Semi-supervised learning; Transfer learning; Action recognition		The number of categories for action recognition is growing rapidly and it has become increasingly hard to label sufficient training data for learning conventional models for all categories. Instead of collecting ever more data and labelling them exhaustively for all categories, an attractive alternative approach is "zero-shot learning" (ZSL). To that end, in this study we construct a mapping between visual features and a semantic descriptor of each action category, allowing new categories to be recognised in the absence of any visual training data. Existing ZSL studies focus primarily on still images, and attribute-based semantic representations. In this work, we explore word-vectors as the shared semantic space to embed videos and category labels for ZSL action recognition. This is a more challenging problem than existing ZSL of still images and/or attributes, because the mapping between video space-time features of actions and the semantic space is more complex and harder to learn for the purpose of generalising over any cross-category domain shift. To solve this generalisation problem in ZSL action recognition, we investigate a series of synergistic strategies to improve upon the standard ZSL pipeline. Most of these strategies are transductive in nature which means access to testing data in the training phase. First, we enhance significantly the semantic space mapping by proposing manifold-regularized regression and data augmentation strategies. Second, we evaluate two existing post processing strategies (transductive self-training and hubness correction), and show that they are complementary. We evaluate extensively our model on a wide range of human action datasets including HMDB51, UCF101, Olympic Sports and event datasets including CCV and TRECVID MED 13. The results demonstrate that our approach achieves the state-of-the-art zero-shot action recognition performance with a simple and efficient pipeline, and without supervised annotation of attributes. Finally, we present in-depth analysis into why and when zero-shot works, including demonstrating the ability to predict cross-category transferability in advance.	[Xu, Xun; Hospedales, Timothy; Gong, Shaogang] Queen Mary Univ London, London, England	University of London; Queen Mary University London	Xu, X (corresponding author), Queen Mary Univ London, London, England.	xun.xu@qmul.ac.uk; t.hospedales@qmul.ac.uk; s.gong@qmul.ac.uk	Xu, Xun/AAU-6810-2020	Xu, Xun/0000-0002-5220-2240				Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653; Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911; Belkin M, 2006, J MACH LEARN RES, V7, P2399; Chen J., 2014, P INT C MULT RETR, P1; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dinu Georgiana, 2015, ICLR WORKSH TRACK; Frome Andrea, 2013, NEURIPS; Fu Y, 2014, INT J DISTRIB SENS N, V2014, P1; Fu YW, 2015, IEEE T PATTERN ANAL, V37, P2332, DOI 10.1109/TPAMI.2015.2408354; Fu YW, 2014, LECT NOTES COMPUT SC, V8690, P584, DOI 10.1007/978-3-319-10605-2_38; Fu YW, 2012, LECT NOTES COMPUT SC, V7575, P530, DOI 10.1007/978-3-642-33765-9_38; Fu YW, 2014, IEEE T PATTERN ANAL, V36, P303, DOI 10.1109/TPAMI.2013.128; FU ZY, 2015, PROC CVPR IEEE, P2635, DOI DOI 10.1109/CVPR.2015.7298879; Gan C, 2015, AAAI CONF ARTIF INTE, P3769; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Habibian A., 2014, ICMR, P17; Habibian A, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P17, DOI 10.1145/2647868.2654913; Jain M, 2015, PROC CVPR IEEE, P46, DOI 10.1109/CVPR.2015.7298599; Jiang Y., 2013, THUMOS CHALLENGE ACT; Jiang Y.-G., 2011, ICMR, P1; Jiang Y.-G., 2015, ARXIV150207209; Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353; Klaser Alexander, 2008, BMVC; Kodirov E, 2015, IEEE I CONF COMP VIS, P2452, DOI 10.1109/ICCV.2015.282; Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543; Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140; Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Larochelle H., 2008, AAAI, V1, P3; Lazaridou A, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1403; Marszaek M., 2009, CVPR, P2929, DOI DOI 10.1109/CVPR.2009.5206557; Mensink T, 2014, PROC CVPR IEEE, P2441, DOI 10.1109/CVPR.2014.313; Mikolov Tomas., 2013, ADV NEURAL INFORM PR, P3111, DOI DOI 10.1162/JMLR.2003.3.4-5.951; Milajevs Dmitrijs, 2014, P 2014 C EMP METH NA, P708, DOI [10.3115/v1/D14-1079, DOI 10.3115/V1/D14-1079]; Mitchell J., 2008, ACL, P236, DOI DOI 10.1039/9781847558633-00236; Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29; Norouzi Mohammad, 2014, ICLR; Over P., 2014, TRECVID 2013 AN OVER; Palatucci Mark, 2009, ADV NEURAL INFORM PR, P1410; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Peters J, 2017, ADAPT COMPUT MACH LE; Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014; Rohrbach M, 2016, INT J COMPUT VISION, V119, P346, DOI 10.1007/s11263-015-0851-8; Rohrbach M, 2011, PROC CVPR IEEE, P1641, DOI 10.1109/CVPR.2011.5995627; Rohrbach M, 2010, PROC CVPR IEEE, P910, DOI 10.1109/CVPR.2010.5540121; Romera-Paredes Bernardino, 2015, ICML; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Scovanner P., 2007, ACM MM, P357; Shao L, 2015, IEEE T NEUR NET LEAR, V26, P1019, DOI 10.1109/TNNLS.2014.2330900; Socher R., 2013, EMNLP, P1631, DOI DOI 10.1371/JOURNAL.PONE.0073791; Soomro K., 2012, ARXIV; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Wang H, 2016, INT J COMPUT VISION, V119, P219, DOI 10.1007/s11263-015-0846-5; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Wu S, 2014, PROC CVPR IEEE, P2665, DOI 10.1109/CVPR.2014.341; Xu X, 2015, IEEE IMAGE PROC, P63, DOI 10.1109/ICIP.2015.7350760; Yang Y., 2015, ICLR; Yeffet L, 2009, IEEE I CONF COMP VIS, P492, DOI 10.1109/ICCV.2009.5459201; Zhao F., 2013, ADV NEURAL INFORM PR, P2580; Zheng J., 2014, NIPS, P1; Zhou DY, 2004, ADV NEUR IN, V16, P321	65	59	66	1	30	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2017	123	3					309	333		10.1007/s11263-016-0983-5	http://dx.doi.org/10.1007/s11263-016-0983-5			25	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	EX9EO		Green Submitted, Green Accepted			2022-12-18	WOS:000403559600001
J	Gong, BQ; Grauman, K; Sha, F				Gong, Boqing; Grauman, Kristen; Sha, Fei			Learning Kernels for Unsupervised Domain Adaptation with Applications to Visual Object Recognition	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Domain adaptation; Kernels; Object recognition; Cross; dataset bias		Domain adaptation aims to correct the mismatch in statistical properties between the source domain on which a classifier is trained and the target domain to which the classifier is to be applied. In this paper, we address the challenging scenario of unsupervised domain adaptation, where the target domain does not provide any annotated data to assist in adapting the classifier. Our strategy is to learn robust features which are resilient to the mismatch across domains and then use them to construct classifiers that will perform well on the target domain. To this end, we propose novel kernel learning approaches to infer such features for adaptation. Concretely, we explore two closely related directions. In the first direction, we propose unsupervised learning of a geodesic flow kernel (GFK). The GFK summarizes the inner products in an infinite sequence of feature subspaces that smoothly interpolates between the source and target domains. In the second direction, we propose supervised learning of a kernel that discriminatively combines multiple base GFKs. Those base kernels model the source and the target domains at fine-grained granularities. In particular, each base kernel pivots on a different set of landmarks-the most useful data instances that reveal the similarity between the source and the target domains, thus bridging them to achieve adaptation. Our approaches are computationally convenient, automatically infer important hyper-parameters, and are capable of learning features and classifiers discriminatively without demanding labeled data from the target domain. In extensive empirical studies on standard benchmark recognition datasets, our appraches yield state-of-the-art results compared to a variety of competing methods.	[Gong, Boqing; Sha, Fei] Univ So Calif, Dept Comp Sci, Los Angeles, CA 90089 USA; [Grauman, Kristen] Univ Texas Austin, Dept Comp Sci, Austin, TX 78701 USA	University of Southern California; University of Texas System; University of Texas Austin	Gong, BQ (corresponding author), Univ So Calif, Dept Comp Sci, Los Angeles, CA 90089 USA.	boqinggo@usc.edu; grauman@cs.utexas.edu; feisha@usc.edu		Gong, Boqing/0000-0003-3915-5977	DARPA [D11-AP00278]; NSF [IIS-1065243]; ONR ATL [N00014-11-1-0105]	DARPA(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); NSF(National Science Foundation (NSF)); ONR ATL	This work is partially supported by DARPA D11-AP00278 and NSF IIS-1065243 (B. G. and F. S.), and ONR ATL #N00014-11-1-0105 (K. G.). We thank the anonymous reviewers for their constructive comments and suggestions. The Flickr images in Fig. 1 are under a CC Attribution 2.0 Generic license, courtesy of berzowska, IvanWalsh.com, warrantedarrest, HerryLawford, yuichi.sakuraba, zimaowuyu, GrahamAndDairne, Bernt Rostad, Keith Roper, flavorrelish, and deflam.	Ando RK, 2005, J MACH LEARN RES, V6, P1817; [Anonymous], 2011, CVPR; [Anonymous], 2007, PASCAL VISUAL OBJECT; Bay H., 2006, ECCV; Ben-David S., 2006, ADV NEURAL INFORM PR, V19; Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4; Bergamo A., 2010, NIPS; Blitzer J., 2006, EMNLP; Blitzer J., 2011, AISTATS; BLITZER J, 2007, ACL; Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57; Chen M., 2011, NIPS; Daume III H., 2007, ACL; Daume III Hal, 2010, NIPS; Deng J., 2009, CVPR; Dollar P., 2009, CVPR; Dredze M., 2008, PROC C EMPIRICALMETH, P689; Duan L., 2009, CVPR; Duan Lixin, 2012, IEEE Trans Neural Netw Learn Syst, V23, P504, DOI 10.1109/TNNLS.2011.2178556; DUAN LX, 2010, CVPR, P1959, DOI DOI 10.1109/CVPR.2010.5539870; Friedman J., 2009, ELEMENTS STAT LEARNI, DOI 10.1007/978-0-387-84858-7; Gong B., 2012, CVPR; Gong B., 2013, P INT C MACH LEARN J, V711, P712; Gong B., 2013, ADV NEURAL INFORM PR; Gopalan R., 2013, CVPR; Gopalan R., 2011, P 2011 INT C COMP VI; Gretton A., 2006, NIPS; Gretton A, 2009, NEURAL INF PROCESS S, P131; Griffin G., 2007, TECH REP; HAM J, 2004, ICML; Hamm J., 2008, ICML; Huang J., 2006, NIPS; Kulis B., 2011, CVPR; LEGGETTER CJ, 1995, COMPUT SPEECH LANG, V9, P171, DOI 10.1006/csla.1995.0010; Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012; Li R., 2012, CVPR; Mansour Y., 2009, UAI; Mansour Yishay, 2009, P COLT; Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Perronnin F., 2010, CVPR; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Saenko K., 2010, ECCV, P2; Shi Y., 2012, ICML; Shimodaira H, 2000, J STAT PLAN INFER, V90, P227, DOI 10.1016/S0378-3758(00)00115-4; Vedaldi A., 2009, ICCV; Wang M., 2011, CVPR; Weinberger KQ, 2006, INT J COMPUT VISION, V70, P77, DOI 10.1007/s11263-005-4939-z; Zheng J., 2012, ICPR	53	59	61	3	18	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2014	109	1-2			SI		3	27		10.1007/s11263-014-0718-4	http://dx.doi.org/10.1007/s11263-014-0718-4			25	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AI7QY					2022-12-18	WOS:000337091700002
J	Ayvaci, A; Raptis, M; Soatto, S				Ayvaci, Alper; Raptis, Michalis; Soatto, Stefano			Sparse Occlusion Detection with Optical Flow	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Occlusion detection; Optical flow; Convex optimization; Sparse optimization; Nesterov's algorithm; Split-Bregman method	MINIMIZATION	We tackle the problem of detecting occluded regions in a video stream. Under assumptions of Lambertian reflection and static illumination, the task can be posed as a variational optimization problem, and its solution approximated using convex minimization. We describe efficient numerical schemes that reach the global optimum of the relaxed cost functional, for any number of independently moving objects, and any number of occlusion layers. We test the proposed algorithm on benchmark datasets, expanded to enable evaluation of occlusion detection performance, in addition to optical flow.	[Ayvaci, Alper; Raptis, Michalis; Soatto, Stefano] Univ Calif Los Angeles, Los Angeles, CA 90095 USA	University of California System; University of California Los Angeles	Ayvaci, A (corresponding author), Univ Calif Los Angeles, 405 Hilgard Ave,Boelter Hall 3811, Los Angeles, CA 90095 USA.	ayvaci@cs.ucla.edu; mraptis@cs.ucla.edu; soatto@ucla.edu			ARO [56765-CI]; ONR [N000141110863]; AFOSR [FA9550-09-1-0427]	ARO; ONR(Office of Naval Research); AFOSR(United States Department of DefenseAir Force Office of Scientific Research (AFOSR))	Research supported by ARO 56765-CI, ONR N000141110863, AFOSR FA9550-09-1-0427.	Alvarez L, 2007, INT J COMPUT VISION, V75, P371, DOI 10.1007/s11263-007-0041-4; Ayvaci A., 2011, P EN MIN METH COMP V; Ayvaci A., 2010, ADV NEURAL INFORM PR; Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191; Becker S., 2009, 904 ARXIV; Ben-Ari R, 2007, IEEE I CONF COMP VIS, P1311; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3; Bruhn A, 2005, INT J COMPUT VISION, V61, P211, DOI 10.1023/B:VISI.0000045324.43199.43; Candes EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x; Caselles V, 1999, INT J COMPUT VISION, V33, P5, DOI 10.1023/A:1008144113494; Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286; Dahl J., 2009, NUMER ALGORITHMS, P67; Gibson J. J., 1984, ECOLOGICAL APPROACH; Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891; He X., 2010, P EUR C COMP VIS; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Humayun A, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995517; Ince S, 2008, IEEE T IMAGE PROCESS, V17, P1443, DOI 10.1109/TIP.2008.925381; Jackson J., 2008, INT J COMPUTER VISIO; Jackson JD, 2005, LECT NOTES COMPUT SC, V3757, P427, DOI 10.1007/11585978_28; Kim YH, 2005, IMAGE VISION COMPUT, V23, P365, DOI 10.1016/j.imavis.2004.05.010; Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668; Lim KP, 2002, IEEE T PATTERN ANAL, V24, P712, DOI 10.1109/34.1000246; Negahdaripour S, 1998, IEEE T PATTERN ANAL, V20, P961, DOI 10.1109/34.713362; Nesterov Y, 2005, MATH PROGRAM, V103, P127, DOI 10.1007/s10107-004-0552-5; Nesterov Yu. E., 1983, Doklady Akademii Nauk SSSR, V269, P543; Proesmans M., 1994, P EUR C COMP VIS; Robert CP., 2001, BAYESIAN CHOICE; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Shulman D., 1989, Proceedings. Workshop on Visual Motion (IEEE Cat. No.89CH2716-9), P81, DOI 10.1109/WVM.1989.47097; Soatto S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P974; SOATTO S, 2002, P EUR C COMP VIS, V3, P32; Soatto S, 2011, MACHINE LEARNING COM; Stein AN, 2009, INT J COMPUT VISION, V82, P325, DOI 10.1007/s11263-008-0203-z; Strecha C, 2004, LECT NOTES COMPUT SC, V3247, P71; Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939; Sun J, 2005, PROC CVPR IEEE, P399; Sundaramoorthi G., 2009, P C COMP VIS PATT RE; Teng CH, 2005, COMPUT VIS IMAGE UND, V97, P315, DOI 10.1016/j.cviu.2004.08.002; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; VERRI A, 1989, IEEE T PATTERN ANAL, V11, P490, DOI 10.1109/34.24781; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; Wang Y., 2007, CAAM TECHNICAL REPOR; Wedel A., 2008, P STAT GEOM APPR VIS; Wedel A., 2009, P INT C COMP VIS; Weiss P, 2009, SIAM J SCI COMPUT, V31, P2047, DOI 10.1137/070696143; Werlberger M., 2009, P BRIT MACH VIS C; Xiao JJ, 2006, LECT NOTES COMPUT SC, V3951, P211	49	59	68	0	16	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2012	97	3					322	338		10.1007/s11263-011-0490-7	http://dx.doi.org/10.1007/s11263-011-0490-7			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	907VP					2022-12-18	WOS:000301447600005
J	Boix, X; Gonfaus, JM; van de Weijer, J; Bagdanov, AD; Serrat, J; Gonzalez, J				Boix, Xavier; Gonfaus, Josep M.; van de Weijer, Joost; Bagdanov, Andrew D.; Serrat, Joan; Gonzalez, Jordi			Harmony Potentials	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Semantic object segmentation; Hierarchical conditional random fields	ENERGY MINIMIZATION; TEXTURE; CLASSIFICATION; SEGMENTATION; LAYOUT	The Hierarchical Conditional Random Field (HCRF) model have been successfully applied to a number of image labeling problems, including image segmentation. However, existing HCRF models of image segmentation do not allow multiple classes to be assigned to a single region, which limits their ability to incorporate contextual information across multiple scales. At higher scales in the image, this representation yields an oversimplified model since multiple classes can be reasonably expected to appear within large regions. This simplified model particularly limits the impact of information at higher scales. Since class-label information at these scales is usually more reliable than at lower, noisier scales, neglecting this information is undesirable. To address these issues, we propose a new consistency potential for image labeling problems, which we call the harmony potential. It can encode any possible combination of labels, penalizing only unlikely combinations of classes. We also propose an effective sampling strategy over this expanded label set that renders tractable the underlying optimization problem. Our approach obtains state-of-the-art results on two challenging, standard benchmark datasets for semantic image segmentation: PASCAL VOC 2010, and MSRC-21.	[Boix, Xavier; Gonfaus, Josep M.; van de Weijer, Joost; Bagdanov, Andrew D.; Serrat, Joan; Gonzalez, Jordi] Ctr Visio Comp, Barcelona, Spain; [Gonfaus, Josep M.; van de Weijer, Joost; Serrat, Joan; Gonzalez, Jordi] Univ Autonoma Barcelona, Dept Comp Sci, E-08193 Barcelona, Spain; [Boix, Xavier] Swiss Fed Inst Technol, Comp Vis Lab, Zurich, Switzerland	Centre de Visio per Computador (CVC); Autonomous University of Barcelona; Swiss Federal Institutes of Technology Domain; ETH Zurich	Boix, X (corresponding author), Ctr Visio Comp, Barcelona, Spain.	boixbosch@vision.ee.ethz.ch; gonfaus@cvc.uab.cat	Gonzàlez, Jordi/I-1812-2015; Serrat, Joan/L-4735-2014; van de Weijer, Joost/A-1643-2009	Gonzàlez, Jordi/0000-0001-8033-0306; Serrat, Joan/0000-0002-4554-199X; van de Weijer, Joost/0000-0002-9656-9706	EU [ERGTS-VICI-224737, VIDI-VIDEO IST-045547, FP7-ICT-24314, FP7-ICT-248873]; Spanish Research Program Consolider-Ingenio: MIPRCV [CSD2007-00018]; Spanish projects [TIN2009-14501-C02-02, TIN2009-14173, TRA2010-21371-C03-01]; Ramon y Cajal fellowship; FPU [AP2008-03378]	EU(European Commission); Spanish Research Program Consolider-Ingenio: MIPRCV; Spanish projects(Spanish Government); Ramon y Cajal fellowship(Spanish Government); FPU(Spanish Government)	We gratefully acknowledge Fahad Shahbaz Khan for providing image classification results for the PASCAL dataset. This work has been supported by the EU projects ERGTS-VICI-224737, VIDI-VIDEO IST-045547, FP7-ICT-24314 and FP7-ICT-248873; by the Spanish Research Program Consolider-Ingenio 2010: MIPRCV (CSD2007-00018); and by the Spanish projects TIN2009-14501-C02-02, TIN2009-14173 and TRA2010-21371-C03-01. Joost van de Weijer acknowledges the support of a Ramon y Cajal fellowship, and Xavier Boix the support of the FPU fellowship AP2008-03378.	Adelson E. H, 2001, P SPIE HUM VIS EL IM; [Anonymous], P COMP VIS PATT REC; [Anonymous], 1971, MARKOV RANDOM UNPUB; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Carreira J., 2010, P COMP VIS PATT REC; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Coughlan J. M., 2002, P EUR C COMP VIS; Csurka G, 2011, INT J COMPUT VISION, V95, P198, DOI 10.1007/s11263-010-0344-8; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Delong A., 2010, P COMP VIS PATT REC; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075; Frey B., 1998, ADV NEUR INF PROC SY; FULKERSON B., 2009, P IEEE INT C COMP VI; Galleguillos C, 2010, COMPUT VIS IMAGE UND, V114, P712, DOI 10.1016/j.cviu.2010.02.004; Gonfaus J., 2010, P COMP VIS PATT REC; Gould S., 2009, ADV NEURAL INFORM PR; Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5; Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y; Ihler A., 2009, P C ART INT STAT; Ishikawa H, 2009, P COMP VIS PATT REC; Jain A., 2010, P EUR C COMP VIS; Jiang J., 2009, P COMP VIS PATT REC; Kohli P., 2010, P COMP VIS PATT REC; KOHLI P., 2009, P IEEE INT C COMP VI; Kohli P, 2009, IEEE T PATTERN ANAL, V31, P1645, DOI 10.1109/TPAMI.2008.217; Kohli P, 2009, INT J COMPUT VISION, V82, P302, DOI 10.1007/s11263-008-0202-0; Koller D., 1999, P ANN C UNC ART INT; Kumar M. P., 2005, P COMP VIS PATT REC; Kumar S., 2005, P IEEE INT C COMP VI; Ladicicy L., 2010, P EUR C COMP VIS; Ladicky L., 2009, P IEEE INT C COMP VI; Lauritzen S., 1996, OXFORD STAT SCI SERI; Lazebnik S., 2006, P COMP VIS PATT REC; Lee Y., 2010, P COMP VIS PATT REC; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; Levin A., 2009, INT J COMPUT VISION, V81, P1645; Li F., 2010, P COMP VIS PATT REC; Li Y., 2008, P EUR C COMP VIS; Lim J. J., 2009, P IEEE INT C COMP VI; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maji S., 2008, P COMP VIS PATT REC; Marr D., 1982, VISION COMPUTATIONAL; Martin D., 2001, P IEEE INT C COMP VI; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Mori G., 2004, P COMP VIS PATT REC; Munoz D., 2010, P EUR C COMP VIS; Munoz D., 2009, P COMP VIS PATT REC; NOWAK E, 2006, P EUR C COMP VIS; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Oliva A, 2007, TRENDS COGN SCI, V11, P520, DOI 10.1016/j.tics.2007.09.009; Pantofaru C., 2008, P EUR C COMP VIS; Plath N., 2009, P INT C MACH LEARN; Platt JC, 2000, ADV NEUR IN, P61; Rabinovich A., 2007, P IEEE INT C COMP VI; Ramalingam S., 2008, P COMP VIS PATT REC; Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6; Rother C., 2009, P COMP VIS PATT REC; Russell C., 2010, P ANN C UNC ART INT; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; Shahbaz Khan F., 2009, P IEEE INT C COMP VI; Shechtman E., 2007, P COMP VIS PATT REC; Shotton J., 2008, P COMP VIS PATT REC; Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1; Sivic J, 2003, P IEEE INT C COMP VI; Sudderth E. B., 2002, P COMP VIS PATT REC; Tu Z., 2005, INT J COMPUT VISION, V63, P18; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154; van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809; Vazquez E, 2011, IEEE T PATTERN ANAL, V33, P917, DOI 10.1109/TPAMI.2010.146; Vedaldi A., 2008, P EUR C COMP VIS; Verbeek J., 2008, ADV NEURAL INFORM PR; Wainwright M, 2008, GRAPHICAL MODELS EXP; WINN J, 2005, P IEEE INT C COMP VI; Woodford O, 2009, IEEE T PATTERN ANAL, V31, P2115, DOI 10.1109/TPAMI.2009.131; Yang J., 2009, P COMP VIS PATT REC; Yang Y., 2010, P COMP VIS PATT REC; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; Zhu L., 2008, ADV NEURAL INFORM PR	82	59	61	0	12	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2012	96	1					83	102		10.1007/s11263-011-0449-8	http://dx.doi.org/10.1007/s11263-011-0449-8			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	872LF		Green Published			2022-12-18	WOS:000298810300005
J	Wu, CY; Narasimhan, SG; Jaramaz, B				Wu, Chenyu; Narasimhan, Srinivasa G.; Jaramaz, Branislav			A Multi-Image Shape-from-Shading Framework for Near-Lighting Perspective Endoscopes	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	Workshop on Photometric Analysis for Computer Vision held in Conjunction with the 11th International Conference on Computer Vision Conference	OCT 04, 2007	Rio de Janeiro, BRAZIL			Multi-image; Shape-from-shading; Near-lighting; Perspective projection; Calibration; Endoscope; Bone	RECONSTRUCTION; REGISTRATION; CALIBRATION; PROJECTION; IMAGES	This article formulates a near-lighting shape-from-shading problem with a pinhole camera (perspective projection) and presents a solution to reconstruct the Lambertian surface of bones using a sequence of overlapped endoscopic images, with partial boundaries in each image. First we extend the shape-from-shading problem to deal with perspective projection and near point light sources that are not co-located with the camera center. Secondly we propose a multi-image framework which can align partial shapes obtained from different images in the world coordinates by tracking the endoscope. An iterative closest point (ICP) algorithm is used to improve the matching and recover complete occluding boundaries of the bone. Finally, a complete and consistent shape is obtained by simultaneously re-growing the surface normals and depths in all views. In order to fulfill our shape-from-shading algorithm, we also calibrate both geometry and photometry for an oblique-viewing endoscope that are not well addressed before in the previous literatures. We demonstrate the accuracy of our technique using simulations and experiments with artificial bones.	[Wu, Chenyu; Narasimhan, Srinivasa G.; Jaramaz, Branislav] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA; [Jaramaz, Branislav] Inst Comp Assisted Surg, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Wu, CY (corresponding author), Carnegie Mellon Univ, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	cywu@cs.cmu.edu; srinivas@cs.cmu.edu; branko@icaos.org						BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Clarkson MJ, 1999, LECT NOTES COMPUT SC, V1679, P579; Courteille F, 2004, INT C PATT RECOG, P277, DOI 10.1109/ICPR.2004.1334160; Dey D, 2002, IEEE T MED IMAGING, V21, P23, DOI 10.1109/42.981231; Durou JD, 2008, COMPUT VIS IMAGE UND, V109, P22, DOI 10.1016/j.cviu.2007.09.003; FORSTER CHQ, 2000, P 13 BRAZ S COMP GRA, P90; FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909; Fuchs H, 1998, LECT NOTES COMPUT SC, V1496, P934, DOI 10.1007/BFb0056282; Hartley R., 2004, ROBOTICA; Hasegawa JK, 1996, COMPUT GRAPH, V20, P351, DOI 10.1016/0097-8493(96)00004-0; Horn B.K.P., 1989, SHAPE SHADING; HORN BKP, 1979, APPL OPTICS, V18, P1770, DOI 10.1364/AO.18.001770; HORN BKP, 1986, COMPUT VISION GRAPH, V33, P174, DOI 10.1016/0734-189X(86)90114-3; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; Iyengar AKS, 2001, ANN BIOMED ENG, V29, P963, DOI 10.1114/1.1415523; Kimmel R, 2001, J MATH IMAGING VIS, V14, P237, DOI 10.1023/A:1011234012449; Kozera R., 1992, International Journal of Pattern Recognition and Artificial Intelligence, V6, P673, DOI 10.1142/S0218001492000357; KOZERA R, 1991, APPL MATH COMPUT, V44, P1, DOI 10.1016/0096-3003(91)90001-4; KOZERA R, 2004, P INT C COMP VIS GRA, V32, P103; Kozera R., 1998, MACHINE GRAPHICS VIS, V7, P291; Leclerc Y. G., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P552, DOI 10.1109/CVPR.1991.139752; Lee KM, 1997, COMPUT VIS IMAGE UND, V67, P143, DOI 10.1006/cviu.1997.0522; LEE KM, 1994, CVGIP-IMAG UNDERSTAN, V59, P202, DOI 10.1006/ciun.1994.1013; Litvinov A, 2005, PROC CVPR IEEE, P52; Mourgues F, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P191, DOI 10.1109/ISAR.2001.970537; Okatani T, 1997, COMPUT VIS IMAGE UND, V66, P119, DOI 10.1006/cviu.1997.0613; PENNA MA, 1989, IEEE T PATTERN ANAL, V11, P545, DOI 10.1109/34.24790; Poelman CJ, 1997, IEEE T PATTERN ANAL, V19, P206, DOI 10.1109/34.584098; Prados E, 2005, PROC CVPR IEEE, P870; Prados E, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P826; SAMARAS D, 1999, P INT C COMP VIS, V2, P868; Seshamani S, 2006, LECT NOTES COMPUT SC, V4190, P355; Stoyanov Danail, 2005, Comput Aided Surg, V10, P199, DOI 10.1080/10929080500230379; Tankus A, 2005, INT J COMPUT VISION, V63, P21, DOI 10.1007/s11263-005-4945-6; Tankus A, 2004, INT C PATT RECOG, P778, DOI 10.1109/ICPR.2004.1334644; Tankus A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P862; TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Yamaguchi Tetsuzo, 2004, Comput Aided Surg, V9, P203, DOI 10.3109/10929080500163505; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284; Zhang Z., 1998, MSRTR9871	42	59	63	0	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2010	86	2-3			SI		211	228		10.1007/s11263-009-0207-3	http://dx.doi.org/10.1007/s11263-009-0207-3			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	534NA					2022-12-18	WOS:000272903200007
J	Kumar, MP; Torr, PHS; Zisserman, A				Kumar, M. Pawan; Torr, P. H. S.; Zisserman, A.			Learning layered motion segmentations of video	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						motion segmentation; layered representation; coarse-to-fine belief propagation; graph cuts	IMAGES; STATISTICS	We present an unsupervised approach for learning a layered representation of a scene from a video for motion segmentation. Our method is applicable to any video containing piecewise parametric motion. The learnt model is a composition of layers, which consist of one or more segments. The shape of each segment is represented using a binary matte and its appearance is given by the RGB value for each point belonging to the matte. Included in the model are the effects of image projection, lighting, and motion blur. Furthermore, spatial continuity is explicitly modeled resulting in contiguous segments. Unlike previous approaches, our method does not use reference frame(s) for initialization. The two main contributions of our method are: (i) A novel algorithm for obtaining the initial estimate of the model by dividing the scene into rigidly moving components using efficient loopy belief propagation; and (ii) Refining the initial estimate using alpha beta-swap and alpha-expansion algorithms, which guarantee a strong local minima. Results are presented on several classes of objects with different types of camera motion, e. g. videos of a human walking shot with static or translating cameras. We compare our method with the state of the art and demonstrate significant improvements.	[Zisserman, A.] Univ Oxford, Dept Engn Sci, Oxford OX1 2JD, England; [Kumar, M. Pawan; Torr, P. H. S.] Oxford Brookes Univ, Dept Comp, Oxford OX3 0BP, England	University of Oxford; Oxford Brookes University	Kumar, MP (corresponding author), Oxford Brookes Univ, Dept Comp, Oxford OX3 0BP, England.	pkmudigonda@brookes.ac.uk; philiptorr@brookes.ac.uk; az@robots.ox.ac.uk						AGARWAL A, 2004, EUR C COMP VIS, V3, P54; Black MJ, 2000, INT J COMPUT VISION, V38, P231, DOI 10.1023/A:1008195307933; BLAKE A, 2004, ECCV, P428; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y.Y., 2001, ICCV, V1, P105, DOI DOI 10.1109/ICCV.2001.937505; Cremers D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P886; Felzenszwalb P., 2003, NIPS; Jojic N, 2001, PROC CVPR IEEE, P199; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Kumar MP, 2005, IEEE I CONF COMP VIS, P33; Kumar MP, 2005, PROC CVPR IEEE, P18; KUMAR MP, 2004, ICVGIP, P148; LAFFERTY J, 2005, ICML; Magee DR, 2002, IMAGE VISION COMPUT, V20, P581, DOI 10.1016/S0262-8856(02)00047-1; PEARL J, 1998, PROBABILISTIC REASON; Ramanan D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P338; Sidenbladh H, 2003, INT J COMPUT VISION, V54, P181, DOI 10.1023/A:1023765619733; Torr PH, 1999, P INT WORKSH VIS ALG, P278, DOI DOI 10.1007/3-540-44480-7_19; Torr PHS, 2001, IEEE T PATTERN ANAL, V23, P297, DOI 10.1109/34.910882; VOGIATZIS G, 2004, BMVC, P117; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; WEISS Y, CVPR, P321; Williams CKI, 2004, NEURAL COMPUT, V16, P1039, DOI 10.1162/089976604773135096; Wills Josh, 2003, CVPR, V2, P4; WINN J, 2004, NIPS, P1505	25	59	63	0	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2008	76	3					301	319		10.1007/s11263-007-0064-x	http://dx.doi.org/10.1007/s11263-007-0064-x			19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	255VI		Green Submitted			2022-12-18	WOS:000252685500006
J	Aggarwal, M; Ahuja, N				Aggarwal, M; Ahuja, N			Split aperture imaging for high dynamic range	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						beam splitting; high dynamic range; multiple sensors; video-rate imaging; split aperture imaging		Most imaging sensors have limited dynamic range and hence are sensitive to only a part of the illumination range present in a natural scene. The dynamic range can be improved by acquiring multiple images of the same scene under different exposure settings and then combining them. In this paper, we describe a camera design for simultaneously acquiring multiple images. The cross-section of the incoming beam from a scene point is partitioned into as many parts as the required number of images. This is done by splitting the aperture into multiple parts and directing the beam exiting from each in a different direction using an assembly of mirrors. A sensor is placed in the path of each beam and exposure of each sensor is controlled either by appropriately setting its exposure parameter, or by splitting the incoming beam unevenly. The resulting multiple exposure images are used to construct a high dynamic range image. We have implemented a video-rate camera based on this design and the results obtained are presented.	Univ Illinois, Beckman Inst, Urbana, IL 61801 USA	University of Illinois System; University of Illinois Urbana-Champaign	Aggarwal, M (corresponding author), Sarnoff Corp, 201 Washington Rd, Princeton, NJ 08540 USA.	maggarwal@sarnoff.com; ahuja@vision.ai.uiuc.edu						Brajovic V, 1996, IEEE INT CONF ROBOT, P1638, DOI 10.1109/ROBOT.1996.506947; Burt P. J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P173, DOI 10.1109/ICCV.1993.378222; Debevec P., 1997, P ACM SIGGRAPH 1997, DOI [DOI 10.1145/258734.258884, 10.1145/258734.258884]; *EIO, 2000, OPT TOP INSTR CAT; HARADA K, 2000, Patent No. 6141049; Harvey R. P., 1998, U.S. Patent, Patent No. [5,734,507, 5734507]; HEALEY GE, 1994, IEEE T PATTERN ANAL, V16, P267, DOI 10.1109/34.276126; HIDEAKI D, 1996, Patent No. 8223491; Hiura S, 1998, PROC CVPR IEEE, P953, DOI 10.1109/CVPR.1998.698719; Ikeda E., 1998, U.S. Patent, Patent No. 5801773; KANEKO T, 1997, INT C SOL STAT SENS, P63; Kaneko Y., 1993, U.S. Patent, Patent No. [5 194 959, 5194959]; Kingslake R., 1983, OPTICAL SYSTEM DESIG; MADDEN BC, 1996, MSCIS9396 U PENNS; MANN S, 1995, IS&T'S 48TH ANNUAL CONFERENCE - IMAGING ON THE INFORMATION SUPERHIGHWAY, FINAL PROGRAM AND PROCEEDINGS, P442; Mitsunaga T., P 1999 IEEE COMP SOC, P374; Nayar SK, 2000, PROC CVPR IEEE, P472, DOI 10.1109/CVPR.2000.855857; RUBIN LB, 1998, Patent No. 5835278; Saito K., 1996, Japanese Patent, Patent No. [08-340486, 08340486]; SIMONCELLI E, 1998, P EUR C COMP VIS, V2, P953; Street R. A., 1998, U.S. Patent, Patent No. 5789737; TAKAHASHI K, 1997, Patent No. 5638118; TSUTOMU K, 1998, Patent No. 10069011	23	59	75	0	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2004	58	1					7	17		10.1023/B:VISI.0000016144.56397.1a	http://dx.doi.org/10.1023/B:VISI.0000016144.56397.1a			11	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	823OD					2022-12-18	WOS:000221621600002
J	Vougioukas, K; Petridis, S; Pantic, M				Vougioukas, Konstantinos; Petridis, Stavros; Pantic, Maja			Realistic Speech-Driven Facial Animation with GANs	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Generative modelling; Face generation; Speech-driven animation	HEAD	Speech-driven facial animation is the process that automatically synthesizes talking characters based on speech signals. The majority of work in this domain creates a mapping from audio features to visual features. This approach often requires post-processing using computer graphics techniques to produce realistic albeit subject dependent results. We present an end-to-end system that generates videos of a talking head, using only a still image of a person and an audio clip containing speech, without relying on handcrafted intermediate features. Our method generates videos which have (a) lip movements that are in sync with the audio and (b) natural facial expressions such as blinks and eyebrow movements. Our temporal GAN uses 3 discriminators focused on achieving detailed frames, audio-visual synchronization, and realistic expressions. We quantify the contribution of each component in our model using an ablation study and we provide insights into the latent representation of the model. The generated videos are evaluated based on sharpness, reconstruction quality, lip-reading accuracy, synchronization as well as their ability to generate natural blinks.	[Vougioukas, Konstantinos; Petridis, Stavros; Pantic, Maja] Imperial Coll London, Dept Comp, 180 Queens Gate, London SW7 2AZ, England; [Petridis, Stavros; Pantic, Maja] Samsung AI Res Ctr Cambridge, 50 Stn Rd, Cambridge CB1 2RE, England	Imperial College London	Vougioukas, K (corresponding author), Imperial Coll London, Dept Comp, 180 Queens Gate, London SW7 2AZ, England.	k.vougioukas@imperial.ac.uk; stavros.petridis04@imperial.ac.uk; m.pantic@imperial.ac.uk		Vougioukas, Konstantinos/0000-0001-8552-5559	NVIDIA Corporation; EPSRC [2130174] Funding Source: UKRI	NVIDIA Corporation; EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	We would like to thank Berk Tinaz for his help with the detection of blinks and the estimation blink duration. We also gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan V GPU used for this research and Amazon Web Services for providing the computational resources for our experiments.	Amos Brandon, 2016, OPENFACE GEN PURPOSE, V6; Arjovsky Mart<prime>in, 2017, P 5 INT C LEARN REPR; Assael Yannis M., 2016, ARXIV161101599; Bentivoglio AR, 1997, MOVEMENT DISORD, V12, P1028, DOI 10.1002/mds.870120629; Bregler C., 2007, P ACM SIGGRAPH, P353; Cao HW, 2014, IEEE T AFFECT COMPUT, V5, P377, DOI 10.1109/TAFFC.2014.2336244; Cao Y, 2005, ACM T GRAPHIC, V24, P1283, DOI 10.1145/1095878.1095881; Carl V., 2016, ADV NEURAL INFORM PR, V29, P613, DOI DOI 10.13016/M26GIH-TNYZ; Cech J., 2016, REAL TIME EYE BLINK, DOI DOI 10.1017/CBO9781107415324.004; Chen L, 2018, EURASIP J WIREL COMM, DOI 10.1186/s13638-017-1011-3; Chen LL, 2019, PROC CVPR IEEE, P7824, DOI 10.1109/CVPR.2019.00802; Chung JS, 2017, LECT NOTES COMPUT SC, V10112, P87, DOI 10.1007/978-3-319-54184-6_6; Chung Joon Son, 2016, P AS C COMP VIS, P251, DOI [DOI 10.1007/978-3-319-54427-4_19, 10.1007/978-3-319-54427-4{_}19, DOI 10.1007/978-3-319-54427-4{_}19]; Chung Joon Son, 2017, BMVC; Cooke M, 2006, J ACOUST SOC AM, V120, P2421, DOI 10.1121/1.2229005; Dai W, 2017, INT CONF ACOUST SPEE, P421, DOI 10.1109/ICASSP.2017.7952190; Fan B, 2015, INT CONF ACOUST SPEE, P4884, DOI 10.1109/ICASSP.2015.7178899; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Guo X. Z. Jianzhu, 2018, 3DDFA; Harte N, 2015, IEEE T MULTIMEDIA, V17, P603, DOI 10.1109/TMM.2015.2407694; Karras T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073658; Kingma D.P, P 3 INT C LEARNING R; Li Y., 2018, WIFS; Li Y., 2017, ARXIV171000421; Mathieu Michael, 2015, ARXIV151105440; Narvekar ND, 2009, INT WORK QUAL MULTIM, P87, DOI 10.1109/QOMEX.2009.5246972; Pham HV, 2020, GEOSYNTH INT, V27, P157, DOI 10.1680/jgein.18.00039; Pham HX, 2017, IEEE COMPUT SOC CONF, P2328, DOI 10.1109/CVPRW.2017.287; Pumarola A, 2018, LECT NOTES COMPUT SC, V11214, P835, DOI 10.1007/978-3-030-01249-6_50; Radford A., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.1051/0004-6361/201527329; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Saito M, 2017, IEEE I CONF COMP VIS, P2849, DOI 10.1109/ICCV.2017.308; SIMONS AD, 1990, P I ACOUSTICS, V12, P475; Solomon ELS, 2017, MINERAL MET MAT SER, P349, DOI 10.1007/978-3-319-52392-7_50; Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640; Taylor S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073699; Tulyakov S, 2018, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR.2018.00165; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vougioukas Konstantinos, 2018, BMVC; Xie L, 2007, PATTERN RECOGN, V40, P2325, DOI 10.1016/j.patcog.2006.12.001; Yamamoto E, 1998, SPEECH COMMUN, V26, P105, DOI 10.1016/S0167-6393(98)00054-5; Yehia H, 1998, SPEECH COMMUN, V26, P23, DOI 10.1016/S0167-6393(98)00048-X; Yehia HC, 2002, J PHONETICS, V30, P555, DOI 10.1006/jpho.2002.0165; Zhou H, 2019, AAAI CONF ARTIF INTE, P9299; Zhou Yang, 2018, ACM T GRAPHIC, V37; Zhu X., 2017, IEEE TPAMI	46	58	60	2	25	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2020	128	5					1398	1413		10.1007/s11263-019-01251-8	http://dx.doi.org/10.1007/s11263-019-01251-8		OCT 2019	16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	LL9ON		Green Published, Green Submitted			2022-12-18	WOS:000490090600001
J	Gao, SH; Jia, K; Zhuang, LS; Ma, Y				Gao, Shenghua; Jia, Kui; Zhuang, Liansheng; Ma, Yi			Neither Global Nor Local: Regularized Patch-Based Representation for Single Sample Per Person Face Recognition	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Single sample per person; Regularized patch-based representation; Group sparsity; Intra-class variance dictionary	EXPRESSION VARIANT FACES; ONE TRAINING IMAGE; CLASSIFICATION; ROBUST; MODEL; FLDA; PCA	This paper presents a regularized patch-based representation for single sample per person face recognition. We represent each image by a collection of patches and seek their sparse representations under the gallery images patches and intra-class variance dictionaries at the same time. For the reconstruction coefficients of all the patches from the same image, by imposing a group sparsity constraint on the reconstruction coefficients corresponding to the patches from the gallery images, and by imposing a sparsity constraint on the reconstruction coefficients corresponding to the intra-class variance dictionaries, our formulation harvests the advantages of both patch-based image representation and global image representation, i.e. our method overcomes the side effect of those patches which are severely corrupted by the variances in face recognition, while enforcing those less discriminative patches to be constructed by the gallery patches from the right person. Moreover, instead of using the manually designed intra-class variance dictionaries, we propose to learn the intra-class variance dictionaries which not only greatly accelerate the prediction of the probe images but also improve the face recognition accuracy in the single sample per person scenario. Experimental results on the AR, Extended Yale B, CMU-PIE, and LFW datasets show that our method outperforms sparse coding related face recognition methods as well as some other specially designed single sample per person face representation methods, and achieves the best performance. These encouraging results demonstrate the effectiveness of regularized patch-based face representation for single sample per person face recognition.	[Gao, Shenghua; Ma, Yi] ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China; [Jia, Kui] Univ Macau, Dept Elect & Comp Engn, Fac Sci & Technol, Macau, Peoples R China; [Zhuang, Liansheng] Univ Sci & Technol China, CAS Key Lab Electromagnet Space Informat, Hefei 230026, Peoples R China	ShanghaiTech University; University of Macau; Chinese Academy of Sciences; University of Science & Technology of China, CAS	Gao, SH (corresponding author), ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China.	gaoshh@shanghaitech.edu.cn; kuijia@gmail.com; lszhuang@ustc.edu.cn; mayi@shanghaitech.edu.cn						Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Chen SC, 2004, PATTERN RECOGN LETT, V25, P1173, DOI 10.1016/j.patrec.2004.03.012; Chen SC, 2004, PATTERN RECOGN, V37, P1553, DOI 10.1016/j.patcog.2003.12.010; Deng WH, 2013, PROC CVPR IEEE, P399, DOI 10.1109/CVPR.2013.58; Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30; Deng WH, 2010, PATTERN RECOGN, V43, P1748, DOI 10.1016/j.patcog.2009.12.004; Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067; Gao QX, 2008, APPL MATH COMPUT, V205, P726, DOI 10.1016/j.amc.2008.05.019; Gao SH, 2013, IEEE T IMAGE PROCESS, V22, P423, DOI 10.1109/TIP.2012.2215620; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Gottumukkal R, 2004, PATTERN RECOGN LETT, V25, P429, DOI 10.1016/j.patrec.2003.11.005; Huang GB, 2007, 07 UMASS TR; Kim KI, 2002, IEEE SIGNAL PROC LET, V9, P40, DOI 10.1109/97.991133; Kim TK, 2005, IEEE T PATTERN ANAL, V27, P318, DOI 10.1109/TPAMI.2005.58; Kong S., 2012, P EUR C COMP VIS; Kumar R., 2011, P INT C COMP VIS; Lee H., 2006, P C NEUR INF PROC SY; Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679; Lu JW, 2011, IEEE I CONF COMP VIS, P1943, DOI 10.1109/ICCV.2011.6126464; Martinez A., 1998, THE AR FACE DATABASE, V24; Martinez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382; Shan S, 2002, IEEE INT S CIRC SYST; Sim T., 2002, INT C AUT FAC GEST R; Su Y., 2010, P IEEE C COMP VIS PA; Tan XY, 2005, IEEE T NEURAL NETWOR, V16, P875, DOI 10.1109/TNN.2005.849817; Turk MA, 1991, P IEEE COMP SOC C CO; Wolf L., 2009, P AS C COMP VIS; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Wu JX, 2002, PATTERN RECOGN LETT, V23, P1711, DOI 10.1016/S0167-8655(02)00134-4; Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097; Yang JF, 2009, SIAM J IMAGING SCI, V2, P569, DOI 10.1137/080730421; Yang M., 2013, INT C COMP VIS; Yuan XT, 2012, IEEE T IMAGE PROCESS, V21, P4349, DOI 10.1109/TIP.2012.2205006; Zhang L., 2011, P INT C COMP VIS; Zhu P., 2012, P EUR C COMP VIS	37	58	64	0	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	FEB	2015	111	3					365	383		10.1007/s11263-014-0750-4	http://dx.doi.org/10.1007/s11263-014-0750-4			19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	CB9XK					2022-12-18	WOS:000349987400006
J	Paul, G; Cardinale, J; Sbalzarini, I				Paul, Gregory; Cardinale, Janick; Sbalzarini, Ivo F.			Coupling Image Restoration and Segmentation: A Generalized Linear Model/Bregman Perspective	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Segmentation; Restoration; Generalized linear model; Shape gradient; Convex relaxation; Alternating split Bregman	ACTIVE CONTOURS; VARIATIONAL APPROACH; GLOBAL MINIMIZATION; CONVEX FORMULATION; REGION COMPETITION; SHAPE; ALGORITHMS; MODEL; RECONSTRUCTION; PARAMETER	We introduce a new class of data-fitting energies that couple image segmentation with image restoration. These functionals model the image intensity using the statistical framework of generalized linear models. By duality, we establish an information-theoretic interpretation using Bregman divergences. We demonstrate how this formulation couples in a principled way image restoration tasks such as denoising, deblurring (deconvolution), and inpainting with segmentation. We present an alternating minimization algorithm to solve the resulting composite photometric/geometric inverse problem. We use Fisher scoring to solve the photometric problem and to provide asymptotic uncertainty estimates. We derive the shape gradient of our data-fitting energy and investigate convex relaxation for the geometric problem. We introduce a new alternating split-Bregman strategy to solve the resulting convex problem and present experiments and comparisons on both synthetic and real-world images.	[Paul, Gregory; Cardinale, Janick; Sbalzarini, Ivo F.] ETH, MOSAIC Grp, CH-8092 Zurich, Switzerland	Swiss Federal Institutes of Technology Domain; ETH Zurich	Sbalzarini, I (corresponding author), Max Planck Inst Mol Cell Biol & Genet, Ctr Syst Biol, MOSAIC Grp, Pfotenhauerstr 108, D-01307 Dresden, Germany.	grpaul@ethz.ch; janickc@inf.ethz.ch; ivos@mpi-cbg.de	Sbalzarini, Ivo F/B-2789-2017	Sbalzarini, Ivo Fabian/0000-0003-4414-4340	Swiss Federal Commission for Technology and Innovation [9325.2-PFLS-LS]; Swiss SystemsX.ch initiative	Swiss Federal Commission for Technology and Innovation; Swiss SystemsX.ch initiative	We thank Jo A. Helmuth for sharing his experience in many discussions. JC and GP were funded through CTI grant 9325.2-PFLS-LS from the Swiss Federal Commission for Technology and Innovation ( to IFS in collaboration with Bitplane, Inc). This project was further supported with grants from the Swiss SystemsX.ch initiative, grants LipidX and WingX, to IFS. We thank J. Zartman, S. Restrepo, and K. Basler for providing the Drosophila wing disc example image.	Alliney S, 1997, IEEE T SIGNAL PROCES, V45, P913, DOI 10.1109/78.564179; Art J., 2006, HDB BIOL CONFOCAL MI, P251; Aubert G, 2003, SIAM J APPL MATH, V63, P2128, DOI 10.1137/S0036139902408928; Aubert G., 2006, MATH PROBLEMS IMAGE, V147; Aubert G, 2008, SIAM J APPL MATH, V68, P925, DOI 10.1137/060671814; Aujol JF, 2006, INT J COMPUT VISION, V67, P111, DOI 10.1007/s11263-006-4331-z; Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412; Banerjee A, 2005, J MACH LEARN RES, V6, P1705; BARNDORFFNIELSE.O, 1978, WILEY SERIES PROBABI; BERTERO M, 1988, P IEEE, V76, P869, DOI 10.1109/5.5962; Bertero Mario, 2020, INTRO INVERSE PROBLE, P2; Bovik A, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, pV, DOI 10.1016/B978-012119792-6/50062-0; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0; Brown ES, 2012, INT J COMPUT VISION, V98, P103, DOI 10.1007/s11263-011-0499-y; Brox T, 2010, IMAGE VISION COMPUT, V28, P376, DOI 10.1016/j.imavis.2009.06.009; Burger M, 2005, EUR J APPL MATH, V16, P263, DOI 10.1017/S0956792505006182; Burger M., 2005, PAMM, V5, P11; Cardinale J, 2012, IEEE T IMAGE PROCESS, V21, P3531, DOI 10.1109/TIP.2012.2192129; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685; Chambolle A, 2004, J MATH IMAGING VIS, V20, P89; Chambolle A, 2012, SIAM J IMAGING SCI, V5, P1113, DOI 10.1137/110856733; Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1; Chan T., 2005, IMAGE PROCESSING ANA; Chan TF, 2005, SIAM J APPL MATH, V65, P1817, DOI 10.1137/040604297; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286; Chesnaud C, 1999, IEEE T PATTERN ANAL, V21, P1145, DOI 10.1109/34.809108; Choksi R, 2011, INVERSE PROBL IMAG, V5, P591, DOI 10.3934/ipi.2011.5.591; Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1; Delfour M, 2011, ADV DES CONTROL, pXIX, DOI 10.1137/1.9780898719826; Dey N, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 and 2, P1223; ESSER E., 2009, APPL LAGRANGIAN BASE; GEIGER D, 1991, INT J COMPUT VISION, V6, P227, DOI 10.1007/BF00115697; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Goldstein T, 2010, J SCI COMPUT, V45, P272, DOI 10.1007/s10915-009-9331-z; Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891; Goudail F, 2004, J OPT SOC AM A, V21, P1231, DOI 10.1364/JOSAA.21.001231; Goudail F, 2003, LECT NOTES COMPUT SC, V2683, P373; GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x; Hansen P.C., 2006, DEBLURRING IMAGES MA; HEBERT T, 1989, IEEE T MED IMAGING, V8, P194, DOI 10.1109/42.24868; Helmuth JA, 2009, J STRUCT BIOL, V167, P1, DOI 10.1016/j.jsb.2009.03.017; Helmuth JA, 2009, LECT NOTES COMPUT SC, V5875, P544, DOI 10.1007/978-3-642-10331-5_51; Jung M, 2009, SPIE ELECT IMAGING C, V7246; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kersten D, 2004, ANNU REV PSYCHOL, V55, P271, DOI 10.1146/annurev.psych.55.090902.142005; Lecellier F, 2006, P IEEE INT AC SPEECH, V2; Lecellier F, 2010, J MATH IMAGING VIS, V36, P28, DOI 10.1007/s10851-009-0168-8; Lellmann J, 2011, SIAM J IMAGING SCI, V4, P1049, DOI 10.1137/100805844; Leung SY, 2005, LECT NOTES COMPUT SC, V3752, P149; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; Marquina A, 2008, J SCI COMPUT, V37, P367, DOI 10.1007/s10915-008-9214-8; Martin P, 2004, IEEE T PATTERN ANAL, V26, P799, DOI 10.1109/TPAMI.2004.11; MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9; McCullagh P., 1989, GEN LINEAR MODELS, V2nd; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; MUMFORD D, 1994, GEOMETRY DRIVEN DIFF, P141; NELDER JA, 1972, J R STAT SOC SER A-G, V135, P370, DOI 10.2307/2344614; Nikolova M, 2004, J MATH IMAGING VIS, V20, P99, DOI 10.1023/B:JMIV.0000011920.58935.9c; Osher S., 2003, APPL MATH SCI, V153; Osher S., 2003, GEOMETRIC LEVEL SET; Paragios N, 2002, J VIS COMMUN IMAGE R, V13, P249, DOI 10.1006/jvci.2001.0475; Paul G, 2011, CONF REC ASILOMAR C, P426, DOI 10.1109/ACSSC.2011.6190034; Pock T, 2008, LECT NOTES COMPUT SC, V5304, P792, DOI 10.1007/978-3-540-88690-7_59; Pock T, 2009, PROC CVPR IEEE, P810, DOI 10.1109/CVPRW.2009.5206604; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Sbalzarini IF, 2006, BIOPHYS J, V90, P878, DOI 10.1529/biophysj.105.073809; Sbalzarini IF, 2005, BIOPHYS J, V89, P1482, DOI 10.1529/biophysj.104.057885; Sethian J. A., 1999, LEVEL SET METHODS FA; Setzer S, 2010, J VIS COMMUN IMAGE R, V21, P193, DOI 10.1016/j.jvcir.2009.10.006; Setzer S, 2011, INT J COMPUT VISION, V92, P265, DOI 10.1007/s11263-010-0357-3; Song PXK, 2007, SPRINGER SER STAT, P121, DOI 10.1007/978-0-387-71393-9_6; Strang G, 1999, SIAM REV, V41, P135, DOI 10.1137/S0036144598336745; Tai XC, 2009, LECT NOTES COMPUT SC, V5567, P502; Vogel C. R., 2002, FRONT APPL MATH, DOI DOI 10.1137/1.9780898717570; Vonesch C, 2008, IEEE T IMAGE PROCESS, V17, P539, DOI 10.1109/TIP.2008.917103; Zartman J, 2013, DEVELOPMENT, V140, P667, DOI 10.1242/dev.088872; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	81	58	60	0	30	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2013	104	1					69	93		10.1007/s11263-013-0615-2	http://dx.doi.org/10.1007/s11263-013-0615-2			25	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	179LY		hybrid, Green Published, Green Accepted			2022-12-18	WOS:000321523000004
J	Kirmani, A; Hutchison, T; Davis, J; Raskar, R				Kirmani, Ahmed; Hutchison, Tyler; Davis, James; Raskar, Ramesh			Looking Around the Corner using Ultrafast Transient Imaging	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Light transport; Global illumination; Multi-path analysis; Inverse problems; Inverse rendering; Computational Imaging		We propose a novel framework called transient imaging for image formation and scene understanding through impulse illumination and time images. Using time-of-flight cameras and multi-path analysis of global light transport, we pioneer new algorithms and systems for scene understanding through time images. We demonstrate that our proposed transient imaging framework allows us to accomplish tasks that are well beyond the reach of existing imaging technology. For example, one can infer the geometry of not only the visible but also the hidden parts of a scene, enabling us to look around corners. Traditional cameras estimate intensity per pixel I (x, y). Our transient imaging camera captures a 3D time-image I (x, y, t) for each pixel and uses an ultra-short pulse laser for illumination. Emerging technologies are supporting cameras with a temporal-profile per pixel at picosecond resolution, allowing us to capture an ultra-high speed time-image. This time-image contains the time profile of irradiance incident at a sensor pixel. We experimentally corroborated our theory with free space hardware experiments using a femtosecond laser and a picosecond accurate sensing device. The ability to infer the structure of hidden scene elements, unobservable by both the camera and illumination source, will create a range of new computer vision opportunities.	[Kirmani, Ahmed; Hutchison, Tyler; Raskar, Ramesh] MIT Media Lab, Cambridge, MA 02139 USA; [Davis, James] UC Santa Cruz, Dept Comp Sci, Santa Cruz, CA 95064 USA	Massachusetts Institute of Technology (MIT); University of California System; University of California Santa Cruz	Kirmani, A (corresponding author), MIT Media Lab, Cambridge, MA 02139 USA.	akirmani@mit.edu; thutch@mit.edu; davis@cs.ucsc.edu; raskar@mit.edu			NSF [CCF-0746690]; Nokia; Sloan research fellowship	NSF(National Science Foundation (NSF)); Nokia(Nokia Corporation); Sloan research fellowship(Alfred P. Sloan Foundation)	Davis was supported in part by NSF #CCF-0746690 and Raskar was supported in part by Nokia Research and Sloan research fellowship.	Arvo J., 1993, GLOBAL ILLUMINATION; CAMPILLO A, 1983, IEEE J QUANTUM ELECT; DATTORRO J, 2006, CONVEX OPTIMIZATION; DENK W, 1990, SCIENCE, V248, P73, DOI 10.1126/science.2321027; GARREN D, 2005, P IEEE INT RAD C; Garren DA, 2004, IEEE RAD CONF, P323, DOI 10.1109/NRC.2004.1316443; GONZALEZBANOS H, 2004, COMPUTER VISION PATT; IDDAN GJ, 2001, SPIE, P3; IMMEL DS, 1986, ACM SIGGRAPH; Itatani J, 2002, PHYS REV LETT, V88, DOI 10.1103/PhysRevLett.88.173903; Kajiya J. T., 1986, ACM SIGGRAPH; KAMERMAN GW, 1993, INFRARED ELECTROOPTI, V6, pCH1; KUTULAKOS KN, 2007, INT J COMPUTER VISIO; LANGE R, 2001, IEEE J QUANTUM ELECT; MORRIS NJW, 2007, INT C COMP VIS; NAYAR SK, 2006, ACM SIGGRAPH; NAYAR SK, 1990, INT C COMP VIS; Ng R., 2005, COMPUT SCI TECH REP, V2, P1; Patow G., 2003, COMPUTER GRAPHICS FO; RAMAMOORTHI R, 2001, COMPUTER GRAPHICS IN; RASKAR R, 2007, 5D TIME LIGHT TRANSP; SARUNIC P, 2001, OVER HORIZON RADAR M; SCHMITT JM, 1999, IEEE QUANTUM ELECT; Seitz SM, 2005, IEEE I CONF COMP VIS, P1440; SEN P, 2005, ACM SIGGRAPH; SMITH A, 2008, UCSCSOE0826, P2; VANDAPEL N, 2004, IEEE INT C ROB AUT; VEERARAGHAVAN A, 2007, ACM SIGGRAPH	28	58	62	5	31	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	OCT	2011	95	1					13	28		10.1007/s11263-011-0470-y	http://dx.doi.org/10.1007/s11263-011-0470-y			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	815ZU					2022-12-18	WOS:000294569300002
J	Sim, R; Elinas, P; Little, JJ				Sim, Robert; Elinas, Pantelis; Little, James J.			A study of the rao-blackwellised particle filter for efficient and accurate vision-based SLAM	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						vision; slam; robotics; rao-blackwellised particle filters; mixture proposal; feature matching; localization	LOCALIZATION	With recent advances in real-time implementations of filters for solving the simultaneous localization and mapping (SLAM) problem in the range-sensing domain, attention has shifted to implementing SLAM solutions using vision-based sensing. This paper presents and analyses different models of the Rao-Blackwellised particle filter (RBPF) for vision-based SLAM within a comprehensive application architecture. The main contributions of our work are the introduction of a new robot motion model utilizing structure from motion (SFM) methods and a novel mixture proposal distribution that combines local and global pose estimation. In addition, we compare these under a wide variety of operating modalities, including monocular sensing and the standard odometry-based methods. We also present a detailed study of the RBPF for SLAM, addressing issues in achieving real-time, robust and numerically reliable filter behavior. Finally, we present experimental results illustrating the improved accuracy of our proposed models and the efficiency and scalability of our implementation.	Univ British Columbia, Dept Comp Sci, 2366 Main Mall, Vancouver, BC V6T 1Z4, Canada	University of British Columbia	Sim, R (corresponding author), Univ British Columbia, Dept Comp Sci, 2366 Main Mall, Vancouver, BC V6T 1Z4, Canada.	simra@cs.ubc.ca; elinas@es.ubc.ca; little@cs.ubc.ca	Elinas, Pantelis/GPK-7403-2022					ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965; Bailey T, 2006, IEEE INT CONF ROBOT, P424, DOI 10.1109/ROBOT.2006.1641748; Barfoot TD, 2005, 2005 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P3076, DOI 10.1109/IROS.2005.1545444; Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451; Bolles R.C., 1981, P 7 INT JOINT C ART, V1981, P637; Davison AJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1403; Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381; Doucet A., 2001, SEQUENTIAL MONTE CAR; Doucet A., 2000, P 16 C UNC ART INT, P176, DOI DOI 10.1049/IET-SPR:20070075.; Eliazar AI, 2004, IEEE INT CONF ROBOT, P1314, DOI 10.1109/ROBOT.2004.1308006; Elinas P., 2005, P ROB SCI SYST JUN, P373; Elinas P, 2006, IEEE INT CONF ROBOT, P1564, DOI 10.1109/ROBOT.2006.1641930; Eustice R., 2005, P ROBOTICS SCI SYSTE; Eustice RM, 2005, IEEE INT CONF ROBOT, P2417; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Folkesson J, 2005, 2005 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P3383, DOI 10.1109/IROS.2005.1545493; Hahnel D, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P206; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Karlsson N, 2005, IEEE INT CONF ROBOT, P24; KWOK N, 2004, P IEEE RSJ C INT ROB, P736; Leonard J. J., 1991, Proceedings IROS '91. IEEE/RSJ International Workshop on Intelligent Robots and Systems '91. Intelligence for Mechanical Systems (Cat. No.91TH0375-6), P1442, DOI 10.1109/IROS.1991.174711; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043; Montemerlo M, 2003, IEEE INT CONF ROBOT, P1985, DOI 10.1109/ROBOT.2003.1241885; Montemerlo M, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P593; Montemerlo M., 2003, P INT JOINT C ART IN, P1151; MURPHY K, 1999, 1999 NEUR INF PROC S, P1015; PASKIN MA, 2003, P 18 INT JOINT C ART, P1157; Se S, 2002, INT J ROBOT RES, V21, P735, DOI 10.1177/027836402761412467; Sim R., 2005, IJCAI WORKSHOP REASO, V14, P9; Sim Robert, 2005, IEEE IROS WORKSH ROB, P16; Smith R., 1990, AUTONOMOUS ROBOT VEH, P167, DOI DOI 10.1007/978-1-4613-8997-2_14; Sola J, 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, Vols 1-4, P2751, DOI 10.1109/IROS.2005.1545392; Stachniss C, 2005, IEEE INT CONF ROBOT, P655; Thrun S, 2004, INT J ROBOT RES, V23, P693, DOI 10.1177/0278364904045479; Thrun S, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P859; ZHANG Z, 2001, MSRTR015	37	58	62	3	16	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2007	74	3					303	318		10.1007/s11263-006-0021-0	http://dx.doi.org/10.1007/s11263-006-0021-0			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	192YG		Green Submitted			2022-12-18	WOS:000248239400006
J	Shimizu, M; Okutomi, M				Shimizu, M; Okutomi, M			Sub-pixel estimation error cancellation on area-based matching	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						area-based image matching; similarity measure; sub-pixel estimation; pixel-locking effect; estimation error reduction	SUBPIXEL; ALGORITHMS; STEREO	Area-based image matching and sub-pixel displacement estimation using similarity measures are common methods that are used in various fields. Sub-pixel estimation using parabola fitting over three points with their similarity measures is also a common method to increase the matching resolution. However, few investigations or studies have explored the characteristics of this estimation. This study(1) analyzed sub-pixel estimation error using two different types of matching model. Our analysis demonstrates that the estimation contains a systematic error depending on image characteristics, the similarity function, and the fitting function. This error causes some inherently problematic phenomena such as the so-called pixel-locking effect, by which the estimated positions tend to be biased toward integer values. We also show that there are good combinations of the similarity functions and fitting functions. In addition, we propose a new algorithm to greatly reduce sub-pixel estimation error. This method is independent of the similarity measure and the fitting function. Moreover, it is quite simple to implement. The advantage of our novel method is confirmed through experiments using different types of images.	Tokyo Inst Technol, Grad Sch Sci & Engn, Meguro Ku, Tokyo 1528550, Japan	Tokyo Institute of Technology	Shimizu, M (corresponding author), Tokyo Inst Technol, Grad Sch Sci & Engn, Meguro Ku, 2-12-1 Ookayama, Tokyo 1528550, Japan.	mas@ok.ctrl.titech.ac.jp; mxo@ctrl.titech.ac.jp		Okutomi, Masatoshi/0000-0001-5787-0742				AGGARWAL JK, 1988, P IEEE, V76, P917, DOI 10.1109/5.5965; AGHAJAN HK, 1993, OPT ENG, V32, P828, DOI 10.1117/12.132375; Davis CQ, 1998, OPT ENG, V37, P1290, DOI 10.1117/1.601966; DAVIS CQ, 1995, IEEE INT S COMP VIS, P7; Driscoll WG., 1978, HDB OPTICS; DVORNYCHENKO VN, 1983, IEEE T PATTERN ANAL, V5, P206, DOI 10.1109/TPAMI.1983.4767373; FINCHAM A, 1999, P 3 INT WORKSH PIV S; Foroosh H, 2002, IEEE T IMAGE PROCESS, V11, P188, DOI 10.1109/83.988953; FRISCHHOLZ RW, 1993, EUR C MUN; Fusiello A, 2000, INT J PATTERN RECOGN, V14, P1053, DOI 10.1142/S0218001400000696; HART DP, 1998, P 9 INT S APPL LAS T; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L; KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690; LECORDIER B, 1999, P 3 INT WORKSH PIV S, P37; Lucas B.D., 1981, ITERATIVE IMAGE REGI, P674; Mitiche A, 2004, IEEE T IMAGE PROCESS, V13, P848, DOI 10.1109/TIP.2004.827235; Raffel M., 1998, EXP FLUID MECH; Schreier HW, 2000, OPT ENG, V39, P2915, DOI 10.1117/1.1314593; Shimizu M, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P1239, DOI 10.1109/ICDSP.2002.1028317; Shimizu M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P90, DOI 10.1109/ICCV.2001.937503; SHORTIS MR, 1994, P SOC PHOTO-OPT INS, V2350, P239, DOI 10.1117/12.189136; Szeliski R, 2002, LECT NOTES COMPUT SC, V2351, P525; TIAN Q, 1986, COMPUT VISION GRAPH, V35, P220, DOI 10.1016/0734-189X(86)90028-9; WEST GAW, 1990, P SOC PHOTO-OPT INS, V1395, P456; WESTERWEEL J, 1998, P 9 INT S APPL LAS T	27	58	64	0	16	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2005	63	3					207	224		10.1007/s11263-005-6878-5	http://dx.doi.org/10.1007/s11263-005-6878-5			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	928YR					2022-12-18	WOS:000229308500003
J	Ezzat, T; Poggio, T				Ezzat, T; Poggio, T			Visual speech synthesis by morphing visemes	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						computer vision; machine learning; facial modelling; facial animation; morphing; optical flow; speech synthesis; lip synchronization	OPTICAL-FLOW; PERFORMANCE	We present MikeTalk, a text-to-audiovisual speech synthesizer which converts input text into an audiovisual speech stream. MikeTalk is built using visemes, which are a small set of images spanning a large range of mouth shapes. The visemes are acquired from a recorded visual corpus of a human subject which is specifically designed to elicit one instantiation of each viseme. Using optical flow methods, correspondence from every viseme to every other viseme is computed automatically. By morphing along this correspondence, a smooth transition between viseme images may be generated. A complete visual utterance is constructed by concatenating viseme transitions. Finally, phoneme and timing information extracted from a text-to-speech synthesizer is exploited to determine which viseme transitions to use, and the rate at which the morphing process should occur. In this manner, we are able to synchronize the visual speech stream with the audio speech stream, and hence give the impression of a photorealistic talking face.	MIT, Artificial Intelligence Lab, Ctr Biol & Computat Learning, Cambridge, MA 02139 USA; MIT, Dept Brain & Cognit Sci, Ctr Biol & Computat Learning, Cambridge, MA 02139 USA	Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT)	Ezzat, T (corresponding author), MIT, Artificial Intelligence Lab, Ctr Biol & Computat Learning, Cambridge, MA 02139 USA.	tonebone@ai.mit.edu; tp@ai.mit.edu						Avidan S., 1997, VRST'97. ACM Symposium on Virtual Reality Software and Technology 1997, P103, DOI 10.1145/261135.261155; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; BEIER T, 1992, COMP GRAPH, V26, P35, DOI 10.1145/142920.134003; BERGEN JR, 1990, HIERARCHICAL MOTION; BEYMER D, 1993, 1431 MIT AI LAB; Black A. W., 1997, FESTIVAL SPEECH SYNT; BREGLER C, 1997, SIGGRAPH 97 P LOS AN; CHEN SE, 1993, SIGGRAPH 93, P279; Cohen M. M., 1993, Models and Techniques in Computer Animation, P139; COOTES TF, 1998, P EUR C COMP VIS FRE; Cosatto E, 1998, COMP ANIM CONF PROC, P103, DOI 10.1109/CA.1998.681914; EZZAT T, IN PRESS MORPHABLE M; FISHER CG, 1968, J SPEECH HEAR RES, V11, P796, DOI 10.1044/jshr.1104.796; Guenin BM, 1998, P IEEE SEMICOND THER, P55, DOI 10.1109/STHERM.1998.660387; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; JONES M, 1998, P INT C COMP VIS BOM; LEE SY, 1992, SIGGRAPH 92 P, P439; LEE Y, 1995, SIGGRAPH 95 C P, P55; LEGOFF B, 1996, P INT C SPOK LANG PR; Lim JS, 1990, 2 DIMENSIONAL SIGNAL; MONTGOMERY AA, 1983, J ACOUST SOC AM, V73, P2134, DOI 10.1121/1.389537; MOULINES E, 1990, SPEECH COMMUN, V9, P453, DOI 10.1016/0167-6393(90)90021-Z; Olive J. P., 1993, ACOUSTICS AM ENGLISH; OWENS E, 1985, J SPEECH HEAR RES, V28, P381, DOI 10.1044/jshr.2803.381; Parke F. I., 1974, THESIS U UTAH; PEARCE A, 1986, GRAPHICS INTERFACE 8, P136; PIGHIN F, 1998, SIGGRAPH 98 P ORL FL; SCOTT KC, 1994, P 5 AUSTR C SPEECH S, V2, P620; SEITZ SM, 1996, SIGGRAPH, P21; WATERS K, 1993, DECFACE AUTOMATIC LI; WATSON S, 1997, ADV MORPHING ALGORIT; Wolberg G, 1990, DIGITAL IMAGE WARPIN	33	58	68	0	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2000	38	1					45	57		10.1023/A:1008166717597	http://dx.doi.org/10.1023/A:1008166717597			13	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	342GH					2022-12-18	WOS:000088636500005
J	Williams, LR; Thornber, KK				Williams, LR; Thornber, KK			A comparison of measures for detecting natural shapes in cluttered backgrounds	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						contours; saliency; closure; grouping	COMPLETION; CURVES	We propose a new measure of perceptual saliency and quantitatively compare its ability to detect natural shapes in cluttered backgrounds to five previously proposed measures. As defined in the new measure, the saliency of an edge is the fraction of closed random walks which contain that edge. The transition-probability matrix defining the random walk between edges is based on a distribution of natural shapes modeled by a stochastic motion. Each of the saliency measures in our comparison is a function of a set of affinity values assigned to pairs of edges. Although the authors of each measure define the affinity between a pair of edges somewhat differently, all incorporate the Gestalt principles of good-continuation and proximity in some form. In order to make the comparison meaningful, we use a single definition of affinity and focus instead on the performance of the different functions for combining affinity values. The primary performance criterion is accuracy. We compute false-positive rates in classifying edges as signal or noise for a large set of test figures. In almost every case, the new measure significantly outperforms previous measures.	Univ New Mexico, Dept Comp Sci, Albuquerque, NM 87131 USA; NEC Res Inst, Princeton, NJ 08540 USA	University of New Mexico; NEC Corporation	Williams, LR (corresponding author), Univ New Mexico, Dept Comp Sci, Albuquerque, NM 87131 USA.							Alter TD, 1996, PROC CVPR IEEE, P13, DOI 10.1109/CVPR.1996.517047; FIELD DJ, 1993, VISION RES, V33, P173, DOI 10.1016/0042-6989(93)90156-Q; GROSSBERG S, 1985, PSYCHOL REV, V92, P173, DOI 10.1037/0033-295X.92.2.173; Guy G, 1996, INT J COMPUT VISION, V20, P113, DOI 10.1007/BF00144119; HERAULT L, 1993, IEEE T PATTERN ANAL, V15, P899, DOI 10.1109/34.232076; HORN BKP, 1981, 612 MIT AI LAB; KOVACS I, 1993, P NATL ACAD SCI USA, V90, P7495, DOI 10.1073/pnas.90.16.7495; MONTANARI U, 1971, COMMUN ACM, V14, P335, DOI 10.1145/362588.362594; MUMFORD D., 1993, ALGEBRAIC GEOMETRY I; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; PERONA P, 1998, P 5 EUR C COMP VIS E; Press WH, 1988, NUMERICAL RECIPES C; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; Sarkar S, 1996, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.1996.517115; Sharon E, 1997, PROC CVPR IEEE, P884, DOI 10.1109/CVPR.1997.609432; SHASHUA A, 1988, 2 INT C COMP VIS ICC; Thornber KK, 1996, BIOL CYBERN, V75, P141, DOI 10.1007/s004220050282; ULLMAN S, 1976, BIOL CYBERN, V21, P1; WILLIAMS L, 1997, NEURAL COMPUT, V9, P849; WILLIAMS LR, 1997, P 7 INT C COMP AN IM; YEN S, 1996, INVEST OPHTHALMOL, V37, P5293	21	58	58	0	6	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	1999	34	2-3					81	96		10.1023/A:1008187804026	http://dx.doi.org/10.1023/A:1008187804026			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	265NF					2022-12-18	WOS:000084249700002
J	Chrysos, GG; Antonakos, E; Snape, P; Asthana, A; Zafeiriou, S				Chrysos, Grigorios G.; Antonakos, Epameinondas; Snape, Patrick; Asthana, Akshay; Zafeiriou, Stefanos			A Comprehensive Performance Evaluation of Deformable Face Tracking "In-the-Wild"	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Deformable face tracking; Face detection; Model free tracking; Facial landmark localisation; Long-term tracking	ACTIVE APPEARANCE MODELS; 3-D MOTION ESTIMATION; VISUAL TRACKING; OBJECT TRACKING; IMAGE ALIGNMENT; REGISTRATION; POSE; CLASSIFICATION; RECOGNITION; REDUCTION	Recently, technologies such as face detection, facial landmark localisation and face recognition and verification have matured enough to provide effective and efficient solutions for imagery captured under arbitrary conditions (referred to as "in-the-wild"). This is partially attributed to the fact that comprehensive "in-the-wild" benchmarks have been developed for face detection, landmark localisation and recognition/verification. A very important technology that has not been thoroughly evaluated yet is deformable face tracking "in-the-wild". Until now, the performance has mainly been assessed qualitatively by visually assessing the result of a deformable face tracking technology on short videos. In this paper, we perform the first, to the best of our knowledge, thorough evaluation of state-of-the-art deformable face tracking pipelines using the recently introduced 300 VW benchmark. We evaluate many different architectures focusing mainly on the task of on-line deformable face tracking. In particular, we compare the following general strategies: (a) generic face detection plus generic facial landmark localisation, (b) generic model free tracking plus generic facial landmark localisation, as well as (c) hybrid approaches using state-of-the-art face detection, model free tracking and facial landmark localisation technologies. Our evaluation reveals future avenues for further research on the topic.	[Chrysos, Grigorios G.; Antonakos, Epameinondas; Snape, Patrick; Zafeiriou, Stefanos] Imperial Coll London, Dept Comp, 180 Queens Gate, London SW7 2AZ, England; [Asthana, Akshay] Seeing Machines Ltd, Level 1,11 Lonsdale St, Braddon, ACT 2612, Australia; [Zafeiriou, Stefanos] Univ Oulu, Ctr Machine Vis & Signal Anal, Oulu, Finland	Imperial College London; University of Oulu	Chrysos, GG (corresponding author), Imperial Coll London, Dept Comp, 180 Queens Gate, London SW7 2AZ, England.	g.chrysos@imperial.ac.uk; e.antonakos@imperial.ac.uk; p.snape@imperial.ac.uk; akshay.asthana@seeingmachines.com; s.zafeiriou@imperial.ac.uk	Chrysos, Grigorios/ABE-2026-2021	Chrysos, Grigorios/0000-0002-0650-1856; Asthana, Akshay/0000-0001-6871-346X	EPSRC DTA award at Imperial College London; EPSRC project ADAMANT [EP/L026813/1]; European Community [688520]; FiDiPro program of Tekes [1849/31/2015]; EPSRC Programme Grant FACER2VM [EP/N007743/1]; EPSRC [EP/N007743/1, EP/J017787/1, EP/H016988/1, EP/L026813/1] Funding Source: UKRI; Engineering and Physical Sciences Research Council [EP/L026813/1, EP/H016988/1, EP/J017787/1, EP/N007743/1] Funding Source: researchfish	EPSRC DTA award at Imperial College London(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC project ADAMANT(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); European Community(European Commission); FiDiPro program of Tekes; EPSRC Programme Grant FACER2VM(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	GC was supported by EPSRC DTA award at Imperial College London, as well as from the EPSRC project ADAMANT (EP/L026813/1). The work of PS and EA was funded by the European Community Horizon 2020 [H2020/2014-2020] under Grant Agreement No. 688520 (TeSLA). The work of S. Zafeiriou was funded by the FiDiPro program of Tekes (Project No. 1849/31/2015), as well as from EPSRC Programme Grant FACER2VM (EP/N007743/1).	Adam A., 2006, IEEE C COMP VIS PATT; Alabort-i-Medina J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P679, DOI 10.1145/2647868.2654890; Alabort-i-Medina J, 2015, PROC CVPR IEEE, P3679, DOI 10.1109/CVPR.2015.7298991; Alabort-i-Medina J, 2014, PROC CVPR IEEE, P3438, DOI 10.1109/CVPR.2014.439; Allen J. G., 2004, P PAN SYDN AR WORKSH, V100, P3; Amberg B, 2011, EDITING FACES VIDEOS; Amberg B, 2009, PROC CVPR IEEE, P1714, DOI 10.1109/CVPRW.2009.5206788; [Anonymous], 2015, ARXIV150200046; [Anonymous], 2014, ARXIV14101037; Antonakos E, 2015, PROC CVPR IEEE, P5435, DOI 10.1109/CVPR.2015.7299182; Antonakos E, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2431445; Antonakos E, 2014, IEEE IMAGE PROC, P224, DOI 10.1109/ICIP.2014.7025044; ARANDJELOVIC R, 2012, PROC CVPR IEEE, P2911, DOI DOI 10.1109/CVPR.2012.6248018; Asthana A, 2015, IEEE T PATTERN ANAL, V37, P1312, DOI 10.1109/TPAMI.2014.2362142; Asthana A, 2014, PROC CVPR IEEE, P1859, DOI 10.1109/CVPR.2014.240; Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Balan A. O., 2006, 2006 IEEE COMPUTER S, V1, P758; Barbu A, 2014, ARXIV14043596; Basu S., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P611, DOI 10.1109/ICPR.1996.547019; Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; Belhumeur PN, 2013, IEEE T PATTERN ANAL, V35, P2930, DOI 10.1109/TPAMI.2013.23; Bertinetto L., 2016, IEEE P INT C COMP VI; Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56; Bischof H., 2006, BMVC, P47; Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436; BLACK MJ, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P374, DOI 10.1109/ICCV.1995.466915; Bourlai T, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY (HST), P54, DOI 10.1109/THS.2013.6698976; BOZDAGI G, 1994, IEEE T CIRC SYST VID, V4, P246, DOI 10.1109/76.305870; Bradski G., 2000, DOBBS J SOFTWARE TOO, V3; Bradski GR, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P214, DOI 10.1109/ACV.1998.732882; Burgos-Artizzu X. P., 2013, IEEE P INT C COMP VI; Cai Q, 2010, LECT NOTES COMPUT SC, V6313, P229; Campbell K. L., 2016, 2 STRATEGIC HIGHWAY; Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3; Chen D, 2014, LECT NOTES COMPUT SC, V8694, P109, DOI 10.1007/978-3-319-10599-4_8; Chrysos G., 2015, IEEE P INT C COMP VI; Colmenarez A., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P657, DOI 10.1109/ICIP.1999.821717; Comaniciu D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1197, DOI 10.1109/ICCV.1999.790416; Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761; Cootes T. F., 2016, TALKING FACE VIDEO; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Crowley JL, 1997, PROC CVPR IEEE, P640, DOI 10.1109/CVPR.1997.609393; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Danelljan M, 2014, BRIT MACHINE VISIO, P1; Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29; Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490; De la Torre F, 2012, IEEE T PATTERN ANAL, V34, P1041, DOI 10.1109/TPAMI.2011.184; DeCarlo D, 2000, INT J COMPUT VISION, V38, P99, DOI 10.1023/A:1008122917811; Dedeoglu G, 2007, IEEE T PATTERN ANAL, V29, P807, DOI 10.1109/TPAMI.2007.1054; Del Moral P., 1996, MARKOV PROCESSES REL, V2, P555; Dollar P, 2009, BRIT MACHINE VISION, DOI [10.5244/C.23.91, DOI 10.5244/C.23.91]; Dollar P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094; Dornaika F, 2004, IEEE T SYST MAN CY B, V34, P1838, DOI 10.1109/TSMCB.2004.829135; Dubout C, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.28; Dubout C, 2012, LECT NOTES COMPUT SC, V7574, P301, DOI 10.1007/978-3-642-33712-3_22; Essa I., 1996, Proceedings. Computer Animation '96, P68, DOI 10.1109/CA.1996.540489; Essa I. A., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P36, DOI 10.1109/MNRAO.1994.346257; Essa IA, 1997, IEEE T PATTERN ANAL, V19, P757, DOI 10.1109/34.598232; ESSA IA, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P76, DOI 10.1109/CVPR.1994.323813; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Gao J, 2014, LECT NOTES COMPUT SC, V8691, P188, DOI 10.1007/978-3-319-10578-9_13; Ghiasi G, 2014, PROC CVPR IEEE, P1899, DOI 10.1109/CVPR.2014.306; Gokturk S. B., 2004, IEEE P INT C COMP VI, V2, P2; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Hare S, 2012, PROC CVPR IEEE, P1894, DOI 10.1109/CVPR.2012.6247889; Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251; Heisele B, 2003, PATTERN RECOGN, V36, P2007, DOI 10.1016/S0031-3203(03)00062-1; Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390; Hu Peiyun, 2016, ARXIV161204402; Huang Gary B., 2007, 0749 U MASS, P7; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Isard M., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P343, DOI 10.1007/BFb0015549; Jain V., 2010, UMCS2010009; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; Jianguo Li, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P2183, DOI 10.1109/ICCVW.2011.6130518; Jun B, 2013, IEEE T PATTERN ANAL, V35, P1423, DOI 10.1109/TPAMI.2012.219; Jurie F, 1999, PATTERN RECOGN, V32, P865, DOI 10.1016/S0031-3203(98)00096-X; Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239; Kalal Z, 2010, IEEE IMAGE PROC, P3789, DOI 10.1109/ICIP.2010.5653525; Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231; Kalman RE., 1960, T ASME J BASIC ENG, V82, P35, DOI [10.1115/1.3662552, DOI 10.1115/1.3662552]; Kawulok M., 2016, ADV FACE DETECTION F, P189, DOI DOI 10.1007/978-3-319-25958-1_8; Kazemi V., 2014, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2014.241; Kim M, 2008, PROC CVPR IEEE, P1787; King DE, 2009, J MACH LEARN RES, V10, P1755; KLARE BF, 2015, PROC CVPR IEEE, P1931, DOI DOI 10.1109/CVPR.2015.7298803; Koelstra S, 2010, IEEE T PATTERN ANAL, V32, P1940, DOI 10.1109/TPAMI.2010.50; Koestinger M., 2011, ICCV WORKSH, DOI [10.1109/ICCVW.2011.6130513, DOI 10.1109/ICCVW.2011.6130513]; Kokiopoulou E, 2011, NUMER LINEAR ALGEBR, V18, P565, DOI 10.1002/nla.743; Kostinger M., 2012, DAGM 2012 CVAW WORKS; Koukis V, 2013, IEEE INTERNET COMPUT, V17, P67, DOI 10.1109/MIC.2013.43; Kristan M., 2019, 6 VISUAL OBJECT TRAC; Kristan M., 2013, IEEE PROCEEDINGS OF; Kristan M, 2016, IEEE T PATTERN ANAL, V38, P2137, DOI 10.1109/TPAMI.2016.2516982; Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79; Kumar V, 2015, IEEE I CONF COMP VIS, P1994, DOI 10.1109/ICCV.2015.231; La Cascia M, 2000, IEEE T PATTERN ANAL, V22, P322, DOI 10.1109/34.845375; LANITIS A, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P368, DOI 10.1109/ICCV.1995.466919; Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49; Levy A, 2000, IEEE T IMAGE PROCESS, V9, P1371, DOI 10.1109/83.855432; Li A., 2016, NUS PRO TRACKING CHA; Li AN, 2016, IEEE T PATTERN ANAL, V38, P335, DOI 10.1109/TPAMI.2015.2417577; Li HX, 2014, PROC CVPR IEEE, P1843, DOI 10.1109/CVPR.2014.238; Li HX, 2013, IEEE I CONF COMP VIS, P793, DOI 10.1109/ICCV.2013.103; LI HB, 1993, IEEE T PATTERN ANAL, V15, P545, DOI 10.1109/34.216724; Li JG, 2013, PROC CVPR IEEE, P3468, DOI 10.1109/CVPR.2013.445; Li SZ, 2002, LECT NOTES COMPUT SC, V2353, P67; Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039; Li Y, 2015, PROC CVPR IEEE, P353, DOI 10.1109/CVPR.2015.7298632; Liao SC, 2016, IEEE T PATTERN ANAL, V38, P211, DOI 10.1109/TPAMI.2015.2448075; Liwicki S., 2012, P AS C COMP VIS, P162; Liwicki S., 2016, ANNOTATED FACE VIDEO; Liwicki S, 2015, IEEE T IMAGE PROCESS, V24, P2955, DOI 10.1109/TIP.2015.2428052; Liwicki S, 2013, INT J COMPUT VISION, V101, P498, DOI 10.1007/s11263-012-0558-z; Liwicki S, 2012, IEEE T NEUR NET LEAR, V23, P1624, DOI 10.1109/TNNLS.2012.2208654; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177; Malciu M., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P169, DOI 10.1109/AFGR.2000.840630; Mathias M, 2014, LECT NOTES COMPUT SC, V8692, P720, DOI 10.1007/978-3-319-10593-2_47; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16; Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66; Mita T, 2005, IEEE I CONF COMP VIS, P1619; NAM H, 2016, PROC CVPR IEEE, P4293, DOI DOI 10.1109/CVPR.2016.465; Nebehay G., 2015, IEEE P INT C COMP VI; Ning J., 2016, IEEE P INT C COMP VI; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Oliver N, 1997, PROC CVPR IEEE, P123, DOI 10.1109/CVPR.1997.609309; Orozco J, 2013, IMAGE VISION COMPUT, V31, P322, DOI 10.1016/j.imavis.2013.02.001; Osadchy M, 2007, J MACH LEARN RES, V8, P1197; Papandreou G, 2008, PROC CVPR IEEE, P1539; Parkhi Omkar M., 2015, BRIT MACH VIS C; Patras I, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P97, DOI 10.1109/AFGR.2004.1301515; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282; Perez F, 2007, COMPUT SCI ENG, V9, P21, DOI 10.1109/MCSE.2007.53; Pernici F, 2014, IEEE T PATTERN ANAL, V36, P2538, DOI 10.1109/TPAMI.2013.250; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Pighin F., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P143, DOI 10.1109/ICCV.1999.791210; Poling B, 2014, PROC CVPR IEEE, P3454, DOI 10.1109/CVPR.2014.441; Qi Y., 2016, IEEE P INT C COMP VI; Qian RJ, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P131, DOI 10.1109/ICIP.1998.723443; Rajamanoharan G., 2015, IEEE P INT C COMP VI; Ranjan Rajeev, 2017, Proceedings of the Indian National Science Academy Part B Biological Sciences, V87, P377, DOI 10.1007/s40011-015-0618-6; Ratsch M, 2004, LECT NOTES COMPUT SC, V3175, P62; Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218; Romdhani S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P695, DOI 10.1109/ICCV.2001.937694; Ross D., 2015, DUDEK FACE SEQUENCE; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284; Sagonas C., 2015, IMAGE VISION COMPUTI; Sagonas C, 2014, PROC CVPR IEEE, P1789, DOI 10.1109/CVPR.2014.231; Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59; Sagonas C, 2013, IEEE COMPUT SOC CONF, P896, DOI 10.1109/CVPRW.2013.132; Sakai T., 1972, 1st USA-Japan Computer Conference Proceedings, P55; Salti S, 2012, IEEE T IMAGE PROCESS, V21, P4334, DOI 10.1109/TIP.2012.2206035; Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4; Schneiderman H, 2004, INT J COMPUT VISION, V56, P151, DOI 10.1023/B:VISI.0000011202.85607.00; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Schwerdt K., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P90, DOI 10.1109/AFGR.2000.840617; Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891; Shen J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1003, DOI 10.1109/ICCVW.2015.132; Shen XH, 2013, PROC CVPR IEEE, P3460, DOI 10.1109/CVPR.2013.444; Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230; Snape P., 2015, IEEE P INT C COMP VI; Sobottka K, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P483, DOI 10.1109/ICIP.1996.560536; Stern H, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P249, DOI 10.1109/AFGR.2002.1004162; Sung J, 2008, INT J COMPUT VISION, V80, P260, DOI 10.1007/s11263-007-0125-1; Sung J, 2009, PATTERN RECOGN LETT, V30, P359, DOI 10.1016/j.patrec.2008.11.006; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Tao H, 1998, PROC CVPR IEEE, P735, DOI 10.1109/CVPR.1998.698685; Toyama K., 1998, LOOK MA HANDS HANDS; Tresadern PA, 2012, INT J COMPUT VISION, V96, P280, DOI 10.1007/s11263-011-0464-9; Tzimiropoulos Georgios, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P650, DOI 10.1007/978-3-642-37431-9_50; Tzimiropoulos G, 2015, PROC CVPR IEEE, P3659, DOI 10.1109/CVPR.2015.7298989; Tzimiropoulos G, 2014, IEEE T INF FOREN SEC, V9, P2024, DOI 10.1109/TIFS.2014.2361018; Tzimiropoulos G, 2014, PROC CVPR IEEE, P1851, DOI 10.1109/CVPR.2014.239; Tzimiropoulos G, 2013, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2013.79; Uricar M., 2015, IEEE P INT C COMP VI; Vadakkepat P, 2008, IEEE T IND ELECTRON, V55, P1385, DOI 10.1109/TIE.2007.903993; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang P, 2004, INT C PATT RECOG, P179, DOI 10.1109/ICPR.2004.1333733; Wang XM, 2015, IEEE I CONF COMP VIS, P4337, DOI 10.1109/ICCV.2015.493; Wei X., 2004, COMP VIS PATT REC WO, P71; Weise T., 2011, ACM T GRAPHIC, V30, P77; Wolf L., 2011, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2011.5995566; Wu B, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P79; Wu Y., 2013, IEEE P INT C COMP VI; Wu Y., 2015, IEEE P INT C COMP VI; Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226; Wu Y, 2012, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2012.6247878; Xiao J, 2004, PROC CVPR IEEE, P535; Xiao S., 2015, IEEE P INT C COMP VI; Xiao ZY, 2014, IEEE T CIRC SYST VID, V24, P1301, DOI 10.1109/TCSVT.2013.2291355; Xiong XH, 2015, PROC CVPR IEEE, P2664, DOI 10.1109/CVPR.2015.7298882; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Yacoob Y, 1996, IEEE T PATTERN ANAL, V18, P636, DOI 10.1109/34.506414; Yan J, 2013, SCI WORLD J, DOI 10.1155/2013/458106; Yan JJ, 2014, PROC CVPR IEEE, P2497, DOI 10.1109/CVPR.2014.320; Yang B., 2014, P IEEE INT JOINT C B, P1, DOI [10.1109/BTAS.2014.6996284, DOI 10.1109/BTAS.2014.6996284]; Yang F, 2014, IEEE T IMAGE PROCESS, V23, P1639, DOI 10.1109/TIP.2014.2300823; Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024; Yang J., 2015, IEEE P INT C COMP VI; Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883; Yang S, 2015, IEEE I CONF COMP VIS, P3676, DOI 10.1109/ICCV.2015.419; Yao R, 2013, PROC CVPR IEEE, P2363, DOI 10.1109/CVPR.2013.306; Yongmin Li, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P300, DOI 10.1109/AFGR.2000.840650; Zafeiriou S, 2015, COMPUT VIS IMAGE UND, V138, P1, DOI 10.1016/j.cviu.2015.03.015; Zhang C, 2014, IEEE WINT CONF APPL, P1036, DOI 10.1109/WACV.2014.6835990; Zhang C, 2010, C ELECT INSUL DIEL P; Zhang J. Y., 2014, MOD AGRIC SCI TECHNO, V2014, P188; Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9; Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808; Zhang L, 2014, IEEE T PATTERN ANAL, V36, P756, DOI 10.1109/TPAMI.2013.221; Zhang L, 2013, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2013.240; Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908; Zhang W, 2008, LECT NOTES COMPUT SC, V5303, P720, DOI 10.1007/978-3-540-88688-4_53; Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360; Zhu SZ, 2015, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2015.7299134; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014	227	57	60	2	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	2018	126	2-4			SI		198	232		10.1007/s11263-017-0999-5	http://dx.doi.org/10.1007/s11263-017-0999-5			35	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	FW8XA	31983805	Green Published, hybrid, Green Submitted			2022-12-18	WOS:000425619100005
J	Zhu, LC; Xu, ZW; Yang, Y; Hauptmann, AG				Zhu, Linchao; Xu, Zhongwen; Yang, Yi; Hauptmann, Alexander G.			Uncovering the Temporal Context for Video Question Answering	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Video sequence modeling; Video question answering; Video prediction; Cross-media		In this work, we introduce Video Question Answering in the temporal domain to infer the past, describe the present and predict the future. We present an encoder-decoder approach using Recurrent Neural Networks to learn the temporal structures of videos and introduce a dual-channel ranking loss to answer multiple-choice questions. We explore approaches for finer understanding of video content using the question form of "fill-in-the-blank", and collect our Video Context QA dataset consisting of 109,895 video clips with a total duration of more than 1000 h from existing TACoS, MPII-MD and MEDTest 14 datasets. In addition, 390,744 corresponding questions are generated from annotations. Extensive experiments demonstrate that our approach significantly outperforms the compared baselines.	[Zhu, Linchao; Xu, Zhongwen; Yang, Yi] Univ Technol Sydney, CAI, Sydney, NSW, Australia; [Hauptmann, Alexander G.] Carnegie Mellon Univ, SCS, Pittsburgh, PA 15213 USA	University of Technology Sydney; Carnegie Mellon University	Yang, Y (corresponding author), Univ Technol Sydney, CAI, Sydney, NSW, Australia.	yee.i.yang@gmail.com	yang, yang/GWB-9426-2022; yang, yang/HGT-7999-2022; Zhu, Linchao/AAE-6700-2020; Yang, Yi/B-9273-2017; yang, yang/GVT-5210-2022	Zhu, Linchao/0000-0002-4093-7557; Yang, Yi/0000-0002-0512-880X; 	Data to Decisions Cooperative Research Centre; Google Faculty Award; Australian Government Research Training Program Scholarship; NVIDIA Corporation	Data to Decisions Cooperative Research Centre; Google Faculty Award(Google Incorporated); Australian Government Research Training Program Scholarship(Australian GovernmentDepartment of Industry, Innovation and Science); NVIDIA Corporation	Our work is partially supported by the Data to Decisions Cooperative Research Centre (www.d2dcrc.com.au), Google Faculty Award, and an Australian Government Research Training Program Scholarship. We gratefully acknowledge the support of NVIDIA Corporation with the donation of the TITAN X (Pascal) GPU used for this research.	Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52; Cho K., 2015, P C EMP METH NAT LAN; Chung J., 2014, ARXIV14123555; Collobert R., 2011, C NEUR INF PROC SYST; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510; Dzmitry Bahdanau, 2016, Arxiv, DOI arXiv:1409.0473; Elliott D., 2014, P ANN M ASS COMP LIN; Frome Andrea, 2013, NEURIPS; Gao H., 2015, C NEUR INF PROC SYST; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Jabri A, 2016, LECT NOTES COMPUT SC, V9912, P727, DOI 10.1007/978-3-319-46484-8_44; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Kiros R., 2015, C NEUR INF PROC SYST; Klein D., 2003, P ANN M ASS COMP LIN; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kulkarni G., 2011, C COMP VIS PATT REC; Lebret R., 2015, INT C MACH LEARN ICM; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin X., 2015, C COMP VIS PATT REC; Malinowski M., 2015, INT C COMP VIS ICCV; Malinowski M., 2014, C NEUR INF PROC SYST; Mao J., 2015, C COMP VIS PATT REC; MED, 2014, TRECV MED 14; Mikolov T., 2013, ARXIV; Ordonez V, 2016, INT J COMPUT VISION, V119, P46, DOI 10.1007/s11263-015-0840-y; Pan P., 2016, C COMP VIS PATT REC; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Regneri M., 2013, TACL, V1, P25, DOI DOI 10.1162/TACL_A_00207; Ren M., 2015, C NEUR INF PROC SYST; Rohrbach A., 2015, C COMP VIS PATT REC; Rohrbach M., 2013, INT C COMP VIS ICCV; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Simonyan Karen, 2014, ARXIV14062199, DOI DOI 10.1002/14651858.CD001941.PUB3; Srivastava N, 2015, PR MACH LEARN RES, V37, P843; Sutskever Ilya, 2014, C NEUR INF PROC SYST; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Tapaswi M, 2016, PROC CVPR IEEE, P4631, DOI 10.1109/CVPR.2016.501; Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; VEDANTAM R, 2015, PROC CVPR IEEE, P4566, DOI DOI 10.1109/CVPR.2015.7299087; Venugopalan S., 2015, INT C COMP VIS ICCV; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Vondrick C., 2015, C COMP VIS PATT REC; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Wu Q., 2016, C COMP VIS PATT REC; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Xu ZW, 2015, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2015.7298789; Yan Y, 2016, IEEE T MULTIMEDIA, V18, P2494, DOI 10.1109/TMM.2016.2602938; Yang Y., 2009, P 17 ACM INT C MULTI, V17, P175, DOI DOI 10.1145/1631272.1631298; Yao L., 2015, INT C COMP VIS ICCV; Young P., 2014, P TACL, V2, P67, DOI 10.1162/tacl_a_00166; Yu H., 2013, P ANN M ASS COMP LIN; Yu LF, 2015, IEEE I CONF COMP VIS, P711, DOI 10.1109/ICCV.2015.88; Zaremba Wojciech, 2014, ABS14092329 CORR; Zhu YX, 2016, PROC CVPR IEEE, P3823, DOI 10.1109/CVPR.2016.415; Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11	64	57	57	1	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2017	124	3					409	421		10.1007/s11263-017-1033-7	http://dx.doi.org/10.1007/s11263-017-1033-7			13	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	FE1ER		Green Submitted			2022-12-18	WOS:000407961700008
J	Sarfraz, MS; Stiefelhagen, R				Sarfraz, M. Saquib; Stiefelhagen, Rainer			Deep Perceptual Mapping for Cross-Modal Face Recognition	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Heterogeneous face recognition; Visible face recognition; Night-time surveillance		Cross modal face matching between the thermal and visible spectrum is a much desired capability for night-time surveillance and security applications. Due to a very large modality gap, thermal-to-visible face recognition is one of the most challenging face matching problem. In this paper, we present an approach to bridge this modality gap by a significant margin. Our approach captures the highly non-linear relationship between the two modalities by using a deep neural network. Our model attempts to learn a non-linear mapping from the visible to the thermal spectrum while preserving the identity information. We show substantive performance improvement on three difficult thermal-visible face datasets. The presented approach improves the state-of-the-art by more than 10 % on the UND-X1 dataset and by more than 15-30 % on the NVESD dataset in terms of Rank-1 identification. Our method bridges the drop in performance due to the modality gap by more than 40 %.	[Sarfraz, M. Saquib; Stiefelhagen, Rainer] KIT, Inst Anthropomat & Robot, Karlsruhe, Germany	Helmholtz Association; Karlsruhe Institute of Technology	Sarfraz, MS (corresponding author), KIT, Inst Anthropomat & Robot, Karlsruhe, Germany.	saquib.sarfraz@kit.edu						Bourlai T., 2012, SPIE DEFENSE SECURIT; Byrd K. A., 2013, P SOC PHOTO-OPT INS, V8734, P8734; Chen CJ, 2016, PATTERN RECOGN LETT, V72, P25, DOI 10.1016/j.patrec.2015.06.021; Chen X, 2005, COMPUT VIS IMAGE UND, V99, P332, DOI 10.1016/j.cviu.2005.03.001; Choi J., 2012, SPIE DEFENSE SECURIT; Espinosa-Duro V, 2013, COGN COMPUT, V5, P119, DOI 10.1007/s12559-012-9163-2; Ganin Y., 2014, ARXIV14097495; Glorot X., 2010, PROC MACH LEARN RES, P249; Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242; Hu S., 2014, SPIE DEFENSE SECURIT; Hu SW, 2015, J OPT SOC AM A, V32, P431, DOI 10.1364/JOSAA.32.000431; Klare B., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1513, DOI 10.1109/ICPR.2010.374; Klare BF, 2013, IEEE T PATTERN ANAL, V35, P1410, DOI 10.1109/TPAMI.2012.229; Lei Z, 2009, PROC CVPR IEEE, P1123, DOI 10.1109/CVPRW.2009.5206860; Li J, 2008, IEEE IMAGE PROC, P465, DOI 10.1109/ICIP.2008.4711792; Li SZ, 2007, IEEE T PATTERN ANAL, V29, P627, DOI 10.1109/TPAMI.2007.1014; Liao SC, 2009, LECT NOTES COMPUT SC, V5558, P209, DOI 10.1007/978-3-642-01793-3_22; Mostafa E, 2013, COMPUT VIS IMAGE UND, V117, P1689, DOI 10.1016/j.cviu.2013.07.010; Nicolo F, 2012, IEEE T INF FOREN SEC, V7, P1717, DOI 10.1109/TIFS.2012.2213813; Parkhi Omkar M., 2015, BRIT MACH VIS C; Riggan BS, 2016, IEEE WINT CONF APPL; Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2; Ross T. B. N. K. A., 2010, CROSS SPECTRAL FACE; Sarfraz M. S., 2015, P BRIT MACHINE VISIO; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Socolinsky D. A., 2002, TECH REP; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Yi D, 2007, LECT NOTES COMPUT SC, V4642, P523; Zhou HL, 2014, IEEE T HUM-MACH SYST, V44, P701, DOI 10.1109/THMS.2014.2340578	29	57	59	0	27	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2017	122	3			SI		426	438		10.1007/s11263-016-0933-2	http://dx.doi.org/10.1007/s11263-016-0933-2			13	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	ES7OH		Green Submitted			2022-12-18	WOS:000399739200003
J	Tolias, G; Avrithis, Y; Jegou, H				Tolias, Giorgos; Avrithis, Yannis; Jegou, Herve			Image Search with Selective Match Kernels: Aggregation Across Single and Multiple Images	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Image retrieval; Match kernels; Feature aggregation; Feature augmentation; Query expansion; Place recognition		This paper considers a family of metrics to compare images based on their local descriptors. It encompasses the vector or locally aggregated descriptors descriptor and matching techniques such as hamming embedding. Making the bridge between these approaches leads us to propose a match kernel that takes the best of existing techniques by combining an aggregation procedure with a selective match kernel. The representation underpinning this kernel is approximated, providing a large scale image search both precise and scalable, as shown by our experiments on several benchmarks. We show that the same aggregation procedure, originally applied per image, can effectively operate on groups of similar features found across multiple images. This method implicitly performs feature set augmentation, while enjoying savings in memory requirements at the same time. Finally, the proposed method is shown effective for place recognition, outperforming state of the art methods on a large scale landmark recognition benchmark.	[Tolias, Giorgos; Jegou, Herve] INRIA, Rennes, France; [Avrithis, Yannis] NTUA, Athens, Greece	Inria; National Technical University of Athens	Tolias, G (corresponding author), INRIA, Rennes, France.	giorgos.tolias@inria.fr	Tolias, Giorgos/O-9939-2017	Tolias, Giorgos/0000-0002-9570-3870	ERC Grant VIAMASS [336054]; ANR project Fire-ID	ERC Grant VIAMASS; ANR project Fire-ID(French National Research Agency (ANR))	This work was supported by ERC Grant VIAMASS No. 336054 and ANR project Fire-ID.	Arandjelovi<prime>c Relja, 2014, ACCV; Arandjelovic R., 2013, CVPR; Arandjelovic R, 2012, CVPR; Avrithis Y., 2010, ACMMM; Bo L., 2009, NIPS; Boureau Y, 2010, CVPR; Charikar M., 2002, ACM S THEOR COMP; Chen D., 2011, CVPR; Chum O., 2007, ICCV; Chum O., 2011, CVPR; Csurka G., 2004, ECCV WORKSHOPS; Danfeng Q., 2011, CVPR; Delhumeau J., 2013, ACM MULTIMEDIA; Delvinioti A., 2014, VISAPP; Hays J., 2008, CVPR; Jain M., 2012, ICMR; Jain M., 2011, ACM MULTIMEDIA; Jegou H., 2009, CVPR; Jegou H., 2010, CVPR; Jegou H., 2008, ECCV; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Ji RR, 2012, INT J COMPUT VISION, V96, P290, DOI 10.1007/s11263-011-0472-9; Johns E., 2011, ICCV; Kalantidis Y., 2014, CVPR; Knopp J., 2010, ECCV; Li Y., 2009, ICCV; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mikulik A, 2013, INT J COMPUT VISION, V103, P163, DOI 10.1007/s11263-012-0600-1; Nister D, 2006, IEEE COMP SOC C COMP, V2, P2161, DOI DOI 10.1109/CVPR.2006.264; Perdoch M., 2009, CVPR; Perronnin F., 2010, CVPR; Perronnin F., 2010, ECCV; Perronnin F., 2007, CVPR; Philbin J., 2007, CVPR; Philbin J., 2008, CVPR; Qin D., 2013, CVPR; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Schindler G., 2007, CVPR; Shen X, 2012, C COMP VIS PATT REC, DOI DOI 10.1109/CVPR.2012.6248031; Sivic J., 2003, ICCV; Tao R, 2014, CVPR; Tolias G., 2013, ICCV; Tolias G., 2011, ICCV; Tolias G., 2014, PATTERN RECOGNITION; Torii A., 2013, CVPR; Torralba A., 2008, CVPR; Turcot P., 2009, CVPR; Wang J., 2010, CVPR; Wu Z, 2009, PROC CVPR IEEE, P25, DOI 10.1109/CVPRW.2009.5206566; Zhang S., 2012, ECCV	51	57	57	1	14	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	FEB	2016	116	3			SI		247	261		10.1007/s11263-015-0810-4	http://dx.doi.org/10.1007/s11263-015-0810-4			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	DC7SY		Green Submitted			2022-12-18	WOS:000369421900004
J	Corsini, M; Dellepiane, M; Ganovelli, F; Gherardi, R; Fusiello, A; Scopigno, R				Corsini, M.; Dellepiane, M.; Ganovelli, F.; Gherardi, R.; Fusiello, A.; Scopigno, R.			Fully Automatic Registration of Image Sets on Approximate Geometry	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						2D-3D registration; Image-geometry alignment; Texture registration; 3D scanning	3D; RECONSTRUCTION; INFORMATION; MODELS	The photorealistic acquisition of 3D objects often requires color information from digital photography to be mapped on the acquired geometry, in order to obtain a textured 3D model. This paper presents a novel fully automatic 2D/3D global registration pipeline consisting of several stages that simultaneously register the input image set on the corresponding 3D object. The first stage exploits Structure From Motion (SFM) on the image set in order to generate a sparse point cloud. During the second stage, this point cloud is aligned to the 3D object using an extension of the 4 Point Congruent Set (4PCS) algorithm for the alignment of range maps. The extension accounts for models with different scales and unknown regions of overlap. In the last processing stage a global refinement algorithm based on mutual information optimizes the color projection of the aligned photos on the 3D object, in order to obtain high quality textures. The proposed registration pipeline is general, capable of dealing with small and big objects of any shape, and robust. We present results from six real cases, evaluating the quality of the final colors mapped onto the 3D object. A comparison with a ground truth dataset is also presented.	[Corsini, M.; Dellepiane, M.; Ganovelli, F.; Scopigno, R.] Visual Comp Lab ISTI CNR, Pisa, Italy; [Gherardi, R.] Toshiba Cambridge Res Lab, Cambridge, England; [Fusiello, A.] Univ Verona, I-37100 Verona, Italy	Toshiba Corporation; University of Verona	Corsini, M (corresponding author), Visual Comp Lab ISTI CNR, Pisa, Italy.	massimiliano.corsini@isti.cnr.it; riccardo.gherardi@crl.toshiba.co.uk; andrea.fusiello@univr.it	Fusiello, Andrea/GOJ-9893-2022; Fusiello, Andrea/A-3162-2016; scopigno, roberto/AAH-7645-2020; Corsini, Massimiliano/B-6375-2015	Fusiello, Andrea/0000-0003-2963-0316; Fusiello, Andrea/0000-0003-2963-0316; Corsini, Massimiliano/0000-0003-0543-1638	EU Community FP7 ICT under the V-MUST.net project [270404]	EU Community FP7 ICT under the V-MUST.net project	This research work was partly funded by the EU Community FP7 ICT under the V-MUST.net project (Grant Agreement 270404). We would also like to thank the anonymous reviewers for their feedback which enabled us to improve the final version of the paper.	Aiger D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360684; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bonarrigo F., 2011, 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), P350, DOI 10.1109/3DIMPVT.2011.51; Bradley D., 2008, P IEEE C COMP VIS PA, P1; Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218; Brown M., 2005, P INT C 3D DIG IM MO; BRUNIE L, 1992, LECT NOTES COMPUT SC, V588, P670; Callieri M, 2008, COMPUT GRAPH-UK, V32, P464, DOI 10.1016/j.cag.2008.05.004; Cignoni P, 2008, COMPUTING, P129, DOI [10.2312/LocalChapterEvents/ItalChap/ItalianChapConf2008/129, DOI 10.2312/LOCALCHAPTEREVENTS/ITALCHAP/ITALIANCHAPCONF2008/129-136]; Cleju I, 2007, LECT NOTES COMPUT SC, V4713, P517; Cohen-Steiner D, 2004, ACM T GRAPHIC, V23, P905, DOI 10.1145/1015706.1015817; Corsini M, 2009, COMPUT GRAPH FORUM, V28, P1755, DOI 10.1111/j.1467-8659.2009.01552.x; Dellepiane M, 2008, COMPUT GRAPH FORUM, V27, P2178, DOI 10.1111/j.1467-8659.2008.01194.x; Dellepiane M, 2012, IEEE T VIS COMPUT GR, V18, P463, DOI 10.1109/TVCG.2011.75; Eisemann M, 2008, COMPUT GRAPH FORUM, V27, P409, DOI 10.1111/j.1467-8659.2008.01138.x; Farenzena M., 2009, IEEE INT WORKSH 3 D; FITZGIBBON AW, 1998, P EUR C COMP VIS, P311; Franken T, 2005, VISUAL COMPUT, V21, P619, DOI 10.1007/s00371-005-0309-z; Fruh C, 2003, IEEE COMPUT GRAPH, V23, P52, DOI 10.1109/MCG.2003.1242382; Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161; Gherardi R, 2010, PROC CVPR IEEE, P1594, DOI 10.1109/CVPR.2010.5539782; Gibson S., 2002, IEEE ACM INT S MIX A; Goesele M., 2006, PROC IEEE COMPUT SOC, V2, P2402, DOI [10.1109/CVPR.2006.199, DOI 10.1109/CVPR.2006.199]; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; Ikeuchi K, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P7, DOI 10.1109/ISMAR.2003.1240683; IRSCHARA A., 2007, P 11 INT C COMP VIS, P1; Johnson A., 1997, THESIS CARNEGIE MELL; Kalogerakis E, 2009, COMPUT AIDED DESIGN, V41, P282, DOI 10.1016/j.cad.2008.12.004; Kamberov G., 2006, P 2 INT S VIS COMP; Kazhdan Michael, 2006, P EUR S GEOM PROC, V7, P2; Krishnan Shankar, 2007, International Journal of Intelligent Systems Technologies and Applications, V3, P319, DOI 10.1504/IJISTA.2007.014267; Krishnan S., 2005, P 3 EUR S GEOM PROC; Lensch HPA, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P317, DOI 10.1109/PCCGA.2000.883955; Li X., 2005, P 3 EUR S GEOM PROC; Liu L., 2006, P IEEE COMP SOC C CO, V2, P2293; Liu LY, 2005, PROC CVPR IEEE, P137; LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043; Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664; Makadia A., 2006, P IEEE C COMP VIS PA, V1, P1297, DOI DOI 10.1109/CVPR.2006.122; Malzbender T, 2001, COMP GRAPH, P519, DOI 10.1145/383259.383320; Matsushita K, 1999, COMPUT GRAPH FORUM, V18, pC349; Neugebauer PJ, 1999, COMPUT GRAPH FORUM, V18, pC245; Ni K, 2007, IEEE I CONF COMP VIS, P2009; Nister D, 2000, LECT NOTES COMPUT SC, V1842, P649; Pintus R., 2011, 12 INT S VI IN PRESS; Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867; Pons JP, 2007, INT J COMPUT VISION, V72, P179, DOI 10.1007/s11263-006-8671-5; Portelli  D., 2010, P WSCG 18 INT C COMP; Pottmann H, 2006, INT J COMPUT VISION, V67, P277, DOI 10.1007/s11263-006-5167-2; Powell MJD, 2008, IMA J NUMER ANAL, V28, P649, DOI 10.1093/imanum/drm047; Pulli K, 1998, INT C PATT RECOG, P11, DOI 10.1109/ICPR.1998.711067; Pulli K., 1999, Second International Conference on 3-D Digital Imaging and Modeling (Cat. No.PR00062), P160, DOI 10.1109/IM.1999.805346; Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423; Sequeira V, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P776, DOI 10.1109/TDPVT.2002.1024159; Shum H. Y., 1999, P INT C COMP VIS PAT; Skelly L., 2007, P SPIE C 2 3 DIM MET, V6762; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; Sottile M, 2010, EUR IT CHAPT C, P81; Stamos I, 2008, INT J COMPUT VISION, V78, P237, DOI 10.1007/s11263-007-0089-1; Steedly D., 2003, P INT C COMP VIS, P649; Strecha C., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587706; Vergauwen M, 2006, MACH VISION APPL, V17, P411, DOI 10.1007/s00138-006-0027-1; Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918; Wu C., 2008, CVPR 08; Yang GH, 2007, 3DIM 2007: SIXTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P159; Zhao WY, 2005, IEEE T PATTERN ANAL, V27, P1305, DOI 10.1109/TPAMI.2005.152; Zheng H., 2009, LECT NOTES COMPUTER, V5996, P426	68	57	57	0	44	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2013	102	1-3					91	111		10.1007/s11263-012-0552-5	http://dx.doi.org/10.1007/s11263-012-0552-5			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	097VO					2022-12-18	WOS:000315501800007
J	Huang, P; Hilton, A; Starck, J				Huang, Peng; Hilton, Adrian; Starck, Jonathan			Shape Similarity for 3D Video Sequences of People	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Temporal shape similarity; 3D video; Surface motion capture; Human motion	OBJECT RECOGNITION; MOTION SYNTHESIS; RETRIEVAL; SIGNATURES	This paper presents a performance evaluation of shape similarity metrics for 3D video sequences of people with unknown temporal correspondence. Performance of similarity measures is compared by evaluating Receiver Operator Characteristics for classification against ground-truth for a comprehensive database of synthetic 3D video sequences comprising animations of fourteen people performing twenty-eight motions. Static shape similarity metrics shape distribution, spin image, shape histogram and spherical harmonics are evaluated using optimal parameter settings for each approach. Shape histograms with volume sampling are found to consistently give the best performance for different people and motions. Static shape similarity is extended over time to eliminate the temporal ambiguity. Time-filtering of the static shape similarity together with two novel shape-flow descriptors are evaluated against temporal ground-truth. This evaluation demonstrates that shape-flow with a multi-frame alignment of motion sequences achieves the best performance, is stable for different people and motions, and overcome the ambiguity in static shape similarity. Time-filtering of the static shape histogram similarity measure with a fixed window size achieves marginally lower performance for linear motions with the same computational cost as static shape descriptors. Performance of the temporal shape descriptors is validated for real 3D video sequence of nine actors performing a variety of movements. Time-filtered shape histograms are shown to reliably identify frames from 3D video sequences with similar shape and motion for people with loose clothing and complex motion.	[Huang, Peng; Hilton, Adrian; Starck, Jonathan] Univ Surrey, CVSSP, Guildford GU2 7XH, Surrey, England	University of Surrey	Huang, P (corresponding author), Univ Surrey, CVSSP, Guildford GU2 7XH, Surrey, England.	p.huang@surrey.ac.uk; a.hilton@surrey.ac.uk; j.starck@surrey.ac.uk	Hilton, Adrian/N-3736-2014	Hilton, Adrian/0000-0003-4223-238X	UK EPSRC [EP/E001351]; EPSRC [EP/E001351/1, EP/F02827X/1] Funding Source: UKRI; Engineering and Physical Sciences Research Council [EP/F02827X/1, EP/E001351/1] Funding Source: researchfish	UK EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was funded by the UK EPSRC Grant EP/E001351 Video-based Animation Production.	ANKERST M, 1999, SSD 99, P207; Arikan O, 2003, ACM T GRAPHIC, V22, P402, DOI 10.1145/882262.882284; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Bustos B, 2007, IEEE COMPUT GRAPH, V27, P22, DOI 10.1109/MCG.2007.80; Carranza J, 2003, ACM T GRAPHIC, V22, P569, DOI 10.1145/882262.882309; Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669; Chua CS, 1997, INT J COMPUT VISION, V25, P63, DOI 10.1023/A:1007981719186; Corney J, 2002, IEEE COMPUT GRAPH, V22, P65, DOI 10.1109/MCG.2002.999789; Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681; de Aguiar E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360697; Del Bimbo A, 2006, ACM T MULTIM COMPUT, V2, P20; Efros A., 2003, ICCV 03; El-Mehalawi M, 2003, COMPUT AIDED DESIGN, V35, P95, DOI 10.1016/S0010-4485(01)00178-6; Elad A, 2003, IEEE T PATTERN ANAL, V25, P1285, DOI 10.1109/TPAMI.2003.1233902; GLEICHER M, 2003, ACM T GRAPHIC, V22, P181, DOI DOI 10.1145/641480.641515; Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711; Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282; HUANG P, 2007, 4 EUR C VIS MED PROD, P1; Huang P, 2007, 3DIM 2007: SIXTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P408; Huang P, 2009, PROC CVPR IEEE, P1478, DOI 10.1109/CVPRW.2009.5206626; Iyer N, 2005, COMPUT AIDED DESIGN, V37, P509, DOI 10.1016/j.cad.2004.07.002; Jain V, 2007, COMPUT AIDED DESIGN, V39, P398, DOI 10.1016/j.cad.2007.02.009; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; Kanade T, 1997, IEEE MULTIMEDIA, V4, P34, DOI 10.1109/93.580394; Kazhdan M., 2003, Symposium on Geometry Processing, P156; KAZHDAN M, 2002, ECCV, V2, P642; Kortgen M., 2003, P 7 CENTRAL EUR SEMI, V3, P5; Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605; Kruger V, 2007, ADV ROBOTICS, V21, P1473; Lee JH, 2002, ACM T GRAPHIC, V21, P491; MCWHERTER D, 2001, J COMPUTING INFORM S, V1, P300, DOI DOI 10.1115/1.1430233; Novotni M., 2003, P 8 ACM S SOL MOD AP, P216; Ohbuchi R, 2003, THEORY AND PRACTICE OF COMPUTER GRAPHICS, PROCEEDINGS, P97, DOI 10.1109/TPCG.2003.1206936; Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648; Paquet E, 2000, SIGNAL PROCESS-IMAGE, V16, P103, DOI 10.1016/S0923-5965(00)00020-5; Schodl A, 2000, COMP GRAPH, P489, DOI 10.1145/344779.345012; Shum HY, 1996, PROC CVPR IEEE, P526, DOI 10.1109/CVPR.1996.517122; Starck J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P915; Starck J., 2005, P ACM SIGGRAPH EUR S, P49, DOI DOI 10.1145/1073368.1073375; Starck J, 2007, IEEE COMPUT GRAPH, V27, P21, DOI 10.1109/MCG.2007.68; Sundar H, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P130, DOI 10.1109/smi.2003.1199609; Tangelder JWH, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P145, DOI 10.1109/SMI.2004.1314502; Theoloalt C, 2007, IEEE T VIS COMPUT GR, V13, P663, DOI 10.1109/TVCG.2007.1006; Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696; Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013; Xu JF, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P472; Zaharia T, 2001, PROC SPIE, V4304, P133, DOI 10.1117/12.424969; Zhang C, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P935, DOI 10.1109/ICIP.2001.958278; Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766	50	57	57	0	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2010	89	2-3			SI		362	381		10.1007/s11263-010-0319-9	http://dx.doi.org/10.1007/s11263-010-0319-9			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	594OS					2022-12-18	WOS:000277547600014
J	Samir, C; Srivastava, A; Daoudi, M; Klassen, E				Samir, Chafik; Srivastava, Anuj; Daoudi, Mohamed; Klassen, Eric			An Intrinsic Framework for Analysis of Facial Surfaces	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Facial surface; Facial shapes; Face analysis; Geodesic between faces; Faces mean; Faces deformation	SHAPE; RECOGNITION; MANIFOLDS	A statistical analysis of shapes of facial surfaces can play an important role in biometric authentication and other face-related applications. The main difficulty in developing such an analysis comes from the lack of a canonical system to represent and compare all facial surfaces. This paper suggests a specific, yet natural, coordinate system on facial surfaces, that enables comparisons of their shapes. Here a facial surface is represented as an indexed collection of closed curves, called facial curves, that are level curves of a surface distance function from the tip of the nose. Defining the space of all such representations of face, this paper studies its differential geometry and endows it with a Riemannian metric. It presents numerical techniques for computing geodesic paths between facial surfaces in that space. This Riemannian framework is then used to: (i) compute distances between faces to quantify differences in their shapes, (ii) find optimal deformations between faces, and (iii) define and compute average of a given set of faces. Experimental results generated using laser-scanned faces are presented to demonstrate these ideas.	[Samir, Chafik] Catholic Univ Louvain, Dept Engn Math, B-1348 Louvain, Belgium; [Daoudi, Mohamed] TELECOM Lille 1 LIFL, Inst TELECOM, UMR 8022, F-59650 Villeneuve Dascq, France; [Srivastava, Anuj] Florida State Univ, Dept Stat, Tallahassee, FL 32306 USA; [Klassen, Eric] Florida State Univ, Dept Math, Tallahassee, FL 32306 USA	Universite Catholique Louvain; IMT - Institut Mines-Telecom; IMT Atlantique; Universite de Lille - ISITE; Universite de Lille; State University System of Florida; Florida State University; State University System of Florida; Florida State University	Samir, C (corresponding author), Catholic Univ Louvain, Dept Engn Math, Batiment Euler A-202,Ave Georges Lemaitre 4, B-1348 Louvain, Belgium.	chafik.samir@uclouvain.be	Srivastava, Anuj/F-7417-2011; Srivastava, Anuj/L-4705-2019; Daoudi, Mohammed/H-5935-2013	Daoudi, Mohammed/0000-0003-4219-7860; samir, chafik/0000-0003-0619-5040	ARO [W911NF-04-01-0268]; AFOSR [FA9550-06-1-0324]; Northrop-Grumman Innovation Alliance; Institut TELECOM [Reco Vis3D]; ANR [FAR3D ANR-07-SESU-004]	ARO; AFOSR(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)); Northrop-Grumman Innovation Alliance; Institut TELECOM; ANR(French National Research Agency (ANR))	The authors would like to thank CNRS, France, for a visiting Professorship to Anuj Srivastava. The research presented here was supported in part by the grants ARO W911NF-04-01-0268, AFOSR FA9550-06-1-0324, and Northrop-Grumman Innovation Alliance grant to Anuj Srivastava. This research was also supported in part by Institut TELECOM under the project Reco Vis3D and the ANR under the project FAR3D ANR-07-SESU-004. We also thank the two reviewers and the associate editor for their feedback in improving this paper.	Bronstein AM, 2005, INT J COMPUT VISION, V64, P5, DOI 10.1007/s11263-005-1085-y; Cazals F, 2006, COMPUT AIDED GEOM D, V23, P582, DOI 10.1016/j.cagd.2006.04.002; Chang KI, 2005, IEEE T PATTERN ANAL, V27, P619, DOI 10.1109/TPAMI.2005.70; Chang KI, 2006, IEEE T PATTERN ANAL, V28, P1695, DOI 10.1109/TPAMI.2006.210; Dijkstra E. W., 1959, NUMERISCHE MATH; EDELSBRUNNER H, 2001, CAMBRIDGE MONOGRAPHS, V7; Glaunes J, 2004, PROC CVPR IEEE, P712; Hallinan P. W., 1999, 2 3 DIMENSIONAL PATT; Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282; KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81; Khaneja N, 1998, IEEE T PATTERN ANAL, V20, P1260, DOI 10.1109/34.730559; Klassen E, 2006, LECT NOTES COMPUT SC, V3951, P95; Klassen E, 2004, IEEE T PATTERN ANAL, V26, P372, DOI 10.1109/TPAMI.2004.1262333; Memoli F, 2005, FOUND COMPUT MATH, V5, P313, DOI 10.1007/s10208-004-0145-y; Michor PW, 2006, J EUR MATH SOC, V8, P1, DOI 10.4171/JEMS/37; Mio W, 2007, INT J COMPUT VISION, V73, P307, DOI [10.1007/s11263-006-9968-0, 10.1007/s11263-006-996S-0]; Osada R., 2001, IEEE SHAPE MODELING; Pennec X, 2006, J MATH IMAGING VIS, V25, P127, DOI 10.1007/s10851-006-6228-4; Rustamov Raif M, 2007, P 5 EUR S GEOM PROC, P225, DOI DOI 10.2312/SGP/SGP07/225-233; SAMIR C, 2006, INT C AC SPEECH SIGN, V5; Samir C, 2006, IEEE T PATTERN ANAL, V28, P1858, DOI 10.1109/TPAMI.2006.235; Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951; Shah J., 2006, WORKSH MATH FDN COMP; SHINAGAWA Y, 1991, IEEE COMPUT GRAPH, V11, P66, DOI 10.1109/38.90568; SPIVAK M., 1979, COMPREHENSIVE INTRO, VI; Spivak M., 1979, COMPREHENSIVE INTRO, VII; SRIVASTAVA A, 2008, J MATH IMAG IN PRESS; Surazhsky V, 2005, ACM T GRAPHIC, V24, P553, DOI 10.1145/1073204.1073228; THIRION J, 1992, 1672 INRIA; Tierny J, 2008, VISUAL COMPUT, V24, P155, DOI 10.1007/s00371-007-0181-0; Vaillant M, 2005, LECT NOTES COMPUT SC, V3565, P381; Varun J., 2007, INT J SHAPE MODELING, V13, P101, DOI DOI 10.1142/S0218654307000968; WANG S, 2006, IEEE C CVPR, P2453; Yoshizawa S., 2005, P ACM S SOL PHYS MOD, P227, DOI [DOI 10.1145/1060244.1060270, 10.1145/1060244.1060270]; Younes L, 1998, SIAM J APPL MATH, V58, P565, DOI 10.1137/S0036139995287685	35	57	59	0	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	2009	82	1					80	95		10.1007/s11263-008-0187-8	http://dx.doi.org/10.1007/s11263-008-0187-8			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	402AH		Green Submitted			2022-12-18	WOS:000262986100005
J	Chen, P				Chen, Pei			Optimization algorithms on subspaces: Revisiting missing data problem in low-rank matrix	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						low-rank matrix approximation; missing data problem; subspace; singular value decomposition; Levenberg-Marquardt algorithm	FACTORIZATION; MOTION; RECONSTRUCTION; APPROXIMATION; GEOMETRY; SHAPE	Low-rank matrix approximation has applications in many fields, such as 3D reconstruction from an image sequence and 2D filter design. In this paper, one issue with low-rank matrix approximation is re-investigated: the missing data problem. Much effort was devoted to this problem, and the Wiberg algorithm or the damped Newton algorithm were recommended in previous studies. However, the Wiberg or damped Newton algorithms do not suit for large (especially "long") matrices, because one needs to solve a large linear system in every iteration. In this paper, we revitalize the usage of the Levenberg-Marquardt algorithm for solving the missing data problem, by utilizing the property that low-rank approximation is a minimization problem on subspaces. In two proposed implementations of the Levenberg-Marquardt algorithm, one only needs to solve a much smaller linear system in every iteration, especially for "long" matrices. Simulations and experiments on real data show the superiority of the proposed algorithms. Though the proposed algorithms achieve a high success rate in estimating the optimal solution by random initialization, as illustrated by real examples; it still remains an open issue how to properly do the initialization in a severe situation (that is, a large amount of data is missing and with high-level noise).	Chinese Univ Hong Kong, Chinese Acad Sci, Shenzhen Inst Adv Int Technol, Shenzhen, Peoples R China	Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS; Chinese University of Hong Kong, Shenzhen	Chen, P (corresponding author), Chinese Univ Hong Kong, Chinese Acad Sci, Shenzhen Inst Adv Int Technol, Shenzhen, Peoples R China.	chenpei75@yahoo.com						Aguiar P. M., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P178, DOI 10.1109/CVPR.1999.786936; Aguiar PMQ, 2003, IEEE T PATTERN ANAL, V25, P1134, DOI 10.1109/TPAMI.2003.1227988; Aguiar PMQ, 2000, IEEE IMAGE PROC, P549, DOI 10.1109/ICIP.2000.901017; Anandan P, 2002, INT J COMPUT VISION, V49, P101, DOI 10.1023/A:1020137420717; [Anonymous], 1999, NUMERICAL OPTIMIZATI; Brand M, 2002, LECT NOTES COMPUT SC, V2350, P707; BRANDT S, 2002, STAT METH VID PROC W, P109; BUCHANAN AM, 2005, P IEEE COMP VIS PATT; Chen P, 2007, J MATH IMAGING VIS, V28, P191, DOI 10.1007/s10851-007-0003-z; Chen P, 2004, IEEE T PATTERN ANAL, V26, P1051, DOI 10.1109/TPAMI.2004.52; CHEN P, 2004, THESIS MONASH U; Chen P, 2008, IEEE T SIGNAL PROCES, V56, P1429, DOI 10.1109/TSP.2007.909353; De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986; Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954; Golub Gene H., 2013, MATRIX COMPUTATION, V3; GUERREIRO RFC, 2003, ENERGY MINIMIZATION; GUERREIRO RFC, 2002, IEEE INT C IM PROC I; Hartley R., 2003, MULTIPLE VIEW GEOMET; Heyden A, 1998, INT C PATT RECOG, P47, DOI 10.1109/ICPR.1998.711076; Hua YB, 2001, IEEE T SIGNAL PROCES, V49, P457, DOI 10.1109/78.905856; IRANI M, 2000, P EUR C COMP VIS, V49, P539; Jacobs D, 1997, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.1997.609321; Jacobs DW, 2001, COMPUT VIS IMAGE UND, V82, P57, DOI 10.1006/cviu.2001.0906; Kahl F, 1999, INT J COMPUT VISION, V33, P163, DOI 10.1023/A:1008192713051; KAHL F, 1998, P EUR C COMP VIS, P327; Lu WS, 1997, IEEE T CIRCUITS-I, V44, P650, DOI 10.1109/81.596949; Manton JH, 2003, IEEE T SIGNAL PROCES, V51, P500, DOI 10.1109/TSP.2002.807002; Martinec D, 2005, PROC CVPR IEEE, P198; Martinec D, 2002, LECT NOTES COMPUT SC, V2351, P355; Morris DD, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P696, DOI 10.1109/ICCV.1998.710793; Okatani T, 2007, INT J COMPUT VISION, V72, P329, DOI 10.1007/s11263-006-9785-5; Poelman CJ, 1997, IEEE T PATTERN ANAL, V19, P206, DOI 10.1109/34.584098; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; SHUM HY, 1995, IEEE T PATTERN ANAL, V17, P854, DOI 10.1109/34.406651; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298; VIDAL R, 2004, P C COMP VIS PATT RE; WIBERG T, 1976, 2 S COMP STAT	38	57	69	0	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	OCT	2008	80	1					125	142		10.1007/s11263-008-0135-7	http://dx.doi.org/10.1007/s11263-008-0135-7			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	344CB					2022-12-18	WOS:000258901900009
J	Lin, ZC; Shum, HY				Lin, ZC; Shum, HY			A geometric analysis of light field rendering	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						light field; lumigraph; image-based modeling and rendering; view interpolation; sampling; double image		Recently, many image-based modeling and rendering techniques have been successfully designed to render photo-realistic images without the need for explicit 3D geometry. However, these techniques (e.g., light field rendering (Levoy, M. and Hanrahan, R, 1996. In SIGGRAPH 1996 Conference Proceedings, Annual Conference Series, Aug. 1996, pp. 31-42) and Lumigraph (Gortler, S.J., Grzeszczuk, R., Szeliski, R., and Cohen, M.F., 1996. In SIGGRAPH 1996 Conference Proceedings, Annual Conference Series, Aug. 1996, pp. 43-54)) may require a substantial number of images. In this paper, we adopt a geometric approach to investigate the minimum sampling problem for light field rendering, with and without geometry information of the scene. Our key observation is that anti-aliased light field rendering is equivalent to eliminating the "double image" artifacts caused by view interpolation. Specifically, we present a closed-form solution of the minimum sampling rate for light field rendering. The minimum sampling rate is determined by the resolution of the camera and the depth variation of the scene. This rate is ensured if the optimal constant depth for rendering is chosen as the harmonic mean of the maximum and minimum depths of the scene. Moreover, we construct the minimum sampling curve in the joint geometry and image space, with the consideration of depth discontinuity. The minimum sampling curve quantitatively indicates how reduced geometry information can be compensated by increasing the number of images, and vice versa. Experimental results demonstrate the effectiveness of our theoretical analysis.	Microsoft Res Asia, Beijing 100080, Peoples R China	Microsoft; Microsoft Research Asia	Lin, ZC (corresponding author), Microsoft Res Asia, Beijing 100080, Peoples R China.							Ayres F, 1967, THEORY PROBLEMS PROJ; Buehler C, 2001, COMP GRAPH, P425, DOI 10.1145/383259.383309; CAMAHORT E, 1998, P 9 EUR WORKSH REND, P117; Chai JX, 2000, COMP GRAPH, P307, DOI 10.1145/344779.344932; CHEN SE, 1993, COMPUTER GRAPHICS, V27, P279; CHEN WC, 2002, ANN C SERIES, P447; Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200; HALLE MW, 1994, P SOC PHOTO-OPT INS, V2176, P73, DOI 10.1117/12.172620; HLAVAC V, 1996, P ECCV, P526; Isaksen A, 2000, COMP GRAPH, P297, DOI 10.1145/344779.344929; Landy M.S., 1991, COMPUTATIONAL MODELS; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; Lin ZC, 2000, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2000.855873; Nishida Y, 2001, ORG LETT, V3, P1, DOI 10.1021/ol006590n; Romeny B.M., 1994, GEOMETRY DRIVEN DIFF; SCHIRMACHER H, 1999, P EUROGRAPHICS 99, P151; Shade J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P231, DOI 10.1145/280814.280882; Shum HY, 1999, COMP GRAPH, P299, DOI 10.1145/311535.311573; SHUM HY, 2001, SIGGRAPH 2001 TECHN, P253; SLOAN PP, 1997, S INT 3D GRAPH PROV, P17; Tekalp AM, 1995, DIGITAL VIDEO PROCES; Wood DN, 2000, COMP GRAPH, P287, DOI 10.1145/344779.344925; WU MS, 2000, IEEE SPIE VIS COMM I, P23; Xu A., 2018, KINETIC THEORY, DOI [10.1007/978-94-015-8668-9, DOI 10.1007/978]; ZHANG C, 2000, IEEE DAT COMPR C MAR, P253	25	57	61	0	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2004	58	2					121	138		10.1023/B:VISI.0000015916.91741.27	http://dx.doi.org/10.1023/B:VISI.0000015916.91741.27			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	829FY					2022-12-18	WOS:000222034000003
J	Cyr, CM; Kimia, BB				Cyr, CM; Kimia, BB			A similarity-based aspect-graph approach to 3D object recognition	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						3D object recognition; aspect-graph; view-based recognition; shape similarity; characteristic views	CURVED OBJECTS; SHAPE; SOLIDS	This paper describes a view-based method for recognizing 3D objects from 2D images. We employ an aspect-graph structure, where the aspects are not based on the singularities of visual. mapping but are instead formed using a notion of shape similarity between views. Specifically, the viewing sphere is endowed with a metric of dis-similarity for each pair of views and the problem of aspect generation is viewed as a "segmentation" of the viewing sphere into homogeneous regions. The viewing sphere is sampled at regular (5 degree) intervals and the similarity metric is used in an iterative procedure to combine views into aspects with a prototype representing each aspect. This is done in a "region-growing" regime which stands in contrast to the usual "edge detection" styles to computing the aspect graph. The aspect growth is constrained such that two aspects of an object remain distinct under the given similarity metric. Once the database of 3D objects is organized as a set of aspects, and prototypes for these aspects for each object, unknown views of database objects are compared with the prototypes and the results are ordered by similarity. We use two similarity metrics for shape, one based on curve matching and the other based on matching shock graphs, which for a database of 64 objects and unknown views of objects from the database give a recall rate of (90.3%, 74.2%, 59.7%) and (95.2%, 69.0%, 57.5%), respectively, for the top three matches; cumulative recall rate based on the top three matches is 98% and 100%, respectively. The result of indexing unknown views of objects not in the database also produce intuitive matches. We also develop a hierarchical indexing scheme to prune unlikely objects at an early stage to improve the efficiency of indexing, resulting in savings of 35% at the top level and of 55% at the next level, cumulatively.	Brown Univ, Div Engn, Lab Engn Man Machine Syst, Providence, RI 02912 USA	Brown University	Cyr, CM (corresponding author), Brown Univ, Div Engn, Lab Engn Man Machine Syst, 182 Hope St, Providence, RI 02912 USA.	cmc@lems.brown.edu; kimia@lems.brown.edu						ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913; ARCELLI C, 2001, P INT WORKSH VIS FOR; BAJCSY R, 1987, INT C COMP VIS LOND, P231; Barr A. H., 1981, IEEE Computer Graphics and Applications, V1, P11, DOI 10.1109/MCG.1981.1673799; BASRI R, 1988, INT C COMP VIS, P482; BELLAIRE G, 1993, MACH GRAPHICS VISION, V2, P105; BESL PJ, 1985, COMPUT SURV, V17, P75, DOI 10.1145/4078.4081; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; Bowyer K. W., 1990, International Journal of Imaging Systems and Technology, V2, P315, DOI 10.1002/ima.1850020407; BURNS J, 1987, IJCAI 87, P763; Carlsson S, 1998, INT J COMPUT VISION, V27, P227, DOI 10.1023/A:1007961913417; CHIEN CH, 1989, IEEE T PATTERN ANAL, V11, P372, DOI 10.1109/34.19034; Cyr CM, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P254, DOI 10.1109/ICCV.2001.937526; DICKMAN S, 1992, ANN ONCOL, V3, P2, DOI 10.1093/oxfordjournals.annonc.a058061; EGGERT D, 1993, IEEE T PATTERN ANAL, V15, P109, DOI 10.1109/34.192483; EGGERT DW, 1993, IEEE T PATTERN ANAL, V15, P1114, DOI 10.1109/34.244674; FAN TJ, 1989, IEEE T PATTERN ANAL, V11, P1140, DOI 10.1109/34.42853; FLYNN PJ, 1991, IEEE T PATTERN ANAL, V13, P1066, DOI 10.1109/34.99239; GIGUS Z, 1991, IEEE T PATTERN ANAL, V13, P542, DOI 10.1109/34.87341; HALLIMAN P, 1999, 2 3 DIMENSIONAL PATT; HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921; IKEUCHI K, 1988, P IEEE, V76, P1016, DOI 10.1109/5.5972; KEREN D, 1994, IEEE T PATTERN ANAL, V16, P38, DOI 10.1109/34.273718; KIRBY M, 1990, PAMI, V1, P103; Klein PN, 2001, SIAM PROC S, P781; KOENDERINK JJ, 1976, BIOL CYBERN, V24, P51, DOI 10.1007/BF00365595; KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644; KRIEGMAN DJ, 1990, INT J COMPUT VISION, V5, P119, DOI 10.1007/BF00054918; Nayar SK, 1996, IEEE INT CONF ROBOT, P2321, DOI 10.1109/ROBOT.1996.506510; PETITJEAN S, 1992, INT J COMPUT VISION, V9, P231, DOI 10.1007/BF00133703; POPE AR, 1993, INT C COMP VIS, P296; Rosch E., 1978, PRINCIPLES CATEGORIZ; SEALES WB, 1992, CVGIP-IMAG UNDERSTAN, V55, P198, DOI 10.1016/1049-9660(92)90017-W; Sebastian T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P755, DOI 10.1109/ICCV.2001.937602; Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951; Sebastian TB, 2002, LECT NOTES COMPUT SC, V2352, P731; Sebastian TB, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P22, DOI 10.1109/ICIP.2001.958041; Sebastian TB, 2000, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P70, DOI 10.1109/MMBIA.2000.852362; SEBASTIAN TB, 2001, P 4 INT WORKSH VIS F, P606; SEBASTIAN TB, 2004, IN PRESS PAMI; Shimshoni I, 1997, IEEE T PATTERN ANAL, V19, P315, DOI 10.1109/34.588001; Shokoufandeh A, 1999, IMAGE VISION COMPUT, V17, P445, DOI 10.1016/S0262-8856(98)00124-3; SRIPRADISVARAKU.T, 1989, 3DWS89, P109; STEWMAN J, 1988, CREATING PERSPECTIVE, V9, P494; Stone JV, 1999, VISION RES, V39, P4032, DOI 10.1016/S0042-6989(99)00123-6; Tarr MJ, 2001, VISION RES, V41, P1981, DOI 10.1016/S0042-6989(01)00024-4; TURK M, 1990, J COGNITIVE NEUROSCI; Weinshall D, 1997, IEEE T PATTERN ANAL, V19, P97, DOI 10.1109/34.574783; WEISHALL D, 1993, INT J COMPUT VISION, V10, P27; Weiss I, 2001, IEEE T PATTERN ANAL, V23, P116, DOI 10.1109/34.908963; WILKES D, 1993, CVPR92, P136; WONG AKC, 1989, IEEE T PATTERN ANAL, V11, P279, DOI 10.1109/34.21797; [No title captured]; 2001, 8 INT C COMP VIS JUL	54	57	58	0	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	2004	57	1					5	22		10.1023/B:VISI.0000013088.59081.4c	http://dx.doi.org/10.1023/B:VISI.0000013088.59081.4c			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	766DP					2022-12-18	WOS:000188330400001
J	Giblin, PJ; Kimia, BB				Giblin, PJ; Kimia, BB			On the local form and transitions of symmetry sets, medial axes, and shocks	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article								In this paper we explore the local geometry of the medial axis (MA) and shocks (SH), and their structural changes under deformations, by viewing these symmetries as subsets of the symmetry set (SS) and present two results. First, we establish that the local form of the medial axis must generically be one of three cases, which we denote by the A notation explained below (here, it merely serves as a reference to sections of the paper): endpoints (A(3)), interior points (A(1)(2)), and junctions (A(1)(3)). The local form of shocks is a sub-classification of these points into six types. Second, we address the (classical) instabilities of the MA, i.e., abrupt changes in the representation with a slight changes in shape, as when a new branch appears with slight protrusion. The identification of these 'transitions' is clearly crucial in robust object recognition. We show that for the medial axis only two such instabilities are generically possible: (i) when four branches come together (A(1)(4)), and (ii) when a new branch grows out of an existing one (A(1)A(3)). Similarly, there are six cases of shock instabilities, derived as sub-classifications of the MA instabilities. We give an explicit example of a dent forming in an ellipse where many of the transitions described in the paper can be seen to appear.	Univ Liverpool, Dept Math, Liverpool L69 3BX, Merseyside, England; Brown Univ, Div Engn, Providence, RI 02912 USA	University of Liverpool; Brown University	Giblin, PJ (corresponding author), Univ Liverpool, Dept Math, Liverpool L69 3BX, Merseyside, England.							ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6; BOGAEVSKI IA, 2002, PERESTROIKAS SHOCKS; BOGAEVSKY IA, 1990, ST PETERSBURG LENING, V1, P807; BRUCE JW, 1986, P ROY SOC EDINB A, V104, P179, DOI 10.1017/S030821050001917X; BRUCE JW, 1985, P ROY SOC EDINB A, V101, P163, DOI 10.1017/S0308210500026263; Bruce JW, 1984, CURVES SINGULARITIES; BUCHNER MA, 1978, COMPOS MATH, V37, P103; GEIGER D, 1998, ICCV1998 6 INT C COM; Giblin P. J., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P79, DOI 10.1109/CVPR.1999.784612; Klein P, 2000, PROCEEDINGS OF THE ELEVENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P696; LEYTON M, 1987, COMPUT VISION GRAPH, V38, P327, DOI 10.1016/0734-189X(87)90117-4; Sebastian T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P755, DOI 10.1109/ICCV.2001.937602; SEBASTIAN T, 2000, 183 LEMS BROWN U; Sharvit D, 1998, J VIS COMMUN IMAGE R, V9, P366, DOI 10.1006/jvci.1998.0396; Siddiqi K, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P222, DOI 10.1109/ICCV.1998.710722; Siddiqi K, 1996, PROC CVPR IEEE, P507, DOI 10.1109/CVPR.1996.517119; TEK H, 1999, P IEEE INT C COMP VI, P362; TEK H, 1999, 181 LEMS BROWN U; Tirthapura S, 1998, P SOC PHOTO-OPT INS, V3527, P25, DOI 10.1117/12.325825; YOMDIN Y, 1981, COMPOS MATH, V43, P225; Zhu SC, 1996, INT J COMPUT VISION, V20, P187; 1998, 6 INT C COMP VIS BOM	23	57	57	0	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG-SEP	2003	54	1-2					143	156		10.1023/A:1023761518825	http://dx.doi.org/10.1023/A:1023761518825			14	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	678EA					2022-12-18	WOS:000182851000007
J	Koenderink, JJ; Van Doorn, AJ; Dana, KJ; Nayar, S				Koenderink, JJ; Van Doorn, AJ; Dana, KJ; Nayar, S			Bidirectional reflection distribution function of thoroughly pitted surfaces	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						bidirectional reflection distribution function; photometry; surface scattering; texture; physical properties	TEXTURE	We derive the BRDF (Bidirectional Reflection Distribution Function) at the mega scale of opaque surfaces that are rough on the macro and micro scale. The roughness at the micro scale is modeled as a uniform, isotropically scattering, Lambertian surface. At the macro scale the roughness is modeled by way of a distribution of spherical concavities. These pits influence the BRDF via vignetting, cast shadow, interreflection and interposition, causing it to differ markedly from Lambertian. Pitted surfaces show strong backward scattering (so called "opposition effect"). When we assume that the macro scale can be resolved, the radiance histogram and the spatial structure of the textons of the textured surface (at the mega scale) can be calculated. This is the main advantage of the model over previous ones: One can do exact (numerical) calculations for a surface geometry that is physically realizable.	Univ Utrecht, Helmholtz Inst, Buys Ballot Lab, NL-3584 CC Utrecht, Netherlands; Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Utrecht University; Columbia University	Koenderink, JJ (corresponding author), Univ Utrecht, Helmholtz Inst, Buys Ballot Lab, Princetonplein 5, NL-3584 CC Utrecht, Netherlands.							BECKMANN P, 1965, IEEE T ANTENN PROPAG, VAP13, P384, DOI 10.1109/TAP.1965.1138443; Beckmann Petr, 1987, SCATTERING ELECTROMA, P4; Blinn J.F., 1977, ACM COMPUTER GRAPHIC, V19, P542; Born M., 1980, PRINCIPLES OPTICS, P180; Buckley H, 1927, PHILOS MAG, V4, P753; BUHL D, 1968, J GEOPHYS RES, V73, P5281, DOI 10.1029/JB073i016p05281; Dana K. J., 1996, CUCS04896; DANA KJ, 1997, P IEEE C COMP VIS PA; Fock V, 1924, Z PHYS, V28, P102, DOI 10.1007/BF01327170; Gershun A., 1939, J MATH PHYS, V18, P51, DOI [DOI 10.1002/SAPM193918151, 10.1002/sapm193918151]; Gibson James J., 1950, PERCEPTION VISUAL WO, P3; Hunter R., 1975, MEASUREMENT APPEARAN; JACQUEZ JA, 1955, J OPT SOC AM, V45, P460, DOI 10.1364/JOSA.45.000460; Kerker M., 1969, SCATTERING LIGHT OTH; Koenderink JJ, 1996, J OPT SOC AM A, V13, P452, DOI 10.1364/JOSAA.13.000452; KOENDERINK JJ, 1983, J OPT SOC AM, V73, P843, DOI 10.1364/JOSA.73.000843; KOENDERINK JJ, 1996, COMPUTER VISION ECCV, V2; Kortum G., 1969, SPECTROSCOPY-US, P5; Lambert J.H., 1760, PHOTOMETRIA SIVE MEN; LONGHURST RS, 1957, GEOMETRICAL PHYSICAL; Minnaert M, 1941, ASTROPHYS J, V93, P403, DOI 10.1086/144279; Moon P, 1940, J OPT SOC AM, V30, P195, DOI 10.1364/JOSA.30.000195; MOON P, 1981, PHOTIC FIELD; NAYAR SK, 1995, SCIENCE, V267, P1153, DOI 10.1126/science.7855592; NAYAR SK, 1991, IEEE T PATTERN ANAL, V13, P611, DOI 10.1109/34.85654; Nicodemus FE, 1977, NBS MONOGRAPH, V160; OPIK E, 1924, PUBLICATIONS OBSERVA, V26, P1; OREN M, 1995, INT J COMPUT VISION, V14, P227, DOI 10.1007/BF01679684; RICHARDS WA, 1982, APPL OPTICS, V21, P2569, DOI 10.1364/AO.21.002569; SMITH BG, 1967, IEEE T ANTENN PROPAG, VAP15, P668, DOI 10.1109/TAP.1967.1138991; Stavridi M, 1997, APPL OPTICS, V36, P3717, DOI 10.1364/AO.36.003717; TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105; VANDIGGELEN J, 1959, RECH OBS UTRECHT, V14, P1; WAGNER RJ, 1967, J ACOUST SOC AM, V41, P138, DOI 10.1121/1.1910308	35	57	57	0	4	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	APR	1999	31	2-3					129	144		10.1023/A:1008061730969	http://dx.doi.org/10.1023/A:1008061730969			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	209NA					2022-12-18	WOS:000081053100003
J	Lai, SH; Vemuri, BC				Lai, SH; Vemuri, BC			Reliable and efficient computation of optical flow	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						motion estimation; motion analysis; optical flow computation; regularization	VISUAL-MOTION; FIELDS; REGULARIZATION; FRAMEWORK; EVOLUTION	In this paper, we present two very efficient and accurate algorithms for computing optical flow. The first is a modified gradient-based regularization method, and the other is an SSD-based regularization method. For the gradient-based method, to amend the errors in the discrete image flow equation caused by numerical differentiation as well as temporal and spatial aliasing in the brightness function, we propose to selectively combine the image flow constraint and a contour-based flow constraint into the data constraint by using a reliability measure. Each data constraint is appropriately normalized to obtain an approximate minimum distance (of the data point to the linear flow equation) constraint instead of the conventional linear flow constraint. These modifications lead to robust and accurate optical flow estimation. We propose an incomplete Cholesky preconditioned conjugate gradient algorithm to solve the resulting large and sparse linear system efficiently. Our SSD-based regularization method uses a normalized SSD measure (based on a similar reasoning as in the gradient-based scheme) as the data constraint in a regularization framework. The nonlinear conjugate gradient algorithm in conjunction with an incomplete Cholesky preconditioning is developed to solve the resulting nonlinear minimization problem. Experimental results on synthetic and real image sequences for these two algorithms are given to demonstrate their performance in comparison with competing methods reported in literature.	Siemens Corp Res, Princeton, NJ 08540 USA; Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA	Siemens AG; State University System of Florida; University of Florida	Lai, SH (corresponding author), Siemens Corp Res, 755 Coll Rd E, Princeton, NJ 08540 USA.			Lai, Shang-Hong/0000-0002-5092-993X				ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Black MJ, 1996, IEEE T PATTERN ANAL, V18, P972, DOI 10.1109/34.541407; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; DUNCAN JH, 1992, IEEE T PATTERN ANAL, V14, P346, DOI 10.1109/34.120329; ELMAN HC, 1986, MATH COMPUT, V47, P191, DOI 10.2307/2008089; Gill P. E., 1981, PRACTICAL OPTIMIZATI; Golub G. H., 1996, MATRIX COMPUTATIONS; HEITZ F, 1993, IEEE T PATTERN ANAL, V15, P1217, DOI 10.1109/34.250841; HILDRETH EC, 1984, ARTIF INTELL, V23, P309, DOI 10.1016/0004-3702(84)90018-3; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Ju SX, 1996, PROC CVPR IEEE, P307, DOI 10.1109/CVPR.1996.517090; Kumar A, 1996, IEEE T IMAGE PROCESS, V5, P598, DOI 10.1109/83.491336; Lai SH, 1997, IEEE T PATTERN ANAL, V19, P594, DOI 10.1109/34.601247; Lucas B.D., 1981, P INT JOINT C ART IN, P121, DOI DOI 10.5334/JORS.BL; Marr D., 1982, VISION COMPUTATIONAL; MEIJERINK JA, 1977, MATH COMPUT, V31, P148, DOI 10.2307/2005786; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; NAGEL HH, 1983, P INT JOINT C ART IN, P945; NEGAHDARIPOUR S, 1993, P IEEE INT C COMP VI, P2; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; SZELISKI R, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P194, DOI 10.1109/CVPR.1994.323829; SZELISKI R, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P757, DOI 10.1109/ICCV.1995.466862; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; URAS S, 1988, BIOL CYBERN, V60, P79, DOI 10.1007/BF00202895; VERRI A, 1989, IEEE T PATTERN ANAL, V11, P490, DOI 10.1109/34.24781; WAXMAN AM, 1985, INT J ROBOT RES, V4, P95, DOI 10.1177/027836498500400307; WEBER J, 1995, INT J COMPUT VISION, V14, P67, DOI 10.1007/BF01421489	28	57	61	1	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG-SEP	1998	29	2					87	105		10.1023/A:1008005509994	http://dx.doi.org/10.1023/A:1008005509994			19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	127DL					2022-12-18	WOS:000076335200001
J	Chen, H; Wolff, LB				Chen, H; Wolff, LB			Polarization phase-based method for material classification in computer vision	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						material classification for image understanding; physics-based image understanding; automatic target recognition; inspection	REFLECTION; COLOR	A robust and accurate polarization phase-based technique for material classification is presented. The novelty of this technique is three-fold in (i) its theoretical development, (ii) application, and, (iii) experimental implementation. The concept of phase of polarization of a light wave is introduced to computer vision for discrimination between materials according to their intrinsic electrical conductivity, such as distinguishing conducting metals, and poorly conducting dielectrics. Previous work has used intensity, color and polarization component ratios. This new method is based on the physical principle that metals retard orthogonal components of light upon reflection while dielectrics do not. This method has significant complementary advantages with respect to existing techniques, is computationally efficient, and can be easily implemented with existing imaging technology. Experiments for real circuit board inspection, nonconductive and conductive glass, and, outdoor object recognition have been performed to demonstrate its accuracy and potential capabilities.	Johns Hopkins Univ, Dept Comp Sci, Comp Vis Lab, Baltimore, MD 21218 USA	Johns Hopkins University	Chen, H (corresponding author), Johns Hopkins Univ, Dept Comp Sci, Comp Vis Lab, Baltimore, MD 21218 USA.							Born M.A.X., 1980, PRINCIPLES OPTICS, VSixth, P1, DOI 10.1016/B978-0-08-026482-0.50008-6; Chandrasekhar S., 1960, RAD TRANSFER; HEALEY G, 1989, J OPT SOC AM A, V6, P920, DOI 10.1364/JOSAA.6.000920; Healey G., 1988, P DARPA IM UND WORKS, P1140; HEALEY G, 1988, SPIE P OPTICS ELECTR; HEALEY G, COMMUNICATION; Horn Berthold K. P., 1975, PSYCHOL COMPUTER VIS, P115; Klinker G. J., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P145; KOSHIKAWA K, 1987, ADV ROBOTICS, V2; SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409; Siegal R., 1981, THERMAL RAD HEAT TRA, V2; Wolff L. B., 1992, Proceedings. IEEE Workshop on Applications of Computer Vision (Cat. No.92TH0446-5), P120, DOI 10.1109/ACV.1992.240320; WOLFF LB, 1991, IEEE T PATTERN ANAL, V13, P635, DOI 10.1109/34.85655; WOLFF LB, 1990, IEEE T PATTERN ANAL, V12, P1059, DOI 10.1109/34.61705; WOLFF LB, 1991, THESIS COLUMBIA U	15	57	58	2	6	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	1998	28	1					73	83		10.1023/A:1008054731537	http://dx.doi.org/10.1023/A:1008054731537			11	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	ZX971					2022-12-18	WOS:000074573800004
J	Kooij, JFP; Flohr, F; Pool, EAI; Gavrila, DM				Kooij, Julian F. P.; Flohr, Fabian; Pool, Ewoud A. I.; Gavrila, Dariu M.			Context-Based Path Prediction for Targets with Switching Dynamics	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Intelligent vehicles; Path prediction; Situational awareness; Vulnerable road users; Intention estimation; Dynamic Bayesian Network; Probabilistic inference	BEHAVIOR; PATTERNS; MODEL; HEAD	Anticipating future situations from streaming sensor data is a key perception challenge for mobile robotics and automated vehicles. We address the problem of predicting the path of objects with multiple dynamic modes. The dynamics of such targets can be described by a Switching Linear Dynamical System (SLDS). However, predictions from this probabilistic model cannot anticipate when a change in dynamic mode will occur. We propose to extract various types of cues with computer vision to provide context on the target's behavior, and incorporate these in a Dynamic Bayesian Network (DBN). The DBN extends the SLDS by conditioning the mode transition probabilities on additional context states. We describe efficient online inference in this DBN for probabilistic path prediction, accounting for uncertainty in both measurements and target behavior. Our approach is illustrated on two scenarios in the Intelligent Vehicles domain concerning pedestrians and cyclists, so-called Vulnerable Road Users (VRUs). Here, context cues include the static environment of the VRU, its dynamic environment, and its observed actions. Experiments using stereo vision data from a moving vehicle demonstrate that the proposed approach results in more accurate path prediction than SLDS at the relevant short time horizon (1s). It slightly outperforms a computationally more demanding state-of-the-art method.	[Kooij, Julian F. P.; Gavrila, Dariu M.] Delft Univ Technol, Mekelweg 2, NL-2628 CD Delft, Netherlands; [Pool, Ewoud A. I.; Gavrila, Dariu M.] Univ Amsterdam, AMLab, Sci Pk 904, NL-1098 XH Amsterdam, Netherlands; [Flohr, Fabian] Daimler AG, Dept Environm Percept, Wilhelm Runge Str 11, D-89081 Ulm, Germany	Delft University of Technology; University of Amsterdam; Daimler AG	Gavrila, DM (corresponding author), Delft Univ Technol, Mekelweg 2, NL-2628 CD Delft, Netherlands.; Gavrila, DM (corresponding author), Univ Amsterdam, AMLab, Sci Pk 904, NL-1098 XH Amsterdam, Netherlands.	j.f.p.kooij@tudelft.nl; fabian.flohr@daimler.com; e.a.i.pool@uva.nl; d.m.gavrila@tudelft.nl		Flohr, Fabian/0000-0002-1499-3790; Kooij, Julian/0000-0001-9919-0710	European Communitys Eighth Framework Program (Horizon2020) [634149]	European Communitys Eighth Framework Program (Horizon2020)	The research leading to the results of this work has received funding from the European Communitys Eighth Framework Program (Horizon2020) under Grant Agreement No. 634149, the PROSPECT project.	Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110; Althoff M, 2009, IEEE T INTELL TRANSP, V10, P299, DOI 10.1109/TITS.2009.2018966; Antonini G, 2006, INT J COMPUT VISION, V69, P159, DOI 10.1007/s11263-005-4797-0; Ba SO, 2011, IEEE T PATTERN ANAL, V33, P101, DOI 10.1109/TPAMI.2010.69; Ballan L, 2016, LECT NOTES COMPUT SC, V9905, P697, DOI 10.1007/978-3-319-46448-0_42; Bandyopadhyay T., 2013, ALGORITHMIC FDN ROBO, P475; Bar-Shalom Y., 2001, ESTIMATION APPL TRAC; Benfold B., 2009, P BRIT MACH VIS C BM; Bishop CM, 2006, PATTERN RECOGNITION; Blackman S. S., 1999, DESIGN ANAL MODERN T; Bonnin S, 2014, IEEE T INTELL TRANSP, V15, P1478, DOI 10.1109/TITS.2014.2299340; Boyen X., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P33; Braun M, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P1546, DOI 10.1109/ITSC.2016.7795763; Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257; Cara I, 2015, IEEE INT C INTELL TR, P1995, DOI 10.1109/ITSC.2015.323; Chen B., 2017, P IEEE INT VEH S; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; Enzweiler M, 2010, PROC CVPR IEEE, P982, DOI 10.1109/CVPR.2010.5540110; Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260; Flohr F, 2015, IEEE T INTELL TRANSP, V16, P1872, DOI 10.1109/TITS.2014.2379441; Gavrila DM, 2002, IV'2002: IEEE INTELLIGENT VEHICLE SYMPOSIUM, PROCEEDINGS, P8; Geiger A., 2012, P IEEE COMP SOC C CO; Geiger A, 2014, IEEE T PATTERN ANAL, V36, P1012, DOI 10.1109/TPAMI.2013.185; Hamaoka H, 2013, 2013 IEEE INTELLIGENT VEHICLES SYMPOSIUM WORKSHOPS (IV WORKSHOPS), P99, DOI 10.1109/IVWorkshops.2013.6615233; Hashimoto Y, 2016, TRANSPORT RES C-EMER, V71, P164, DOI 10.1016/j.trc.2016.07.011; HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282; Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI [10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166]; Huang L, 2017, IEEE T IND INFORM, V13, P782, DOI 10.1109/TII.2016.2597744; Hubert A, 2017, IEEE INT VEH SYM, P1071, DOI 10.1109/IVS.2017.7995856; Hyunggi Cho, 2011, IEEE International Conference on Robotics and Automation, P4391; Jacobs HO, 2017, IEEE ROBOT AUTOM LET, V2, P2064, DOI 10.1109/LRA.2017.2719762; Karasev V, 2016, IEEE INT CONF ROBOT, P2543, DOI 10.1109/ICRA.2016.7487409; Keller CG, 2014, IEEE T INTELL TRANSP, V15, P494, DOI 10.1109/TITS.2013.2280766; Keller CG, 2011, IEEE T INTELL TRANSP, V12, P1292, DOI 10.1109/TITS.2011.2158424; Kitani KM, 2012, LECT NOTES COMPUT SC, V7575, P201, DOI 10.1007/978-3-642-33765-9_15; Klostermann D., 2016, P BRIT MACH VIS C BM; Kohler S, 2013, IEEE INT VEH SYM, P519, DOI 10.1109/IVS.2013.6629520; Kooij JFP, 2016, IEEE T PATTERN ANAL, V38, P322, DOI 10.1109/TPAMI.2015.2443801; Kooij JFP, 2014, IEEE INT VEH SYM, P1445, DOI 10.1109/IVS.2014.6856505; Kooij JFP, 2014, LECT NOTES COMPUT SC, V8694, P618, DOI 10.1007/978-3-319-10599-4_40; LAURITZEN SL, 1992, J AM STAT ASSOC, V87, P1098, DOI 10.2307/2290647; Lee Namhoon, 2017, P IEEE C COMP VIS PA; Li XF, 2017, IEEE T INTELL TRANSP, V18, P269, DOI 10.1109/TITS.2016.2567418; Li XF, 2016, IEEE INT VEH SYM, P1028; Meinecke M.M., 2003, STRATEGIES TERMS VUL; Menze Moritz, 2015, CVPR; Meuter M, 2008, IEEE INT VEH SYM, P399; Minka T.P., 2001, P 17 C UNC ART INT, P362; Morris BT, 2011, IEEE T PATTERN ANAL, V33, P2287, DOI 10.1109/TPAMI.2011.64; Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103; Murphy KP., 2002, DYNAMIC BAYESIAN NET; Oh SM, 2008, INT J COMPUT VISION, V77, P103, DOI 10.1007/s11263-007-0062-z; Ohn-Bar E, 2016, IEEE T INTELL VEHICL, V1, P90, DOI 10.1109/TIV.2016.2571067; Oniga F, 2008, PROCEEDINGS OF THE 11TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, P67, DOI 10.1109/ITSC.2008.4732706; Otsuka K, 2017, IEEE INT VEH SYM, P251, DOI 10.1109/IVS.2017.7995728; Paden B, 2016, IEEE T INTELL VEHICL, V1, P33, DOI 10.1109/TIV.2016.2578706; PAVLOVIC V., 2000, ADV NEURAL INFORM PR, V13, P981; Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260; Pool EAI, 2017, IEEE INT VEH SYM, P289, DOI 10.1109/IVS.2017.7995734; Rasouli A., 2017, P IEEE INT VEH S; Redmon J, 2016, YOU ONLY LOOK ONCE U, DOI [DOI 10.1109/CVPR.2016.91, 10.1109/CVPR.2016.91]; Rehder E, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P139, DOI 10.1109/ICCVW.2015.28; Robicquet A, 2016, LECT NOTES COMPUT SC, V9912, P549, DOI 10.1007/978-3-319-46484-8_33; Rosti AVI, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P809; Roth M, 2016, IEEE INT VEH SYM, P454, DOI 10.1109/IVS.2016.7535425; Sattarov E, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P1179, DOI 10.1109/ITSC.2014.6957847; Sayed T, 2013, SAFETY SCI, V59, P163, DOI 10.1016/j.ssci.2013.05.009; Schmidt S, 2009, TRANSPORT RES F-TRAF, V12, P300, DOI 10.1016/j.trf.2009.02.003; Schneider N, 2013, LECT NOTES COMPUT SC, V8142, P174, DOI 10.1007/978-3-642-40602-7_18; Schreiber M, 2013, IEEE INT VEH SYM, P449, DOI 10.1109/IVS.2013.6629509; Schulz AT, 2015, IEEE INT C INTELL TR, P173, DOI 10.1109/ITSC.2015.37; Schulz AT, 2015, IEEE INT VEH SYM, P622, DOI 10.1109/IVS.2015.7225754; Tamura Y, 2012, IEEE INT C INT ROBOT, P382, DOI 10.1109/IROS.2012.6385599; Vanparijs J, 2015, ACCIDENT ANAL PREV, V84, P9, DOI 10.1016/j.aap.2015.08.007; Volz B, 2016, IEEE INT VEH SYM, P426, DOI 10.1109/IVS.2016.7535421; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Wohler C, 1999, IMAGE VISION COMPUT, V17, P281, DOI 10.1016/S0262-8856(98)00108-5; Yang Y, 2017, IEEE INT VEH SYM, P1393, DOI 10.1109/IVS.2017.7995905; Yi S, 2016, LECT NOTES COMPUT SC, V9905, P263, DOI 10.1007/978-3-319-46448-0_16; Zernetsch S, 2016, IEEE INT VEH SYM, P833, DOI 10.1109/IVS.2016.7535484; Zhang RH, 2017, IEEE ACCESS, V5, P10108, DOI 10.1109/ACCESS.2017.2703816	85	56	60	2	12	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2019	127	3					239	262		10.1007/s11263-018-1104-4	http://dx.doi.org/10.1007/s11263-018-1104-4			24	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	HM5CT		hybrid			2022-12-18	WOS:000459493200002
J	Harandi, M; Hartley, R; Shen, CH; Lovell, B; Sanderson, C				Harandi, Mehrtash; Hartley, Richard; Shen, Chunhua; Lovell, Brian; Sanderson, Conrad			Extrinsic Methods for Coding and Dictionary Learning on Grassmann Manifolds	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Riemannian geometry; Grassmann manifolds; Sparse coding; Dictionary learning	CENTER-OF-MASS; SPARSE REPRESENTATION; ACTION RECOGNITION; MEAN SHIFT; CLASSIFICATION; ALGORITHM; SEGMENTATION; REDUCTION	Sparsity-based representations have recently led to notable results in various visual recognition tasks. In a separate line of research, Riemannian manifolds have been shown useful for dealing with features and models that do not lie in Euclidean spaces. With the aim of building a bridge between the two realms, we address the problem of sparse coding and dictionary learning in Grassmann manifolds, i.e., the space of linear subspaces. To this end, we propose to embed Grassmann manifolds into the space of symmetric matrices by an isometric mapping. This in turn enables us to extend two sparse coding schemes to Grassmann manifolds. Furthermore, we propose an algorithm for learning a Grassmann dictionary, atom by atom. Lastly, to handle non-linearity in data, we extend the proposed Grassmann sparse coding and dictionary learning algorithms through embedding into higher dimensional Hilbert spaces. Experiments on several classification tasks (gender recognition, gesture classification, scene analysis, face recognition, action recognition and dynamic texture classification) show that the proposed approaches achieve considerable improvements in discrimination accuracy, in comparison to state-of-the-art methods such as kernelized Affine Hull Method and graph-embedding Grassmann discriminant analysis.	[Harandi, Mehrtash; Hartley, Richard] Australian Natl Univ, Coll Engn & Comp Sci, Canberra, ACT, Australia; [Harandi, Mehrtash; Hartley, Richard; Sanderson, Conrad] NICTA, Canberra, ACT, Australia; [Shen, Chunhua] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia; [Lovell, Brian; Sanderson, Conrad] Univ Queensland, Brisbane, Qld, Australia	Australian National University; Australian National University; University of Adelaide; University of Queensland	Harandi, M (corresponding author), Australian Natl Univ, Coll Engn & Comp Sci, Canberra, ACT, Australia.	mehrtash.harandi@nicta.com.au; richard.hartley@nicta.com.au; chunhua.shen@adelaide.edu.au; lovell@itee.edu.au	Harandi, Mehrtash/D-6586-2018	Harandi, Mehrtash/0000-0002-6937-6300	Australian Government; Australian Research Council through the ICT Centre of Excellence program; ARC [DP130104567, F120100969]	Australian Government(Australian GovernmentCGIAR); Australian Research Council through the ICT Centre of Excellence program(Australian Research Council); ARC(Australian Research Council)	NICTA is funded by the Australian Government as represented by the Department of Broadband, Communications and the Digital Economy, as well as the Australian Research Council through the ICT Centre of Excellence program. This work is funded in part through an ARC Discovery Grant DP130104567. C. Shen's participation was in part supported by ARC Future Fellowship F120100969.	Absil PA, 2004, ACTA APPL MATH, V80, P199, DOI 10.1023/B:ACAP.0000013855.14971.91; Absil PA, 2008, OPTIMIZATION ALGORITHMS ON MATRIX MANIFOLDS, P1; Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Arsigny V, 2006, MAGN RESON MED, V56, P411, DOI 10.1002/mrm.20965; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Begelfor E., 2006, 2006 IEEE COMPUTER S, V2, P2087, DOI DOI 10.1109/CVPR.2006.50; Binlong Li, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3193, DOI 10.1109/CVPR.2011.5995672; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Cetingul HE, 2011, I S BIOMED IMAGING, P1750, DOI 10.1109/ISBI.2011.5872744; Cetingul HE, 2009, PROC CVPR IEEE, P1896, DOI 10.1109/CVPRW.2009.5206806; Cetingul HE, 2014, IEEE T MED IMAGING, V33, P301, DOI 10.1109/TMI.2013.2284360; Cevikalp H, 2010, PROC CVPR IEEE, P2567, DOI 10.1109/CVPR.2010.5539965; Chan AB, 2005, PROC CVPR IEEE, P846; Chen SK, 2013, PROC CVPR IEEE, P452, DOI 10.1109/CVPR.2013.65; Chikuse Yasuko, 2003, STAT SPECIAL MANIFOL, V174; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; De Cock K, 2002, SYST CONTROL LETT, V46, P265, DOI 10.1016/S0167-6911(02)00135-4; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132; Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P3, DOI 10.1007/978-1-4419-7011-4_1; Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57; Gallivan KA, 2003, PROCEEDINGS OF THE 2003 IEEE WORKSHOP ON STATISTICAL SIGNAL PROCESSING, P315; Ghanem B, 2010, LECT NOTES COMPUT SC, V6312, P223; Goh A, 2008, 2008 IEEE C COMP VIS, P1; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911; Gopalan R, 2014, IEEE T PATTERN ANAL, V36, P2288, DOI 10.1109/TPAMI.2013.249; Guo K, 2013, IEEE T IMAGE PROCESS, V22, P2479, DOI 10.1109/TIP.2013.2252622; Hamm J., 2008, P INT C MACH LEARN I, P376, DOI DOI 10.1145/1390156.1390204; Harandi M., 2015, NEURAL NETWORKS LEAR, V99, P1; Harandi M., 2013, P INT C COMP VIS ICC; Harandi M. T., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2705, DOI 10.1109/CVPR.2011.5995564; Hartley R, 2013, INT J COMPUT VISION, V103, P267, DOI 10.1007/s11263-012-0601-0; Helmke U., 2007, ARXIV07092205; KARCHER H, 1977, COMMUN PUR APPL MATH, V30, P509, DOI 10.1002/cpa.3160300502; Kim M, 2008, GLOB TELECOMM CONF, DOI 10.1109/GLOCOM.2008.ECP.1093; Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037; Kim TK, 2009, IEEE T PATTERN ANAL, V31, P1415, DOI 10.1109/TPAMI.2008.167; Kokiopoulou E, 2011, NUMER LINEAR ALGEBR, V18, P565, DOI 10.1002/nla.743; Lee JM, 2012, INTRO SMOOTH MANIFOL, V218; Lui YM, 2012, J MACH LEARN RES, V13, P3297; Mairal J., 2008, P IEEE C COMP VIS PA, V2, P1, DOI DOI 10.1109/CVPR.2008.4587652; Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828; Mairal J, 2012, IEEE T PATTERN ANAL, V34, P791, DOI 10.1109/TPAMI.2011.156; Mairal J, 2010, J MACH LEARN RES, V11, P19; Manton JH, 2004, I C CONT AUTOMAT ROB, P2211; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Ramamoorthi R, 2002, IEEE T PATTERN ANAL, V24, P1322, DOI 10.1109/TPAMI.2002.1039204; Ravichandran A, 2011, LECT NOTES COMPUT SC, V6492, P425, DOI 10.1007/978-3-642-19315-6_33; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Sanderson C, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P294, DOI 10.1109/AVSS.2012.23; Sankaranarayanan AC, 2010, LECT NOTES COMPUT SC, V6311, P129, DOI 10.1007/978-3-642-15549-9_10; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Shirazi S., 2015, ARXIV14082313; Shuai Zheng, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2073, DOI 10.1109/ICIP.2011.6115889; Srivastava A, 2004, ADV APPL PROBAB, V36, P43, DOI 10.1239/aap/1077134463; Subbarao R, 2009, INT J COMPUT VISION, V84, P1, DOI 10.1007/s11263-008-0195-8; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Tron R., 2008, P IEEE C COMP VIS PA, P1; Turaga P, 2011, IEEE T PATTERN ANAL, V33, P2273, DOI 10.1109/TPAMI.2011.52; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Vemulapalli R, 2013, PROC CVPR IEEE, P1782, DOI 10.1109/CVPR.2013.233; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018; Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1762, DOI 10.1109/TPAMI.2009.43; Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Xie Yuchen, 2013, JMLR Workshop Conf Proc, V28, P1480; Xu Y., 2011, P INT C COMP VIS ICC; Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757; Yu K., 2009, NIPS, V9, P1; Yu Kai, 2010, ICML, P1215; Yu SQ, 2009, IEEE T IMAGE PROCESS, V18, P1905, DOI 10.1109/TIP.2009.2020535; Yuan CF, 2010, LECT NOTES COMPUT SC, V5994, P343; Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110	76	56	59	0	14	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2015	114	2-3			SI		113	136		10.1007/s11263-015-0833-x	http://dx.doi.org/10.1007/s11263-015-0833-x			24	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	CP7MJ		Green Submitted, Green Published			2022-12-18	WOS:000360071900003
J	Carreira, J; Li, FX; Sminchisescu, C				Carreira, Joao; Li, Fuxin; Sminchisescu, Cristian			Object Recognition by Sequential Figure-Ground Ranking	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Object recognition; Semantic segmentation; Learning and ranking		We present an approach to visual object-class segmentation and recognition based on a pipeline that combines multiple figure-ground hypotheses with large object spatial support, generated by bottom-up computational processes that do not exploit knowledge of specific categories, and sequential categorization based on continuous estimates of the spatial overlap between the image segment hypotheses and each putative class. We differ from existing approaches not only in our seemingly unreasonable assumption that good object-level segments can be obtained in a feed-forward fashion, but also in formulating recognition as a regression problem. Instead of focusing on a one-vs.-all winning margin that may not preserve the ordering of segment qualities inside the non-maximum (non-winning) set, our learning method produces a globally consistent ranking with close ties to segment quality, hence to the extent entire object or part hypotheses are likely to spatially overlap the ground truth. We demonstrate results beyond the current state of the art for image classification, object detection and semantic segmentation, in a number of challenging datasets including Caltech-101, ETHZ-Shape as well as PASCAL VOC 2009 and 2010.	[Carreira, Joao; Li, Fuxin; Sminchisescu, Cristian] Univ Bonn, INS, D-53115 Bonn, Germany	University of Bonn	Sminchisescu, C (corresponding author), Univ Bonn, INS, Wegelerstr 6, D-53115 Bonn, Germany.	cristian.sminchisescu@ins.uni-bonn.de			European Commission [MCEXT-025481]; CNCSIS-UEFISCU [PN II-RU-RC-2 / 2009]	European Commission(European CommissionEuropean Commission Joint Research Centre); CNCSIS-UEFISCU(Consiliul National al Cercetarii Stiintifice (CNCS))	This work was supported, in part, by the European Commission, under MCEXT-025481, and by CNCSIS-UEFISCU, under project number PN II-RU-RC-2 / 2009.	Arbelaez P, 2008, PROC CVPR IEEE, P1158; Arbelaez P, 2009, PROC CVPR IEEE, P2294, DOI 10.1109/CVPRW.2009.5206707; Bishop Christopher M., 2007, PATTERN RECOGNITION, V4, DOI 10.1117/1.2819119; Blaschko MB, 2008, LECT NOTES COMPUT SC, V5302, P2, DOI 10.1007/978-3-540-88682-2_2; Blaschko MB, 2008, PROC CVPR IEEE, P93, DOI 10.1109/cvpr.2008.4587586; Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598; Borenstein E, 2002, LECT NOTES COMPUT SC, V2351, P109; Borenstein E, 2008, IEEE T PATTERN ANAL, V30, P2109, DOI 10.1109/TPAMI.2007.70840; Bosch A., 2007, P 6 ACM INT C IM VID, V5, P401, DOI [10.1145/1282280.1282340, DOI 10.1145/1282280]; Boykov Y.Y., 2001, ICCV, V1, P105, DOI DOI 10.1109/ICCV.2001.937505; Carreira J., 2010, 062010 U BONN I NUM; Carreira J., 2010, CONSTRAINED PARAMETR; Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231; Carreira J, 2010, PROC CVPR IEEE, P3241, DOI 10.1109/CVPR.2010.5540063; Cour T., 2007, P IEEE C COMP VIS PA, P1; Csurka G., 2010, INT J COMPUT VISION, P1; Csurka Gabriela, 2008, BMVC, P1; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Ferrari V, 2007, PROC CVPR IEEE, P564; Fulkerson B., 2009, IEEE I CONF COMP VIS, P670, DOI [10.1109/ICCV.2009.5459175, DOI 10.1109/ICCV.2009.5459175]; GALLO G, 1989, SIAM J COMPUT, V18, P30, DOI 10.1137/0218003; Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169; Gonfaus JM, 2010, PROC CVPR IEEE, P3280, DOI 10.1109/CVPR.2010.5540048; Gould S., 2009, ADV NEURAL INFORM PR, V22, P655; Grauman K, 2005, IEEE I CONF COMP VIS, P1458; Griffin Gregory, 2007, CALTECH 256 OBJECT C; Gu CH, 2009, PROC CVPR IEEE, P1030, DOI 10.1109/CVPRW.2009.5206727; He XM, 2004, PROC CVPR IEEE, P695; Ion A, 2011, IEEE I CONF COMP VIS, P2110, DOI 10.1109/ICCV.2011.6126486; Kohli P, 2008, PROC CVPR IEEE, P587; Kumar A, 2007, IEEE I CONF COMP VIS, P1855; Kumar MP, 2005, PROC CVPR IEEE, P18; Ladicky L, 2010, LECT NOTES COMPUT SC, V6314, P424, DOI 10.1007/978-3-642-15561-1_31; Ladicky L, 2009, IEEE I CONF COMP VIS, P739, DOI 10.1109/ICCV.2009.5459248; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; Levin A, 2009, INT J COMPUT VISION, V81, P105, DOI 10.1007/s11263-008-0166-0; Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012; Li FX, 2010, LECT NOTES COMPUT SC, V6376, P262; Li FX, 2010, PROC CVPR IEEE, P1712, DOI 10.1109/CVPR.2010.5539839; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maire M, 2008, PROC CVPR IEEE, P611; Malisiewicz T., 2007, P BRIT MACH VIS C UK, DOI 10.5244/C.21.55; Malisiewicz T, 2008, PROC CVPR IEEE, P932; MORI G, 2004, CVPR, V2, P326; Pantofaru C, 2008, LECT NOTES COMPUT SC, V5304, P481, DOI 10.1007/978-3-540-88690-7_36; Pinto N, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.0040027; Rabinovich A., 2007, CS2007090; Rabinovich A., 2006, P IEEE C COMP VIS PA, P1130; Rahimi A., 2007, ADV NEURAL INFORM PR, P3; Schoenemann T, 2010, IEEE T PATTERN ANAL, V32, P1153, DOI 10.1109/TPAMI.2009.79; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1; Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1; Sminchisescu C, 2009, NEURIPS, P135; Srinivasan P., 2007, IEEE C COMP VIS PATT; Todorovic S, 2008, PROC CVPR IEEE, P195; Toshev A, 2010, PROC CVPR IEEE, P950, DOI 10.1109/CVPR.2010.5540114; Tsochantaridis Ioannis, 2004, P 21 INT C MACH LEAR; Tukey JW., 1977, EXPLORATORY DATA ANA; van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154; Vedaldi A, 2010, PROC CVPR IEEE, P3539, DOI 10.1109/CVPR.2010.5539949; Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Yang Y, 2010, PROC CVPR IEEE, P3113, DOI 10.1109/CVPR.2010.5540070; Yu H. F., 2010, ACM SIGKDD C KNOWL D; Yu SX, 2003, PROC CVPR IEEE, P39; Zhang H, 2006, 2006 IEEE COMP SOC C, P2126, DOI [10.1109/CVPR.2006.301, DOI 10.1109/CVPR.2006.301]	70	56	60	0	13	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2012	98	3					243	262		10.1007/s11263-011-0507-2	http://dx.doi.org/10.1007/s11263-011-0507-2			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	934NI					2022-12-18	WOS:000303450600001
J	Islam, SMS; Davies, R; Bennamoun, M; Mian, AS				Islam, Syed M. S.; Davies, Rowan; Bennamoun, Mohammed; Mian, Ajmal S.			Efficient Detection and Recognition of 3D Ears	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Biometrics; Ear detection; 3D ear recognition; 3D local features; Geometric consistency		The use of ear shape as a biometric trait is a recent trend in research. However, fast and accurate detection and recognition of the ear are very challenging because of its complex geometry. In this work, a very fast 2D AdaBoost detector is combined with fast 3D local feature matching and fine matching via an Iterative Closest Point (ICP) algorithm to obtain a complete, robust and fully automatic system with a good balance between speed and accuracy. Ear images are detected from 2D profile images using the proposed Cascaded AdaBoost detector. The corresponding 3D ear data is then extracted from the co-registered range image and represented with local 3D features. Unlike previous approaches, local features are used to construct a rejection classifier, to extract a minimal region with feature-rich data points and finally, to compute the initial transformation for matching with the ICP algorithm. The proposed system provides a detection rate of 99.9% and an identification rate of 95.4% on Collection F of the UND database. On a Core 2 Quad 9550, 2.83 GHz machine, it takes around 7.7 ms to detect an ear from a 640 x 480 image. Extracting features from an ear takes 22.2 sec and matching it with a gallery using only the local features takes 0.06 sec while using the full matching including ICP requires 2.28 sec on average.	[Islam, Syed M. S.; Davies, Rowan; Bennamoun, Mohammed; Mian, Ajmal S.] Univ Western Australia, Sch Comp Sci & Software Engn, Stirling, WA 6009, Australia	University of Western Australia	Islam, SMS (corresponding author), Univ Western Australia, Sch Comp Sci & Software Engn, 35 Stirling highway, Stirling, WA 6009, Australia.	shams@csse.uwa.edu.au; rowan@csse.uwa.edu.au; m.bennamoun@csse.uwa.edu.au; ajmal@csse.uwa.edu.au	Islam, Syed/H-1801-2011; Bennamoun, Mohammed/C-2789-2013	Islam, Syed/0000-0002-3200-2903; Bennamoun, Mohammed/0000-0002-6603-3257; Mian, Ajmal/0000-0002-5206-3842	Australian Research Council (ARC) [DP0664228]	Australian Research Council (ARC)(Australian Research Council)	This research is sponsored by the Australian Research Council (ARC) grant DP0664228. The authors acknowledge the use of the UND, the NIST, the XM2VTSDB, the UMIST, the USTB and the MIT-CBCL face databases for ear detection and the UND profile and the UCR ear databases for ear recognition. They would also like to acknowledge Mitsubishi Electric Research Laboratories, Inc., Jones and Viola for the permission to use their rectangular filters and D'Errico for the surface fitting code. They would like to thank R. Owens and W. Snyder for their helpful discussions and K. M. Tracey, J. Wan and A. Chew for their technical assistance.	Alvarez L, 2005, CAR C SECUR, P145; Ansari S, 2007, ICCTA 2007: INTERNATIONAL CONFERENCE ON COMPUTING: THEORY AND APPLICATIONS, PROCEEDINGS, P688; Arbab-Zavar B, 2007, LECT NOTES COMPUT SC, V4842, P549; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005; Burge M, 2000, INT C PATT RECOG, P822, DOI 10.1109/ICPR.2000.906202; Cadavid S., 2007, P 2007 1 IEEE INT C, P1; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Chang K, 2003, IEEE T PATTERN ANAL, V25, P1160, DOI 10.1109/TPAMI.2003.1227990; Chen H, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P123; Chen H, 2004, INT C PATT RECOG, P574, DOI 10.1109/ICPR.2004.1334594; Chen H, 2007, IEEE T PATTERN ANAL, V29, P718, DOI 10.1109/TPAMI.2007.1005; Choras M., 2005, ELECT LETT COMPUTER, V5, P84, DOI DOI 10.5565/REV/ELCVIA.108; Choras M, 2007, ADVANCES IN INFORMATION PROCESSING AND PROTECTION, P361, DOI 10.1007/978-0-387-73137-7_32; D'Errico J., 2006, SURFACE FITTING USIN; Freund Y., 1995, P EUR C COMP LEARN T; GENTILE J, 2008, P BIOM THEOR APPL SY, P1; GRAHAM DB, 1998, NATO ASI SERIES F, V163, P446; Guo YM, 2008, IEEE IMAGE PROC, P289, DOI 10.1109/ICIP.2008.4711748; Hu YF, 2005, PR IEEE COMP DESIGN, P111; Hurley DJ, 2005, COMPUT VIS IMAGE UND, V98, P491, DOI 10.1016/j.cviu.2004.11.001; HURLEY DJ, 2007, EUSIPCO 2007, P25; IANNARELLI A., 1989, EAR IDENTIFICATION F; Islam S, 2008, P 4 INT S 3DPVT, P131; Islam S. M. M., 2008, P IEEE 35 INT C PLAS, P1; Islam SMS, 2008, ADVANCES IN COMPUTER AND INFORMATIOM SCIENCES AND ENGINEERING, P509, DOI 10.1007/978-1-4020-8741-7_90; Islam SMS, 2008, LECT NOTES COMPUT SC, V5259, P1081, DOI 10.1007/978-3-540-88458-3_98; Islam SMS, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P513, DOI 10.1109/DICTA.2009.87; Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349; Jain AK, 2006, IEEE T INF FOREN SEC, V1, P125, DOI 10.1109/TIFS.2006.873653; Jeremy K, 2004, J PARALLEL DISTR COM, V64, P997, DOI 10.1016/j.jpdc.2004.03.018; Jiang D, 2007, IEEE INT CONF MOB, P1001; JONES MJ, 2003, TR200396 MERL; Lienhart R, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P277; LU L, 2007, P INT C INN COMP INF, V3, P353; Messer K., 1999, P INT C AUD VID BAS, P1; Mian AS, 2008, INT J COMPUT VISION, V79, P1, DOI 10.1007/s11263-007-0085-5; Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105; *MIT CBCL, 2004, MIT CBCL FAC REC DAT; MONTEIRO G, 2006, ROB 2006 SCI M 6 ROB; *NIST MID, 1994, NIST MUGSH ID DAT MI; Niu ZH, 2006, INT C PATT RECOG, P1216; Passalis G, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P39, DOI 10.1109/AVSS.2007.4425283; Pun KH, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P164, DOI 10.1109/AFGR.2004.1301525; ROSS A, 2004, P 12 EUR SIGN PROC C, P1221; Simard PY, 1999, ADV NEUR IN, V11, P571; Treptow A, 2004, ROBOT AUTON SYST, V48, P41, DOI 10.1016/j.robot.2004.05.005; *UMIST, 2002, UMIST FAC DAT; UND, 2005, U NOTR DAM BIOM DAT; *USTB, 2002, USTB EAR DAT; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Weyrauch B, 2004, 1 IEEE WORKSH FAC PR; YAN P, 2005, P IEEE COMP SOC C CO, P41; YAN P, 2005, P IEEE C COMP VIS PA, P121; Yan P, 2007, IEEE T PATTERN ANAL, V29, P1297, DOI 10.1109/TPAMI.2007.1067; Yuizono T, 2002, IEEE C EVOL COMPUTAT, P237, DOI 10.1109/CEC.2002.1006240; Zhang HJ, 2005, Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9, P4511; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342	58	56	61	0	22	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	OCT	2011	95	1					52	73		10.1007/s11263-011-0436-0	http://dx.doi.org/10.1007/s11263-011-0436-0			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	815ZU		Green Submitted			2022-12-18	WOS:000294569300004
J	Sung, J; Kanade, T; Kim, D				Sung, Jaewon; Kanade, Takeo; Kim, Daijin			Pose robust face tracking by combining active appearance models and cylinder head models	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						face tracking; active appearance models; 2D+3D active appearance models		The active appearance models (AAMs) provide the detailed descriptive parameters that are useful for various autonomous face analysis problems. However, they are not suitable for robust face tracking across large pose variation for the following reasons. First, they are suitable for tracking the local movements of facial features within a limited pose variation. Second, they use gradient-based optimization techniques for model fitting and the fitting performance is thus very sensitive to initial model parameters. Third, when their fitting is failed, it is difficult to obtain appropriate model parameters to re-initialize them. To alleviate these problems, we propose to combine the active appearance models and the cylinder head models (CHMs), where the global head motion parameters obtained from the CHMs are used as the cues of the AAM parameters for a good fitting or re-initialization. The good AAM parameters for robust face tracking are computed in the following manner. First, we estimate the global motion parameters by the CHM fitting algorithm. Second, we project the previously fitted 2D shape points onto the 3D cylinder surface inversely. Third, we transform the inversely projected shape points by the estimated global motion parameters. Fourth, we project the transformed 3D points onto the input image and computed the AAM parameters from them. Finally, we treat the computed AAM parameters as the initial parameters for the fitting. Experimental results showed that face tracking combining AAMs and CHMs is more pose robust than that of AAMs in terms of 170% higher tracking rate and the 115% wider pose coverage.	[Sung, Jaewon; Kim, Daijin] POSTECH, Dept Comp Sci & Engn, Pohang 790784, South Korea; [Kanade, Takeo] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA	Pohang University of Science & Technology (POSTECH); Carnegie Mellon University	Kim, D (corresponding author), POSTECH, Dept Comp Sci & Engn, San 31, Pohang 790784, South Korea.	jwsung@postech.ac.kr; tk@cs.cmu.edu; dkim@postech.ac.kr			Ministry of Education and Human Resources Development (MOE); Ministry of Commerce, Industry and Energy (MOCIE); Ministry of Labor (MOLAB); Intelligent Robotics Development; Ministry of Commerce, Industry and Energy of Korea	Ministry of Education and Human Resources Development (MOE)(Ministry of Education & Human Resources Development (MOEHRD), Republic of Korea); Ministry of Commerce, Industry and Energy (MOCIE)(Ministry of Trade, Industry & Energy (MOTIE), Republic of Korea); Ministry of Labor (MOLAB); Intelligent Robotics Development; Ministry of Commerce, Industry and Energy of Korea(Ministry of Trade, Industry & Energy (MOTIE), Republic of Korea)	It was financially supported by the Ministry of Education and Human Resources Development (MOE), the Ministry of Commerce, Industry and Energy (MOCIE) and the Ministry of Labor (MOLAB) through the fostering project of the Lab of Excellency. Also, it was partially supported by the Intelligent Robotics Development Program, one of the 21st Century Frontier R&D Programs funded by the Ministry of Commerce, Industry and Energy of Korea.	AGGARWAL G, 2005, INT C PATT REC MACH; BASU S, 1996, INT C PATT REC; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Bregler C., 1998, P IEEE C COMP VIS PA; CASCIA ML, 2000, IEEE T PATTERN ANAL, V22, P322; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; DECARLO D, 1996, P IEEE C COMP VIS PA; Fidaleo D, 2005, LECT NOTES COMPUT SC, V3723, P125; GROSS R, 2004, P IEE WORKSH FAC PRO; GROSS R, 2004, P BRIT MACH VIS C; KANADE T, 1981, INT JOINT C ART INT, V1, P674; MALCIU M, 2000, IEEE INT C AUT FAC G; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; ROMDHANI S, 2003, SELECTIVE VS GLOBAL; STROM J, 1999, P MOD PEOPL WORKSH I; Vacchetti L, 2004, IEEE T PATTERN ANAL, V26, P1385, DOI 10.1109/TPAMI.2004.92; XIAO J, 2002, AUTOMATIC FACE GESTU; Xiao J., 2004, EUR C COMP VIS; XIAO J, 2004, INT C COMP VIS PATT	19	56	63	0	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	2008	80	2					260	274		10.1007/s11263-007-0125-1	http://dx.doi.org/10.1007/s11263-007-0125-1			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	348DA					2022-12-18	WOS:000259190000006
J	Schmitt, O; Modersitzki, J; Heldmann, S; Wirtz, S; Fischer, B				Schmitt, Oliver; Modersitzki, Jan; Heldmann, Stefan; Wirtz, Stefan; Fischer, Bernd			Image registration of sectioned brains	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Review						neuroimaging; human and rat brain serial sections; affine registration; elastic registration; matching; alignment; warping; 3D-reconstruction	3-DIMENSIONAL RECONSTRUCTION; VISUAL-CORTEX; NONRIGID REGISTRATION; PRINCIPAL-AXES; ELASTIC REGISTRATION; SIMILARITY MEASURES; CT IMAGES; MR; ALIGNMENT; SYSTEM	The physical (microtomy), optical (microscopy), and radiologic (tomography) sectioning of biological objects and their digitization lead to stacks of images. Due to the sectioning process, and disturbances, movement of objects during imaging for example, adjacent images of the image stack are not optimally aligned to each other. Such mismatches have to be corrected automatically by Suitable registration methods. Here, a whole brain of a Sprague Dawley rat was serially sectioned and stained followed by digitizing the 20 mu m thin histologic sections. We describe how to prepare the images for subsequent automatic intensity based registration. Different registration schemes are presented and their results compared to each other from an anatomical and mathematical perspective. In the first part we concentrate on rigid and affine linear methods and deal only with linear mismatches of the images. Digitized images of stained histologic sections often exhibit inhomogenities of the gray level distribution coming from staining and/or sectioning variations. Therefore, a method is developed that is robust with respect to inhomogenities and artifacts. Furthermore we combined this approach by minimizing a suitable distance measure for shear and rotation mismatches of foreground objects after applying the principal axes transform. As a consequence of our investigations, we must emphasize that the combination of a robust principal axes based registration in combination with optimizing translation, rotation and shearing errors gives rise to the best reconstruction results from the mathematical and anatomical view point. Because the sectioning process introduces nonlinear deformations to the relative thin histologic sections as well, an elastic registration has to be applied to correct these deformations. In the second part of the Study a detailed description of the advances of an elastic registration after affine linear registration of the rat brain is given. We found quantitative evidence that affine linear registration is a suitable starting point for the alignment of histologic sections but elastic registration must be performed to improve significantly the registration result. A strategy is presented that enables to register elastically the affine linear preregistered rat brain sections and the first one hundred images of serial histologic sections through both occipital lobes of a human brain (6112 images). Additionally, we will describe how a parallel implementation of the elastic registration was realized. Finally, the computed force fields have been applied here for the first time to the morphometrized data of cells determined automatically by an image analytic framework.	Univ Rostock, Inst Anat, D-18055 Rostock, Germany; Med Univ Lubeck, Inst Math, D-23560 Lubeck, Germany	University of Rostock; University of Lubeck	Schmitt, O (corresponding author), Univ Rostock, Inst Anat, Gertrudenstr 9, D-18055 Rostock, Germany.	schmitt@med.uni-rostock.de; modersitzki@math.uni-luebeck.de; heldmann@math.uni.luebeck.de; wirtz@math.uni-lubeck.de; fischer@math.uni-luebeck.de	Fischer, Bernd/E-4301-2010					Abbe E., 1873, ARCH MIKROSK ANAT, V9, P413, DOI [10.1007/ BF02956173, DOI 10.1007/BF02956173]; Abeles M, 1991, CORTICONICS NEURAL C, DOI DOI 10.1017/CBO9780511574566; AFERZON J, 1991, ANAL QUANT CYTOL, V13, P80; Alexander ME, 1997, MAGN RESON IMAGING, V15, P505, DOI 10.1016/S0730-725X(96)00384-0; ALPERT NM, 1990, J NUCL MED, V31, P1717; AMIT Y, 1991, J AM STAT ASSOC, V86, P376, DOI 10.2307/2290581; Arbib MA, 1995, HDB BRAIN THEORY NEU; Arsigny V, 2005, MED IMAGE ANAL, V9, P507, DOI 10.1016/j.media.2005.04.001; Ashburner J, 2000, HUM BRAIN MAPP, V9, P212, DOI 10.1002/(SICI)1097-0193(200004)9:4<212::AID-HBM3>3.0.CO;2-#; Auer M, 2005, IEEE T IMAGE PROCESS, V14, P475, DOI 10.1109/TIP.2005.843756; Baheerathan S, 1998, J MICROSC-OXFORD, V192, P37, DOI 10.1046/j.1365-2818.1998.00405.x; BAJCSY R, 1983, J COMPUT ASSIST TOMO, V7, P618, DOI 10.1097/00004728-198308000-00008; BAJCSY R, 1989, COMPUT VISION GRAPH, V46, P1, DOI 10.1016/S0734-189X(89)80014-3; BAJCSY R, 1982, P 6 INT C PATT REC, V6, P351; BANERJEE PK, 1994, PHYS MED BIOL, V39, P1969, DOI 10.1088/0031-9155/39/11/011; BARDINET E, 2001, LECT NOTES COMPUTER, V2208, P957; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; BARNEA DI, 1972, IEEE T COMPUT, VC 21, P179, DOI 10.1109/TC.1972.5008923; BAUMANN MA, 1994, ANN ANAT, V176, P185; Benveniste H, 2002, PROG NEUROBIOL, V67, P393, DOI 10.1016/S0301-0082(02)00020-5; BOHME M, 2002, SIIMTRA0208 MED U LU; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; BOOKSTEIN FL, 1984, J THEOR BIOL, V107, P475, DOI 10.1016/S0022-5193(84)80104-6; BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107; Born G, 1883, ARCH MIKROSK ANAT, V22, P584, DOI 10.1007/bf02952679; Braitenberg V., 1978, Theoretical approaches to complex systems, P171; Broit C., 1981, OPTIMAL REGISTRATION; BRON C, 1990, J MICROSC-OXFORD, V157, P115, DOI 10.1111/j.1365-2818.1990.tb02952.x; BroNielsen M, 1996, LECT NOTES COMPUT SC, V1131, P267; Brown L.G., 1992, ACM COMPUT SURV, V24, P325, DOI DOI 10.1145/146370.146374; BUDO A, 1990, THEORETISCHE MECH; Christensen GE, 1997, IEEE T MED IMAGING, V16, P864, DOI 10.1109/42.650882; Christensen GE, 2001, IEEE T MED IMAGING, V20, P568, DOI 10.1109/42.932742; CHRISTENSEN GE, 1994, THESIS SEVER I TECHN; CHUI H, 2001, LECT NOTES COMPUT SC, V2082, P300; Ciarlet P.G., 2021, SOC IND APPL MATH, DOI [10.1137/1.9781611976823, DOI 10.1137/1.9781611976823]; Cohen FS, 1998, IEEE T BIO-MED ENG, V45, P642, DOI 10.1109/10.668755; Collins DL, 1995, HUM BRAIN MAPP, V3, P190, DOI 10.1002/hbm.460030304; d'Aische AD, 2005, MED IMAGE ANAL, V9, P538, DOI 10.1016/j.media.2005.04.003; Dauguet J, 2004, LECT NOTES COMPUT SC, V3216, P242; Davatzikos C, 1997, COMPUT VIS IMAGE UND, V66, P207, DOI 10.1006/cviu.1997.0605; Davatzikos C., 1994, Proceedings of the IEEE Workshop on Biomedical Image Analysis (Cat. No.94TH0624-7), P245, DOI 10.1109/BIA.1994.315847; de Munck JC, 1998, PHYS MED BIOL, V43, P1255, DOI 10.1088/0031-9155/43/5/015; DECASTRO E, 1987, IEEE T PATTERN ANAL, V9, P700, DOI 10.1109/TPAMI.1987.4767966; Desgeorges M, 1997, J NEURORADIOLOGY, V24, P108; DIERKER M, 1976, ALGORITHM ALIGNMENT; DOUGHERTY E, 1993, MATH MORPHOLOGY IMAG; Ferrant M, 2001, IEEE T MED IMAGING, V20, P1384, DOI 10.1109/42.974933; FISCHER A, 2002, CONTEMP MATH, V313, P117; FISCHER A, 2001, BVM, V22, P168; Fischer B, 1999, NUMER ALGORITHMS, V22, P1, DOI 10.1023/A:1019194421221; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; FORTNER, 1999, USERS GUIDE REFERENC; Fu Yong-Bi, 2001, NONLINEAR ELASTICITY; Gefen S, 2003, IEEE T MED IMAGING, V22, P1480, DOI 10.1109/TMI.2003.819280; GERSTEIN GL, 1989, IEEE T BIO-MED ENG, V36, P4, DOI 10.1109/10.16444; GLASER EM, 1965, IEEE T BIO-MED ENG, VBM12, P22, DOI 10.1109/TBME.1965.4502337; Gold S, 1998, PATTERN RECOGN, V31, P1019, DOI 10.1016/S0031-3203(98)80010-1; Golub G. H., 1996, MATRIX COMPUTATIONS; Green A.E., 1968, THEORETICAL ELASTICI; GREEN AE, 1970, LARGE ELASTIC DEFORM; Gremillet Ph., 1991, Machine Vision and Applications, V4, P263, DOI 10.1007/BF01815303; Guimond A, 2001, IEEE T MED IMAGING, V20, P58, DOI 10.1109/42.906425; HAJNAL JV, 1995, J COMPUT ASSIST TOMO, V19, P289, DOI 10.1097/00004728-199503000-00022; HAMILTON P, 2001, LNCS, V2208, P66; Hayakawa N, 2000, NUCL MED BIOL, V27, P121, DOI 10.1016/S0969-8051(99)00098-0; Hebb D., 1949, ORG BEHAV; Hellem S, 2001, Clin Implant Dent Relat Res, V3, P20, DOI 10.1111/j.1708-8208.2001.tb00125.x; HIBBARD LS, 1988, J NEUROSCI METH, V26, P55, DOI 10.1016/0165-0270(88)90129-X; HIBBARD LS, 1992, J NEUROSCI METH, V41, P133, DOI 10.1016/0165-0270(92)90056-J; HIBBARD LS, 1987, SCIENCE, V236, P1641, DOI 10.1126/science.3603004; Hill DLG, 2001, PHYS MED BIOL, V46, pR1, DOI 10.1088/0031-9155/46/3/201; Hoehn M, 2002, P NATL ACAD SCI USA, V99, P16267, DOI 10.1073/pnas.242435499; Holden M, 2000, IEEE T MED IMAGING, V19, P94, DOI 10.1109/42.836369; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Hsu CC, 2001, MED BIOL ENG COMPUT, V39, P517, DOI 10.1007/BF02345141; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; Iosifescu DV, 1997, NEUROIMAGE, V6, P13, DOI 10.1006/nimg.1997.0274; Jacobs MA, 1999, MED PHYS, V26, P1568, DOI 10.1118/1.598671; Jannin P, 2000, Comput Aided Surg, V5, P1; JOHNSON EM, 1983, COMPUT BIOMED RES, V16, P79, DOI 10.1016/0010-4809(83)90008-3; Johnson H.J., 2001, LNCS, V2082, P329; Joshi SC, 2000, IEEE T IMAGE PROCESS, V9, P1357, DOI 10.1109/83.855431; Juan M C, 2000, Stud Health Technol Inform, V70, P153; Kent J.T., 1988, J APPL STAT, V15, P247, DOI DOI 10.1080/02664768800000029; Kiebel SJ, 1997, NEUROIMAGE, V5, P271, DOI 10.1006/nimg.1997.0265; KOSEVICH A, 1995, THEORY ELASTICITY; Kostelec PJ, 1998, MED PHYS, V25, P1593, DOI 10.1118/1.598403; Kremser C, 1997, MAGN RESON IMAGING, V15, P579, DOI 10.1016/S0730-725X(97)00023-4; Kuglin C. D., 1975, Proceedings of the 1975 International Conference on Cybernetics and Society, P163; KULJIS RO, 1990, P NATL ACAD SCI USA, V87, P5303, DOI 10.1073/pnas.87.14.5303; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Lamade W, 2000, ARCH SURG-CHICAGO, V135, P1256, DOI 10.1001/archsurg.135.11.1256; Lester H, 1999, PATTERN RECOGN, V32, P129, DOI 10.1016/S0031-3203(98)00095-8; Likar B, 1999, MED PHYS, V26, P1678, DOI 10.1118/1.598660; Lurie A. I., 1990, NONLINEAR THEORY ELA; MACAGNO E, 1976, RECORDING ANAL 3 D I; MACAGNO ER, 1979, ANNU REV BIOPHYS BIO, V8, P323, DOI 10.1146/annurev.bb.08.060179.001543; MacDonald D, 2000, NEUROIMAGE, V12, P340, DOI 10.1006/nimg.1999.0534; MAINTZ J, 1981, MED IMAGE ANAL, V2, P1; Malandain G, 2003, LECT NOTES COMPUT SC, V2879, P41; Malandain G, 2004, NEUROIMAGE, V23, P111, DOI 10.1016/j.neuroimage.2004.04.038; MAURER C, 1998, J ANAT, V193, P347; Maurer CR, 1997, IEEE T MED IMAGING, V16, P447, DOI 10.1109/42.611354; Maurer CR, 1998, IEEE T MED IMAGING, V17, P817, DOI 10.1109/42.736050; Maurer CR, 1998, IEEE T MED IMAGING, V17, P753, DOI 10.1109/42.736031; MAURER CR, 1993, REV MED IMAGE REGIST, P17; MCINERNEY J, 1998, LNCS, V1496, P861; Mega MS, 1997, NEUROIMAGE, V5, P147, DOI 10.1006/nimg.1996.0255; Miller K, 1997, J BIOMECH, V30, P1115, DOI 10.1016/S0021-9290(97)00092-4; Modersitzki J, 1999, LECT NOTES COMPUT SC, V1593, P141; Modersitzki J, 2004, NUMER MATH SCI COMP; Mountcastle VB, 1997, BRAIN, V120, P701, DOI 10.1093/brain/120.4.701; Murphy M, 2001, J CLIN NEUROSCI, V8, P534, DOI 10.1054/jocn.2001.0921; Mutic S, 2001, INT J RADIAT ONCOL, V51, P255, DOI 10.1016/S0360-3016(01)01659-5; Nowinski W L, 1997, Comput Aided Surg, V2, P42, DOI 10.1002/(SICI)1097-0150(1997)2:1<42::AID-IGS7>3.0.CO;2-N; Nowinski WL, 2001, MED IMAGE ANAL, V5, P207, DOI 10.1016/S1361-8415(01)00043-3; OKAJIMA K, 1986, BIOL CYBERN, V54, P107, DOI 10.1007/BF00320481; ONGARO I, 1991, ANAT REC, V229, P285, DOI 10.1002/ar.1092290217; Otte M, 2001, IEEE T MED IMAGING, V20, P193, DOI 10.1109/42.918470; Ourselin S, 2001, IMAGE VISION COMPUT, V19, P25, DOI 10.1016/S0262-8856(00)00052-4; OURSELIN S, 2001, LNCS, V2208, P743; OZTURK C, 2002, ALIGN 1 1; Palm G, 1982, STUDIES BRAIN FUNCTI; PAWLEY JB, 1995, HDB BIOL CONFOCAL MI; Penney GP, 1998, IEEE T MED IMAGING, V17, P586, DOI 10.1109/42.730403; PERKINS WJ, 1982, J BIOMED ENG, V4, P37, DOI 10.1016/0141-5425(82)90024-3; Rangarajan A, 1999, Med Image Anal, V3, P425, DOI 10.1016/S1361-8415(99)80034-6; Rangarajan A, 1997, Med Image Anal, V1, P379; Rohlfing T, 2000, Comput Aided Surg, V5, P414, DOI 10.1002/igs.1003; ROHLFING T, 2001, LECT NOTES COMPUTER, V2208, P111; Rohr K, 2001, IEEE T MED IMAGING, V20, P526, DOI 10.1109/42.929618; Rouet JM, 2000, IEEE T INF TECHNOL B, V4, P126, DOI 10.1109/4233.845205; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284; RUSINEK H, 1993, J NUCL MED, V34, P2019; RUSSO R, 1996, MATH PROBLEMS ELASTI; Sabbah P, 2002, CLIN IMAG, V26, P6, DOI 10.1016/S0899-7071(01)00313-8; SANTORI EM, 1993, J NEUROSCI METH, V50, P187, DOI 10.1016/0165-0270(93)90007-E; Schieweck F., 1993, Impact of Computing in Science and Engineering, V5, P345, DOI 10.1006/icse.1993.1016; SCHLAUG G, 1995, J COMP NEUROL, V351, P441, DOI 10.1002/cne.903510310; Schmitt O, 2005, MICROSC RES TECHNIQ, V66, P203, DOI 10.1002/jemt.20163; Schmitt O, 1997, MICRON, V28, P197, DOI 10.1016/S0968-4328(97)00026-7; Schmitt O, 1999, J MICROSC-OXFORD, V196, P337, DOI 10.1046/j.1365-2818.1999.00604.x; Schmitt O, 1998, BIOTECH HISTOCHEM, V73, P44, DOI 10.3109/10520299809140505; SCHMITT O, 1999, NEUROIMAGE, V9, pS22; Schmolke C, 1996, ANAT EMBRYOL, V193, P15; SCHMOLKE C, 1984, ANAT EMBRYOL, V169, P125, DOI 10.1007/BF00303141; Schormann T, 1997, IEEE T MED IMAGING, V16, P942, DOI 10.1109/42.650891; Schormann T, 1996, LECT NOTES COMPUT SC, V1131, P337, DOI 10.1007/BFb0046971; Schormann T, 1998, HUM BRAIN MAPP, V6, P339, DOI 10.1002/(SICI)1097-0193(1998)6:5/6<339::AID-HBM3>3.0.CO;2-Q; SCHORMANN T, 1997, INFORM AKTUELL, V19, P384; Silva AC, 2002, P NATL ACAD SCI USA, V99, P15182, DOI 10.1073/pnas.222561899; SJOSTRAND FS, 1958, J ULTRA MOL STRUCT R, V2, P122, DOI 10.1016/S0022-5320(58)90050-9; Sokolnikoff I.S., 1956, MATH THEORY ELASTICI, V83, DOI [10.1090/S0002-9904-1956-10055-4, DOI 10.1090/S0002-9904-1956-10055-4]; STREET CH, 1983, J NEUROSCI METH, V7, P359, DOI 10.1016/0165-0270(83)90028-6; Studholme C, 1999, PATTERN RECOGN, V32, P71, DOI 10.1016/S0031-3203(98)00091-0; SYMON K, 1971, MECH; TANAKA S, 1991, BIOL CYBERN, V64, P263, DOI 10.1007/BF00199589; Thirion J P, 1998, Med Image Anal, V2, P243, DOI 10.1016/S1361-8415(98)80022-4; Thompson JK, 2003, SCIENCE, V299, P1070, DOI 10.1126/science.1079220; THOMPSON MC, 1989, J COMPUT PHYS, V82, P94, DOI 10.1016/0021-9991(89)90037-5; THURFJELL L, 1995, COMPUT METH PROG BIO, V47, P51, DOI 10.1016/0169-2607(95)01629-8; TOGA AW, 1993, J NEUROSCI METH, V48, P1, DOI 10.1016/S0165-0270(05)80002-0; Toga AW, 2001, IMAGE VISION COMPUT, V19, P3, DOI 10.1016/S0262-8856(00)00055-X; TOGA AW, 1995, BRAIN RES BULL, V38, P77, DOI 10.1016/0361-9230(95)00074-O; VANDENELSEN PA, 1993, IEEE ENG MED BIOL, V12, P26, DOI 10.1109/51.195938; VanEssen DC, 1997, NATURE, V385, P313, DOI 10.1038/385313a0; VATSA VN, 1990, COMPUT FLUIDS, V18, P391, DOI 10.1016/0045-7930(90)90029-W; Viergever MA, 1997, BIOPHYS CHEM, V68, P207, DOI 10.1016/S0301-4622(97)00047-1; Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918; VIOLA P, 1993, 5 INT C COMP VIS IEE, V5, P16; WARE RW, 1975, INT REV CYTOL, V40, P325, DOI 10.1016/S0074-7696(08)60956-0; Watanabe H, 2001, NEUROIMAGE, V14, P1089, DOI 10.1006/nimg.2001.0910; WEBSTER R, 1994, INT J NUMER METH FL, V18, P761, DOI 10.1002/fld.1650180805; West JB, 2001, NEUROSURGERY, V48, P810, DOI 10.1097/00006123-200104000-00023; White E.L., 1989, CORTICAL CIRCUITS SY; WIDROW B, 1973, PATTERN RECOGN, V5, P175, DOI 10.1016/0031-3203(73)90042-3; WOODS R, 2002, AIR 5 08; Woods RP, 1998, J COMPUT ASSIST TOMO, V22, P139, DOI 10.1097/00004728-199801000-00027; Woods RP, 1999, HUM BRAIN MAPP, V8, P73, DOI 10.1002/(SICI)1097-0193(1999)8:2/3<73::AID-HBM1>3.0.CO;2-7; Yeshurun Y, 1999, BIOL CYBERN, V80, P117, DOI 10.1007/s004220050510; You J., 1995, Real-Time Imaging, V1, P245, DOI 10.1006/rtim.1995.1025; Young M, 1996, ANAL CORTICAL CONNEC; YOUNG MP, 1992, NATURE, V358, P152, DOI 10.1038/358152a0; ZEISS, 1992, KS400 REFERENCE GUID; ZHAO WZ, 1993, IEEE T MED IMAGING, V12, P782, DOI 10.1109/42.251130; Zhu YM, 2002, IEEE T MED IMAGING, V21, P174, DOI 10.1109/42.993135	187	56	58	1	26	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2007	73	1					5	39		10.1007/s11263-006-9780-x	http://dx.doi.org/10.1007/s11263-006-9780-x			35	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	141YV					2022-12-18	WOS:000244616100001
J	Haber, E; Modersitzki, J				Haber, Eldad; Modersitzki, Jan			Image registration with guaranteed displacement regularity	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						image registration; image matching; image fusion; variational approach; constrained optimization	DIFFEOMORPHISMS; DEFORMATION	The goal of image registration is twofold. One goal is to enforce a certain similarity of two images by geometrically transforming one of the images. The second goal is to keep this transformation meaningful or regular. There exists a large amount of approaches aiming for regularity. Most of those are based on certain regularization techniques, others use so-called regridding options. Here, we present a mathematically sound formulation that explicitly controls the deformation in terms of the determinant of the Jacobian of the transformation. In contrast to similar work, we use pointwise inequality constraints, i.e., the volume is controlled voxel by voxel and not by integral measures. This approach guaranties grid regularity and prevent folding. As it turns out, the discretization of the volume constraint inequality is not straightforward. Therefore, we present a new type of discretization enabling the detection of twists in a pixel or a voxel. Such detection is crucial since a twists indicates that a transformation is physically meaningless. To solve the large-scale inequality constrained optimization problem, we present a numerical approach based on an interior point method. We finally present some numerical examples that demonstrate the advantage of including inequality constraints explicitly.	Emory Univ, Dept Math & Comp Sci, Atlanta, GA 30322 USA; Med Univ Lubeck, Inst Math, D-23538 Lubeck, Germany	Emory University; University of Lubeck	Modersitzki, J (corresponding author), Emory Univ, Dept Math & Comp Sci, Atlanta, GA 30322 USA.	haber@mathcs.emory.edu; modersitzki@math.uni-luebeck.de						[Anonymous], 1999, NUMERICAL OPTIMIZATI; Ascher UM, 2006, SIAM J SCI COMPUT, V28, P339, DOI 10.1137/040617261; Ascher UM, 2001, INVERSE PROBL, V17, P571, DOI 10.1088/0266-5611/17/3/314; Broit C., 1981, OPTIMAL REGISTRATION; Christensen G. E., 1994, THESIS WASHINGTON U; Christensen GE, 1999, LECT NOTES COMPUT SC, V1613, P224; Droske M, 2003, SIAM J APPL MATH, V64, P668, DOI 10.1137/S0036139902419528; Dupuis P, 1998, Q APPL MATH, V56, P587, DOI 10.1090/qam/1632326; FIACCO AV, 1991, CLASSICS APPL MATH; Fitzpatrick J. M., 2000, HDB MED IMAGING, V2, P447; GOLUB GH, 1979, TECHNOMETRICS, V21, P215, DOI 10.1080/00401706.1979.10489751; Haber E, 2006, SIAM J SCI COMPUT, V27, P1594, DOI 10.1137/040608106; Haber E, 2004, INVERSE PROBL, V20, P1621, DOI 10.1088/0266-5611/20/5/018; HABER E, 2004, JCP, V115, P1; HABER E, 2004, UNPUB IEEE TMI; Maintz J B, 1998, Med Image Anal, V2, P1, DOI 10.1016/S1361-8415(01)80026-8; MAINTZ JB, 2000, IEEE TMI, V19, P809; *MATH WORKS, 1992, MATLAB US GUID; Miller MI, 2002, ANNU REV BIOMED ENG, V4, P375, DOI 10.1146/annurev.bioeng.4.092101.125733; Miller MI, 2001, INT J COMPUT VISION, V41, P61, DOI 10.1023/A:1011161132514; Modersitzki J, 2004, NUMER MATH SCI COMP; Peckar W, 1999, J MATH IMAGING VIS, V10, P143, DOI 10.1023/A:1008375006703; Rohlfing T, 2003, IEEE T MED IMAGING, V22, P730, DOI 10.1109/TMI.2003.814791; TROTTENBERG U., 2000, MULTIGRID; Trouve A, 1998, INT J COMPUT VISION, V28, P213, DOI 10.1023/A:1008001603737; TWINING CJ, 2003, P IPMI; Wahba G., 1990, SPLINE MODELS OBSERV; Wells W M 3rd, 1996, Med Image Anal, V1, P35; Zhu L, 2003, LECT NOTES COMPUT SC, V2879, P277; Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9	31	56	57	0	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2007	71	3					361	372		10.1007/s11263-006-8984-4	http://dx.doi.org/10.1007/s11263-006-8984-4			12	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	104CB					2022-12-18	WOS:000241932400005
J	Slabaugh, GG; Culbertson, WB; Malzbender, T; Stevens, MR; Schafer, RW				Slabaugh, GG; Culbertson, WB; Malzbender, T; Stevens, MR; Schafer, RW			Methods for volumetric reconstruction of visual scenes	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						scene reconstruction; voxel coloring; space carving; photo-consistency; histogram intersection; volumetric warping	CONSTRUCTION; STEREO	In this paper, we present methods for 3D volumetric reconstruction of visual scenes photographed by multiple calibrated cameras placed at arbitrary viewpoints. Our goal is to generate a 3D model that can be rendered to synthesize new photo-realistic views of the scene. We improve upon existing voxel coloring/space carving approaches by introducing new ways to compute visibility and photo-consistency, as well as model infinitely large scenes. In particular, we describe a visibility approach that uses all possible color information from the photographs during reconstruction, photo-consistency measures that are more robust and/or require less manual intervention, and a volumetric warping method for application of these reconstruction methods to large-scale scenes.	Siemens Corp Res, Intelligent Vis & Reasoning Dept, Princeton, NJ 08540 USA; Hewlett Packard Labs, Visual Comp Dept, Palo Alto, CA 94304 USA; Charles River Anal Inc, Cambridge, MA 02138 USA; Georgia Inst Technol, Ctr Signal & Image Proc, Atlanta, GA 30318 USA	Siemens AG; Hewlett-Packard; University System of Georgia; Georgia Institute of Technology	Slabaugh, GG (corresponding author), Siemens Corp Res, Intelligent Vis & Reasoning Dept, Princeton, NJ 08540 USA.	greg.slabaugh@scr.siemens.com; bruce_culbertson@hp.com; tom_malzbender@hp.com; mstevens@cra.com; rws@ece.gatech.edu		Slabaugh, Greg/0000-0003-4060-5226				Beardsley P., 1996, P EUR C COMP VIS, P683; BHOTIKA R, 2002, P EUR C COMP VIS, V3, P112; BLINN JF, 1976, COMMUN ACM, V19, P542, DOI [10.1145/360349.360353, 10.1145/965143.563322]; BOLLES RC, 1987, INT J COMPUT VISION, V1, P7, DOI 10.1007/BF00128525; Broadhurst A, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P388, DOI 10.1109/ICCV.2001.937544; Carceroni RL, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P60; CHHABRA V, 2001, THESIS WORCHESTER PO; Colosimo A, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P181, DOI 10.1109/ICIP.2001.958454; CULBERTSON WB, 1999, SPRINGER VERLAG LECT, V1883, P100; De Bonet J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P418, DOI 10.1109/ICCV.1999.791251; Debevec P. E., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P11, DOI 10.1145/237170.237191; Dyer Charles R, 2001, FDN IMAGE UNDERSTAND, P469; Eisert P, 1999, INT CONF ACOUST SPEE, P3509, DOI 10.1109/ICASSP.1999.757599; Eisert P, 2000, IEEE T CIRC SYST VID, V10, P261, DOI 10.1109/76.825726; Faugeras O, 1998, IEEE T IMAGE PROCESS, V7, P336, DOI 10.1109/83.661183; Faugeras O. D., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, P485, DOI 10.1142/S0218001488000285; FUA P, 1995, INT J COMPUT VISION, V16, P35, DOI 10.1007/BF01428192; Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200; GREENE N, 1986, IEEE COMPUT GRAPH, P21; Jebara T, 1999, IEEE SIGNAL PROC MAG, V16, P66, DOI 10.1109/79.768574; JOHANSSON B, 1999, P ICCV, V1, P54; Kimura M., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P135, DOI 10.1109/ICIP.1999.817086; KUTULAKOS K, 1999, INT C COMP VIS ICCV, V1, P307; Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; LIVINGSTON M, 2001, HPL2001226R1; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; MATUSIK W, 2000, P SIGGRAPH, P367; Max N., 1996, Rendering Techniques '96. Proceedings of the Eurographics Workshop. Eurographics, P165; MCMILLAN M, 1995, P SIGGRAPH, P39; NARAYANAN PJ, 1998, P INT C COMP VIS; OZUN O, 2002, THESIS MIDDLE E TU; Pfister H, 2000, COMP GRAPH, P335, DOI 10.1145/344779.344936; POLLEFEYS M, 1999, P 2 INT C 3D DIG IM, P14; Prock AC, 1998, P IM UND WORKSH, P315; Saito H., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P49, DOI 10.1109/CVPR.1999.784607; SAVARESE S, 2001, P INT C COMP VIS, V1, P190; Seitz SM, 1999, INT J COMPUT VISION, V35, P151, DOI 10.1023/A:1008176507526; Shade J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P231, DOI 10.1145/280814.280882; Shum HY, 1998, PROC CVPR IEEE, P427, DOI 10.1109/CVPR.1998.698641; Slabaugh G, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P704, DOI 10.1109/TDPVT.2002.1024145; Slabaugh G, 2001, SPRING EUROGRAP, P81; SLABAUGH G, 2000, P WORKSH 3D STRUCT M, P41; SLABAUGH G, 2002, THESIS GEORGIA I TEC; Steinbach E, 2000, IEEE IMAGE PROC, P569, DOI 10.1109/ICIP.2000.901022; STEVENS M, 1999, THESIS COLORADO STAT; Stevens MR, 2002, INT C PATT RECOG, P118, DOI 10.1109/ICPR.2002.1047413; SZELISKI R, 1993, CVGIP-IMAG UNDERSTAN, V58, P23, DOI 10.1006/ciun.1993.1029; Szeliski R, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P517, DOI 10.1109/ICCV.1998.710766; TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109; Vedula S, 2000, PROC CVPR IEEE, P592, DOI 10.1109/CVPR.2000.854926; WEGHORST H, 1984, ACM T GRAPHIC, V3, P52, DOI 10.1145/357332.357335; Yezzi AJ, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P59, DOI 10.1109/ICCV.2001.937499	54	56	66	0	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY-JUN	2004	57	3					179	199		10.1023/B:VISI.0000013093.45070.3b	http://dx.doi.org/10.1023/B:VISI.0000013093.45070.3b			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	766DR		Green Accepted			2022-12-18	WOS:000188330600002
J	Bartoli, A; Sturm, P				Bartoli, A; Sturm, P			Constrained structure and motion from multiple uncalibrated views of a piecewise planar scene	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						3D reconstruction; piecewise planar scene; constrained structure and motion; maximum likelihood estimator	AUTOCALIBRATION; ROBUST	This paper is about multi-view modeling of a rigid scene. We merge the traditional approaches of reconstructing image-extractable features and of modeling via user-provided geometry. We use features to obtain a first guess for structure and motion, fit geometric primitives, correct the structure so that reconstructed features lie exactly on geometric primitives and optimize both structure and motion in a bundle adjustment manner while enforcing the underlying constraints. We specialize this general scheme to the point features and the plane geometric primitives. The underlying geometric relationships are described by multi-coplanarity constraints. We propose a minimal parameterization of the structure enforcing these constraints and use it to devise the corresponding maximum likelihood estimator. The recovered primitives are then textured from the input images. The result is an accurate and photorealistic model. Experimental results using simulated data confirm that the accuracy of the model using the constrained methods is of clearly superior quality compared to that of traditional methods and that our approach performs better than existing ones, for various scene configurations. In addition, we observe that the method still performs better in a number of configurations when the observed surfaces are not exactly planar. We also validate our method using real images.	INRIA Rhone Alpes, F-38334 Saint Ismier, France		Bartoli, A (corresponding author), INRIA Rhone Alpes, 655 Ave Europe, F-38334 Saint Ismier, France.	Adrien.Bartoli@inria.fr; Peter.Sturm@inria.fr						Alon J, 2000, PROC CVPR IEEE, P550, DOI 10.1109/CVPR.2000.854911; ATKINSON KB, 1996, CLOSE RANGE PHOTOGRA; Baillard C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P559, DOI 10.1109/CVPR.1999.784966; Bartoli A, 2001, VIRTUAL AND AUGMENTED ARCHITECTURE (VAA'01), P195; BARTOLI A, 2001, P 8 INT C COMP VIS V, V1, P593; BEARDSLEY PA, 1996, LNCS, V1065, P683; BERTHILSSON R, 1998, P 6 INT C COMP VIS B, P72; CROSS G, 2000, NATO ADV RES WORKSH, P25; DEBEVEC PE, 1996, SIGGRAPH 96 NEW ORL; DICK AR, 2001, P 8 INT C COMP VIS V; Faugeras O. D., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, P485, DOI 10.1142/S0218001488000285; Fornland P, 1997, PROC CVPR IEEE, P508, DOI 10.1109/CVPR.1997.609373; Gill P. E., 1981, PRACTICAL OPTIMIZATI; Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200; Hartley RI, 1997, COMPUT VIS IMAGE UND, V68, P146, DOI 10.1006/cviu.1997.0547; HARTLEY RI, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1064; HEYDEN A, 1998, P 3 AS C COMP VIS HO, V2, P169; HEYDEN A, 1995, WORKSH REPR VIS SCEN, P45; HORN BKP, 1988, J OPT SOC AM A, V5, P1127, DOI 10.1364/JOSAA.5.001127; Kahl F, 2000, J MATH IMAGING VIS, V13, P131, DOI 10.1023/A:1026524030731; Kutulakos K. N., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P307, DOI 10.1109/ICCV.1999.791235; LANG F, 1996, P 18 ISPRS C VIENN A; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; MALIS E, 2000, LNCS, V1843, P610; MAYBANK SJ, 1992, INT J COMPUT VISION, V8, P123, DOI 10.1007/BF00127171; MCGLONE C, 1996, P 18 ISPRS C VIENN A, P529; NIEM W, 1994, P SOC PHOTO-OPT INS, V2182, P388, DOI 10.1117/12.171088; Pollefeys M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P90, DOI 10.1109/ICCV.1998.710705; POLLEFEYS M, 2000, P 19 ISPRS C AMST B, V5, P619; Pollefeys M., 1999, THESIS KATHOLIEKE U; Seitz SM, 1997, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.1997.609462; Sinclair D, 1996, INT J COMPUT VISION, V18, P77, DOI 10.1007/BF00126141; Slama CC., 1980, MANUAL PHOTOGRAMMETR, V4th edn; STREILEIN A, 1995, P INT CAAD FUT C SIN; Sturm P, 2000, IEEE T PATTERN ANAL, V22, P1199, DOI 10.1109/34.879804; STURM P, 1999, P BRIT MACH VIS C NO, P63; Sturm P., 1996, LECT NOTES COMPUTER, V1065, P709, DOI [DOI 10.1007/3-540-61123-1, 10.1007/3-540-61123-1_183, DOI 10.1007/3-540-61123-1_183]; SZELISKI R, 1993, CVGIP-IMAG UNDERSTAN, V58, P23, DOI 10.1006/ciun.1993.1029; SZELISKI R, 1998, 3D STRUCTURE MULTIPL; TAREL JP, 1995, P SCAND C IM AN UPPS, P1061; Triggs B, 1997, PROC CVPR IEEE, P609, DOI 10.1109/CVPR.1997.609388; TRIGGS B, 1998, 3D STRUCTURE MULTIPL; Triggs B., 1998, P 5 EUR C COMP VIS F; TRIGGS B, 2000, LECT NOTES COMPUTER, V1883, P298, DOI DOI 10.1007/3-540-44480-7; Vieville T, 1996, INT J COMPUT VISION, V20, P213, DOI 10.1007/BF00208720; XU G, 2000, P C COMP VIS PATT RE; Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561	47	56	59	0	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	2003	52	1					45	64		10.1023/A:1022318524906	http://dx.doi.org/10.1023/A:1022318524906			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	643XD					2022-12-18	WOS:000180887700003
J	Tschumperle, D; Deriche, R				Tschumperle, D; Deriche, R			Orthonormal vector sets regularization with PDE's and applications	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	1st IEEE Workshop on Variational and Level Set Methods in Computer Vision	JUL 07-13, 2001	VANCOUVER, CANADA	Siemens Corp Res, Inst Natl Rech Informat & Automat, IEEE Comp Soc Tech Council Pattern Analysis & Machine Intelligence		partial differential equations (PDE); constrained vector-valued regularization; orientation features; anisotropic diffusion; orthogonal matrices	ANISOTROPIC DIFFUSION; EDGE-DETECTION; SCALE-SPACE; COLOR; MAPS; IMAGES	We are interested in regularizing fields of orthonormal vector sets, using constraint-preserving anisotropic diffusion PDE's. Each point of such a field is defined by multiple orthogonal and unitary vectors and can indeed represent a lot of interesting orientation features such as direction vectors or orthogonal matrices (among other examples). We first develop a general variational framework that solves this regularization problem, thanks to a constrained minimization of phi-functionals. This leads to a set of coupled vector-valued PDE's preserving the orthonormal constraints. Then, we focus on particular applications of this general framework, including the restoration of noisy direction fields, noisy chromaticity color images, estimated camera motions and DT-MRI (Diffusion Tensor MRI) datasets.	INRIA Sophia Antipolis, Odyssee Lab, F-06902 Sophia Antipolis, France		Tschumperle, D (corresponding author), INRIA Sophia Antipolis, Odyssee Lab, F-06902 Sophia Antipolis, France.	David.Tschumperle@sophia.inria.fr; Rachid.Deriche@sophia.inria.fr	Deriche, Rachid/AAM-9869-2021	Deriche, Rachid/0000-0002-4643-8417				Acton ST, 1998, IEEE T IMAGE PROCESS, V7, P280, DOI 10.1109/83.661178; Alvarez L, 2002, J VIS COMMUN IMAGE R, V13, P3, DOI 10.1006/jvci.2001.0482; ALVAREZ L, 1992, SIAM J NUMER ANAL, V29, P845, DOI 10.1137/0729052; Bertalmio M, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P186, DOI 10.1109/VLSM.2001.938899; Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972; Blomgren P, 1998, IEEE T IMAGE PROCESS, V7, P304, DOI 10.1109/83.661180; Caselles V, 1998, IEEE T IMAGE PROCESS, V7, P269, DOI 10.1109/TIP.1998.661176; Chambolle A, 1997, NUMER MATH, V76, P167, DOI 10.1007/s002110050258; Chan T, 2000, SIAM J APPL MATH, V61, P1338, DOI 10.1137/S003613999935799X; CHAN T, 2000, J VISUAL COMMUNICATI, V12; Chan TE, 2000, J VIS COMMUN IMAGE R, V11, P130, DOI 10.1006/jvci.1999.0442; Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P436, DOI 10.1006/jvci.2001.0487; Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844; CHARBONNIER P, 1994, IEEE IMAGE PROC, P168; Chefd'hotel C, 2002, P ECCV 02; COHEN L, 1995, INT C COMP VIS; COTTET GH, 1993, MATH COMPUT, V61, P659, DOI 10.1090/S0025-5718-1993-1195422-2; COULON O, 2001, GEOMETRICAL APPROACH; COULON O, 2001, 17 INT C INF PROC ME; DIBOS F, 1998, 9801 CEREMADE URACNR; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; GEMAN S, 1985, AM STAT ASS, P12; Granlund G.H., 1995, SIGNAL PROCESSING CO; Kimmel R, 1997, LECT NOTES COMPUT SC, V1252, P236; Kimmel R, 2000, INT J COMPUT VISION, V39, P111, DOI 10.1023/A:1008171026419; Kimmel R, 2002, J VIS COMMUN IMAGE R, V13, P238, DOI 10.1006/jvci.2001.0501; Kornprobst P, 1997, PROC CVPR IEEE, P325, DOI 10.1109/CVPR.1997.609344; KORNPROBST P, 1998, 11 C RFIA AFCET JAN, V1, P277; KORNPROBST P, 1997, P INT C IM PROC SANT, V4, P458; KOSCHAN A, 1995, P 2 AS C COMP VIS AC, V3, P574; Le Bihan D, 2000, MAGNETIC RESONANCE I; Malladi R, 1996, GRAPH MODEL IM PROC, V58, P127, DOI 10.1006/gmip.1996.0011; MOREL J.-M., 1988, REV MAT COMPLUT, V1, P169; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; NIKOLOVA M, 2001, P INT C IM PROC; NORDSTROM KN, 1990, IMAGE VISION COMPUT, V8, P318, DOI 10.1016/0262-8856(90)80008-H; OSHER S, 1990, SIAM J NUMER ANAL, V27, P919, DOI 10.1137/0727053; Paragios N, 2002, J VIS COMMUN IMAGE R, V13, P249, DOI 10.1006/jvci.2001.0475; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Perona P, 1998, IEEE T IMAGE PROCESS, V7, P457, DOI 10.1109/83.661195; Poupon C, 1998, LECT NOTES COMPUT SC, V1496, P489, DOI 10.1007/BFb0056234; POUPON C, 1999, THESIS ECOLE NATL SU; PROESMANS M, 1994, COUPLED GEOMETRY DRI, P191; ROMENY BMT, 1994, COMPUTATIONAL IMAGIN; Rudin L. I., 1994, Proceedings ICIP-94 (Cat. No.94CH35708), P31, DOI 10.1109/ICIP.1994.413269; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Sapiro G, 1996, PROC CVPR IEEE, P680, DOI 10.1109/CVPR.1996.517146; Sapiro G, 1996, IEEE T IMAGE PROCESS, V5, P1582, DOI 10.1109/83.541429; SAPIRO G, 1997, COMPUTER VISION IMAG, V68; Sapiro G., 2001, GEOMETRIC PARTIAL DI; SHAH J, 1996, INT C COMP VIS PATT; STERNBERG P, 1991, ROCKY MT J MATH, V21, P799, DOI 10.1216/rmjm/1181072968; STRONG DM, 1996, 46 UCLA; STRONG DM, 1996, P IEEE WORKSH MATH M; Tang B, 2000, INT J COMPUT VISION, V36, P149, DOI 10.1023/A:1008152115986; Teboul S, 1998, IEEE T IMAGE PROCESS, V7, P387, DOI 10.1109/83.661189; Tikhonov AN, 1963, SOV MATH DOKL, V4, P1624; Tschumperle D., 2001, Proceedings of 12th Scandinavian Conference on Image Analysis, P153; Tschumperle D, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P3, DOI 10.1109/VLSM.2001.938875; TSCHUMPERLE D, 2001, IEEE COMP SOC C COMP; TSCHUMPERLE D, 2002, IEEE SIGNAL PROCESSI; VEMURI B, 2001, 1 IEEE WORKSH VAR LE; VESE LA, 2002, SIAM 50 ANN ANN M; Weickert J, 1997, LECT NOTES COMPUT SC, V1252, P3; Weickert J, 1999, J MATH IMAGING VIS, V10, P237, DOI 10.1023/A:1008344623873; Weickert J, 2001, INT J COMPUT VISION, V45, P245, DOI 10.1023/A:1013614317973; Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1; YOU YL, 1994, IEEE IMAGE PROC, P497, DOI 10.1109/ICIP.1994.413620	69	56	57	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	2002	50	3					237	252		10.1023/A:1020870207168	http://dx.doi.org/10.1023/A:1020870207168			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	607XU					2022-12-18	WOS:000178816700002
J	BATTITI, R; AMALDI, E; KOCH, C				BATTITI, R; AMALDI, E; KOCH, C			COMPUTING OPTICAL-FLOW ACROSS MULTIPLE SCALES - AN ADAPTIVE COARSE-TO-FINE STRATEGY	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							VISUAL-MOTION; COMPUTATIONAL THEORY; IMAGE SEQUENCES; PERCEPTION; VISION; SELECTIVITY; RELAXATION; MODELS; FIELDS	Single-scale approaches to the determination of the optical flow field from the time-varying brightness pattern assume that spatio-temporal discretization is adequate for representing the patterns and motions in a scene. However, the choice of an appropriate spatial resolution is subject to conflicting, scene-dependent, constraints. In intensity-based methods for recovering optical flow, derivative estimation is more accurate for long wavelengths and slow velocities (with respect to the spatial and temporal discretization steps). On the contrary, short wavelengths and fast motions are required in order to reduce the errors caused by noise in the image acquisition and quantization process. Estimating motion across different spatial scales should ameliorate this problem. However, homogeneous multiscale approaches, such as the standard multigrid algorithm, do not improve this situation, because an optimal velocity estimate at a given spatial scale is likely to be corrupted at a finer scale. We propose an adaptive multiscale method, where the discretization scale is chosen locally according to an estimate of the relative error in the velocity estimation, based on image properties. Results for synthetic and video-acquired images show that our coarse-to-fine method, fully parallel at each scale, provides substantially better estimates of optical flow than do conventional algorithms, while adding little computational cost.	CALTECH,DIV BIOL 216-76,COMP & NEURAL SYST PROGRAM,PASADENA,CA 91125	California Institute of Technology			Battiti, Roberto/C-2108-2009	Battiti, Roberto/0000-0002-0259-8603; Koch, Christof/0000-0001-6482-8067				ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; BATTITI R, 1990, THESIS CALTECH; BATTITI R, 1989, 4TH P C HYP CONC COM; BULTHOFF H, 1989, NATURE, V337, P549, DOI 10.1038/337549a0; Burt P.J., 1984, MULTIRESOLUTION IMAG, P6; ENKELMANN W, 1988, COMPUT VISION GRAPH, V43, P150, DOI 10.1016/0734-189X(88)90059-X; FENNEMA CL, 1979, COMPUT VISION GRAPH, V9, P301, DOI 10.1016/0146-664X(79)90097-2; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GIROSI F, 1989, MAR P IEEE WORKSH VI, P116; GLAZER F, 1984, MULTIRESOLUTION IMAG, P312; HARRIS JG, 1990, INT J COMPUT VISION, V4, P211, DOI 10.1007/BF00054996; HASSENSTEIN B, 1956, Z NATURFORSCH PT B, V11, P513; HILDRETH EC, 1984, ARTIF INTELL, V23, P309, DOI 10.1016/0004-3702(84)90018-3; HILDRETH EC, 1987, ANNU REV NEUROSCI, V10, P477, DOI 10.1146/annurev.ne.10.030187.002401; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HUTCHINSON J, 1988, IEEE COMPUT, V21, P52; KAMGARPARSI B, 1989, IEEE T PATTERN ANAL, V11, P929, DOI 10.1109/34.35496; KOCH C, 1989, J EXP BIOL, V146, P115; LITTLE J, 1989, MAR P IEEE WORKSH VI, P173; MARR D, 1981, PROC R SOC SER B-BIO, V211, P151, DOI 10.1098/rspb.1981.0001; MARROQUIN JL, 1984, MIT792 ART INT LAB M; MAUNSELL JHR, 1983, J NEUROPHYSIOL, V49, P1127, DOI 10.1152/jn.1983.49.5.1127; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; NAGEL HH, 1978, 4TH P INT JOINT C PA; POGGIO T, 1988, SCIENCE, V242, P436, DOI 10.1126/science.3175666; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; POGGIO T, 1973, KYBERNETIK, V13, P223, DOI 10.1007/BF00274887; REICHARDT W, 1988, NATURWISSENSCHAFTEN, V75, P313, DOI 10.1007/BF00367326; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P129, DOI 10.1109/TPAMI.1986.4767767; ULLMAN S, 1981, IEEE COMPUT, V14, P57; URAS S, 1988, BIOL CYBERN, V60, P79, DOI 10.1007/BF00202895; VANSANTEN JPH, 1984, J OPT SOC AM A, V1, P451, DOI 10.1364/JOSAA.1.000451; VERRI A, 1989, IEEE T PATTERN ANAL, V11, P490, DOI 10.1109/34.24781; WANG HT, 1991, IN PRESS ADV NEURAL; WANG HT, 1989, NEURAL COMPUT, V1, P92; WATSON AB, 1985, J OPT SOC AM A, V2, P322, DOI 10.1364/JOSAA.2.000322; YUILLE AL, 1988, NATURE, V333, P71, DOI 10.1038/333071a0	39	56	63	0	6	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	1991	6	2					133	145		10.1007/BF00128153	http://dx.doi.org/10.1007/BF00128153			13	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	FW779		Green Accepted			2022-12-18	WOS:A1991FW77900003
J	Wang, Q; Gao, JY; Lin, W; Yuan, Y				Wang, Qi; Gao, Junyu; Lin, Wei; Yuan, Yuan			Pixel-Wise Crowd Understanding via Synthetic Data	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Crowd analysis; Pixel-wise understanding; Crowd counting; Crowd segmentation; Synthetic data generation	ANOMALY DETECTION	Crowd analysis via computer vision techniques is an important topic in the field of video surveillance, which has wide-spread applications including crowd monitoring, public safety, space design and so on. Pixel-wise crowd understanding is the most fundamental task in crowd analysis because of its finer results for video sequences or still images than other analysis tasks. Unfortunately, pixel-level understanding needs a large amount of labeled training data. Annotating them is an expensive work, which causes that current crowd datasets are small. As a result, most algorithms suffer from over-fitting to varying degrees. In this paper, take crowd counting and segmentation as examples from the pixel-wise crowd understanding, we attempt to remedy these problems from two aspects, namely data and methodology. Firstly, we develop a free data collector and labeler to generate synthetic and labeled crowd scenes in a computer game, Grand Theft Auto V. Then we use it to construct a large-scale, diverse synthetic crowd dataset, which is named as "GCC Dataset". Secondly, we propose two simple methods to improve the performance of crowd understanding via exploiting the synthetic data. To be specific, (1) supervised crowd understanding: pre-train a crowd analysis model on the synthetic data, then fine-tune it using the real data and labels, which makes the model perform better on the real world; (2) crowd understanding via domain adaptation: translate the synthetic data to photo-realistic images, then train the model on translated data and labels. As a result, the trained model works well in real crowd scenes.Extensive experiments verify that the supervision algorithm outperforms the state-of-the-art performance on four real datasets: UCF_CC_50, UCF-QNRF, and Shanghai Tech Part A/B Dataset. The above results show the effectiveness, values of synthetic GCC for the pixel-wise crowd understanding. The tools of collecting/labeling data, the proposed synthetic dataset and the source code for counting models are available at.	[Wang, Qi; Gao, Junyu; Lin, Wei; Yuan, Yuan] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China; [Wang, Qi; Gao, Junyu; Lin, Wei; Yuan, Yuan] Northwestern Polytech Univ, Ctr Opt Imagery Anal & Learning OPTIMAL, Xian 710072, Shaanxi, Peoples R China	Northwestern Polytechnical University; Northwestern Polytechnical University	Yuan, Y (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.; Yuan, Y (corresponding author), Northwestern Polytech Univ, Ctr Opt Imagery Anal & Learning OPTIMAL, Xian 710072, Shaanxi, Peoples R China.	crabwq@gmail.com; gjy3035@gmail.com; elonlin24@gmail.com; y.yuan1.ieee@gmail.com	Yuan, Yuan/GVS-5120-2022; Yuan, Yuan/ABB-2379-2020; Gao, Junyu/GLU-4957-2022	Lin, Wei/0000-0001-8425-956X; Wang, Qi/0000-0002-7028-4956	National Key R&D Program of China [2017YFB1002202]; National Natural Science Foundation of China [U1864204, 61773316, 61632018, 61825603]	National Key R&D Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported by the National Key R&D Program of China under Grant 2017YFB1002202, National Natural Science Foundation of China under Grant U1864204, 61773316, 61632018, and 61825603.	Abu-El-Haija S., 2016, ARXIV; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Bak S., 2018, ARXIV180410094; Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45; Chan AB, 2008, PROC CVPR IEEE, P1766, DOI 10.1109/cvpr.2008.4587569; Chan AB, 2009, IEEE I CONF COMP VIS, P545, DOI 10.1109/ICCV.2009.5459191; Chandler A, 2009, UBICOMP'09: PROCEEDINGS OF THE 11TH ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P101; Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dong L, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1011; Dosovitskiy A., 2017, C ROBOT LEARNING, P1; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Fu M, 2015, ENG APPL ARTIF INTEL, V43, P81, DOI 10.1016/j.engappai.2015.04.006; Gao JY, 2020, IEEE T CIRC SYST VID, V30, P3486, DOI 10.1109/TCSVT.2019.2919139; Gao Junyu, 2019, ARXIV PREPRINT ARXIV; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Idrees H., 2018, ARXIV180801050; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Johnston-Hollitt M, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P1, DOI 10.1145/3038912.3050769; Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90; Kang K., 2014, FULLY CONVOLUTIONAL, V1411, P4464; Kempka M., 2016, 2016 IEEE C COMP INT, P1; Kingma D.P, P 3 INT C LEARNING R; Li CL, 2019, IEEE T PATTERN ANAL, V41, P2770, DOI 10.1109/TPAMI.2018.2864965; Li T, 2015, IEEE T CIRC SYST VID, V25, P367, DOI 10.1109/TCSVT.2014.2358029; Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111; Li XT, 2017, AAAI CONF ARTIF INTE, P2210; Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120; Lian DZ, 2019, PROC CVPR IEEE, P1821, DOI 10.1109/CVPR.2019.00192; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu J, 2018, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2018.00545; Liu Lingbo, 2018, ARXIV180700601; Liu WZ, 2019, PROC CVPR IEEE, P5094, DOI 10.1109/CVPR.2019.00524; Liu X., 2018, ARXIV180303095; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; MAHADEVAN V, 2010, PROC CVPR IEEE, P1975, DOI DOI 10.1109/CVPR.2010.5539872; Marsden M, 2016, ARXIV161200220; Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641; Onoro-Rubio D, 2016, LECT NOTES COMPUT SC, V9911, P615, DOI 10.1007/978-3-319-46478-7_38; Pan X., 2017, ARXIV171206080; Paszke A., 2017, PYTORCH TENSORS DYNA, V1st; Popoola OP, 2012, IEEE T SYST MAN CY C, V42, P865, DOI 10.1109/TSMCC.2011.2178594; Qiu W, 2017, ACM MULTIMEDIA OPEN; Ranjan V., 2018, ARXIV180709959; Richter S, 2017, PROC SPIE, V10094, DOI 10.1117/12.2250389; Richter SR, 2016, LECT NOTES COMPUT SC, V9906, P102, DOI 10.1007/978-3-319-46475-6_7; ROS G, 2016, PROC CVPR IEEE, P3234, DOI DOI 10.1109/CVPR.2016.352; Sam D. B., 2017, CVPR; Sam DB, 2018, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2018.00381; Sam Deepak Babu, 2018, ARXIV180709993; Sam Deepak Babu Neeraj N., 2019, P 33 AAAI C ART INT, V27; Shah S., 2018, FIELD SERVICE ROBOTI, P621, DOI 10.1007/978-3-319-67361-5_40; Shen Z, 2018, PROC CVPR IEEE, P5245, DOI 10.1109/CVPR.2018.00550; Shi ZL, 2018, PROC CVPR IEEE, P5382, DOI 10.1109/CVPR.2018.00564; Sindagi V. A., 2017, ADV VIDEO SIGNAL BAS, V14, P1, DOI DOI 10.1109/AVSS.2017.8078491; Sindagi VA, 2020, TECHNICAL REPORT LAR; Sindagi VA, 2019, IEEE I CONF COMP VIS, P1221, DOI 10.1109/ICCV.2019.00131; Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206; Walach E, 2016, LECT NOTES COMPUT SC, V9906, P660, DOI 10.1007/978-3-319-46475-6_41; Wan J, 2019, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2019.00416; Wang C, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1299, DOI 10.1145/2733373.28063370-12345-67-8/90/01; Wang Q., 2020, ARXIV200103360; Wang Q, 2019, PROC CVPR IEEE, P8190, DOI 10.1109/CVPR.2019.00839; Wang Q, 2020, IEEE T PATTERN ANAL, V42, P46, DOI 10.1109/TPAMI.2018.2875002; Wang Q, 2018, IEEE T CIRC SYST VID, V28, P2633, DOI 10.1109/TCSVT.2017.2703920; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Xiong F., 2017, ARXIV170707890; Yan ZY, 2019, IEEE I CONF COMP VIS, P952, DOI 10.1109/ICCV.2019.00104; Yuan Y, 2015, IEEE T CYBERNETICS, V45, P562, DOI 10.1109/TCYB.2014.2330853; Zhang C, 2016, IEEE T MULTIMEDIA, V18, P1048, DOI 10.1109/TMM.2016.2542585; Zhang WH, 2019, PR IEEE COMP DESIGN, P613, DOI 10.1109/ICCD46524.2019.00088; Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70; Zhao MM, 2019, PROC CVPR IEEE, P12728, DOI 10.1109/CVPR.2019.01302; Zhu J.-Y., 2017, ARXIV170310593; Zuo WM, 2019, IEEE T PATTERN ANAL, V41, P1158, DOI 10.1109/TPAMI.2018.2829180	78	55	57	1	21	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2021	129	1								10.1007/s11263-020-01365-4	http://dx.doi.org/10.1007/s11263-020-01365-4		AUG 2020	21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	PU0KV		Green Submitted			2022-12-18	WOS:000564116900001
J	Saleemi, I; Shah, M				Saleemi, Imran; Shah, Mubarak			Multiframe Many-Many Point Correspondence for Vehicle Tracking in High Density Wide Area Aerial Videos	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Wide area aerial surveillance; Multi target tracking; Multiframe data association; Multiple hypothesis; Multiple candidate tracking; CLIF dataset	ALGORITHM; ASSIGNMENTS	This paper presents a novel framework for tracking thousands of vehicles in high resolution, low frame rate, multiple camera aerial videos. The proposed algorithm avoids the pitfalls of global minimization of data association costs and instead maintains multiple object-centric associations for each track. Representation of object state in terms of many to many data associations per track is proposed and multiple novel constraints are introduced to make the association problem tractable while allowing sharing of detections among tracks. Weighted hypothetical measurements are introduced to better handle occlusions, mis-detections and split or merged detections. A two-frame differencing method is presented which performs simultaneous moving object detection in both. Two novel contextual constraints of vehicle following model, and discouragement of track intersection and merging are also proposed. Extensive experiments on challenging, ground truthed data sets are performed to show the feasibility and superiority of the proposed approach. Results of quantitative comparison with existing approaches are presented, and the efficacy of newly introduced constraints is experimentally established. The proposed algorithm performs better and faster than global, 1-1 data association methods.	[Saleemi, Imran; Shah, Mubarak] Univ Cent Florida, Dept Elect Engn & Comp Sci, Orlando, FL 32816 USA	State University System of Florida; University of Central Florida	Saleemi, I (corresponding author), Univ Cent Florida, Dept Elect Engn & Comp Sci, 4000 Cent Florida Blvd, Orlando, FL 32816 USA.	imran@eecs.ucf.edu; shah@eecs.ucf.edu		Shah, Mubarak/0000-0001-6172-5572				Ablavsky V., 2008, CVPR; Bazzani L., 2010, ICIP; Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21; Breitenstein M., 2009, ICCV KYOT; Cox IJ, 1996, IEEE T PATTERN ANAL, V18, P138, DOI 10.1109/34.481539; Cox IJ, 1997, IEEE T AERO ELEC SYS, V33, P295, DOI 10.1109/7.570789; Cucchiara R., 2000, IEEE Transactions on Intelligent Transportation Systems, V1, P119, DOI 10.1109/6979.880969; Danchick R, 2006, IEE P-RADAR SON NAV, V153, P13, DOI 10.1049/ip-rsn:20050041; DURRANTWHYTE HF, 1988, INT J ROBOT RES, V7, P97, DOI 10.1177/027836498800700608; EDIE LC, 1961, OPER RES, V9, P66, DOI 10.1287/opre.9.1.66; GAZIS DC, 1959, OPER RES, V7, P499, DOI 10.1287/opre.7.4.499; Grabner H., 2008, ECCV; Hinton GE, 1999, IEE CONF PUBL, P1, DOI 10.1049/cp:19991075; Huang KQ, 2008, PATTERN RECOGN, V41, P432, DOI 10.1016/j.patcog.2007.05.017; Kang J., 2003, ICCV PETS WORKSH NIC; Kikuchi S., 1992, TRANSP RES REC, V82; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; Mann S, 1997, IEEE T IMAGE PROCESS, V6, P1281, DOI 10.1109/83.623191; MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003; MURTY KG, 1968, OPER RES, V16, P682, DOI 10.1287/opre.16.3.682; NAGEL K, 1992, J PHYS I, V2, P2221, DOI 10.1051/jp1:1992277; NEWELL GF, 1961, OPER RES, V9, P209, DOI 10.1287/opre.9.2.209; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Perera AG Amitha, 2006, CVPR; Porikli F., 2009, AVSS; REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177; Reilly Vladimir, 2010, ECCV, P7; Schubert R., 2008, ICIF SHANGH; Schulz D., 2001, ICRA SEOUL; Shafique K, 2005, IEEE T PATTERN ANAL, V27, P51, DOI 10.1109/TPAMI.2005.1; SHALOM YB, 1988, TRACKING DATA ASS; Shamos M., 1976, 17 ANN S FDN COMP SC, P208; Song B., 2010, ECCV; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; USAF, 2006, COL LARG IM FORM DAT; Vezzani R., 2009, ICIAP VIETR MAR; Wang GL, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS, VOLS 1-6, P2961, DOI 10.1109/ICAL.2008.4636684; Xiao J., 2010, CVPR; XIAO J, 2008, CVPR; Xing J., 2009, CVPR; Yang M., 2009, ICCV; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; Yin Z., 2006, OTCBVS KOK	44	55	56	0	24	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2013	104	2					198	219		10.1007/s11263-013-0624-1	http://dx.doi.org/10.1007/s11263-013-0624-1			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	189FD					2022-12-18	WOS:000322251800005
J	Liwicki, S; Tzimiropoulos, G; Zafeiriou, S; Pantic, M				Liwicki, Stephan; Tzimiropoulos, Georgios; Zafeiriou, Stefanos; Pantic, Maja			Euler Principal Component Analysis	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Euler PCA; Robust subspace; Online learning; Tracking; Background modeling	COMPUTER VISION; TRACKING; SURVEILLANCE; SYSTEM	Principal Component Analysis (PCA) is perhaps the most prominent learning tool for dimensionality reduction in pattern recognition and computer vision. However, the a"" (2)-norm employed by standard PCA is not robust to outliers. In this paper, we propose a kernel PCA method for fast and robust PCA, which we call Euler-PCA (e-PCA). In particular, our algorithm utilizes a robust dissimilarity measure based on the Euler representation of complex numbers. We show that Euler-PCA retains PCA's desirable properties while suppressing outliers. Moreover, we formulate Euler-PCA in an incremental learning framework which allows for efficient computation. In our experiments we apply Euler-PCA to three different computer vision applications for which our method performs comparably with other state-of-the-art approaches.	[Liwicki, Stephan; Tzimiropoulos, Georgios; Zafeiriou, Stefanos; Pantic, Maja] Univ London Imperial Coll Sci Technol & Med, Dept Comp, London SW7 2AZ, England; [Tzimiropoulos, Georgios] Lincoln Univ, Sch Comp Sci, Lincoln LN6 7TS, England; [Pantic, Maja] Univ Twente, Fac Elect Engn Math & Comp Sci, NL-7500 AE Enschede, Netherlands	Imperial College London; University of Lincoln; University of Twente	Liwicki, S (corresponding author), Univ London Imperial Coll Sci Technol & Med, Dept Comp, 180 Queens Gate, London SW7 2AZ, England.	sl609@imperial.ac.uk; gtzimiropoulos@lincoln.ac.uk; s.zafeiriou@imperial.ac.uk; m.pantic@imperial.ac.uk		Tzimiropoulos, Georgios/0000-0002-1803-5338	European Research Council (ERC) [ERC-2007- StG-203143]; Engineering and Physical Science Research Council DTA Studentship; European Community [288235]	European Research Council (ERC)(European Research Council (ERC)European Commission); Engineering and Physical Science Research Council DTA Studentship; European Community(European Commission)	The research presented in this paper is supported in part by the European Research Council (ERC) under the ERC Starting Grant Agreement ERC-2007- StG-203143 (MAH-NOB). The work of S. Liwicki is supported by the Engineering and Physical Science Research Council DTA Studentship. The work of G. Tzimiropoulos is currently supported in part by the European Community's 7th Framework Programme FP7/2007-2013 under Grant Agreement 288235 (FROG).	[Anonymous], 2002, PRINCIPAL COMPONENT; Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53; Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226; Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737; Candes E. J., 2009, ROBUST PRINCIPAL COM; Chin TJ, 2007, IEEE T IMAGE PROCESS, V16, P1662, DOI 10.1109/TIP.2007.896668; Chin TJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P461; Cohn JF, 1999, PSYCHOPHYSIOLOGY, V36, P35, DOI 10.1017/S0048577299971184; Collins RT, 2001, P IEEE, V89, P1456, DOI 10.1109/5.959341; Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991; De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986; Ding C., 2006, PROC INT C MACH LEAR, P281, DOI DOI 10.1145/1143844.1143880; Fitch AJ, 2005, IEEE T IMAGE PROCESS, V14, P1063, DOI 10.1109/TIP.2005.849767; Fraundorfer F, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P3878; Gunawan H, 2005, BEITRAGE ALGEBRA GEO, V46, P311; Handmann U, 1998, P SOC PHOTO-OPT INS, V3364, P136, DOI 10.1117/12.317463; Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683; Hashima M., 1997, Proceedings of the 1997 IEEE/RSJ International Conference on Intelligent Robot and Systems. Innovative Robotics for Real-World Applications. IROS '97 (Cat. No.97CH36108), P345, DOI 10.1109/IROS.1997.649076; He R, 2011, IEEE T IMAGE PROCESS, V20, P1485, DOI 10.1109/TIP.2010.2103949; Honeine P, 2011, IEEE SIGNAL PROC MAG, V28, P77, DOI 10.1109/MSP.2010.939747; Hsieh JW, 2006, IEEE T INTELL TRANSP, V7, P175, DOI 10.1109/TITS.2006.874722; Kamijo S., 2000, IEEE Transactions on Intelligent Transportation Systems, V1, P108, DOI 10.1109/6979.880968; Ke Q., 2003, CMUCS03172 COMP SCI; Ke QF, 2005, PROC CVPR IEEE, P739; KRZANOWSKI WJ, 1979, J AM STAT ASSOC, V74, P703, DOI 10.2307/2286995; Kwak N, 2008, IEEE T PATTERN ANAL, V30, P1672, DOI 10.1109/TPAMI.2008.114; Kwok JTY, 2004, IEEE T NEURAL NETWOR, V15, P1517, DOI 10.1109/TNN.2004.837781; Levy A, 2000, IEEE T IMAGE PROCESS, V9, P1371, DOI 10.1109/83.855432; Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169; Li YM, 2004, PATTERN RECOGN, V37, P1509, DOI 10.1016/j.patcog.2003.11.010; Liu WF, 2007, IEEE T SIGNAL PROCES, V55, P5286, DOI 10.1109/TSP.2007.896065; Liwicki Stephan, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P50, DOI 10.1109/CVPR.2009.5204291; Luo Y, 2003, COMPUT VIS IMAGE UND, V92, P196, DOI 10.1016/j.cviu.2003.08.001; Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285; Martinez A.M., 1998, 24 OH STAT U; Mei X., 2009, ICCV 09; Mika S, 1999, ADV NEUR IN, V11, P536; Nguyen M. H., 2009, P ADV NEUR INF PROC, P1185; Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684; Paulsen V. I., 2009, INTRO THEORY REPROD; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Tzimiropoulos G, 2012, IEEE T PATTERN ANAL, V34, P2454, DOI 10.1109/TPAMI.2012.40; Tzimiropoulos G, 2010, IEEE T PATTERN ANAL, V32, P1899, DOI 10.1109/TPAMI.2010.107; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236	46	55	61	13	76	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	FEB	2013	101	3			SI		498	518		10.1007/s11263-012-0558-z	http://dx.doi.org/10.1007/s11263-012-0558-z			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	086WF		Green Accepted, Green Submitted			2022-12-18	WOS:000314719000007
J	Eshel, R; Moses, Y				Eshel, Ran; Moses, Yael			Tracking in a Dense Crowd Using Multiple Cameras	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Tracking; Detection; Multiple-view	HUMANS; MOTION	Tracking people in a dense crowd is a challenging problem for a single camera tracker due to occlusions and extensive motion that make human segmentation difficult. In this paper we suggest a method for simultaneously tracking all the people in a densely crowded scene using a set of cameras with overlapping fields of view. To overcome occlusions, the cameras are placed at a high elevation and only people's heads are tracked. Head detection is still difficult since each foreground region may consist of multiple subjects. By combining data from several views, height information is extracted and used for head segmentation. The head tops, which are regarded as 2D patches at various heights, are detected by applying intensity correlation to aligned frames from the different cameras. The detected head tops are then tracked using common assumptions on motion direction and velocity. The method was tested on sequences in indoor and outdoor environments under challenging illumination conditions. It was successful in tracking up to 21 people walking in a small area (2.5 people per m(2)), in spite of severe and persistent occlusions.	[Eshel, Ran; Moses, Yael] Interdisciplinary Ctr, Efi Arazi Sch Comp Sci, IL-46150 Herzliyya, Israel	Reichman University	Eshel, R (corresponding author), Interdisciplinary Ctr, Efi Arazi Sch Comp Sci, IL-46150 Herzliyya, Israel.	eshel.ran@idc.ac.il; yael@idc.ac.il						Ali S, 2008, LECT NOTES COMPUT SC, V5303, P1, DOI 10.1007/978-3-540-88688-4_1; ARSIC D, 2008, INT C DISTR SMART CA; Brostow G.J., 2006, P IEEE INT C COMP VI, P594, DOI DOI 10.1109/CVPR.2006.320; Cai Q, 1999, IEEE T PATTERN ANAL, V21, P1241, DOI 10.1109/34.809119; Cheung GKM, 2000, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2000.854944; Du W, 2007, LECT NOTES COMPUT SC, V4843, P365; Eshel R., 2008, 2008 IEEE C COMP VIS; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Felzenszwalb PF, 2001, PROC CVPR IEEE, P1056; Fleuret Francois, 2007, IEEE T PATTERN ANAL, V3; Franco JS, 2005, IEEE I CONF COMP VIS, P1747; GARIBOTTO G, 2005, P INT C IM PROC ICIP, P105; GAVRILA DM, 1999, P IEEE INT C COMP VI, P87, DOI DOI 10.1109/ICCV.1999.791202; GOLDSCHMIDT R, 2008, PRACTICAL CALIBRATIO; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594; Kettnaker V., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P253, DOI 10.1109/CVPR.1999.784638; Khan SM, 2006, LECT NOTES COMPUT SC, V3954, P133; KHAN SM, 2007, P INT C COMP VIS ICC; Kim K, 2006, LECT NOTES COMPUT SC, V3953, P98; Kobayashi Yoshinori, 2006, P BRIT MACH VIS C BM; Krumm J., 2000, INT WORKSH VIS SURV; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; Leibe B, 2005, PROC CVPR IEEE, P878; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; Mittal A, 2003, INT J COMPUT VISION, V51, P189, DOI 10.1023/A:1021849801764; MITTAL A, 2001, P IEEE WORKSH MULT T; NUMMIARO K, 2003, GERM PATT REC S, P591; Orwell J, 1999, SECOND IEEE WORKSHOP ON VISUAL SURVEILLANCE (VS'99), PROCEEDINGS, P14, DOI 10.1109/VS.1999.780264; PAPAGEORGIOU C, 1998, IEEE C INT VEH, P35; Polana R., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P77, DOI 10.1109/MNRAO.1994.346251; QUARITSCH M, 2007, J EMBEDDED SYSTEMS, P10; Rodriguez M. D., 2007, P INT C MULT, P353, DOI DOI 10.1145/1291233.1291310; Shashua A, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P1; Smith K, 2005, PROC CVPR IEEE, P962; Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8; Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7; Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355; YU Q, 2007, P IEEE C COMP VIS PA; Zhao T, 2004, IEEE T PATTERN ANAL, V26, P1208, DOI 10.1109/TPAMI.2004.73	40	55	58	0	13	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2010	88	1					129	143		10.1007/s11263-009-0307-0	http://dx.doi.org/10.1007/s11263-009-0307-0			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	571LS					2022-12-18	WOS:000275753900007
J	Lalonde, JF; Narasimhan, SG; Efros, AA				Lalonde, Jean-Francois; Narasimhan, Srinivasa G.; Efros, Alexei A.			What Do the Sun and the Sky Tell Us About the Camera?	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Sky; Camera calibration; Physics-based vision; Time-lapse video; Camera geolocation	MODELS	As the main observed illuminant outdoors, the sky is a rich source of information about the scene. However, it is yet to be fully explored in computer vision because its appearance in an image depends on the sun position, weather conditions, photometric and geometric parameters of the camera, and the location of capture. In this paper, we analyze two sources of information available within the visible portion of the sky region: the sun position, and the sky appearance. By fitting a model of the predicted sun position to an image sequence, we show how to extract camera parameters such as the focal length, and the zenith and azimuth angles. Similarly, we show how we can extract the same parameters by fitting a physically-based sky model to the sky appearance. In short, the sun and the sky serve as geometric calibration targets, which can be used to annotate a large database of image sequences. We test our methods on a high-quality image sequence with known camera parameters, and obtain errors of less that 1% for the focal length, 1A degrees for azimuth angle and 3A degrees for zenith angle. We also use our methods to calibrate 22 real, low-quality webcam sequences scattered throughout the continental US, and show deviations below 4% for focal length, and 3A degrees for the zenith and azimuth angles. Finally, we demonstrate that by combining the information available within the sun position and the sky appearance, we can also estimate the camera geolocation, as well as its geometric parameters. Our method achieves a mean localization error of 110 km on real, low-quality Internet webcams. The estimated viewing and illumination geometry of the scene can be useful for a variety of vision and graphics tasks such as relighting, appearance analysis and scene recovery.	[Lalonde, Jean-Francois; Narasimhan, Srinivasa G.; Efros, Alexei A.] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Lalonde, JF (corresponding author), Carnegie Mellon Univ, Sch Comp Sci, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	jlalonde@cs.cmu.edu; srinivas@cs.cmu.edu; efros@cs.cmu.edu		Efros, Alexei A./0000-0001-5720-8070; Lalonde, Jean-Francois/0000-0002-6583-2364	ONR [N00014-08-1-0330]; NSF [IIS-0643628, CCF-0541307, CCF-0541230]	ONR(Office of Naval Research); NSF(National Science Foundation (NSF))	The authors would like to thank Nathan Jacobs for sharing his webcam dataset and for fruitful discussions. We would also like to thank Tom Stepleton, and especially Mohit Gupta for very helpful suggestions in reviewing this paper. This research is supported in parts by an ONR grant N00014-08-1-0330 and NSF grants IIS-0643628, CCF-0541307 and CCF-0541230. A. Efros is grateful to the WILLOW team at ENS Paris for their hospitality. Parts of the results presented in this paper have previously appeared in Lalonde et al. (2008b).	Bitouk D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360638; Buluswar SD, 2002, COMPUT VIS IMAGE UND, V85, P71, DOI 10.1006/cviu.2001.0950; CHIAO CC, 2000, J OPTICAL SOC AM, V17; *COMM C T, 1994, CIE1101994 COMM CT I; COZMAN F, 1995, IEEE INT CONF ROBOT, P106, DOI 10.1109/ROBOT.1995.525271; Debevec P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P189, DOI 10.1145/280814.280864; Debevec P., 1997, P ACM SIGGRAPH 1997, DOI [DOI 10.1145/258734.258884, 10.1145/258734.258884]; Debevec P., 2004, ACM T GRAPHIC, V1, P1; Dror R, 2004, J VISION, V4, P821, DOI 10.1167/4.9.11; Forsyth David A, 2012, COMPUTER VISION MODE; GROSS R, 2004, HDB FACE RECOGNITION; Hill Roger D., 1994, P227; Hoiem D, 2005, IEEE I CONF COMP VIS, P654; INEICHEN P, 1994, SOL ENERGY, V52, P337, DOI 10.1016/0038-092X(94)90140-6; JACOBS N, 2008, WORKSH APPL COMP VIS; Jacobs N, 2007, IEEE I CONF COMP VIS, P1305; KHAN EA, 2006, ACM T GRAPHICS S AUG; Kim SJ, 2008, IEEE T PATTERN ANAL, V30, P562, DOI 10.1109/TPAMI.2007.70732; KIM SJ, 2008, IEEE C COMP VIS PATT; KOPPAL SJ, 2006, IEEE INT C COMP VIS; KUTHIRUMMAL S, 2008, EUR C COMP VIS; Lalonde JF, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239454, 10.1145/1276377.1276381]; LALONDE JF, 2008, CMURITR0832; LALONDE JF, 2009, ACM T GRAPHICS SIGGR; LALONDE JF, 2008, EUR C COMP VIS; LIN S, 2004, IEEE C COMP VIS PATT; Manduchi R, 2006, IEEE T PATTERN ANAL, V28, P1713, DOI 10.1109/TPAMI.2006.231; Narasimhan Srinivasa G, 2002, LNCS, P2, DOI DOI 10.1007/3-540-47977-5_10; PEREZ R, 1993, SOL ENERGY, V50, P235, DOI 10.1016/0038-092X(93)90017-I; Preetham AJ, 1999, COMP GRAPH, P91, DOI 10.1145/311535.311545; Reda I., 2005, NRELTP56034302; Sato Y., 1995, Proceedings of the Workshop on Physics-Based Modeling in Computer Vision (Cat. No.95TB8038), P180, DOI 10.1109/PBMCV.1995.514684; SLATER D, 1998, IEEE C COMP VIS PATT; Stumpfel J., 2004, P AFRIGRAPH, P145, DOI DOI 10.1145/1185657.1185687; Sunkavalli K, 2008, PROC CVPR IEEE, P541; Sunkavalli K, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239552, 10.1145/1276377.1276504]; Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228; Trebi-Ollennu A, 2001, IEEE T ROBOTIC AUTOM, V17, P939, DOI 10.1109/70.976028; Tsin Y, 2001, PROC CVPR IEEE, P1132; Weiss Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P68, DOI 10.1109/ICCV.2001.937606; Yu Y., 1998, P ACM SIGGRAPH 1998; ZHENG Y, 2006, IEEE C COMP VIS PATT	42	55	58	0	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2010	88	1					24	51		10.1007/s11263-009-0291-4	http://dx.doi.org/10.1007/s11263-009-0291-4			28	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	571LS					2022-12-18	WOS:000275753900002
J	Matthews, I; Xiao, J; Baker, S				Matthews, Iain; Xiao, Jing; Baker, Simon			2D vs. 3D deformable face models: Representational power, construction, and real-time fitting	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						model-based face analysis; 2D Active Appearance Models; 3D Morphable Models; representational power; model construction; non-rigid structure-from-motion; factorization; real-time fitting; the inverse compositional algorithm; constrained fitting	MOTION; SHAPE	Model-based face analysis is a general paradigm with applications that include face recognition, expression recognition, lip-reading, head pose estimation, and gaze estimation. A face model is first constructed from a collection of training data, either 2D images or 3D range scans. The face model is then fit to the input image(s) and the model parameters used in whatever the application is. Most existing face models can be classified as either 2D (e.g. Active Appearance Models) or 3D (e.g. Morphable Models). In this paper we compare 2D and 3D face models along three axes: (1) representational power, (2) construction, and (3) real-time fitting. For each axis in turn, we outline the differences that result from using a 2D or a 3D face model.	Epson Res & Dev, Epson Palo Alto Lab, San Jose, CA 95131 USA; Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA; Microsoft Corp, Microsoft Res, Redmond, WA 98052 USA	Carnegie Mellon University; Microsoft	Matthews, I (corresponding author), Microsoft Corp, Microsoft Res, Redmond, WA 98052 USA.	iainm@cs.cmu.edu; jing.xiaoj@gmail.com; sbaker@microsoft.com						Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Baker S, 2001, PROC CVPR IEEE, P1090; Baker S., 2004, CMURITR0464; BAKER S, 2004, CMURITR0414; Baker S., 2003, CMURITR0335; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; BLANZ V, 2003, P EUROGRAPHICS; Brand M, 2001, PROC CVPR IEEE, P456; BREGLER C, 2000, P IEEE C COMP VIS PA; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; GROSS R, 2004, P IEEE WORKSH FAC PR, P72; Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606; Ishikawa T., IEEE T INTELLIGENT T; Kanade T., 1973, THESIS KYOTO U; Koterba S, 2005, IEEE I CONF COMP VIS, P511; Lanitis A, 1997, IEEE T PATTERN ANAL, V19, P743, DOI 10.1109/34.598231; Lucas B.D., 1981, ITERATIVE IMAGE REGI, P674; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; Matthews I, 2002, IEEE T PATTERN ANAL, V24, P198, DOI 10.1109/34.982900; MATTHEWS I, 2006, CMURITR0612; Romdhani S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P59; Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647; SHUM HY, 2000, INT J COMPUT VISION, V16, P63; Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torresani L, 2001, PROC CVPR IEEE, P493; Xiao J, 2004, PROC CVPR IEEE, P535; XIAO J, 2004, P EUR C COMP VIS, V4, P573; Xiao J, 2006, INT J COMPUT VISION, V67, P233, DOI 10.1007/s11263-005-3962-9	29	55	64	0	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	OCT	2007	75	1					93	113		10.1007/s11263-007-0043-2	http://dx.doi.org/10.1007/s11263-007-0043-2			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	197RM		Green Submitted			2022-12-18	WOS:000248574200006
J	Fitzgibbon, A; Wexler, Y; Zisserman, A				Fitzgibbon, A; Wexler, Y; Zisserman, A			Image-based rendering using image-based priors	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	9th IEEE International Conference on Computer Vision	OCT 13-16, 2003	NICE, FRANCE	IEEE Comp Soc, TC Pattern Anal & Machine Intelligence		new view synthesis; image-based rendering		Given a set of images acquired from known viewpoints, we describe a method for synthesizing the image which would be seen from a new viewpoint. In contrast to existing techniques, which explicitly reconstruct the 3D geometry of the scene, we transform the problem to the reconstruction of colour rather than depth. This retains the benefits of geometric constraints, but projects out the ambiguities in depth estimation which occur in textureless regions. On the other hand, regularization is still needed in order to generate high-quality images. The paper's second contribution is to constrain the generated views to lie in the space of images whose texture statistics are those of the input images. This amounts to an image-based prior on the reconstruction which regularizes the solution, yielding realistic synthetic views. Examples are given of new view generation for cameras interpolated between the acquisition viewpoints-which enables synthetic steadicam stabilization of a sequence with a high level of realism.	Univ Oxford, Oxford OX1 2JD, England; Weizmann Inst Sci, IL-76100 Rehovot, Israel	University of Oxford; Weizmann Institute of Science	Fitzgibbon, A (corresponding author), Univ Oxford, Oxford OX1 2JD, England.	awf@robots.ox.ac.uk; yonatan.wexler@weizmann.ac.il; az@robots.ox.ac.uk						BESAG J, 1986, J R STAT SOC B, V48, P259; BROADHURST A, 2001, P ICCV; Debevec P. E., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P11, DOI 10.1145/237170.237191; EFROS A, 1999, P ICCV, P1039; Freeman W. T., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1182, DOI 10.1109/ICCV.1999.790414; GORTLER SJ, 1996, SIG GRAPH96; Grenander U, 2001, IEEE T PATTERN ANAL, V23, P424, DOI 10.1109/34.917579; HUANG J, 1999, P CVPR, P1541; IRANI M, 2002, P ECCV; Koch R., 2001, Multi-Image Analysis. 10th International Workshop on Theoretical Foundations of Computer Vision. Revised Papers (Lecture Notes in Computer Science Vol.2032), P51; KOCH R, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P109, DOI 10.1109/ICCV.1995.466799; Kutulakos K. N., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P307, DOI 10.1109/ICCV.1999.791235; LEVOY M, 1996, SIG GRAPH96; Matusik W, 2000, COMP GRAPH, P369, DOI 10.1145/344779.344951; MATUSIK W, 2002, P ACMSIGGRAPH; MCMILLAN L, 1995, SIGGRAPH95; Rademacher P, 1999, COMP GRAPH, P439, DOI 10.1145/311535.311612; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; SCHARSTEIN D, 1999, LNCS, V1583; Seitz SM, 1997, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.1997.609462; SMINCHISESCU C, 2002, P ECCV, V1, P566; Srivastava A, 2003, J MATH IMAGING VIS, V18, P17, DOI 10.1023/A:1021889010444; Szeliski R, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P517, DOI 10.1109/ICCV.1998.710766; Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009; WEXLER Y, 2001, P BMVC	25	55	72	0	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2005	63	2					141	151		10.1007/s11263-005-6643-9	http://dx.doi.org/10.1007/s11263-005-6643-9			11	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	925JK					2022-12-18	WOS:000229049200003
J	Van Meerbergen, G; Vergauwen, M; Pollefeys, M; Van Gool, L				Van Meerbergen, G; Vergauwen, M; Pollefeys, M; Van Gool, L			A hierarchical symmetric stereo algorithm using dynamic programming	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						stereo vision; hierarchical stereo algorithm; dynamic programming; disparity computation; symmetric stereo	PIXEL	In this paper, a new hierarchical stereo algorithm is presented. The algorithm matches individual pixels in corresponding scanlines by minimizing a cost function. Several cost functions are compared. The algorithm achieves a tremendous gain in speed and memory requirements by implementing it hierarchically. The images are downsampled an optimal number of times and the disparity map of a lower level is used as 'offset' disparity map at a higher level. An important contribution consists of the complexity analysis of the algorithm. It is shown that this complexity is independent of the disparityrange. This result is also used to determine the optimal number of downsample levels. This speed gain results in the ability to use more complex (compute intensive) cost functions that deliver high quality disparity maps. Another advantage of this algorithm is that cost functions can be chosen independent of the optimisation algorithm. The algorithm in this paper is symmetric, i.e. exactly the same matches are found if left and right image are swapped. Finally, the algorithm was carefully implemented so that a minimal amount of memory is used. It has proven its efficiency on large images with a high disparity range as well as its quality. Examples are given in this paper.	Katholieke Univ Leuven, ESAT, PSI, B-3001 Louvain, Belgium	KU Leuven	Van Meerbergen, G (corresponding author), Katholieke Univ Leuven, ESAT, PSI, B-3001 Louvain, Belgium.		Vergauwen, Maarten/B-6498-2018; Pollefeys, Marc/I-7607-2013	Vergauwen, Maarten/0000-0003-3465-9033; 				Birchfield S, 1999, INT J COMPUT VISION, V35, P269, DOI 10.1023/A:1008160311296; Birchfield S, 1998, IEEE T PATTERN ANAL, V20, P401, DOI 10.1109/34.677269; Birchfield S., 1999, THESIS STANFORD U; Boykov Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P377, DOI 10.1109/ICCV.1999.791245; COX I, 1996, COMPUTER VISION IMAG, V63; DHOND UR, 1989, IEEE T SYST MAN CYB, V19, P1489, DOI 10.1109/21.44067; Falkenhagen L., 1994, IMAGE PROCESSING BRO, P115; FALKENHAGEN L, 1997, P INT WORKSH SNHC 3D, P115; Hartley R., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P761, DOI 10.1109/CVPR.1992.223179; INTILLE SS, 1994, P 3 EUR C COMP VIS, P179; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; OKUTOMI M, 1992, INT J COMPUT VISION, V7, P143, DOI 10.1007/BF00128133; ROY S, 1998, P INT C COMP VIS BOM; [No title captured]	14	55	57	1	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR-JUN	2002	47	1-3					275	285		10.1023/A:1014562312225	http://dx.doi.org/10.1023/A:1014562312225			11	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	530JN					2022-12-18	WOS:000174354700020
J	Basri, R; Rivlin, E; Shimshoni, I				Basri, R; Rivlin, E; Shimshoni, I			Visual homing: Surfing on the epipoles	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						visual navigation; camera motion computation; robot navigation; visual servoing	PERSPECTIVE VIEWS; MOBILE ROBOT; MOTION; NAVIGATION; REPRESENTATION; LOCALIZATION; ALGORITHM; OBJECT	We introduce a novel method for visual homing. Using this method a robot can be sent to desired positions and orientations in 3D space specified by single images taken from these positions. Our method is based on recovering the epipolar geometry relating the current image taken by the robot and the target image. Using the epipolar geometry, most of the parameters which specify the differences in position and orientation of the camera between the two images are recovered. However, since not all of the parameters can be recovered from two images, we have developed specific methods to bypass these missing parameters and resolve the ambiguities that exist. We present two homing algorithms for two standard projection models, weak and full perspective. Our method determines the path of the robot on-line, the starting position of the robot is relatively not constrained, and a 3D model of the environment is not required. The method is almost entirely memoryless, in the sense that at every step the path to the target position is determined independently of the previous path taken by the robot. Because of this property the robot may be able, while moving toward the target, to perform auxiliary tasks or to avoid obstacles, without this impairing its ability to eventually reach the target position. We have performed simulations and real experiments which demonstrate the robustness of the method and that the algorithms always converge to the target pose.	Weizmann Inst Sci, Dept Appl Math, IL-76100 Rehovot, Israel; Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel; Technion Israel Inst Technol, Dept Ind Engn & Management, IL-32000 Haifa, Israel	Weizmann Institute of Science; Technion Israel Institute of Technology; Technion Israel Institute of Technology	Basri, R (corresponding author), Weizmann Inst Sci, Dept Appl Math, IL-76100 Rehovot, Israel.							BASRI R, 1995, ARTIF INTELL, V78, P327, DOI 10.1016/0004-3702(95)00021-6; Basri R, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P863, DOI 10.1109/ICCV.1998.710818; BEARDSLEY PA, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P58, DOI 10.1109/ICCV.1995.466806; BRADSHAW KJ, 1994, IMAGE VISION COMPUT, V12, P155, DOI 10.1016/0262-8856(94)90067-1; Dudek G, 1996, IEEE INT CONF ROBOT, P76, DOI 10.1109/ROBOT.1996.503576; ESPIAU B, 1992, IEEE T ROBOTIC AUTOM, V8, P313, DOI 10.1109/70.143350; FAYMAN JA, 1996, INT C PATT REC; FENNEMA C, 1990, IEEE T SYST MAN CYB, V20, P1352, DOI 10.1109/21.61206; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; HASHIMOTO K, 1993, VISUAL SERVOING; Hong J., 1992, IEEE Control Systems Magazine, V12, P38, DOI 10.1109/37.120451; HUANG TS, 1989, IEEE T PATTERN ANAL, V11, P536, DOI 10.1109/34.24786; Hutchinson S, 1996, IEEE T ROBOTIC AUTOM, V12, P651, DOI 10.1109/70.538972; JENKIN MRM, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P806, DOI 10.1109/CVPR.1994.323903; KONTSEVICH LL, 1993, J OPT SOC AM A, V10, P1129, DOI 10.1364/JOSAA.10.001129; Kruppa E., 1913, SITZ BER AKAD WIS MN, V122, P1939; LEE CH, 1990, COMPUT VISION GRAPH, V52, P309, DOI 10.1016/0734-189X(90)90078-A; LEVITT TS, 1990, ARTIF INTELL, V44, P305, DOI 10.1016/0004-3702(90)90027-W; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; MADSEN CB, 1989, IEEE T PATTERN ANAL, V19, P158; Matsumoto Y, 1996, IEEE INT CONF ROBOT, P83, DOI 10.1109/ROBOT.1996.503577; More J., 1980, ANL8074; NELSON B, 1993, PROCEEDINGS : IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, pC418; NELSON RC, 1989, DARPA IM UND WORKSH, P245; PAHLAVAN K, 1992, CVGIP-IMAG UNDERSTAN, V56, P41, DOI 10.1016/1049-9660(92)90084-G; PRETLOVE J, 1991, P 22 INT S ROB RES; Pritchett P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P754, DOI 10.1109/ICCV.1998.710802; SHAPIRO LS, 1995, INT J COMPUT VISION, V16, P147, DOI 10.1007/BF01539553; Shimshoni I, 1999, IEEE T PATTERN ANAL, V21, P252, DOI 10.1109/34.754615; Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710; Torr P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P485, DOI 10.1109/ICCV.1998.710762; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779; Wilkes D., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P136, DOI 10.1109/CVPR.1992.223215; YI X, 1997, IEEE C COMP VIS PATT, P962; ZHENG JY, 1992, INT J COMPUT VISION, V9, P55; Zipser D, 1986, PARALLEL DISTRIBUTED, V2, P432	39	55	57	0	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	1999	33	2					117	137		10.1023/A:1008194012143	http://dx.doi.org/10.1023/A:1008194012143			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	247MF					2022-12-18	WOS:000083224000002
J	Fua, P				Fua, P			From multiple stereo views to multiple 3-D surfaces	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						stereo; shape; particles and object representation	MODELS; IMAGES	We present a framework for 3-dimensional surface reconstruction that can be used to model fully 3-D scenes from an arbitrary number of stereo views taken from vastly different viewpoints. This is a key step toward producing 3-D world-descriptions of complex scenes using stereo and is a very challenging problem: real-world scenes tend to contain many 3-D objects, they do not usually conform to the 2-1/2-D assumption made by traditional algorithms, and one cannot take it for granted that the computed 3-D points can easily be clustered into separate groups. Furthermore, stereo data is often incomplete and sometimes erroneous, which makes the problem even more difficult. By combining a particle-based representation, robust fitting, and optimization of an image-based objective function, we have been able to reconstruct surfaces without any a priori knowledge of their topology and in spite of the noisiness of the stereo data. Our current implementation goes through three steps-initializing a set of particles from the input 3-D data, optimizing their location, and finally grouping them into global surfaces. Using several complex scenes containing multiple objects, we demonstrate the competence of this method and its ability to merge information and thus to go beyond what can be done with conventional stereo alone.	ECOLE POLYTECH FED LAUSANNE,LIG,CH-1015 LAUSANNE,SWITZERLAND	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Fua, P (corresponding author), SRI INT,333 RAVENSWOOD AVE,MENLO PK,CA 94025, USA.			Fua, Pascal/0000-0002-6702-9970				BEATON AE, 1974, TECHNOMETRICS, V16, P147, DOI 10.2307/1267936; BLACK MJ, 1994, C COMP VIS PATT REC, P121; CERNUSCHIFRIAS B, 1984, IEEE T PATTERN ANAL, V6, P430, DOI 10.1109/TPAMI.1984.4767548; CHEN Y, 1994, C COMP VIS PATT REC, P437; COHEN I, 1991, C COMP VIS PATT REC, P738; DELINGETTE H, 1991, C COMP VIS PATT REC, P467; DEVERNAY F, 1994, CVPR, P208; FERRIE FP, 1992, EUR C COMP VIS GEN I; Fua P., 1993, Machine Vision and Applications, V6, P35, DOI 10.1007/BF01212430; FUA P, 1995, INT J COMPUT VISION, V16, P35, DOI 10.1007/BF01428192; FUA P, 1997, COMPUTER VISION  FEB; Guelch E., 1988, INT ARCH PHOT REM SE, V27, P254; Hannah M., 1988, INT SOC PHOTOGRAMM R, V27, P280; HEIPKE C, 1992, INT SOC PHOTOGRAMMET, P832; HOFF W, 1987, INT C COMP VIS; HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011; HOTZ B, 1993, WORKSH COMP VIS SPAC, P33; KOH E, 1994, EUR C COMP VIS STOCK; Leonardis A., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P121, DOI 10.1109/ICCV.1990.139508; LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043; Nishihara H. K., 1984, OPTICAL ENG, V23; PARK J, 1994, C COMP VIS PATT REC, P437; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660; PENTLAND AP, 1990, INT J COMPUT VISION, V4, P107, DOI 10.1007/BF00127812; Rissanen J., 1987, ENCY STATISTICAL SCI, V5, P523; ROBERT L, 1992, ECAI 92 - 10TH EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE : PROCEEDINGS, P821; SANDER PT, 1990, IEEE T PATTERN ANAL, V12, P833, DOI 10.1109/34.57680; SHEWCHUK JR, 1994, CS94125 CMU; STEWART CV, 1994, C COMP VIS PATT REC, P167; STOKELY EM, 1992, IEEE T PATTERN ANAL, V14, P833, DOI 10.1109/34.149594; SZELISKI R, 1992, COMP GRAPH, V26, P185, DOI 10.1145/142920.134037; TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659; Terzopoulos D., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P70, DOI 10.1109/CVPR.1991.139663; VEMURI BC, 1991, JUN P IEEE C COMP VI, P724; WROBEL BP, 1991, PHOTOGRAMM REC, V13, P765, DOI 10.1111/j.1477-9730.1991.tb00738.x; ZHANG Z, 1990, 9TH P EUR C ART INT, P747; [No title captured]	37	55	59	0	0	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	1997	24	1					19	35		10.1023/A:1007918123901	http://dx.doi.org/10.1023/A:1007918123901			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	XV644		Green Submitted			2022-12-18	WOS:A1997XV64400002
J	Zhang, BC; Perina, A; Li, ZG; Murino, V; Liu, JZ; Ji, RR				Zhang, Baochang; Perina, Alessandro; Li, Zhigang; Murino, Vittorio; Liu, Jianzhuang; Ji, Rongrong			Bounding Multiple Gaussians Uncertainty with Application to Object Tracking	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Uncertainty principle; Object tracking; MGU	VISUAL TRACKING	This paper proves the uncertainty bound for the multiple Gaussian functions, termed multiple Gaussians Uncertainty (MGU), which significantly generalizes the uncertainty principle for the single Gaussian function. First, as a theoretical contribution, we prove that the momentum (velocity) and position for the sum of multiple Gaussians wave function are theoretically bounded. Second, as for a practical application, we show that the bound can be well exploited for object tracking to detect anomalies of local movement in an online learning framework. By integrating MGU with a given object tracker, we demonstrate that uncertainty principle can provide remarkable robustness in tracking. Extensive experiments are done to show that the proposed MGU can significantly help base trackers overcome the object drifting and reach state-of-the-art results.	[Zhang, Baochang; Li, Zhigang] Beihang Univ, Sch Automat Sci & Elect Engn, Beijing 100191, Peoples R China; [Ji, Rongrong] Xiamen Univ, Sch Informat Sci & Engn, Fujian Key Lab Sensing & Comp Smart City, Xiamen, Peoples R China; [Perina, Alessandro; Murino, Vittorio] IIT, Pattern Anal & Comp Vis PAVIS, Genoa, Italy; [Liu, Jianzhuang] Huawei Technol Co Ltd, Media Lab, Shenzhen 518129, Peoples R China	Beihang University; Xiamen University; Istituto Italiano di Tecnologia - IIT; Huawei Technologies	Ji, RR (corresponding author), Xiamen Univ, Sch Informat Sci & Engn, Fujian Key Lab Sensing & Comp Smart City, Xiamen, Peoples R China.	bczhang@buaa.edu.cn; jirongrong@gmail.com		Murino, Vittorio/0000-0002-8645-2328	Natural Science Foundation of China [61272052, 61473086]; Program for New Century Excellent Talents University of Ministry of Education of China; National Basic Research Program of China [2015CB352501]; Special Fund for Earthquake Research in the Public Interest [201508025]; Open Projects Program of National Laboratory of Pattern Recognition; Nature Science Foundation of China [61422210, 61373076]	Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Program for New Century Excellent Talents University of Ministry of Education of China(Program for New Century Excellent Talents in University (NCET)); National Basic Research Program of China(National Basic Research Program of China); Special Fund for Earthquake Research in the Public Interest; Open Projects Program of National Laboratory of Pattern Recognition; Nature Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported in the part by Natural Science Foundation of China, under Contracts 61272052 and 61473086, and by the Program for New Century Excellent Talents University of Ministry of Education of China, and the National Basic Research Program of China (2015CB352501). The work of R. Ji is supported by the Special Fund for Earthquake Research in the Public Interest No. 201508025, the Open Projects Program of National Laboratory of Pattern Recognition, and the Nature Science Foundation of China (Nos. 61422210 and 61373076). Thanks for the suggestions from Alessio Del Bue and Wanquan Liu to improve the paper. Alessandro Perina and Zhigang Li have the same contribution to the paper.	Ali S, 2008, P ECCV; Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53; Babenko B., 2011, IEEE T PAMI, V6; Betke M, 2007, PROC CVPR IEEE, P192; Bischof H., 2006, BMVC, P47; Born, 1926, ANALEN PHYS, P79; Brostow G.J., 2006, P IEEE INT C COMP VI, P594, DOI DOI 10.1109/CVPR.2006.320; Canny J., 2009, IEEE T PATTERN ANAL; Cehovin L, 2013, IEEE T PATTERN ANAL, V35, P941, DOI 10.1109/TPAMI.2012.145; Chu CT, 2013, IEEE T MULTIMEDIA, V15, P1602, DOI 10.1109/TMM.2013.2266634; Cui P, 2009, IEEE T MULTIMEDIA, V11, P333, DOI 10.1109/TMM.2008.2009722; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; de Broglie L., 1929, NOBEL LECT, V12; Doulamis A, 2009, LECT NOTES COMPUT SC, V5769, P715, DOI 10.1007/978-3-642-04277-5_72; Duffner S., 2013, P ICCV; Gabor D., 1946, J I ELECT ENG 3, V93; Gilbert A, 2007, LECT NOTES COMPUT SC, V4814, P166; Godec M, 2013, COMPUT VIS IMAGE UND, V117, P1245, DOI 10.1016/j.cviu.2012.11.005; Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19; Gustafsson F, 2002, IEEE T SIGNAL PROCES, V50, P425, DOI 10.1109/78.978396; Han Z., 2011, PATTERN RECOGNITION; Hardy G. H., 1967, INEQUALITIES; Hare S, 2012, PROC CVPR IEEE, P1894, DOI 10.1109/CVPR.2012.6247889; Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251; Hariharakrishnan K, 2005, IEEE T MULTIMEDIA, V7, P853, DOI 10.1109/TMM.2005.854437; Hodge V., 2004, ARTIFICIAL INTELLIGE; Hu WM, 2011, INT J COMPUT VISION, V91, P303, DOI 10.1007/s11263-010-0399-6; Jacobs N., 2008, IEEE WORKSH VID COMP; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; Kalal Z., 2010, IEEE T PAMI, V6; Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231; Knutsson H., 1994, SIGNAL PROCESSING CO; Kristan, 2014, ECCV VIS OBJ TRACK C; Kwon J., 2014, P IEEE CVPR; Kwon J., 2013, P IEEE CVPR; Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821; Li S., 1999, IEEE T INFORM THEORY, V45; Nestares O, 2001, PROC CVPR IEEE, P358; Purdy TP, 2013, SCIENCE, V339, P801, DOI 10.1126/science.1231282; Qu W, 2007, IEEE T MULTIMEDIA, V9, P511, DOI 10.1109/TMM.2006.886266; Ramakrishna V., 2013, P IEEE CVPR; Rodriguez M., 2009, P IEEE ICCV; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Shimshoni, 2006, CVPR; Shinde S, 2001, IEEE T SIGNAL PROCES, V49, P2545, DOI 10.1109/78.960402; Stauder J, 1999, IEEE T MULTIMEDIA, V1, P65, DOI 10.1109/6046.748172; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; Wang XY, 2010, EBM 2010: INTERNATIONAL CONFERENCE ON ENGINEERING AND BUSINESS MANAGEMENT, VOLS 1-8, P200; WILSON R, 1984, IEEE T PATTERN ANAL, V6, P758, DOI 10.1109/TPAMI.1984.4767599; Wu B., 2006, 2006 IEEE COMP SOC C, V1, P951, DOI [10.1109/CVPR.2006.312, DOI 10.1109/CVPR.2006.312]; Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312; Yao Rui, 2013, P IEEE CVPR, P25; Zhang B., 2016, IEEE T CSVT ADAPTIVE; Zhang BC, 2011, IEEE T CIRC SYST VID, V21, P29, DOI 10.1109/TCSVT.2011.2105591; Zhang K., 2014, ECCV; Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808; Zhuang BH, 2014, IEEE T IMAGE PROCESS, V23, P1872, DOI 10.1109/TIP.2014.2308414	57	54	55	3	37	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2016	118	3					364	379		10.1007/s11263-016-0880-y	http://dx.doi.org/10.1007/s11263-016-0880-y			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	DP9AM					2022-12-18	WOS:000378789100005
J	Zhao, Q; Feng, W; Wan, L; Zhang, JW				Zhao, Qiang; Feng, Wei; Wan, Liang; Zhang, Jiawan			SPHORB: A Fast and Robust Binary Feature on the Sphere	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Spherical image; Binary feature; Panoramic image matching; Geodesic grid		In this paper, we propose SPHORB, a new fast and robust binary feature detector and descriptor for spherical panoramic images. In contrast to state-of-the-art spherical features, our approach stems from the geodesic grid, a nearly equal-area hexagonal grid parametrization of the sphere used in climate modeling. It enables us to directly build fine-grained pyramids and construct robust features on the hexagonal spherical grid, thus avoiding the costly computation of spherical harmonics and their associated bandwidth limitation. We further study how to achieve scale and rotation invariance for the proposed SPHORB feature. Extensive experiments show that SPHORB consistently outperforms other existing spherical features in accuracy, efficiency and robustness to camera movements. The superior performance of SPHORB has also been validated by real-world matching tests.	[Zhao, Qiang; Feng, Wei] Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China; [Wan, Liang; Zhang, Jiawan] Tianjin Univ, Sch Comp Software, Tianjin 300072, Peoples R China; [Wan, Liang] Civil Aviat Univ China, Tianjin Key Lab Adv Signal Proc, Tianjin, Peoples R China	Tianjin University; Tianjin University; Civil Aviation University of China	Wan, L (corresponding author), Tianjin Univ, Sch Comp Software, Tianjin 300072, Peoples R China.	qiangzhao@tju.edu.cn; wfeng@tju.edu.cn; lwan@tju.edu.cn; jwzhang@tju.edu.cn	Feng, Wei/E-3985-2016	Feng, Wei/0000-0003-3809-1086; Zhang, Jiawan/0000-0002-0667-6744	National Natural Science Foundation of China [61100122, 61100121]; New Century Excellent Talents in University [NCET-11-0365]; National Science and Technology Support Project [2013BAK01B01, 2014BAK09 B04]; Tianjin Science Foundation for Youth [12JCQNJC00100]; Tianjin Key Lab for Advanced Signal Processing, Civil Aviation University of China [TJKLASP-2012-2]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); New Century Excellent Talents in University(Program for New Century Excellent Talents in University (NCET)); National Science and Technology Support Project; Tianjin Science Foundation for Youth; Tianjin Key Lab for Advanced Signal Processing, Civil Aviation University of China	The authors thank all reviewers and the associate editor for their valuable comments. The authors also thank Chu Han, Wuyao Shen, and Xiangyu Mao for capturing CUHK dataset used in Table 1. The work was supported by the National Natural Science Foundation of China (61100122 and 61100121), New Century Excellent Talents in University (NCET-11-0365), the National Science and Technology Support Project (2013BAK01B01 and 2014BAK09 B04), Tianjin Science Foundation for Youth (12JCQNJC00100), and the research Fund from The Tianjin Key Lab for Advanced Signal Processing, Civil Aviation University of China (TJKLASP-2012-2).	Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715; Ambai M, 2011, IEEE I CONF COMP VIS, P97, DOI 10.1109/ICCV.2011.6126230; Anguelov D, 2010, COMPUTER, V43, P32, DOI 10.1109/MC.2010.170; Arican Z, 2012, IEEE T IMAGE PROCESS, V21, P2412, DOI 10.1109/TIP.2012.2185937; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Bulow T, 2004, IEEE T PATTERN ANAL, V26, P1650, DOI 10.1109/TPAMI.2004.129; Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56; Cruz-Mota J, 2012, INT J COMPUT VISION, V98, P217, DOI 10.1007/s11263-011-0505-4; Hadj-Abdelkader H., 2008, P 8 WORKSH OMN VIS C; Hansen P, 2007, IEEE I CONF COMP VIS, P512; Hansen P, 2010, INT J ROBOT RES, V29, P267, DOI 10.1177/0278364909356484; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Micusik Branislav, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2906, DOI 10.1109/CVPRW.2009.5206535; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Puig L, 2011, IEEE I CONF COMP VIS, P1599, DOI 10.1109/ICCV.2011.6126420; Randall DA, 2002, COMPUT SCI ENG, V4, P32, DOI 10.1109/MCISE.2002.1032427; Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34; Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275; Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544; Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103; Taneja A, 2013, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2013.22; Valgren C., 2007, 3 EUR C MOB ROB ECMR, P253; WILLIAMSON DL, 1968, TELLUS, V20, P642, DOI 10.1111/j.2153-3490.1968.tb00406.x; Xiao JX, 2012, PROC CVPR IEEE, P2695, DOI 10.1109/CVPR.2012.6247991; Xuebin Qin, 2012, 2012 International Conference on Systems and Informatics (ICSAI 2012), P1914, DOI 10.1109/ICSAI.2012.6223422; Yagnik J, 2011, IEEE I CONF COMP VIS, P2431, DOI 10.1109/ICCV.2011.6126527; Zamir AR, 2010, LECT NOTES COMPUT SC, V6314, P255, DOI 10.1007/978-3-642-15561-1_19; Zhao Q, 2013, IEEE T MULTIMEDIA, V15, P1745, DOI 10.1109/TMM.2013.2280249; Ziegler A, 2012, ADV NEURAL INFORM PR, P1	32	54	56	2	22	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2015	113	2					143	159		10.1007/s11263-014-0787-4	http://dx.doi.org/10.1007/s11263-014-0787-4			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	CI1FE					2022-12-18	WOS:000354487300005
J	Lu, CW; Xu, L; Jia, JY				Lu, Cewu; Xu, Li; Jia, Jiaya			Contrast Preserving Decolorization with Perception-Based Quality Metrics	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Decolorization; Color2gray; Conversion; Contrast preservation; Perceptual-based; Quality metrics	COLOR; CONVERSION; IMAGES	Converting color images into grayscale ones suffer from information loss. In the meantime, it is one fundamental tool indispensable for single channel image processing, digital printing, and monotone e-ink display. In this paper, we propose an optimization framework aiming at maximally preserving color contrast. Our main contribution is threefold. First, we employ a bimodal objective function to alleviate the restrictive order constraint for color mapping. Second, we develop an efficient solver that allows for automatic selection of suitable grayscales based on global contrast constraints. Third, we advocate a perceptual-based metric to measure contrast loss, as well as content preservation, in the produced grayscale images. It is among the first attempts in this field to quantitatively evaluate decolorization results.	[Lu, Cewu; Jia, Jiaya] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China; [Xu, Li] Lenovo Res & Technol, Hong Kong, Hong Kong, Peoples R China	Chinese University of Hong Kong; Legend Holdings; Lenovo	Jia, JY (corresponding author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.	xuli@cse.cuhk.edu.hk; leojia@cse.cuhk.edu.hk	Jia, Jiaya/I-3251-2012		Research Grants Council of the Hong Kong SAR [413110]; NSF of China [61133009]	Research Grants Council of the Hong Kong SAR(Hong Kong Research Grants Council); NSF of China(National Natural Science Foundation of China (NSFC))	The authors would like to thank the editor and all the anonymous reviewers for their time and effort. This work is supported by a grant from the Research Grants Council of the Hong Kong SAR (Project No. 413110) and by NSF of China (key Project No. 61133009).	Achanta R., 2009, IEEE C COMP VIS PATT; Ahn J. H., 2010, AS C COMP VIS ACCV; Ancuti C. O., 2011, IEEE C COMP VIS PATT; Bala R, 2004, P SOC PHOTO-OPT INS, V5293, P196, DOI 10.1117/12.532192; Bala R., 2004, COL IM C; Cadik M, 2008, COMPUT GRAPH FORUM, V27, P1745; Chen HC, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P593; Corney D, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0005091; Fairchild M.D., 2005, COLOR APPEARANCE MOD; Gooch AA, 2005, ACM T GRAPHIC, V24, P634, DOI 10.1145/1073204.1073241; Grundland M, 2007, PATTERN RECOGN, V40, P2891, DOI 10.1016/j.patcog.2006.11.003; HUNTER RS, 1958, J OPT SOC AM, V48, P985, DOI 10.1364/JOSA.48.000985; Kim Y, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618507; Lotto RB, 2002, TRENDS NEUROSCI, V25, P84, DOI 10.1016/S0166-2236(02)02059-3; Lu C., 2012, INT C COMP PHOT ICCP; Martin D., 2001, INT C COMP VIS ICCV; Nayatani Y, 1997, COLOR RES APPL, V22, P385, DOI 10.1002/(SICI)1520-6378(199712)22:6<385::AID-COL6>3.0.CO;2-R; Nelsen R.B., 2001, KENDALL TAU METRIC; Neumann L., 2007, COMPUTATIONAL AESTHE; Ozgen E, 2004, CURR DIR PSYCHOL SCI, V13, P95, DOI 10.1111/j.0963-7214.2004.00282.x; Rasche K, 2005, IEEE COMPUT GRAPH, V25, P22, DOI 10.1109/MCG.2005.54; REBER AS, 1985, PENGUIN DICT PSYCHOL; Sharma G., 2002, DIGITAL COLOR IMAGIN; Smith K, 2008, COMPUT GRAPH FORUM, V27, P193, DOI 10.1111/j.1467-8659.2008.01116.x; Song ML, 2010, IEEE T PATTERN ANAL, V32, P1537, DOI 10.1109/TPAMI.2009.74; Wong B, 2010, NAT METHODS, V7, P573, DOI 10.1038/nmeth0810-573; Wyszecki G., 2000, COLOR SCI CONCEPTS M, V2nded.; Zhou K., 2010, P NATL ACAD SCI	28	54	58	0	16	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	2014	110	2			SI		222	239		10.1007/s11263-014-0732-6	http://dx.doi.org/10.1007/s11263-014-0732-6			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AY5UE					2022-12-18	WOS:000347636400010
J	Kanatani, K				Kanatani, Kenichi			Statistical optimization for geometric fitting: Theoretical accuracy bound and high order error analysis	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						geometric fitting; parameter estimation; error analysis; hyperaccuracy; KCR lower bound	CONIC SECTIONS; SURFACES; VISION; HEIV; FNS	A rigorous accuracy analysis is given to various techniques for estimating parameters of geometric models from noisy data. First, it is pointed out that parameter estimation for vision applications is very different in nature from traditional statistical analysis and hence a different mathematical framework is necessary. After a general framework is formulated, typical numerical techniques are selected, and their accuracy is evaluated up to high order terms. As a byproduct, our analysis leads to a "hyperaccurate" method that outperforms existing methods.	Okayama Univ, Dept Comp Sci, Okayama 7008530, Japan	Okayama University	Kanatani, K (corresponding author), Okayama Univ, Dept Comp Sci, Okayama 7008530, Japan.	kanatani@suri.it.okayama-u.ac.jp						AKAIKE H, 1977, IEEE T AUTOMAT CONTR, V16, P716; Amari S, 1997, BERNOULLI, V3, P29, DOI 10.2307/3318651; Begelfor E, 2005, IEEE T PATTERN ANAL, V27, P1666, DOI 10.1109/TPAMI.2005.200; Bickel P.J., 1994, EFFICIENT ADAPTIVE E; BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V9, P56, DOI 10.1016/0146-664X(79)90082-0; Chernov N, 2004, COMPUT STAT DATA AN, V47, P713, DOI 10.1016/j.csda.2003.11.008; Chojnacki W, 2005, J MATH IMAGING VIS, V23, P175, DOI 10.1007/s10851-005-6465-y; Chojnacki W, 2004, IEEE T PATTERN ANAL, V26, P264, DOI 10.1109/TPAMI.2004.1262197; Chojnacki W, 2001, J MATH IMAGING VIS, V14, P21, DOI 10.1023/A:1008355213497; Chojnacki W, 2000, IEEE T PATTERN ANAL, V22, P1294, DOI 10.1109/34.888714; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Kanatani K, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P2, DOI 10.1109/3DIM.2005.49; Kanatani K, 2004, IEEE T PATTERN ANAL, V26, P1307, DOI 10.1109/TPAMI.2004.93; Kanatani K, 2003, J ELECTRON IMAGING, V12, P478, DOI 10.1117/1.1579018; Kanatani K., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P599, DOI 10.1109/ICCV.1993.378156; Kanatani K, 1998, GRAPH MODEL IM PROC, V60, P93, DOI 10.1006/gmip.1998.0466; Kanatani K, 2000, IEICE T INF SYST, VE83D, P1369; Kanatani K., 2005, STAT OPTIMIZATION GE; KANATANI K, 2000, IEICE T INF SYST, V90, P579; Kanatani K, 2007, COMPUT STAT DATA AN, V52, P1208, DOI 10.1016/j.csda.2007.05.013; Kanatani K, 2006, IEICE T INF SYST, VE89D, P2653, DOI 10.1093/ietisy/e89-4.10.2653; Leedan Y, 2000, INT J COMPUT VISION, V37, P127, DOI 10.1023/A:1008185619375; Neyman J, 1948, ECONOMETRICA, V16, P1, DOI 10.2307/1914288; OHTA N, 2003, 3 INT WORKSH STAT CO; Okatani T, 2003, PROC CVPR IEEE, P432; Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z; Rissanen Jorma, 1989, STOCHASTIC COMPLEXIT; SAMPSON PD, 1982, COMPUT VISION GRAPH, V18, P97, DOI 10.1016/0146-664X(82)90101-0; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273	29	54	56	0	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	2008	80	2					167	188		10.1007/s11263-007-0098-0	http://dx.doi.org/10.1007/s11263-007-0098-0			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	348DA		Green Submitted			2022-12-18	WOS:000259190000001
J	Ikeuchi, K; Oishi, T; Takamatsu, J; Sagawa, R; Nakazawa, A; Kurazume, R; Nishino, K; Kamakura, M; Okamoto, Y				Ikeuchi, Katsushi; Oishi, Takeshi; Takamatsu, Jun; Sagawa, Ryusuke; Nakazawa, Atsushi; Kurazume, Ryo; Nishino, Ko; Kamakura, Mawo; Okamoto, Yasuhide			The Great Buddha project: Digitally archiving, restoring, and analyzing cultural heritage objects	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						cultural heritage; range data; alignment; merging; texturing	REGISTRATION; SHAPE	This paper presents an overview of our research project on digital preservation of cultural heritage objects and digital restoration of the original appearance of these objects. As an example of these objects, this project focuses on the preservation and restoration of the Great Buddhas. These are relatively large objects existing outdoors and providing various technical challenges. Geometric models of the great Buddhas are digitally achieved through a pipeline, consisting of acquiring data, aligning multiple range images, and merging these images. We have developed two alignment algorithms: a rapid simultaneous algorithm, based on graphics hardware, for quick data checking on site, and a parallel alignment algorithm, based on a PC cluster, for precise adjustment at the university. We have also designed a parallel voxel-based merging algorithm for connecting all aligned range images. On the geometric models created, we aligned texture images acquired from color cameras. We also developed two texture mapping methods. In an attempt to restore the original appearance of historical objects, we have synthesized several buildings and statues using scanned data and a literature survey with advice from experts.	Univ Tokyo, Tokyo, Japan	University of Tokyo	Ikeuchi, K (corresponding author), Univ Tokyo, Tokyo, Japan.		Kurazume, Ryo/S-8271-2019	Kurazume, Ryo/0000-0002-4219-7644; Oishi, Takeshi/0000-0002-2010-2608				Benjemaa R, 1997, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P113, DOI 10.1109/IM.1997.603856; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Borovikov E, 2000, 5TH INTERNATIONAL WORKSHOP ON COMPUTER ARCHITECTURES FOR MACHINE PERCEPTION, PROCEEDINGS, P183, DOI 10.1109/CAMP.2000.875976; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269; GAGNON H, 1994, COMPUTER VISION PATT, P581; IKEUCHI K., 2001, MODELING REALITY; Kamakura M., 2005, VIRTUAL SYSTEMS MULT, P751; Kanade T, 1997, IEEE MULTIMEDIA, V4, P34, DOI 10.1109/93.580394; Kitahara I, 2004, PRESENCE-VIRTUAL AUG, V13, P164, DOI 10.1162/1054746041382401; KURAZUME R, 2002, 5 AS C COMP VIS ACCV, V1, P99; Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954; Levoy M, 2000, COMP GRAPH, P131, DOI 10.1145/344779.344849; Matsuyama T, 2004, IEEE T CIRC SYST VID, V14, P357, DOI 10.1109/TCSVT.2004.823396; Neugebauer P, 1997, 1997 INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P130, DOI 10.1109/SMA.1997.634890; Nishino K., 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P454; Oishi T, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P195, DOI 10.1109/IM.2003.1240250; Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423; Sagawa R, 2005, IEEE T PATTERN ANAL, V27, P392, DOI 10.1109/TPAMI.2005.46; Sagawa R, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P410, DOI 10.1109/IM.2003.1240276; Sagawa R, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P79, DOI 10.1109/IM.2003.1240235; SAGAWA R, 2001, IEEE RSJ INT C INT R, V1, P577; Stamos I, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P731, DOI 10.1109/ICCV.2001.937699; Wasserman Jack, 2003, MICHELANGELOS FLOREN; Wheeler MD, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P917, DOI 10.1109/ICCV.1998.710826; WHEELER MD, 1995, IEEE T PATTERN ANAL, V17, P252, DOI 10.1109/34.368190	26	54	58	2	18	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	OCT	2007	75	1					189	208		10.1007/s11263-007-0039-y	http://dx.doi.org/10.1007/s11263-007-0039-y			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	197RM		Green Submitted			2022-12-18	WOS:000248574200011
J	Sivic, J; Schaffalitzky, F; Zisserman, A				Sivic, Josef; Schaffalitzky, Frederik; Zisserman, Andrew			Object level grouping for video shots	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	8th European Conference on Computer Vision	MAY 11-14, 2004	Prague, CZECH REPUBLIC	Business Informat Grp as, Camea spol sro, Casablanca INT sro, ECVision, Microsoft Res, Miracle Network sro, Neovision sro, Toyota		3D object retrieval in videos; tracking affine covariant regions; independent motion segmentation; robust affine factorization	IMAGE-ANALYSIS	We describe a method for automatically obtaining object representations suitable for retrieval from generic video shots. The object representation consists of an association of frame regions. These regions provide exemplars of the object's possible visual appearances. Two ideas are developed: (i) associating regions within a single shot to represent a deforming object; (ii) associating regions from the multiple visual aspects of a 3D object, thereby implicitly representing 3D structure. For the association we exploit temporal continuity (tracking) and wide baseline matching of affine covariant regions. In the implementation there are three areas of novelty: First, we describe a method to repair short gaps in tracks. Second, we show how to join tracks across occlusions (where many tracks terminate simultaneously). Third, we develop an affine factorization method that copes with motion degeneracy. We obtain tracks that last throughout the shot, without requiring a 3D reconstruction. The factorization method is used to associate tracks into object-level groups, with common motion. The outcome is that separate parts of an object that are not simultaneously visible (such as the front and back of a car, or the front and side of a face) are associated together. In turn this enables object-level matching and recognition throughout a video. We illustrate the method on the feature film "Groundhog Day." Examples are given for the retrieval of deforming objects (heads, walking people) and rigid objects (vehicles, locations).	Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England	University of Oxford	Sivic, J (corresponding author), Univ Oxford, Dept Engn Sci, Parks Rd, Oxford OX1 3PJ, England.							Aanaes H, 2002, IEEE T PATTERN ANAL, V24, P1215, DOI 10.1109/TPAMI.2002.1033213; Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463; BOLLES RC, 1987, INT J COMPUT VISION, V1, P7, DOI 10.1007/BF00128525; De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986; Ferrari V, 2004, LECT NOTES COMPUT SC, V3021, P40; Ferrari V, 2004, PROC CVPR IEEE, P105; Ferrari V, 2003, PROC CVPR IEEE, P718; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; GOEDEME T, 2005, IN PRESS COGNITIVE V; HARTLEY RI, 2000, MULITPLE VIEW GEOMET; Jacobs D, 1997, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.1997.609321; Kender JR, 1998, PROC CVPR IEEE, P367, DOI 10.1109/CVPR.1998.698632; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Lowe DG, 2001, PROC CVPR IEEE, P682; MAHINDROO A, 2002, P IND C COMP VIS GRA, P105; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; Mikolajczyk K., 2002, P 7 EUR C COMP VIS C; Osian M, 2004, MACH VISION APPL, V15, P172, DOI 10.1007/s00138-004-0141-x; Rothganger F, 2004, PROC CVPR IEEE, P914; Rothganger F, 2003, PROC CVPR IEEE, P272; Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414; Schaffalitzky F, 2003, COMPUT VIS IMAGE UND, V92, P236, DOI 10.1016/j.cviu.2003.06.008; SCHMID C, 1997, THESIS I NATL POLYTE; SHUM HY, 1995, IEEE T PATTERN ANAL, V17, P854, DOI 10.1109/34.406651; Sivic J., 2003, P INT C COMP VIS; SIVIC J, 2004, P EUR C COMP VIS, V2, P85; Torr P.H.S., 1995, THESIS U OXFORD; Torr PHS, 2001, IEEE T PATTERN ANAL, V23, P297, DOI 10.1109/34.910882; Torr PHS, 1998, COMPUT VIS IMAGE UND, V71, P312, DOI 10.1006/cviu.1997.0559; Tuytelaars T., 2000, BMV2000. Proceedings of the 11th British Machine Vision Conference, P412; WALLRAVEN C, 2001, P IEEE C COMP VIS PA; ZELNIKMANOR L, 1999, P 7 INT C COMP VIS K, V2, P710	32	54	58	0	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	2006	67	2					189	210		10.1007/s11263-005-4264-y	http://dx.doi.org/10.1007/s11263-005-4264-y			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	048ZO					2022-12-18	WOS:000237985300004
J	Savarese, S; Chen, M; Perona, P				Savarese, S; Chen, M; Perona, P			Local shape from mirror reflections	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							SURFACES	We study the problem of recovering the 3D shape of an unknown smooth specular surface from a single image. The surface reflects a calibrated pattern onto the image plane of a calibrated camera. The pattern is such that points are available in the image where position, orientations, and local scale may be measured (e.g. checkerboard). We first explore the differential relationship between the local geometry of the surface around the point of reflection and the local geometry in the image. We then study the inverse problem and give necessary and sufficient conditions for recovering surface position and shape. We prove that surface position and shape up to third order can be derived as a function of local position, orientation and local scale measurements in the image when two orientations are available at the same point (e.g. a corner). Information equivalent to scale and orientation measurements can be also extracted from the reflection of a planar scene patch of arbitrary geometry, provided that the reflections of (at least) 3 distinctive points may be identified. We validate our theoretical results with both numerical simulations and experiments with real surfaces.	CALTECH, Pasadena, CA 91125 USA	California Institute of Technology	Savarese, S (corresponding author), CALTECH, Mail Stop 136-93, Pasadena, CA 91125 USA.	savarese@vision.caltech.edu; minchencm@yahoo.com; perona@vision.caltech.edu						BINFORD TO, 1981, ARTIF INTELL, V17, P205, DOI 10.1016/0004-3702(81)90025-4; BLAKE A, 1988, P IEEE INT C COMP VI, P394; Blake A., 1985, IJCAI, P973; BONFORT T, 2003, P INT C COMP VIS, P394; Born M., 1965, PRINCIPLE OPTICS ELE; Carmo M. P., 1976, DIFFERENTIAL GEOMETR, V2nd; Chen M, 2000, ACM T GRAPHIC, V19, P246, DOI 10.1145/380666.380670; Cipolla R., 2000, VISUAL MOTION CURVES; DORRIE M, 1989, 100 GREAT PROBLEMS E; FLEMING R, 2003, P 3 ANN M VVS; GOESELE M, 2002, P SIGGRAPH SKETCH AP, P248; HALSEAD M, 1996, SIGGRAPH; HEALEY G, 1988, COMPUT VISION GRAPH, V42, P62, DOI 10.1016/0734-189X(88)90143-0; IKEUCHI K, 1981, IEEE T PATTERN ANAL, V3, P661, DOI 10.1109/TPAMI.1981.4767167; KOENDERINK JJ, 1980, OPT ACTA, V27, P981, DOI 10.1080/713820338; NEUMANN P, 1998, AM MATH MONTHLY; OREN M, 1997, T INT J COMP VIS, P105; PERARD D, 2001, THESIS; SAVARESE S, 2002, P 3D DAT PROC VIS TR; SAVARESE S, 2004, ACM SIGGRAPH APPL PE; SAVARESE S, 2004, P EUR C COMP VIS; SAVARESE S, 2002, P EUR C COMP VIS; Savarese Silvio, 2001, P IEEE C COMP VIS PA; Smith J.D., 1992, MATH GAZ, V76, P189; SOLEM J, 2003, INT S 3D DAT PROC VI; SWAMINATHAN R, 2004, P 5 WORKSH OMN VIS; SWAMINATHAN R, 2001, P INT C COMP VIS; Wang J.G., 2003, P INT C COMP VIS; ZHENG J, 2000, IEEE J PATTERN ANAL, V8; ZISSERMAN A, 1989, IMAGE VISION COMPUT, V7, P38, DOI 10.1016/0262-8856(89)90018-8	30	54	59	0	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2005	64	1					31	67		10.1007/s11263-005-1086-x	http://dx.doi.org/10.1007/s11263-005-1086-x			37	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	950KB					2022-12-18	WOS:000230854900002
J	Styner, M; Gerig, G; Joshi, S; Pizer, S				Styner, M; Gerig, G; Joshi, S; Pizer, S			Automatic and robust computation of 3D medial models incorporating object variability	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						medical imaging; shape analysis; voronoi skeleton; medial shape description; skeleton pruning	SHAPE; SEGMENTATION	This paper presents a novel processing scheme for the automatic and robust computation of a medial shape model, which represents an object population with shape variability. The sensitivity of medial descriptions to object variations and small boundary perturbations are fundamental problems of any skeletonization technique. These problems are approached with the computation of a model with common medial branching topology and grid sampling. This model is then used for a medial shape description of individual objects via a constrained model fit. The process starts from parametric 3D boundary representations with existing point-to-point homology between objects. The Voronoi skeleton of each sampled object boundary is partitioned into non-branching medial sheets and simplified by a novel pruning algorithm using a volumetric contribution criterion. Using the surface homology, medial sheets are combined to form a common medial branching topology. Finally, the medial sheets are sampled and represented as meshes of medial primitives. Results on populations of up to 184 biological objects clearly demonstrate that the common medial branching topology can be described by a small number of medial sheets and that even a coarse sampling leads to a close approximation of individual objects.	Duke Univ, Med Ctr, Dept Radiol, Duke Image Anal Lab, Durham, NC 27706 USA; Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27599 USA	Duke University; University of North Carolina; University of North Carolina Chapel Hill	Styner, M (corresponding author), Duke Univ, Med Ctr, Dept Radiol, Duke Image Anal Lab, Durham, NC 27706 USA.							Attali D, 1997, IMAGE PROCESSING COM, V3, P63; AUGUST J, 1999, COMPTER VISION IMAGE, P231; AUGUST J, 1999, ICCV, P315; BLUM TO, 1967, MODELS PERCEPTION SP; BOISSONNAT JD, 1985, IEEE C COMPUTER VISI, P398; Bookstein FL, 1997, COMPUT VIS IMAGE UND, V66, P97, DOI 10.1006/cviu.1997.0607; BORGERFORS G, 1991, SCIA C, P974; BRANDT JW, 1992, CVGIP-IMAG UNDERSTAN, V55, P329, DOI 10.1016/1049-9660(92)90030-7; BREVCHBUHLER C, 1995, THESIS IKT BIWI ETH; Burbeck CA, 1996, VISION RES, V36, P361, DOI 10.1016/0042-6989(95)00106-9; CHRISTENSEN GE, 1994, PHYS MED BIOL, V39, P609, DOI 10.1088/0031-9155/39/3/022; Davatzikos C, 1996, J COMPUT ASSIST TOMO, V20, P88, DOI 10.1097/00004728-199601000-00017; Fritsch D, 1997, LECT NOTES COMPUT SC, V1230, P127; FU K, 1981, COMP GRAPH IM P, V17, P315; GERIG G, 2001, MED IMAGE COMPUTING, V2208, P24; GERIG G, 2002, 11 BIENN WORKSH SCHI; Giblin P, 2000, PROC CVPR IEEE, P566, DOI 10.1109/CVPR.2000.855870; Golland P, 1999, LECT NOTES COMPUT SC, V1613, P382; HERDA L, 2000, COMPUTER ANIMATION; Joshi S., 2001, Information Processing in Medical Imaging. 17th International Conference, IPMI 2001. Proceedings (Lecture Notes in Computer Science Vol.2082), P64; Joshi SC, 1997, INT J PATTERN RECOGN, V11, P1317, DOI 10.1142/S0218001497000615; Kelemen A, 1999, IEEE T MED IMAGING, V18, P828, DOI 10.1109/42.811260; KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741; LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346; MONTANVERT A, 1987, INT C PATT REC, P197; NAF M, 1996, MATH METHODS BIOMEDI, P139; Ogniewicz R., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P63, DOI 10.1109/CVPR.1992.223226; Pizer SM, 1999, IEEE T MED IMAGING, V18, P851, DOI 10.1109/42.811263; Shen DG, 2001, IEEE T MED IMAGING, V20, P257, DOI 10.1109/42.921475; SHIH FY, 1995, PATTERN RECOGN, V28, P331, DOI 10.1016/0031-3203(94)00104-T; Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703; Siddiqi K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P828, DOI 10.1109/ICCV.1999.790307; Siddiqi K, 1999, IMAGE VISION COMPUT, V17, P365, DOI 10.1016/S0262-8856(98)00130-9; STAIB LH, 1996, IEEE T MED IMAGING, V15, P1; Styner M, 2001, SCHIZOPHR RES, V49, P167; STYNER M, 1997, 179 ETH ZUR IM SCI L; STYNER M, 2001, THESIS UNC CHAPEL HI; STYNER M, 2001, INFORM PROCESSING ME, V2082, P502; Subsol G, 1998, Med Image Anal, V2, P37, DOI 10.1016/S1361-8415(01)80027-X; TEK H, 1999, ICCV, P362; Yushkevich P., 2001, Information Processing in Medical Imaging. 17th International Conference, IPMI 2001. Proceedings (Lecture Notes in Computer Science Vol.2082), P402	41	54	55	0	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV-DEC	2003	55	2-3					107	122		10.1023/A:1026378916288	http://dx.doi.org/10.1023/A:1026378916288			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	732YN					2022-12-18	WOS:000185973300003
J	Favaro, P; Mennucci, A; Soatto, S				Favaro, P; Mennucci, A; Soatto, S			Observing shape from defocused images	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						shape; surface geometry; low-level vision; shape from defocus; shape from focus	DEPTH; RESTORATION	Accommodation cues are measurable properties of an image that are associated with a change in the geometry of the imaging device. To what extent can three-dimensional shape be reconstructed using accommodation cues alone? This question is fundamental to the problem of reconstructing shape from focus (SFF) and shape from defocus (SFD) for applications in inspection, microscopy, image restoration and visualization. We address it by studying the "observability" of accommodation cues in an analytical framework that reveals under what conditions shape can be reconstructed from defocused images. We do so in three steps: (1) we characterize the observability of any surface in the presence of a controlled radiance ("weak observability"), (2) we conjecture the existence of a radiance that allows distinguishing any two surfaces ("sufficient excitation") and (3) we show that in the absence of any prior knowledge on the radiance, two surfaces can be distinguished up to the degree of resolution determined by the complexity of the radiance ("strong observability"). We formulate the problem of reconstructing the shape and radiance of a scene as the minimization of the information divergence between blurred images, and propose an algorithm that is provably convergent and guarantees that the solution is admissible, in the sense of corresponding to a positive radiance and imaging kernel.	Washington Univ, Dept Elect Engn, St Louis, MO 63130 USA; Scuola Normale Super Pisa, I-56100 Pisa, Italy; Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA	Washington University (WUSTL); Scuola Normale Superiore di Pisa; University of California System; University of California Los Angeles	Favaro, P (corresponding author), Washington Univ, Dept Elect Engn, 1 Brookings Dr, St Louis, MO 63130 USA.	fava@ee.wustl.edu; mennucci@tonelli.sns.it; soatto@ucla.edu	Mennucci, Andrea C. G./B-6335-2012	Mennucci, Andrea C. G./0000-0002-4302-3275				[Anonymous], 1998, INTRO THEORY DISTRIB; Asada N, 1998, IEEE T PATTERN ANAL, V20, P155, DOI 10.1109/34.659933; Chan TF, 1998, IEEE T IMAGE PROCESS, V7, P370, DOI 10.1109/83.661187; Chaudhuri S., 1999, DEPTH DEFOCUS REAL A; Cover T.M., 2006, ELEMENTS INFORM THEO, DOI [10.1002/047174882X, DOI 10.1002/047174882X]; CSISZAR I, 1991, ANN STAT, V19, P2032, DOI 10.1214/aos/1176348385; ENS J, 1993, IEEE T PATTERN ANAL, V15, P97, DOI 10.1109/34.192482; Farid H, 1998, J OPT SOC AM A, V15, P1777, DOI 10.1364/JOSAA.15.001777; FAVARO P, 2000, P EUR C COMP VIS, V1, P755; GIROD B, 1989, SPIE, P209; GOKSTORP M, 1994, INT C PATT REC, VA, P153; Harikumar G, 1999, IEEE T IMAGE PROCESS, V8, P202, DOI 10.1109/83.743855; HOPKINS HH, 1955, PROC R SOC LON SER-A, V231, P91, DOI 10.1098/rspa.1955.0158; Hwang T.-l., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P476, DOI 10.1109/CVPR.1989.37890; KALIFA J, 1998, P INT C IM PROC, P98; Kundur D, 1998, IEEE T SIGNAL PROCES, V46, P375, DOI 10.1109/78.655423; LUEMBERGER D, 1968, OPTIMIZATION VECTOR; Marshall JA, 1996, J OPT SOC AM A, V13, P681, DOI 10.1364/JOSAA.13.000681; MENNUCCI A, 1999, 99001 WASH U; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Nair H. N., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P309, DOI 10.1109/CVPR.1992.223258; Namba M, 1998, SIGNAL PROCESS, V68, P119, DOI 10.1016/S0165-1684(98)00092-9; Nayar S., 1990, IEEE INT C ROB AUT, DOI DOI 10.1109/ROBOT.1990.125976; NAYAR SK, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P995, DOI 10.1109/ICCV.1995.466826; NEELAMANI R, 1999, P INT C IM PROC, P58; NOGUCHI M, 1994, INT C PATT RECOG, P147, DOI 10.1109/ICPR.1994.576247; PENTLAND A, 1994, J OPT SOC AM A, V11, P2925, DOI 10.1364/JOSAA.11.002925; PENTLAND A, 1989, COMPUTER VISION PATT, P256; PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940; Rajagopalan AN, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1047, DOI 10.1109/ICCV.1998.710846; Rajagopalan AN, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC636; RAJAGOPALAN AN, 1997, COMPUTER VISION PATT, P219; Schechner YY, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1061, DOI 10.1109/ICCV.1998.710848; SCHECHNER YY, 1999, IEEE P INT C COMP VI, V2, P843; SCHEROCK S, 1981, 167 MIT MED LAB; SCHNEIDER G, 1994, IEEE IMAGE PROC, P116, DOI 10.1109/ICIP.1994.413542; SIMONCELLI EP, 1996, EUR C COMP VIS, V2, P82; SNYDER DL, 1992, IEEE T SIGNAL PROCES, V40, P1143, DOI 10.1109/78.134477; Soatto S, 2000, PROC CVPR IEEE, P10, DOI 10.1109/CVPR.2000.854725; SUBBARAO M, 1994, INT J COMPUT VISION, V13, P271, DOI 10.1007/BF02028349; SUBBARAO M, 1992, COMPUTER VISION PATT, P773; Taylor ME, 1996, PARTIAL DIFFERENTIAL, VI; WATANABE M, 1996, CVPR 96, P431; WATANABE M, 1996, ECCV96, V2, P439; XIONG Y, 1995, P INT C INT ROB SYST, P108; Ziou D, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P799, DOI 10.1109/ICCV.1998.710809	46	54	72	0	13	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	2003	52	1					25	43		10.1023/A:1022366408068	http://dx.doi.org/10.1023/A:1022366408068			19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	643XD		Green Published			2022-12-18	WOS:000180887700002
J	Sumi, Y; Kawai, Y; Yoshimi, T; Tomita, F				Sumi, Y; Kawai, Y; Yoshimi, T; Tomita, F			3D object recognition in cluttered environments by segment-based stereo vision	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						3D object recognition; free-form objects; segment-based stereo vision; 3D object modeling; 3D shape matching; robot vision	RANGE IMAGES; REPRESENTATION; REGISTRATION; MODELS; SYSTEM; ALIGNMENT; PICK	We propose a new method for 3D object recognition which uses segment-based stereo vision. An object is identified in a cluttered environment and its position and orientation (6 dof) are determined accurately enabling a robot to pick up the object and manipulate it. The object can be of any shape (planar figures, polyhedra, free-form objects) and partially occluded by other objects. Segment-based stereo vision is employed for 3D sensing. Both CAD-based and sensor-based object modeling subsystems are available. Matching is performed by calculating candidates for the object position and orientation using local features, verifying each candidate, and improving the accuracy of the position and orientation by an iteration method. Several experimental results are presented to demonstrate the usefulness of the proposed method.	Natl Inst Adv Ind Sci & Technol, Intelligent Syst Inst, AIST Tsukuba Cent 2, Tsukuba, Ibaraki 3058568, Japan	National Institute of Advanced Industrial Science & Technology (AIST)	Sumi, Y (corresponding author), Natl Inst Adv Ind Sci & Technol, Intelligent Syst Inst, AIST Tsukuba Cent 2, Tsukuba, Ibaraki 3058568, Japan.	y.sumi@aist.go.jp	Sumi, Yasushi/N-1551-2016; Kawai, Yoshihiro/M-3378-2016; Yoshimi, Takashi/M-3354-2016	Sumi, Yasushi/0000-0002-0286-3411; Kawai, Yoshihiro/0000-0002-9847-0072; Yoshimi, Takashi/0000-0002-7368-7646				ARMAN F, 1993, COMPUT SURV, V25, P5, DOI 10.1145/151254.151255; ARMAN F, 1993, CVGIP-IMAG UNDERSTAN, V58, P33, DOI 10.1006/ciun.1993.1030; AYACHE N, 1986, IEEE T PATTERN ANAL, V8, P44, DOI 10.1109/TPAMI.1986.4767751; BASRI R, 1993, CVGIP-IMAG UNDERSTAN, V57, P331, DOI 10.1006/ciun.1993.1022; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; Chen Z, 1996, CANCER GENE THER, V3, P18; Chua CS, 1996, INT J COMPUT VISION, V17, P77, DOI 10.1007/BF00127819; Chua CS, 1997, INT J COMPUT VISION, V25, P63, DOI 10.1023/A:1007981719186; CIPOLLA R, 1992, INT J COMPUT VISION, V9, P83, DOI 10.1007/BF00129682; Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; FLYNN PJ, 1991, IEEE T PATTERN ANAL, V13, P1066, DOI 10.1109/34.99239; FLYNN PJ, 1994, IEEE T PATTERN ANAL, V16, P814, DOI 10.1109/34.308477; Grimson W. E. L., 1990, OBJECT RECOGNITION C; HORN BKP, 1984, P IEEE, V72, P1671, DOI 10.1109/PROC.1984.13073; HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921; Johnson AE, 1998, IMAGE VISION COMPUT, V16, P635, DOI 10.1016/S0262-8856(98)00074-2; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; Joshi T, 1997, IMAGE VISION COMPUT, V15, P479, DOI 10.1016/S0262-8856(97)00001-2; Kawai Y., 1996, ASSETS '96. The Second Annual ACM Conference on Assistive Technologies, P45, DOI 10.1145/228347.228356; Kawai Y, 1998, INT C PATT RECOG, P648, DOI 10.1109/ICPR.1998.711227; KRIEGMAN DJ, 1990, IEEE T PATTERN ANAL, V12, P1127, DOI 10.1109/34.62602; MATSUI T, 1995, EUSLISP REFERENECE M; Matsushita T, 1998, 1998 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - PROCEEDINGS, VOLS 1-3, P185, DOI 10.1109/IROS.1998.724617; OHTA Y, 1986, P 8 INT C PATT REC I, V1, P519; OUE Y, 1999, T I ELECT INFORMATIO, P2307; PONCE J, 1992, CVGIP-IMAG UNDERSTAN, V55, P184, DOI 10.1016/1049-9660(92)90016-V; PORRILL J, 1988, IMAGE VISION COMPUT, V6, P91, DOI 10.1016/0262-8856(88)90004-2; RYGOL M, 1991, IMAGE VISION COMPUT, V9, P33, DOI 10.1016/0262-8856(91)90046-R; SEALES WB, 1995, COMPUT VIS IMAGE UND, V61, P308, DOI 10.1006/cviu.1995.1025; STEIN F, 1992, IEEE T PATTERN ANAL, V14, P125, DOI 10.1109/34.121785; Sugimoto K., 1994, Proceeding IEEE Workshop on Visualization and Machine Vision (Cat. No.94TH0636-1), P13, DOI 10.1109/VMV.1994.324992; Tan TN, 1998, INT J COMPUT VISION, V27, P5, DOI 10.1023/A:1007924428535; Tomita F, 1998, IEEE SYS MAN CYBERN, P4510, DOI 10.1109/ICSMC.1998.727561; TOMITA F, 1986, ALGORITHMS BREP IMAG; TOMITA F, 1990, COMPUTER ANAL VISUAL, pCH3; Ueshiba T., 1998, Proceedings of IAPR Workshop on Machine Vision Applications, P61; VAILLANT R, 1992, IEEE T PATTERN ANAL, V14, P157, DOI 10.1109/34.121787; VAYDA AJ, 1991, CVGIP-IMAG UNDERSTAN, V54, P1, DOI 10.1016/1049-9660(91)90073-X; YACHIDA M, 1986, P ICRP PAR FRANC, V2, P1041; Zerroug M., 1995, Proceedings International Symposium on Computer Vision (Cat. No.95TB100006), P431, DOI 10.1109/ISCV.1995.477040; ZHANG ZY, 1992, INT J COMPUT VISION, V7, P211, DOI 10.1007/BF00126394	43	54	56	0	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.		2002	46	1					5	23		10.1023/A:1013240031067	http://dx.doi.org/10.1023/A:1013240031067			19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	503NT					2022-12-18	WOS:000172805100001
J	Fagin, R; Stockmeyer, L				Fagin, R; Stockmeyer, L			Relaxing the triangle inequality in pattern matching	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						pattern matching; shape matching; triangle inequality; distance measure; image database	RETRIEVAL; IMAGES; SHAPE	Any notion of "closeness" in pattern matching should have the property that if A is close to B, and B is close to C, then A is close to C. Traditionally, this property is attained because of the triangle inequality (d(A, C) less than or equal to d(A, B) + d(B, C), where d represents a notion of distance). However, the full power of the triangle inequality is not needed for this property to hold. Instead, a "relaxed triangle inequality" suffices, of the form d(A, C) less than or equal to c(d(A, B) + d(B, C)), where c is a constant that is not too large. In this paper, we show that one of the measures used for distances between shapes in (an experimental version of) IBM's QBIC(1) ("Query by Image Content") system (Niblack et al., 1993) satisfies a relaxed triangle inequality, although it does not satisfy the triangle inequality.	IBM Corp, Almaden Res Ctr, San Jose, CA 95120 USA	International Business Machines (IBM)	Fagin, R (corresponding author), IBM Corp, Almaden Res Ctr, 650 Harry Rd, San Jose, CA 95120 USA.							ARKIN EM, 1990, PROCEEDINGS OF THE FIRST ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P129; CORTELAZZO G, 1994, PATTERN RECOGN, V27, P1005, DOI 10.1016/0031-3203(94)90140-6; Huttenlocher D. P., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P654, DOI 10.1109/CVPR.1992.223209; Jain A. K., 1989, FUNDAMENTALS DIGITAL; Kim YS, 1997, PROC CVPR IEEE, P307; MCCONNELL R, 1991, IEEE T GEOSCI REMOTE, V29, P1004, DOI 10.1109/36.101377; Mehtre BM, 1997, INFORM PROCESS MANAG, V33, P319, DOI 10.1016/S0306-4573(96)00069-6; NIBLACK W, 1993, SPIE, V1908, P173; NIBLACK W, 1995, P IEEE INT C IM PROC; SCASSELLATI B, 1994, P SOC PHOTO-OPT INS, V2185, P2, DOI 10.1117/12.171777; TAUBIN G, 1991, P SOC PHOTO-OPT INS, V1570, P175, DOI 10.1117/12.48423; [No title captured]	12	54	54	0	1	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	1998	30	3					219	231		10.1023/A:1008023416823	http://dx.doi.org/10.1023/A:1008023416823			13	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	156FL					2022-12-18	WOS:000077990900004
J	Kanatani, K				Kanatani, K			Geometric information criterion for model selection	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						model selection; degeneracy detection; statistical estimation; AIC; maximum likelihood estimation; structure from motion	3-DIMENSIONAL MOTION PARAMETERS; OPTICAL-FLOW; COMPUTER VISION; PLANAR SURFACES; MOVING-OBJECTS; SEGMENTATION; PROJECTIONS; ESTIMATOR; ALGORITHM; SEQUENCE	In building a 3-D model of the environment from image and sensor data, one must fit to the data an appropriate class of models, which can be regarded as a parametrized manifold, or geometric model, defined in the data space. In this paper, we present a statistical framework for detecting degeneracies of a geometric model by evaluating its predictive capability in terms of the expected residual and derive the geometric AIC. We show that it allows us to detect singularities in a structure-from-motion analysis without introducing any empirically adjustable thresholds. We illustrate our approach by simulation examples. We also discuss the application potential of this theory for a wide range of computer vision and robotics problems.	Gunma Univ, Dept Comp Sci, Gunma 376, Japan	Gunma University	Kanatani, K (corresponding author), Gunma Univ, Dept Comp Sci, Gunma 376, Japan.	kanatani@cs.gunma-u.ac.jp						ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; AKAIKE H, 1974, IEEE T AUTOMAT CONTR, V19, P176, DOI DOI 10.1109/TAC.1974.1100705; Akaike H., 1969, ANN STAT MATH, V21, P234; Aloimonos Y, 1993, ACTIVE PERCEPTION; BARRON AR, 1991, IEEE T INFORM THEORY, V37, P1034, DOI 10.1109/18.86996; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; BOYER KL, 1994, IEEE T PATTERN ANAL, V16, P987, DOI 10.1109/34.329010; CLARKE BS, 1990, IEEE T INFORM THEORY, V36, P453, DOI 10.1109/18.54897; CLARKE BS, 1994, J STAT PLAN INFER, V41, P37, DOI 10.1016/0378-3758(94)90153-8; Efron B., 1994, MONOGR STAT APPL PRO, DOI DOI 10.1007/978-1-4899-4541-9; ENDOH T, 1994, IEICE T INF SYST, VE77D, P1240; FAUGERAS OD, 1990, INT J COMPUT VISION, V4, P225, DOI 10.1007/BF00054997; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Gu HS, 1996, IEEE T PATTERN ANAL, V18, P58, DOI 10.1109/34.476012; HANNAN EJ, 1979, J ROY STAT SOC B MET, V41, P190; HEEGER DJ, 1992, INT J COMPUT VISION, V7, P95, DOI 10.1007/BF00128130; HORN BKP, 1987, INT J COMPUT VISION, V1, P259, DOI 10.1007/BF00127824; HORN BKP, 1990, INT J COMPUT VISION, V4, P59, DOI 10.1007/BF00137443; KANATANI K, 1987, COMPUT VISION GRAPH, V38, P122, DOI 10.1016/S0734-189X(87)80133-0; Kanatani K, 1997, IEEE T PATTERN ANAL, V19, P246, DOI 10.1109/34.584101; KANATANI K, 1993, INT J COMPUT VISION, V11, P267, DOI 10.1007/BF01469345; KANATANI K, 1994, IEICE T INF SYST, VE77D, P1233; KANATANI K, 1995, IEICE T INF SYST, VE78D, P1074; KANATANI K, 1994, IEEE T PATTERN ANAL, V16, P543, DOI 10.1109/34.291441; Kanatani K., 1993, GEOMETRIC COMPUTATIO; KANATANI K, 1996, P 4 EUR C COMP VIS C, V1, P697; KANATANI K, 1997, IEEE T PATT ANAL MAC, V19; KANATANI K, 1996, STAET OPTIMIZATION G; Kanazawa Y, 1996, IROS 96 - PROCEEDINGS OF THE 1996 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - ROBOTIC INTELLIGENCE INTERACTING WITH DYNAMIC WORLDS, VOLS 1-3, P1272, DOI 10.1109/IROS.1996.568981; KANAZAWA Y, 1995, IEICE T INF SYST, VE78D, P917; KULLBACK S, 1959, INFORMATION THEORY S; LECLERC YG, 1989, INT J COMPUT VISION, V3, P73, DOI 10.1007/BF00054839; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; LONGUETHIGGINS HC, 1986, PROC R SOC SER B-BIO, V227, P399, DOI 10.1098/rspb.1986.0030; LONGUETHIGGINS HC, 1984, PROC R SOC SER B-BIO, V223, P165, DOI 10.1098/rspb.1984.0088; MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380; MATSUSHIMA T, 1991, IEEE T INFORM THEORY, V37, P1288, DOI 10.1109/18.133247; MAYBANK S, 1993, THEORY RECONSTRUCTIO; MAYBANK SJ, 1985, P ROY SOC LOND A MAT, V401, P317, DOI 10.1098/rspa.1985.0101; MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126; Mitiche A, 1996, INT J COMPUT VISION, V19, P29, DOI 10.1007/BF00131147; NEGAHDARIPOUR S, 1990, J OPT SOC AM A, V7, P279, DOI 10.1364/JOSAA.7.000279; NEGAHDARIPOUR S, 1990, IEEE T PATTERN ANAL, V12, P1025, DOI 10.1109/34.61703; NEGAHDARIPOUR S, 1989, INT J COMPUT VISION, V3, P293, DOI 10.1007/BF00132601; Ohta N, 1995, IEICE T INF SYST, VE78D, P1559; RISSANEN J, 1984, IEEE T INFORM THEORY, V30, P629, DOI 10.1109/TIT.1984.1056936; RISSANEN J, 1987, STOCHASTIC COMPLEXIT; ROSIN PL, 1995, IEEE T PATTERN ANAL, V17, P1140, DOI 10.1109/34.476507; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; SHIBATA R, 1981, BIOMETRIKA, V68, P45, DOI 10.1093/biomet/68.1.45; STEWART CV, 1995, IEEE T PATTERN ANAL, V17, P925, DOI 10.1109/34.464558; STONE M, 1977, J R STAT SOC B, V39, P44, DOI 10.1111/j.2517-6161.1977.tb01603.x; SUBBARAO M, 1986, COMPUT VISION GRAPH, V36, P208, DOI 10.1016/0734-189X(86)90076-9; TAGAWA N, 1994, IEICE T INF SYST, VE77D, P1148; TAGAWA N, 1993, IEICE T INF SYST, VE76D, P1263; TORR PHS, 1993, IMAGE VISION COMPUT, V11, P180, DOI 10.1016/0262-8856(93)90034-E; TRIONO I, 1996, P IAPR WORKSH MACH V, P393; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; Weng J., 1993, MOTION STRUCTURE IMA; WENG JY, 1991, IEEE T SIGNAL PROCES, V39, P2691, DOI 10.1109/78.107418; WENG JY, 1993, IEEE T PATTERN ANAL, V15, P864, DOI 10.1109/34.232074; YASUMOTO Y, 1986, IEEE T PATTERN ANAL, V8, P464, DOI 10.1109/TPAMI.1986.4767810; YOUNG GSJ, 1992, IEEE T PATTERN ANAL, V14, P995, DOI 10.1109/34.159903; ZABRODSKY H, 1995, IEEE T PATTERN ANAL, V17, P1154, DOI 10.1109/34.476508; ZHANG P, 1992, J AM STAT ASSOC, V87, P732, DOI 10.2307/2290211	65	54	56	0	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	FEB-MAR	1998	26	3					171	189		10.1023/A:1007948927139	http://dx.doi.org/10.1023/A:1007948927139			19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	ZD490					2022-12-18	WOS:000072691200001
J	FERMULLER, C; ALOIMONOS, Y				FERMULLER, C; ALOIMONOS, Y			QUALITATIVE EGOMOTION	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							OPTICAL-FLOW; 3-DIMENSIONAL MOTION; PERCEPTION; OBJECTS; IMAGE	Due to the aperture problem, the only motion measurement in images, whose computation does not require any assumptions about the scene in view, is normal flow-the projection of image motion on the gradient direction. In this paper we show how a monocular observer can estimate its 3D motion relative to the scene by using normal flow measurements in a global and qualitative way. The problem is addressed through a search technique. By checking constraints imposed by 3D motion parameters on the normal flow field, the possible space of solutions is gradually reduced. In the four modules that comprise the solution, constraints of increasing restriction are considered, culminating in testing every single normal flow value for its consistency with a set of motion parameters. The fact that motion is rigid defines geometric relations between certain values of the normal flow field. The selected values form patterns in the image plane that are dependent on only some of the motion parameters. These patterns, which are determined by the signs of the normal flow values, are searched for in order to find the axes of translation and rotation. The third rotational component is computed from normal flow vectors that are only due to rotational motion. Finally, by looking at the complete data set, all solutions that cannot give rise to the given normal flow field are discarded from the solution space.	VIENNA TECH UNIV,INST AUTOMAT,DEPT PATTERN RECOGNIT & IMAGE PROC,A-1040 VIENNA,AUSTRIA; UNIV MARYLAND,INST ADV COMP STUDIES,COLLEGE PK,MD 20742	Technische Universitat Wien; University System of Maryland; University of Maryland College Park	FERMULLER, C (corresponding author), UNIV MARYLAND,CTR AUTOMAT RES,COMP VIS LAB,COLLEGE PK,MD 20742, USA.		Aloimonos, Yiannis/AAI-2969-2020	Aloimonos, Yiannis/0000-0002-8152-4281				Adiv G., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P70; ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; Aloimonos J., 1984, Proceedings of the Workshop on Computer Vision: Representation and Control, P72; ALOIMONOS J, 1989, INTEGRATION VISUAL M; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; BERGHOLM F, 1988, INT J COMPUT VISION, V3, P395; BRUSS AR, 1983, COMPUT VISION GRAPH, V21, P3, DOI 10.1016/S0734-189X(83)80026-7; BURGER W, 1990, IEEE T PATTERN ANAL, V12, P1040, DOI 10.1109/34.61704; Chandrashekhar S., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P2, DOI 10.1109/WVM.1991.212795; FAUGERAS OD, 1990, INT J COMPUT VISION, V4, P225, DOI 10.1007/BF00054997; FERMULLER C, 1992, BIOL CYBERN, V67, P259, DOI 10.1007/BF00204399; FERMULLER C, 1992, ESTIMATING TIME COLL; FERMULLER C, 1994, CARTR722 U MAR CTR A; HILDRETH E, 1983, MEASUREMENT VISUAL M; Horn B. K. P., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P2; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HORN BKP, 1987, INT J COMPUT VISION, V1, P259, DOI 10.1007/BF00127824; HORN BKP, 1990, INT J COMPUT VISION, V4, P59, DOI 10.1007/BF00137443; JAIN R, 1983, IEEE T PATTERN ANAL, V5, P58, DOI 10.1109/TPAMI.1983.4767345; LIU YC, 1988, COMPUT VISION GRAPH, V43, P37, DOI 10.1016/0734-189X(88)90041-2; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; NAVAB N, 1993, P INT C COMPUTER VIS; NEGAHDARIPOUR S, 1986, DIRECT PASSIVE NAVIG; NELSON RC, 1988, BIOL CYBERN, V58, P261, DOI 10.1007/BF00364131; PRAZDNY K, 1981, COMPUT VISION GRAPH, V17, P238, DOI 10.1016/0146-664X(81)90004-6; SPETSAKIS M, 1991, INT J COMPUT VISION, V6, P245, DOI 10.1007/BF00115698; SPETSAKIS M, 1990, INT J COMPUTER VISIO, V1, P171; SPETSAKIS ME, 1988, DEC P INT C COMP VIS, P449; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; ULLMAN S, 1979, PROC R SOC SER B-BIO, V203, P405, DOI 10.1098/rspb.1979.0006; VERRI A, 1989, IEEE T PATTERN ANAL, V11, P490, DOI 10.1109/34.24781; VERRI A, 1992, PHILOS T ROY SOC B, V337, P429, DOI 10.1098/rstb.1992.0119; WAXMAN AM, 1987, ADV COMPUTER VISION; WHITE G, 1988, P INT C COMPUTER VIS, P64	35	54	54	0	4	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	1995	15	1-2					7	29		10.1007/BF01450848	http://dx.doi.org/10.1007/BF01450848			23	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	QY042					2022-12-18	WOS:A1995QY04200002
J	MOONS, T; PAUWELS, EJ; VANGOOL, LJ; OOSTERLINCK, A				MOONS, T; PAUWELS, EJ; VANGOOL, LJ; OOSTERLINCK, A			FOUNDATIONS OF SEMI-DIFFERENTIAL INVARIANTS	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							RECOGNITION	This paper elaborates the theoretical foundations of a semi-differential framework for invariance. Semi-differential invariants combine coordinates and their derivatives with respect to some contour parameter at several points of the image contour, thus allowing for an optimal trade-off between identification of points and the calculation of derivatives. A systematic way of generating complete and independent sets of such invariants is presented. It is also shown that invariance under reparametrisation can be cast in the same framework. The theory is illustrated by a complete analysis of 2D affine transformations. In a companion paper (Pauwels et al. 1995) these affine semi-differential invariants are implemented in the computer program FORM (Flat Object Recognition Method) for the recognition of planar contours under pseudo-perspective projection.			MOONS, T (corresponding author), KATHOLIEKE UNIV LEUVEN,ESAT MI2,KARD MERCIERLAAN 94,B-3001 LOUVAIN,BELGIUM.							ARBTER K, 1990, IEEE T PATTERN ANAL, V12, P640, DOI 10.1109/34.56206; BRILL MH, 1992, GEOMETRIC IVNARIANCE, V9, P193; BRUCKSTEIN AM, 1990, DIFFERENTIAL INVARIA; CHESTER CR, 1971, TECHNIQUES PARTIAL D; COSTA M, 1989, SPIE, V1095, P515; Cyganski D., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P496; FORSYTH DA, 1990, P BMVC 90; Guggenheimer H., 1977, DIFFERENTIAL GEOMETR; KANATANI, 1990, GROUP THEORETICAL ME; KEMPENAERS P, 1991, VISUAL FORM, P323; LAMDAN Y, 1988, APR P IEEE INT C ROB, P1407; Moon P, 1969, PARTIAL DIFFERENTIAL; MOONS T, 1994, KULESATMI29404 KATH; Mundy J., 1992, GEOMETRIC INVARIANCE; Olver P.J., 1986, GRADUATE TEXTS MATH, V107; PAUWELS EJ, 1995, IN PRES SINT J COMPU, V14; ROTHWELL CA, 1991, P BMVC, P62; SAGLE AA, 1973, INTRO LIE GROUPS LIE, V51; Schutz B., 1980, GEOMETRICAL METHODS; ULLMAN S, 1989, COGNITION, V32, P193, DOI 10.1016/0010-0277(89)90036-X; Van Gool L., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P454, DOI 10.1109/CVPR.1991.139735; VANGOOL L, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P530; VANGOOL L, 1992, GEOMETRIC INVARIANCE, P293; VANGOOL L, 1992, GEOMETRIC INVARIANCE, V8, P157; Weiss I., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P291, DOI 10.1109/CVPR.1988.196251; WEISS I, 1991, 1ST P DARPA ESPRIT W, P345; WEISS I, 1992, GEOMETRIC INVARIANCE, V7, P135; WEISS I, 1991, 1ST P DARPA ESPRIT W, P319; WEYL H, 1966, CLASSICAL GROUPS; [No title captured]	30	54	54	0	3	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	1995	14	1					25	47		10.1007/BF01421487	http://dx.doi.org/10.1007/BF01421487			23	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	QG479					2022-12-18	WOS:A1995QG47900002
J	SCHNORR, C				SCHNORR, C			DETERMINING OPTICAL-FLOW FOR IRREGULAR DOMAINS BY MINIMIZING QUADRATIC FUNCTIONALS OF A CERTAIN CLASS	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							IMAGE SEQUENCES; VISUAL-MOTION; REGULARIZATION; FIELDS	Synder (1989) has recently classified all smoothness terms which involve first-order derivatives of the flowfield u(x, t) and of the image grey-value function g(x, t). The physically plausible smoothness terms belonging to this class are known from the work of Horn and Schunck (1981) and Nagel (1987). In this paper we discuss the possibilities of approximating the solutions to the minimization problems of Horn & Schunk (1981) and Nagel (1987). In particular, it is shown that these solutions exist, are unique, and depend continuously on the input data. These properties make it possible, while taking into consideration arbitrary models of the grey-value function, to approximate efficiently the (weak) solutions of the associated boundary-value problems in irregularly shaped domains (with a "sufficiently smooth" boundary) using finite elements. Experiments with image sequences from synthetic as well as outdoor scenes show how the orientation dependency of the smoothness term in Nagel's approach influences the results.	FRAUNHOFER INST INFORMAT & DATA PROC, W-7500 KARLSRUHE 1, GERMANY	Fraunhofer Gesellschaft								ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; ADELSON EH, 1986, MOTION REPRESENTATIO, P151; AGGARWAL JK, 1988, P IEEE, V76, P917, DOI 10.1109/5.5965; ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167; ANANDAN P, 1987, MAY INT C COMP VIS L, P219; Aubin J.-P., 1972, APPROXIMATION ELLIPT; BERTERO M, 1988, P IEEE, V76, P869, DOI 10.1109/5.5962; BERTERO M, 1986, LECT NOTES MATH, V1225, P52; BUZBEE BL, 1970, SIAM J NUMER ANAL, V7, P627, DOI 10.1137/0707049; BUZBEE BL, 1971, SIAM J NUMER ANAL, V8, P722, DOI 10.1137/0708066; Ciarlet P.G., 1978, FINITE ELEMENT METHO; DENGLER J, 1985, THESIS U HEIDELBERG; ENKELMANN W, 1988, COMPUT VISION GRAPH, V43, P150, DOI 10.1016/0734-189X(88)90059-X; Enkelmann W., 1986, Proceedings of the Workshop on Motion: Representation and Analysis (Cat. No.86CH2322-6), P81; ENKELMANN W, 1985, THESIS U HAMBURG; FISHER D, 1974, MATH COMPUT, V28, P349; FLEET DJ, 1989, P IEEE C COMPUT VISI; Fogel S. V., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P619, DOI 10.1109/CCV.1988.590042; Hackbusch W., 1986, THEORIE NUMERIK ELLI; HASHIMOTO M, 1987, COMPUT VISION GRAPH, V39, P28, DOI 10.1016/S0734-189X(87)80201-3; HEEGER DJ, 1987, 1ST P INT C COMP VIS, P181; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HSU YZ, 1984, COMPUT VISION GRAPH, V26, P73, DOI 10.1016/0734-189X(84)90131-2; HUTCHINSON J, 1988, IEEE COMPUT, V21, P52; JACOBSON L, 1987, COMPUT VISION GRAPH, V38, P29, DOI 10.1016/S0734-189X(87)80152-4; LOCKER J, 1980, J MATH ANAL APPL, V74, P504, DOI 10.1016/0022-247X(80)90145-6; MAYBANK SJ, 1987, THESIS U LONDON; MEER P, 1987, IEEE T PATTERN ANAL, V9, P512, DOI 10.1109/TPAMI.1987.4767939; Nagel H.-H., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, P459, DOI 10.1142/S0218001488000273; Nagel H.-H., 1983, IJCAI, P945; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; NAGEL HH, 1987, ARTIF INTELL, V33, P299, DOI 10.1016/0004-3702(87)90041-5; NAGEL HH, 1983, COMPUT VISION GRAPH, V21, P85, DOI 10.1016/S0734-189X(83)80030-9; NAGEL HH, 1984, 1984 DAGM S MUST KEN, P154; NAGEL HH, 1983, 2ND P EUR SIGN PROC, P299; ROHR K, 1989, ROHRSNR10174 IITB FR; SCHNORR C, 1989, MUSTERERKENNUNG 1989, P294; SCHWARZ HR, 1980, METHODE FINITEN ELEM; Simchony T., 1987, Proceedings of the IEEE Computer Society Workshop on Computer Vision (Cat. No.87TH0210-5), P44; SMIRNOV WI, 1976, LEHRGANG HOHEREN M 5; SNYDER MA, 1989, MAR P WORKSH VIS MOT, P107; Strang G., 1973, ANAL FINITE ELEMENT; SWARZTRAUBER PN, 1977, SIAM REV, V19, P491; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P129, DOI 10.1109/TPAMI.1986.4767767; TOET A, 1987, OPTIC FLOW ESTIMATIO; WATSON AB, 1985, J OPT SOC AM A, V2, P322, DOI 10.1364/JOSAA.2.000322; WERKHOVEN P, 1986, 8TH INT C PATT REC P, V2, P798; [No title captured]	48	54	54	0	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	1991	6	1					25	38		10.1007/BF00127124	http://dx.doi.org/10.1007/BF00127124			14	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	FL254					2022-12-18	WOS:A1991FL25400002
J	Marchesotti, L; Murray, N; Perronnin, F				Marchesotti, Luca; Murray, Naila; Perronnin, Florent			Discovering Beautiful Attributes for Aesthetic Image Analysis	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Image aesthetics; Database; Visual attributes; Textual attributes	SELECTION; MODEL	Aesthetic image analysis is the study and assessment of the aesthetic properties of images. Current computational approaches to aesthetic image analysis either provide accurate or interpretable results. To obtain both accuracy and interpretability by humans, we advocate the use of learned and nameable visual attributes as mid-level features. For this purpose, we propose to discover and learn the visual appearance of attributes automatically, using a recently introduced database, called AVA, which contains more than 250,000 images together with their aesthetic scores and textual comments given by photography enthusiasts. We provide a detailed analysis of these annotations as well as the context in which they were given. We then describe how these three key components of AVA-images, scores, and comments-can be effectively leveraged to learn visual attributes. Lastly, we show that these learned attributes can be successfully used in three applications: aesthetic quality prediction, image tagging and retrieval.	[Marchesotti, Luca] Beautifeye, IADT, Media Cube, Dublin, Ireland; [Marchesotti, Luca; Murray, Naila; Perronnin, Florent] Xerox Res Ctr Europe, Meylan, France	Dun Laoghaire Institute of Art & Design; Xerox	Murray, N (corresponding author), Xerox Res Ctr Europe, Meylan, France.	luca@beautifeye.co; naila.murray@xrce.xerox.com; Florent.Perronnin@xrce.xerox.com						Akata Z, 2014, IEEE T PATTERN ANAL, V36, P507, DOI 10.1109/TPAMI.2013.146; Bekkerman R., 2004, IR408 U MASS DEP COM; Berg AC, 2012, PROC CVPR IEEE, P3562, DOI 10.1109/CVPR.2012.6248100; Berg Tamara L, 2010, ECCV; Bottou L., 2007, NIPS; Chatfield K., 2011, BMVC; Chatterjee A, 2011, J COGNITIVE NEUROSCI, V23, P53, DOI 10.1162/jocn.2010.21457; Clinchant S, 2007, IMAGEEVAL WORKSH CVI; Crammer K, 2002, J MACH LEARN RES, V2, P265, DOI 10.1162/15324430260185628; Csurka G., 2004, ECCV, P1; Datta R., 2006, ECCV; Datta R., 2010, MIR; Datta R., 2008, ICIP; Dhar S., 2011, CVPR; Donahue J., 2011, ICCV; Duan Kun, 2012, CVPR; Eastman Kodak Company, 1981, TAK GOOD PICT PHOT G; Farhadi A., 2009, CVPR; FERRARI V, 2007, P ADV NEUR INF PROC; Geng B., 2011, ACM MM; Gracyk T., 2011, STANFORD ENCY PHILOS; Hammermeister Kai, 2002, GERMAN AESTHETIC TRA; Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950; Howitt DL, 2004, SAGE DICT STAT, P21; Isola P., 2011, NIPS, P3; Jacobson E., 1946, COLOR HARMONY MANUAL; Jegou H., 2011, IEEE TPAMI; Joachims T, 1998, ECML; Joshi D, 2011, IEEE SIGNAL PROC MAG, V28, P94, DOI 10.1109/MSP.2011.941851; Ke Y., 2006, CVPR; KRAGES BPK, 2005, PHOTOGRAPHY ART COMP; Lampert C. H., 2009, CVPR; Lazebnik S., 2006, P 2006 IEEE COMP VIS, P2169; Leder H, 2004, BRIT J PSYCHOL, V95, P489, DOI 10.1348/0007126042369811; Li C., 2010, ACM MM; Lowe D. G., 1999, ICCV; Luo W., 2011, ICCV; Luo Y., 2008, ECCV; Machajdik J., 2010, ACM MM; Marchesotti L., 2011, ICCV; Marchesotti L., 2013, BMVC; money, 2006, AM HERITAGE DICT ENG; Muller H, 2010, INFORM RETRIEVAL SER, V32, P1, DOI 10.1007/978-3-642-15181-1; Murray N., 2012, BMVC; Murray N., 2012, CVPR; Ng A., 2002, NIPS; Obrador P., 2010, ICIP; Obrador P, 2012, LECT NOTES COMPUT SC, V7131, P63; Orendovici R., 2010, ACM MM; Pang B., 2012, P ACL 02 C EMP METH; Parikh D., 2011, CVPR; Parikh D., 2011, ICCV; Perronnin F., 2010, ECCV; Perronnin F., 2007, CVPR; Riloff E., 2006, P 2006 C EMP METH NA; Rohrbach M., 2010, CVPR; RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714; San Pedro J., 2012, WWW; Shelley J., 2012, STANFORD ENCY PHILOS; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Torralba A, 2001, IJCV; Wang J., 2009, BMVC; Yanai Keiji, 2005, ACM MM; Yao L., 2012, IJCV; Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x	66	53	54	0	18	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2015	113	3			SI		246	266		10.1007/s11263-014-0789-2	http://dx.doi.org/10.1007/s11263-014-0789-2			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	CK3BZ		Green Submitted			2022-12-18	WOS:000356091900008
J	Rodriguez-Serrano, JA; Gordo, A; Perronnin, F				Rodriguez-Serrano, Jose A.; Gordo, Albert; Perronnin, Florent			Label Embedding: A Frugal Baseline for Text Recognition	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Label embedding; Scene text recognition; Structured learning	HANDWRITING RECOGNITION; WORD RECOGNITION; MODEL	The standard approach to recognizing text in images consists in first classifying local image regions into candidate characters and then combining them with high-level word models such as conditional random fields. This paper explores a new paradigm that departs from this bottom-up view. We propose to embed word labels and word images into a common Euclidean space. Given a word image to be recognized, the text recognition problem is cast as one of retrieval: find the closest word label in this space. This common space is learned using the Structured SVM framework by enforcing matching label-image pairs to be closer than non-matching pairs. This method presents several advantages: it does not require ad-hoc or costly pre-/post-processing operations, it can build on top of any state-of-the-art image descriptor (Fisher vectors in our case), it allows for the recognition of never-seen-before words (zero-shot recognition) and the recognition process is simple and efficient, as it amounts to a nearest neighbor search. Experiments are performed on challenging datasets of license plates and scene text. The main conclusion of the paper is that with such a frugal approach it is possible to obtain results which are competitive with standard bottom-up approaches, thus establishing label embedding as an interesting and simple to compute baseline for text recognition.	[Rodriguez-Serrano, Jose A.] Xerox Res Ctr Europe, Machine Learning Serv Area, Meylan, France; [Gordo, Albert; Perronnin, Florent] Xerox Res Ctr Europe, Comp Vis Grp, Meylan, France	Xerox; Xerox	Rodriguez-Serrano, JA (corresponding author), Xerox Res Ctr Europe, Machine Learning Serv Area, Meylan, France.	Jose-Antonio.Rodriguez@xrce.xerox.com; Albert.Gordo@xrce.xerox.com; Florent.Perronnin@xrce.xerox.com			French ANR project FIRE-ID	French ANR project FIRE-ID(French National Research Agency (ANR))	This work was partially funded by the French ANR project FIRE-ID.	Almazan J., 2013, ICCV; Almazan J, 2014, IEEE T PATTERN ANAL, V36, P2552, DOI 10.1109/TPAMI.2014.2339814; [Anonymous], 2012, ECCV; Bai B., 2009, CIKM; Bazzi I, 1999, IEEE T PATTERN ANAL, V21, P495, DOI 10.1109/34.771314; Bishop C., 1995, NEURAL COMPUTATION; Bishop C.M, 2006, PATTERN RECOGN; Bissacco A., 2013, ICCV; Brakensiek A, 2004, LECT NOTES COMPUT SC, V2956, P103; Brakensiek A., 2000, ICFHR; Breuel T. M., 2001, ICDAR; BUNKE H, 1995, PATTERN RECOGN, V28, P1399, DOI 10.1016/0031-3203(95)00013-P; CASH GL, 1987, COMPUT VISION GRAPH, V39, P291, DOI 10.1016/S0734-189X(87)80183-4; Chatfield K., 2011, BMVC; CHEN MY, 1994, IEEE T PATTERN ANAL, V16, P481; Csurka G., 2004, ECCV, P1; Dutta S., 2012, DAS; El-Yacoubi A, 1999, IEEE T PATTERN ANAL, V21, P752, DOI 10.1109/34.784288; Hinton GE, 2012, IMPROVING NEURAL NET; Jain R., 2010, P 9 IAPR INT WORKSH, P363; Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235; Joachims T., 2002, SIGKDD; Kedem D., 2012, NIPS; Knerr S, 1998, COMPUT VIS IMAGE UND, V70, P404, DOI 10.1006/cviu.1998.0685; Koerich AL, 2003, PATTERN ANAL APPL, V6, P97, DOI 10.1007/s10044-002-0169-3; Larochelle H., 2008, AAAI; Lazebnik S., 2006, P 2006 IEEE COMP VIS, P2169; LeCun Y., 1998, NEURAL NETWORKS TRIC; Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Madhvanath S, 2001, IEEE T PATTERN ANAL, V23, P149, DOI 10.1109/34.908966; Marti UV, 2001, INT J PATTERN RECOGN, V15, P65, DOI 10.1142/S0218001401000848; Mikolov T., 2013, ADV NEURAL INF PROCE, V26; Mishra A., 2012, BMVC; Mishra A., 2012, CVPR; Mohamed M, 1996, IEEE T PATTERN ANAL, V18, P548, DOI 10.1109/34.494644; MORI S, 1999, WILEY MICRO, P1; Nagy G, 2000, IEEE T PATTERN ANAL, V22, P38, DOI 10.1109/34.824820; Neumann L., 2012, IEEE C COMP VIS PATT; Novikova T., 2012, ECCV; Nowozin Sebastian, 2011, FDN TRENDS COMPUTER; Perronnin F., 2010, CVPR; Perronnin F., 2010, ECCV; Perronnin F., 2007, CVPR; Rath T.M., 2003, CVPR; Rodriguez-Serrano J. A., 2013, BMVC; Rodriguez-Serrano JA, 2012, IEEE T PATTERN ANAL, V34, P2108, DOI 10.1109/TPAMI.2012.25; Rodriguez-Serrano Jose A., 2012, ECCV WORKSH COMP VIS; Sankar K., 2010, DAS; Scholkopf B., 1998, NEURAL COMPUTATION; Senior AW, 1998, IEEE T PATTERN ANAL, V20, P309, DOI 10.1109/34.667887; Vinciarelli A, 2004, IEEE T PATTERN ANAL, V26, P709, DOI 10.1109/TPAMI.2004.14; Wang K., 2011, ICCV; Wang K., 2010, ECCV; Weston J., 2010, LEARNING RANK JOINT; Williams C. K. I., 2001, NIPS; Yao C., 2014, CVPR; Zimmermann M, 2006, IEEE T PATTERN ANAL, V28, P818, DOI 10.1109/TPAMI.2006.103	58	53	57	0	12	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2015	113	3			SI		193	207		10.1007/s11263-014-0793-6	http://dx.doi.org/10.1007/s11263-014-0793-6			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	CK3BZ					2022-12-18	WOS:000356091900004
J	Verdoolaege, G; Scheunders, P				Verdoolaege, Geert; Scheunders, Paul			Geodesics on the Manifold of Multivariate Generalized Gaussian Distributions with an Application to Multicomponent Texture Discrimination	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Geodesic distance; Multivariate generalized Gaussian distribution; Texture discrimination; Multicomponent images	IMAGE; RETRIEVAL; TENSOR; PROBABILITY; DISTANCE; DENSITY; SURFACE; SIGNAL	We consider the Rao geodesic distance (GD) based on the Fisher information as a similarity measure on the manifold of zero-mean multivariate generalized Gaussian distributions (MGGD). The MGGD is shown to be an adequate model for the heavy-tailed wavelet statistics in multicomponent images, such as color or multispectral images. We discuss the estimation of MGGD parameters using various methods. We apply the GD between MGGDs to color texture discrimination in several classification experiments, taking into account the correlation structure between the spectral bands in the wavelet domain. We compare the performance, both in terms of texture discrimination capability and computational load, of the GD and the Kullback-Leibler divergence (KLD). Likewise, both uni- and multivariate generalized Gaussian models are evaluated, characterized by a fixed or a variable shape parameter. The modeling of the interband correlation significantly improves classification efficiency, while the GD is shown to consistently outperform the KLD as a similarity measure.	[Verdoolaege, Geert] Univ Ghent, Dept Appl Phys, B-9000 Ghent, Belgium; [Scheunders, Paul] Univ Antwerp, Dept Phys, IBBT Visionlab, B-2610 Antwerp, Belgium	Ghent University; University of Antwerp	Verdoolaege, G (corresponding author), Univ Ghent, Dept Appl Phys, J Plateaustr 22, B-9000 Ghent, Belgium.	geert.verdoolaege@ugent.be	Scheunders, Paul/I-4764-2013; Verdoolaege, Geert/I-4655-2012	Scheunders, Paul/0000-0003-2447-4772; Verdoolaege, Geert/0000-0002-2640-4527	Fund for Scientific Research-Flanders (FWO-Vlaanderen)	Fund for Scientific Research-Flanders (FWO-Vlaanderen)(FWO)	This work was partially funded by the Fund for Scientific Research-Flanders (FWO-Vlaanderen).	ABRAMOWITZ M., 1965, HDB MATH FUNCTIONS; AMARI S, 2000, T MATH MONOGRAPHS, V191; [Anonymous], 1993, MONOGRAPHS STAT APPL; Atkinson C., 1981, SANKHYA A, V43, P345; Benazza-Benyahia A, 2005, IEEE T IMAGE PROCESS, V14, P1814, DOI 10.1109/TIP.2005.857247; Berkane M, 1997, J MULTIVARIATE ANAL, V63, P35, DOI 10.1006/jmva.1997.1690; Berman AP, 1999, COMPUT VIS IMAGE UND, V75, P175, DOI 10.1006/cviu.1999.0772; Boubchir L, 2005, ISSPA 2005: The 8th International Symposium on Signal Processing and its Applications, Vols 1 and 2, Proceedings, P747; BURBEA J, 1982, J MULTIVARIATE ANAL, V12, P575, DOI 10.1016/0047-259X(82)90065-3; Burbea J., 1986, EXPO MATH, V4, P347; BURKHARD WA, 1973, COMMUN ACM, V16, P230, DOI 10.1145/362003.362025; Calvo M, 2002, J COMPUT APPL MATH, V145, P319, DOI 10.1016/S0377-0427(01)00584-2; Castano-Moraga CA, 2007, SIGNAL PROCESS, V87, P263, DOI 10.1016/j.sigpro.2006.02.049; Cenkov N., 1982, TRANSLATIONS MATH MO, V53; Chang C. I., 2007, HYPERSPECTRAL DATA E; Cho D, 2005, SIGNAL PROCESS-IMAGE, V20, P77, DOI 10.1016/j.image.2004.10.003; Cramer H, 1946, SKAND AKTUARIETIDSKR, V29, P85; Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248; DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6; De Backer S, 2008, IMAGE VISION COMPUT, V26, P1038, DOI 10.1016/j.imavis.2007.11.003; De Bonet JS, 1998, PROC CVPR IEEE, P641, DOI 10.1109/CVPR.1998.698672; do Carmo M. P., 1992, RIEMANNIAN GEOMETRY; Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822; Fang K.-T., 1990, GEN MULTIVARIATE ANA; Fang K.T., 1990, MONOGRAPHS STAT APPL, V36; Gomez E, 1998, COMMUN STAT-THEOR M, V27, P589, DOI 10.1080/03610929808832115; JAMES AT, 1973, MULTIVARIATE ANALYSI, P00157; JENSEN S. T., 1976, COMMUNICATION; Kass R. E., 1997, WILEY SERIES IN PROB; KULLBACK S, 1968, INFORM THEORY STAT; Lehmann E., 2003, SPRINGER TEXTS STAT; Lenglet C, 2006, J MATH IMAGING VIS, V25, P423, DOI 10.1007/s10851-006-6897-z; Lenglet C, 2006, IEEE T MED IMAGING, V25, P685, DOI 10.1109/TMI.2006.873299; Mallat S., 1999, WAVELET TOUR SIGNAL, DOI 10.1016/B978-012466606-1/50008-8; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803; Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424; Mardia K. V., 1982, MULTIVARIATE ANAL; MARSAGLIA G, 1972, ANN MATH STAT, V43, P645, DOI 10.1214/aoms/1177692644; Mathiassen J., 2002, EUR C COMP VIS, P19; Mercier G, 2002, INT GEOSCI REMOTE SE, P2584, DOI 10.1109/IGARSS.2002.1026708; Mihcak MK, 1999, IEEE SIGNAL PROC LET, V6, P300, DOI 10.1109/97.803428; MIT vision and modeling group, 2010, VIS TEXT; MITCHELL AFS, 1989, ANN I STAT MATH, V41, P289, DOI 10.1007/BF00049397; MULLER ME, 1959, COMMUN ACM, V2, P19, DOI 10.1145/377939.377946; O'Neill B., 1982, ELEMENTARY DIFFERENT; Pizurica A, 2006, IEEE T IMAGE PROCESS, V15, P654, DOI 10.1109/TIP.2005.863698; Rao C.R., 1945, BULL CALCUTTA MATH S, V37, P81, DOI DOI 10.1007/978-1-4612-0919-5_15; Scheunders P, 2007, IEEE T IMAGE PROCESS, V16, P1865, DOI 10.1109/TIP.2007.899598; SKOVGAARD L, 1981, 813 STAT RES UN DAN; SKOVGAARD LT, 1984, SCAND J STAT, V11, P211; STEPHENS MA, 1964, J AM STAT ASSOC, V59, P160, DOI 10.2307/2282867; Synyavskyy A., 2001, FACT U NIS SERIES EL, V14, P375; Tzagkarakis G, 2006, IEEE T IMAGE PROCESS, V15, P2702, DOI 10.1109/TIP.2006.877356; Van de Wouwer G, 1999, IEEE T IMAGE PROCESS, V8, P592, DOI 10.1109/83.753747; VARANASI MK, 1989, J ACOUST SOC AM, V86, P1404, DOI 10.1121/1.398700; Varma M, 2003, PROC CVPR IEEE, P691; Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182; Verdoolaege G., 2011, J MATH IMAGING UNPUB; Verdoolaege G, 2009, IEEE IMAGE PROC, P265, DOI 10.1109/ICIP.2009.5413405; Verdoolaege G, 2008, IEEE IMAGE PROC, P169, DOI 10.1109/ICIP.2008.4711718; WATSON GS, 1956, BIOMETRIKA, V43, P344, DOI 10.1093/biomet/43.3-4.344	62	53	54	0	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	2011	95	3					265	286		10.1007/s11263-011-0448-9	http://dx.doi.org/10.1007/s11263-011-0448-9			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	913AD		Green Published			2022-12-18	WOS:000301842800003
J	Brune, C; Sawatzky, A; Burger, M				Brune, Christoph; Sawatzky, Alex; Burger, Martin			Primal and Dual Bregman Methods with Application to Optical Nanoscopy	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Imaging; Poisson noise; Bregman distance; Inverse scale space; Duality; Error estimation; Image processing	SCALE-SPACE METHODS; CONVERGENCE-RATES; TIKHONOV REGULARIZATION; VARIATIONAL APPROACH; NOISE; MINIMIZATION; ALGORITHM; MICROSCOPY; LIKELIHOOD; PARAMETER	Measurements in nanoscopic imaging suffer from blurring effects modeled with different point spread functions (PSF). Some apparatus even have PSFs that are locally dependent on phase shifts. Additionally, raw data are affected by Poisson noise resulting from laser sampling and "photon counts" in fluorescence microscopy. In these applications standard reconstruction methods (EM, filtered backprojection) deliver unsatisfactory and noisy results. Starting from a statistical modeling in terms of a MAP likelihood estimation we combine the iterative EM algorithm with total variation (TV) regularization techniques to make an efficient use of a-priori information. Typically, TV-based methods deliver reconstructed cartoon images suffering from contrast reduction. We propose extensions to EM-TV, based on Bregman iterations and primal and dual inverse scale space methods, in order to obtain improved imaging results by simultaneous contrast enhancement. Besides further generalizations of the primal and dual scale space methods in terms of general, convex variational regularization methods, we provide error estimates and convergence rates for exact and noisy data. We illustrate the performance of our techniques on synthetic and experimental biological data.	[Brune, Christoph; Sawatzky, Alex; Burger, Martin] Univ Munster, Inst Numer & Angew Math, D-48149 Munster, Germany	University of Munster	Brune, C (corresponding author), Univ Munster, Inst Numer & Angew Math, Einsteinstr 62, D-48149 Munster, Germany.	christoph.brune@wwu.de; alex.sawatzky@wwu.de; martin.burger@wwu.de	Brune, Christoph/C-1700-2013; Burger, Martin/D-9928-2012	Brune, Christoph/0000-0003-0145-5069; Burger, Martin/0000-0003-2619-2912	German Federal Ministry of Education and Research; Deutsche Telekom Foundation; German Science Foundation DFG	German Federal Ministry of Education and Research(Federal Ministry of Education & Research (BMBF)); Deutsche Telekom Foundation; German Science Foundation DFG(German Research Foundation (DFG))	This work has been supported by the German Federal Ministry of Education and Research through the project INVERS. C. B. acknowledges further support by the Deutsche Telekom Foundation, and M.B. by the German Science Foundation DFG through the project "Regularisierung mit Singularen Energien". The authors thank Dr. Katrin Willig and Dr. Andreas Schonle (MPI Biophysical Chemistry, Gottingen) for providing experimental data and stimulating discussions.	ACAR R, 1994, INVERSE PROBL, V10, P1217, DOI 10.1088/0266-5611/10/6/003; Aubert G, 2008, SIAM J APPL MATH, V68, P925, DOI 10.1137/060671814; Bardsley JM, 2009, INVERSE PROBL, V25, DOI 10.1088/0266-5611/25/9/095005; Bardsley JM, 2009, ADV COMPUT MATH, V31, P35, DOI 10.1007/s10444-008-9081-8; Benning M., 2009, 0940 UCLA CAM; BERTERO M, 2008, CRM SER, V8; Bissantz N, 2007, SIAM J NUMER ANAL, V45, P2610, DOI 10.1137/060651884; Bregman L. M., 1967, COMP MATH MATH PHYS+, V7, P200, DOI DOI 10.1016/0041-5553(67)90040-7; BRUNE C, 2010, FORWARD BACKWARD EM; Brune C, 2009, LECT NOTES COMPUT SC, V5567, P235, DOI 10.1007/978-3-642-02256-2_20; Burger M, 2007, COMPUTING, V81, P109, DOI 10.1007/s00607-007-0245-z; Burger M, 2007, MULTISCALE MODEL SIM, V6, P366, DOI 10.1137/060660564; Burger M, 2006, COMMUN MATH SCI, V4, P179; Burger M, 2004, INVERSE PROBL, V20, P1411, DOI 10.1088/0266-5611/20/5/005; BURGER M, 2009, SIAM J IMAGING SCI, V3; Chambolle A, 2004, J MATH IMAGING VIS, V20, P89; CSISZAR I, 1991, ANN STAT, V19, P2032, DOI 10.1214/aos/1176348385; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Dey N, 2006, MICROSC RES TECHNIQ, V69, P260, DOI 10.1002/jemt.20294; Ekeland I, 1999, CONVEX ANAL VARIATIO; Gariepy RF., 1992, STUDIES ADV MATH; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GEMAN S, 1985, AM STAT ASS, P12; Giusti E., 1984, MONOGRAPHS MATH; Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891; He L, 2005, INT J IMAG SYST TECH, V15, P74, DOI 10.1002/ima.20040; HELL S, 2006, SCI MICROCOPY; Hiriart-Urruty JB., 1993, CONVEX ANAL MINIMIZA; Hofmann B, 2007, INVERSE PROBL, V23, P987, DOI 10.1088/0266-5611/23/3/009; HOHAGE T, 2009, VARIATIONAL REGULARI; Huang YM, 2009, SIAM J IMAGING SCI, V2, P20, DOI 10.1137/080712593; IUSEM AN, 1991, MATH METHOD APPL SCI, V14, P573, DOI 10.1002/mma.1670140805; Jonsson E., 1998, 9848 CAM UCLA; Kittel RJ, 2006, SCIENCE, V312, P1051, DOI 10.1126/science.1126308; Kiwiel KC, 1997, SIAM J CONTROL OPTIM, V35, P1142, DOI 10.1137/S0363012995281742; Klar TA, 2000, P NATL ACAD SCI USA, V97, P8206, DOI 10.1073/pnas.97.15.8206; Le T, 2007, J MATH IMAGING VIS, V27, P257, DOI 10.1007/s10851-007-0652-y; Liao HY, 2009, J OPT SOC AM A, V26, P2311, DOI 10.1364/JOSAA.26.002311; Lorenz DA, 2008, INVERSE PROBL, V24, DOI 10.1088/0266-5611/24/5/055010; Lorenz DA, 2008, J INVERSE ILL-POSE P, V16, P463, DOI 10.1515/JIIP.2008.025; LUCY LB, 1974, ASTRON J, V79, P745, DOI 10.1086/111605; Marquina A, 2009, SIAM J IMAGING SCI, V2, P64, DOI 10.1137/080724289; NATTERER F., 2001, MONOGR MATH MODEL CO, V5; Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412; Panin VY, 1999, IEEE T NUCL SCI, V46, P2202, DOI 10.1109/23.819305; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; REMMELE S, 2008, INFORM AKTUELL, P72, DOI DOI 10.1007/978-3-540-78640-5_15; Resmerita E, 2007, INVERSE PROBL, V23, P2575, DOI 10.1088/0266-5611/23/6/019; Resmerita E, 2007, MATH METHOD APPL SCI, V30, P1527, DOI 10.1002/mma.855; Resmerita E, 2006, INVERSE PROBL, V22, P801, DOI 10.1088/0266-5611/22/3/004; RICHARDSON WH, 1972, J OPT SOC AM, V62, P55, DOI 10.1364/JOSA.62.000055; Rudin L, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P103, DOI 10.1007/0-387-21810-6_6; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; SAWATZKY A, 2008, IEEE NUCL SCI S; Scherzer O, 2001, LECT NOTES COMPUT SC, V2106, P317; Shi JN, 2008, SIAM J IMAGING SCI, V1, P294, DOI 10.1137/070689954; SNYDER DL, 1995, J OPT SOC AM A, V12, P272, DOI 10.1364/JOSAA.12.000272; Strong DM, 2006, MULTISCALE MODEL SIM, V5, P273, DOI 10.1137/040621624; VARDI Y, 1985, J AM STAT ASSOC, V80, P8, DOI 10.2307/2288030; Vogel C. R., 2002, FRONT APPL MATH, DOI DOI 10.1137/1.9780898717570; Wernick M. N, 2004, EMISSION TOMOGRAPHY; Willig KI, 2007, NAT METHODS, V4, P915, DOI 10.1038/NMETH1108; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729	65	53	53	0	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	2011	92	2					211	229		10.1007/s11263-010-0339-5	http://dx.doi.org/10.1007/s11263-010-0339-5			19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	729DR					2022-12-18	WOS:000287929300006
J	Bronstein, AM; Bronstein, MM; Bruckstein, AM; Kimmel, R				Bronstein, Alexander M.; Bronstein, Michael M.; Bruckstein, Alfred M.; Kimmel, Ron			Partial Similarity of Objects, or How to Compare a Centaur to a Horse	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Shape similarity; Partial similarity; Non-rigid shapes; Gromov-Hausdorff distance; Metric geometry; Deformation-invariant similarity; Correspondence; Levenshtein distance; Edit distance; Pareto optimality; Multicriterion optimization	IMAGE RETRIEVAL; INVARIANT SIGNATURES; FRAMEWORK; REPRESENTATION; REGISTRATION; DISTANCES; SURFACES	Similarity is one of the most important abstract concepts in human perception of the world. In computer vision, numerous applications deal with comparing objects observed in a scene with some a priori known patterns. Often, it happens that while two objects are not similar, they have large similar parts, that is, they are partially similar. Here, we present a novel approach to quantify partial similarity using the notion of Pareto optimality. We exemplify our approach on the problems of recognizing non-rigid geometric objects, images, and analyzing text sequences.	[Bronstein, Alexander M.; Bronstein, Michael M.; Bruckstein, Alfred M.; Kimmel, Ron] Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Technion Israel Institute of Technology	Bronstein, AM (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	bronstein@ieee.org	Bronstein, Michael/G-5415-2010	Bronstein, Michael/0000-0002-1262-7252; Bruckstein, Alfred/0000-0001-5669-0037	Center for Security Science and Technology; United States-Israel Binational Science Foundation [2004274]; Ministry of Science [3-3414]; Elias Fund for Medical Research	Center for Security Science and Technology; United States-Israel Binational Science Foundation(US-Israel Binational Science Foundation); Ministry of Science(Ministry of Science, ICT & Future Planning, Republic of Korea); Elias Fund for Medical Research	This research was supported in part by the Center for Security Science and Technology. The authors are grateful to Alexander Brook and Irad Yavneh for valuable comments. This research was partly supported by United States-Israel Binational Science Foundation grant No. 2004274 and by the Ministry of Science grant No. 3-3414, and in part by Elias Fund for Medical Research.	Basri R, 1998, VISION RES, V38, P2365, DOI 10.1016/S0042-6989(98)00043-1; Berchtold S., 1997, VLDB Journal, V6, P333, DOI 10.1007/s007780050049; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BOIMAN O, 2006, P NIPS; Bonhoeffer S, 2004, SCIENCE, V306, P1547, DOI 10.1126/science.1101786; Borg I., 1997, MODERN MULTIDIMENSIO; Bronstein AM, 2008, INT J COMPUT VISION, V78, P67, DOI 10.1007/s11263-007-0078-4; Bronstein AM, 2007, LECT NOTES COMPUT SC, V4485, P264; Bronstein AM, 2007, IEEE T VIS COMPUT GR, V13, P902, DOI 10.1109/TVCG.2007.1041; Bronstein AM, 2006, LECT NOTES COMPUT SC, V3953, P396, DOI 10.1007/11744078_31; Bronstein AM, 2006, LECT NOTES COMPUT SC, V4069, P38; Bronstein AM, 2006, LECT NOTES COMPUT SC, V4069, P48; Bronstein AM, 2006, SIAM J SCI COMPUT, V28, P1812, DOI 10.1137/050639296; Bronstein AM, 2008, MONOGR COMPUT SCI, P1, DOI 10.1007/978-0-387-73301-2_1; Bronstein AM, 2006, P NATL ACAD SCI USA, V103, P1168, DOI 10.1073/pnas.0508601103; Bronstein AM, 2005, INT J COMPUT VISION, V64, P5, DOI 10.1007/s11263-005-1085-y; Bronstein AM, 2003, LECT NOTES COMPUT SC, V2688, P62; BRONSTEIN AM, 2004, P ICIP, P87; BRONSTEIN AM, 2007, P ICCV; BRONSTEIN AM, 2008, CIS200802 DEP COMP S; Bronstein MM, 2006, NUMER LINEAR ALGEBR, V13, P149, DOI 10.1002/nla.475; Bruckstein AM, 1998, IEEE T IMAGE PROCESS, V7, P1583, DOI 10.1109/83.725365; BRUCKSTEIN AM, 1992, INT J COMPUT VISION, V7, P271, DOI 10.1007/BF00126396; Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38; Burago D., 2001, GRADUATE STUDIES MAT, V33, DOI 10.1090/gsm/033; CHEN Y, 2003, P SOC PHOTO-OPT INS, V3656, P523; CHEN Y, 1991, P C ROB AUT; Cheng SW, 2001, COMP GEOM-THEOR APPL, V19, P205, DOI 10.1016/S0925-7721(01)00020-7; CONNELLY R, 1978, MATH INTELL, V1, P130, DOI 10.1007/BF03023258; Damerau F. J., 1964, TECHNIQUE COMPUTER D, P5; DEROOIJ S, 2006, IEEE T INFORM UNPUB; Di Lucca GA, 2002, P INT COMP SOFTW APP, P481, DOI 10.1109/CMPSAC.2002.1045051; DUNN E, 2004, P C EV COMP CEC; Elad A, 2003, IEEE T PATTERN ANAL, V25, P1285, DOI 10.1109/TPAMI.2003.1233902; Everingham M, 2002, LECT NOTES COMPUT SC, V2353, P34; Everson RM, 2006, PATTERN RECOGN LETT, V27, P918, DOI 10.1016/j.patrec.2005.10.016; Felzenszwalb PF, 2005, IEEE T PATTERN ANAL, V27, P208, DOI 10.1109/TPAMI.2005.35; Foote J, 2002, P INT C MUS INF RETR, P265; Foote JT, 1997, P SOC PHOTO-OPT INS, V3229, P138, DOI 10.1117/12.290336; Geiger D, 2003, IEEE T PATTERN ANAL, V25, P86, DOI 10.1109/TPAMI.2003.1159948; GELFAND N, 2005, P S GEOM PROC SGP; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Giles C.L., 1998, CITESEER AUTOMATIC C; GLUCK H, 1974, P C GEOM TOP; Gooskens C., 2004, LANG VAR CHANGE, V16, P189, DOI [DOI 10.1017/S0954394504163023, 10.1017/S0954394504163023]; GREENE B, 2000, ELEGANT UNIVERSE; GROMOV M., 1981, TEXTES MATH, V1; GUDIVADA VN, 1995, COMPUTER, V28, P18, DOI 10.1109/2.410145; HALLINAN PW, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P995, DOI 10.1109/CVPR.1994.323941; HATZIVASSILOGLO.V, 1999, P JOINT SIGDAT C EMP; HOCHBAUM DS, 1985, MATH OPER RES, V10, P180, DOI 10.1287/moor.10.2.180; JACOBS D, 2005, P ICCV, V2, P719; Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197; Kim CR, 2006, INFORM PROCESS MANAG, V42, P484, DOI 10.1016/j.ipm.2005.01.007; Kimmel R, 1998, P NATL ACAD SCI USA, V95, P8431, DOI 10.1073/pnas.95.15.8431; KRUSKAL JB, 1999, OVERVIEW SEQUENCE CO; Latecki LJ, 2000, IEEE T PATTERN ANAL, V22, P1185, DOI 10.1109/34.879802; Latecki LJ, 2005, IMAGE VISION COMPUT, V23, P227, DOI 10.1016/j.imavis.2004.06.015; LEVENSHT.VI, 1965, DOKL AKAD NAUK SSSR+, V163, P845; LING H, 2005, P CVPR; Memoli F, 2005, FOUND COMPUT MATH, V5, P313, DOI 10.1007/s10208-004-0145-y; MUMFORD D, 1990, IMAGE UNDERSTANDING; OLIVEIRA LS, 2002, P INT C PATT REC ICP; Pareto Vilfredo., 1906, MANUALE EC POLITICA, V13th ed; Platel B, 2005, LECT NOTES COMPUT SC, V3753, P211, DOI 10.1007/11577812_19; RAVIV D, 2007, P WORKSH NONR REG TR; Reuter M, 2006, COMPUT AIDED DESIGN, V38, P342, DOI 10.1016/j.cad.2005.10.011; SALUKWADZE ME, 1979, VECTOR VALUED OPTIMI; SETHIAN JA, 1996, ACTA NUMER, P309; Sochen N, 1998, IEEE T IMAGE PROCESS, V7, P310, DOI 10.1109/83.661181; STRICKER M, 1995, P SOC PHOTO-OPT INS, V2420, P381; TAL A, 2001, P EUR WORKSH MULT; TOMASI C, 1998, P ICCV; Veltkamp RC, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P188, DOI 10.1109/SMA.2001.923389; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; WISE MJ, 1996, P 27 SIGCSE TECHN S, P130; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X; ZHANG J, 2004, P CVPR, V2, P342; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149	79	53	55	1	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2009	84	2					163	183		10.1007/s11263-008-0147-3	http://dx.doi.org/10.1007/s11263-008-0147-3			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	451NO					2022-12-18	WOS:000266477100004
J	Wu, YN; Zhu, SC; Liu, XW				Wu, YN; Zhu, SC; Liu, XW			Equivalence of Julesz ensembles and FRAME models	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	7th IEEE International Conference on Computer Vision	SEP 20-27, 1999	KERKYRA, GREECE	IEEE		entropy functions; ensemble equivalence; FRAME models; Julesz ensembles; Kullback-Leibler divergence; large deviation; Markov random fields	LATTICE SYSTEMS; TEXTURE MODELS	In the past thirty years, research on textures has been pursued along two different lines. The first line of research, pioneered by Julesz (1962, IRE Transactions of Information Theory, IT-8:84-92), seeks essential ingredients in terms of features and statistics in human texture perception. This leads us to a mathematical definition of textures in terms of Julesz ensembles (Zhu et al., IEEE Trans. on PAMI, Vol. 22, No. 6, 2000). A Julesz ensemble is a set of images that share the same value of some basic feature statistics. Images in the Julesz ensemble are defined on a large image lattice (a mathematical idealization being Z(2)) so that exact constraint on feature statistics makes sense. The second line of research studies Markov random field (MRF) models that characterize texture patterns on finite (or small) image lattice in a statistical way. This leads us to a general class of MRF models called FRAME (Filter, Random field, And Maximum Entropy) (Zhu et al., Neural Computation, 9:1627-1660). In this article, we bridge the two lines of research by the fundamental principle of equivalence of ensembles in statistical mechanics (Gibbs, 1902, Elementary Principles of Statistical Mechanics. Yale University Press). We show that 1). As the size of the image lattice goes to infinity, a FRAME model concentrates its probability mass uniformly on a corresponding Julesz ensemble. Therefore, the Julesz ensemble characterizes the global statistical property of the FRAME model; 2). For a large image randomly sampled from a Julesz ensemble, any local patch of the image given its environment follows the conditional distribution specified by a corresponding FRAME model. Therefore, the FRAME model describes the local statistical property of the Julesz ensemble, and is an inevitable texture model on finite (or small) lattice if texture perception is decided by feature statistics. The key to derive these results is the large deviation estimate of the volume of (or the number of images in) the Julesz ensemble, which we call the entropy function. Studying the equivalence of ensembles provides deep insights into questions such as the origin of MRF models, typical images of statistical models, and error rates in various texture related vision tasks (Yuille and Coughlan, IEEE Trans. on PAMI, Vol. 2, No. 2, 2000). The second thrust of this paper is to study texture distance based on the texture models of both small and large lattice systems. We attempt to explain the asymmetry phenomenon observed in texture "pop-out" experiments by the asymmetry of Kullback-Leibler divergence. Our results generalize the traditional signal detection theory (Green and Swets, 1988, Signal Detection Theory and Psychophysics, Peninsula Publishing) for distance measures from iid cases to random fields. Our theories are verified by two groups of computer simulation experiments.	Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA; Ohio State Univ, Dept Comp & Informat Sci, Columbus, OH 43210 USA	University of California System; University of California Los Angeles; University System of Ohio; Ohio State University	Wu, YN (corresponding author), Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA.							AZENCOTT R, 1997, IEEE T PAMI, V19; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; DEBONET JS, 1997, ADV NEURAL INFORMATI, V10; GAGALOWICZ A, 1986, COMPUT GRAPH-UK, V10, P161, DOI 10.1016/0097-8493(86)90042-7; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Gibbs JW., 1960, ELEMENTARY PRINCIPLE; GREEN DM, 1988, SIGNAL DETECTION THE; GRIFFITHS RB, 1971, COMMUN MATH PHYS, V23, P169, DOI 10.1007/BF01877738; HEEGER DJ, 1995, P ACM SIGGRAPHS; JULESZ B, 1995, DIAGLOUES PERCEPTION; Julesz B., 1962, IRE T INFORM THEOR, V8, P84, DOI 10.1109/TIT.1962.1057698; Lanford O.E, 1973, STAT MECH MATH PROBL, P1; Leung T., 1999, P 7 INT C COMP VIS C; Lewis J. T., 1995, MARKOV PROCESS RELAT, V1, P319; LIU F, 1996, IEEE T PATTERN ANAL, V18; MALIK J, 1990, J OPTICAL SOC AM, V7; MARTINLOF A, 1979, J STAT PHYS, V20, P557, DOI 10.1007/BF01012899; Meng XL, 1996, STAT SINICA, V6, P831; Portilla J., 1999, P IEEE WORKSH STAT C; Richards W, 1995, PERCEPTION, V24, P1315, DOI 10.1068/p241315; Rosenholtz R, 1999, VISION RES, V39, P3157, DOI 10.1016/S0042-6989(99)00077-2; Rubner Y., 1998, STANCSTN9886; VISTNES R, 1989, INT J COMPUT VISION, V3, P313, DOI 10.1007/BF00132602; YUILLE AL, 2000, IEEE T PAMI, V22; Zhu SC, 1997, NEURAL COMPUT, V9, P1627, DOI 10.1162/neco.1997.9.8.1627; ZHU SC, 1997, IEEE T PATTERN ANAL, V19; ZHU SC, 1999, IEEE T PAMI, V21; ZHU SC, 2000, IEEE T PAMI, V22; ZHU SC, 2000, P SPIE AER C AUT TAR	30	53	53	0	0	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2000	38	3					247	265		10.1023/A:1008199424771	http://dx.doi.org/10.1023/A:1008199424771			19	Computer Science, Artificial Intelligence	Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	352VV					2022-12-18	WOS:000089239400005
J	Kang, SB; Szeliski, R				Kang, SB; Szeliski, R			3-D scene data recovery using omnidirectional multibaseline stereo	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						omnidirectional stereo; multibaseline stereo; panoramic structure from motion; 8-point algorithm; scene modeling; 3-D median filtering	MOTION	A traditional approach to extracting geometric information from a large scene is to compute multiple 3-D depth maps from stereo pairs or direct range finders, and then to merge the 3-D data. However, the resulting merged depth maps may be subject to merging errors if the relative poses between depth maps are not known exactly. In addition, the 3-D data may also have to be resampled before merging, which adds additional complexity and potential sources of errors. This paper provides a means of directly extracting 3-D data covering a very wide field of view, thus by-passing the need for numerous depth map merging. In our work, cylindrical images are first composited from sequences of images taken while the camera is rotated 360 degrees about a vertical axis. By taking such image panoramas at different camera locations, we can recover 3-D data of the scene using a set of simple techniques: feature tracking, an 8-point structure from motion algorithm, and multibaseline stereo. We also investigate the effect of median filtering on the recovered 3-D point distributions, and show the results of our approach applied to both synthetic and real scenes.	MICROSOFT CORP, REDMOND, WA 98052 USA	Microsoft	Kang, SB (corresponding author), DIGITAL EQUIPMENT CORP, CAMBRIDGE RES LAB, 1 KENDALL SQ, BLDG 700, CAMBRIDGE, MA 02139 USA.							Ayache N, 1991, ARTIFICIAL VISION MO; AZARBAYEJANI A, 1995, IEEE T PATTERN ANAL, V17, P562, DOI 10.1109/34.387503; BARNARD ST, 1982, ACM COMPUT SURV, V14, P553, DOI DOI 10.1145/356893.356896; BOLLES RC, 1987, INT J COMPUT VISION, V1, P7, DOI 10.1007/BF00128525; DERICHE R, 1994, P EUR C COMP VIS STO, P567; DHOND UR, 1989, IEEE T SYST MAN CYB, V19, P1489, DOI 10.1109/21.44067; FAUGERAS OD, 1992, 2 EUR C COMP VIS ECC, P563; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Ferrie F. P., 1987, Proceedings of the IEEE Computer Society Workshop on Computer Vision (Cat. No.87TH0210-5), P117; FREEDMAN DH, 1995, DISCOVER, V16, P48; Hartley R. I., 1995, Proceedings. Fifth International Conference on Computer Vision (Cat. No.95CB35744), P1064, DOI 10.1109/ICCV.1995.466816; HIGUCHI K, 1993, CMUCS93214; ISHIGURO H, 1992, IEEE T PATTERN ANAL, V14, P257, DOI 10.1109/34.121792; KANG SB, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P88, DOI 10.1109/ICCV.1995.466802; KANG SB, 1996, 962 DIG EQ CORP CAMB; KANG SB, 1995, 957 DIG EQ CORP CAMB; KOLB CE, 1994, RAYSHADE USERS GUIDE; KRISHNAN A, 1996, IEEE COMP SOC C COMP; KUGLIN CD, 1975, IEEE C CYB SOC, P163; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; McMillan L., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P39, DOI 10.1145/218380.218398; MURRAY DW, 1995, COMPUT VIS IMAGE UND, V61, P285, DOI 10.1006/cviu.1995.1021; OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955; PARVIN B, 1992, IEEE INT C ROB AUT I, P1602; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; Shabana A. A, 1989, DYNAMICS MULTIBODY S; SHASHUA A, 1994, IEEE T PATTERN ANAL, V16, P778, DOI 10.1109/34.308472; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; SHUM HY, 1994, IEEE COMP SOC C COMP, P560; STEIN GP, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P230, DOI 10.1109/ICCV.1995.466781; Szeliski R, 1996, IEEE COMPUT GRAPH, V16, P22, DOI 10.1109/38.486677; Szeliski R., 1994, Journal of Visual Communication and Image Representation, V5, P10, DOI 10.1006/jvci.1994.1002; SZELISKI R, 1995, INT S COMP VIS COR G, P241; SZELISKI R, 1994, 942 DIG EQ CORP CAMB; Szeliski R., 1994, IEEE COMP SOC C COMP, P194; TAYLOR CJ, 1996, 4 EUR C COMP VIS ECC, P659; Tian TY, 1996, PROC CVPR IEEE, P315, DOI 10.1109/CVPR.1996.517091	37	53	59	0	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	1997	25	2					167	183		10.1023/A:1007971901577	http://dx.doi.org/10.1023/A:1007971901577			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	YG836					2022-12-18	WOS:A1997YG83600004
J	COOMBS, D; BROWN, C				COOMBS, D; BROWN, C			REAL-TIME BINOCULAR SMOOTH-PURSUIT	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							EYE-MOVEMENTS	This article examines the problem of a moving robot tracking a moving object with its cameras, without requiring the ability to recognize the target to distinguish it from distracting surroundings. A novel aspect of the approach taken is the use of controlled camera movements to simplify the visual processing necessary to keep the cameras locked on the target. A gaze-holding system implemented on a robot's binocular head demonstrates this approach. Even while the robot is moving, the cameras are able to track an object that rotates and moves in three dimensions. The central idea is that localizing attention in 3-D space makes precategorical visual processing sufficient to hold gaze. Visual fixation can help separate the target object from distracting surroundings. Converged cameras produce a horopter (surface of zero stereo disparity) in the scene. Binocular features with no disparity can be located with a simple filter, showing the object's location in the image. Similarly, an object that is being tracked is imaged near the center of the field of view, so spatially localized processing helps concentrate visual attention on the target. Instead of requiring a way to recognize the target, the system relies on active control of camera movements and binocular fixation segmentation to locate the target.	UNIV ROCHESTER,DEPT COMP SCI,ROCHESTER,NY 14627	University of Rochester	COOMBS, D (corresponding author), US TECHNOL ADM,NIST,MFG ENGN LAB,DIV ROBOT SYST,BLDG 220,ROOM B-124,GAITHERSBURG,MD 20899, USA.							AGRE PE, 1987, AAAI 87, P268; ALLEN P, 1989, P DARPA IMAGE UNDERS; Bar-Shalom Y., 1988, TRACKING DATA ASS; Bogert B.P., 1963, P S TIM SER AN, V15, P209; BROWN C, 1990, BIOL CYBERN, V63, P61, DOI 10.1007/BF00202454; BROWN C, 1991, 387 U ROCH COMP SCI; Carpenter RHS, 1988, MOVEMENTS EYES; CLARK J, 1988, 2ND P INT C COMP VIS; COOMBS D, 1991, IEEE CONTROL SYS JUN; COOMBS D, 1992, 9TH P SPIE C INT ROB, P15; CORKE P, 1989, MSCIS8918 U PENNS DE; DORF RC, 1980, MODERN CONTROL SYSTE; Howard I., 1982, HUMAN VISUAL ORIENTA; JENKIN M, 1991, P C COMPUT IS PATT R; KRAUZLIS R, 1989, NEURAL COMPUT, P1; LAND M, 1975, HDB PSYCHOBIOLOGY, P49; LEE SW, 1988, MSCIS897 U PENNS COM; LISBERGER SG, 1987, ANNU REV NEUROSCI, V10, P97, DOI 10.1146/annurev.ne.10.030187.000525; MATTHIES L, 1989, INT J COMPUT VISION, V3, P209, DOI 10.1007/BF00133032; MCDONALD JD, 1983, IEEE T SYST MAN CYB, V13, P167, DOI 10.1109/TSMC.1983.6313110; NISHIHARA HK, 1984, OPT ENG, V23, P536, DOI 10.1117/12.7973334; OLSON T, 1992, 11TH P SPIE C INT RO, P15; OLSON T, 1991, OCT P IEEE INT C SYS; OLSON TJ, 1991, INT J COMPUT VISION, V7, P67, DOI 10.1007/BF00130490; PAHLAVAN K, 1992, 2ND P EUR C COMP VIS, P18; PAPANIKOLOPOULOS N, 1991, P INT IEEE C ROBOT A; READING RW, 1983, BINOCULAR VISION F A; ROJER A, 1990, P INT C PATT RECOG; SHINKMAN P, 1985, ADV NEURAL BEHAVIORA; THORPE C, 1983, CMURITR8319 CARN MEL; TILLEY DG, 1990, 315 U ROCH COMP SCI; TOLG S, 1992, 11TH P SPIE C INT RO, P585; TSOTSOS J, 1988, INT COMPUT VIS   JAN, V1; TYLER C, 1979, PHYSL HUMAN EYE VISU, P634; VANDERSPIEGEL J, 1989, ANALOG VLSI IMPLEMEN; WAVERING AJ, 1993, MAY P IEEE INT C ROB; WAXMAN AM, 1988, NEURAL NETWORKS S1, V1, P365; WHITHEAD S, 1990, NEURAL COMPUTATION, V2; YOUNG LR, 1971, CONTROL EYE MOVEMENT	39	53	55	0	5	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	OCT	1993	11	2					147	164		10.1007/BF01469226	http://dx.doi.org/10.1007/BF01469226			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	MB329					2022-12-18	WOS:A1993MB32900004
J	Jourabloo, A; Liu, XM				Jourabloo, Amin; Liu, Xiaoming			Pose-Invariant Face Alignment via CNN-Based Dense 3D Model Fitting	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Pose-invariant face alignment; CNN; Cascaded regressor; Dense model fitting; Mirrorability constraint		Pose-invariant face alignment is a very challenging problem in computer vision, which is used as a prerequisite for many facial analysis tasks, e.g., face recognition, expression recognition, and 3D face reconstruction. Recently, there have been a few attempts to tackle this problem, but still more research is needed to achieve higher accuracy. In this paper, we propose a face alignment method that aligns an image with arbitrary poses, by combining the powerful cascaded CNN regressors, 3D Morphable Model (3DMM), and mirrorability constraint. The core of our proposed method is a novel 3DMM fitting algorithm, where the camera projection matrix parameters and 3D shape parameters are estimated by a cascade of CNN-based regressors. Furthermore, we impose the mirrorability constraint during the CNN learning by employing a novel loss function inside the siamese network. The dense 3D shape enables us to design pose-invariant appearance features for effective CNN learning. Extensive experiments are conducted on the challenging large-pose face databases (AFLW and AFW), with comparison to the state of the art.	[Jourabloo, Amin; Liu, Xiaoming] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA	Michigan State University	Liu, XM (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.	jourablo@msu.edu; liuxm@cse.msu.edu						Amberg B, 2008, IEEE INT CONF AUTOMA, P667; [Anonymous], 2014, ARXIV14101037; Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602; Bell S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766959; Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339; Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191; Cao C, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601204; Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249; Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3; COOTES TF, 1994, BMVC94 - PROCEEDINGS OF THE 5TH BRITISH MACHINE VISION CONFERENCE, VOLS 1 AND 2, P327; Glorot X., 2011, P 14 INT C ART INT S, P315; Hsu GS, 2015, IEEE I CONF COMP VIS, P3855, DOI 10.1109/ICCV.2015.439; Jeni Laszlo A., 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163142; Jeni LA, 2016, LECT NOTES COMPUT SC, V9914, P511, DOI 10.1007/978-3-319-48881-3_35; Jia Y., 2014, P 22 ACM INT C MULT, P675; Jourabloo A, 2016, PROC CVPR IEEE, P4188, DOI 10.1109/CVPR.2016.454; Jourabloo A, 2015, IEEE I CONF COMP VIS, P3694, DOI 10.1109/ICCV.2015.421; Jourabloo A, 2015, INT CONF BIOMETR, P278, DOI 10.1109/ICB.2015.7139096; Koestinger M., 2011, ICCV WORKSH, DOI [10.1109/ICCVW.2011.6130513, DOI 10.1109/ICCVW.2011.6130513]; Liu XM, 2010, IMAGE VISION COMPUT, V28, P1162, DOI 10.1016/j.imavis.2009.09.016; Liu XM, 2009, IEEE T PATTERN ANAL, V31, P1941, DOI 10.1109/TPAMI.2008.238; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58; Pfister T, 2015, LECT NOTES COMPUT SC, V9003, P538, DOI 10.1007/978-3-319-16865-4_35; Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790; Qu CC, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301348; Roth J, 2016, PROC CVPR IEEE, P4197, DOI 10.1109/CVPR.2016.455; Roth J, 2015, PROC CVPR IEEE, P2606, DOI 10.1109/CVPR.2015.7298876; Saragih JM, 2009, IEEE I CONF COMP VIS, P1034, DOI 10.1109/ICCV.2009.5459377; Shan SG, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P314; Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Tulyakov S, 2015, IEEE I CONF COMP VIS, P3748, DOI 10.1109/ICCV.2015.427; Tzimiropoulos G, 2015, PROC CVPR IEEE, P3659, DOI 10.1109/CVPR.2015.7298989; Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412; Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112; Wu Y, 2015, IEEE I CONF COMP VIS, P3658, DOI 10.1109/ICCV.2015.417; Xiangyu Zhu, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163096; Xiao J, 2004, PROC CVPR IEEE, P535; Yang B, 2015, IEEE I CONF COMP VIS, P82, DOI 10.1109/ICCV.2015.18; Yang H, 2015, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2015.7299100; YOSINSKI J, 2014, ADV NEURAL INFORM PR, P3320, DOI DOI 10.1109/IJCNN.2016.7727519; Yu X, 2014, LECT NOTES COMPUT SC, V8692, P105, DOI 10.1007/978-3-319-10593-2_8; Yu X, 2013, IEEE I CONF COMP VIS, P1944, DOI 10.1109/ICCV.2013.244; ZAGORUYKO S, 2015, 2015 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2015.7299064; Zhang JT, 2009, CIV ENG ENVIRON SYST, V26, P35, DOI 10.1080/10286600802003567; Zhang J, 2014, LECT NOTES COMPUT SC, V8690, P1, DOI 10.1007/978-3-319-10605-2_1; Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7; Zhou EJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P386, DOI 10.1109/ICCVW.2013.58; Zhu SZ, 2015, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2015.7299134; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014; Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679	55	52	54	4	32	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2017	124	2					187	203		10.1007/s11263-017-1012-z	http://dx.doi.org/10.1007/s11263-017-1012-z			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	FC3PK					2022-12-18	WOS:000406751100005
J	Bariya, P; Novatnack, J; Schwartz, G; Nishino, K				Bariya, Prabin; Novatnack, John; Schwartz, Gabriel; Nishino, Ko			3D Geometric Scale Variability in Range Images: Features and Descriptors	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Range image; Scale variability; Scale-space; Geometric feature; Shape descriptor; Range image registration; 3D object recognition	OBJECT RECOGNITION; AUTOMATIC REGISTRATION; HARMONIC MAPS; HEAT-FLOW; SPACE	Despite their ubiquitous presence, little has been investigated about the scale variability-the relative variations in the spatial extents of local structures-of 3D geometric data. In this paper we present a comprehensive framework for exploiting this 3D geometric scale variability in range images that provides rich information for characterizing the overall geometry. We derive a sound scale-space representation, which we refer to as the geometric scale-space, that faithfully encodes the scale variability of the surface geometry, and derive novel detectors to extract prominent features and identify their natural scales. The result is a hierarchical set of features of different scales which we refer to as scale-dependent geometric features. We then derive novel local shape descriptors that represent the surface structures that give rise to those features by carving out and encoding the local surface that fall within the support regions of the features. This leads to scale-dependent or scale-invariant local shape descriptors that convey significant discriminative information of the object geometry. We demonstrate the effectiveness of geometric scale analysis on range images, and show that it enables novel applications, in particular, fully automatic registration of multiple objects from a mixed set of range images and 3D object recognition in highly cluttered range image scenes.	[Bariya, Prabin; Novatnack, John; Schwartz, Gabriel; Nishino, Ko] Drexel Univ, Dept Comp Sci, Philadelphia, PA 19104 USA	Drexel University	Nishino, K (corresponding author), Drexel Univ, Dept Comp Sci, 3141 Chestnut St, Philadelphia, PA 19104 USA.	pb339@drexel.edu; jmn27@drexel.edu; gbs25@drexel.edu; kon@drexel.edu			National Science Foundation [IIS-0746717, IIS-0803670]	National Science Foundation(National Science Foundation (NSF))	This work was supported in part by National Science Foundation CAREER Award IIS-0746717 and IIS-0803670. The Armadillo, Happy Buddha, and Dragon models were provided courtesy of Stanford University Computer Graphics Laboratory. The Chinese Lion and Eros models were provided courtesy of INRIA by the AIM@SHAPE Shape Repository. The Sitting Buddha model was provided courtesy of VCG-ISTI by the AIM@SHAPE Shape Repository. The Chef, Chicken, Parasaurolophus, T-Rex and Rhino models and 50 scenes containing them were provided courtesy of the University of Western Australia. The Angel, BigBird, Gnome, Kid and Zoe models and 80 point cloud scenes containing them were provided courtesy of Queen's University, Canada.	Akagunduz E, 2007, IEEE I CONF COMP VIS, P55; [Anonymous], 2010, MESHLAB; Bariya P., 2010, IEEE C COMP VIS PATT; Brady M., 1985, AIM822 MIT AR LAB; Bro R, 2008, J CHEMOMETR, V22, P135, DOI 10.1002/cem.1122; Carmo M. P., 1976, DIFFERENTIAL GEOMETR, V2nd; CHANG KC, 1992, J DIFFER GEOM, V36, P507; Chen CS, 1999, IEEE T PATTERN ANAL, V21, P1229, DOI 10.1109/34.809117; Chua CS, 1997, INT J COMPUT VISION, V25, P63, DOI 10.1023/A:1007981719186; Cohen R., 1987, THEORY APPL LIQ CRYS, P99; CORON JM, 1990, ANN I H POINCARE-AN, V7, P335, DOI 10.1016/S0294-1449(16)30295-5; Dinh H. Quynh, 2006, P IEEE INT C COMP VI, V1, P863; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FLYNN PJ, 1991, IEEE T PATTERN ANAL, V13, P1066, DOI 10.1109/34.99239; FREIRE A, 1995, CALC VAR PARTIAL DIF, V3, P95, DOI 10.1007/s005260050008; Frome A., 2004, EUR C COMP VIS; GELFAND N., 2005, S GEOM PROC; Grimson W. E. L., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P218, DOI 10.1109/CCV.1988.589993; Grimson W. E. L., 1990, OBJECT RECOGNITION C; Hardt RM, 1997, B AM MATH SOC, V34, P15, DOI 10.1090/S0273-0979-97-00692-7; Huber DF, 2003, IMAGE VISION COMPUT, V21, P637, DOI 10.1016/S0262-8856(03)00060-X; Johnson A., 1998, P 1998 IM UND WORKSH, V431, P1097; Johnson A., 1997, THESIS CARNEGIE MELL; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; Kazhdan Michael, 2006, P EUR S GEOM PROC, V7, P2; Kimmel R, 1997, LECT NOTES COMPUT SC, V1252, P212; Kimmel R, 1998, P NATL ACAD SCI USA, V95, P8431, DOI 10.1073/pnas.95.15.8431; Lab QURCV, 2009, QUEENS RANG IM 3 D M; LALONDE JF, 2005, INT C 3 D DIG IM MOD; Li X., 2005, S GEOM PROC; Li XJ, 2007, IEEE I CONF COMP VIS, P9; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; Lindeberg T., 1994, SCALE SPACE THEORY C; Makadia A., 2006, P IEEE C COMP VIS PA, V1, P1297, DOI DOI 10.1109/CVPR.2006.122; Mian AS, 2006, IEEE T PATTERN ANAL, V28, P1584, DOI 10.1109/TPAMI.2006.213; Mian AS, 2004, THEORY AND PRACTICE OF COMPUTER GRAPHICS 2004, PROCEEDINGS, P162, DOI 10.1109/TPCG.2004.1314466; Mokhtarian F, 2001, COMPUT VIS IMAGE UND, V83, P118, DOI 10.1006/cviu.2001.0919; Morita S., 1992, EUR C COMP VIS; Nishino K., 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P454; Novatnack J, 2008, LECT NOTES COMPUT SC, V5304, P440, DOI 10.1007/978-3-540-88690-7_33; Novatnack J, 2007, IEEE I CONF COMP VIS, P2001; Pauly M, 2006, ACM T GRAPHIC, V25, P177, DOI 10.1145/1138450.1138451; Ponce J., 1985, IEEE INT C ROB AUTO, V2, P420; Schlattmann M., 2006, CENTRAL EUROPEAN SEM, P169; Skelly L. J., 2007, P SPIE C 2 3 DIMENSI, V6762, P63; STEIN F, 1992, IEEE T PATTERN ANAL, V14, P125, DOI 10.1109/34.121785; Sun Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P263, DOI 10.1109/ICCV.2001.937634; Taati B, 2009, THESIS QUEENS U ONTA; Taati B, 2007, IEEE I CONF COMP VIS, P15; Tang B, 2000, INT J COMPUT VISION, V36, P149, DOI 10.1023/A:1008152115986; Taubin G., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P351, DOI 10.1145/218380.218473; ter Haar FB, 2007, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2007, PROCEEDINGS, P137, DOI 10.1109/SMI.2007.10; UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573; Unnikrishnan R., 2008, IEEE INT C COMP VIS; Weickert J, 1999, J MATH IMAGING VIS, V10, P237, DOI 10.1023/A:1008344623873; Witkin A., 1984, P IEEE INT C AC SPEE, V9, P150, DOI DOI 10.1109/ICASSP.1984.1172729; Zhang D., 1999, IEEE INT C COMP VIS, V2; Zou GY, 2009, IEEE T VIS COMPUT GR, V15, P1193, DOI 10.1109/TVCG.2009.159	60	52	52	0	24	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2012	99	2					232	255		10.1007/s11263-012-0526-7	http://dx.doi.org/10.1007/s11263-012-0526-7			24	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	943RU					2022-12-18	WOS:000304143700006
J	Miyazaki, D; Hara, K; Ikeuchi, K				Miyazaki, Daisuke; Hara, Kenji; Ikeuchi, Katsushi			Median Photometric Stereo as Applied to the Segonko Tumulus and Museum Objects	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	Workshop on Photometric Analysis for Computer Vision held in Conjunction with the 11th International Conference on Computer Vision Conference	OCT 04, 2007	Rio de Janeiro, BRAZIL			Photometric stereo; M-estimation; Virtual museum; Cultural asset	SEPARATING REFLECTIONS; TRANSPARENT LAYERS; MULTIPLE IMAGES; LIGHT-SOURCE; SHAPE; SURFACES; FLASH; RECONSTRUCTION; PHOTOGRAPHY; HIGHLIGHTS	One of the necessary techniques for constructing a virtual museum is to estimate the surface normal and the albedo of the artwork which has high specularity. In this paper, we propose a novel photometric stereo method which is robust to the specular reflection of the object surface. Our method can also digitize the artwork arranged inside a glass or acrylic display case without bringing the artwork out of the display case. Our method treats the specular reflection at the object surface or at the display case as an outlier, and finds a good surface normal evading the influence of the outliers. We judiciously design the cost function so that the outlier will be automatically removed under the assumption that the object's shape and color are smooth. At the end of this paper, we also show some archived 3D data of Segonko Tumulus and objects in the University Museum at The University of Tokyo that were generated by applying the proposed method.	[Miyazaki, Daisuke; Ikeuchi, Katsushi] Univ Tokyo, Inst Ind Sci, Meguro Ku, Tokyo 1538505, Japan; [Hara, Kenji] Kyushu Univ, Fac Design, Minato Ku, Fukuoka 8158540, Japan	University of Tokyo; Kyushu University	Miyazaki, D (corresponding author), Hiroshima City Univ, Grad Sch Informat Sci, Asaminami Ku, 3-4-1 Ozukahigashi, Hiroshima 7313194, Japan.	miyazaki@hiroshima-cu.ac.jp						*ADOBE, 2009, AD PHOT; AGRAWAL A, 2006, P EUR C COMP VIS, P578; Alldrin N., 2008, P IEEE C COMP VIS PA; Barsky S, 2003, IEEE T PATTERN ANAL, V25, P1239, DOI 10.1109/TPAMI.2003.1233898; Basri R, 2007, INT J COMPUT VISION, V72, P239, DOI 10.1007/s11263-006-8815-7; Belhumeur PN, 1999, INT J COMPUT VISION, V35, P33, DOI 10.1023/A:1008154927611; BIRKBECK N, 2006, P EUR C COMP VIS, P536; Chandraker M.K., 2007, P IEEE C COMP VIS PA; Chen CP, 2006, LECT NOTES COMPUT SC, V3953, P72, DOI 10.1007/11744078_6; COLEMAN EN, 1982, COMPUT VISION GRAPH, V18, P309, DOI 10.1016/0146-664X(82)90001-6; Courant R, 2008, METHODS MATH PHYS PA; Drew M. S., 1995, Proceedings International Symposium on Computer Vision (Cat. No.95TB100006), P419, DOI 10.1109/ISCV.1995.477038; Eisemann E, 2004, ACM T GRAPHIC, V23, P673, DOI 10.1145/1015706.1015778; Farid H, 1999, J OPT SOC AM A, V16, P2136, DOI 10.1364/JOSAA.16.002136; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FUA P, 1995, INT J COMPUT VISION, V16, P35, DOI 10.1007/BF01428192; Georghiades AS, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P816; Goldman DB, 2005, IEEE I CONF COMP VIS, P341; Hahn D. V., 2006, P SOC PHOTO-OPT INS, V6056, P130; HAYAKAWA H, 1994, J OPT SOC AM A, V11, P3079, DOI 10.1364/JOSAA.11.003079; Hertzmann A, 2005, IEEE T PATTERN ANAL, V27, P1254, DOI 10.1109/TPAMI.2005.158; Horn B., 1986, ROBOT VISION, P1; IKEUCHI K, 1984, P INT C PATT REC, P736; KIM B, 1991, CVGIP-IMAG UNDERSTAN, V54, P416, DOI 10.1016/1049-9660(91)90040-V; KLINKER GJ, 1988, INT J COMPUT VISION, V2, P7, DOI 10.1007/BF00836279; Levin A, 2004, PROC CVPR IEEE, P306; Levin A, 2004, LECT NOTES COMPUT SC, V3021, P602; Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719; Lim J, 2005, IEEE I CONF COMP VIS, P1635; LU C, 2006, P COL IM C; LU JP, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P80; Magda S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P391, DOI 10.1109/ICCV.2001.937652; *MINOLTA3D, 2009, KON MIN VIVID 910; Mukaigawa Y, 2007, J OPT SOC AM A, V24, P3326, DOI 10.1364/JOSAA.24.003326; Narasimhan SG, 2005, IEEE I CONF COMP VIS, P420; Nayar SK, 2006, ACM T GRAPHIC, V25, P935, DOI 10.1145/1141911.1141977; NAYAR SK, 1990, IEEE T ROBOTIC AUTOM, V6, P418, DOI 10.1109/70.59367; NAYAR SK, 1991, INT J COMPUT VISION, V6, P173, DOI 10.1007/BF00115695; NAYAR SK, 1991, IEEE T PATTERN ANAL, V13, P611, DOI 10.1109/34.85654; Oishi T, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P476, DOI 10.1109/3DIM.2005.41; Oo T, 2007, MACH VISION APPL, V18, P17, DOI [10.1007/s00138-006-0043-1, 10.1007/S00138-006-0043-1]; Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777; Press W.H., 1997, NUMER RECIPES C; Ragheb H, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P18, DOI 10.1109/TDPVT.2004.1335136; Raskar R, 2004, ACM T GRAPHIC, V23, P679, DOI 10.1145/1015706.1015779; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Sarel B, 2005, IEEE I CONF COMP VIS, P26; Sarel B, 2004, LECT NOTES COMPUT SC, V2034, P328; Sato I., 2007, P INT C COMP VIS; Sato Y., 1995, Proceedings of the Workshop on Physics-Based Modeling in Computer Vision (Cat. No.95TB8038), P180, DOI 10.1109/PBMCV.1995.514684; Schechner YY, 2000, J OPT SOC AM A, V17, P276, DOI 10.1364/JOSAA.17.000276; Schechner YY, 2000, INT J COMPUT VISION, V39, P25, DOI 10.1023/A:1008166017466; Seitz SM, 2005, IEEE I CONF COMP VIS, P1440; Shen L, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P326; Simakov D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1202; Solomon F, 1996, IEEE T PATTERN ANAL, V18, P449, DOI 10.1109/34.491627; Sun J, 2006, ACM T GRAPHIC, V25, P772, DOI 10.1145/1141911.1141954; Sun J, 2007, IMAGE VISION COMPUT, V25, P1050, DOI 10.1016/j.imavis.2006.04.025; Szeliski R, 2000, PROC CVPR IEEE, P246, DOI 10.1109/CVPR.2000.855826; Tan P., 2007, P IEEE C COMP VIS PA; TAN P, 2006, P EUR C COMP VIS, P58; Tang KL, 2005, PROC CVPR IEEE, P132; Tominaga S, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P70; Tsai R.Y., 1986, P IEEE C COMP VIS PA, P364; TU P, 2003, P IEEE COMP SOC C CO; Wada T, 1997, INT J COMPUT VISION, V24, P125, DOI 10.1023/A:1007906904009; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; WOODHAM RJ, 1991, PHOTOMETRIC STEREO L; Wu TG, 2006, PROCEEDINGS OF THE 6TH INTERNATIONAL CYTOKINE CONFERENCE, P159; Wu TP, 2006, IEEE T PATTERN ANAL, V28, P1830, DOI 10.1109/TPAMI.2006.224; Wu TP, 2005, PROC CVPR IEEE, P140; Yang J, 1997, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.1997.609307; Yuille AL, 1999, INT J COMPUT VISION, V35, P203, DOI 10.1023/A:1008180726317; Zhang L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P618, DOI 10.1109/ICCV.2003.1238405; Zickler TE, 2002, INT J COMPUT VISION, V49, P215, DOI 10.1023/A:1020149707513; ZICKLER TE, 2003, P IEEE COMP SOC C CO	76	52	57	1	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2010	86	2-3			SI		229	242		10.1007/s11263-009-0262-9	http://dx.doi.org/10.1007/s11263-009-0262-9			14	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	534NA					2022-12-18	WOS:000272903200008
J	Lookingbill, A; Rogers, J; Lieb, D; Curry, J; Thrun, S				Lookingbill, A.; Rogers, J.; Lieb, D.; Curry, J.; Thrun, S.			Reverse optical flow for self-supervised adaptive autonomous robot navigation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						off-road navigation; terrain classification; optical flow; mobile robots; computer vision	CLASSIFICATION; VISION	Autonomous mobile robot navigation, either off-road or on ill-structured roads, presents unique challenges for machine perception. A successful terrain or roadway classifier must be able to learn in a self-supervised manner and adapt to inter- and intra-run changes in the local environment. This paper demonstrates the improvements achieved by augmenting an existing self-supervised image segmentation procedure with an additional supervisory input. Obstacles and roads may differ in appearance at distance because of illumination and texture frequency properties. Reverse optical flow is added as an input to the image segmentation technique to find examples of a region of interest at previous times in the past. This provides representations of this region at multiple scales and allows the robot to better determine where more examples of this class appear in the image.	Stanford Univ, Stanford Artificial Intelligence Lab, Stanford, CA 94305 USA	Stanford University	Lookingbill, A (corresponding author), Stanford Univ, Stanford Artificial Intelligence Lab, Stanford, CA 94305 USA.	apml@stanford.edu; jgrogers@stanford.edu; dlieb@stanford.edu; curryj@stanford.edu; thrun@stanford.edu						ASENSIO JR, 1999, IEEE P INT C ROB AUT, V4, P2905; BELLUTTA P, 2000, P INT VEH C DEARB MI; Berthod M, 1996, IMAGE VISION COMPUT, V14, P285, DOI 10.1016/0262-8856(95)01072-6; Bouguet Jean yves, 2000, PYRAMIDAL IMPLEMENTA, P1; Coombs D, 1998, IEEE T ROBOTIC AUTOM, V14, P49, DOI 10.1109/70.660840; CRISMAN J, 1991, P INT C ROB AUT SACR; DALPOZ AP, 2003, ISPRS ARCH, V34; DeSouza GN, 2002, IEEE T PATTERN ANAL, V24, P237, DOI 10.1109/34.982903; Durrant-Whyte H., 2001, SAND20013685; Ettinger S.M., 2002, FLOR C REC ADV ROB; Giachetti A, 1998, IEEE T ROBOTIC AUTOM, V14, P34, DOI 10.1109/70.660838; HORSWILL I, 1993, PROCEEDINGS OF THE ELEVENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P824; IAGNEMMA KD, 2002, P SPIE C UNM GROUND, V4; Kang DJ, 2003, PATTERN RECOGN LETT, V24, P3177, DOI 10.1016/j.patrec.2003.08.003; KATO Z, 1992, P ICQSSP SAN FRANC, V3, P573; KATO Z, 1994, THESIS INRIA SOPHIA; Kim H, 2002, LECT NOTES COMPUT SC, V2532, P806; LIEB D, 2005, P ROB SCI SYST; Lorigo L. M., 1997, Proceedings of the 1997 IEEE/RSJ International Conference on Intelligent Robot and Systems. Innovative Robotics for Real-World Applications. IROS '97 (Cat. No.97CH36108), P373, DOI 10.1109/IROS.1997.649086; Manduchi R, 2005, AUTON ROBOT, V18, P81, DOI 10.1023/B:AURO.0000047286.62481.1d; MOOREHEAD S, 1999, INT S ART INT ROB AU; Murray D, 2000, AUTON ROBOT, V8, P161, DOI 10.1023/A:1008987612352; Pilutti T, 1998, P AMER CONTR CONF, P1838, DOI 10.1109/ACC.1998.707335; POMERLEAU D, 1995, IEEE S INT VEH DETR; RASMUSSEN C, 2002, P IEEE INT C ROB AUT; REDMILL K, 2001, P IEEE INT TRANSP SY; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Shirkhodaie A, 2004, P SOC PHOTO-OPT INS, V5608, P118, DOI 10.1117/12.579298; Shoemaker CM, 1998, P SOC PHOTO-OPT INS, V3366, P202, DOI 10.1117/12.317547; SINGH S, 2001, P 7 AUSTR NZ INT INF; SOFMAN B, 2006, IN PRESS P ROBOTICS; STENTZ A, 1994, IEEE INT CONF ROBOT, P3310, DOI 10.1109/ROBOT.1994.351061; Ulrich I, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P866; YASNOFF WA, 1977, PATTERN RECOGN, V9, P217, DOI 10.1016/0031-3203(77)90006-1	34	52	58	0	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2007	74	3					287	302		10.1007/s11263-006-0024-x	http://dx.doi.org/10.1007/s11263-006-0024-x			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	192YG					2022-12-18	WOS:000248239400005
J	Baker, S; Nayar, K; Murase, H				Baker, S; Nayar, K; Murase, H			Parametric feature detection	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							COMPUTATIONAL APPROACH; EDGE DETECTORS; OPERATOR; IMAGES	Most visual features are parametric in nature, including, edges, lines, corners, and junctions. We propose an algorithm to automatically construct detectors for arbitrary parametric features. To maximize robustness we use realistic multi-parameter feature models and incorporate optical and sensing effects. Each feature is represented as a densely sampled parametric manifold in a low dimensional subspace of a Hilbert space. During detection, the vector of intensity values in a window about each pixel in the image is projected into the subspace. If the projection lies sufficiently close to the feature manifold, the feature is detected and the location of the closest manifold point yields the feature parameters. The concepts of parameter reduction by normalization, dimension reduction, pattern rejection, and heuristic search are all employed to achieve the required efficiency. Detectors have been constructed for five features, namely, step edge (five parameters), roof edge (five parameters), line (six parameters), corner (five parameters), and circular disc (six parameters). The results of detailed experiments are presented which demonstrate the robustness of feature detection and the accuracy of parameter estimation.	Columbia Univ, Dept Comp Sci, New York, NY 10027 USA; NTT Corp, Basic Res Lab, Atsugi, Kanagawa 24301, Japan	Columbia University; Nippon Telegraph & Telephone Corporation	Baker, S (corresponding author), Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.	simonb@cs.columbia.edu; nayar@cs.columbia.edu; murase@siva.ntt.jp						ABDOU IE, 1979, P IEEE, V67, P753, DOI 10.1109/PROC.1979.11325; BAKER S, 1996, P IEEE C COMP VIS PA; BARBE DF, 1980, CHARGE COIUPLED DEVI; BERZINS V, 1984, COMPUT VISION GRAPH, V27, P195, DOI 10.1016/S0734-189X(84)80043-2; Born M., 1968, PRINCIPLES OPTICS; BRACEWELL RN, 1978, FOURIER TRANSFORM IT; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; DERICHE R, 1993, INT J COMPUT VISION, V10, P101, DOI 10.1007/BF01420733; DEUTSCH ES, 1978, IEEE T COMPUT, V27, P205, DOI 10.1109/TC.1978.1675073; FRAM JR, 1975, IEEE T COMPUT, VC 24, P616, DOI 10.1109/T-C.1975.224274; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475; HARTLEY R, 1985, COMPUT VISION GRAPH, V30, P70, DOI 10.1016/0734-189X(85)90019-2; *HN ABR INC, 1984, MUS MOD ART NEW YORK; Horn B., 1986, ROBOT VISION, P1; HUECKEL MH, 1973, J ACM, V20, P634, DOI 10.1145/321784.321791; HUECKEL MH, 1971, J ACM, V18, P113, DOI 10.1145/321623.321635; HUMMEL RA, 1979, COMPUT VISION GRAPH, V9, P40, DOI 10.1016/0146-664X(79)90081-9; Knuth D. E., 1981, ART COMPUTER PROGRAM, V2; KRUMM J, 1996, P IEEE C COMP VIS PA; LENZ R, 1987, PATTERN RECOGN, V20, P163, DOI 10.1016/0031-3203(87)90050-1; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Moravec H. P., 1977, P 5 INT JOINT C ART; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Nalwa V. S., 1993, GUIDED TOUR COMPUTER; NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852; NANDY D, 1996, P ARPA IM UND WORKSH; NAYAR SK, 1996, P IEEE C COMP VIS PA; NOBLE JA, 1988, IMAGE VISION COMPUT, V6, P121, DOI 10.1016/0262-8856(88)90007-8; NORTON HN, 1982, SENSOR ANAL HDB; OGORMAN F, 1978, ARTIF INTELL, V10, P215, DOI 10.1016/S0004-3702(78)80013-7; OJA E, 1983, SUBSPACE METHODS PAT; PRATT W, 1990, DIGITAL IMAGE PROCES; Prewitt J., 1970, PICTURE PROCESSING P, VVolume 10; ROHR K, 1992, INT J COMPUT VISION, V9, P213, DOI 10.1007/BF00133702; ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519; YANILOS PN, 1993, P ACM SIAM S DISCR A; ZUCKER SW, 1981, IEEE T PATTERN ANAL, V3, P324, DOI 10.1109/TPAMI.1981.4767105	39	52	58	0	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	1998	27	1					27	50		10.1023/A:1007901712605	http://dx.doi.org/10.1023/A:1007901712605			24	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	ZH371					2022-12-18	WOS:000073101800002
J	Govindaraju, V				Govindaraju, V			Locating human faces in photographs	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							ALGORITHM; CURVES	The human face is an object that is easily located in complex scenes by infants and adults alike. Yet the development of an automated system to perform this task is extremely challenging. An attempt to solve this problem raises two important issues in object location. First, natural objects such as human faces tend to have boundaries which are not exactly described by analytical functions. Second, the object of interest (face) could occur in a scene in various sizes, thus requiring the use of scale independent techniques which can detect instances of the object at al scales. Although, the task of identifying a well-framed face (as one of a set of labeled faces) has been well researched, the task of locating a face in a natural scene is relatively unexplored. We present a computational theory for locating human faces in scenes with certain constraints. The theory will be validated by experiments confined to instances where people's faces are the primary subject of the scene, occlusion is minimal, and the faces contrast well against the background.			Govindaraju, V (corresponding author), SUNY BUFFALO, DEPT COMP SCI, CEDAR, 226 BELL HALL, BUFFALO, NY 14260 USA.							ARNOLD EC, 1969, MODERN NEWSPAPER DES; AUGUSTEIJN MF, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P392, DOI 10.1109/ICNN.1993.298589; BEUS HL, 1987, PATTERN RECOGN, V20, P291, DOI 10.1016/0031-3203(87)90004-5; BROMLEY LK, 1977, THESIS U HOUSTON; Cheng J. K., 1982, Proceedings of PRIP 82. IEEE Computer Society Conference on Pattern Recognition and Image Processing, P343; CIBA N, 1985, SIAM J COMPUT, V14, P210; FARKAS LG, 1987, ANTHR FACIAL PROPORT; FISCHLER MA, 1973, IEEE T COMPUT, pC22; FREEMAN H, 1977, IEEE T COMPUT, V26, P297, DOI 10.1109/TC.1977.1674825; GOVINDARAJU V, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P718; GOVINDARAJU V, 1990, ADV IMAGING, V5, P22; GOVINDARAJU V, 1992, P AAAI 92 SAN JOSE C, P350; GOVINDARAJU V, 1989, P IEEE CS C COMPUTER, P278; GOVINDARSHU V, LECT NOTES ARTIFICIA, V444, P375; KANADE T, 1973, PICTURE PROCESSING S; LAMBERT LC, 1987, THESIS AIR FORCE I T; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; MEDIONI G, 1987, COMPUT VISION GRAPH, V39, P267, DOI 10.1016/S0734-189X(87)80181-0; PAVLIDIS T, 1982, GRAPHICS IMAGER PROC; SAKAI T, 1969, PATTERN RECOGN, V2, P233; SEITZ P, 1991, P SOC PHOTO-OPT INS, V1606, P252, DOI 10.1117/12.50340; SMITH EJ, 1986, THESIS AIR FORCE I T; SRIHARI RK, 1991, TYHESIS STATE U NEW; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Vaillant R., 1993, Revue Technique Thomson-CSF, V25, P23; VAILLIANT R, 1993, 3 INT C ART NEUR NET, V372, P26; WALTERS D, 1987, COMMUNICATION; YHUILLE A, 1988, 882 HARV ROB LAB	28	52	62	0	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	1996	19	2					129	146		10.1007/BF00055801	http://dx.doi.org/10.1007/BF00055801			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	VE939					2022-12-18	WOS:A1996VE93900002
J	WEINSHALL, D				WEINSHALL, D			MODEL-BASED INVARIANTS FOR 3-D VISION	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							MOTION; RECOGNITION; IMAGES	Invariance under a group of 3-D transformations seems a desirable component of an efficient 3-D shape representation. We propose representations which are invariant under weak perspective to either rigid or linear 3-D transformations, and we show how they can be computed efficiently from a sequence of images with a linear and incremental algorithm. We show simulated results with perspective projection and noise, and the results of model acquisition from a real sequence of images. The use of linear computation, together with the integration through time of invariant representations, offers improved robustness and stability. Using these invariant representations, we derive model-based projective invariant functions of general 3-D objects. We discuss the use of the model-based invariants with existing recognition strategies: alignment without transformation, and constant time indexing from 2-D images of general 3-D objects.	IBM CORP,TJ WATSON RES CTR,HAWTHORNE,NY 10532	International Business Machines (IBM)								ALOIMONOS J, 1986, JUN P IEEE C COMP VI, P510; BURNS JB, 1990, APR P DARPA IM UND W, P650; CLEMENS DT, 1991, IEEE T PATTERN ANAL, V13, P1007, DOI 10.1109/34.99235; FAUGERAS OD, 1992, 2 EUR C COMP VIS ECC, P563; FORSYTH D, 1991, IEEE T PATTERN ANAL, V13, P971, DOI 10.1109/34.99233; GROS P, 1991, RT69IMAG7LIFIA U GRE; HEEGER DJ, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P96; HUANG TS, 1989, IEEE T PATTERN ANAL, V11, P536, DOI 10.1109/34.24786; JACOBS DW, 1992, JAN P DARPA IM UND W; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; Lamdan Y., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P238, DOI 10.1109/CCV.1988.589995; MITSUMOTO H, 1992, IEEE T PATTERN ANAL, V14, P941, DOI 10.1109/34.161352; MOHAN R, 1993, 4TH P INT C COMP VIS; MOHN R, 1992, RT84IMAG12LIFIA U GR; MOSES Y, 1991, AI1301 MIT ART INT L; POGGIO T, 1992, AI1347 MIT ART INT L; SAWHNEY HS, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P494; SHASHUA A, 1991, AI1327 MIT ART INT L; TOAMSI C, 1991, OCT IEEE WORKSH MOT, P21; Tomasi C., 1991, CMUCS91132 CARN MELL; ULLMAN S, 1984, PERCEPTION, V13, P255, DOI 10.1068/p130255; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; Ullman S., 1983, HUMAN MACHINE VISION; WEINSHALL D, 1993, 4TH P INT C COMP VIS; WEISS I, 1988, JAN P IEEE C COMP VI, P291; [No title captured]	26	52	52	0	0	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	FEB	1993	10	1					27	42		10.1007/BF01440845	http://dx.doi.org/10.1007/BF01440845			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	LP384					2022-12-18	WOS:A1993LP38400002
J	Brubaker, MA; Fleet, DJ; Hertzmann, A				Brubaker, Marcus A.; Fleet, David J.; Hertzmann, Aaron			Physics-Based Person Tracking Using the Anthropomorphic Walker	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Tracking people; Physics; Passive-based walking	NONRIGID MOTION; LOCOMOTION; ROBOTS; SIMULATION; MODEL; BODY	We introduce a physics-based model for 3D person tracking. Based on a biomechanical characterization of lower-body dynamics, the model captures important physical properties of bipedal locomotion such as balance and ground contact. The model generalizes naturally to variations in style due to changes in speed, step-length, and mass, and avoids common problems (such as footskate) that arise with existing trackers. The dynamics comprise a two degree-of-freedom representation of human locomotion with inelastic ground contact. A stochastic controller generates impulsive forces during the toe-off stage of walking, and spring-like forces between the legs. A higher-dimensional kinematic body model is conditioned on the underlying dynamics. The combined model is used to track walking people in video, including examples with turning, occlusion, and varying gait. We also report quantitative monocular and binocular tracking results with the HumanEva dataset.	[Brubaker, Marcus A.; Fleet, David J.; Hertzmann, Aaron] Univ Toronto, Dept Comp Sci, Toronto, ON, Canada	University of Toronto	Brubaker, MA (corresponding author), Univ Toronto, Dept Comp Sci, Toronto, ON, Canada.	mbrubake@cs.toronto.edu; fleet@cs.toronto.edu; hertzman@dgp.toronto.edu		/0000-0003-0734-7114; Brubaker, Marcus/0000-0002-7892-9026; Hertzmann, Aaron/0000-0001-9667-0292	NSERC Canada; Canadian Institute for Advanced Research (CIFAR); Canada Foundation for Innovation (CFI); Alfred P. Sloan Foundation; Microsoft Research; Ontario Ministry of Research and Innovation	NSERC Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)); Canadian Institute for Advanced Research (CIFAR)(Canadian Institute for Advanced Research (CIFAR)); Canada Foundation for Innovation (CFI)(Canada Foundation for Innovation); Alfred P. Sloan Foundation(Alfred P. Sloan Foundation); Microsoft Research(Microsoft); Ontario Ministry of Research and Innovation(Ministry of Research and Innovation, Ontario)	This work was financially supported in part by NSERC Canada, the Canadian Institute for Advanced Research (CIFAR), the Canada Foundation for Innovation (CFI), the Alfred P. Sloan Foundation, Microsoft Research and the Ontario Ministry of Research and Innovation. A preliminary version of this work appeared in Brubaker et al. (2007).	Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21; Bissacco A, 2005, PROC CVPR IEEE, P421; Black M. J., 2006, CS0608 BROWN U; BLICKHAN R, 1993, J COMP PHYSIOL A, V173, P509; BRUBAKER MA, 2008, P IEEE C COMP VIS PA; BRUBAKER MA, 2007, P IEEE C COMP VIS PA; CHAN M, 1994, INT C PATT RECOG, P432, DOI 10.1109/ICPR.1994.576317; Choo K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P321, DOI 10.1109/ICCV.2001.937643; Collins S, 2005, SCIENCE, V307, P1082, DOI 10.1126/science.1107799; Collins SH, 2001, INT J ROBOT RES, V20, P607, DOI 10.1177/02783640122067561; COLLINS SH, 2005, P IEEE C ROB AUT; Delamarre Q, 2001, COMPUT VIS IMAGE UND, V81, P328, DOI 10.1006/cviu.2000.0892; Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038; Elgammal A, 2004, PROC CVPR IEEE, P681; Fleet D, 2006, HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION, P239; Full RJ, 1999, J EXP BIOL, V202, P3325; Goldstein H., 2001, CLASSICAL MECH; Herda L, 2005, COMPUT VIS IMAGE UND, V99, P189, DOI 10.1016/j.cviu.2005.01.005; HODGINS JK, 1995, P SIGGRAPH 95, P71; Kakadiaris I, 2000, IEEE T PATTERN ANAL, V22, P1453, DOI 10.1109/34.895978; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Khan Z, 2004, PROC CVPR IEEE, P980; KONG A, 1994, J AM STAT ASSOC, V89, P278, DOI 10.2307/2291224; KOVAR L, 2002, P S COMP AN; Kuo AD, 2001, J BIOMECH ENG-T ASME, V123, P264, DOI 10.1115/1.1372322; Kuo AD, 2002, J BIOMECH ENG-T ASME, V124, P113, DOI 10.1115/1.1427703; Liu CK, 2005, ACM T GRAPHIC, V24, P1071, DOI 10.1145/1073204.1073314; MCGEER T, 1990, INT J ROBOT RES, V9, P62, DOI 10.1177/027836499000900206; McGeer T., 1992, Advances in Comparative and Environmental Physiology, V11, P113; McGeer T., 1990, Proceedings 1990 IEEE International Conference on Robotics and Automation (Cat. No.90CH2876-1), P1640, DOI 10.1109/ROBOT.1990.126245; METAXAS D, 1993, IEEE T PATTERN ANAL, V15, P580, DOI 10.1109/34.216727; Pavlovic V., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P94, DOI 10.1109/ICCV.1999.791203; PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P730, DOI 10.1109/34.85661; Pitt MK, 1999, J AM STAT ASSOC, V94, P590, DOI 10.2307/2670179; Popovic Z, 1999, COMP GRAPH, P11, DOI 10.1145/311535.311536; Pratt GA, 2000, IEEE ROBOT AUTOM MAG, V7, P15, DOI 10.1109/100.876907; Rahimi A, 2005, PROC CVPR IEEE, P868; ROBERT CP, 1995, STAT COMPUT, V5, P121, DOI 10.1007/BF00143942; Rosales R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P378, DOI 10.1109/ICCV.2001.937543; Safonova A, 2004, ACM T GRAPHIC, V23, P514, DOI 10.1145/1015706.1015754; Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750; Shin HJ, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P194; Sidenbladh H., 2000, LNCS, V2, P702; Sminchisescu C, 2004, P ICML, P96; Sminchisescu C, 2007, IEEE T PATTERN ANAL, V29, P2030, DOI 10.1109/TPAMI.2007.1111; Terzopoulos D., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P606, DOI 10.1109/ICCV.1990.139605; Urtasun R, 2005, IEEE I CONF COMP VIS, P403; URTASUN R, 2006, P 2006 IEEE COMP SOC, V1, P238, DOI DOI 10.1109/CVPR.2006.15; VANDERLINDE RQ, 2002, LECT NOTES MULTIBO B; VONDRAK M, 2008, P IEEE C COMP VIS PA; Wachter S, 1999, COMPUT VIS IMAGE UND, V74, P174, DOI 10.1006/cviu.1999.0758; Wisse M, 2007, IEEE T ROBOT, V23, P112, DOI 10.1109/TRO.2006.886843; Witkin A., 1988, Computer Graphics, V22, P159, DOI 10.1145/378456.378507; WREN CR, 1998, P AUT FAC GEST REC; Yin KK, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239556	55	51	51	1	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2010	87	1-2			SI		140	155		10.1007/s11263-009-0274-5	http://dx.doi.org/10.1007/s11263-009-0274-5			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	539GP		Green Submitted			2022-12-18	WOS:000273242300008
J	Kumano, S; Otsuka, K; Yamato, J; Maeda, E; Sato, Y				Kumano, Shiro; Otsuka, Kazuhiro; Yamato, Junji; Maeda, Eisaku; Sato, Yoichi			Pose-Invariant Facial Expression Recognition Using Variable-Intensity Templates	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Facial expression recognition; Variable-intensity templates; Intensity distribution models; Particle filter	AUTOMATIC-ANALYSIS; SEQUENCES; HEAD	In this paper, we propose a method for pose-invariant facial expression recognition from monocular video sequences. The advantage of our method is that, unlike existing methods, our method uses a simple model, called the variable-intensity template, for describing different facial expressions. This makes it possible to prepare a model for each person with very little time and effort. Variable-intensity templates describe how the intensities of multiple points, defined in the vicinity of facial parts, vary with different facial expressions. By using this model in the framework of a particle filter, our method is capable of estimating facial poses and expressions simultaneously. Experiments demonstrate the effectiveness of our method. A recognition rate of over 90% is achieved for all facial orientations, horizontal, vertical, and in-plane, in the range of +/- 40 degrees, +/- 20 degrees, and +/- 40 degrees from the frontal view, respectively.	[Kumano, Shiro; Sato, Yoichi] Univ Tokyo, Inst Ind Sci, Meguro Ku, Tokyo 1538505, Japan; [Otsuka, Kazuhiro; Yamato, Junji; Maeda, Eisaku] Nippon Telegraph & Tel Corp, NTT Commun Sci Labs, Atsugi, Kanagawa 2430198, Japan	University of Tokyo; Nippon Telegraph & Telephone Corporation	Kumano, S (corresponding author), Univ Tokyo, Inst Ind Sci, Meguro Ku, 4-6-1 Komaba, Tokyo 1538505, Japan.	kumano@iis.u-tokyo.ac.jp	Otsuka, Kazuhiro/AAP-7814-2020	Otsuka, Kazuhiro/0000-0003-4352-3955				Bartlett M. S., 2006, Journal of Multimedia, V1, DOI 10.4304/jmm.1.6.22-35; BEATON AE, 1974, TECHNOMETRICS, V16, P147, DOI 10.2307/1267936; Black MJ, 1997, INT J COMPUT VISION, V25, P23, DOI 10.1023/A:1007977618277; CASCIA ML, 2000, IEEE T PATTERN ANAL, V22, P322; Castrillon M, 2007, J VIS COMMUN IMAGE R, V18, P130, DOI 10.1016/j.jvcir.2006.11.004; Chang Y, 2006, IMAGE VISION COMPUT, V24, P605, DOI 10.1016/j.imavis.2005.08.006; Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X; Dornaika F, 2008, INT J COMPUT VISION, V76, P257, DOI 10.1007/s11263-007-0059-7; Ekman P., 1975, UNMASKING FACE GUIDE; Ekman P., 2002, FACS INVESTIGATORS G; Ekman P., 2002, FACIAL ACTION CODING; Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3; Fasel B, 2004, P 6 ACM SIGMM INT WO, P181; Geman S, 1987, B INT STAT I, V4, P5; Gokturk SB, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P287, DOI 10.1109/AFGR.2002.1004168; Gross R, 2005, IMAGE VISION COMPUT, V23, P1080, DOI 10.1016/j.imavis.2005.07.009; HU Y, 2008, P IEEE INT C AUT FAC; Huang CL, 1997, J VIS COMMUN IMAGE R, V8, P278, DOI 10.1006/jvci.1997.0359; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Koelstra S., 2008, P IEEE INT C AUT FAC; Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954; KUMANO S, 2007, P AS C COMP VIS, V1, P324; Lanitis A, 1997, IEEE T PATTERN ANAL, V19, P743, DOI 10.1109/34.598231; Liao W.-K., 2006, P IEEE SOC C COMP VI, P158; Littlewort G, 2006, IMAGE VISION COMPUT, V24, P615, DOI 10.1016/j.imavis.2005.09.011; Loy G, 2003, IEEE T PATTERN ANAL, V25, P959, DOI 10.1109/TPAMI.2003.1217601; Lucey S, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P155; Matsuoka H, 2005, EPILEPSIA, V46, P17, DOI 10.1111/j.0013-9580.2005.461006.x; MURPHY C, 2008, IEEE T PATT IN PRESS; Oka K, 2005, LECT NOTES COMPUT SC, V3723, P308; Otsuka K, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P255; Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976; Pantic M, 2000, IMAGE VISION COMPUT, V18, P881, DOI 10.1016/S0262-8856(00)00034-2; PANTIC M, 2007, I TECH ED PUBLISHING, P377; Russell SJ, 1995, ARTIF INTELL, V4th; Sebe N, 2007, IMAGE VISION COMPUT, V25, P1856, DOI 10.1016/j.imavis.2005.12.021; Tang H., 2008, P IEEE INT C AUT FAC; Tian Y.-L., 2005, FACIAL EXPRESSION AN; Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962; Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wang J., 2006, COMPUTER VISION PATT, V2, P1399, DOI [10.1109/CVPR.2006.14, DOI 10.1109/CVPR.2006.14]; Xiao J, 2004, PROC CVPR IEEE, P535; Xiao J, 2003, INT J IMAG SYST TECH, V13, P85, DOI 10.1002/ima.10048; YANG P, 2008, P IEEE COMP SOC C CO; ZHANG W, 2006, P INT C COMP INT SEC, V1, P725; Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110; ZHU Z, 2006, P IEEE INT C COMP VI, P681	50	51	53	0	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2009	83	2					178	194		10.1007/s11263-008-0185-x	http://dx.doi.org/10.1007/s11263-008-0185-x			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	423UE					2022-12-18	WOS:000264520400005
J	Mojsilovic, A; Gomes, J; Rogowitz, B				Mojsilovic, A; Gomes, J; Rogowitz, B			Semantic-friendly indexing and quering of images based on the extraction of the objective semantic cues	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						image semantic categorization; image browsing and retrieval; color naming; perceptual features	RETRIEVAL; VOCABULARY; GRAMMAR; SYSTEM	bstract image semantics resists all forms of modeling, very much like any kind of intelligence does. However, in order to develop more satisfying image navigation systems, we need tools to construct a semantic bridge between the user and the database. In this paper we present an image indexing scheme and a query language, which allow the user to introduce cognitive dimension to the search. At an abstract level, this approach consists of: (1) learning the "natural language" that humans speak to communicate their semantic experience of images, (2) understanding the relationships between this language and objective measurable image attributes, and then (3) developing corresponding feature extraction schemes. More precisely, we have conducted a number of subjective experiments in which we asked human subjects to group images, and then explain verbally why they did so. The results of this study indicated that a part of the abstraction involved in image interpretation is often driven by semantic categories, which can be broken into more tangible semantic entities, i.e. objective semantic indicators. By analyzing our experimental data, we have identified some candidate semantic categories (i.e. portraits, people, crowds, cityscapes, landscapes, etc.) and their underlying semantic indicators (i.e. skin, sky, water, object, etc.). These experiments also helped us derive important low-level image descriptors, accounting for our perception of these indicators. We have then used these findings to develop an image feature extraction and indexing scheme. In particular, our feature set has been carefully designed to match the way humans communicate image meaning. This led us to the development of a "semantic-friendly" query language for browsing and searching diverse collections of images. We have implemented our approach into an Internet search engine, and tested it on a large number of images. The results we obtained are very promising.	IBM Corp, TJ Watson Res Ctr, Hawthorne, NY 10532 USA	International Business Machines (IBM)	Mojsilovic, A (corresponding author), IBM Corp, TJ Watson Res Ctr, 19 Skyline Dr, Hawthorne, NY 10532 USA.	aleksand@us.ibm.com; josegome@us.ibm.com; rogowitz@us.ibm.com						Ambrosio L, 1996, J DIFFER GEOM, V43, P693; BACH JR, 1993, IEEE T KNOWL DATA EN, V5, P619, DOI 10.1109/69.234774; BELPAEME T, 2002, THESIS VRIJE U BRUSS; Berlin B, 1969, BASIC COLOR TERMS TH; Bishop, 1995, NEURAL NETWORKS PATT; Colombo C, 1999, IEEE MULTIMEDIA, V6, P38, DOI 10.1109/93.790610; Comaniciu D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1197, DOI 10.1109/ICCV.1999.790416; CORRIDONI JM, 1999, ACM MULTIMEDIA SYSTE, V7; Forsyth DA, 1997, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.1997.609399; Forsyth David A, 1996, P EUR C COMP VIS, V1065, P593, DOI DOI 10.1007/3-540-61123-1_173; Garcia C, 1999, IEEE T MULTIMEDIA, V1, P264, DOI 10.1109/6046.784465; GOMES J, 2002, IN PRESS P 7 EUR C C; GRAYSON MA, 1987, J DIFFER GEOM, V26, P285; Hahn GJ, 1967, STAT MODELS ENG; HAYS S, 1981, STATISTICS; Jain AK, 1998, PATTERN RECOGN, V31, P1369, DOI 10.1016/S0031-3203(97)00131-3; Kachigan S.K., 1986, STAT ANAL; Kandel E.R., 1991, PRINC NEUROSCI; Kelly K., 1955, 553 NBS; LAMBERSON LR, 1967, NONNORMAL DATA ANAL; Lammens J.M., 1994, THESIS U BUFFALO; Li YB, 1997, P SOC PHOTO-OPT INS, V3022, P340, DOI 10.1117/12.263422; Lorigo LM, 1999, LECT NOTES COMPUT SC, V1613, P126; Ma WY, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P568, DOI 10.1109/ICIP.1997.647976; Maerz A, 1930, DICT COLOR; Marr D., 1982, VISION; Mojsilovic A, 2000, IEEE T IMAGE PROCESS, V9, P38, DOI 10.1109/83.817597; Mojsilovic A, 2000, IEEE T IMAGE PROCESS, V9, P417, DOI 10.1109/83.826779; MOJSILOVIC A, 2001, P IEEE INT C IM PROC; Mojsilovic A., 2002, P IEEE INT C IM PROC; MUNSELL H, 1946, COLOR NOTATION; Niblack W., 1994, P SPIE STOR RETR IM, P172; Palmer S.E., 1999, VISION SCI PHOTONS P; Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; RABENHORST D, OPAL USERS MANUAL; ROGOWITZ B, 1997, P SPIE; Rui Y, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P815, DOI 10.1109/ICIP.1997.638621; SANTINI S, 2001, ICME 2001 IEEE INT C; SANTINI S, 2001, P SPIE, V4315; Schroeder W., 1996, VISUALIZATION TOOLKI; Sethian J., 1996, LEVEL SET METHODS; Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972; Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151; SOBOTTKA K, 1996, INT C PATT REC ICPR, V3, pC421; STATSOFT INC, 2001, EL STAT TXB; Szummer M, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P42, DOI 10.1109/CAIVD.1998.646032; Tenenbaum Jay M, 1983, HUMAN MACHINE VISION, P481; TOMINAGA S, 1985, P IEEE INT C CYB SOC, P573; Turk L, 1999, AEROSP SCI TECHNOL, V3, P71, DOI 10.1016/S1270-9638(99)80031-5; VAILAYA A, 1988, P IEEE WORKSH CONT B, P3; Wang JZ, 1998, COMPUT COMMUN, V21, P1355, DOI 10.1016/S0140-3664(98)00203-5; WANG JZ, 2001, IEEE T PATT AN MACH, V23; WERTHEIMER M, 1958, PSYCHOL FORSCH, V4, P1923; Wyszecki G., 2000, COLOR SCI CONCEPTS M, V2nd; ZHU W, 1998, P INT WORKSH CONT BA, P31; ZUCKER SW, 1983, HUMAN MACHINE VISION, P545	58	51	54	0	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN-FEB	2004	56	1-2			SI		79	107		10.1023/B:VISI.0000004833.39906.33	http://dx.doi.org/10.1023/B:VISI.0000004833.39906.33			29	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	745MJ					2022-12-18	WOS:000186692200007
J	Lillholm, M; Nielsen, M; Griffin, LD				Lillholm, M; Nielsen, M; Griffin, LD			Feature-based image analysis	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	3rd International Conference on Scale-Space and Morphology held in conjunction with the 8th International Conference on Computer Vision	JUL 07-08, 2001	VANCOUVER, CANADA	IEEE Tech Comm Pattern Anal & Machine Intelligence		features; stochastic complexity; statistics of natural images; least commitment; scale-space; image reconstruction; variational methods	NATURAL IMAGES; RECEPTIVE-FIELDS; SCALE-SPACE	According to Marr's paradigm of computational vision the first process is an extraction of relevant features. The goal of this paper is to quantify and characterize the information carried by features using image-structure measured at feature-points to reconstruct images. In this way, we indirectly evaluate the concept of feature-based image analysis. The main conclusions are that (i) a reasonably low number of features characterize the image to such a high degree, that visually appealing reconstructions are possible, (ii) different feature-types complement each other and all carry important information. The strategy is to define metamery classes of images and examine the information content of a canonical least informative representative of this class. Algorithms for identifying these are given. Finally, feature detectors localizing the most informative points relative to different complexity measures derived from models of natural image statistics, are given.	IT Univ Copenhagen, Copenhagen NV, Denmark; Kings Coll London, London WC2R 2LS, England	IT University Copenhagen; University of London; King's College London	Lillholm, M (corresponding author), IT Univ Copenhagen, Glentevej 67, Copenhagen NV, Denmark.	grumse@it-c.dk; malte@it-c.dk; lewis.griffin@kcl.ac.uk	Griffin, Lewis/C-2118-2008					ALVAREZ L, 1993, ARCH RATION MECH AN, V123, P199, DOI 10.1007/BF00375127; CHAN T, 1997, ICIP97; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; Florack L. M. J., 1993, Journal of Mathematical Imaging and Vision, V3, P327, DOI 10.1007/BF01664793; FLORACK LMJ, 1992, IMAGE VISION COMPUT, V10, P376, DOI 10.1016/0262-8856(92)90024-W; FLORACK LMJ, 1990, 9020 UTR BIOPH RES I; Fox C., 1987, INTRO CALCULUS VARIA; Golub G. H., 1996, MATRIX COMPUTATIONS; Griffin LD, 2002, PERCEPTION, V31, P377; Griffin LD, 2000, P ROY SOC A-MATH PHY, V456, P2995, DOI 10.1098/rspa.2000.0650; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; HUANG J, 1999, CVPR99; HUANG J, 2000, CVPRO00; HUANG TS, 1994, P IEEE, V82, P252, DOI 10.1109/5.265351; HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215, DOI 10.1113/jphysiol.1968.sp008455; HUMMEL R, 1989, IEEE T ACOUST SPEECH, V37, P2111, DOI 10.1109/29.45555; Johansen P, 2000, J MATH IMAGING VIS, V13, P193, DOI 10.1023/A:1011241531216; Johansen P., 1994, Journal of Mathematical Imaging and Vision, V4, P57, DOI 10.1007/BF01250004; JONES DG, 1992, IMAGE VISION COMPUT, V10, P699, DOI 10.1016/0262-8856(92)90015-U; JONES JP, 1987, J NEUROPHYSIOL, V58, P1233, DOI 10.1152/jn.1987.58.6.1233; KASS M, 1988, IJCV, V1, P357; KINDEBERG T, 1994, SCALE SPACE THEORY C; KOENDERINK JJ, 1990, BIOL CYBERN, V63, P291, DOI 10.1007/BF00203452; KOENDERINK JJ, 1996, ADV IMAGE UNDERSTAND, P113; Lee AB, 2001, INT J COMPUT VISION, V41, P35, DOI 10.1023/A:1011109015675; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; LINDEBERG T, 1993, ISRN KTH; Lindeberg T., 1996, CVPR; MAINTZ JBA, 1995, CVRMED95; MAJER P, 2001, LNCS, V2106; Marr D., 1982, VISION COMPUTATIONAL; Nielsen M, 2001, LECT NOTES COMPUT SC, V2106, P39; NIELSEN M, 1995, THESIS KOPENHAGEN U; Pedersen KS, 2000, J VIS COMMUN IMAGE R, V11, P266, DOI 10.1006/jvci.1999.0443; Press WH., 1993, NUMERICAL RECIPES C; PRICE KE, 1990, ICPR90, V1, P114; RISSANEN J., 1998, STOCHASTIC COMPLEXIT; ROSEN JB, 1960, J SOC IND APPL MATH, V8, P181, DOI 10.1137/0108011; RUDERMAN DL, 1994, PHYS REV LETT, V73, P814, DOI 10.1103/PhysRevLett.73.814; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x; STRONG DM, 1986, EXACT SOLUTIONS TOTA; Tagliati E, 2001, LECT NOTES COMPUT SC, V2106, P51; Tikhonov A.N., 1977, SOLUTION ILL POSED P; van Hateren JH, 1998, P ROY SOC B-BIOL SCI, V265, P359, DOI 10.1098/rspb.1998.0303; Vogel CR, 1996, SIAM J SCI COMPUT, V17, P227, DOI 10.1137/0917016; Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1; Wells WM, 1997, INT J COMPUT VISION, V21, P63, DOI 10.1023/A:1007923522710; YOUNG RA, 1985, GMR4920 GEN MOT RES	52	51	54	0	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY-JUN	2003	52	2-3					73	95		10.1023/A:1022995822531	http://dx.doi.org/10.1023/A:1022995822531			23	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	659EL					2022-12-18	WOS:000181764500002
J	Caspi, Y; Irani, M				Caspi, Y; Irani, M			Aligning non-overlapping sequences	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						spatio-temporal alignment; temporal synchronization; multi-sensor alignment; alignment for wide-screen movies; alignment across different zooms		This paper shows how two image sequences that have no spatial overlap between their fields of view can be aligned both in time and in space. Such alignment is possible when the two cameras are attached closely together and are moved jointly in space. The common motion induces "similar" changes over time within the two sequences. This correlated temporal behavior, is used to recover the spatial and temporal transformations between the two sequences. The requirement of "consistent appearance" in standard image alignment techniques is therefore replaced by "consistent temporal behavior", which is often easier to satisfy. This approach to alignment can be used not only for aligning non-overlapping sequences, but also for handling other cases that are inherently difficult for standard image alignment techniques. We demonstrate applications of this approach to three real-world problems: (i) alignment of non-overlapping sequences for generating wide-screen movies, (ii) alignment of images (sequences) obtained at significantly different zooms, for surveillance applications, and, (iii) multi-sensor image alignment for multi-sensor fusion.	Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel	Weizmann Institute of Science	Caspi, Y (corresponding author), Weizmann Inst Sci, Dept Comp Sci & Appl Math, IL-76100 Rehovot, Israel.	caspi@wisdom.weizmann.ac.il; irani@wisdom.weizmann.ac.il						AVIDAN S, 1998, EUR C COMP VIS; BEARDSLEY PA, 1996, LNCS, V1065, P683; BJORCK A, 1996, NUMERICAL METHODES L; Burt P. J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P173, DOI 10.1109/ICCV.1993.378222; Caspi Y, 2000, PROC CVPR IEEE, P682, DOI 10.1109/CVPR.2000.854940; CASPI Y, 2001, INT C COMP VIS VANC, V2, P76; Demirdjian D., 2000, ECCV, P625; Dufournaud Y, 2000, PROC CVPR IEEE, P612, DOI 10.1109/CVPR.2000.855876; Gantmakher F.R., 2000, THEORY MATRICES, VVolume 2; Golub G. H., 1996, MATRIX COMPUTATIONS; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; HORAUD R, 1995, INT J ROBOT RES, V14, P195, DOI 10.1177/027836499501400301; Horaud R, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P96, DOI 10.1109/ICCV.1998.710706; IRANI M, 1994, INT J COMPUT VISION, V12, P5, DOI 10.1007/BF01420982; IRANI M, 1999, VISION ALGORITHMS TH, P267; IRANI M, 1998, EUR C COMP VIS, P829; KUMAR R, 1994, INT C PATT RECOG, P685, DOI 10.1109/ICPR.1994.576402; Pearson C, 2012, HDB APPL MATH SELECT; SAWHNEY HS, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P929, DOI 10.1109/CVPR.1994.323927; SHASHUA A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P483, DOI 10.1109/CVPR.1994.323870; Slama CC., 1980, MANUAL PHOTOGRAMMETR, V4th edn; STEIN GP, 1998, DARPA IU WORKSH, P1037; TORR PHS, 1999, VIS ALG WORKSH CORF, P279; TSAI RY, 1989, IEEE T ROBOTIC AUTOM, V5, P345, DOI 10.1109/70.34770; VIOLA P, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P16, DOI 10.1109/ICCV.1995.466930; ZISSERMAN A, 1995, WORKSH REPR VIS SCEN, P93	27	51	58	0	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2002	48	1					39	51		10.1023/A:1014803327923	http://dx.doi.org/10.1023/A:1014803327923			13	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	534UM					2022-12-18	WOS:000174606100005
J	Pope, AR; Lowe, DG				Pope, AR; Lowe, DG			Probabilistic models of appearance for 3-D object recognition	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						object recognition; appearance representation; model-based vision; visual learning; clustering; model indexing	INVARIANTS	We describe how to model the appearance of a 3-D object using multiple views, learn such a model from training images, and use the model for object recognition. The model uses probability distributions to describe the range of possible variation in the object's appearance. These distributions are organized on two levels. Large variations are handled by partitioning training images into clusters corresponding to distinctly different views of the object. Within each cluster, smaller variations are represented by distributions characterizing uncertainty in the presence, position, and measurements of various discrete features of appearance. Many types of features are used, ranging in abstraction from edge segments to perceptual groupings and regions. A matching procedure uses the feature uncertainty information to guide the search for a match between model and image. Hypothesized feature pairings are used to estimate a viewpoint transformation taking account of feature uncertainty. These methods have been implemented in an object recognition system, OLIVER. Experiments show that OLIVER is capable of learning to recognize complex objects in cluttered images, while acquiring models that represent those objects using relatively few views.	David Sarnoff Res Ctr, Princeton, NJ 08540 USA; Univ British Columbia, Dept Comp Sci, Vancouver, BC V6T 1Z4, Canada	Sarnoff Corporation; University of British Columbia	Pope, AR (corresponding author), David Sarnoff Res Ctr, CN 5300, Princeton, NJ 08540 USA.	apope@sarnoff.com; lowe@cs.ubc.ca						[Anonymous], 1985, PERCEPTUAL ORG VISUA; AYACHE N, 1986, IEEE T PATTERN ANAL, V8, P44, DOI 10.1109/TPAMI.1986.4767751; Beis JS, 1999, IEEE T PATTERN ANAL, V21, P1000, DOI 10.1109/34.799907; BIEMAN GJ, 1977, FACTORIZATION METHOD; Bolles R. C., 1982, INT J ROBOT RES, V1, P57; BREUEL TM, 1992, THESIS MIT; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; BURL M, 1998, P EUR C COMP VIS, P628; Burns J. B., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P328, DOI 10.1109/CVPR.1992.223255; Fisher D. H., 1987, Machine Learning, V2, P139, DOI 10.1007/BF00114265; GRIMSON WEL, 1987, IEEE T PATTERN ANAL, V9, P469, DOI 10.1109/TPAMI.1987.4767935; HELOR Y, 1995, IEEE T PATTERN ANAL, V17, P195, DOI 10.1109/34.368169; HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Nelson RC, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P614, DOI 10.1109/ICCV.1998.710781; PETITJEAN S, 1992, INT J COMPUT VISION, V9, P231, DOI 10.1007/BF00133703; POPE A, 1995, THESIS U BRIT COLUMB; POPE AR, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P768, DOI 10.1109/CVPR.1994.323895; RISSANEN J, 1983, ANN STAT, V11, P416, DOI 10.1214/aos/1176346150; Roberts L, 1965, MACHINE PERCEPTION 3; SCHIELE B, 1996, 4 EUR C COMP VIS CAM, P610; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; Van Huffel S., 1991, FRONTIERS APPL MATH, V9; Wells WM, 1997, INT J COMPUT VISION, V21, P63, DOI 10.1023/A:1007923522710	27	51	58	0	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	2000	40	2					149	167		10.1023/A:1026502202780	http://dx.doi.org/10.1023/A:1026502202780			19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	388TA					2022-12-18	WOS:000166197700003
J	Niessen, WJ; Vincken, KL; Weickert, J; Romeny, BMT; Viergever, MA				Niessen, WJ; Vincken, KL; Weickert, J; Romeny, BMT; Viergever, MA			Multiscale segmentation of three-dimensional MR brain images	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						segmentation; linear scale space; nonlinear scale space	MEAN-CURVATURE; MULTISPECTRAL ANALYSIS; NONLINEAR DIFFUSION; MEDICAL IMAGES; EDGE-DETECTION; SURFACE; REGION; MODEL; HEAD; CLASSIFICATION	Segmentation of MR brain images using intensity values is severely limited owing to field inhomogeneities, susceptibility artifacts and partial volume effects. Edge based segmentation methods suffer from spurious edges and gaps in boundaries. A multiscale method to MRI brain segmentation is presented which uses both edge and intensity information. First a multiscale representation of an image is created, which can be made edge dependent to favor intra-tissue diffusion over inter-tissue diffusion. Subsequently a multiscale linking model (the hyperstack) is used to group voxels into a number of objects based on intensity. It is shown that both an improvement in accuracy and a reduction in image post-processing can be achieved if edge dependent diffusion is used instead of linear diffusion. The combination of edge dependent diffusion and intensity based linking facilitates segmentation of grey matter, white matter and cerebrospinal fluid with minimal user interaction. To segment the total brain (white matter plus grey matter) morphological operations are applied to remove small bridges between the brain and cranium. If the total brain is segmented, grey matter, white matter and cerebrospinal fluid can be segmented by joining a small number of segments. Using a supervised segmentation technique and MRI simulations of a brain phantom for validation it is shown that the errors are in the order of or smaller than reported in literature.	Univ Utrecht Hosp, Image Sci Inst, NL-3508 CX Utrecht, Netherlands	Utrecht University; Utrecht University Medical Center	Niessen, WJ (corresponding author), Univ Utrecht Hosp, Image Sci Inst, HP E01-334,POB 85500, NL-3508 CX Utrecht, Netherlands.	wiro@isi.uu.nl	Romenij, Bart M. ter Haar/A-5323-2013; Viergever, Max A/J-1215-2014; Vincken, Koen/AAP-3558-2021	Niessen, Wiro/0000-0002-5822-1995				ACTON ST, 1994, IEEE IMAGE PROC, P478, DOI 10.1109/ICIP.1994.413760; ALVAREZ L, 1993, ARCH RATION MECH AN, V123, P199, DOI 10.1007/BF00375127; Atkins MS, 1998, IEEE T MED IMAGING, V17, P98, DOI 10.1109/42.668699; BEZDEK JC, 1993, MED PHYS, V20, P1033, DOI 10.1118/1.597000; BOMANS M, 1990, IEEE T MED IMAGING, V9, P177, DOI 10.1109/42.56342; BRUMMER ME, 1993, IEEE T MED IMAGING, V12, P153, DOI 10.1109/42.232244; CASELLES V, 1997, SIAM J NUMER ANAL, V56, P1199; CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012; CHU CC, 1993, IEEE T PATTERN ANAL, V15, P1241, DOI 10.1109/34.250843; CLARKE LP, 1995, MAGN RESON IMAGING, V13, P343, DOI 10.1016/0730-725X(94)00124-L; CLINE HE, 1990, J COMPUT ASSIST TOMO, V14, P1037, DOI 10.1097/00004728-199011000-00041; COLLINS DL, 1992, P SOC PHOTO-OPT INS, V1808, P10, DOI 10.1117/12.131063; DAI DY, 1993, IEEE T MED IMAGING, V12, P693, DOI 10.1109/42.251120; Davatzikos C, 1996, IEEE T MED IMAGING, V15, P785, DOI 10.1109/42.544496; DAWANT BM, 1993, IEEE T MED IMAGING, V12, P770, DOI 10.1109/42.251128; DZIUK G, 1991, J DIFFER EQUATIONS, V93, P142, DOI 10.1016/0022-0396(91)90024-4; EVANS LC, 1991, J DIFFER GEOM, V33, P635, DOI 10.4310/jdg/1214446559; FIREY WJ, 1974, MATHEMATIKA, V21, P1, DOI 10.1112/S0025579300005714; FLETCHER LM, 1993, MAGNET RESON MED, V29, P623, DOI 10.1002/mrm.1910290507; Florack L. M. J., 1994, Journal of Mathematical Imaging and Vision, V4, P325, DOI 10.1007/BF01262401; GERIG G, 1992, IMAGE VISION COMPUT, V10, P349, DOI 10.1016/0262-8856(92)90021-T; GRAYSON MA, 1989, DUKE MATH J, V58, P555, DOI 10.1215/S0012-7094-89-05825-0; GRIFFIN LD, 1992, SPIE, V1808, P24; GRIFFIN LD, 1993, BRIT MACH VIS C, P135; Grimson WEL, 1996, IEEE T MED IMAGING, V15, P129, DOI 10.1109/42.491415; GRIMSON WEL, 1995, LECT NOTES COMPUTER, V905, P3; HOHNE KH, 1992, J COMPUT ASSIST TOMO, V16, P285, DOI 10.1097/00004728-199203000-00019; HUISKEN G, 1984, J DIFFER GEOM, V20, P237; HUISKEN G, 1990, J DIFFER GEOM, V31, P285; Johnston B, 1996, IEEE T MED IMAGING, V15, P154, DOI 10.1109/42.491417; Kapur T, 1996, Med Image Anal, V1, P109, DOI 10.1016/S1361-8415(96)80008-9; KENNEDY DN, 1989, IEEE T MED IMAGING, V8, P1, DOI 10.1109/42.20356; KIKINIS R, 1992, JMRI-J MAGN RESON IM, V2, P619, DOI 10.1002/jmri.1880020603; KOENDERINK JJ, 1986, BIOL CYBERN, V53, P383, DOI 10.1007/BF00318204; KOHN MI, 1991, RADIOLOGY, V178, P115, DOI 10.1148/radiology.178.1.1984289; Koster ASE, 1997, COMPUT VIS IMAGE UND, V65, P382, DOI 10.1006/cviu.1996.0490; KOSTER ASE, 1995, THESIS UTRECHT U NET; LI CL, 1993, IEEE T MED IMAGING, V12, P740, DOI 10.1109/42.251125; LIM KO, 1990, J COMPUTER ASSISTED, V13, P588; MAES F, 1995, LECT NOTES COMPUTER, V905, P77; McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7; Neskovic P., 1994, Proceedings ICIP-94 (Cat. No.94CH35708), P6, DOI 10.1109/ICIP.1994.413264; Niessen WJ, 1998, IEEE T MED IMAGING, V17, P634, DOI 10.1109/42.730407; Niessen WJ, 1996, PROCEEDINGS OF THE IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, P263, DOI 10.1109/MMBIA.1996.534078; Niessen WJ, 1997, COMPUT VIS IMAGE UND, V66, P233, DOI 10.1006/cviu.1997.0614; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Peters T, 1996, IEEE T MED IMAGING, V15, P121, DOI 10.1109/42.491414; RAYA SP, 1990, IEEE T MED IMAGING, V9, P327, DOI 10.1109/42.57771; RUSINEK H, 1991, RADIOLOGY, V178, P109, DOI 10.1148/radiology.178.1.1984287; Sandor S, 1997, IEEE T MED IMAGING, V16, P41, DOI 10.1109/42.552054; SETHIAN JA, 1990, J DIFFER GEOM, V31, P131; SHENTON ME, 1992, NEW ENGL J MED, V327, P604, DOI 10.1056/NEJM199208273270905; Sled J. G., 1997, P 15 INT C INFORM PR, P459; Sled JG, 1998, IEEE T MED IMAGING, V17, P87, DOI 10.1109/42.668698; Sonka M, 1996, IEEE T MED IMAGING, V15, P443, DOI 10.1109/42.511748; VANNIER MW, 1985, RADIOLOGY, V154, P221, DOI 10.1148/radiology.154.1.3964938; Vincken KL, 1997, IEEE T PATTERN ANAL, V19, P109, DOI 10.1109/34.574787; VINCKEN KL, 1995, THESIS UTRECHT U NET; Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190; Weickert J., 1996, THESIS U KAISERSLAUT; Wells WM, 1996, IEEE T MED IMAGING, V15, P429, DOI 10.1109/42.511747; Yezzi A, 1997, IEEE T MED IMAGING, V16, P199, DOI 10.1109/42.563665; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343; ZIJDENBOS AP, 1994, IEEE T MED IMAGING, V13, P716, DOI 10.1109/42.363096; ZIJDENBOS AP, 1994, COMPUT MED IMAG GRAP, V18, P11, DOI 10.1016/0895-6111(94)90057-4; Zuiderveld KJ, 1996, COMPUT GRAPH-UK, V20, P775, DOI 10.1016/S0097-8493(96)00050-7	70	51	53	0	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	1999	31	2-3					185	202		10.1023/A:1008070000018	http://dx.doi.org/10.1023/A:1008070000018			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	209NA					2022-12-18	WOS:000081053100007
J	DOERMANN, DS; ROSENFELD, A				DOERMANN, DS; ROSENFELD, A			RECOVERY OF TEMPORAL INFORMATION FROM STATIC IMAGES OF HANDWRITING	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article								The problem of off-line handwritten character recognition has eluded a satisfactory solution for several decades. Researchers working in the area of on-line recognition have had greater success, but the possibility of extracting on-line information from static images has not been fully explored. The experience of forensic document examiners assures us that in many cases, such information can be successfully recovered. We outline the design of a system for the recovery of temporal information from static handwritten images. We provide a taxonomy of local, regional and global temporal clues which are often found in hand-written samples, and describe methods for recovering these clues from the image. We show how this system can benefit from obtaining a comprehensive understanding of the handwriting signal and a detailed analysis of stroke and sub-stroke properties. We suggest that the recovery task requires that we break away from traditional thresholding and thinning techniques, and we provide a framework for such analysis. We demonstrate how isolated temporal clues can reliably be extracted from this framework and propose a control structure for integrating the partial information. We show how many seemingly ambiguous situations can be resolved by the derived clues and our knowledge of the writing process, and provide several examples to illustrate our approach.			DOERMANN, DS (corresponding author), UNIV MARYLAND,CTR AUTOMAT RES,DOCUMENT PROC GRP,COLLEGE PK,MD 20742, USA.							DOERMANN D, 1993, THESIS U MARYLAND CO; DOERMANN D, 1993, P INT WORKSH FRONT H, P41; DOERMANN DS, 1994, PATTERN RECOGN, V27, P233, DOI 10.1016/0031-3203(94)90056-6; DOERMANN DS, 1990, P USPS ADV TECHNOLOG, P961; FREYD JJ, 1983, MEM COGNITION, V4, P342; Fujimoto Y., 1976, 3rd International Joint Conference on Pattern Recognition, P113; GOVINDARAJU V, 1992, PIXELS FEATURES, V3, P17; KASTURI R, 1992, MACH VISION APPL, V5, P141; MANDLER E, 1985, IMAGE ANAL, P77; NISHIDA H, 1992, PIXELS FEATURES, V3, P29; OGORMAN L, 1992, IEEE COMPUTER, V25; Pan J. C., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P679, DOI 10.1109/CVPR.1991.139779; PAVLIDIS T, 1992, P IEEE, P80; Simon J. C., 1991, International Journal of Pattern Recognition and Artificial Intelligence, V5, P57, DOI 10.1142/S0218001491000065; SNAPE KW, 1980, J FORENSIC SCI, V25, P386; SUZUKI T, 1990, P INT WORKSHOP FRONT, P39; TAPPERT CC, 1990, T PATTERN ANAL MACHI, V12, P878	17	51	60	0	2	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	1995	15	1-2					143	164		10.1007/BF01450853	http://dx.doi.org/10.1007/BF01450853			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	QY042					2022-12-18	WOS:A1995QY04200007
J	Li, LRH; Pan, JS; Lai, WS; Gao, CX; Sang, N; Yang, MH				Li, Lerenhan; Pan, Jinshan; Lai, Wei-Sheng; Gao, Changxin; Sang, Nong; Yang, Ming-Hsuan			Blind Image Deblurring via Deep Discriminative Priors	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Blind mage deblurring; Deep learning; Discriminative prior		We present an effective blind image deblurring method based on a data-driven discriminative prior. Our work is motivated by the fact that a good image prior should favor sharp images over blurred ones. In this work, we formulate the image prior as a binary classifier using a deep convolutional neural network. The learned prior is able to distinguish whether an input image is sharp or not. Embedded into the maximum a posterior framework, it helps blind deblurring in various scenarios, including natural, face, text, and low-illumination images, as well as non-uniform deblurring. However, it is difficult to optimize the deblurring method with the learned image prior as it involves a non-linear neural network. In this work, we develop an efficient numerical approach based on the half-quadratic splitting method and gradient descent algorithm to optimize the proposed model. Furthermore, we extend the proposed model to handle image dehazing. Both qualitative and quantitative experimental results show that our method performs favorably against the state-of-the-art algorithms as well as domain-specific image deblurring approaches.	[Li, Lerenhan; Gao, Changxin; Sang, Nong] Huazhong Univ Sci & Technol, Sch Automat, Natl Key Lab Sci & Technol Multispectral Informat, Wuhan, Hubei, Peoples R China; [Li, Lerenhan; Lai, Wei-Sheng; Yang, Ming-Hsuan] Univ Calif, Elect Engn & Comp Sci, Merced, CA USA; [Pan, Jinshan] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing, Jiangsu, Peoples R China	Huazhong University of Science & Technology; University of California System; University of California Merced; Nanjing University of Science & Technology	Sang, N (corresponding author), Huazhong Univ Sci & Technol, Sch Automat, Natl Key Lab Sci & Technol Multispectral Informat, Wuhan, Hubei, Peoples R China.	lrhli@hust.edu.cn; sdluran@gmail.com; wlai24@ucmerced.edu; cgao@hust.edu.cn; nsang@hust.edu.cn; mhyang@ucmerced.edu	Pan, Jinshan/AAO-2258-2021; Yang, Ming-Hsuan/T-9533-2019; Gao, Changxin/L-4841-2016; Yang, Ming-Hsuan/AAE-7350-2019	Yang, Ming-Hsuan/0000-0003-4848-2304; Gao, Changxin/0000-0003-2736-3920; 	National Natural Science Foundation of China [61433007, 61872421]; National Science Foundation CAREER [1149783]; Natural Science Foundation of Jiangsu Province [BK20180471]; China Scholarship Council	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Science Foundation CAREER(National Science Foundation (NSF)); Natural Science Foundation of Jiangsu Province(Natural Science Foundation of Jiangsu Province); China Scholarship Council(China Scholarship Council)	This work is partially supported by the National Natural Science Foundation of China (Nos. 61433007 and 61872421), the National Science Foundation CAREER (No. 1149783), the Natural Science Foundation of Jiangsu Province (No. BK20180471), and gifts from Adobe and Nvidia. Lerenhan Li is supported by a scholarship from China Scholarship Council.	Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185; Bigdeli S. A., 2017, PROC INT C NEURAL IN, V30, P763; Boracchi G, 2012, IEEE T IMAGE PROCESS, V21, P3502, DOI 10.1109/TIP.2012.2192126; Chakrabarti A, 2016, LECT NOTES COMPUT SC, V9907, P221, DOI 10.1007/978-3-319-46487-9_14; Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491; Dong C, 2015, IEEE I CONF COMP VIS, P576, DOI 10.1109/ICCV.2015.73; Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13; Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956; Genenko YA, 2012, IEEE INT FERRO; Glorot X., 2010, PROC MACH LEARN RES, P249; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168; Hradi M., 2015, BRIT MACH VIS C; Hu Z, 2014, PROC CVPR IEEE, P3382, DOI 10.1109/CVPR.2014.432; Hu Z, 2012, LECT NOTES COMPUT SC, V7576, P59, DOI 10.1007/978-3-642-33715-4_5; Huiskes Mark J, 2008, P 1 ACM INT C MULTIM, P39, DOI DOI 10.1145/1460096.1460104; Jin MG, 2018, IEEE COMPUT SOC CONF, P858, DOI 10.1109/CVPRW.2018.00118; Kim J, 2016, IEEE CONF COMPUT; Kohler R, 2012, LECT NOTES COMPUT SC, V7578, P27, DOI 10.1007/978-3-642-33786-4_3; Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521; Krishnan D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531402; Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854; Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618; Lai WS, 2016, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2016.188; Lai WS, 2015, PROC CVPR IEEE, P64, DOI 10.1109/CVPR.2015.7298601; Leclaire A., 2013, INT C SCAL SPAC VAR; Levin A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2657, DOI 10.1109/CVPR.2011.5995308; Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815; Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951; Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511; Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1017/S1368980013002176, 10.1109/PLASMA.2013.6634954]; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Mao XJ, 2016, ADV NEUR IN, V29; Michaeli T, 2014, LECT NOTES COMPUT SC, V8691, P783, DOI 10.1007/978-3-319-10578-9_51; Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35; Noroozi M, 2017, LECT NOTES COMPUT SC, V10496, P65, DOI 10.1007/978-3-319-66709-6_6; Pan JS, 2018, IEEE T PATTERN ANAL, V40, P2315, DOI 10.1109/TPAMI.2017.2753804; Pan JS, 2016, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2016.306; Pan JS, 2014, PROC CVPR IEEE, P2901, DOI 10.1109/CVPR.2014.371; Pan JS, 2014, LECT NOTES COMPUT SC, V8695, P47, DOI 10.1007/978-3-319-10584-0_4; Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10; Schuler CJ, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481418; Shen Z, 2018, PROC CVPR IEEE, P5245, DOI 10.1109/CVPR.2018.00550; Sreehari S, 2016, IEEE T COMPUT IMAG, V2, P408, DOI 10.1109/TCI.2016.2599778; Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677; Sun LB, 2013, IEEE INT CONF COMPUT; Tai YW, 2011, IEEE T PATTERN ANAL, V33, P1603, DOI 10.1109/TPAMI.2010.222; Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853; Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412; Whyte O, 2012, INT J COMPUT VISION, V98, P168, DOI 10.1007/s11263-011-0502-7; Xu L., 2010, ECCV, P157, DOI DOI 10.1007/978-3-642-15549-9_12; Xu L., 2013, IEEE C COMP VIS PATT; Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208; Yan RM, 2016, IEEE T IMAGE PROCESS, V25, P1910, DOI 10.1109/TIP.2016.2535273; YAN Y, 2017, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2017.738; Zhang J., 2017, IEEE C COMP VIS PATT, P3817, DOI DOI 10.1109/CVPR.2017.742; ZHANG K, 2017, PROC CVPR IEEE, P2808, DOI DOI 10.1109/CVPR.2017.300; Zhao P, 2015, 2015 COLOUR AND VISUAL COMPUTING SYMPOSIUM (CVCS); Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278	59	50	56	2	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2019	127	8					1025	1043		10.1007/s11263-018-01146-0	http://dx.doi.org/10.1007/s11263-018-01146-0			19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	IH5UM					2022-12-18	WOS:000474559000004
J	Hofmann, M; Gavrila, DM				Hofmann, M.; Gavrila, D. M.			Multi-view 3D Human Pose Estimation in Complex Environment	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Human motion capture; Articulated pose recovery; Human computer interaction; Surveillance	SHAPE-FROM-SILHOUETTE; TIME PART; TRACKING; PEOPLE	We introduce a framework for unconstrained 3D human upper body pose estimation from multiple camera views in complex environment. Its main novelty lies in the integration of three components: single-frame pose recovery, temporal integration and model texture adaptation. Single-frame pose recovery consists of a hypothesis generation stage, in which candidate 3D poses are generated, based on probabilistic hierarchical shape matching in each camera view. In the subsequent hypothesis verification stage, the candidate 3D poses are re-projected into the other camera views and ranked according to a multi-view likelihood measure. Temporal integration consists of computing K-best trajectories combining a motion model and observations in a Viterbi-style maximum-likelihood approach. Poses that lie on the best trajectories are used to generate and adapt a texture model, which in turn enriches the shape likelihood measure used for pose recovery. The multiple trajectory hypotheses are used to generate pose predictions, augmenting the 3D pose candidates generated at the next time step. We demonstrate that our approach outperforms the state-of-the-art in experiments with large and challenging real-world data from an outdoor setting.	[Hofmann, M.; Gavrila, D. M.] Univ Amsterdam, Intelligent Autonomous Syst Grp, Inst Informat, NL-1098 XG Amsterdam, Netherlands	University of Amsterdam	Gavrila, DM (corresponding author), Univ Amsterdam, Intelligent Autonomous Syst Grp, Inst Informat, Sci Pk 107, NL-1098 XG Amsterdam, Netherlands.	mhofmann.uva@gmail.com; d.m.gavrila@uva.nl			MultimediaN project	MultimediaN project	The authors would like to thank John Schave-maker (TNO) for stimulating discussions throughout this research. This research was in part funded by the MultimediaN project.	Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21; Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754; Balan A., 2006, P IEEE C COMP VIS PA; Balan Alexandru O., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383340; Bergtholdt Martin, 2010, International Journal of Computer Vision, V87, P93, DOI 10.1007/s11263-009-0209-1; Bissacco A., 2007, 2007 IEEE C COMP VIS, P1, DOI [10.1109/CVPR.2007.383129, DOI 10.1109/CVPR.2007.383129]; Bo LF, 2010, INT J COMPUT VISION, V87, P28, DOI 10.1007/s11263-008-0204-y; Bouguet J.-Y., 2003, CAMERA CALIBRATION T; Bray M, 2007, IMAGE VISION COMPUT, V25, P352, DOI 10.1016/j.imavis.2005.10.009; Brubaker MA, 2010, INT J COMPUT VISION, V87, P140, DOI 10.1007/s11263-009-0274-5; Cheung KM, 2005, INT J COMPUT VISION, V63, P225, DOI 10.1007/s11263-005-6879-4; Cheung KM, 2005, INT J COMPUT VISION, V62, P221, DOI 10.1007/s11263-005-4881-5; Corazza S, 2010, INT J COMPUT VISION, V87, P156, DOI 10.1007/s11263-009-0284-3; Deutscher J, 2005, INT J COMPUT VISION, V61, P185, DOI 10.1023/B:VISI.0000043757.18370.9c; Drummond T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P315, DOI 10.1109/ICCV.2001.937642; Ferrari V, 2009, PROC CVPR IEEE, P1, DOI 10.1109/CVPRW.2009.5206495; Fleuret F, 2008, IEEE T PATTERN ANAL, V30, P267, DOI 10.1109/TPAMI.2007.1174; Forsyth DA, 2005, FOUND TRENDS COMPUT, V1, P77, DOI 10.1561/0600000005; Fossati A, 2009, PROC CVPR IEEE, P1137, DOI 10.1109/CVPRW.2009.5206489; Fossati A, 2007, PROC CVPR IEEE, P2510; Gall J, 2009, PROC CVPR IEEE, P1746, DOI 10.1109/CVPRW.2009.5206755; Gall J, 2010, INT J COMPUT VISION, V87, P75, DOI 10.1007/s11263-008-0173-1; Gavrila DM, 2007, INT J COMPUT VISION, V73, P41, DOI 10.1007/s11263-006-9038-7; Gavrila DM, 2007, IEEE T PATTERN ANAL, V29, P1408, DOI 10.1109/TPAMI.2007.1062; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; Gavrila DM, 1996, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.1996.517056; Hasler N, 2009, PROC CVPR IEEE, P224, DOI 10.1109/CVPRW.2009.5206859; Hofmann M, 2009, LECT NOTES COMPUT SC, V5748, P71, DOI 10.1007/978-3-642-03798-6_8; Hofmann M, 2009, PROC CVPR IEEE, P2214, DOI 10.1109/CVPRW.2009.5206508; Kakadiaris I, 2000, IEEE T PATTERN ANAL, V22, P1453, DOI 10.1109/34.895978; Kanaujia A., 2007, P IEEE C COMP VIS PA, P1; Kehl R, 2006, COMPUT VIS IMAGE UND, V104, P190, DOI 10.1016/j.cviu.2006.07.010; Knossow D, 2008, INT J COMPUT VISION, V79, P247, DOI 10.1007/s11263-007-0116-2; Kohli P, 2008, INT J COMPUT VISION, V79, P285, DOI 10.1007/s11263-007-0120-6; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; Lee CS, 2010, INT J COMPUT VISION, V87, P118, DOI 10.1007/s11263-009-0266-5; Lee MW, 2009, IEEE T PATTERN ANAL, V31, P27, DOI 10.1109/TPAMI.2008.35; Lee MW, 2006, IEEE T PATTERN ANAL, V28, P905, DOI 10.1109/TPAMI.2006.110; Li R, 2010, INT J COMPUT VISION, V87, P170, DOI 10.1007/s11263-009-0283-4; Liem M., 2009, P BRIT MACH VIS C BM; Lv F., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383131; MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030; Mikic I, 2003, INT J COMPUT VISION, V53, P199, DOI 10.1023/A:1023012723347; Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002; Mori G, 2006, IEEE T PATTERN ANAL, V28, P1052, DOI 10.1109/TPAMI.2006.149; NAVARATNAM R, 2005, P BRIT MACH VIS C BM; Peursum P, 2010, INT J COMPUT VISION, V87, P53, DOI 10.1007/s11263-009-0205-5; Pilu M, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P257; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Ramanan D, 2007, IEEE T PATTERN ANAL, V29, P65, DOI 10.1109/TPAMI.2007.250600; Roberts TJ, 2006, IMAGE VISION COMPUT, V24, P1332, DOI 10.1016/j.imavis.2006.04.011; Rogez G, 2008, PROC CVPR IEEE, P2142; Rosenhahn B, 2007, PROC CVPR IEEE, P1203; SESHADRI N, 1994, IEEE T COMMUN, V42, P313, DOI 10.1109/TCOMM.1994.577040; Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750; Sigal L, 2004, PROC CVPR IEEE, P421; Starck J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P915; Stenger B, 2006, IEEE T PATTERN ANAL, V28, P1372, DOI 10.1109/TPAMI.2006.189; Sundaresan A, 2009, IEEE T IMAGE PROCESS, V18, P2114, DOI 10.1109/TIP.2009.2022290; Vondrak M, 2008, PROC CVPR IEEE, P1849; Xu XY, 2007, IEEE I CONF COMP VIS, P968; Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992; [No title captured]	65	50	52	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2012	96	1					103	124		10.1007/s11263-011-0451-1	http://dx.doi.org/10.1007/s11263-011-0451-1			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	872LF		Bronze, Green Published			2022-12-18	WOS:000298810300006
J	Aylward, SR; Jomier, J; Weeks, S; Bullitt, E				Aylward, SR; Jomier, J; Weeks, S; Bullitt, E			Registration and analysis of vascular images	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						tubes; registration; vessels; multi-scale; Hessian	MR-IMAGES; SEGMENTATION; VESSELS; ANGIOGRAMS; SCALE; SHAPE	We have developed a method for rigidly aligning images of tubes. This paper presents an evaluation of the consistency of that method for three-dimensional images of human vasculature. Vascular images may contain alignment ambiguities, poorly corresponding vascular networks, and non-rigid deformations, yet the Monte Carlo experiments presented in this paper show that our method registers vascular images with sub-voxel consistency in a matter of seconds. Furthermore, we show that the method's insensitivity to non-rigid deformations enables the localization, quantification, and visualization of those deformations. Our method aligns a source image with a target image by registering a model of the tubes in the source image directly with the target image. Time can be spent to extract an accurate model of the tubes in the source image. Multiple target images can then be registered with that model without additional extractions. Our registration method builds upon the principles of our tubular object segmentation work that combines dynamic-scale central ridge traversal with radius estimation. In particular, our registration method's consistency stems from incorporating multi-scale ridge and radius measures into the model-image match metric. Additionally, the method's speed is due in part to the use of coarse-to-fine optimization strategies that are enabled by measures made during model extraction and by the parameters inherent to the model-image match metric.	Univ N Carolina, Comp Aided Diag & Display Lab, Chapel Hill, NC 27515 USA	University of North Carolina; University of North Carolina Chapel Hill	Aylward, SR (corresponding author), Univ N Carolina, Comp Aided Diag & Display Lab, Chapel Hill, NC 27515 USA.							ALPERIN N, 1994, JMRI-J MAGN RESON IM, V4, P139, DOI 10.1002/jmri.1880040207; [Anonymous], 1978, STAT EXPT INTRO DESI; Aylward S, 1996, PROCEEDINGS OF THE IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, P131, DOI 10.1109/MMBIA.1996.534065; Aylward SR, 2002, IEEE T MED IMAGING, V21, P61, DOI 10.1109/42.993126; Aylward SR, 2002, IEEE INT S BIOM IM W, P4; AYLWARD SR, 2001, MICCAI, P932; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bullitt E, 1999, ACAD RADIOL, V6, P539, DOI 10.1016/S1076-6332(99)80432-2; Bullitt E, 2001, NEUROSURGERY, V48, P576, DOI 10.1097/00006123-200103000-00024; Bullitt E, 2001, MED IMAGE ANAL, V5, P157, DOI 10.1016/S1361-8415(01)00037-8; Bullitt E, 1997, LECT NOTES COMPUT SC, V1230, P537; COLLIGNON A, 1995, COMP IMAG VIS, V3, P263; Dryden I.L., 1998, STAT SHAPE ANAL, DOI [DOI 10.5555/1046920.1088707, 10.1002/9781119072492]; DU YPP, 1995, JMRI-J MAGN RESON IM, V5, P353, DOI 10.1002/jmri.1880050321; EBERLY D, 1996, COMPUTATIONAL IMAGIN, V7; Frangi AF, 1999, IEEE T MED IMAGING, V18, P946, DOI 10.1109/42.811279; FRITSCH DS, 1995, KLUWER SERIES COMPUT, P385; Gao LM, 1996, RADIOLOGY, V201, P359, DOI 10.1148/radiology.201.2.8888223; GE Y, 1996, P SPIE; Gerig G., 1993, Information Processing in Medical Imaging. 13th International Conference, IPMI '93 Proceedings, P94, DOI 10.1007/BFb0013783; Haris K, 1999, IEEE T MED IMAGING, V18, P1003, DOI 10.1109/42.811312; Herline A J, 2000, Comput Aided Surg, V5, P11, DOI 10.1002/(SICI)1097-0150(2000)5:1<11::AID-IGS2>3.0.CO;2-G; Hill DLG, 2001, PHYS MED BIOL, V46, pR1, DOI 10.1088/0031-9155/46/3/201; HOOGEVEEN RM, 1998, J MAGNETIC RESONANCE, V8; IBANEZ L, 2002, IEEE INT S BIOM IM, P4; KOLLER TM, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P864, DOI 10.1109/ICCV.1995.466846; Lindeberg T., 1994, SCALE SPACE THEORY C; Lorenz C., 1997, MULTISCALE LINE SEGM, P233; Lorigo LM, 1999, LECT NOTES COMPUT SC, V1613, P126; Masutani Y, 1998, LECT NOTES COMPUT SC, V1496, P1242, DOI 10.1007/BFb0056314; McInerney T, 1999, IEEE T MED IMAGING, V18, P840, DOI 10.1109/42.811261; MORSE B, 1994, P SOC PHOTO-OPT INS, V2167, P104, DOI 10.1117/12.175046; ORKISZ MM, 1997, MAGNETIC RESONANCE I, P37; Park W, 1998, IEEE T MED IMAGING, V17, P489, DOI 10.1109/42.730394; Pizer SM, 1998, COMPUT VIS IMAGE UND, V69, P55, DOI 10.1006/cviu.1997.0563; Porter BC, 2001, IEEE T MED IMAGING, V20, P354, DOI 10.1109/42.921484; REUZE P, 1993, TECHNOL HEALTH CARE, V1, P181, DOI 10.3233/THC-1993-1209; Roche A, 2001, IEEE T MED IMAGING, V20, P1038, DOI 10.1109/42.959301; ROHLFING T, 2001, P SPIE MED IMAGING 2, P337; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284; Sato Y, 1997, LECT NOTES COMPUT SC, V1205, P213, DOI 10.1007/BFb0029240; Schnabel J.A., 2001, LNCS, V2208, P573, DOI [DOI 10.1007/3-540-45468-3_69, DOI 10.1007/3-540-45468-3_]; SOBOL LM, 1994, PRIMER MONTE CARLO M; Soler L, 2000, Stud Health Technol Inform, V70, P316; VANDENELSEN PA, 1995, IEEE T MED IMAGING, V14, P384, DOI 10.1109/42.387719; Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918; West J, 1999, IEEE T MED IMAGING, V18, P144, DOI 10.1109/42.759119; Wilson DL, 1999, IEEE T MED IMAGING, V18, P938, DOI 10.1109/42.811277; Yim PJ, 2000, IEEE T MED IMAGING, V19, P568, DOI 10.1109/42.870662	49	50	76	0	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV-DEC	2003	55	2-3					123	138		10.1023/A:1026126900358	http://dx.doi.org/10.1023/A:1026126900358			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	732YN					2022-12-18	WOS:000185973300004
J	Reid, ID; Murray, DW				Reid, ID; Murray, DW			Active tracking of foveated feature clusters using affine structure	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							MOTION; VISION; ROBOTS	We describe a novel method of obtaining a fixation point on a moving object for a real-time gaze control system. The method makes use of a real-time implementation of a corner detector and tracker and reconstructs the image position of the desired fixation point from a cluster of corners detected on the object using the affine structure available from two or three views. The method is fast, reliable, viewpoint invariant, and insensitive to occlusion and/or individual corner dropout or reappearance. We compare two- and three-dimensional forms of the algorithm, present results for the method in use with a high performance head/eye platform, and compare the results with two naive fixation methods.			Reid, ID (corresponding author), UNIV OXFORD, DEPT ENGN SCI, PARKS RD, OXFORD OX1 3PJ, ENGLAND.			Reid, Ian/0000-0001-7790-6423				ALOIMONOS J, 1987, 1ST P INT C COMP VIS, P35; [Anonymous], 1988, EYE BRAIN VISION; [Anonymous], 1988, ALVEY VISION C; Bar-Shalom Y., 1988, TRACKING DATA ASS; BLAKE A, 1993, INT J COMPUT VISION, V11, P127, DOI 10.1007/BF01469225; BRADSHAW KJ, 1993, J IMAGE VISION COMPU, V12, P155; BRADY JM, 1992, P 2 INT C AUT ROB CO; BRADY M, 1992, PHILOS T ROY SOC B, V337, P341, DOI 10.1098/rstb.1992.0112; Clark J. J., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P514, DOI 10.1109/CCV.1988.590032; COOMBS D, 1993, INT J COMPUT VISION, V11, P147, DOI 10.1007/BF01469226; DEMEY S, 1992, P BRIT MACH VIS C LE, P49; DERICHE R, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P66; ESPIAU B, 1992, IEEE T ROBOTIC AUTOM, V8, P313, DOI 10.1109/70.143350; FAUGERAS OD, 1992, P 2 EUR C COMP VIS S, P563; FERMULLER C, 1993, INT J COMPUT VISION, V11, P165, DOI 10.1007/BF01469227; Golub G. H., 1996, MATRIX COMPUTATIONS; Householder A. S., 1938, AM MATH MONTHLY, V45, P165; INOUE H, 1992, 1992 IEEE INTERNATIONAL CONF ON ROBOTICS AND AUTOMATION : PROCEEDINGS, VOLS 1-3, P1621, DOI 10.1109/ROBOT.1992.220020; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; MARU N, 1993, P IEEE RSJ INT C INT, P1865; MCLAUCHLAN PF, 1992, P BIRT MACHINE VISIO, P357; MCLAUCHLAN PF, 1994, P 3 EUR C COMP VIS, V1, P217; Mundy J., 1992, GEOMETRIC INVARIANCE; MURRAY D, 1993, P IEEE INT C COMP VI, P403; MURRAY DW, 1995, INT J COMPUT VISION, V16, P205, DOI 10.1007/BF01539627; MURRAY DW, 1991, EXPT MACHINE INTERPR; NAGEL HH, 1983, COMPUT VISION GRAPH, V21, P85, DOI 10.1016/S0734-189X(83)80030-9; OLSON TJ, 1991, INT J COMPUT VISION, V7, P67, DOI 10.1007/BF00130490; PAHLAVAN K, 1993, P 4 INT C COMP VIS B, P412; PAHLAVAN K, 1992, P 2 EUR C COMP VIS S, P526; POELMAN C, 1994, P 3 EUR C COMP VIS S, V2, P97; QUAN L, 1991, P IEEE WORKSH VIS MO; REID ID, 1994, IEEE INT CONF ROBOT, P718, DOI 10.1109/ROBOT.1994.351402; ROBINSON DA, 1988, VISION BRAIN COOPERA; Samson C., 1991, ROBOT CONTROL TASK F; SHAPIRO LS, 1994, P EUROPEAN C COMPUTE, V2, P73; SHAPIRO LS, 1992, P BRIT MACH VIS C, P306; SHARKEY PM, 1993, MECHATRONICS, V3, P517, DOI 10.1016/0957-4158(93)90021-S; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; WANG H, 1991, P BAERNAIMAGE 9U BAR; Wavering A. J., 1993, Proceedings IEEE International Conference on Robotics and Automation (Cat. No.93CH3247-4), P410, DOI 10.1109/ROBOT.1993.292207; WEINSHALL D, 1993, P 4 INT C COMP VIS B, P675	43	50	53	0	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	1996	18	1					41	60		10.1007/BF00126139	http://dx.doi.org/10.1007/BF00126139			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	UJ409					2022-12-18	WOS:A1996UJ40900003
J	PETITJEAN, S; PONCE, J; KRIEGMAN, DJ				PETITJEAN, S; PONCE, J; KRIEGMAN, DJ			COMPUTING EXACT ASPECT GRAPHS OF CURVED OBJECTS - ALGEBRAIC-SURFACES	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							SMOOTH SURFACES; 3-D OBJECTS; REPRESENTATION; SINGULARITIES; RECOGNITION; LINE	This article presents an algorithm for computing the exact aspect graph of an opaque solid bounded by a smooth algebraic surface. Orthographic projection is assumed. The algorithm is based on a catalog of visual events available from singularity theory. It uses curve tracing, cell decomposition, homotopy continuation, and rav tracing to construct the regions of the view sphere delineated by visual-event curves. The algorithm has been fully implemented, and examples are presented.	UNIV ILLINOIS,BECKMAN INST,URBANA,IL 61801; UNIV ILLINOIS,DEPT COMP SCI,URBANA,IL 61801; YALE UNIV,DEPT ELECT ENGN,CTR SYST SCI,NEW HAVEN,CT 06520	University of Illinois System; University of Illinois Urbana-Champaign; University of Illinois System; University of Illinois Urbana-Champaign; Yale University								ARNOLD VI, 1983, RUSS MATH SURV+, V38, P87, DOI 10.1070/RM1983v038n02ABEH003471; ARNOLD VI, 1984, CATASTOPHE THEORY; ARNOLD VI, 1969, RUSS MATH SURV, P3; Arnon D. S., 1983, Computer Graphics, V17, P219, DOI 10.1145/964967.801152; ARNON DS, 1984, SIAM J COMPUT, V13, P865, DOI 10.1137/0213054; Bajaj C. L., 1988, Computer-Aided Geometric Design, V5, P285, DOI 10.1016/0167-8396(88)90010-6; BINFORD TO, 1971, P C SYST C MIAMI; Callahan J., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P240; CASTORE G, 1984, SOLID MODELING COMPU, P277; CHAKRAVARTY I, 1982, IPLTR034 RENSS POL I; CHEN S, 1991, JUN IEEE WORKSH DIR, P34; COLLINS GE, 1975, LECTURE NOTES COMPUT, V33; Do Carmo M.P., 2016, DIFFERENTIAL GEOMETR, Vsecond; EGGERT D, 1991, JUN IEEE WORKSH DIR, P44; EGGERT D, 1989, NOV P IEEE WORKSH IN, P102; EGGERT D, 1992, IN PRESS P IEEE C CO; EGGERT DW, 1991, ASPECT GRAPHS SOLIDS; FAROUKI RT, 1986, COMPUT VISION GRAPH, V33, P209, DOI 10.1016/0734-189X(86)90115-5; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; GIGUS Z, 1990, IEEE T PATTERN ANAL, V12, P113, DOI 10.1109/34.44399; GIGUS Z, 1991, IEEE T PAT ANAL MACH, V13; GRIMSON WEL, 1987, IEEE T PATTERN ANAL, V9, P469, DOI 10.1109/TPAMI.1987.4767935; HEBERT M, 1985, JUN P IIEEE C COMP V; IKEUCHI K, 1988, P IEEE, V76, P1016, DOI 10.1109/5.5972; KAJIYA JT, 1982, P SIGGRAPH, P245; KERGOSIEN YL, 1981, CR ACAD SCI I-MATH, V292, P929; Koenderink J., 1990, SOLID SHAPE; Koenderink J.J., 1987, IMAGE UNDERSTANDING, P257; Koenderink J. J., 1984, PERCEPTION, V13; KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644; KRIEGMAN D, 1992, P EUROP C COMPUT VIS; KRIEGMAN DJ, 1990, INT J COMPUT VISION, V5, P119, DOI 10.1007/BF00054918; KRIEGMAN DJ, 1990, IEEE T PATTERN ANAL, V12, P1127, DOI 10.1109/34.62602; KRIEGMAN DJ, 1991, SPIE C CURVES SURFAC, V2; KRIEGMAN DJ, 1991, CURVES SURFACES, P267; MALIK J, 1987, INT J COMPUT VISION, V1, P73, DOI 10.1007/BF00128527; MANOCHA D, 1990, IN PRESS COMPUTER AI; MARGAN A, 1987, SOLVING POLYNOMIAL S; MATHER JN, 1968, ANN MATH, V87, P89, DOI 10.2307/1970595; PETITJEAN S, 1992, THESIS U ILLINOIS UR; PLANTINGA H, 1990, INT J COMPUT VISION, V5, P137, DOI 10.1007/BF00054919; PLATONOVA OA, 1981, RUSS MATH SURV+, V36, P248, DOI 10.1070/RM1981v036n01ABEH002556; PLATONOVA OA, 1984, RUSS MATH SURV+, V39, P177, DOI 10.1070/RM1984v039n01ABEH003080; PONCE J, 1991, P EUROP C COMPUT VIS; PONCE J, 1990, UIUCDCSR901579 U ILL; RIEGER JH, 1992, INT J COMPUT VISION, V7, P171, DOI 10.1007/BF00126392; RIEGER JH, 1990, ARTIF INTELL, V44, P1, DOI 10.1016/0004-3702(90)90097-J; RIIEGER J, 1987, IMAGE VIS COMPUT, V5, P91; SEALES WB, 1991, JUN IEEE WORKSH DIR, P54; SEDERBERG TW, 1984, COMPUT VISION GRAPH, V28, P72, DOI 10.1016/0734-189X(84)90140-3; Shafer S. A., 1985, SHADOWS SILHOUETTES; SRIPRADISVARAKU.T, 1989, NOV P IEEE WORKSH IN, P109; STEWMAN J, 1988, 2ND P INT C COMP VIS; Stewman J. H., 1987, Proceedings of the IEEE Computer Society Workshop on Computer Vision (Cat. No.87TH0210-5), P123; THOM R, 1956, ANN I FOURIER, V6, P43; WALL CTC, 1976, GEOM TOPOL, P707; WANG R, 1990, 10TH P INT C PATT RE; WATTS N, 1987, CS234 ROCH U TECH RE; Weatherburn C.E, 2016, DIFFERENTIAL GEOMETR; WHITNEY H, 1955, ANN MATH, V62, P374, DOI 10.2307/1970070; WHITTED T, 1980, COMMUN ACM, V23, P343, DOI 10.1145/358876.358882; [No title captured]; [No title captured]	63	50	51	0	0	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	1992	9	3					231	255		10.1007/BF00133703	http://dx.doi.org/10.1007/BF00133703			25	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	KC414					2022-12-18	WOS:A1992KC41400004
J	Sun, J; Ling, HB				Sun, Jin; Ling, Haibin			Scale and Object Aware Image Thumbnailing	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Image thumbnailing; Image retargeting; Thumbnail cropping; Contrast sensitivity function; Seam carving; Thin plate spline	VISUAL-ATTENTION; MODEL	In this paper we study effective approaches to create thumbnails from input images. Since a thumbnail will eventually be presented to and perceived by a human visual system, a thumbnailing algorithm should consider several important issues in the process including thumbnail scale, object completeness and local structure smoothness. To address these issues, we propose a new thumbnailing framework named scale and object aware thumbnailing (SOAT), which contains two components focusing respectively on saliency measure and thumbnail warping/cropping. The first component, named scale and object aware saliency (SOAS), models the human perception of thumbnails using visual acuity theory, which takes thumbnail scale into consideration. In addition, the "objectness" measurement (Alexe et al. 2012) is integrated in SOAS, as to preserve object completeness. The second component uses SOAS to guide the thumbnailing based on either retargeting or cropping. The retargeting version uses the thin-plate-spline (TPS) warping for preserving structure smoothness. An extended seam carving algorithm is developed to sample control points used for TPS model estimation. The cropping version searches a cropping window that balances the spatial efficiency and SOAS-based content preservation. The proposed algorithms were evaluated in three experiments: a quantitative user study to evaluate thumbnail browsing efficiency, a quantitative user study for subject preference, and a qualitative study on the RetargetMe dataset. In all studies, SOAT demonstrated promising performances in comparison with state-of-the-art algorithms.	[Sun, Jin; Ling, Haibin] Temple Univ, Dept Comp & Informat Sci, Philadelphia, PA 19122 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University	Ling, HB (corresponding author), Temple Univ, Dept Comp & Informat Sci, 1805 N Broad St, Philadelphia, PA 19122 USA.	jinsun@cs.umd.edu; hbling@temple.edu			NSF [IIS-1218156]	NSF(National Science Foundation (NSF))	We thank B. Alexe for making the objectness code available, M. Rubinstein for seam carving code, G. Teodoro for proofreading the manuscript, and all anonymous reviewers for valuable suggestions which help significantly improve the manuscript. This work was supported in part by NSF Grant IIS-1218156.	Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28; Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; Chen LQ, 2003, MULTIMEDIA SYST, V9, P353, DOI 10.1007/s00530-003-0105-4; Ding YY, 2011, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2011.5995445; El-Alfy H., 2007, P 15 ACM INT C MULT, P97; Everingham M., 2008, PASCAL VISUAL OBJECT; Gotsman C., 2010, CONTENT AWARE IMAGE, P1; Grundmann M, 2010, PROC CVPR IEEE, P569, DOI 10.1109/CVPR.2010.5540165; Guo YW, 2009, IEEE T MULTIMEDIA, V11, P856, DOI 10.1109/TMM.2009.2021781; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Judd T, 2011, J VISION, V11, DOI 10.1167/11.4.14; Karni Z, 2009, COMPUT GRAPH FORUM, V28, P1257, DOI 10.1111/j.1467-8659.2009.01503.x; Kennedy L., 2011, P 1 ACM INT C MULT R, P30; Kim JS, 2009, PROC CVPR IEEE, P1730, DOI 10.1109/CVPRW.2009.5206666; Krahenbuhl P, 2009, ACM T GRAPHIC, V28, DOI [10.1145/1616452.1618472, 10.1145/1618452.1618472]; Lam H., 2005, P SIGCHI C HUM FACT, P681; Li X, 2009, IEEE INT CON MULTI, P558, DOI 10.1109/ICME.2009.5202557; Liu F, 2005, P 18 ANN ACM S USER, P153; Liu F, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1477, DOI 10.1109/ICME.2006.262821; Luo Y, 2011, LECT NOTES COMPUT SC, V6494, P396, DOI 10.1007/978-3-642-19318-7_31; MANNOS JL, 1974, IEEE T INFORM THEORY, V20, P525, DOI 10.1109/TIT.1974.1055250; Mansfield A, 2010, LECT NOTES COMPUT SC, V6311, P143, DOI 10.1007/978-3-642-15549-9_11; Marchesotti L, 2009, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2009.5459467; Niu YZ, 2012, MULTIMED TOOLS APPL, V56, P485, DOI 10.1007/s11042-010-0613-0; Peli E, 2001, J OPT SOC AM A, V18, P283, DOI 10.1364/JOSAA.18.000283; Pritch Y, 2009, IEEE I CONF COMP VIS, P151, DOI 10.1109/ICCV.2009.5459159; Rubinstein M., 2010, BENCHMARK IMAGE RETA; Rubinstein M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866186; Rubinstein M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531329; Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615; Simakov D., 2008, 2008 IEEE CVPR, P1; Suh B, 2003, P 16 ANN ACM S USER, P95, DOI [10.1145/964696.964707, DOI 10.1145/964696.964707]; Sun J, 2011, IEEE I CONF COMP VIS, P1511, DOI 10.1109/ICCV.2011.6126409; VANNES FL, 1967, J OPT SOC AM, V57, P401, DOI 10.1364/JOSA.57.000401; Wang Y.-S., 2010, ACM T GRAPHIC, P1; Wang Y, 2008, INT J COMPUT VISION, V80, P143, DOI 10.1007/s11263-008-0138-4; Wang Y, 2008, CELL POLYM, V27, P1; Wolf L., 2007, P IEEE 11 INT C COMP, P1, DOI DOI 10.1109/ICCV.2007.4409010; Wu HS, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866185	40	49	52	0	23	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2013	104	2					135	153		10.1007/s11263-013-0618-z	http://dx.doi.org/10.1007/s11263-013-0618-z			19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	189FD					2022-12-18	WOS:000322251800002
J	Kim, TK; Stenger, B; Kittler, J; Cipolla, R				Kim, Tae-Kyun; Stenger, Bjoern; Kittler, Josef; Cipolla, Roberto			Incremental Linear Discriminant Analysis Using Sufficient Spanning Sets and Its Applications	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Linear discriminant analysis; LDA; Incremental learning; Online learning; Label propagation; Semi-supervised learning; Face image retrieval; Object recognition; Object categorisation; Face authentication	ALGORITHM	This paper presents an incremental learning solution for Linear Discriminant Analysis (LDA) and its applications to object recognition problems. We apply the safficient spanning set approximation in three steps i.e. update for the total scatter matrix, between-class scatter matrix and the projected data matrix, which leads an online solution which closely agrees with the batch solution in accuracy while significantly reducing the computational complexity. The algorithm yields an efficient solution to incremental LDA even when the number of classes as well as the set size is large. The incremental LDA method has been also shown useful for semi-supervised online learning. Label propagation is done by integrating the incremental LDA into an EM framework. The method has been demonstrated in the task of merging large datasets which were collected during MPEG standardization for face image retrieval, face authentication using the BANCA dataset, and object categorisation using the Caltech 101 dataset.	[Kim, Tae-Kyun] Univ Cambridge, Sidney Sussex Coll, Cambridge CB2 3HU, England; [Stenger, Bjoern] Toshiba Res Europe Ltd, Cambridge CB4 0GZ, England; [Kittler, Josef] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England; [Cipolla, Roberto] Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England	University of Cambridge; Toshiba Corporation; University of Surrey; University of Cambridge	Kim, TK (corresponding author), Univ Cambridge, Sidney Sussex Coll, Cambridge CB2 3HU, England.	tkk22@cam.ac.uk; bjorn.stenger@crl.toshiba.co.uk; J.Kittler@surrey.ac.uk; cipolla@eng.cam.ac.uk	Arandjelović, Ognjen/V-5255-2019	Arandjelović, Ognjen/0000-0002-9314-194X; Cipolla, Roberto/0000-0002-8999-2151	Toshiba-Cambridge Scholarship; Sidney Sussex College of the University of Cambridge; EU	Toshiba-Cambridge Scholarship; Sidney Sussex College of the University of Cambridge; EU(European Commission)	This study has been funded in part by the Toshiba-Cambridge Scholarship. T.-K. Kim is presently supported by the research fellowship of the Sidney Sussex College of the University of Cambridge. J. Kittler was partially supported by EU Projects VidiVideo and Mobio.	Bar-Hillel AB, 2005, J MACH LEARN RES, V6, P937; BELKIN M, 2004, P NIPS; BERG A, 2005, P CVPR; BOUVEYRON C, 2004, P 5 FRENCH DAN WORKS; Chan CH, 2007, LECT NOTES COMPUT SC, V4642, P809; CHENG H, 2009, P ICCV; CHIN TJ, 2006, P BMVC; FEIFEI L, 2004, P CVPR WORKSH GMBV; FRADE FD, 2005, P CVPR; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Grauman K., 2005, IEEE INT C COMP VIS; Hall P, 2000, IEEE T PATTERN ANAL, V22, P1042, DOI 10.1109/34.877525; HIRAOKA K, 2000, P ICPR; HOLUB AD, 2005, P NIPS WORKSH INT TR; KAMEI T, 2002, JTC1SC29WG11M8998 IS; Kim HC, 2003, PATTERN RECOGN LETT, V24, P2815, DOI 10.1016/S0167-8655(03)00126-0; Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037; Kim TK, 2005, IMAGE VISION COMPUT, V23, P631, DOI 10.1016/j.imavis.2005.02.005; KIM TK, 2007, P CVPR MINN MN; Leibe B., 2003, P CVPR; LIN RS, 2005, P NIPS; Manjunath B. S., 2002, INTRO MPEG 7 MULTIME; MESSER K, 2004, P ICPR; MOOSMANN F, 2007, P NIPS; MUTCH J, 2006, P CVPR; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; OJA E, 1983, SUBSPACE METHODS PAT; Pang S, 2005, IEEE T SYST MAN CY B, V35, P905, DOI 10.1109/TSMCB.2005.847744; POH N, 2009, P ICPR; SKOCAJ D, 2003, P ICCV; STENGER B, 2008, P BMVC LEEDS UK; TAO X, 2004, P NIPS; URAY M, 2007, P BMVC; WANG F, 2007, P ICML; WANG X, 2009, P ICCV KYOT; WINN J, 2005, P ICCV; WU Y, 2000, P INT C COMP VIS PAT, P2088; YAN J, 2004, P INT C KNOWL DISC D; Ye JP, 2005, IEEE T KNOWL DATA EN, V17, P1208, DOI 10.1109/TKDE.2005.148; Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X; Zhu X., 2006, COMPUT SCI, V2, P4	41	49	52	0	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2011	91	2					216	232		10.1007/s11263-010-0381-3	http://dx.doi.org/10.1007/s11263-010-0381-3			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	708KJ		Green Submitted			2022-12-18	WOS:000286360400006
J	Levin, A; Weiss, Y				Levin, Anat; Weiss, Yair			Learning to Combine Bottom-Up and Top-Down Segmentation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	9th European Conference on Computer Vision (ECCV 2006)	MAY 07-13, 2006	Graz, AUSTRIA	Adv Comp Vis, Graz Univ Technol, Univ Ljubljana		Image segmentation; Object detection		Bottom-up segmentation based only on low-level cues is a notoriously difficult problem. This difficulty has lead to recent top-down segmentation algorithms that are based on class-specific image information. Despite the success of top-down algorithms, they often give coarse segmentations that can be significantly refined using low-level cues. This raises the question of how to combine both top-down and bottom-up cues in a principled manner. In this paper we approach this problem using supervised learning. Given a training set of ground truth segmentations we train a fragment-based segmentation algorithm which takes into account both bottom-up and top-down cues simultaneously, in contrast to most existing algorithms which train top-down and bottom-up modules separately. We formulate the problem in the framework of Conditional Random Fields (CRF) and derive a feature induction algorithm for CRF, which allows us to efficiently search over thousands of candidate fragments. Whereas pure top-down algorithms often require hundreds of fragments, our simultaneous learning procedure yields algorithms with a handful of fragments that are combined with low-level cues to efficiently compute high quality segmentations.	[Levin, Anat; Weiss, Yair] Hebrew Univ Jerusalem, Sch Engn & Comp Sci, IL-91904 Jerusalem, Israel	Hebrew University of Jerusalem	Levin, A (corresponding author), Hebrew Univ Jerusalem, Sch Engn & Comp Sci, IL-91904 Jerusalem, Israel.			Levin, Anat/0000-0002-9849-9043				BARBU A, 2003, P IEEE INT C COMP VI; BORENSTEIN E., 2004, P IEEE C COMP VIS PA; BORENSTEIN E, 2002, P EUR C COMP VIS MAY; Fei-Fei L., 2006, IEEE T PATTERN ANAL; He X., 2004, P IEEE C COMP VIS PA; HE X, 2006, ECCV; KUMAR MP, 2004, P IEEE C COMP VIS PA; Kumar S., 2003, P IEEE INT C COMP VI; Lafferty J., 2001, P 18 INT C MACHINE L, P282, DOI DOI 10.5555/645530.655813; Lafferty J., 2004, ICML; LeCun Y., 2005, INT WORKSH ART INT S; Leibe B., 2004, P WORKSH STAT LEARN; MALIK J, 2000, PERCEPTUAL ORG ARTIF; MCCALLUM A, 2004, UAI; Quattoni A, 2004, NIPS; Ren X., 2005, ADV NEURAL INFORM PR; Sharon E., 2001, P IEEE C COMP VIS PA; Shotton J., 2006, ECCV; TU ZW, 2003, P IEEE INT C COMP VI; Wainwright M., 2003, 9 WORKSH ART INT STA; Winn J. M., 2005, P INT C COMP VIS; Yedidia JS, 2005, IEEE T INFORM THEORY, V51, P2282, DOI 10.1109/TIT.2005.850085; Yu S.X., 2003, P IEEE C COMP VIS PA; YUILLE A, 2002, ACTIVE VISION; Zhu SC, 1997, NEURAL COMPUT, V9, P1627, DOI 10.1162/neco.1997.9.8.1627	25	49	52	0	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2009	81	1					105	118		10.1007/s11263-008-0166-0	http://dx.doi.org/10.1007/s11263-008-0166-0			14	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	387RI		Green Submitted			2022-12-18	WOS:000261968900007
J	Lazebnik, S; Furukawa, Y; Ponce, J				Lazebnik, Svetlana; Furukawa, Yasutaka; Ponce, Jean			Projective visual hulls	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						silhouette; visual hull; frontier point; projective differential geometry; oriented projective geometry; projective reconstruction; 3D photography	OBJECT SILHOUETTES; SHAPE; RECONSTRUCTION; CONSTRUCTION; DEFORMATION; MODELS	This article presents a novel method for computing the visual hull of a solid bounded by a smooth surface and observed by a finite set of cameras. The visual hull is the intersection of the visual cones formed by back-projecting the silhouettes found in the corresponding images. We characterize its surface as a generalized polyhedron whose faces are visual cone patches; edges are intersection curves between two viewing cones; and vertices are frontier points where the intersection of two cones is singular, oar intersection points where triples of cones meet. We use the mathematical framework of oriented projective differential geometry to develop an image-based algorithm for computing the visual hull. This algorithm works in a weakly calibrated setting-that is, it only requires projective camera matrices or, equivalently, fundamental matrices for each pair of cameras. The promise of the proposed algorithm is demonstrated with experiments on several challenging data sets and a comparison to another state-of-the-art method.	Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; Univ Illinois, Beckman Inst, Urbana, IL 61801 USA; Ecole Normale Super, Dept Informat, F-75231 Paris, France	University of Illinois System; University of Illinois Urbana-Champaign; University of Illinois System; University of Illinois Urbana-Champaign; UDICE-French Research Universities; PSL Research University Paris; Ecole Normale Superieure (ENS)	Lazebnik, S (corresponding author), Univ Illinois, Dept Comp Sci, 1304 W Springfield Ave, Urbana, IL 61801 USA.	slazebni@uiuc.edu; yfurukaw@uiuc.edu; jponce@uiuc.edu						AHUJA N, 1989, IEEE T PATTERN ANAL, V11, P137, DOI 10.1109/34.16710; Arbogast E., 1991, J PATTERN RECOGNITIO, V5; BAUMGART B, 1974, AIM249 STANF U DEP C; Bottino A, 2004, IEEE T PATTERN ANAL, V26, P1622, DOI 10.1109/TPAMI.2004.130; Boyer E, 1997, INT J COMPUT VISION, V22, P219, DOI 10.1023/A:1007978616082; Boyer E, 2003, PROC CVPR IEEE, P695; Brand M, 2004, PROC CVPR IEEE, P30; CHUM P, 2003, P BRIT MACH VIS C, P73; CIPOLLA R, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P269, DOI 10.1109/ICCV.1995.466775; CIPOLLA R, 1992, INT J COMPUT VISION, V9, P83, DOI 10.1007/BF00129682; Cipolla R., 2000, VISUAL MOTION CURVES; Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016; Forsyth DA, 2002, PRENT HALL PROF TECH; Franco J.-S., 2003, BRIT MACH VIS C BMVC, V1, P329, DOI [DOI 10.5244/C.17.32, 10.5244/C.17.32]; FRANCO JS, 2005, THESIS I NATL POLYTE; FURUKAWA Y, 2006, P EUR C COMP VIS; Giblin P., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P136; Grauman K, 2003, PROC CVPR IEEE, P187; GRAUMAN K, 2004, P 2 WORKSH STAT METH; HARTLEY R, 1998, P 5 EUR C COMP VIS, P20; Heo HS, 1999, COMPUT AIDED DESIGN, V31, P33, DOI 10.1016/S0010-4485(98)00078-5; HOFFMAN CM, 1989, GEOMETRIC SOLID MODE; Hoppe H., 1993, Computer Graphics Proceedings, P19, DOI 10.1145/166117.166119; KOENDERINK JJ, 1984, PERCEPTION, V13, P321, DOI 10.1068/p130321; Kutulakos K. N., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P307, DOI 10.1109/ICCV.1999.791235; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; LAVEST JM, 1998, P EUR C COMP VIS, V1, P158; Lazebnik S, 2005, INT J COMPUT VISION, V63, P65, DOI 10.1007/s11263-005-4947-4; Lazebnik S, 2001, PROC CVPR IEEE, P156; LAZEBNIK S, 2002, THESIS U ILLINOIS UR; LAZEBNIK S, CVRTR200201; Lorensen W. E., 1987, COMPUT GRAPH, V21, P163, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422]; MARTIN WN, 1983, IEEE T PATTERN ANAL, V5, P150, DOI 10.1109/TPAMI.1983.4767367; Matsuyama T, 2004, COMPUT VIS IMAGE UND, V96, P393, DOI 10.1016/j.cviu.2004.03.012; Matusik W, 2001, SPRING EUROGRAP, P115; MATUSIK W, 2000, ACM SIGGRAPH, P36; MATUSIK W, 2002, ACM SIGGRAPH, P427; Nister D, 2004, INT J COMPUT VISION, V60, P165, DOI 10.1023/B:VISI.0000029667.76852.a1; O'Rourke J, 1998, COMPUTATIONAL GEOMET; OWEN J, 1987, GEOMETRIC MODELING A; Petitjean S, 1998, INT J COMPUT GEOM AP, V8, P407, DOI 10.1142/S0218195998000229; PORRILL J, 1991, IMAGE VISION COMPUT, V9, P45, DOI 10.1016/0262-8856(91)90048-T; POTMESIL M, 1987, COMPUT VISION GRAPH, V40, P1, DOI 10.1016/0734-189X(87)90053-3; RIEGER JH, 1986, OPT LETT, V11, P123, DOI 10.1364/OL.11.000123; Shlyakhter I, 2001, IEEE COMPUT GRAPH, V21, P53, DOI 10.1109/38.920627; Sinha S. N., 2005, ICCV; Sinha SN, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P349; SRIVASTAVA SK, 1990, COMPUT VISION GRAPH, V49, P68, DOI 10.1016/0734-189X(90)90163-P; Stolfi J., 1991, ORIENTED PROJECTIVE; Sullivan S, 1998, IEEE T PATTERN ANAL, V20, P1091, DOI 10.1109/34.722621; SZELISKI R, 1993, CVGIP-IMAG UNDERSTAN, V58, P23, DOI 10.1006/ciun.1993.1029; VAILLANT R, 1992, IEEE T PATTERN ANAL, V14, P157, DOI 10.1109/34.121787; VOGIATZIS G, 2005, CVPR, P391; WERNER T, 2001, ICCV, P548; WERNER T, 2001, P BRIT MACH VIS C, P441	55	49	56	0	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2007	74	2					137	165		10.1007/s11263-006-0008-x	http://dx.doi.org/10.1007/s11263-006-0008-x			29	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	167ZH					2022-12-18	WOS:000246490900003
J	Kang, SB; Szeliski, R				Kang, SB; Szeliski, R			Extracting view-dependent depth maps from a collection of images	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						stereo correspondence; multi-view stereo; occlusions; view-dependent texture maps; view-dependent depth maps; image-based rendering	BAYESIAN-APPROACH; ADAPTIVE WINDOW; STEREO; ALGORITHM; REGULARIZATION	Stereo correspondence algorithms typically produce a single depth map. In addition to the usual problems of occlusions and textureless regions, such algorithms cannot model the variation in scene or object appearance with respect to the viewing position. In this paper, we propose a new representation that overcomes the appearance variation problem associated with an image sequence. Rather than estimating a single depth map, we associate a depth map with each input image (or a subset of them). Our representation is motivated by applications such as view interpolation and depth-based segmentation for model-building or layer extraction. We describe two approaches to extract such a representation from a sequence of images. The first approach, which is more classical, computes the local depth map associated with each chosen reference frame independently. The novelty of this approach lies in its combination of shiftable windows, temporal selection, and graph cut optimization. The second approach simultaneously optimizes a set of self-consistent depth maps at multiple key-frames. Since multiple depth maps are estimated simultaneously, visibility can be modeled explicitly and disparity consistency imposed across the different depth maps. Results, which include a difficult specular scene example. show the effectiveness of our approach.	Microsoft Res, Redmond, WA 98052 USA	Microsoft	Kang, SB (corresponding author), Microsoft Res, 1 Microsoft Way, Redmond, WA 98052 USA.	sbkang@microsoft.com; szeliski@microsoft.com						ARNOLD RD, 1983, AIM351 STANF U; Baker S, 1998, PROC CVPR IEEE, P434, DOI 10.1109/CVPR.1998.698642; BARNARD ST, 1989, INT J COMPUT VISION, V3, P17, DOI 10.1007/BF00054836; Belhumeur PN, 1996, INT J COMPUT VISION, V19, P237, DOI 10.1007/BF00055146; BERGEN JR, 1992, 2ND P EUR C COMP VIS, P237; Birchfield S, 1998, IEEE T PATTERN ANAL, V20, P401, DOI 10.1109/34.677269; BIRCHFIELD S, 1999, 7 INT C COMP VIS ICC, P489; Black MJ, 1996, IEEE T PATTERN ANAL, V18, P972, DOI 10.1109/34.541407; Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148; Blonde L, 1996, IEEE MULTIMEDIA, V3, P18, DOI 10.1109/93.502291; Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Buehler C, 2001, COMP GRAPH, P425, DOI 10.1145/383259.383309; CHOU PB, 1990, INT J COMPUT VISION, V4, P185, DOI 10.1007/BF00054995; Collins RT, 1996, PROC CVPR IEEE, P358, DOI 10.1109/CVPR.1996.517097; De Haan G, 1998, P IEEE, V86, P1839, DOI 10.1109/5.705528; Debevec P. E., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P11, DOI 10.1145/237170.237191; DEBEVEC PE, 1998, EUR REND WORKSH 1998, P105, DOI DOI 10.1007/978-3-7091-6453-210; DHOND UR, 1989, IEEE T SYST MAN CYB, V19, P1489, DOI 10.1109/21.44067; GEIGER D, 1992, 2 EUR C COMP VIS ECC, P425; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200; Hanna K. J., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P156, DOI 10.1109/WVM.1991.212812; Hoff W., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P516; IRANI M, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P605, DOI 10.1109/ICCV.1995.466883; ISHIKAWA H, 1998, 5 EUR C COMP VIS, P232; Ju SX, 1996, PROC CVPR IEEE, P307, DOI 10.1109/CVPR.1996.517090; Kanade T, 1996, PROC CVPR IEEE, P196, DOI 10.1109/CVPR.1996.517074; KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690; KANG SB, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P88, DOI 10.1109/ICCV.1995.466802; Kang SB, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P13, DOI 10.1109/ICIP.2000.899212; KANG SB, 2001, MSRTR200180 MICR RES; KANG SB, 2001, IEEE COMP SOC C COMP; KOLMOGOROV V, 2001, 8 INT C COMP VIS, V2, P508; KOLMOGOROV V, 2002, 7 EUR C COMP VIS ECC, V3, P82; Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954; Lee MC, 1997, IEEE T CIRC SYST VID, V7, P130, DOI 10.1109/76.554424; LEGALL D, 1991, COMMUN ACM, V34, P46, DOI 10.1145/103085.103090; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127; MATTHIES L, 1989, INT J COMPUT VISION, V3, P209, DOI 10.1007/BF00133032; McMillan L., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P39, DOI 10.1145/218380.218398; Nakamura Y, 1996, PROC CVPR IEEE, P371, DOI 10.1109/CVPR.1996.517099; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955; Okutomi M, 2002, INT J COMPUT VISION, V47, P261, DOI 10.1023/A:1014510328154; OKUTOMI M, 1992, INT J COMPUT VISION, V7, P143, DOI 10.1007/BF00128133; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; PULLI K, 1997, P 8 EUR WORKSH REND; Quam L. H., 1984, IM UND WORKSH NEW OR, P149; Roy S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P492, DOI 10.1109/ICCV.1998.710763; SAITO H, 1999, IEEE COMP SOC C COMP, V2, P49; SATOH K, 1996, 13 INT C PATT REC IC, P280; Sawhney HS, 1996, IEEE T PATTERN ANAL, V18, P814, DOI 10.1109/34.531801; SAWHNEY HS, 1991, IEEE COMP SOC C COMP, P179; Scharstein D, 1998, INT J COMPUT VISION, V28, P155, DOI 10.1023/A:1008015117424; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Seitz SM, 1999, INT J COMPUT VISION, V35, P151, DOI 10.1023/A:1008176507526; Shade J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P231, DOI 10.1145/280814.280882; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; SHUM H, 1999, 7 INT C COMP VIS ICC, P14; Shum HY, 1999, COMP GRAPH, P299, DOI 10.1145/311535.311573; SUN S, 2000, ICIP 2000 VANC SEPT, V1, P852; SWAMINATHAN R, 2002, 7 EUR C COMP VIS ECC, P508; Szeliski R, 1997, INT J COMPUT VISION, V22, P199, DOI 10.1023/A:1007996332012; Szeliski R, 2000, PROC CVPR IEEE, P246, DOI 10.1109/CVPR.2000.855826; SZELISKI R, 1999, INT WORKSH VIS ALG K, P1; SZELISKI R, 1995, IEEE WORKSH REPR VIS, P26; SZELISKI R, 1999, IEEE COMPUTER VISION, V1, P157; TAO H, 2001, 8 INT C COMP VIS ICC, V1, P532; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; TIAN Q, 1986, COMPUT VISION GRAPH, V35, P220, DOI 10.1016/0734-189X(86)90028-9; Torr PHS, 2001, IEEE T PATTERN ANAL, V23, P297, DOI 10.1109/34.910882; Tsin Y, 2003, PROC CVPR IEEE, P702; VEKSLER O, 1999, THESIS CORNELL U; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; Weiss Y, 1997, PROC CVPR IEEE, P520, DOI 10.1109/CVPR.1997.609375; Weiss Y, 1996, PROC CVPR IEEE, P321, DOI 10.1109/CVPR.1996.517092; Yagi, 1973, COMPUT VISION GRAPH, V2, P131; YANG Y, 1993, IEEE COMP SOC C COMP, P274, DOI DOI 10.1109/CVPR.1993.340969; Zitnick CL, 2000, IEEE T PATTERN ANAL, V22, P675, DOI 10.1109/34.865184	84	49	71	0	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2004	58	2					139	163		10.1023/B:VISI.0000015917.35451.df	http://dx.doi.org/10.1023/B:VISI.0000015917.35451.df			25	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	829FY					2022-12-18	WOS:000222034000004
J	Rother, C; Carlsson, S				Rother, C; Carlsson, S			Linear multi view reconstruction and camera recovery using a reference plane	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						structure from motion; projective reconstruction; multiple views; missing data; duality; critical configurations; reference plane; planar parallax	MOTION; SHAPE	This paper presents a linear algorithm for simultaneous computation of 3D points and camera positions from multiple perspective views based on having a reference plane visible in all views. The reconstruction and camera recovery is achieved in a single step by finding the null-space of a matrix built from image data using Singular Value Decomposition. Contrary to factorization algorithms this approach does not need to have all points visible in all views. This paper investigates two reference plane configurations: Finite reference planes defined by four coplanar points and infinite reference planes defined by vanishing points. A further contribution of this paper is the study of critical configurations for configurations with four coplanar points. By simultaneously reconstructing points and views we can exploit the numerical stabilizing effect of having wide spread cameras with large mutual baselines. This is demonstrated by reconstructing the outside and inside (courtyard) of a building on the basis of 35 views in one single Singular Value Decomposition.	KTH, Dept Numer Anal & Comp Sci, Computat Vis & Act Percept Lab, SE-10044 Stockholm, Sweden	Royal Institute of Technology	Rother, C (corresponding author), KTH, Dept Numer Anal & Comp Sci, Computat Vis & Act Percept Lab, SE-10044 Stockholm, Sweden.	carstenr@nada.kth.se; stefanc@nada.kth.se						CAPRILE B, 1990, INT J COMPUT VISION, V4, P127, DOI 10.1007/BF00127813; Carlsson S, 1998, INT J COMPUT VISION, V27, P227, DOI 10.1023/A:1007961913417; CARLSSON S, 1995, IEEE WORKSH REPR VIS; CRIMINISI A, 1998, EUR C COMP VIS, P846; CROSS G, 1999, INT C COMP VIS KERK, P323; FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P564; FITZGIBBON AW, 1998, ECCV, P311; Frahm J.-M., 1996, EUR C COMP VIS CAMBR, P2; HARTLEY R, 2000, EUR C COMP VIS DUBL, P922; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; HARTLEY RI, 1998, LNCS, V1506, P14; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Heyden A, 1997, IMAGE VISION COMPUT, V15, P749, DOI 10.1016/S0262-8856(97)00005-X; Heyden A, 1999, IMAGE VISION COMPUT, V17, P981, DOI 10.1016/S0262-8856(99)00002-5; Heyden A, 1998, INT J COMPUT VISION, V30, P5, DOI 10.1023/A:1008020228557; HEYDEN A, 1995, IEEE WORKSH REPR VIS; IRANI M, 1998, EUR C COMP VIS, P829; Jacobs D, 1997, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.1997.609321; Kaucic R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P420, DOI 10.1109/ICCV.2001.937548; KOCH R, 1998, EUR C COMP VIS, P55; KRAMES J, 1942, BILDMESSUNG LUFTBILD, V17, P1; KUMAR R, 1994, INT C PATT RECOG, P685, DOI 10.1109/ICPR.1994.576402; Liebowitz D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P293, DOI 10.1109/ICCV.1999.791233; Maybank S., 1992, THEORY RECONSTRUCTIO; Oliensis J, 1999, INT J COMPUT VISION, V34, P163, DOI 10.1023/A:1008139920864; OLIENSIS J, 1999, ICCV, P536; OLIENSIS J, 1995, WORKSH REPR VIS SCEN, P77; QIAN C, 1999, IEEE C COMP VIS PATT, P55; QUAN L, 1994, ECCV, P459; QUAN L, 1999, IEEE C COMP VIS PATT, P210; Rother C, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P42, DOI 10.1109/ICCV.2001.937497; ROTHER C, 2000, 11 BRIT MACH VIS C B, P382; Schaffalitzky F, 2000, LECT NOTES COMPUT SC, V1842, P632; SPARR G, 1996, IEEE C COMP VIS PATT, P328; SVEDBERG D, 1999, SCAND C IM AN KANG G, P111; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298; TRIGGS B, 2000, EUR C COMP VIS, P522; WEINSHALL D, 1998, LNCS, V1506, P208; WEINSHALL D, 1995, IEEE WORKSH REPR VIS, P58	41	49	52	0	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP-OCT	2002	49	2-3					117	141		10.1023/A:1020189404787	http://dx.doi.org/10.1023/A:1020189404787			25	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	590TA					2022-12-18	WOS:000177837100003
J	Coorg, S; Teller, S				Coorg, S; Teller, S			Spherical mosaics with quaternions and dense correlation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						panoramas; texture; automated; self-calibration		We describe an algorithm for generating spherical mosaics from a collection of images acquired from a common optical center. The algorithm takes as input an arbitrary number of partially overlapping images, an adjacency map relating the images, initial estimates of the rotations relating each image to a specified base image, and approximate internal calibration information for the camera. The algorithm's output is a rotation relating each image to the base image, and revised estimates of the camera's internal parameters. Our algorithm is novel in the following respects. First, it requires no user input. (Our image capture instrumentation provides both an adjacency map for the mosaic, and an initial rotation estimate for each image.) Second, it optimizes an objective function based on a global correlation of overlapping image regions. Third, our representation of rotations significantly increases the accuracy of the optimization. Finally, our representation and use of adjacency information guarantees globally consistent rotation estimates. The algorithm has proved effective on a collection of nearly four thousand images acquired from more than eighty distinct optical centers. The experimental results demonstrate that the described global optimization strategy is superior to non-global aggregation of pair-wise correlation terms, and that it successfully generates high-quality mosaics despite significant error in initial rotation estimates.	MIT, Comp Sci Lab, Comp Graph Grp, Cambridge, MA 02139 USA	Massachusetts Institute of Technology (MIT)	Coorg, S (corresponding author), MIT, Comp Sci Lab, Comp Graph Grp, 545 Technol Sq, Cambridge, MA 02139 USA.	satyan@ics.mit.edu; seth@ics.mit.edu						Antone ME, 2000, PROC CVPR IEEE, P282, DOI 10.1109/CVPR.2000.854809; Coorg S., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P625, DOI 10.1109/CVPR.1999.787004; Coorg S, 1998, PROC CVPR IEEE, P872, DOI 10.1109/CVPR.1998.698707; COORG S, 1998, THESIS MIT; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Hartley RI, 1997, INT J COMPUT VISION, V22, P5, DOI 10.1023/A:1007957826135; HECKBERT P, 1989, UCBCSD89516; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1991, J OPT SOC AM A, V8, P1630, DOI 10.1364/JOSAA.8.001630; HORN BKP, 1987, J OPTICAL SOC AM A, V4; HSU S, 1998, WACV 98 PRINC NJ OCT, P154; Kropp A, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P47, DOI 10.1109/OMNVIS.2000.853803; LENZ RK, 1987, P IEEE INT C ROB AUT; McMillan L., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P39, DOI 10.1145/218380.218398; McMillan L., 1997, THESIS U N CAROLINA; PAETH AW, 1990, GRAPHICS GEMS, P307; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; Sawhney HS, 1999, IEEE T PATTERN ANAL, V21, P235, DOI 10.1109/34.754589; SAWHNEY HS, 1998, ECCV, P103; Scales L. E., 1985, INTRO NONLINEAR OPTI; Shum HY, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P953, DOI 10.1109/ICCV.1998.710831; STEIN GP, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P230, DOI 10.1109/ICCV.1995.466781; STRANG G, 1998, LINEAR ALGEBRA ITS A; Szeliski R, 1996, IEEE COMPUT GRAPH, V16, P22, DOI 10.1109/38.486677; Szeliski R., 1997, SIGGRAPH 97, P251; TELLER S, 1997, P IM UND WORKSH; TSAI R, 1987, IEEE J ROBOTICS AUTO, V3; WHEELER MD, 1995, CMUCS95215; ZOGHIAMI I, 1997, CVPR97, P420	29	49	51	0	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2000	37	3					259	273		10.1023/A:1008184124789	http://dx.doi.org/10.1023/A:1008184124789			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	342GF					2022-12-18	WOS:000088636300003
J	Shelton, CR				Shelton, CR			Morphable Surface Models	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						computer vision; learning; correspondence; morphable models; surface matching		We describe a novel automatic technique for finding a dense correspondence between a pair of n-dimensional surfaces with arbitrary topologies. This method employs a different formulation than previous correspondence algorithms (such as optical flow) and includes images as a special case. We use this correspondence algorithm to build Morphable Surface Models (an extension of Morphable Models) from examples. We present a method for matching the model to new surfaces and demonstrate their use for analysis, synthesis, and clustering.	MIT, Artificial Intelligence Lab, Ctr Biol & Computat Learning, Cambridge, MA 02139 USA; MIT, Dept Brain & Cognit Sci, Ctr Biol & Computat Learning, Cambridge, MA 02139 USA	Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT)	Shelton, CR (corresponding author), MIT, Artificial Intelligence Lab, Ctr Biol & Computat Learning, Cambridge, MA 02139 USA.		Shelton, Christian/GQJ-1146-2022	Shelton, Christian/0000-0001-6698-7838				Beymer D, 1996, SCIENCE, V272, P1905, DOI 10.1126/science.272.5270.1905; BEYMER D, 1993, 1431 MIT AI LAB; Bishop, 1995, NEURAL NETWORKS PATT; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; COOTES TF, 1998, P EUR C COMP VIS, V2, P484; DURBIN R, 1987, NATURE, V326, P689, DOI 10.1038/326689a0; Durbin R, 1989, NEURAL COMPUT, V1, P348, DOI 10.1162/neco.1989.1.3.348; Garland M., 1997, COMPUTER GRAPHICS, V31, P209, DOI DOI 10.1145/258734258849; Heckbert PS, 1997, SURVEY POLYGONAL SUR; Hoppe H., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P99, DOI 10.1145/237170.237216; HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011; HOPPE H, 1993, COMPUT GRAPH, V27, P19; Jones MJ, 1998, INT J COMPUT VISION, V29, P107, DOI 10.1023/A:1008074226832; KANG S, COMMUNICATION; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; MCINERNEY T, 1995, P 5 INT C COMP VIS I, P840; NASTAR C, 1996, P 4 EUR C COMP VIS; POGGIO T, 1992, 1347 MIT AI LAB; Popovic J., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P217, DOI 10.1145/258734.258852; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; RIESENHUBER M, 2000, P BMCV2000; RIESENHUBER M, 1999, 1679 MIT AI LAB CBCL; SHASHUA A, 1992, 1363 MIT AI LAB; SHELTON CR, AITR1650; SHELTON CR, 1998, THESIS MIT; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; VETTER T, 1995, 1531 MIT AI LAB; VETTER T, 1997, 1600 MIT AI LAB	28	49	52	0	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2000	38	1					75	91		10.1023/A:1008170818506	http://dx.doi.org/10.1023/A:1008170818506			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	342GH					2022-12-18	WOS:000088636500007
J	Asada, N; Fujiwara, H; Matsuyama, T				Asada, N; Fujiwara, H; Matsuyama, T			Edge and depth from focus	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						information integration; multi-focus images; depth from focus/defocus; edge detection; depth estimation		This paper proposes a novel method to obtain the reliable edge and depth information by integrating a set of multi-focus images, i.e., a sequence of images taken by systematically varying a camera parameter focus. In previous work on depth measurement using focusing or defocusing, the accuracy depends upon the size and location of local windows where the amount of blur is measured. In contrast,no windowing is needed in our method; the blur is evaluated from the intensity change along corresponding pixels in the multi-focus images. Such a blur analysis enables us not only to detect the edge points without using spatial differentiation but also to estimate the depth with high accuracy. In addition, the analysis result is stable because the proposed method involves integral computations such as summation and least-square model fitting. This paper first discusses the fundamental properties of multi-focus images based on a step edge model. Then, two algorithms are presented: edge detection using art accumulated defocus image which represents the spatial distribution of blur, and depth estimation using a spatio-focal image which represents the intensity distribution along focus axis. The experimental results demonstrate that the highly precise measurement has been achieved: 0.5 pixel position fluctuation in edge detection and 0.2% error at 2.4 m in depth estimation.	Hiroshima City Univ, Dept Intelligent Syst, Hiroshima 73131, Japan; Ind Res Ctr Okayama, Okayama 70112, Japan; Kyoto Univ, Dept Elect & Commun, Kyoto 60601, Japan	Kyoto University	Asada, N (corresponding author), Hiroshima City Univ, Dept Intelligent Syst, 3-4-1 Ozuka Higashi, Hiroshima 73131, Japan.	asada@irs.hiroshima-cu.ac.jp; fujiwara@okakogi.go.jp; tm@kuee.kyoto-u.ac.jp						ASADA N, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P150, DOI 10.1109/ICCV.1995.466793; ASADA N, 1992, P INT C PATT REC, pA466; Darrell T., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P504, DOI 10.1109/CVPR.1988.196282; ENS J, 1993, IEEE T PATTERN ANAL, V15, P97, DOI 10.1109/34.192482; GROSSMANN P, 1987, PATTERN RECOGN LETT, V5, P63, DOI 10.1016/0167-8655(87)90026-2; JARVIS RA, 1983, IEEE T PATTERN ANAL, V5, P122, DOI 10.1109/TPAMI.1983.4767365; KROTKOV E, 1987, INT J COMPUT VISION, V1, P223, DOI 10.1007/BF00127822; LAI SH, 1992, IEEE T PATTERN ANAL, V14, P405, DOI 10.1109/34.126803; LIGHTART G, 1982, P IEEE INT C PATT RE, P597; Nair H. N., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P309, DOI 10.1109/CVPR.1992.223258; Nayar S.K., 1992, P IMAGE UNDERSTANDIN, P539; PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940; Subbarao M., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P773, DOI 10.1109/CVPR.1992.223176; Subbarao M., 1994, Proceedings 1994 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.94CH3405-8), P786, DOI 10.1109/CVPR.1994.323899; SUBBARAO M, 1988, P INT C COMP VIS, P149; Xiong Y., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P68, DOI 10.1109/CVPR.1993.340977	16	49	59	0	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	FEB	1998	26	2					153	163		10.1023/A:1007996810301	http://dx.doi.org/10.1023/A:1007996810301			11	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	ZC477					2022-12-18	WOS:000072583200001
J	COX, IJ; REHG, JM; HINGORANI, S				COX, IJ; REHG, JM; HINGORANI, S			A BAYESIAN MULTIPLE-HYPOTHESIS APPROACH TO EDGE GROUPING AND CONTOUR SEGMENTATION	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							IMAGE; OBJECTS; RECOGNITION; ALGORITHMS	A contour segmentation algorithm is presented that takes an edge map and extracts continuous curves of arbitrary smoothness, correctly handling curve intersections and capable of extrapolating over significant measurement gaps. The algorithm incorporates noise models of the edge-detection process and limited scene statistics. It is based on an explicit contour model and employs a statistical distance measure to quantify the likelihood of each segmentation hypothesis. A Bayesian multiple-hypothesis tree organizes possible segementations, making it possible to postpone grouping decisions until a sufficient amount of information is available. We have demonstrated its performance on real and synthetic images.	CARNEGIE MELLON UNIV,DEPT ELECT & COMP ENGN,PITTSBURGH,PA 15213	Carnegie Mellon University	COX, IJ (corresponding author), NEC RES INST,4 INDEPENDENCE WAY,PRINCETON,NJ 08540, USA.		Rehg, James/AAM-6888-2020	Rehg, James/0000-0003-1793-5462				Ballard D.H., 1982, COMPUTER VISION; Bar-Shalom Y., 1988, TRACKING DATA ASS; Bellman R., 1962, APPL DYNAMIC PROGRAM; Boie R. A., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P100; Boie R. A., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P450; Canny J., 1986, IEEE T PATTERN ANAL, V8, P34; COX IJ, 1991, WORKSHOP COMPUTER LE; COX IJ, 1992, 2ND P EUR C COMP VIS, P72; DAVID C, 1990, INT J COMPUT VISION, V5, P219, DOI 10.1007/BF00126500; Davies Machine Vision, 1990, MACHINE VISION THEOR, P91; DERICHE R, 1990, IMAGE VIS COMPUT, V8, P251; GRIMSON WEL, 1989, IEEE T PATTERN ANAL, V11, P632, DOI 10.1109/34.24797; HILDRETH E, 1984, ARTIF INTELL, V27, P309; HORAUD R, 1987, 1ST P INT C COMP VIS, P374; HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921; KASS M, 1988, INT J COMPUT VISION, P321, DOI DOI 10.1007/BF00133570; KRIEGMAN DJ, 1990, IEEE T PATTERN ANAL, V12, P1127, DOI 10.1109/34.62602; Kurien T., 1990, MULTITARGET MULTISEN, P43; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; LOWE DG, 1989, INT J COMPUT VISION, V3, P119, DOI 10.1007/BF00126428; MARTELLI A, 1976, COMMUN ACM, V19, P73, DOI 10.1145/359997.360004; MATTHIES L, 1989, INT J COMPUT VISION, V3, P209, DOI 10.1007/BF00133032; MONTANARI U, 1972, COMMUN ACM, V15, P335; REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177; SHASHUA JA, 1991, ADV NEURAL INFORMATI, V3; SZELISKI R, 1991, SPIE, V1570, P140; UHLMANN JK, 1992, AM SCI, V80, P128; UHLMANN JK, 1991, INFORM PROCESS LETT, V40, P175, DOI 10.1016/0020-0190(91)90074-R; UHLMANN JK, 1991, PATTERN RECOGN LETT, V12, P537, DOI 10.1016/0167-8655(91)90124-5; WITKIN AP, 1982, P AAAI 82, P36; WOHN K, 1991, IEEE T PATT ANAL MAC, V13; ZHOU B, 1992, THESIS PENNSYLVANIA; ZUCKER SW, 1977, IEEE T COMPUT, V26, P394, DOI 10.1109/TC.1977.1674848; [No title captured]	34	49	52	0	2	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	1993	11	1					5	24		10.1007/BF01420590	http://dx.doi.org/10.1007/BF01420590			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	LW796					2022-12-18	WOS:A1993LW79600001
J	KRIEGMAN, DJ; PONCE, J				KRIEGMAN, DJ; PONCE, J			COMPUTING EXACT ASPECT GRAPHS OF CURVED OBJECTS - SOLIDS OF REVOLUTION	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							REPRESENTATION; SINGULARITIES; SURFACE	This paper introduces a new approach to computing the exact orthographic aspect graph of curved objects. Curves corresponding to various visual events partition the view sphere into regions where the image structure is stable. A catalog of these events for piecewise-smooth objects is available from singularity theory. For a solid of revolution whose generator is an algebraic curve, each visual event is characterized by a system of polynomial equations whose roots can be computed by continuation methods. Within each region, the stable image structure is characterized by a variation of cylindrical algebraic decomposition and ray tracing. This approach has been implemented and several examples are presented.	YALE UNIV,CTR SYST SCI,DEPT ELECT ENGN,NEW HAVEN,CT 06520; UNIV ILLINOIS,BECKMAN INST,DEPT COMP SCI,URBANA,IL 61801	Yale University; University of Illinois System; University of Illinois Urbana-Champaign								ARNOLD VI, 1983, RUSS MATH SURV+, V38, P87, DOI 10.1070/RM1983v038n02ABEH003471; Arnon D. S., 1983, Computer Graphics, V17, P219, DOI 10.1145/964967.801152; ARNON DS, 1984, SIAM J COMPUT, V13, P878, DOI 10.1137/0213055; BINFORD TO, 1987, 4TH P INT S ROB RES; BINFORD TO, 1971, P IEEE C SYSTEMS CON; BOWYER K, 1989, MAY P IM UND WORKSH, P831; BURNS J, 1988, APR P IM UND WORKSH, P711; Callahan J., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P240; Canny, 1988, COMPLEXITY ROBOT MOT; CANNY JF, 1988, COMPUTER SCI, V440; CASTORE G, 1984, SOLID MODELING COMPU, P277; CHAKRAVARTY I, 1982, IPLTR034 RENSS POL I; COLLINS GE, 1971, ASS COMPUT MACH, V18, P515; Do Carmo M.P., 2016, DIFFERENTIAL GEOMETR, Vsecond; FAROUKI RT, 1986, COMPUT VISION GRAPH, V33, P209, DOI 10.1016/0734-189X(86)90115-5; GIBLIN PJ, 1988, IMAGE VISION COMPUT, V6, P225, DOI 10.1016/0262-8856(88)90012-1; Gigus Z., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P30, DOI 10.1109/CCV.1988.589969; GIGUS Z, 1988, UCBCSD88402 U CAL CO; Goldman RN, 1985, VISUAL COMPUT, V1, P101, DOI 10.1007/BF01898352; HEBERT M, 1985, JUN P IEEE C COMP VI; IKEUCHI K, 1988, P IEEE, V76, P1016, DOI 10.1109/5.5972; KAJIYA JT, 1982, JUL P SIGGRAPH 82, P245; KERGOSIEN YL, 1981, CR ACAD SCI I-MATH, V292, P929; KOENDERINK JJ, 1976, BIOL CYBERN, V24, P51, DOI 10.1007/BF00365595; KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644; Macaulay F.S., 1916, ALGEBRAIC THEORY MOD; Morgan A. P., 1987, SOLVING POLYNOMIAL S; NALWA V, 1987, FEB P IM UND WORKSH, P956; PLANTINGA H, 1987, CS736 U WISC TECH RE; PONCE J, 1989, IEEE T PATTERN ANAL, V11, P951, DOI 10.1109/34.35498; PONCE J, 1989, REV INTELLIGENCE ART; PONCE J, 1987, INT J COMPUT VISION, V1; PONCE J, 1989, MAY P IM UND WORKSH, P461; PONCE J, 1990, JUL P AAAI NAT C ART, P1074; RIEGER J, 1987, IMAGE VISION COMPUT, V1, P91; ROTH SD, 1982, COMPUT VISION GRAPH, V18, P109, DOI 10.1016/0146-664X(82)90169-1; SALMON G, 1866, MODERN HIGHER ALGEBR; SEDERBERG TW, 1984, COMPUT VISION GRAPH, V28, P72, DOI 10.1016/0734-189X(84)90140-3; Shafer S. A., 1985, SHADOWS SILHOUETTES; STEWMAN J, 1988, P INT C COMPUT VISIO; STEWMAN JH, 1987, IEEE WORKSHOP COMPUT, P123; WALL CTC, 1976, GEOM TOPOL, P707; WATTS N, 1987, CS234 ROCH U TECH RE; WHITNEY H, 1955, ANN MATH, V62, P374, DOI 10.2307/1970070; WHITTED T, 1980, COMMUN ACM, V23, P343, DOI 10.1145/358876.358882	45	49	49	0	1	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	1990	5	2					119	135		10.1007/BF00054918	http://dx.doi.org/10.1007/BF00054918			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	EP651					2022-12-18	WOS:A1990EP65100001
J	Li, SJ; Liu, ZQ; Chan, AB				Li, Sijin; Liu, Zhi-Qiang; Chan, Antoni B.			Heterogeneous Multi-task Learning for Human Pose Estimation with Deep Convolutional Neural Network	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Human Pose Estimation; Deep Learning		We propose a heterogeneous multi-task learning framework for human pose estimation from monocular images using a deep convolutional neural network. In particular, we simultaneously learn a human pose regressor and sliding-window body-part and joint-point detectors in a deep network architecture. We show that including the detection tasks helps to regularize the network, directing it to converge to a good solution. We report competitive and state-of-art results on several datasets. We also empirically show that the learned neurons in the middle layer of our network are tuned to localized body parts.	[Li, Sijin] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China; [Liu, Zhi-Qiang] City Univ Hong Kong, SCM, Hong Kong, Hong Kong, Peoples R China; [Chan, Antoni B.] City Univ Hong Kong, Multimedia Software Engn Res Ctr MERC, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China; [Chan, Antoni B.] Multimedia Software Engn Res Ctr MERC, Shenzhen, Guangdong, Peoples R China	City University of Hong Kong; City University of Hong Kong; City University of Hong Kong	Li, SJ (corresponding author), City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.	sijin.li@my.cityu.edu.hk; smzliu@cityu.edu.hk; abchan@cityu.edu.hk	CHAN, Antoni B./D-7858-2013	CHAN, Antoni B./0000-0002-2886-2513	Research Grants Council of the Hong Kong Special Administrative Region, China [CityU 123212, CityU 110513, GRF 9041574 (CityU 118810), GRF 9041905 (CityU 119313)]	Research Grants Council of the Hong Kong Special Administrative Region, China(Hong Kong Research Grants Council)	A.B.C. was supported by the Research Grants Council of the Hong Kong Special Administrative Region, China (CityU 123212 and CityU 110513). This work was supported by the Research Grants Council of the Hong Kong Special Administrative Region, China, under GRF 9041574 (CityU 118810), GRF 9041905 (CityU 119313).	Bo LF, 2010, INT J COMPUT VISION, V87, P28, DOI 10.1007/s11263-008-0204-y; Bregler C., 2014, ICLR; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Dantone M., 2013, IEEE C COMP VIS PATT; Eichner M, 2012, INT J COMPUT VISION, V99, P190, DOI 10.1007/s11263-012-0524-9; Eichner M., 2009, UPPER BODY DETECTOR; Eichner M., 2012, IEEE T PATTERN ANAL; Eichner M., 2009, BMVC, V2, P5; Eichner M, 2010, LECT NOTES COMPUT SC, V6311, P228, DOI 10.1007/978-3-642-15549-9_17; Evgeniou T, 2005, J MACH LEARN RES, V6, P615; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Gulcehrem C., 2013, INT C LEARN REPR; Hara K., 2013, IEEE C COMP VIS PATT; Johnson S, 2011, PROC CVPR IEEE, P1465, DOI 10.1109/CVPR.2011.5995318; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Le Q., 2012, INT C MACH LEARN, DOI DOI 10.1109/MSP.2011.940881; Nair V, 2010, P 27 INT C MACHINE L, P807; Pishchulin L, 2013, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2013.82; Pishchulin L, 2012, PROC CVPR IEEE, P3178, DOI 10.1109/CVPR.2012.6248052; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sapp B, 2013, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2013.471; Sapp B, 2010, LECT NOTES COMPUT SC, V6312, P406, DOI 10.1007/978-3-642-15552-9_30; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446; Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Weston J., 2008, P 25 INT C MACHINE L, P1168, DOI [DOI 10.1145/1390156.1390303, 10.1145/1390156.1390303]; Yang X., 2009, NEURAL INFORM PROCES; Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261; Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741; Yu K., 2005, P 22 INT C MACH LEAR, P1012, DOI DOI 10.1145/1102351.1102479; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53	34	48	51	2	61	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2015	113	1			SI		19	36		10.1007/s11263-014-0767-8	http://dx.doi.org/10.1007/s11263-014-0767-8			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	CH6GX		Green Submitted			2022-12-18	WOS:000354135700003
J	Branson, S; Van Horn, G; Wah, C; Perona, P; Belongie, S				Branson, Steve; Van Horn, Grant; Wah, Catherine; Perona, Pietro; Belongie, Serge			The Ignorant Led by the Blind: A Hybrid Human-Machine Vision System for Fine-Grained Categorization	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Fine-grained categorization; Human-in-the-loop; Interactive; Parts; Attributes; Crowdsourcing; Deformable part models; Pose mixture models; Object recognition; Information gain; Birds		We present a visual recognition system for fine-grained visual categorization. The system is composed of a human and a machine working together and combines the complementary strengths of computer vision algorithms and (non-expert) human users. The human users provide two heterogeneous forms of information object part clicks and answers to multiple choice questions. The machine intelligently selects the most informative question to pose to the user in order to identify the object class as quickly as possible. By leveraging computer vision and analyzing the user responses, the overall amount of human effort required, measured in seconds, is minimized. Our formalism shows how to incorporate many different types of computer vision algorithms into a human-in-the-loop framework, including standard multiclass methods, part-based methods, and localized multiclass and attribute methods. We explore our ideas by building a field guide for bird identification. The experimental results demonstrate the strength of combining ignorant humans with poor-sighted machines the hybrid system achieves quick and accurate bird identification on a dataset containing 200 bird species.	[Branson, Steve; Perona, Pietro] CALTECH, Pasadena, CA 91125 USA; [Van Horn, Grant; Wah, Catherine; Belongie, Serge] Univ Calif San Diego, La Jolla, CA 92093 USA	California Institute of Technology; University of California System; University of California San Diego	Branson, S (corresponding author), CALTECH, Pasadena, CA 91125 USA.	sbranson@caltech.edu		Belongie, Serge/0000-0002-0388-5217				[Anonymous], ICCV; [Anonymous], ICCV; [Anonymous], 2011, CVPR; Belhumeur P., 2008, ECCV; Berg T., 2013, CVPR; Biederman I, 1999, PSYCHOL RES-PSYCH FO, V62, P131, DOI 10.1007/s004260050047; Bourdev L., 2009, ICCV; Branson S., 2011, ICCV; Branson Steve, 2010, ECCV; Chai Y., 2012, ECCV; Chai Yuning, 2011, ICCV; Cox I.J., 2000, IMAGE PROCESSING; Donahue J., 2011, ICCV; Douze M., 2011, CVPR; Duan Kun, 2012, CVPR; Fang Y., 2005, AVBPA; Farhadi A., 2010, CVPR; Farhadi A., 2009, CVPR; Farrell Ryan, 2011, ICCV; Felzenszwalb P., 2002, CVPR; Felzenszwalb P., 2008, CVPR; Ferecatu M., 2007, ICCV; Ferecatu M., 2009, PAMI; Gavves E., 2013, ICCV; Geman D., 1993, SHAPE RECOGNITION 20; Geman D., 1996, PAMI; Jedynak B, 2012, J APPL PROBAB, V49, P114, DOI 10.1239/jap/1331216837; Khosla A., 2011, CVPR; Kumar N., 2008, ECCV; Kumar N., 2009, ICCV; Kumar Neeraj, 2012, ECCV; Lampert C. H., 2009, CVPR; Larios N., 2010, ICPR; LAZEBNIK S, 2005, ICCV; Levin Anat, 2007, PAMI, V1, P2; Liu J., 2012, ECCV; LU Y, 2000, ACM MULTIMEDIA; Maji S., 2012, ECCV PARTS ATTRIBUTE; Maji S., 2012, C ART INT WORKSH; Martmez-Munoz, 2009, CVPR; Mervis C. B., 1982, CHILD DEV, V53, P256; Nilsback M. E., 2008, ICVGIP; Nilsback M. E., 2006, CVPR; Ott P., 2011, CVPR; PARIKH D, 2013, ICCV; Parikh D., 2011, ICCV; Parikh D., 2011, NIPS WISDOM CROWDS; Parikh D., 2011, CVPR; Parkash Amar, 2012, ECCV; Parkhi O., 2011, ICCV; Parkhi O. M., 2012, CVPR; Perronnin F., 2010, ECCV; Platt J.C., 1999, ALMC; Quinlan J., 2014, C4 5 PROGRAMS MACHIN, DOI DOI 10.1007/BF00993309; Rasiwasia N., 2007, MULTIMEDIA; Rosch E., 1976, COGNITIVE PSYCHOL; Rosch E., 1999, CONCEPTS CORE READIN; Rother Carsten, 2004, TOG; Settles B., 2008, CURIOUS MACHINES ACT; Stark M., 2012, BMVC; Sznitman R., 2010, PAMI; Sznitman R., 2011, MICCAI; Tsiligkaridis T., 2013, ICASSP; Tsochantaridis I., 2006, JMLR; Vijayanarasimhan S, 2011, CVPR; Vijayanarasimhan Sudheendra, 2009, CVPR; VONDRICK C, 2010, ECCV; Vondrick Carl, 2011, NIPS; Wah Catherine, 2011, CALTECH UCSD BIRDS 2; Wang G., 2009, ICCV; Wang J., 2009, BMVC; Wu W., 2006, MULTIMEDIA; Yao B., 2012, CVPR; Yao B., 2011, CVPR; Zhang  N., 2012, CVPR; Zhang Ning, 2013, ICCV; Zhou X., 2003, MULTIMEDIA	77	48	50	0	16	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2014	108	1-2			SI		3	29		10.1007/s11263-014-0698-4	http://dx.doi.org/10.1007/s11263-014-0698-4			27	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AG7BT					2022-12-18	WOS:000335573700002
J	Li, J; Tian, YH; Huang, TJ				Li, Jia; Tian, Yonghong; Huang, Tiejun			Visual Saliency with Statistical Priors	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Visual saliency; Prior knowledge; Image statistics; Bayesian framework	EYE-MOVEMENTS; ATTENTION; FEATURES	Visual saliency is a useful cue to locate the conspicuous image content. To estimate saliency, many approaches have been proposed to detect the unique or rare visual stimuli. However, such bottom-up solutions are often insufficient since the prior knowledge, which often indicates a biased selectivity on the input stimuli, is not taken into account. To solve this problem, this paper presents a novel approach to estimate image saliency by learning the prior knowledge. In our approach, the influences of the visual stimuli and the prior knowledge are jointly incorporated into a Bayesian framework. In this framework, the bottom-up saliency is calculated to pop-out the visual subsets that are probably salient, while the prior knowledge is used to recover the wrongly suppressed targets and inhibit the improperly popped-out distractors. Compared with existing approaches, the prior knowledge used in our approach, including the foreground prior and the correlation prior, is statistically learned from 9.6 million images in an unsupervised manner. Experimental results on two public benchmarks show that such statistical priors are effective to modulate the bottom-up saliency to achieve impressive improvements when compared with 10 state-of-the-art methods.	[Li, Jia; Tian, Yonghong; Huang, Tiejun] Peking Univ, Sch EE & CS, Natl Engn Lab Video Technol, Beijing 100871, Peoples R China	Peking University	Li, J (corresponding author), Peking Univ, Sch EE & CS, Natl Engn Lab Video Technol, Beijing 100871, Peoples R China.	jia.li@pku.edu.cn; yhtian@pku.edu.cn	Li, Jia/AAB-6431-2019	Li, Jia/0000-0002-4346-8696	Chinese National Natural Science Foundation [61370113, 61035001]; Supervisor Award Funding for Excellent Doctoral Dissertation of Beijing [20128000103]; Singapore National Research Foundation under its IDM Futures Funding Initiative	Chinese National Natural Science Foundation(National Natural Science Foundation of China (NSFC)); Supervisor Award Funding for Excellent Doctoral Dissertation of Beijing; Singapore National Research Foundation under its IDM Futures Funding Initiative(National Research Foundation, Singapore)	This work was supported in part by grants from the Chinese National Natural Science Foundation under contract No. 61370113 and No. 61035001, and the Supervisor Award Funding for Excellent Doctoral Dissertation of Beijing (No. 20128000103). This research was also partially supported by the Singapore National Research Foundation under its IDM Futures Funding Initiative and administered by the Interactive & Digital Media Programme Office, Media Development Authority.	Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596; [Anonymous], 2006, NIPS; Aziz MZ, 2008, IEEE T IMAGE PROCESS, V17, P633, DOI 10.1109/TIP.2008.919365; Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711; Cerf M., 2008, ADV NEURAL INFORM PR, V20, P241, DOI DOI 10.1145/2185520.2185525; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Chikkerur S, 2010, VISION RES, V50, P2233, DOI 10.1016/j.visres.2010.05.013; Elazary L, 2008, J VISION, V8, DOI 10.1167/8.3.3; Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800; Frith Chris, 2005, P105, DOI 10.1016/B978-012375731-9/50022-7; Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929; Han F, 2009, IEEE T PATTERN ANAL, V31, P59, DOI 10.1109/TPAMI.2008.55; Harel J., 2006, PAPER PRESENTED INT, P545, DOI DOI 10.7551/MITPRESS/7503.003.0073; Henderson JM, 2003, TRENDS COGN SCI, V7, P498, DOI 10.1016/j.tics.2003.09.006; Hou X., 2008, P ADV NEUR INF PROC, P681; Hou X, 2007, 2007 IEEE C COMP VIS, V800, P1, DOI DOI 10.1109/CVPR.2007.383267; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462; Kienzle W, 2007, ADV NEURAL INFORM PR, P689; Li J, 2010, INT J COMPUT VISION, V90, P150, DOI 10.1007/s11263-010-0354-6; Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147; Liu H., 2007, P ACM INT C MULT, P305, DOI DOI 10.1145/1291233.1291298; Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047; Lu Y, 2011, IEEE I CONF COMP VIS, P233, DOI 10.1109/ICCV.2011.6126247; Meur O. L., 2006, IEEE T PATTERN ANAL, V28, P802; Navalpakkam V, 2007, NEURON, V53, P605, DOI 10.1016/j.neuron.2007.01.018; PARIKH D, 2008, EUR C COMP VIS; Peters R.J., 2007, 2007 IEEE C COMP VIS; Riche N, 2012, IEEE IMAGE PROC, P641, DOI 10.1109/ICIP.2012.6466941; Sun XS, 2012, PROC CVPR IEEE, P1552, DOI 10.1109/CVPR.2012.6247846; Tatler BW, 2005, VISION RES, V45, P643, DOI 10.1016/j.visres.2004.09.017; Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766; Tseng PH, 2009, J VISION, V9, DOI 10.1167/9.7.4; Vikram TN, 2012, PATTERN RECOGN, V45, P3114, DOI 10.1016/j.patcog.2012.02.009; Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001; Wang W., 2010, P IEEE C COMP VIS PA; Wolfe Jeremy M., 2005, P101, DOI 10.1016/B978-012375731-9/50021-5; Wolfe JM, 2000, NATURE, V406, P691, DOI 10.1038/35021132; Wu TF, 2011, INT J COMPUT VISION, V93, P226, DOI 10.1007/s11263-010-0346-6; Yang JM, 2012, PROC CVPR IEEE, P2296, DOI 10.1109/CVPR.2012.6247940; Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32; Zhao Q, 2012, J VISION, V12, DOI 10.1167/12.6.22; Zhao Q, 2011, J VISION, V11, DOI 10.1167/11.3.9	43	48	51	2	31	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2014	107	3					239	253		10.1007/s11263-013-0678-0	http://dx.doi.org/10.1007/s11263-013-0678-0			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AD6IU					2022-12-18	WOS:000333362600002
J	Kim, H; Hilton, A				Kim, Hansung; Hilton, Adrian			3D Scene Reconstruction from Multiple Spherical Stereo Pairs	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						3D reconstruction; Environment modelling; Disparity estimation; 3D registration and mesh integration	OPTICAL-FLOW ESTIMATION; REGISTRATION; SPACE; VIEWS; WORLD	We propose a 3D environment modelling method using multiple pairs of high-resolution spherical images. Spherical images of a scene are captured using a rotating line scan camera. Reconstruction is based on stereo image pairs with a vertical displacement between camera views. A 3D mesh model for each pair of spherical images is reconstructed by stereo matching. For accurate surface reconstruction, we propose a PDE-based disparity estimation method which produces continuous depth fields with sharp depth discontinuities even in occluded and highly textured regions. A full environment model is constructed by fusion of partial reconstruction from spherical stereo pairs at multiple widely spaced locations. To avoid camera calibration steps for all camera locations, we calculate 3D rigid transforms between capture points using feature matching and register all meshes into a unified coordinate system. Finally a complete 3D model of the environment is generated by selecting the most reliable observations among overlapped surface measurements considering surface visibility, orientation and distance from the camera. We analyse the characteristics and behaviour of errors for spherical stereo imaging. Performance of the proposed algorithm is evaluated against ground-truth from the Middlebury stereo test bed and LIDAR scans. Results are also compared with conventional structure-from-motion algorithms. The final composite model is rendered from a wide range of viewpoints with high quality textures.	[Kim, Hansung; Hilton, Adrian] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England	University of Surrey	Kim, H (corresponding author), Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.	coolhs99@hotmail.com; a.hilton@surrey.ac.uk	Hilton, Adrian/N-3736-2014	Hilton, Adrian/0000-0003-4223-238X; Kim, Hansung/0000-0003-4907-0491	EU FP7 project i3DPost; UK TSB project SyMMM; EU ICT FP7 project IMPART; Engineering and Physical Sciences Research Council [EP/F02827X/1] Funding Source: researchfish; EPSRC [EP/F02827X/1] Funding Source: UKRI	EU FP7 project i3DPost; UK TSB project SyMMM; EU ICT FP7 project IMPART; Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This research was executed with the financial support of the EU FP7 project i3DPost, UK TSB project SyMMM and EU ICT FP7 project IMPART.	Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148; Aiger D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360684; Akbari A. A., 2006, 2006 WORLD AUTOMATIO, P1, DOI DOI 10.1109/3DPVT.2006.141; Alvarez L, 2002, J VIS COMMUN IMAGE R, V13, P3, DOI 10.1006/jvci.2001.0482; Alvarez L, 2007, INT J COMPUT VISION, V75, P371, DOI 10.1007/s11263-007-0041-4; Anguelov D, 2010, COMPUTER, V43, P32, DOI 10.1109/MC.2010.170; Asai T, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P447, DOI 10.1109/3DIM.2005.3; Banno A, 2009, P 3DIM; Banno A, 2010, COMPUT VIS IMAGE UND, V114, P491, DOI 10.1016/j.cviu.2009.12.005; Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; BENARI R, 2007, IEEE 11 INT C COMP V, P1, DOI DOI 10.1109/ICCV.2007.4408996; Benosman R, 1998, INT C PATT RECOG, P767, DOI 10.1109/ICPR.1998.711259; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3; BURT PJ, 1981, COMPUT VISION GRAPH, V16, P20, DOI 10.1016/0146-664X(81)90092-7; Chen S. E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P29, DOI 10.1145/218380.218395; CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C; Cornelis N, 2008, INT J COMPUT VISION, V78, P121, DOI 10.1007/s11263-007-0081-9; Dellaert F., 2000, P CVPR; DeSouza GN, 2002, IEEE T PATTERN ANAL, V24, P237, DOI 10.1109/34.982903; Feldman D, 2005, IEEE I CONF COMP VIS, P839, DOI 10.1109/ICCV.2005.200; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fisher R, 2007, CVONLINE; Frahm JM, 2010, LECT NOTES COMPUT SC, V6314, P368, DOI 10.1007/978-3-642-15561-1_27; Furukawa Y., 2009, P CVPR; Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161; Furukawa Yasutaka, 2010, P CVPR; Ganan Stuart, 1985, P STAT COMP SECT AM, P12; Gargallo P, 1988, P CVPR, P885; Goesele M, 2007, P ICCV, P368; Granger S., 2001, LECT NOTES COMPUTER, V2208, P752; Haala N, 2005, P PANOPHOT; Hiep VH, 2009, PROC CVPR IEEE, P1430, DOI 10.1109/CVPRW.2009.5206617; Hilton A, 1998, COMPUT VIS IMAGE UND, V69, P273, DOI 10.1006/cviu.1998.0664; Hilton A, 2005, IMAGE VISION COMPUT, V23, P900, DOI 10.1016/j.imavis.2005.05.018; Hirschmuller H, 2009, IEEE T PATTERN ANAL, V31, P1582, DOI 10.1109/TPAMI.2008.221; Ince S, 2008, IEEE T IMAGE PROCESS, V17, P1443, DOI 10.1109/TIP.2008.925381; Johnson C., 1988, NUMERICAL SOLUTION P; Kang SB, 1997, INT J COMPUT VISION, V25, P167, DOI 10.1023/A:1007971901577; Kazhdan Michael, 2006, P EUR S GEOM PROC, V7, P2; Kim H, 2003, IEEE IMAGE PROC, P373; Kim H, 2003, P SOC PHOTO-OPT INS, V5006, P544, DOI 10.1117/12.473879; Kim H, 2010, P RMLE WORKSH ECCV; Kim H, 2009, P 3DIM; Klaus A., 2006, P ICPR; KOLMOGOROV V, 2001, P ICCV; Lemmens M, 2007, GIM INT, V21, P13; Lhuillier M, 2008, COMPUT VIS IMAGE UND, V109, P186, DOI 10.1016/j.cviu.2007.05.004; Li SG, 2006, INT C PATT RECOG, P1046; Mathias M., 2011, 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), P304, DOI 10.1109/3DIMPVT.2011.45; MERRELL P, 2007, P ICCV; Micusik Branislav, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2906, DOI 10.1109/CVPRW.2009.5206535; Micusik B, 2004, P ACCV; Min D, 2008, IEEE T IMAGE PROCESS, V17, P1431, DOI 10.1109/TIP.2008.925372; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; Nayar SK, 2000, PROC CVPR IEEE, P388; Pollefeys M, 2000, ISPRS J PHOTOGRAMM, V55, P251, DOI 10.1016/S0924-2716(00)00023-X; Pollefeys M, 2008, INT J COMPUT VISION, V78, P143, DOI 10.1007/s11263-007-0086-4; Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423; Salman N, 2009, P ACCV; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; Simon L, 2011, INT J COMPUT VISION, V93, P253, DOI 10.1007/s11263-010-0370-6; Sizintsev M, 2008, PROCEEDINGS OF THE FIFTH CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, P97, DOI 10.1109/CRV.2008.8; Slesareva N, 2005, LECT NOTES COMPUT SC, V3663, P33; Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; SOUCY M, 1995, IEEE T PATTERN ANAL, V17, P344, DOI 10.1109/34.385982; Strecha C, 2004, PROC CVPR IEEE, P552; Strecha C., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587706; Sun DQ, 2008, LECT NOTES COMPUT SC, V5304, P83; Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509; Szeliski R, 2004, IEEE T PATTERN ANAL, V26, P419, DOI 10.1109/TPAMI.2004.1262341; Teller S, 2003, INT J COMPUT VISION, V53, P93, DOI 10.1023/A:1023035826052; Tighe J., 2010, P ECCV; Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241; Vergauwen M, 2006, MACH VISION APPL, V17, P411, DOI 10.1007/s00138-006-0027-1; Weickert J, 1997, LECT NOTES COMPUT SC, V1252, P3; Williams J, 2001, COMPUT VIS IMAGE UND, V81, P117, DOI 10.1006/cviu.2000.0884; Yang QX, 2009, IEEE T PATTERN ANAL, V31, P492, DOI 10.1109/TPAMI.2008.99; YUILLE AL, 1984, 777 MIT AI; Zimmer H., 2008, VISION MODELING VISU, P263; Zomet A, 2003, IEEE T PATTERN ANAL, V25, P741, DOI 10.1109/TPAMI.2003.1201823	82	48	55	0	57	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2013	104	1					94	116		10.1007/s11263-013-0616-1	http://dx.doi.org/10.1007/s11263-013-0616-1			23	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	179LY		Green Submitted			2022-12-18	WOS:000321523000005
J	Duits, R; Franken, E				Duits, Remco; Franken, Erik			Left-Invariant Diffusions on the Space of Positions and Orientations and their Application to Crossing-Preserving Smoothing of HARDI images	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						High angular resolution diffusion imaging (HARDI); Scale spaces; Lie groups; Partial differential equations	COMPLETION; RECONSTRUCTION; ENHANCEMENT; EQUATIONS	HARDI (High Angular Resolution Diffusion Imaging) is a recent magnetic resonance imaging (MRI) technique for imaging water diffusion processes in fibrous tissues such as brain white matter and muscles. In this article we study left-invariant diffusion on the group of 3D rigid body movements (i.e. 3D Euclidean motion group) SE(3) and its application to crossing-preserving smoothing of HARDI images. The linear left-invariant (convection-)diffusions are forward Kolmogorov equations of Brownian motions on the space of positions and orientations in 3D embedded in SE(3) and can be solved by a"e(3) a < S S (2)-convolution with the corresponding Green's functions. We provide analytic approximation formulas and explicit sharp Gaussian estimates for these Green's functions. In our design and analysis for appropriate (nonlinear) convection-diffusions on HARDI data we explain the underlying differential geometry on SE(3). We write our left-invariant diffusions in covariant derivatives on SE(3) using the Cartan connection. This Cartan connection has constant curvature and constant torsion, and so have the exponential curves which are the auto-parallels along which our left-invariant diffusion takes place. We provide experiments of our crossing-preserving Euclidean-invariant diffusions on artificial HARDI data containing crossing-fibers.	[Duits, Remco] Eindhoven Univ Technol, Dept Math & Comp Sci, CASA Appl Anal, NL-5600 MB Eindhoven, Netherlands; [Duits, Remco; Franken, Erik] Eindhoven Univ Technol, Dept Biomed Engn, BMIA Biomed Image Anal, NL-5600 MB Eindhoven, Netherlands	Eindhoven University of Technology; Eindhoven University of Technology	Duits, R (corresponding author), Eindhoven Univ Technol, Dept Math & Comp Sci, CASA Appl Anal, POB 513, NL-5600 MB Eindhoven, Netherlands.	R.Duits@tue.nl; E.M.Franken@tue.nl			Netherlands Organization for Scientific Research (NWO)	Netherlands Organization for Scientific Research (NWO)(Netherlands Organization for Scientific Research (NWO))	Vesna Prckovska and Paulo Rodrigues, biomedical image analysis group Eindhoven University of Technology are gratefully acknowledged for providing the artificial HARDI test images and the DTI tool supporting HARDI glyphs. Special thanks to Mark Bruurmijn and Paulo Rodrigues, Eindhoven University of Technology, for their support on the visualization and implementation of R<SUP>3</SUP> x S<SUP>2</SUP>-convolutions. The Netherlands Organization for Scientific Research (NWO) is gratefully acknowledged for financial support.	Alvarez L., 1993, ARCH RATION MECH AN, V123, P200; ARENDT W, 1994, FORUM MATH, V6, P111, DOI 10.1515/form.1994.6.111; ARSIGNY V, 2006, 5885 INRIA; Aubin T., 2001, GRADUATE STUDIES MAT, V27; Barmpoutis A, 2008, LECT NOTES COMPUT SC, V5241, P9, DOI 10.1007/978-3-540-85988-8_2; Burgeth B, 2003, LECT NOTES COMPUT SC, V2695, P325; BURGETH B, 2008, 220 SAARL U; CHIRIKJIAN G. S., 2001, ENG APPL NONCOMMUTIT; Citti G, 2006, J MATH IMAGING VIS, V24, P307, DOI 10.1007/s10851-005-3630-2; Descoteaux M, 2007, MAGN RESON MED, V58, P497, DOI 10.1002/mrm.21277; DRISCOLL JR, 1994, ADV APPL MATH, V15, P202, DOI 10.1006/aama.1994.1008; Duffs R., 2009, 18 CASA TU EINDH DEP; Duits R, 2004, J MATH IMAGING VIS, V20, P267, DOI 10.1023/B:JMIV.0000024043.96722.aa; Duits R., 2009, 9 CASA TU EINDH DEP, V9; Duits R, 2008, Q APPL MATH, V66, P27; Duits R, 2007, LECT NOTES COMPUT SC, V4485, P300; Duits R, 2007, INT J COMPUT VISION, V72, P79, DOI 10.1007/s11263-006-8894-5; Duits R, 2010, Q APPL MATH, V68, P255, DOI 10.1090/S0033-569X-10-01172-0; Duits R, 2009, LECT NOTES COMPUT SC, V5567, P795, DOI 10.1007/978-3-642-02256-2_66; Fletcher PT, 2007, SIGNAL PROCESS, V87, P250, DOI 10.1016/j.sigpro.2005.12.018; FLORACK L, 2008, P 18 INT C COMP GRAP, P26; FLORACK LMJ, 2008, DIG P CVPR WORKSH TE; Franken E, 2008, THESIS EINDHOVEN U T; Franken E, 2009, INT J COMPUT VISION, V85, P253, DOI 10.1007/s11263-009-0213-5; GAVEAU B, 1977, ACTA MATH-DJURSHOLM, V139, P95, DOI 10.1007/BF02392235; Gerschgorin S., 1931, IZV AKAD NAUK USSR O, V1, P749; Gur Y, 2005, LECT NOTES COMPUT SC, V3752, P13; Gur Y, 2009, J MATH IMAGING VIS, V33, P195, DOI 10.1007/s10851-008-0127-9; Hess CP, 2006, MAGN RESON MED, V56, P104, DOI 10.1002/mrm.20931; HORMANDE.L, 1967, ACTA MATH-UPPSALA, V119, P147, DOI 10.1007/BF02392081; Iijima T., 1962, BULL ELECT LAB, V26, P368; Jost J., 2005, RIEMANNIAN GEOMETRY; Kunis S, 2003, J COMPUT APPL MATH, V161, P75, DOI 10.1016/S0377-0427(03)00546-6; Mumford D., 1994, ALGEBRAIC GEOMETRY I, V5681, P491, DOI DOI 10.1007/978-1-4612-2628-4_31; NAGEL A, 1990, B AM MATH SOC, V23, P139, DOI 10.1090/S0273-0979-1990-15920-8; Ozarslan E, 2003, MAGN RESON MED, V50, P955, DOI 10.1002/mrm.10596; PRCKOVSKA V, 2010, 20 CASA EINDH U TECH; RODRIGUES P, 2010, 15 CASA EINDH U TECH; SPIVAK M, 1975, DIFFERENTIAL GEOMETR, V2; ter Elst AFM, 1998, J FUNCT ANAL, V157, P88, DOI 10.1006/jfan.1998.3259; Thornber KK, 2000, PATTERN RECOGN, V33, P543, DOI 10.1016/S0031-3203(99)00071-0; van Almsick M.A., 2005, THESIS EINDHOVEN U T; Weickert J, 1999, INT J COMPUT VISION, V31, P111, DOI 10.1023/A:1008009714131; Zweck J, 2004, J MATH IMAGING VIS, V21, P135, DOI 10.1023/B:JMIV.0000035179.47895.bc	45	48	48	0	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2011	92	3					231	264		10.1007/s11263-010-0332-z	http://dx.doi.org/10.1007/s11263-010-0332-z			34	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	729DS		Bronze, Green Published			2022-12-18	WOS:000287929400001
J	Guillemaut, JY; Hilton, A				Guillemaut, Jean-Yves; Hilton, Adrian			Joint Multi-Layer Segmentation and Reconstruction for Free-Viewpoint Video Applications	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Segmentation; Reconstruction; Free-viewpoint video; Graph-cuts	ENERGY MINIMIZATION; GRAPH-CUTS; 3D VIDEO; STEREO; FUSION	Current state-of-the-art image-based scene reconstruction techniques are capable of generating high-fidelity 3D models when used under controlled capture conditions. However, they are often inadequate when used in more challenging environments such as sports scenes with moving cameras. Algorithms must be able to cope with relatively large calibration and segmentation errors as well as input images separated by a wide-baseline and possibly captured at different resolutions. In this paper, we propose a technique which, under these challenging conditions, is able to efficiently compute a high-quality scene representation via graph-cut optimisation of an energy function combining multiple image cues with strong priors. Robustness is achieved by jointly optimising scene segmentation and multiple view reconstruction in a view-dependent manner with respect to each input camera. Joint optimisation prevents propagation of errors from segmentation to reconstruction as is often the case with sequential approaches. View-dependent processing increases tolerance to errors in through-the-lens calibration compared to global approaches. We evaluate our technique in the case of challenging outdoor sports scenes captured with manually operated broadcast cameras as well as several indoor scenes with natural background. A comprehensive experimental evaluation including qualitative and quantitative results demonstrates the accuracy of the technique for high quality segmentation and reconstruction and its suitability for free-viewpoint video under these difficult conditions.	[Guillemaut, Jean-Yves; Hilton, Adrian] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England	University of Surrey	Guillemaut, JY (corresponding author), Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.	J.Guillemaut@surrey.ac.uk	Hilton, Adrian/N-3736-2014; Guillemaut, Jean-Yves/N-7739-2014	Hilton, Adrian/0000-0003-4223-238X; Guillemaut, Jean-Yves/0000-0001-8223-5505	Technology Strategy Board; Engineering and Physical Sciences Research Council [TP/11/CII/6/I/ AJ307D, TS/G002800/1, TP/3/DSM/6/I/15515, EP/D033926/1]; Engineering and Physical Sciences Research Council [EP/F02827X/1] Funding Source: researchfish; EPSRC [EP/D033926/1, TS/G002800/1, EP/F02827X/1] Funding Source: UKRI	Technology Strategy Board; Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was supported by the Technology Strategy Board and the Engineering and Physical Sciences Research Council projects "i3Dlive: interactive 3D methods for live-action media" (TP/11/CII/6/I/ AJ307D, TS/G002800/1) and "iview: Free-viewpoint Video for Interactive Entertainment Production" (TP/3/DSM/6/I/15515, EP/D033926/1). The Technology Strategy Board's role is to promote and support research into, and development and exploitation of, technology and innovation for the benefit of UK business, in order to increase economic growth and improve the quality of life. www.innovateuk.org. The authors would like to acknowledge the BBC for providing the sport data, the project partners at BBC R&D, The Foundry, Snell and Hawk-Eye Innovations for technical discussions, Daniel Scharstein for kindly performing the evaluation with the Middlebury datasets, and Martin Klaudiny and Cemre Zor for acting in the Ball and Dance2 sequences.	ALAHARI K, 2008, CVPR; Bai X, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531376; Ballan L, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778824; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Bradley D., 2008, CVPR; Broadhurst A, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P388, DOI 10.1109/ICCV.2001.937544; Campbell NDF, 2010, IMAGE VISION COMPUT, V28, P14, DOI 10.1016/j.imavis.2008.09.005; Chen S. E., 1993, Computer Graphics Proceedings, P279, DOI 10.1145/166117.166153; Chuang YY, 2002, ACM T GRAPHIC, V21, P243, DOI 10.1145/566570.566572; Cohen J. D., 1995, Proceedings 1995 Symposium on Interactive 3D Graphics, P189, DOI 10.1145/199404.199437; CONNOR K, 2003, BMVC; Debevec P. E., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P11, DOI 10.1145/237170.237191; DEBONET JS, 1999, ICCV, P418; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Eisemann M, 2008, COMPUT GRAPH FORUM, V27, P409, DOI 10.1111/j.1467-8659.2008.01138.x; Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016; Franco J.-S., 2003, BRIT MACH VIS C BMVC, V1, P329, DOI [DOI 10.5244/C.17.32, 10.5244/C.17.32]; Franco JS, 2005, IEEE I CONF COMP VIS, P1747; Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161; Germann M, 2010, COMPUT GRAPH FORUM, V29, P585, DOI 10.1111/j.1467-8659.2009.01628.x; GOESELE M, 2006, CVPR, P2402; Goldlucke B, 2003, PROC CVPR IEEE, P683; Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200; GRAU G, 2007, 3DTV; GRAU O, 2005, WIAMIS; Guillemaut JY, 2007, 3DIM 2007: SIXTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P167; Guillemaut JY, 2009, IEEE I CONF COMP VIS, P809, DOI 10.1109/ICCV.2009.5459299; HABBECKE M, 2007, CVPR; Inamoto N, 2007, IEEE T MULTIMEDIA, V9, P1155, DOI 10.1109/TMM.2007.902832; Kang SB, 2006, FOUND TRENDS COMPUT, V2, P173, DOI 10.1561/0600000012; Kazhdan Michael, 2006, P EUR S GEOM PROC, V7, P2; Kilner J, 2007, 3DIM 2007: SIXTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P177; Kilner J, 2009, SIGNAL PROCESS-IMAGE, V24, P3, DOI 10.1016/j.image.2008.10.004; KIMURA K, 2005, CVMP, P112; Kohli P, 2007, IEEE T PATTERN ANAL, V29, P2079, DOI 10.1109/TPAMI.2007.1128; Kolmogorov V, 2002, LECT NOTES COMPUT SC, V2352, P82; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1480, DOI 10.1109/TPAMI.2006.193; Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954; Kutulakos KN, 2000, LECT NOTES COMPUT SC, V1842, P67; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; Li Y, 2005, ACM T GRAPHIC, V24, P595, DOI 10.1145/1073204.1073234; Liu YB, 2009, PROC CVPR IEEE, P2121, DOI [10.1109/CVPRW.2009.5206712, 10.1109/CVPR.2009.5206712]; Matusik W, 2002, ACM T GRAPHIC, V21, P427, DOI 10.1145/566570.566599; Matusik W, 2000, COMP GRAPH, P369, DOI 10.1145/344779.344951; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mitchelson J., 2003, VSSPTR22003 U SURR C; Moezzi S, 1997, IEEE MULTIMEDIA, V4, P18, DOI 10.1109/93.580392; Narayanan PJ, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P3, DOI 10.1109/ICCV.1998.710694; Ohta Y, 2007, INT J COMPUT VISION, V75, P173, DOI 10.1007/s11263-006-0030-z; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Roy S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P492, DOI 10.1109/ICCV.1998.710763; Seitz S., 2006, 2006 IEEE COMP SOC C, V1, P519, DOI [10.1109/CVPR.2006.19, DOI 10.1109/CVPR.2006.19]; Seitz S. M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P21, DOI 10.1145/237170.237196; Seitz SM, 1999, INT J COMPUT VISION, V35, P151, DOI 10.1023/A:1008176507526; Sinha SN, 2005, IEEE I CONF COMP VIS, P349; SLABAUGH G, 2001, INT WORKSH VOL GRAPH; Snow D, 2000, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2000.855839; Starck J, 2005, GRAPH MODELS, V67, P600, DOI 10.1016/j.gmod.2005.01.008; Starck J, 2007, IEEE COMPUT GRAPH, V27, P21, DOI 10.1109/MCG.2007.68; SUN J, 2006, ECCV, P628; Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844; Thomas G, 2007, J REAL-TIME IMAGE PR, V2, P117, DOI 10.1007/s11554-007-0041-1; Vlasic D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618520; Vogiatzis G, 2007, IEEE T PATTERN ANAL, V29, P2241, DOI 10.1109/TPAMI.2007.70712; Waschbusch M, 2007, COMPUT GRAPH FORUM, V26, P561, DOI 10.1111/j.1467-8659.2007.01079.x; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718; Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766	73	48	54	0	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2011	93	1					73	100		10.1007/s11263-010-0413-z	http://dx.doi.org/10.1007/s11263-010-0413-z			28	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	738WJ					2022-12-18	WOS:000288673000005
J	Escobar, MJ; Masson, GS; Vieville, T; Kornprobst, P				Escobar, Maria-Jose; Masson, Guillaume S.; Vieville, Thierry; Kornprobst, Pierre			Action Recognition Using a Bio-Inspired Feedforward Spiking Network	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Spiking networks; Bio-inspired model; Motion analysis; V1; MT; Action recognition	PRIMARY VISUAL-CORTEX; AREA MT; HUMAN MOVEMENT; NEURONAL SYNCHRONIZATION; TEMPORAL PROPERTIES; OBJECT RECOGNITION; BIOLOGICAL MOTION; RECEPTIVE-FIELDS; MODEL; PERCEPTION	We propose a bio-inspired feedforward spiking network modeling two brain areas dedicated to motion (V1 and MT), and we show how the spiking output can be exploited in a computer vision application: action recognition. In order to analyze spike trains, we consider two characteristics of the neural code: mean firing rate of each neuron and synchrony between neurons. Interestingly, we show that they carry some relevant information for the action recognition application. We compare our results to Jhuang et al. (Proceedings of the 11th international conference on computer vision, pp. 1-8, 2007) on the Weizmann database. As a conclusion, we are convinced that spiking networks represent a powerful alternative framework for real vision applications that will benefit from recent advances in computational neuroscience.	[Escobar, Maria-Jose; Vieville, Thierry; Kornprobst, Pierre] INRIA Sophia Antipolis, F-06902 Sophia Antipolis, France; [Masson, Guillaume S.] Univ Aix Marseille, CNRS, UMR6193, Inst Neurosci Cognit Mediterranee, F-13402 Marseille, France	Centre National de la Recherche Scientifique (CNRS); UDICE-French Research Universities; Aix-Marseille Universite	Escobar, MJ (corresponding author), INRIA Sophia Antipolis, 2004 Route Lucioles, F-06902 Sophia Antipolis, France.	mjescoba@sophia.inria.fr; guillaume.masson@incm.cnrs-mrs.fr; pkornp@sophia.inria.fr	Escobar, Maria Jose/O-7483-2019; MASSON, Guillaume S/G-4615-2012; Escobar, Maria-Jose/K-6318-2013	Escobar, Maria Jose/0000-0003-1563-624X; MASSON, Guillaume S/0000-0001-9227-0777; Kornprobst, Pierre/0000-0003-4906-1368	EC IP [FP6-015879]; FACETS; CONICYT Chile	EC IP; FACETS(European Commission); CONICYT Chile(Comision Nacional de Investigacion Cientifica y Tecnologica (CONICYT))	This work was partially supported by the EC IP project FP6-015879, FACETS and CONICYT Chile. We also thank to Olivier Rochel for his Mvaspike simulator, this tools allowed us to create and simulate spiking networks in an easy way.	ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; Bayerl P, 2007, INT J COMPUT VISION, V72, P27, DOI 10.1007/s11263-006-8891-8; Beintema JA, 2002, P NATL ACAD SCI USA, V99, P5661, DOI 10.1073/pnas.082483699; Berzhanskaya J, 2007, SPATIAL VISION, V20, P337, DOI 10.1163/156856807780919000; Biederlack J, 2006, NEURON, V52, P1073, DOI 10.1016/j.neuron.2006.11.012; Blake R, 2007, ANNU REV PSYCHOL, V58, P47, DOI 10.1146/annurev.psych.57.102904.190152; Blank M, 2005, IEEE I CONF COMP VIS, P1395; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Born RT, 2000, J NEUROPHYSIOL, V84, P2658, DOI 10.1152/jn.2000.84.5.2658; Born RT, 2005, ANNU REV NEUROSCI, V28, P157, DOI 10.1146/annurev.neuro.26.041002.131052; Buracas GT, 1996, VISION RES, V36, P869, DOI 10.1016/0042-6989(95)00192-1; Casile A, 2005, J VISION, V5, P348, DOI 10.1167/5.4.6; Casile A, 2003, LECT NOTES COMPUT SC, V2714, P854; CESSAC B, 2008, DEUX C FRANC NEUR CO; Collins RT, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P366, DOI 10.1109/AFGR.2002.1004181; Conway BR, 2003, J NEUROPHYSIOL, V89, P2726, DOI 10.1152/jn.00550.2002; Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681; Dayan P, 2001, THEORETICAL NEUROSCI; De Valois RL, 2000, VISION RES, V40, P3685, DOI 10.1016/S0042-6989(00)00210-8; Destexhe A, 2003, NAT REV NEUROSCI, V4, P739, DOI 10.1038/nrn1198; Dollar P, 2005, VS PETS, P65; EFROS AA, 2003, P IEEE INT C COMP VI, P726; ESCOBAR MJ, 2008, LECT NOTES COMPUTER; ESCOBAR MJ, 2006, P 3 LAT AM ROB S; Felleman DJ, 1991, CEREB CORTEX, V1, P1, DOI 10.1093/cercor/1.1.1; Fellous JM, 2004, J NEUROSCI, V24, P2989, DOI 10.1523/JNEUROSCI.4649-03.2004; Fries P, 2001, NAT NEUROSCI, V4, P194, DOI 10.1038/84032; Gautrais J, 1998, BIOSYSTEMS, V48, P57, DOI 10.1016/S0303-2647(98)00050-1; GAVRILA D, 1996, P INT C COMP VIS PAT; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; GERSTNER, 2002, SPIKING NEURON MODEL; Giese MA, 2003, NAT REV NEUROSCI, V4, P179, DOI 10.1038/nrn1057; Gollisch T, 2008, SCIENCE, V319, P1108, DOI 10.1126/science.1149639; GONCALVES L, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P764, DOI 10.1109/ICCV.1995.466861; GRZYWACZ NM, 1990, PROC R SOC SER B-BIO, V239, P129, DOI 10.1098/rspb.1990.0012; Hiris E, 2005, PERCEPT PSYCHOPHYS, V67, P435, DOI 10.3758/BF03193322; HOGG D, 1983, IMAGE VISION COMPUT, V1, P5, DOI DOI 10.1016/0262-8856(83)90003-3; HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837; Izhikevich EM, 2004, IEEE T NEURAL NETWOR, V15, P1063, DOI 10.1109/TNN.2004.832719; Jhuang H, 2007, IEEE I CONF COMP VIS, P1253; Kreuz T, 2007, J NEUROSCI METH, V165, P151, DOI 10.1016/j.jneumeth.2007.05.031; Laptev I, 2007, COMPUT VIS IMAGE UND, V108, P207, DOI 10.1016/j.cviu.2006.11.023; Lui LL, 2007, J NEUROPHYSIOL, V97, P1135, DOI 10.1152/jn.01018.2006; Maldonado P, 2008, J NEUROPHYSIOL, V100, P1523, DOI 10.1152/jn.00076.2008; Mestre DR, 2001, VISION RES, V41, P2697, DOI 10.1016/S0042-6989(01)00162-6; Michels L, 2005, NEUROREPORT, V16, P1037, DOI 10.1097/00001756-200507130-00002; Mokhber A, 2008, PATTERN RECOGN LETT, V29, P81, DOI 10.1016/j.patrec.2007.08.016; Mutch J, 2006, P IEEE C COMP VIS PA, P11, DOI [10.1109/CVPR.2006.200, DOI 10.1109/CVPR.2006.200]; Neuenschwander S, 1999, VISION RES, V39, P2485, DOI 10.1016/S0042-6989(99)00042-5; Niebles J-C, 2006, BRIT MACH VIS C; Nowak LG, 1997, CEREBR CORT, V12, P205; NOWLAN SJ, 1995, J NEUROSCI, V15, P1195; Pack CC, 2005, J NEUROPHYSIOL, V93, P1809, DOI 10.1152/jn.00629.2004; Perge JA, 2005, J NEUROPHYSIOL, V93, P2104, DOI 10.1152/jn.00601.2004; Perkel D.H., 1968, NEUROSCI RES PROGRAM, V6, P221; Pinto N, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.0040027; Polana R, 1997, INT J COMPUT VISION, V23, P261, DOI 10.1023/A:1007975200487; Riehle A, 1997, SCIENCE, V278, P1950, DOI 10.1126/science.278.5345.1950; Rieke F., 1997, SPIKES EXPLORING NEU; ROBSON JG, 1966, J OPT SOC AM, V56, P1141, DOI 10.1364/JOSA.56.001141; Roelfsema PR, 2004, NAT NEUROSCI, V7, P982, DOI 10.1038/nn1304; ROHR K, 1994, CVGIP-IMAG UNDERSTAN, V59, P94, DOI 10.1006/ciun.1994.1006; Rust NC, 2006, NAT NEUROSCI, V9, P1421, DOI 10.1038/nn1786; Saul AB, 2005, J NEUROPHYSIOL, V94, P282, DOI 10.1152/jn.00868.2004; Seitz SM, 1997, INT J COMPUT VISION, V25, P231, DOI 10.1023/A:1007928103394; Sereno ME, 1999, J EXP PSYCHOL HUMAN, V25, P1834; Serre T, 2005, PROC CVPR IEEE, P994; Serre T., 2006, THESIS MIT CAMBRIDGE; SHAH M, 1997, MOTION BASED RECOGNI; Sigala R, 2005, LECT NOTES COMPUT SC, V3696, P241, DOI 10.1007/11550822_39; Simoncelli EP, 1998, VISION RES, V38, P743, DOI 10.1016/S0042-6989(97)00183-1; Smith MA, 2005, NAT NEUROSCI, V8, P220, DOI 10.1038/nn1382; SNOWDEN RJ, 1991, J NEUROSCI, V11, P2768; Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0; Thorpe S, 2002, LECT NOTES COMPUT SC, V2525, P1; THORPE SJ, 1990, PARALLEL PROCESSING IN NEURAL SYSTEMS AND COMPUTERS, P91; Topsoe F, 2000, IEEE T INFORM THEORY, V46, P1602, DOI 10.1109/18.850703; Tsotsos JK, 2005, COMPUT VIS IMAGE UND, V100, P3, DOI 10.1016/j.cviu.2004.10.011; VanRullen R, 2002, VISION RES, V42, P2593, DOI 10.1016/S0042-6989(02)00298-5; Victor JD, 1996, J NEUROPHYSIOL, V76, P1310, DOI 10.1152/jn.1996.76.2.1310; WANG DL, 1995, IEEE T NEURAL NETWOR, V6, P283, DOI 10.1109/72.363423; WANG L, 2007, P CVPR; Watson A.B, 1983, LOOK MOTION FREQUENC; Wielaard DJ, 2001, J NEUROSCI, V21, P5203, DOI 10.1523/JNEUROSCI.21-14-05203.2001; Wohrer A, 2009, J COMPUT NEUROSCI, V26, P219, DOI 10.1007/s10827-008-0108-4; Wong S, 2007, 2007 INTERNATIONAL SYMPOSIUM ON VLSI TECHNOLOGY, SYSTEMS AND APPLICATIONS (VLSI-TSA), PROCEEDINGS OF TECHNICAL PAPERS, P66; XIAO DK, 1995, P NATL ACAD SCI USA, V92, P11303, DOI 10.1073/pnas.92.24.11303; Xiao DK, 1997, CEREB CORTEX, V7, P662, DOI 10.1093/cercor/7.7.662; Zelnik-Manor L, 2001, PROC CVPR IEEE, P123	89	48	50	0	12	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2009	82	3					284	301		10.1007/s11263-008-0201-1	http://dx.doi.org/10.1007/s11263-008-0201-1			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	411TF					2022-12-18	WOS:000263672800004
J	Ikizler, N; Forsyth, DA				Ikizler, Nazli; Forsyth, David A.			Searching for complex human activities with no visual examples	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						human action recognition; video retrieval; activity; HMM; motion capture	HUMAN MOVEMENT; RECOGNITION; MOTION; MODELS; REPRESENTATION	We describe a method of representing human activities that allows a collection of motions to be queried without examples, using a simple and effective query language. Our approach is based on units of activity at segments of the body, that can be composed across space and across the body to produce complex queries. The presence of search units is inferred automatically by tracking the body, lifting the tracks to 3D and comparing to models trained using motion capture data. Our models of short time scale limb behaviour are built using labelled motion capture set. We show results for a large range of queries applied to a collection of complex motion and activity. We compare with discriminative methods applied to tracker data; our method offers significantly improved performance. We show experimental evidence that our method is robust to view direction and is unaffected by some important changes of clothing.	[Ikizler, Nazli] Bilkent Univ, TR-06800 Ankara, Turkey; [Forsyth, David A.] Univ Illinois, Urbana, IL 61801 USA	Ihsan Dogramaci Bilkent University; University of Illinois System; University of Illinois Urbana-Champaign	Ikizler, N (corresponding author), Bilkent Univ, TR-06800 Ankara, Turkey.	inazli@cs.bilkent.edu.tr	Ikizler-Cinbis, Nazli/E-8961-2013					Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744; ALLEN JF, 1984, ARTIF INTELL, V23, P123, DOI 10.1016/0004-3702(84)90008-0; Ando RK, 2005, J MACH LEARN RES, V6, P1817; ARIKAN O, 2002, P 29 ANN C COMP GRAP, P483; ARIKAN O, 2003, P SIGGRAPH 2003; Barbic J, 2004, PROC GRAPH INTERF, P185; Ben-Arie J, 2002, IEEE T PATTERN ANAL, V24, P1091, DOI 10.1109/TPAMI.2002.1023805; Blank M, 2005, IEEE I CONF COMP VIS, P1395; Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878; Bobick AF, 1997, PHILOS T ROY SOC B, V352, P1257, DOI 10.1098/rstb.1997.0108; Bobick AF, 1997, IEEE T PATTERN ANAL, V19, P1325, DOI 10.1109/34.643892; Bobick AF, 1998, PROC CVPR IEEE, P196, DOI 10.1109/CVPR.1998.698609; Brand M, 2000, IEEE T PATTERN ANAL, V22, P844, DOI 10.1109/34.868685; Brand M, 1997, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.1997.609450; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Del Vecchio D, 2003, AUTOMATICA, V39, P2085, DOI 10.1016/S0005-1098(03)00250-4; DOLLAR P, 2005, VS PETS OCT; Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726; EVGENIOU T, 2004, 17 SIGKDD C KNOWL DI; Farhadi A., 2007, IEEE C COMP VIS PATT; Feng XL, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P717, DOI 10.1109/TDPVT.2002.1024148; Fod A, 2002, AUTON ROBOT, V12, P39, DOI 10.1023/A:1013254724861; FORSYTH D, 2006, FDN TRENDS COMPUTER, V1, P1; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; Hong P., 2000, P 4 IEEE INT C AUT F, P410; Hongeng S, 2004, COMPUT VIS IMAGE UND, V96, P129, DOI 10.1016/j.cviu.2004.02.005; HOWE NR, 2000, P NEUR INF PROC SYST, P820; HOWE NR, 2004, IEEE WORKSH ART NONR, P15; Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274; IKEMOTO L, 2007, ACM S INT 3D GRAPH G; IKIZLER N, 2007, IEEE C COMP VIS PATT; Jenkins O. C., 2004, P 21 INT C MACH LEAR, P56, DOI DOI 10.1145/1015330; Jenkins O. C., 2003, P 2 INT JOINT C AUT, P225; Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605; Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378; LEE J, 2002, P SIGGRAPH 2002; Li Y, 2002, ACM T GRAPHIC, V21, P465; Mataric M. J., 1999, Autonomous Agents and Multi-Agent Systems, V2, P23, DOI 10.1023/A:1010023022632; Mataric M. J., 1998, Proceedings of the Second International Conference on Autonomous Agents, P317, DOI 10.1145/280765.280849; Mori T, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P779, DOI 10.1109/AFGR.2004.1301629; NIEBLES JC, 2006, BRIT MACH VIS C 2006; Oliver N, 2004, COMPUT VIS IMAGE UND, V96, P163, DOI 10.1016/j.cviu.2004.02.004; PINHANEZ C, 1997, DARPA IU WORKSH, P227; Pinhanez CS, 1998, PROC CVPR IEEE, P898, DOI 10.1109/CVPR.1998.698711; Polana R., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P2, DOI 10.1109/CVPR.1993.341009; Rabiner L., 1993, FUNDAMENTALS SPEECH; Ramanan D, 2005, PROC CVPR IEEE, P271; Ramanan D., 2003, P NEUR INF PROC SYST; Ramanan D, 2007, IEEE T PATTERN ANAL, V29, P65, DOI 10.1109/TPAMI.2007.250600; RELZENSZWALB P, 2005, INT J COMPUT VISION, V61, P55; Ren L, 2005, ACM T GRAPHIC, V24, P1090, DOI 10.1145/1073204.1073316; Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559; RYOO MS, 2007, IEEE C COMP VIS PATT; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Siskind JM, 2003, ARTIF INTELL, V151, P91, DOI 10.1016/S0004-3702(03)00112-7; Sminchisescu C, 2005, IEEE I CONF COMP VIS, P1808; Sminchisescu C, 2005, PROC CVPR IEEE, P390; Wilson AD, 1999, IEEE T PATTERN ANAL, V21, P884, DOI 10.1109/34.790429; WILSON AR, 1995, MATER SCI FORUM, V189-9, P229, DOI 10.4028/www.scientific.net/MSF.189-190.229; Wong S.F., 2007, IEEE C COMP VIS PATT; Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161; Yang J, 1997, IEEE T SYST MAN CY A, V27, P34, DOI 10.1109/3468.553220; Zhao T, 2004, IEEE T PATTERN ANAL, V26, P1208, DOI 10.1109/TPAMI.2004.73	63	48	50	0	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	2008	80	3					337	357		10.1007/s11263-008-0142-8	http://dx.doi.org/10.1007/s11263-008-0142-8			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	350RJ		Green Submitted			2022-12-18	WOS:000259370500004
J	Kahl, F; Henrion, D				Kahl, Fredrik; Henrion, Didier			Globally optimal estimates for geometric reconstruction problems	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	10th IEEE International Conference on Computer Vision (ICCV 2005)	OCT 17-20, 2005	Beijing, PEOPLES R CHINA	IEEE, IEEE Comp Soc, Microsoft, intel, OMRON, SIEMENS, Mitsubishi Elect, Sarnoff Corp, Point Grey Res		non-convex optimization; structure from motion; triangulation; LMI relaxations; global optimization semidefinite programming	OPTIMIZATION; POLYNOMIALS; RELAXATIONS; SQUARES; MATRIX; MATLAB; MOTION	We introduce a framework for computing statistically optimal estimates of geometric reconstruction problems. While traditional algorithms often suffer from either local minima or non-optimality-or a combination of both-we pursue the goal of achieving global solutions of the statistically optimal cost-function. Our approach is based on a hierarchy of convex relaxations to solve non-convex optimization problems with polynomials. These convex relaxations generate a monotone sequence of lower bounds and we show how one can detect whether the global optimum is attained at a given relaxation. The technique is applied to a number of classical vision problems: triangulation, camera pose, homography estimation and last, but not least, epipolar geometry estimation. Experimental validation on both synthetic and real data is provided. In practice, only a few relaxations are needed for attaining the global optimum.	Univ Calif San Diego, San Diego, CA 92103 USA; Lund Univ, Ctr Math Sci, Lund, Sweden; CNRS, LAAS, F-31077 Toulouse, France; Czech Tech Univ, Fac Elect Engn, CR-16635 Prague, Czech Republic	University of California System; University of California San Diego; Lund University; Centre National de la Recherche Scientifique (CNRS); Czech Technical University Prague	Kahl, F (corresponding author), Univ Calif San Diego, San Diego, CA 92103 USA.	fredrik@maths.lth.se; henrion@laas.fr						AGARWAL S, 2006, EUR C COMP VIS, P592; Boyd S, 2004, CONVEX OPTIMIZATION; Chesi G, 2002, IEEE T PATTERN ANAL, V24, P397, DOI 10.1109/34.990139; Fazel M, 2004, P AMER CONTR CONF, P3273; Fusiello A, 2004, IEEE T PATTERN ANAL, V26, P1633, DOI 10.1109/TPAMI.2004.125; Garulli, 2005, POSITIVE POLYNOMIALS; Hartley R, 2004, PROC CVPR IEEE, P504; Hartley R., 2004, ROBOTICA; Hartley RI, 1997, COMPUT VIS IMAGE UND, V68, P146, DOI 10.1006/cviu.1997.0547; Henrion D, 2006, IEEE T AUTOMAT CONTR, V51, P192, DOI 10.1109/TAC.2005.863494; Henrion D, 2004, IEEE CONTR SYST MAG, V24, P72, DOI 10.1109/MCS.2004.1299534; Henrion D, 2003, ACM T MATH SOFTWARE, V29, P165, DOI 10.1145/779359.779363; Jibetean D, 2006, MATH PROGRAM, V106, P93, DOI 10.1007/s10107-005-0589-0; Kahl F, 2005, IEEE I CONF COMP VIS, P1002; Kahl F, 2005, IEEE I CONF COMP VIS, P978; Kahl F, 2001, IEEE T PATTERN ANAL, V23, P418, DOI 10.1109/34.917578; KIM Y, 2004, AM CONTROL C, V3, P2015; Kolmogorov V, 2002, LECT NOTES COMPUT SC, V2352, P82; Lasserre JB, 2001, SIAM J OPTIMIZ, V11, P796, DOI 10.1137/S1052623400366802; Ma Y., 2003, INVITATION 3 D VISIO; Nister D., 2001, THESIS ROYAL I TECHN; Oliensis J, 2002, IEEE T PATTERN ANAL, V24, P1618, DOI 10.1109/TPAMI.2002.1114853; SHOR N. Z., 1998, NONDIFFERENTIABLE OP; SOATTO S, 1998, C COMP VIS PATT REC; Stewenius H, 2005, IEEE I CONF COMP VIS, P686; Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766; Szeliski R, 1997, IEEE T PATTERN ANAL, V19, P506, DOI 10.1109/34.589211; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Triggs B., 1999, VISION ALGORITHMS TH, P298; Waki H, 2006, SIAM J OPTIMIZ, V17, P218, DOI 10.1137/050623802; Zhang ZY, 1998, IEEE T PATTERN ANAL, V20, P717, DOI 10.1109/34.689302; [No title captured]	32	48	52	0	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2007	74	1					3	15		10.1007/s11263-006-0015-y	http://dx.doi.org/10.1007/s11263-006-0015-y			13	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	165PX					2022-12-18	WOS:000246318800002
J	Tai, XC; Christiansen, O; Lin, P; Skjaelaaen, I				Tai, Xue-Cheng; Christiansen, Oddvar; Lin, Ping; Skjaelaaen, Inge			Image segmentation using some piecewise constant level set methods with MBO type of projection	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						level set method; image segmentation; total variation regularization; phase field model	TOTAL VARIATION REGULARIZATION; NONLINEAR DIFFUSION; MEAN-CURVATURE; MOTION; MODEL; CLASSIFICATION; ALGORITHMS; EFFICIENT; EQUATIONS	In this work, we are trying to propose fast algorithms for Mumford-Shah image segmentation using some recently proposed piecewise constant level set methods (PCLSM). Two variants of the PCLSM will be considered in this work. The first variant, which we call the binary level set method, needs a level set function which only takes values I to identify the regions. The second variant only needs to use one piecewise constant level set function to identify arbitrary number of regions. For the Murnford-Shah image segmentation model with these new level set methods, one needs to minimize some smooth energy functionals under some constrains. A penalty method will be used to deal with the constraint. AOS (additive operator splitting) and MOS (Multiplicative operator splitting) schemes will be used to solve the Euler-Lagrange equations for the minimization problems. By doing this, we obtain some algorithms which are essentially applying the MBO scheme for Our segmentation models. Advantages and disadvantages are discussed for the proposed schemes.	Univ Bergen, Dept Math, N-5007 Bergen, Norway; Natl Univ Singapore, Dept Math, Singapore 117543, Singapore	University of Bergen; National University of Singapore	Tai, XC (corresponding author), Univ Bergen, Dept Math, Johannes Brunsgate 12, N-5007 Bergen, Norway.	Tai@mi.uib.no	tai, xuecheng/L-9821-2013	tai, xuecheng/0000-0003-3359-9104				AMBROSIO L, 1990, COMMUN PUR APPL MATH, V43, P999, DOI 10.1002/cpa.3160430805; Aubert G., 2002, APPL MATH SCI; Barash D, 2003, J MATH IMAGING VIS, V19, P33, DOI 10.1023/A:1024484920022; Barash D, 2005, APPL NUMER MATH, V52, P1, DOI 10.1016/j.apnum.2004.07.002; Chan TF, 2004, J COMPUT PHYS, V193, P40, DOI 10.1016/j.jcp.2003.08.003; CHAN WCW, 2000, P SOC PHOTO-OPT INS, V1, P2; Cremers D, 2003, PATTERN RECOGN, V36, P1929, DOI 10.1016/S0031-3203(03)00056-6; CREMERS D, 2004, LNCS, V3024, P74; Du Q, 2004, J COMPUT PHYS, V198, P450, DOI 10.1016/j.jcp.2004.01.029; ESEDOGLU S, 2004, CAM0463 UCLA DEP MAT; EVANS LC, 1992, COMMUN PUR APPL MATH, V45, P1097, DOI 10.1002/cpa.3160450903; GIBOU F, 2002, IN PRESS STANFORD TE; Glowinski R, 2003, COMPUT PHYS COMMUN, V152, P242, DOI 10.1016/S0010-4655(02)00823-8; Lie J, 2005, LECT NOTES COMPUT SC, V3459, P573; LIE J, 2004, 0431 UCLA CAM; LIE J, 2003, CAM0350 UCLA; LIONS PL, 1979, SIAM J NUMER ANAL, V16, P964, DOI 10.1137/0716071; LU T, 1992, RAIRO-MATH MODEL NUM, V26, P673; LU T, 1991, APPL MATH LETT, V4, P25, DOI 10.1016/0893-9659(91)90161-N; MARCH R, 1992, IMAGE VISION COMPUT, V10, P30, DOI 10.1016/0262-8856(92)90081-D; Marchuk G., 1990, HDB NUMER ANAL, V1, P197; MERRIMAN B, 1994, J COMPUT PHYS, V112, P334, DOI 10.1006/jcph.1994.1105; Modica L., 1977, B UNIONE MAT ITAL, V14, P285; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; RUBINSTEIN J, 1993, SIAM J APPL MATH, V53, P1669, DOI 10.1137/0153077; RUBINSTEIN J, 1989, SIAM J APPL MATH, V49, P116, DOI 10.1137/0149007; Ruuth SJ, 1998, J COMPUT PHYS, V144, P603, DOI 10.1006/jcph.1998.6025; Samson C, 2000, IEEE T PATTERN ANAL, V22, P460, DOI 10.1109/34.857003; Samson C, 2000, INT J COMPUT VISION, V40, P187, DOI 10.1023/A:1008183109594; SHEN J, 2005, CAM0516 UCLA DEP MAT; SHI Y, 2005, ICASSP 05, pK900; Song B., 2002, 0268 UCLA CAM; Steidl G, 2004, SIAM J NUMER ANAL, V42, P686, DOI 10.1137/S0036142903422429; Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076; Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190; Weickert J, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P43, DOI 10.1007/0-387-21810-6_3; Zhao HK, 1996, J COMPUT PHYS, V127, P179, DOI 10.1006/jcph.1996.0167; ZIEMER WP, 1989, WEAKLY DIFFERENTIABL	38	48	50	0	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2007	73	1					61	76		10.1007/s11263-006-9140-x	http://dx.doi.org/10.1007/s11263-006-9140-x			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	141YV					2022-12-18	WOS:000244616100003
J	Muse, P; Sur, F; Cao, F; Gousseau, Y; Morel, JM				Muse, Pablo; Sur, Frederic; Cao, Frederic; Gousseau, Yann; Morel, Jean-Michel			An a Contrario decision method for shape element recognition	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						planar shape recognition; background model; number of false alarms; meaningful matches; level lines	MODEL; INVARIANT; MATCHES; IMAGES	Shape recognition is the field of computer vision which addresses the problem of finding out whether a query shape lies or not in a shape database, up to a certain invariance. Most shape recognition methods simply sort shapes from the database along some (dis-)similarity measure to the query shape. Their main weakness is the decision stage, which should aim at giving a clear-cut answer to the question: "do these two shapes look alike?" In this article, the proposed solution consists in bounding the number of false correspondences of the query shape among the database shapes, ensuring that the obtained matches are not likely to occur "by chance". As an application, one can decide with a parameterless method whether any two digital images share some shapes or not.	ENS, CMLA, F-94235 Cachan, France; LORIA, F-54506 Vandoeuvre Les Nancy, France; CNRS, F-54506 Vandoeuvre Les Nancy, France; INRIA Rennes, IRISA, F-35042 Rennes, France; Telecom Paris, UMR 5141, Signal & Image Proc Dept, CNRS, F-75634 Paris 13, France	UDICE-French Research Universities; Universite Paris Saclay; Universite de Lorraine; Centre National de la Recherche Scientifique (CNRS); Universite de Lorraine; Centre National de la Recherche Scientifique (CNRS); IMT - Institut Mines-Telecom; Institut Polytechnique de Paris; UDICE-French Research Universities; Universite Paris Cite	Muse, P (corresponding author), ENS, CMLA, 61 Ave President Wilson, F-94235 Cachan, France.	muse@cmla.ens-cachan.fr; sur@cmla.ens-cachan.fr; fcao@irisa.fr; gousseau@tsi.enst.fr; morel@cmla.ens-cachan.fr		Sur, Frederic/0000-0001-8076-3849; Morel, Jean-Michel/0000-0002-6108-897X				Adjeroh DA, 2000, IEEE T IMAGE PROCESS, V9, P120, DOI 10.1109/83.817603; Almansa A, 2003, IEEE T PATTERN ANAL, V25, P502, DOI 10.1109/TPAMI.2003.1190575; ALVAREZ L, 1993, ARCH RATION MECH AN, V123, P199, DOI 10.1007/BF00375127; [Anonymous], 1985, PERCEPTUAL ORG VISUA; ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; ASTROM K, 1995, IEEE T PATTERN ANAL, V17, P77, DOI 10.1109/34.368148; ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663; Bellman R., 1961, ADAPTIVE CONTROL PRO; Cao F., 2004, Computing and Visualization in Science, V7, P3, DOI 10.1007/s00791-004-0123-6; Cao F, 2005, J MATH IMAGING VIS, V22, P159, DOI 10.1007/s10851-005-4888-0; CAO F, 2005, 5766 INRIA; Chapple PB, 2001, IEEE T IMAGE PROCESS, V10, P554, DOI 10.1109/83.913590; Desolneux A, 2001, J MATH IMAGING VIS, V14, P271, DOI 10.1023/A:1011290230196; Desolneux A, 2000, INT J COMPUT VISION, V40, P7, DOI 10.1023/A:1026593302236; DESOLNEUX A, 2005, COMPUTATIONAL GESTAL; Devijver PA, 1982, PATTERN RECOGNITION; FISCHLER MA, 1986, IEEE T PATTERN ANAL, V8, P100, DOI 10.1109/TPAMI.1986.4767756; Frosini P, 2001, APPL ALGEBR ENG COMM, V12, P327, DOI 10.1007/s002000100078; GOUSSEAU Y, 2003, P GRETSI 2003 PAR FR; GRIMSON WEL, 1991, IEEE T PATTERN ANAL, V13, P1201, DOI 10.1109/34.106994; KANIZSA G, 1996, GRAMMAIRE VOIR; Lamdan Y., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P335, DOI 10.1109/CVPR.1988.196257; Lindenbaum M, 1997, IEEE T PATTERN ANAL, V19, P1251, DOI 10.1109/34.632984; Lisani JL, 2003, MULTISCALE MODEL SIM, V1, P1, DOI 10.1137/S1540345902410846; LISANI JL, 2001, THESIS U PARIS 9 DAU; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Marr D., 1982, VISION; MIKOLAJCZYK K, 2005, IN PRESS IEEE PATTER; Moisan L, 2004, INT J COMPUT VISION, V57, P201, DOI 10.1023/B:VISI.0000013094.38752.54; Moisan L, 1998, IEEE T IMAGE PROCESS, V7, P411, DOI 10.1109/83.661191; Muse P., 2003, Traitement du Signal, V20, P279; MUSE P, 2003, P IEEE INT C IM PROC; MUSE P, 2004, THESIS ECOLE NORMALE; Olson CF, 1997, IEEE T IMAGE PROCESS, V6, P103, DOI 10.1109/83.552100; Olson CF, 1998, IMAGE VISION COMPUT, V16, P627, DOI 10.1016/S0262-8856(98)00083-3; Orrite C, 2004, COMPUT VIS IMAGE UND, V93, P34, DOI 10.1016/j.cviu.2003.09.005; PENNEC X, 1998, VIDERE J COMPUTER VI, V1, P58; Rothwell C.A., 1995, OBJECT RECOGNITION I; SAPIRO G, 1993, INT J COMPUT VISION, V11, P25, DOI 10.1007/BF01420591; SCHMID C, 1999, P C COMP VIS PATT RE, V2, P485; Silvey S.D., 1975, REPRINTING MONOGRAPH; SUR F, 2004, CONTARIO DECISION SH; Watson GH, 1996, OPT ENG, V35, P3159, DOI 10.1117/1.601056; Wertheimer M., 1923, SOURCE BOOK GESTALT, P71, DOI DOI 10.1007/BF00410640; Wolfson HJ, 1997, IEEE COMPUT SCI ENG, V4, P10, DOI 10.1109/99.641604; Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008; Zhu SC, 1999, IEEE T PATTERN ANAL, V21, P1170, DOI 10.1109/34.809110	47	48	49	0	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2006	69	3					295	315		10.1007/s11263-006-7546-0	http://dx.doi.org/10.1007/s11263-006-7546-0			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	067YM					2022-12-18	WOS:000239338700003
J	Unal, G; Yezzi, A; Krim, H				Unal, G; Yezzi, A; Krim, H			Information-theoretic active polygons for unsupervised texture segmentation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						region-based active contours; unsupervised segmentation; texture segmentation; polygon evolution; information theoretic measure; electrostatic regularizer	IMAGE SEGMENTATION; SHAPE; SNAKES	Curve evolution models used in image segmentation and based on image region information usually utilize simple statistics such as means and variances, hence can not account for higher order nature of the textural characteristics of image regions. In addition, the object delineation by active contour methods, results in a contour representation which still requires a substantial amount of data to be stored for subsequent multimedia applications such as visual information retrieval from databases. Polygonal approximations of the extracted continuous curves are required to reduce the amount of data since polygons are powerful approximators of shapes for use in later recognition stages such as shape matching and coding. The key contribution of this paper is the development of a new active contour model which nicely ties the desirable polygonal representation of an object directly to the image segmentation process. This model can robustly capture texture boundaries by way of higher-order statistics of the data and using an information-theoretic measure and with its nature of the ordinary differential equations. This new variational texture segmentation model, is unsupervised since no prior knowledge on the textural properties of image regions is used. Another contribution in this sequel is a new polygon regularizer algorithm which uses electrostatics principles. This is a global regularizer and is more consistent than a local polygon regularization in preserving local features such as corners.	Siemens Corp Res, Princeton, NJ 08540 USA; Georgia tech, Sch ECE, Atlanta, GA 30332 USA; N Carolina State Univ, Dept ECE, Raleigh, NC 27695 USA	Siemens AG; University System of Georgia; Georgia Institute of Technology; University of North Carolina; North Carolina State University	Unal, G (corresponding author), Siemens Corp Res, Princeton, NJ 08540 USA.	gozde.unal@siemens.com; ayezzi@ece.gatech.edu; ahk@eos.ncsu.edu	Yezzi, Anthony/AAB-4235-2020; Unal, Gozde/A-2360-2013	Unal, Gozde/0000-0001-5942-8966				BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; Blake A., 1998, ACTIVE CONTOURS, DOI [10.1007/978-1-4471-1555-7, DOI 10.1007/978-1-4471-1555-7]; Bruckstein AM, 1995, INT J PATTERN RECOGN, V9, P991, DOI 10.1142/S0218001495000407; CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685; CASELLES V, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P694, DOI 10.1109/ICCV.1995.466871; Chan T, 1999, LECT NOTES COMPUT SC, V1682, P141; CHAN T, 2001, P IEEE WORKSH VAR LE; Chesnaud C, 1999, IEEE T PATTERN ANAL, V21, P1145, DOI 10.1109/34.809108; Cover T.M., 2006, ELEMENTS INFORM THEO, DOI [10.1002/047174882X, DOI 10.1002/047174882X]; Cremers D, 2002, INT J COMPUT VISION, V50, P295, DOI 10.1023/A:1020826424915; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; DUNHAM JG, 1986, IEEE T PATTERN ANAL, V8, P67, DOI 10.1109/TPAMI.1986.4767753; Figueiredo MAT, 2000, IEEE T IMAGE PROCESS, V9, P1075, DOI 10.1109/83.846249; FREEMAN H, 1978, PATTERN RECOGN, V10, P159, DOI 10.1016/0031-3203(78)90024-9; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Gomez-Lopera JF, 2000, J MATH IMAGING VIS, V13, P35, DOI 10.1023/A:1008325607354; Grenander U, 2001, IEEE T PATTERN ANAL, V23, P424, DOI 10.1109/34.917579; He Y, 2003, IEEE T SIGNAL PROCES, V51, P1211, DOI 10.1109/TSP.2003.810305; Hyvarinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5; HYVARINEN A, 1997, NEW APPROXIMATIONS D; IMAI H, 1986, COMPUT VISION GRAPH, V36, P31, DOI 10.1016/S0734-189X(86)80027-5; JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S; Jaynes E.T., 1963, STAT PHYS, P181; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kendall M., 1958, ADV THEORY STAT; KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855; KOCH MW, 1987, IEEE T PATTERN ANAL, V9, P483, DOI 10.1109/TPAMI.1987.4767936; KUROZUMI Y, 1982, COMPUT VISION GRAPH, V19, P248, DOI 10.1016/0146-664X(82)90011-9; LECLERC YG, 1989, INT J COMPUT VISION, V3, P73, DOI 10.1007/BF00054839; LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; MANJUNATH BS, 1991, IEEE T PATTERN ANAL, V13, P478, DOI 10.1109/34.134046; MUMFORD D., 1985, P IEEE C COMP VIS PA; OConnell KJ, 1997, IEEE T CIRC SYST VID, V7, P251, DOI 10.1109/76.554440; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068; RONFARD R, 1994, INT J COMPUT VISION, V13, P229, DOI 10.1007/BF01427153; Sethian J. A., 1999, LEVEL SET METHODS FA; Siddiqi K, 1998, IEEE T IMAGE PROCESS, V7, P433, DOI 10.1109/83.661193; SIMONCELLI EP, 1992, IEEE T INFORM THEORY, V38, P587, DOI 10.1109/18.119725; Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033; Ulaby F., 1997, FUNDAMENTALS APPL EL; UNAL G, 2002, IEEE 1 INT C 3D DAT; Yezzi A, 2002, J VIS COMMUN IMAGE R, V13, P195, DOI 10.1006/jvci.2001.0500; Yezzi A.  Jr., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P898, DOI 10.1109/ICCV.1999.790317; Yun BJ, 2001, ELECTRON LETT, V37, P754, DOI 10.1049/el:20010531; Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	50	48	48	0	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY-JUN	2005	62	3					199	220		10.1007/s11263-005-4880-6	http://dx.doi.org/10.1007/s11263-005-4880-6			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	906ME		Green Submitted			2022-12-18	WOS:000227645500001
J	Cula, OG; Dana, KJ; Murphy, FP; Rao, BK				Cula, OG; Dana, KJ; Murphy, FP; Rao, BK			Skin texture modeling	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						texture; 3D texture; bidirectional texture; skin texture; bidirectional texture function; BTF; bidirectional feature histogram; texton; image texton; symbolic texture primitive	RECOGNITION; CLASSIFICATION; REFLECTANCE	Quantitative characterization of skin appearance is an important but difficult task. The skin surface is a detailed landscape, with complex geometry and local optical properties. In addition, skin features depend on many variables such as body location (e.g. forehead, cheek), subject parameters (age, gender) and imaging parameters (lighting. camera). As with many real world surfaces, skin appearance is strongly affected by the direction from which it is viewed and illuminated. Computational modeling of skin texture has potential uses in many applications including realistic rendering for computer graphics, robust face models for computer vision, computer-assisted diagnosis for dermatology, topical drug efficacy testing for the pharmaceutical industry and quantitative comparison for consumer products. In this work we present models and measurements of skin texture with an emphasis on faces. We develop two models for use in skin texture recognition. Both models are image-based representations of skin appearance that are suitably descriptive without the need for prohibitively complex physics-based skin models. Our models take into account the varied appearance of the skin with changes in illumination and viewing direction. We also present a new face texture database comprised of more than 2400 images corresponding to 20 human faces, 4 locations on each face (forehead, cheek, chin and nose) and 32 combinations of imaging angles. The complete database is made publicly available for further research.	Rutgers State Univ, Dept Elect & Comp Engn, Dept Comp Sci, Piscataway, NJ 08855 USA; Univ Med & Dent New Jersey, Dept Dermatol, New Brunswick, NJ USA	Rutgers State University New Brunswick; Rutgers State University New Brunswick; Rutgers State University Medical Center	Cula, OG (corresponding author), Rutgers State Univ, Dept Elect & Comp Engn, Dept Comp Sci, POB 909, Piscataway, NJ 08855 USA.	oanacula@caip.rutgers.edu						Aksoy S., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P63, DOI 10.1109/CVPR.1999.786918; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Boissieux L, 2000, SPRING COMP SCI, P15; BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384; CHANTLER MJ, 1995, IEE P-VIS IMAGE SIGN, V142, P199, DOI 10.1049/ip-vis:19952065; Cula OG, 2004, INT J COMPUT VISION, V59, P33, DOI 10.1023/B:VISI.0000020670.05764.55; Cula OG, 2001, PROC CVPR IEEE, P1041; Cula OG, 2001, PROC SPIE, V4299, P209, DOI 10.1117/12.429492; CULA OG, 2002, P TEXT 2002 2 INT WO, P35; Dana K. J., 1999, IEEE Workshop on the Integration of Appearance and Geometric Methods in Object Recognition, P46; Dana KJ, 1998, PROC CVPR IEEE, P618, DOI 10.1109/CVPR.1998.698669; Dana KJ, 1997, PROC CVPR IEEE, P151, DOI 10.1109/CVPR.1997.609313; Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778; DECARLO D, 1998, P SIGGRAPH 98, P67, DOI DOI 10.1145/280814.280823; DONG J, 2002, P TEXT 2002 2 INT WO, P41; Guenin BM, 1998, P IEEE SEMICOND THER, P55, DOI 10.1109/STHERM.1998.660387; Ishii T., 1993, Communicating with Virtual Worlds, P139; JAIN A, 1997, IEEE T PATTERN ANAL, V21, P348; JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0; Koenderink JJ, 1999, INT J COMPUT VISION, V31, P129, DOI 10.1023/A:1008061730969; Koenig BE, 1996, TRANSPORT RES C-EMER, V4, P13, DOI 10.1016/0968-090X(95)00020-J; Lee Y., 1995, P 22 ANN C COMP GRAP, P55, DOI [10.1145/218380.218407, DOI 10.1145/218380.218407]; Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638; LEUNG T, 1999, INT C COMP VIS, V2, P1010; Liu XG, 2001, COMP GRAPH, P97; Ma WY, 1996, PROC CVPR IEEE, P425, DOI 10.1109/CVPR.1996.517107; McGunnigle G, 2000, PATTERN RECOGN LETT, V21, P593, DOI 10.1016/S0167-8655(00)00024-6; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Nahas M., 1990, Visual Computer, V6, P337, DOI 10.1007/BF01901020; PENIRSCHKE A, 2002, P TEXT 2002 2 INT WO, P103; Pont SC, 2002, LECT NOTES COMPUT SC, V2353, P808; PUZICHA J, 1999, INT C COMP VIS, V2, P602; Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261; Suen PH, 2000, IEEE T PATTERN ANAL, V22, P491, DOI 10.1109/34.857005; Suen PH, 1998, PROC CVPR IEEE, P753, DOI 10.1109/CVPR.1998.698688; Van Ginneken B, 1999, INT J COMPUT VISION, V31, P169, DOI 10.1023/A:1008018015948; Varma M, 2002, LECT NOTES COMPUT SC, V2352, P255; Zalesny A, 2001, PROC CVPR IEEE, P615	38	48	50	5	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR-MAY	2005	62	1-2					97	119						23	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	866XV					2022-12-18	WOS:000224807600007
J	Ong, EP; Spann, M				Ong, EP; Spann, M			Robust optical flow computation based on least-median-of-squares regression	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						least-median-or-squares robust regression; optical flow estimation; affine motion model; motion discontinuity detection; image sequence analysis	MOTION ESTIMATION; IMAGE SEQUENCES; SEGMENTATION; FIELDS	An optical flow estimation technique is presented which is based on the least-median-of-squares (LMedS) robust regression algorithm enabling more accurate flow estimates to be computed in the vicinity of motion discontinuities. The how is computed in a blockwise fashion using an affine model. Through the use of overlapping blocks coupled with a block shifting strategy, redundancy is introduced into the computation of the flow. This eliminates blocking effects common in most other techniques based on blockwise processing and also allows flow to be accurately computed in regions containing three distinct motions. A multiresolution Version of the technique is also presented, again based on LMedS regression, which enables image sequences containing large motions to be effectively handled. An extensive set of quantitative comparisons with a wide range of previously published methods are carried out using synthetic, realistic (computer generated images of natural scenes with known flow) and natural images. Both angular and absolute flow errors are calculated for those sequences with known optical how. Displaced frame difference error, used extensively in video compression, is used for those natural scenes with unknown flow. In all of the sequences tested, a comparison with those methods that result in a dense flow field (greater than 80% spatial coverage), show that the LMedS technique produces the least error irrespective of the error measure used.	Inst Microelect, Singapore 117685, Singapore; Univ Birmingham, Sch Elect & Elect Engn, Birmingham B15 2TT, W Midlands, England	University of Birmingham	Ong, EP (corresponding author), Inst Microelect, 11 Sci Pk Rd,Sci Pk 2, Singapore 117685, Singapore.	eeping@ime.org.sg; M.Spann@bham.ac.uk		Ong, Ee Ping/0000-0002-9239-8399				ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167; BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; BIGUN J, 1991, IEEE T PATTERN ANAL, V13, P775, DOI 10.1109/34.85668; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148; BOBER M, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P947, DOI 10.1109/CVPR.1994.323931; CAMPANI M, 1992, CVGIP-IMAG UNDERSTAN, V56, P90, DOI 10.1016/1049-9660(92)90088-K; DARRELL T, 1995, IEEE T PATTERN ANAL, V17, P474, DOI 10.1109/34.391395; Draper N.R., 1998, APPL REGRESSION ANAL; FENNEMA CL, 1979, COMPUT VISION GRAPH, V9, P301, DOI 10.1016/0146-664X(79)90097-2; FLEET DJ, 1992, INT J COMPUT VISION, V5, P77; Heitz F., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P378, DOI 10.1109/ICPR.1990.118132; HEITZ F, 1993, IEEE T PATTERN ANAL, V15, P1217, DOI 10.1109/34.250841; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HUANG Y, 1995, IEEE T PATTERN ANAL, V17, P1177, DOI 10.1109/34.476510; KONRAD J, 1992, IEEE T PATTERN ANAL, V14, P910, DOI 10.1109/34.161350; LIN T, 1994, P VIS INT 94 BANFF N, P73; Lucas B.D., 1981, ITERATIVE IMAGE REGI, P674; MEYER FG, 1994, CVGIP-IMAG UNDERSTAN, V60, P119, DOI 10.1006/ciun.1994.1042; MURRAY DW, 1987, IEEE T PATTERN ANAL, V9, P220, DOI 10.1109/TPAMI.1987.4767896; NEGAHDARIPOUR S, 1992, INT J COMPUT VISION, V9, P163, DOI 10.1007/BF00133700; ODOBEZ JM, 1994, P 7 EUR C SIGN PROC; ODOBEZ JM, 1994, 788 IRISA; Ong EP, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P573; ONG EP, 1996, P IEEE INT C AC SPEE, P1939; OTTE M, 1994, P 3 EUR C COMP VIS S, P51; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; SCHUNCK BG, 1989, IEEE T PATTERN ANAL, V11, P1010, DOI 10.1109/34.42834; TORR PHS, 1994, P BRIT MACH VIS C, V2, P145; WEBER J, 1995, INT J COMPUT VISION, V14, P67, DOI 10.1007/BF01421489; ZHANG J, 1995, IEEE T IMAGE PROCESS, V4, P19, DOI 10.1109/83.350816	33	48	49	0	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	FEB	1999	31	1					51	82		10.1023/A:1008046826441	http://dx.doi.org/10.1023/A:1008046826441			32	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	186GM					2022-12-18	WOS:000079720600003
J	Wada, T; Ukida, H; Matsuyama, T				Wada, T; Ukida, H; Matsuyama, T			Shape from shading with interreflections under a proximal light source: Distortion-free copying of an unfolded book	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	5th International Conference on Computer Vision	JUN 20-23, 1995	MIT, CAMBRIDGE, MA	IEEE Comp Soc Tech Comm Pattern Anal & Machine Intelligence	MIT			We address the problem of recovering the 3D shape of an unfolded book surface from the shading information in a scanner image. This shape-from-shading problem in a real world environment is made difficult by a proximal, moving light source, interreflections, specular reflections, and a nonuniform albedo distribution. Taking all these factors into account, we formulate the problem as an iterative, non-linear optimization problem. Piecewise polynomial models of the 3D shape and albedo distribution are introduced to efficiently and stably compute the shape in practice. Finally, we propose a method to restore the distorted scanner image based on the reconstructed 3D shape. The image restoration experiments for real book surfaces demonstrate that much of the geometric and photometric distortions are removed by our method.			Wada, T (corresponding author), OKAYAMA UNIV,FAC ENGN,DEPT INFORMAT TECHNOL,3-1-1 TSUSHIMA NAKA,OKAYAMA 700,JAPAN.							ASADA M, 1987, P 1 ICCV JUN, P412; BALLARD HD, 1982, COMPUTER VISION, P93; Horn Berthold K. P., 1975, PSYCHOL COMPUTER VIS, P115; IKEUCHI K, 1982, T IECE JAPAN D, V65, P842; NAYAR SK, 1990, INT C COMP VIS ICCV, P2; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Tikhonov A., 1977, SOLUTIONS ILL POSED; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479	8	48	53	0	3	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	1997	24	2					125	135		10.1023/A:1007906904009	http://dx.doi.org/10.1023/A:1007906904009			11	Computer Science, Artificial Intelligence	Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	XW658					2022-12-18	WOS:A1997XW65800003
J	Soatto, S; Perona, P				Soatto, S; Perona, P			Recursive 3-D visual motion estimation using subspace constraints	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						dynamic vision; recursive rigid motion estimation; nonlinear identification; implicit Extended Kalman Filter		The 3-D motion of a camera within a static environment produces a sequence of time-varying images that can be used for reconstructing the relative motion between the scene and the viewer. The problem of reconstructing rigid motion from a sequence of perspective images may be characterized as the estimation of the state of a nonlinear dynamical system, which is defined by the rigidity constraint and the perspective measurement map. The time-derivative of the measured output of such a system, which is called the ''2-D motion field'' and is approximated by the ''optical flow'', is bilinear in the motion parameters, and may be used to specify a subspace constraint on the direction of heading independent of rotation and depth, and a pseudo-measurement for the rotational velocity as a function of the estimated heading. The subspace constraint may be viewed as an implicit dynamical model with parameters on a differentiable manifold, and the visual motion estimation problem may be cast in a system-theoretic framework as the identification of such an implicit model. We use techniques which pertain to nonlinear estimation and identification theory to recursively estimate 3-D rigid motion from a sequence of images independent of the structure of the scene. Such independence from scene-structure allows us to deal with a variable number of visible feature-points and occlusions in a principled way. The further decoupling of the direction of heading from the rotational velocity generates a filter with a state that belongs to a two-dimensional and highly constrained state-space. As a result, the filter exhibits robustness properties which are highlighted in a series of experiments on real and noisy synthetic image sequences. While the position of feature-points is not part of the state of the model, the innovation process of the filter describes how each feature is compatible with a rigid motion interpretation, which allows us to test for outliers and makes the filter robust with respect to errors in the feature tracking/optical flow, reflections, T-junctions. Once motion has been estimated, the 3-D structure of the scene follows easily. By releasing the constraint that the visible points lie in front of the viewer, one may explain some psychophysical effects on the nonrigid percept of rigidly moving objects.	CALTECH,PASADENA,CA 91125; UNIV PADUA,DIPARTIMENTO ELETTR & INFORMAT,PADUA,ITALY	California Institute of Technology; University of Padua								Adiv G., 1985, IEEE T PATTERN ANAL; [Anonymous], 1991, EXTERIOR DIFFERENTIA; AZARBAYEJANI A, 1993, P IEEE C COMP VIS PA; BOUGUET JY, 1995, P 5 IEEE INT C COMP; BROIDA T, 1986, IEEE T PAMI; BUCY RS, 1965, IEEE T AUTOMAT CONTR, VAC10, P198, DOI 10.1109/TAC.1965.1098109; DICKMANNS ED, 1994, SIGNAL PROCESS, V35, P305, DOI 10.1016/0165-1684(94)90219-4; GENNERY DB, 1992, INT J COMPUT VISION, V7, P243, DOI 10.1007/BF00126395; GIBSON EJ, 1959, J EXP PSYCH, V45; HEEGER D, 1992, INT J COMPUTER VISIO, V7; HEEL J, 1990, 1190 AI MIT; Helmholtz H. V., 1860, TREATISE PHYSL OPTIC; HORN BKP, 1990, INT J COMPUT VISION, V4, P59, DOI 10.1007/BF00137443; Isidori A., 1989, NONLINEAR CONTROL SY; Jazwinski A.H., 1970, STOCHASTIC PROCESSES; JEPSON A, 1991, TR9035 RBCV U TOR; Kalman RE., 1960, J BASIC ENG-T ASME, V82, P35, DOI [10.1115/1.3662552, DOI 10.1115/1.3662552]; KOLB C, 1994, INVEST OPHTALMOL V S, P1275; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Lucas Bruce, 1981, IJCAI; MATTHIES L, 1989, INT J COMPUTER VISIO; MCLAUCHLAN P, 1994, P 3 ECCV; OLIENSIS J, 1992, P DARPA IMAGE UNDERS; Soatto S, 1996, IEEE T AUTOMAT CONTR, V41, P393, DOI 10.1109/9.486640; Soatto S., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P428, DOI 10.1109/CVPR.1993.341095; SOATTO S, 1994, IEEE WORKSH MOT NONR, P228; SOATTO S, 1995, P IFAC S NONL CONTR; SOATTO S, 1994, LNCS SERIES, P800; SOATTO S, 1997, IN PRESS AUTOMATICA; Soderstorm T., 1989, SYSTEM IDENTIFICATIO; YOUNG GS, 1990, IEEE T PATTERN ANAL; [No title captured]	32	48	56	0	1	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	MAR-APR	1997	22	3					235	259		10.1023/A:1007930700152	http://dx.doi.org/10.1023/A:1007930700152			25	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	XD969					2022-12-18	WOS:A1997XD96900003
J	Goswami, G; Agarwal, A; Ratha, N; Sing, R; Vatsa, M				Goswami, Gaurav; Agarwal, Akshay; Ratha, Nalini; Sing, Richa; Vatsa, Mayank			Detecting and Mitigating Adversarial Perturbations for Robust Face Recognition	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Face recognition; Deep learning; Adversarial; Dropout; Adversarial learning; Attack detection; Attack mitigation	ATTACKS	Deep neural network (DNN) architecture based models have high expressive power and learning capacity. However, they are essentially a black box method since it is not easy to mathematically formulate the functions that are learned within its many layers of representation. Realizing this, many researchers have started to design methods to exploit the drawbacks of deep learning based algorithms questioning their robustness and exposing their singularities. In this paper, we attempt to unravel three aspects related to the robustness of DNNs for face recognition: (i) assessing the impact of deep architectures for face recognition in terms of vulnerabilities to attacks, (ii) detecting the singularities by characterizing abnormal filter response behavior in the hidden layers of deep networks; and (iii) making corrections to the processing pipeline to alleviate the problem. Our experimental evaluation using multiple open-source DNN-based face recognition networks, and three publicly available face databases demonstrates that the performance of deep learning based face recognition algorithms can suffer greatly in the presence of such distortions. We also evaluate the proposed approaches on four existing quasi-imperceptible distortions: DeepFool, Universal adversarial perturbations, l2, and Elastic-Net (EAD). The proposed method is able to detect both types of attacks with very high accuracy by suitably designing a classifier using the response of the hidden layers in the network. Finally, we present effective countermeasures to mitigate the impact of adversarial attacks and improve the overall robustness of DNN-based face recognition.	[Goswami, Gaurav; Agarwal, Akshay; Sing, Richa; Vatsa, Mayank] IIT Delhi, New Delhi, India; [Ratha, Nalini] IBM Corp, TJ Watson Res Ctr, Yorktown Hts, NY USA	Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Delhi; International Business Machines (IBM)	Vatsa, M (corresponding author), IIT Delhi, New Delhi, India.	gaumvgs@iiitd.ac.in; akshaya@iiitd.ac.in; ratha@us.ibm.com; rsingh@iiitd.ac.in; mayank@iiitd.ac.in	Ratha, Nalini/AAR-6235-2020; Goswami, Gaurav/ABH-9597-2020; Vatsa, Mayank/I-5050-2013; Vatsa, Mayank/AAR-7199-2020; Agarwal, Akshay/X-8084-2019; Singh, Richa/M-9961-2017	Goswami, Gaurav/0000-0001-5607-7654; Vatsa, Mayank/0000-0001-5952-2274; Vatsa, Mayank/0000-0001-5952-2274; Singh, Richa/0000-0003-4060-4573; Agarwal, Akshay/0000-0001-7362-4752	IBM PhD Fellowship; Visvesvaraya PhD Fellowship; CAI@IIIT-Delhi; Department of Science and Technology, Government of India through Swarnajayanti Fellowship	IBM PhD Fellowship(International Business Machines (IBM)); Visvesvaraya PhD Fellowship; CAI@IIIT-Delhi; Department of Science and Technology, Government of India through Swarnajayanti Fellowship(Department of Science & Technology (India))	G. Goswami was partly supported through IBM PhD Fellowship, A. Agarwal is partly supported by Visvesvaraya PhD Fellowship, and M. Vatsa and R. Singh are partly supported through CAI@IIIT-Delhi. M.Vatsa is also partially supported through Department of Science and Technology, Government of India through Swarnajayanti Fellowship.	Addad B., 2018, ARXIV180309468; Agarwal A, 2016, IEEE I C COMP INT CO, P241; Agarwal A, 2018, INT CONF BIOMETR THE, DOI 10.1109/TUFFC.2018.2876285; Agarwal A, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P659, DOI 10.1109/BTAS.2017.8272754; Agarwal A, 2017, IEEE COMPUT SOC CONF, P275, DOI 10.1109/CVPRW.2017.40; Akbulut Y., 2017, INT ART INT DAT PROC, P1, DOI DOI 10.1109/IDAP.2017.8090202; Akhtar N., 2017, ARXIV PREPRINT ARXIV; Akhtar N, 2018, IEEE ACCESS, V6, P14410, DOI 10.1109/ACCESS.2018.2807385; Alaifari Rima, 2018, ARXIV180407729; Amos B., 2016, OPENFACE FACE RECOGN; Nguyen A, 2015, PROC CVPR IEEE, P427, DOI 10.1109/CVPR.2015.7298640; [Anonymous], 2018, NIST FACE RECOGNITIO; [Anonymous], 2017, 2017 19 INT C TRANSP, DOI [DOI 10.1109/ICTON.2017.8024849, 10.1109/ICTON.2017.8024849]; [Anonymous], 2011, MULTIPLE ENCOUNTERS; Athalye A, 2018, PR MACH LEARN RES, V80; Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; Beveridge J. R., 2013, P 6 INT C BIOMETRICS, P1; Bhagoji AN, 2017, ARXIV PREPRINT ARXIV; Bharati A, 2016, IEEE T INF FOREN SEC, V11, P1903, DOI 10.1109/TIFS.2016.2561898; Biggio B, 2017, IEEE T PATTERN ANAL, V39, P561, DOI 10.1109/TPAMI.2016.2558154; Boulkenafet Z, 2017, IEEE SIGNAL PROC LET, V24, P141, DOI 10.1109/LSP.2016.2630740; Boulkenafet Z, 2016, IEEE T INF FOREN SEC, V11, P1818, DOI 10.1109/TIFS.2016.2555286; Bousmalis Konstantinos, 2016, ADV NEURAL INFORM PR, P343; Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49; Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P90, DOI 10.1109/LSP.2014.2347419; Chen PY, 2018, AAAI CONF ARTIF INTE, P10; Chhabra S, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P656; Chingovska I, 2016, FACE RECOGNITION IMA, P165, DOI DOI 10.1007/978-3-319-28501-6_8; Cisse M, 2017, ADV NEUR IN, V30; Das Nilaksh, 2017, ARXIV PREPRINT ARXIV; de Souza GB, 2017, IEEE T CIRCUITS-II, V64, P1397, DOI 10.1109/TCSII.2017.2764460; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dziugaite G. K., 2016, ARXIV 160800853V1 CS; Feinman R., 2017, ARXIV PREPRINT ARXIV; Goel A, 2018, INT CONF BIOMETR THE; Gong Zhitao, 2017, ARXIV170404960; Goodfellow I.J., 2015, STATISTICAL, DOI DOI 10.48550/ARXIV.1412.6572; Goswami Gaurav, 2018, AAAI, V32; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Grosse Kathrin, 2017, ARXIV170206280; Gu S., 2014, ARXIV14125068; Guo Chuan, 2018, ICLR; Hinton G., 2015, ARXIV150302531; Huang GB, 2007, 07 UMASS TR; King DE, 2009, J MACH LEARN RES, V10, P1755; Kurakin Alexey, 2016, ICLR WORKSH; Laskov P, 2010, MACH LEARN, V81, P115, DOI 10.1007/s10994-010-5207-6; Lee H., 2017, GENERATIVE ADVERSARI; Li X, 2017, IEEE I CONF COMP VIS, P5775, DOI 10.1109/ICCV.2017.615; Liang Bin., 2017, ABS170508378 CORR; Liu J., 2015, ARXIV150607310; Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006; Liu M. -Y., 2016, ADV NEURAL INFORM PR, P469; Lu JJ, 2017, IEEE I CONF COMP VIS, P446, DOI 10.1109/ICCV.2017.56; Luo Y., 2015, ARXIV PREPRINT ARXIV, DOI [10.48550/arXiv.1511.06292, DOI 10.48550/ARXIV.1511.06292]; Majumdar A, 2017, IEEE T PATTERN ANAL, V39, P1273, DOI 10.1109/TPAMI.2016.2569436; Manjani I, 2017, IEEE T INF FOREN SEC, V12, P1713, DOI 10.1109/TIFS.2017.2676720; Meng DY, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P135, DOI 10.1145/3133956.3134057; Metzen J. H., 2017, 5 INT C LEARNING REP, DOI DOI 10.1109/ICCV.2017.300; Miyato Takeru, 2017, ICLR; Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888; Moosavi-Dezfooli SM, 2017, PROC CVPR IEEE, P86, DOI 10.1109/CVPR.2017.17; Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282; Nayebi Aran, 2017, ARXIV170309202; Papernot N, 2016, P IEEE S SECUR PRIV, P582, DOI 10.1109/SP.2016.41; Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36; Parkhi Omkar M., 2015, BRIT MACH VIS C; Patel K, 2015, INT CONF BIOMETR, P98, DOI 10.1109/ICB.2015.7139082; Phillips PJ, 2009, LECT NOTES COMPUT SC, V5558, P705, DOI 10.1007/978-3-642-01793-3_72; Prakash A, 2018, PROC CVPR IEEE, P8571, DOI 10.1109/CVPR.2018.00894; Radford A., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.1051/0004-6361/201527329; Raghavendra R, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON IDENTITY, SECURITY AND BEHAVIOR ANALYSIS (ISBA); Rakin Adnan Siraj, 2018, CORR; Ramachandra R, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3038924; Ranjan R., 2017, IMPROVING NETWORK RO; Ratha NK, 2001, LECT NOTES COMPUT SC, V2091, P223; Rauber Jonas, 2017, REL MACH LEARN WILD, P6, DOI DOI 10.21105/JOSS.02607; Ross Andrew Slavin, 2018, AAAI C ART INT; Rozsa A, 2019, PATTERN RECOGN LETT, V124, P100, DOI 10.1016/j.patrec.2017.10.024; Rozsa A, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P168, DOI 10.1109/BTAS.2017.8272695; Rozsa A, 2016, INT C PATT RECOG, P3121, DOI 10.1109/ICPR.2016.7900114; Rudd E. M., 2016, IEEE C COMP VIS PATT; Sabour S., 2016, INT C LEARN REPR; Samangouei Pouya, 2018, ARXIV180506605; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Sharif M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1528, DOI 10.1145/2976749.2978392; Siddiqui TA, 2016, INT C PATT RECOG, P1035, DOI 10.1109/ICPR.2016.7899772; Singh Maneet, 2019, IEEE Transactions on Biometrics, Behavior, and Identity Science, V1, P97, DOI 10.1109/TBIOM.2019.2903860; Smith DF, 2015, IEEE T INF FOREN SEC, V10, P736, DOI 10.1109/TIFS.2015.2398819; Song Y., 2018, ICLR; Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907; Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742; Szegedy Christian, 2014, P 2 INT C LEARNING R; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Tramonti F, 2019, PSYCHOL HEALTH MED, V24, P27, DOI 10.1080/13548506.2018.1510131; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032; Xie CH, 2017, IEEE I CONF COMP VIS, P1378, DOI 10.1109/ICCV.2017.153; Xie Cihang, 2018, P INT C LEARN REPR I; Xu W, 2018, 2018 INTERNATIONAL CONFERENCE ON CYBER SITUATIONAL AWARENESS, DATA ANALYTICS AND ASSESSMENT (CYBER SA); Ye S., 2018, INT C LEARN REPR WOR	102	47	49	1	14	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2019	127	6-7			SI		719	742		10.1007/s11263-019-01160-w	http://dx.doi.org/10.1007/s11263-019-01160-w			24	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	HZ0JD					2022-12-18	WOS:000468525900011
J	Katircioglu, I; Tekin, B; Salzmann, M; Lepetit, V; Fua, P				Katircioglu, Isinsu; Tekin, Bugra; Salzmann, Mathieu; Lepetit, Vincent; Fua, Pascal			Learning Latent Representations of 3D Human Pose with Deep Neural Networks	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						3D human pose estimation; Structured prediction; Deep learning		Most recent approaches to monocular 3D pose estimation rely on Deep Learning. They either train a Convolutional Neural Network to directly regress from an image to a 3D pose, which ignores the dependencies between human joints, or model these dependencies via a max-margin structured learning framework, which involves a high computational cost at inference time. In this paper, we introduce a Deep Learning regression architecture for structured prediction of 3D human pose from monocular images or 2D joint location heatmaps that relies on an overcomplete autoencoder to learn a high-dimensional latent pose representation and accounts for joint dependencies. We further propose an efficient Long Short-Term Memory network to enforce temporal consistency on 3D pose predictions. We demonstrate that our approach achieves state-of-the-art performance both in terms of structure preservation and prediction accuracy on standard 3D human pose estimation benchmarks.	[Katircioglu, Isinsu; Tekin, Bugra; Salzmann, Mathieu; Fua, Pascal] Ecole Polytech Fed Lausanne, Comp Vis Lab CVLab, CH-1015 Lausanne, Switzerland; [Lepetit, Vincent] Univ Bordeaux, LaBRI, F-33405 Talence, France	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Centre National de la Recherche Scientifique (CNRS); UDICE-French Research Universities; Universite de Bordeaux	Tekin, B (corresponding author), Ecole Polytech Fed Lausanne, Comp Vis Lab CVLab, CH-1015 Lausanne, Switzerland.	isinsu.katircioglu@epfl.ch; bugra.tekin@epfl.ch; mathieu.salzmann@epfl.ch; vincent.lepetit@u-bordeaux.fr; pascal.fua@epfl.ch		Salzmann, Mathieu/0000-0002-8347-8637				Agarwal A., 2004, CVPR; Akhter I, 2015, PROC CVPR IEEE, P1446, DOI 10.1109/CVPR.2015.7298751; Bo LF, 2010, INT J COMPUT VISION, V87, P28, DOI 10.1007/s11263-008-0204-y; Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34; Bregler C., 2014, ICLR; Burenius M, 2013, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2013.464; Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512; Chen WZ, 2016, INT CONF 3D VISION, P479, DOI 10.1109/3DV.2016.58; Chen X., 2014, P 27 ANN C NEURAL IN, P1736, DOI DOI 10.1109/CVPR.2018.00742; Cortes C., 2005, ICML; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Du M, 2012, LECT NOTES COMPUT SC, V7578, P167, DOI 10.1007/978-3-642-33786-4_13; Du Y, 2016, LECT NOTES COMPUT SC, V9908, P20, DOI 10.1007/978-3-319-46493-0_2; Elhayek A, 2015, PROC CVPR IEEE, P3810, DOI 10.1109/CVPR.2015.7299005; Fragkiadaki K, 2015, IEEE I CONF COMP VIS, P4346, DOI 10.1109/ICCV.2015.494; Gkioxari G, 2016, LECT NOTES COMPUT SC, V9908, P728, DOI 10.1007/978-3-319-46493-0_44; Glorot X., 2011, P 14 INT C ART INT S, P315; Graves A, 2005, LECT NOTES COMPUT SC, V3697, P799; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860; Ionescu C. S. Catalin, 2011, ICCV; Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248; Jain A, 2016, PROC CVPR IEEE, P5308, DOI 10.1109/CVPR.2016.573; Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494; Johnson Sam, 2010, BMVC, DOI [10.5244/C.24.12, DOI 10.5244/C.24.12]; Kingma D.P, P 3 INT C LEARNING R; Kombrink S., 2011, INTERSPEECH; Konda K., 2015, ICLR; Li S., 2016, IJCV; Li SJ, 2015, IEEE I CONF COMP VIS, P2848, DOI 10.1109/ICCV.2015.326; Li SJ, 2015, LECT NOTES COMPUT SC, V9004, P332, DOI 10.1007/978-3-319-16808-1_23; Liang M, 2015, PROC CVPR IEEE, P3367, DOI 10.1109/CVPR.2015.7298958; Mehta D, 2017, INT CONF 3D VISION, P506, DOI 10.1109/3DV.2017.00064; Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29; Oberweger M., 2015, ARXIVABS150206807; Park S., 2016, ECCV WORKSH; Pavlakos G, 2017, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2017.138; Pfister T, 2015, IEEE I CONF COMP VIS, P1913, DOI 10.1109/ICCV.2015.222; Pinheiro PO, 2014, PR MACH LEARN RES, V32; Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533; Popa Alin-Ionut, 2017, CVPR; Ramakrishna V, 2012, LECT NOTES COMPUT SC, V7575, P573, DOI 10.1007/978-3-642-33765-9_41; Rifai S., 2011, PROC INT C MACH LEAR; Rogez G, 2016, ADV NEUR IN, V29; Salzmann M., 2010, P ADV NEUR INF PROC, V23, P2065; Sanzari M, 2016, LECT NOTES COMPUT SC, V9912, P566, DOI 10.1007/978-3-319-46484-8_34; SIGAL L, 2006, CS0608 BROWN U; Simo-Serra E, 2013, PROC CVPR IEEE, P3634, DOI 10.1109/CVPR.2013.466; Sutskever Ilya, 2011, P 28 INT C MACH LEAR; Tekin B, 2016, PROC CVPR IEEE, pCP8, DOI 10.1109/CVPR.2016.113; Tekin Bugra, 2016, BRIT MACH VIS C BMVC, P2; Tome D, 2017, PROC CVPR IEEE, P5689, DOI 10.1109/CVPR.2017.603; Tompson J.J., 2014, ADV NEURAL INFORM PR, V27, P1799; Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vincent P., 2008, P 25 INT C MACH LEAR, P1096, DOI 10.1145/1390156.1390294; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511; Weinland D, 2010, LECT NOTES COMPUT SC, V6313, P635; Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741; Yasin H, 2016, PROC CVPR IEEE, P4948, DOI 10.1109/CVPR.2016.535; Zhou XW, 2016, PROC CVPR IEEE, P4966, DOI 10.1109/CVPR.2016.537; Zhou XY, 2016, LECT NOTES COMPUT SC, V9915, P186, DOI 10.1007/978-3-319-49409-8_17	65	47	47	2	16	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	2018	126	12			SI		1326	1341		10.1007/s11263-018-1066-6	http://dx.doi.org/10.1007/s11263-018-1066-6			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	GZ3KT		Green Submitted			2022-12-18	WOS:000449286200005
J	Mikulik, A; Perdoch, M; Chum, O; Matas, J				Mikulik, Andrej; Perdoch, Michal; Chum, Ondrej; Matas, Jiri			Learning Vocabularies over a Fine Quantization	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Image retrieval; Vocabulary; Feature track		A novel similarity measure for bag-of-words type large scale image retrieval is presented. The similarity function is learned in an unsupervised manner, requires no extra space over the standard bag-of-words method and is more discriminative than both L2-based soft assignment and Hamming embedding. The novel similarity function achieves mean average precision that is superior to any result published in the literature on the standard Oxford 5k, Oxford 105k and Paris datasets/protocols. We study the effect of a fine quantization and very large vocabularies (up to 64 million words) and show that the performance of specific object retrieval increases with the size of the vocabulary. This observation is in contradiction with previously published results. We further demonstrate that the large vocabularies increase the speed of the tf-idf scoring step.	[Mikulik, Andrej; Perdoch, Michal; Chum, Ondrej; Matas, Jiri] Czech Tech Univ, CMP, Dept Cybernet, Fac Elect Engn, CR-16635 Prague, Czech Republic	Czech Technical University Prague	Mikulik, A (corresponding author), Czech Tech Univ, CMP, Dept Cybernet, Fac Elect Engn, CR-16635 Prague, Czech Republic.	mikulik@cmp.felk.cvut.cz; predom1@cmp.felk.cvut.cz; chum@cmp.felk.cvut.cz; matas@cmp.felk.cvut.cz	, Matas/AAW-3282-2020; Chum, Ondrej/F-5262-2015					Agarwal S, 2009, P ICCV KYOT; Avrithis Y., 2012, P EUR C COMP VIS ECC; Baeza-Yates R, 1999, MODERN INFORM RETRIE; Cech J, 2008, P CVPR ANCH; Chum O, 2007, P ICCV RIO DE JAN; Chum O, 2009, P CVPR MIAM; Chum O, 2010, IEEE T PATTERN ANAL, V32, P371, DOI 10.1109/TPAMI.2009.166; Duda R., 1995, PATTERN CLASSIFICATI; Ferrari V, 2004, P ECCV PRAG; Fraundorfer F, 2007, P CVPR MINN; Godsil C., 2001, ALGEBRAIC GRAPH THEO; Hua G, 2007, P ICCV RIO DE JAN; Jegou H, 2008, P ECCV MARS; Jegou H, 2009, P CVPR MIAM; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Li X, 2008, P ECCV MARS; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Makadia A, 2010, FEATURE TRACKING WID; Mikolajczyk K, 2007, P ICCV RIO DE JAN; Mikulik A, 2010, LECT NOTES COMPUT SC, V6313, P1; Muja M., 2009, VISSAPP; Nister D, 2006, P CVPR NEW YORK; Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2; Perdoch M, 2009, P CVPR KYOT; Perronnin F, 2008, IEEE T PATTERN ANAL, V30, P1243, DOI 10.1109/TPAMI.2007.70755; Philbin J, 2007, P CVPR MINN; Philbin J, 2008, P CVPR ANCH; Project page, 2012, DATA BINARIES SOURCE; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Tavenard R, 2010, RR7387 INRIA	30	47	48	0	13	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2013	103	1					163	175		10.1007/s11263-012-0600-1	http://dx.doi.org/10.1007/s11263-012-0600-1			13	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	137CV					2022-12-18	WOS:000318413500007
J	Franken, E; Duits, R				Franken, Erik; Duits, Remco			Crossing-Preserving Coherence-Enhancing Diffusion on Invertible Orientation Scores	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Crossing elongated structures; Image enhancement; Orientation scores; Nonlinear diffusion; Coherence-enhancing diffusion; Euclidean motion group	STOCHASTIC COMPLETION FIELDS; EUCLIDEAN MOTION GROUP; NONLINEAR DIFFUSION; SPACE; IMAGES; SIGNAL; MODEL	Many image processing problems require the enhancement of crossing elongated structures. These problems cannot easily be solved by commonly used coherence-enhancing diffusion methods. Therefore, we propose a method for coherence-enhancing diffusion on the invertible orientation score of a 2D image. In an orientation score, the local orientation is represented by an additional third dimension, ensuring that crossing elongated structures are separated from each other. We consider orientation scores as functions on the Euclidean motion group, and use the group structure to apply left-invariant diffusion equations on orientation scores. We describe how we can calculate regularized left-invariant derivatives, and use the Hessian to estimate three descriptive local features: curvature, deviation from horizontality, and orientation confidence. These local features are used to adapt a nonlinear coherence-enhancing, crossing-preserving, diffusion equation on the orientation score. We propose two explicit finite-difference schemes to apply the nonlinear diffusion in the orientation score and provide a stability analysis. Experiments on both artificial and medical images show that preservation of crossings is the main advantage compared to standard coherence-enhancing diffusion. The use of curvature leads to improved enhancement of curves with high curvature. Furthermore, the use of deviation from horizontality makes it feasible to reduce the number of sampled orientations while still preserving crossings.	[Duits, Remco] Eindhoven Univ Technol, Dept Math & Comp Sci, NL-5600 MB Eindhoven, Netherlands; [Franken, Erik; Duits, Remco] Eindhoven Univ Technol, Dept Biomed Engn, NL-5600 MB Eindhoven, Netherlands	Eindhoven University of Technology; Eindhoven University of Technology	Duits, R (corresponding author), Eindhoven Univ Technol, Dept Math & Comp Sci, POB 513, NL-5600 MB Eindhoven, Netherlands.	e.m.franken@tue.nl; r.duits@tue.nl			Dutch BSIK [BSIK 03033]; The Netherlands Organisation for Scientific Research (NWO)	Dutch BSIK; The Netherlands Organisation for Scientific Research (NWO)(Netherlands Organization for Scientific Research (NWO))	The authors would like to thank the anonymous referees whose comments and suggestions led to a significant improvement of the presentation and organization of this paper. The project was financially supported by the Dutch BSIK program entitled Molecular Imaging of Ischemic heart disease (project number BSIK 03033). The Netherlands Organisation for Scientific Research (NWO) is gratefully acknowledged for financial support.	Antoine JP, 1999, APPL COMPUT HARMON A, V6, P314, DOI 10.1006/acha.1998.0255; Antonelli M, 1996, EUR J BIOCHEM, V241, P272, DOI 10.1111/j.1432-1033.1996.0272t.x; AUGUST J, 2001, THESIS YALE U; Candes E. J., 1999, CURVE SURFACE FITTIN; Candes EJ, 1999, PHILOS T R SOC A, V357, P2495, DOI 10.1098/rsta.1999.0444; Chen J, 2000, IEEE T PATTERN ANAL, V22, P417, DOI 10.1109/34.857000; Citti G, 2006, J MATH IMAGING VIS, V24, P307, DOI 10.1007/s10851-005-3630-2; COTTET GH, 1993, MATH COMPUT, V61, P659, DOI 10.1090/S0025-5718-1993-1195422-2; DUITS R, 2005, THESIS TU EINDHOVEN; DUITS R, 2009, Q APPL MATH; DUITS R, 2007, IMAGE PROCESSING ANA, V17, P42; Duits R., 2007, ARXIV07110951V4; Duits R., 2004, 7 INT C PATT REC IM, P193; Duits R, 2008, Q APPL MATH, V66, P27; Duits R, 2007, LECT NOTES COMPUT SC, V4485, P300; Felsberg M, 2006, IEEE T PATTERN ANAL, V28, P209, DOI 10.1109/TPAMI.2006.29; Florack L. M. J., 1993, Journal of Mathematical Imaging and Vision, V3, P327, DOI 10.1007/BF01664793; FOOLEN J, 2008, J ORTHOPAEDIC RES OF; Franken E, 2008, THESIS EINDHOVEN U T; FRANKEN EM, 2007, P 8 IEEE COMP SOC WO; Franken E, 2007, LECT NOTES COMPUT SC, V4485, P461; Franken E, 2006, LECT NOTES COMPUT SC, V4191, P25; Gerschgorin S., 1931, IZV AKAD NAUK USSR O, V1, P749; Granlund G.H., 1995, SIGNAL PROCESSING CO; HEITGER F, 1993, P 4 INT C COMP VIS, P32; Kalitzin SN, 1997, LECT NOTES COMPUT SC, V1252, P77; Kalitzin SN, 1999, INT J COMPUT VISION, V31, P145, DOI 10.1023/A:1008013815039; Manniesing R, 2005, LECT NOTES COMPUT SC, V3565, P138; Manniesing R, 2006, MED IMAGE ANAL, V10, P815, DOI 10.1016/j.media.2006.06.003; Mumford D., 1994, ALGEBRAIC GEOMETRY I, V5681, P491, DOI DOI 10.1007/978-1-4612-2628-4_31; NITZBERG M, 1992, IEEE T PATTERN ANAL, V14, P826, DOI 10.1109/34.149593; Rubbens MP, 2009, TISSUE ENG PT A, V15, P999, DOI 10.1089/ten.tea.2007.0396; Scharr H, 2006, LECT NOTES COMPUT SC, V4174, P51; Shaw CS, 2008, HISTOCHEM CELL BIOL, V129, P65, DOI 10.1007/s00418-007-0349-8; Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI 10.1117/12.408568; Tschumperle D, 2006, INT J COMPUT VISION, V68, P65, DOI 10.1007/s11263-006-5631-z; TUCH DS, 1999, P 7 ANN M ISMRM PHIL, P321; Unser M, 1999, IEEE SIGNAL PROC MAG, V16, P22, DOI 10.1109/79.799930; VANALMSICK MA, 2007, THESIS EINDHOVEN U T; VANGINKEL M, 2002, THESIS TU DELFT; WALTERS D, 1987, COMPUT VISION GRAPH, V37, P261, DOI 10.1016/S0734-189X(87)80005-1; Weickert J, 2002, J VIS COMMUN IMAGE R, V13, P103, DOI 10.1006/jvci.2001.0495; Weickert J, 1999, INT J COMPUT VISION, V31, P111, DOI 10.1023/A:1008009714131; Weickert J., 1998, ANISOTROPIC DIFFUSIO; Welk M, 2006, LECT NOTES COMPUT SC, V3951, P391; Williams LR, 1997, NEURAL COMPUT, V9, P837, DOI 10.1162/neco.1997.9.4.837; Zweck J, 2004, J MATH IMAGING VIS, V21, P135, DOI 10.1023/B:JMIV.0000035179.47895.bc	47	47	47	0	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	2009	85	3					253	278		10.1007/s11263-009-0213-5	http://dx.doi.org/10.1007/s11263-009-0213-5			26	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	502CO		Bronze, Green Submitted			2022-12-18	WOS:000270432200005
J	Stein, AN; Hebert, M				Stein, Andrew N.; Hebert, Martial			Occlusion Boundaries from Motion: Low-Level Detection and Mid-Level Reasoning	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Occlusion detection; Occlusion boundaries; Occluding contours; Edge detection; Motion	SEGMENTATION; PROPAGATION; FRAMEWORK; SURFACES; TRACKING; MODELS; IMAGES	The boundaries of objects in an image are often considered a nuisance to be "handled" due to the occlusion they exhibit. Since most, if not all, computer vision techniques aggregate information spatially within a scene, information spanning these boundaries, and therefore from different physical surfaces, is invariably and erroneously considered together. In addition, these boundaries convey important perceptual information about 3D scene structure and shape. Consequently, their identification can benefit many different computer vision pursuits, from low-level processing techniques to high-level reasoning tasks. While much focus in computer vision is placed on the processing of individual, static images, many applications actually offer video, or sequences of images, as input. The extra temporal dimension of the data allows the motion of the camera or the scene to be used in processing. In this paper, we focus on the exploitation of subtle relative-motion cues present at occlusion boundaries. When combined with more standard appearance information, we demonstrate these cues' utility in detecting occlusion boundaries locally. We also present a novel, mid-level model for reasoning more globally about object boundaries and propagating such local information to extract improved, extended boundaries.	[Stein, Andrew N.; Hebert, Martial] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Stein, AN (corresponding author), Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.	stein@ri.cmu.edu; hebert@ri.cmu.edu			National Science Foundation Graduate Fellowship [IIS-0713406]; 21st Century Frontier R&D Program of the Korean Ministry of Commerce, Industry, and Energy	National Science Foundation Graduate Fellowship(National Science Foundation (NSF)); 21st Century Frontier R&D Program of the Korean Ministry of Commerce, Industry, and Energy(Ministry of Trade, Industry & Energy (MOTIE), Republic of Korea)	Partial support provided in part by National Science Foundation Graduate Fellowship and Grant IIS-0713406, and by the 21st Century Frontier R&D Program of the Korean Ministry of Commerce, Industry, and Energy. Any opinions, findings, and conclusions or recommendations expressed in this material are solely those of the authors.	ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; Arbelaez P., 2006, COMP VIS PATT REC WO, P182, DOI DOI 10.1109/CVPRW.2006.48; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Black MJ, 2000, INT J COMPUT VISION, V38, P231, DOI 10.1023/A:1008195307933; BOUTHEMY P, 1989, IEEE T PATTERN ANAL, V11, P499, DOI 10.1109/34.24782; Brostow G. J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P8, DOI 10.1109/ICCV.1999.791190; Collins M, 2002, MACH LEARN, V48, P253, DOI 10.1023/A:1013912006537; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; DARRELL T, 1995, IEEE T PATTERN ANAL, V17, P474, DOI 10.1109/34.391395; Derpanis KG, 2005, IEEE IMAGE PROC, P2777; Dollar P., 2006, P IEEE COMP SOC C CO, V2, P1964, DOI DOI 10.1109/CVPR.2006.298; Drummond T, 2000, INT J COMPUT VISION, V37, P21, DOI 10.1023/A:1008125412549; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; FLEET DJ, 2005, MATH MODELS COMPUTER; FLEET DJ, 2002, EXPLORING ARTIFICIAL, P139; FOWLKES C, 2003, IEEE C COMP VIS PATT; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Fusiello A, 1997, PROC CVPR IEEE, P858, DOI 10.1109/CVPR.1997.609428; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GUAN L, 2007, IEEE C COMP VIS PATT; GUZMAN A, 1968, FAL AFIPS P JOINT CO, V33, P291; HEEGER DJ, 1988, INT J COMPUT VISION, V1, P270; HEITZ F, 1993, IEEE T PATTERN ANAL, V15, P1217, DOI 10.1109/34.250841; HESKES, 2003, UNCERTAINTY ARTIFICI, P313; Hirschmuller H, 2002, INT J COMPUT VISION, V47, P229, DOI 10.1023/A:1014554110407; Hoiem D, 2005, ACM T GRAPHIC, V24, P577, DOI 10.1145/1073204.1073232; Hoiem D, 2007, IEEE I CONF COMP VIS, P1229; Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y; Jepson AD, 2002, LECT NOTES COMPUT SC, V2350, P692; JOJIC N, 2001, IEEE C COMP VIS PATT, V1, P196; KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690; Ke QF, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P37, DOI 10.1109/MOTION.2002.1182211; Kumar MP, 2005, IEEE I CONF COMP VIS, P33; Kumar S, 2006, INT J COMPUT VISION, V68, P179, DOI 10.1007/s11263-006-7007-9; Lafferty J., 2001, P 18 INT C MACHINE L, P282, DOI DOI 10.5555/645530.655813; Landy M.S., 1991, COMPUTATIONAL MODELS; Lazebnik S, 2005, INT J COMPUT VISION, V63, P65, DOI 10.1007/s11263-005-4947-4; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; LEUNG T, 1998, EUR C COMP VIS ECCV; Liu C., 2006, ADV NEURAL INFORM PR; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; MacKay D. J. C., 2003, INFORM THEORY INFERE, P269; Mahamud S, 2003, IEEE T PATTERN ANAL, V25, P433, DOI 10.1109/TPAMI.2003.1190570; Malisiewicz T., 2007, BRIT MACH VIS C BMVC; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Maxwell B.A., 2003, BRIT MACH VIS C NORW, V2, P549; Mori G, 2005, IEEE I CONF COMP VIS, P1417; MORI G, 2004, IEEE C COMP VIS PATT, V2, P3226; Nestares O, 2001, PROC CVPR IEEE, P358; Ogale AS, 2005, IEEE T PATTERN ANAL, V27, P988, DOI 10.1109/TPAMI.2005.123; Pearl J., 1982, AAAI 82 P 2 AAAI C A, P133; Pearl Judea, 2014, PROBABILISTIC REASON; Ren X., 2005, ADV NEURAL INFORM PR; REN X, 2006, EUR C COMP VIS ECCV; Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10; ROSS MG, 2005, ASS ADV ARTIFICIAL I; RUSSELL BC, 2005, AIM2005025 MIT AI LA; RUZON MA, 1999, IEEE C COMP VIS PATT, P160; Sato J, 1999, IEEE T PATTERN ANAL, V21, P1188, DOI 10.1109/34.809111; Sethi A, 2004, INT J COMPUT VISION, V58, P73, DOI 10.1023/B:VISI.0000016148.08046.fc; Shechtman E, 2005, PROC CVPR IEEE, P405; Shi JB, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1154, DOI 10.1109/ICCV.1998.710861; Simoncelli E. P., 1991, IEEE C COMP VIS PATT; Smith P, 2004, IEEE T PATTERN ANAL, V26, P479, DOI 10.1109/TPAMI.2004.1265863; SMITH PA, 2001, THESIS U CAMBRIDGE; Stein A, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P37; STEIN A, 2008, IEEE C COMP VIS PATT; STEIN A, 2007, BRIT MACH VIS C BMVC; STEIN A, 2008, THESIS CARNEGIE MELL; STEIN AN, 2006, PATCH WORKSH IEEE C, P19; STEIN AN, 2006, BRIT MACH VIS C BMVC, P407; Stein A, 2007, IEEE I CONF COMP VIS, P110; Tao H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P532, DOI 10.1109/ICCV.2001.937562; Tomasi C., 1991, CMUCS91132 MELL U; VAILLANT R, 1992, IEEE T PATTERN ANAL, V14, P157, DOI 10.1109/34.121787; Veit T, 2006, INT J COMPUT VISION, V68, P163, DOI 10.1007/s11263-006-6661-2; Waltz D., 1975, PSYCHOL COMPUTER VIS, P19; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; Weiss Y, 2000, NEURAL COMPUT, V12, P1, DOI 10.1162/089976600300015880; Weiss Y, 1997, ADV NEUR IN, V9, P908; Wolf L, 2006, LECT NOTES COMPUT SC, V3952, P481; XIAO J, 2005, IEEE C COMP VIS PATT; Xiao JJ, 2006, LECT NOTES COMPUT SC, V3951, P211; Yedidia JS, 2005, IEEE T INFORM THEORY, V51, P2282, DOI 10.1109/TIT.2005.850085; YIN P, 2007, IEEE C COMP VIS PATT; YU SX, 2001, CMURITR0121; Yuille AL, 2002, NEURAL COMPUT, V14, P1691, DOI 10.1162/08997660260028674	92	47	56	0	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2009	82	3					325	357		10.1007/s11263-008-0203-z	http://dx.doi.org/10.1007/s11263-008-0203-z			33	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	411TF		Green Submitted			2022-12-18	WOS:000263672800006
J	Hong, W; Yang, AY; Huang, K; Ma, Y				Hong, W; Yang, AY; Huang, K; Ma, Y			On symmetry and multiple-view geometry: Structure, pose, and calibration from a single image	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						structure from symmetry; multiple-view geometry; symmetry group; reflective symmetry; rotational symmetry; and translational symmetry	SURFACE ORIENTATION; TEXTURE; SHAPE; RECONSTRUCTION	In this paper, we provide a principled explanation of how knowledge in global 3-D structural invariants, typically captured by a group action on a symmetric structure, can dramatically facilitate the task of reconstructing a 3-D scene from one or more images. More importantly, since every symmetric structure admits a "canonical" coordinate frame with respect to which the group action can be naturally represented, the canonical pose between the viewer and this canonical frame can be recovered too, which explains why symmetric objects ( e. g., buildings) provide us overwhelming clues to their orientation and position. We give the necessary and sufficient conditions in terms of the symmetry ( group) admitted by a structure under which this pose can be uniquely determined. We also characterize, when such conditions are not satisfied, to what extent this pose can be recovered. We show how algorithms from conventional multiple-view geometry, after properly modified and extended, can be directly applied to perform such recovery, from all "hidden images" of one image of the symmetric structure. We also apply our results to a wide range of applications in computer vision and image processing such as camera self-calibration, image segmentation and global orientation, large baseline feature matching, image rendering and photo editing, as well as visual illusions ( caused by symmetry if incorrectly assumed).	Univ Illinois, Dept Elect & Comp Engn, Urbana, IL 61801 USA	University of Illinois System; University of Illinois Urbana-Champaign	Hong, W (corresponding author), Univ Illinois, Dept Elect & Comp Engn, 1308 W Main St, Urbana, IL 61801 USA.	weihong@uiuc.edu; yangyang@uiuc.edu; kunhuang@uiuc.edu; yima@uiuc.edu	Huang, Kun/E-3272-2011					Bieberbach L., 1910, NACHR KONIGL GES MP, P75; CARLSSON S, 1998, EUROPEAN C COMPUTER; Cham T.-J., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P385, DOI 10.1007/BFb0015552; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Criminisi A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P434, DOI 10.1109/ICCV.1999.791253; CRIMINISI A, 2000, INT J COMPUTER VISIO; Fedorov E.S, 1971, SYMMETRY CRYSTALS, V(Translated from the 1949 Russian edition.); FEDOROV ES, 1891, P S PETERB MINERAL S, V2, P1; FEDOROV ES, 1885, P S PETERB MINERAL S, V2, P1; Fedorov Evgraf Stepanovich, 1891, P S PETERB MINERAL S, V2, P345; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Garding J., 1992, Journal of Mathematical Imaging and Vision, V2, P327, DOI 10.1007/BF00121877; GARDING J, 1993, ARTIF INTELL, V64, P243, DOI 10.1016/0004-3702(93)90106-L; Gibson James J., 1950, PERCEPTION VISUAL WO, P3; GOOL LV, 1996, INT C COMP VIS PATT, P285; Gr?nbaum B., 1987, TILINGS PATTERNS; HONG W, 2004, EUROPEAN C COMPUTER; Huang K, 2004, IEEE INT CONF ROBOT, P1418; HUANG K, 2003, 9 INT C COMP VIS WOR; Kanatani K, 1997, IEEE T PATTERN ANAL, V19, P246, DOI 10.1109/34.584101; Kiryati N, 1998, INT J COMPUT VISION, V29, P29, DOI 10.1023/A:1008034529558; Leung T, 1997, PROC CVPR IEEE, P807, DOI 10.1109/CVPR.1997.609420; Liebowitz D, 1998, PROC CVPR IEEE, P482, DOI 10.1109/CVPR.1998.698649; LIU J, 1995, RECENT DEV COMPUTER, P415; Liu Y., 1998, CMURITR9837; Ma Y., 2003, INVITATION 3 D VISIO; MA Y, 2000, EUR C COMP VIS; Malik J, 1997, INT J COMPUT VISION, V23, P149, DOI 10.1023/A:1007958829620; MAROLA G, 1989, IEEE T PATTERN ANAL, V11, P104, DOI 10.1109/34.23119; Marr D., 1982, VISION; MARTIN GE, 1975, FDN GEOMETRY NONEUCL; MAY Y, 2002, AS C COMP VIS; MITSUMOTO H, 1992, IEEE T PATTERN ANAL, V14, P941, DOI 10.1109/34.161352; MUKHERJEE DP, 1995, PHILOS T R SOC A, V351, P77, DOI 10.1098/rsta.1995.0026; Plamer S. E., 1999, VISION SCI PHOTONS P; Rosenholtz R, 1997, VISION RES, V37, P2283, DOI 10.1016/S0042-6989(96)00121-6; Rothwell C. A., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P573, DOI 10.1109/ICCV.1993.378159; Schaffalitzky F, 2000, IMAGE VISION COMPUT, V18, P647, DOI 10.1016/S0262-8856(99)00069-4; Sun CM, 1997, IEEE T PATTERN ANAL, V19, P164, DOI 10.1109/34.574800; VETTER T, 1994, SPATIAL VISION, V8, P443, DOI 10.1163/156856894X00107; Weng J., 1993, MOTION STRUCTURE IMA; Weyl H., 1952, SYMMETRY; WITKIN AP, 1988, J ARTIFICIAL INTELLI, V17, P17; YANG AY, 2003, IEEE INT C COMP VIS; Zabrodsky H, 1997, COMPUT VIS IMAGE UND, V67, P48, DOI 10.1006/cviu.1996.0506; ZABRODSKY H, 1995, IEEE T PATTERN ANAL, V17, P1154, DOI 10.1109/34.476508; Zhang X, 1995, ELECTRON COMM JPN 3, V78, P1, DOI 10.1002/ecjc.4430780801	47	47	52	2	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	2004	60	3					241	265		10.1023/B:VISI.0000036837.76476.10	http://dx.doi.org/10.1023/B:VISI.0000036837.76476.10			25	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	843OL		Green Submitted			2022-12-18	WOS:000223093300004
J	Wolf, L; Shashua, A				Wolf, L; Shashua, A			On projection matrices Pk -> P-2, k=3, ..., 6, and their applications in computer vision	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						dynamic structure from motion; multiple view geometry; multi-linear constraints		Projection matrices from projective spaces P-3 to P-2 have long been used in multiple-view geometry to model the perspective projection created by the pin-hole camera. In this work we introduce higher-dimensional mappings P-k --> P-2,k=3,4,5,6 for the representation of various applications in which the world we view is no longer rigid. We also describe the multi-view constraints from these new projection matrices (where k > 3) and methods for extracting the (non-rigid) structure and motion for each application.	Hebrew Univ Jerusalem, Sch Comp Sci & Engn, IL-91904 Jerusalem, Israel	Hebrew University of Jerusalem	Wolf, L (corresponding author), Hebrew Univ Jerusalem, Sch Comp Sci & Engn, IL-91904 Jerusalem, Israel.							Avidan S, 2000, IEEE T PATTERN ANAL, V22, P348, DOI 10.1109/34.845377; BARNABEI M, 1985, J ALGEBRA, V96, P120, DOI 10.1016/0021-8693(85)90043-2; Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999; FAUGERAS OD, 1995, P INT C COMP VIS CAM; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; FITZGIBBON AW, 2000, P EUR C COMP VIS ECC; HAN M, 2000, P COMP VIS PATT REC; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Lucas B.D., 1981, ITERATIVE IMAGE REGI, P674; Manning R. A., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P388, DOI 10.1109/CVPR.1999.786968; SHASHUA A, 2000, P EUR C COMP VIS DUB; WEXLER Y, 2000, P IEEE C COMP VIS PA	12	47	56	0	2	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2002	48	1					53	67		10.1023/A:1014855311993	http://dx.doi.org/10.1023/A:1014855311993			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	534UM					2022-12-18	WOS:000174606100006
J	Wu, YT; Kanade, T; Li, CC; Cohn, J				Wu, YT; Kanade, T; Li, CC; Cohn, J			Image registration using wavelet-based motion model	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						image registration; coarse-to-fine motion pyramid; wavelet-based motion model; Cai-Wang wavelet; sum squared difference (SSD); warping	OPTICAL-FLOW; ROBUST STATISTICS; COMPUTATION; ALGORITHM; STEREO; FRAMEWORK; FIELDS; VISION	An image registration algorithm is developed to estimate dense motion vectors between two images using the coarse-to-fine wavelet-based motion model. This motion model is described by a linear combination of hierarchical basis functions proposed by Cai and Wang (SIAM Numer. Anal., 33(3):937-970, 1996). The coarser-scale basis function has larger support while the finer-scale basis function has smaller support. With these variable supports in full resolution, the basis functions serve as large-to-small windows so that the global and local information can be incorporated concurrently for image matching, especially for recovering motion vectors containing large displacements. To evaluate the accuracy of the wavelet-based method, two sets of test images were experimented using both the wavelet-based method and a leading pyramid spline-based method by Szeliski et al. (International Journal of Computer Vision, 22(3):199-218, 1996). One set of test images, taken from Barron et al. (International Journal of Computer Vision, 12:43-77, 1994), contains small displacements. The other set exhibits low texture or spatial aliasing after image blurring and contains large displacements. The experimental results showed that our wavelet-based method produced better motion estimates with error distributions having a smaller mean and smaller standard deviation.	Natl Chi Nan Univ, Dept Comp Sci & Informat Engn, Puli 545, Taiwan; Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA; Univ Pittsburgh, Dept Elect Engn, Pittsburgh, PA 15261 USA; Univ Pittsburgh, Dept Psychiat & Psychol, Pittsburgh, PA 15261 USA	National Chi Nan University; Carnegie Mellon University; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh	Wu, YT (corresponding author), Natl Yang Ming Univ, Dept Med Radiat Technol, Taipei 112, Taiwan.							ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167; BabHadiashar A, 1997, PROC CVPR IEEE, P988, DOI 10.1109/CVPR.1997.609448; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; BERGEN JR, 1992, LECT NOTES COMPUT SC, V588, P237; Black MJ, 1997, PROC CVPR IEEE, P561, DOI 10.1109/CVPR.1997.609381; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148; Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581; BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374; Cai W, 1996, SIAM J NUMER ANAL, V33, P937, DOI 10.1137/0733047; Chui CK, 1992, INTRO WAVELETS; DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199; Enkelmann W., 1986, Proceedings of the Workshop on Motion: Representation and Analysis (Cat. No.86CH2322-6), P81; FLEET DJ, 1990, INT J COMPUT VISION, V5, P77, DOI 10.1007/BF00056772; Fleet DJ, 1998, PROC CVPR IEEE, P274, DOI 10.1109/CVPR.1998.698620; Hanna K. J., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P156, DOI 10.1109/WVM.1991.212812; HEEGER DJ, 1987, INT J COMPUT VISION, V1, P279, DOI 10.1007/BF00133568; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HORN BKP, 1988, INT J COMPUT VISION, V2, P51, DOI 10.1007/BF00836281; JEPSON A, 1993, 1993 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION : PROCEEDINGS, P760; KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690; Kanatani K., 1993, GEOMETRIC COMPUTATIO; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; LUETTGEN MR, 1994, IEEE T IMAGE PROCESS, V3, P41, DOI 10.1109/83.265979; MALLAT S, 1989, IEEE T PATTERN ANAL, V11, P7; Memin E, 1998, IEEE T IMAGE PROCESS, V7, P703, DOI 10.1109/83.668027; NAGEL HH, 1987, ARTIF INTELL, V33, P299, DOI 10.1016/0004-3702(87)90041-5; NESI P, 1995, COMPUT VIS IMAGE UND, V62, P59, DOI 10.1006/cviu.1995.1041; Ong EP, 1996, INT CONF ACOUST SPEE, P1938, DOI 10.1109/ICASSP.1996.544831; Ong EP, 1999, INT J COMPUT VISION, V31, P51, DOI 10.1023/A:1008046826441; OTTE M, 1994, ECCV, P51; POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; Quam L. H., 1984, IM UND WORKSH NEW OR, P149; SINGH A, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P168; Szeliski R, 1997, INT J COMPUT VISION, V22, P199, DOI 10.1023/A:1007996332012; Szeliski R, 1996, IEEE T PATTERN ANAL, V18, P1199, DOI 10.1109/34.546257; WAXMAN AM, 1985, INT J ROBOT RES, V4, P95, DOI 10.1177/027836498500400307; WEBER J, 1995, INT J COMPUT VISION, V14, P67, DOI 10.1007/BF01421489; Wei GQ, 1998, IEEE T PATTERN ANAL, V20, P1143, DOI 10.1109/34.730551; Wu YT, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P992, DOI 10.1109/ICCV.1998.710837; WU YT, 1997, THESIS U PITTSBURGH; WU YT, 2000, 4 AS C COMP VIS, P753; Xiong YL, 1997, INT J COMPUT VISION, V22, P25, DOI 10.1023/A:1007927810205; YSERENTANT H, 1986, NUMER MATH, V49, P397	46	47	48	0	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2000	38	2					129	152		10.1023/A:1008101718719	http://dx.doi.org/10.1023/A:1008101718719			24	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	345GP					2022-12-18	WOS:000088808500002
J	Kiryati, N; Gofman, Y				Kiryati, N; Gofman, Y			Detecting symmetry in grey level images: The global optimization approach	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							SKEWED SYMMETRIES; SHAPE-DESCRIPTION; LOCAL SYMMETRY; AXIS; TRANSFORM; SEGMENTATION; INTENSITY; AXES	The detection of significant local reflectional symmetry in grey level images is considered. Prior segmentation is not assumed, and it is intended that the results could be used for guiding visual attention and for providing side information to segmentation algorithms. A local measure of reflectional symmetry that transforms the symmetry detection problem to a global optimization problem is defined. Reflectional symmetry detection becomes equivalent to finding the global maximum of a complicated multimodal function parameterized by the location of the center of the supporting region, its size, and the orientation of the symmetry axis. Unlike previous approaches, time consuming exhaustive search is avoided. A global optimization algorithm for solving the problem is presented. It is related to genetic algorithms and to adaptive random search techniques. The efficiency of the suggested algorithm is experimentally demonstrated. Just one thousand evaluations of the local symmetry measure are typically needed in order to locate the dominant symmetry in natural test images.	Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel	Technion Israel Institute of Technology	Kiryati, N (corresponding author), Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel.			Kiryati, Nahum/0000-0003-1436-2275				ATALLAH MJ, 1985, IEEE T COMPUT, V34, P663, DOI 10.1109/TC.1985.1676605; Baluja S, 1994, CMUCS94163 CARN MELL; Beasley D, 1993, EVOL COMPUT, V1, P101, DOI 10.1162/evco.1993.1.2.101; BIGUN J, 1990, COMPUT VISION GRAPH, V51, P166, DOI 10.1016/0734-189X(90)90029-U; BIGUN J, 1988, P 9 ICPR ROM, P345; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; BONNEH Y, 1994, SPATIAL VISION, V8, P515, DOI 10.1163/156856894X00152; BRADY M, 1984, INT J ROBOT RES, V3, P36, DOI 10.1177/027836498400300302; BRUCKSTEIN AM, 1995, P 6 INT C COMP AN IM, P17; BURBECK CA, 1995, VISION RES, V35, P1917, DOI 10.1016/0042-6989(94)00286-U; Burbeck CA, 1996, VISION RES, V36, P361, DOI 10.1016/0042-6989(95)00106-9; CHAM TJ, 1995, IMAGE VISION COMPUT, V13, P439, DOI 10.1016/0262-8856(95)99731-F; DAVIS LS, 1977, IEEE T SYST MAN CYB, V7, P204; DIGESU V, 1995, SYMMETRY OPERATORS C; FRIEDBERG SA, 1986, COMPUT VISION GRAPH, V34, P138, DOI 10.1016/S0734-189X(86)80055-X; FRITSCH DS, 1994, PATTERN RECOGN LETT, V15, P445, DOI 10.1016/0167-8655(94)90135-X; Gardner M, 1979, NEW AMBIDEXTROUS UNI; GAUCH JM, 1993, IEEE T PATTERN ANAL, V15, P753, DOI 10.1109/34.236253; Goldberg D. E., 1987, Genetic Algorithms and their Applications: Proceedings of the Second International Conference on Genetic Algorithms, P41; HANSEN O, 1992, PATTERN RECOGN LETT, V13, P253, DOI 10.1016/0167-8655(92)90076-C; Holland J. H., 1992, Scientific American (International Edition), V267, P44, DOI 10.1038/scientificamerican0792-66; KELLY MF, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1016, DOI 10.1109/ICCV.1995.466823; Kimmel R, 1997, INT J COMPUT VISION, V24, P37, DOI 10.1023/A:1007970107971; KUEHNLE A, 1991, PATTERN RECOGN LETT, V12, P249, DOI 10.1016/0167-8655(91)90039-O; Levitt T. S., 1984, P AAAI, P207; MAROLA G, 1989, IEEE T PATTERN ANAL, V11, P104, DOI 10.1109/34.23119; MASUDA T, 1993, PATTERN RECOGN, V26, P1245, DOI 10.1016/0031-3203(93)90209-F; MINOVIC P, 1993, IEEE T PATTERN ANAL, V15, P507, DOI 10.1109/34.211472; MORSE BS, 1994, IMAGE VISION COMPUT, V12, P327, DOI 10.1016/0262-8856(94)90057-4; Mumford D., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P22; NALWA VS, 1989, IEEE T PATTERN ANAL, V11, P1117, DOI 10.1109/34.42842; OGAWA H, 1991, PATTERN RECOGN LETT, V12, P9, DOI 10.1016/0167-8655(91)90022-E; PARUI SK, 1983, PATTERN RECOGN, V16, P63, DOI 10.1016/0031-3203(83)90009-2; Pizer S. M., 1994, Journal of Mathematical Imaging and Vision, V4, P303, DOI 10.1007/BF01254105; PIZER SM, 1987, IEEE T PATTERN ANAL, V9, P505, DOI 10.1109/TPAMI.1987.4767938; PONCE J, 1990, COMPUT VISION GRAPH, V52, P328, DOI 10.1016/0734-189X(90)90079-B; REISFELD D, 1995, INT J COMPUT VISION, V14, P119, DOI 10.1007/BF01418978; Soffer M, 1998, COMPUT VIS IMAGE UND, V69, P119, DOI 10.1006/cviu.1997.0557; SUN CM, 1995, PATTERN RECOGN LETT, V16, P987, DOI 10.1016/0167-8655(95)00049-M; TORN A, 1989, LECT NOTES COMPUT SC, V350, P1; VANGOOL L, 1995, INT J ROBOT RES, V14, P407, DOI 10.1177/027836499501400502; Weil HKH, 1952, SYMMETRY; YlaJaaski A, 1996, COMPUT VIS IMAGE UND, V63, P399, DOI 10.1006/cviu.1996.0031; YUEN KSY, 1994, PATTERN RECOGN LETT, V15, P279, DOI 10.1016/0167-8655(94)90060-4; ZABRODSKY H, 1995, IEEE T PATTERN ANAL, V17, P1154, DOI 10.1109/34.476508; ZIELKE T, 1993, CVGIP-IMAG UNDERSTAN, V58, P177, DOI 10.1006/ciun.1993.1037	46	47	49	2	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	1998	29	1					29	45		10.1023/A:1008034529558	http://dx.doi.org/10.1023/A:1008034529558			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	125XY					2022-12-18	WOS:000076263700002
J	Wilson, DL; Baddeley, AJ; Owens, RA				Wilson, DL; Baddeley, AJ; Owens, RA			A new metric for grey-scale image comparison	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						grey-scale image comparison; error measures; Delta metrics; root-mean-squared error; Sobolev norm; Hausdorff metric; myopic topology; image distortion; visual perception	EDGE-DETECTION; COMPRESSION; DESIGN	Error measures can be used to numerically assess the differences between two images. Much work has been done on binary error measures, but little on objective metrics for grey-scale images. In our discussion here we introduce a new grey-scale measure, Delta(g), aiming to improve upon the most common grey-scale error measure, the root-mean-square error. Our new measure is an extension of the authors' recently developed binary error measure, Delta(b), not only in structure, but also having both a theoretical and intuitive basis. We consider the similarities between Delta(b) and Delta(g) when tested in practice on binary images, and present results comparing Delta(g) to the root-mean-squared error and the Sobolev norm for various binary and grey-scale images. There are no previous examples where the last of these measures, the Sobolev norm, has been implemented for this purpose.	UNIV WESTERN AUSTRALIA,DEPT MATH,NEDLANDS,WA 6009,AUSTRALIA; UNIV WESTERN AUSTRALIA,DEPT COMP SCI,NEDLANDS,WA 6009,AUSTRALIA	University of Western Australia; University of Western Australia	Wilson, DL (corresponding author), UNIV OXFORD,DEPT ENGN SCI,PARKS RD,OXFORD OX1 3PJ,ENGLAND.		Baddeley, Adrian J/E-3661-2010	Baddeley, Adrian J/0000-0001-9499-8382				ABDOU IE, 1979, P IEEE, V67, P753, DOI 10.1109/PROC.1979.11325; Baddeley A.J., 1992, NIEUW ARCH WISK, V10, P157; BADDELEY AJ, 1992, ROBUST COMPUTER VISI, P59; BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0; Bracewell R., 1986, FOURIER TRANSFORM IT; Bryant V, 1985, METRIC SPACES ITERAT; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; CHOQUET G, 1966, TOPOLOGY, P138; CORNSWEET TN, 1970, VISUAL PERCEPTION, P249; Daly Scott, 1993, P179; DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560; DUGUNDJI J, 1966, TOPOLOGY, P83; GONZALEZ RC, 1993, DIGITAL IMAGE PROCES, P307; HABIBI A, 1974, IEEE T COMMUN, VCO22, P614, DOI 10.1109/TCOM.1974.1092258; JAIN AK, 1981, P IEEE, V69, P349, DOI 10.1109/PROC.1981.11971; LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577; MATHERON G, 1975, RANDOM SETS INTEGRAL, P12; NATTERER F, 1986, MATH COMPUTERIZED TO, P200; NETRAVALI AN, 1988, DIGITAL PICTURES REP, P301; PELI T, 1982, COMPUT VISION GRAPH, V20, P1, DOI 10.1016/0146-664X(82)90070-3; PRATT WK, 1991, DIGITAL IMAGE PROCES, P538; RABBINI M, 1991, DIGITAL IMAGE COMPRE; ROSENFELD A, 1969, PICTURE PROCESSING C, P1; SERRA J, 1982, IMAGE ANAL MATH MORP, P34; TAGARE HD, 1990, IEEE T PATTERN ANAL, V12, P1186, DOI [10.1109/34.62607, 10.1117/12.19530]; TEO PC, 1994, 1 INT C IM PROC; TEO PC, 1994, IN PRESS PERCEPTUAL; VERVAAT W, 1988, STAT PROBABIL LETT, V6, P295, DOI 10.1016/0167-7152(88)90002-8; Wallace G., 1992, IEEE T CONSUM ELECTR, V38, P18; Watson A.B., 1993, DIGITAL IMAGES HUMAN, P139; WOODS JW, 1986, IEEE T ACOUST SPEECH, V34, P1278, DOI 10.1109/TASSP.1986.1164962	31	47	48	0	5	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	1997	24	1					5	17		10.1023/A:1007978107063	http://dx.doi.org/10.1023/A:1007978107063			13	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	XV644					2022-12-18	WOS:A1997XV64400001
J	Olson, CF				Olson, CF			Efficient pose clustering using a randomized algorithm	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							3-DIMENSIONAL OBJECT RECOGNITION; HOUGH TRANSFORM; POINTS; IMAGE	Pose clustering is a method to perform object recognition by determining hypothetical object poses and finding clusters of the poses in the space of legal object positions. An object that appears in an image will yield a large cluster of such poses close to the correct position of the object. If there are m model features and rt image features, then there are O (m(3)n(3)) hypothetical poses that can be determined from minimal information for the case of recognition of three-dimensional objects from feature points in two-dimensional images. Rather than clustering all of these poses, we show that pose clustering can have equivalent performance for this case when examining only O (mn) poses, due to correlation between the poses, if we are given two correct matches between model features and image features. Since we do not usually know two correct matches in advance, this property is used with randomization to decompose the pose clustering problem into O (n(2)) problems, each of which clusters O (mn) poses, for a total complexity of O(mn(3)). Further speedup can be achieved through the use of grouping techniques. This method also requires little memory and makes the use of accurate clustering algorithms less costly. We use recursive histograming techniques to perform clustering in time and space that is guaranteed to be linear in the number of poses. Finally, we present results demonstrating the recognition of objects in the presence of noise, clutter, and occlusion.			Olson, CF (corresponding author), CORNELL UNIV, DEPT COMP SCI, ITHACA, NY 14853 USA.							ALTER TD, 1994, IEEE T PATTERN ANAL, V16, P802, DOI 10.1109/34.308475; ALTER TD, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P892, DOI 10.1109/CVPR.1994.323920; ALTER TD, 1993, P INT C COMP VIS, P113; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; BESL PJ, 1985, COMPUT SURV, V17, P75, DOI 10.1145/4078.4081; Breuel T. M., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P445, DOI 10.1109/CVPR.1992.223152; Cass T. A., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P360, DOI 10.1109/ICCV.1990.139551; Cass T. A., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P879, DOI 10.1109/CVPR.1988.196336; CASS TA, 1993, THESIS MIT; CASS TA, 1992, P EUR C COMP VIS, P834; CHIN RT, 1986, COMPUT SURV, V18, P67, DOI 10.1145/6462.6464; DAY WHE, 1984, J CLASSIF, V1, P7, DOI 10.1007/BF01890115; DEFAYS D, 1977, COMPUT J, V20, P364, DOI 10.1093/comjnl/20.4.364; DEMENTHON D, 1992, IEEE T PATTERN ANAL, V14, P1100, DOI 10.1109/34.166625; DHOME M, 1987, IEEE T PATTERN ANAL, V9, P429, DOI 10.1109/TPAMI.1987.4767924; Edelsbrunner H., 1987, ALGORITHMS COMBINATO; Feller W., 1968, INTRO PROBABILITY TH, V3; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Forstner<spacing Wolfgang, 1987, ISPRS INT C FAST PRO, P2; FORSTNER W, 1993, COMPUTER ROBOT VISIO, V2, pCH16; Grimson W. E. L., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P316, DOI 10.1109/CVPR.1992.223257; Grimson W. E. L., 1990, OBJECT RECOGNITION C; GRIMSON WEL, 1990, IEEE T PATTERN ANAL, V12, P255, DOI 10.1109/34.49052; GRIMSON WEL, 1994, INT J COMPUT VISION, V13, P7, DOI 10.1007/BF01420793; Hough P.V.C, 1962, U.S. Patent, Patent No. [3069654, 3,069,654]; HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921; HUTTENLOCHER DP, 1992, P EUR C COMP VIS, P773; ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1; JACOBS D, 1991, IEEE C COMP VIS PATT, P269; LINNAINMAA S, 1988, IEEE T PATTERN ANAL, V10, P634, DOI 10.1109/34.6772; Olson C. F., 1995, Proceedings International Symposium on Computer Vision (Cat. No.95TB100006), P449, DOI 10.1109/ISCV.1995.477043; OLSON CF, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P251, DOI 10.1109/CVPR.1994.323837; SIBSON R, 1973, COMPUT J, V16, P30, DOI 10.1093/comjnl/16.1.30; SILBERBERG TM, 1986, COMPUT VISION GRAPH, V35, P47, DOI 10.1016/0734-189X(86)90125-8; SILBERBERG TM, 1984, PATTERN RECOGN, V17, P621, DOI 10.1016/0031-3203(84)90015-3; STOCKMAN G, 1987, COMPUT VISION GRAPH, V40, P361, DOI 10.1016/S0734-189X(87)80147-0; STOCKMAN G, 1982, IEEE T PATTERN ANAL, V4, P229, DOI 10.1109/TPAMI.1982.4767240; THOMPSON DW, 1987, IEEE J ROBOTIC AUTOM, P208; TURNEY JL, 1985, IEEE T PATTERN ANAL, V7, P410, DOI 10.1109/TPAMI.1985.4767680	39	47	51	0	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	1997	23	2					131	147		10.1023/A:1007906812782	http://dx.doi.org/10.1023/A:1007906812782			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	XK384					2022-12-18	WOS:A1997XK38400002
J	BAKER, HH; BOLLES, RC				BAKER, HH; BOLLES, RC			GENERALIZING EPIPOLAR-PLANE IMAGE-ANALYSIS ON THE SPATIOTEMPORAL SURFACE	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article									SRI INT,CTR ARTIFICIAL INTELLIGENCE,MENLO PK,CA 94025	SRI International								BAKER H, 1989, INT J COMPUTER VISIO, V3; BAKER HH, 1983, JUN P IM UND WORKSH, P327; BOLLES RC, 1987, INT J COMPUT VISION, V1, P7, DOI 10.1007/BF00128525; BROIDA TJ, 1986, MAY P IEEE WORKSH MO, P95; BUXTON BF, 1983, PROC R SOC SER B-BIO, V218, P27, DOI 10.1098/rspb.1983.0024; DICKMANNS ED, 1988, JUN IEEE COMP SOC C, P820; FORSTNER W, 1987, COMPUT VISION GRAPH, V40, P273, DOI 10.1016/S0734-189X(87)80144-5; FORSTNER W, 1986, AUG P S INT ARCH PHO, V26; Gelb A., 1974, APPL OPTIMAL ESTIMAT; Gibson James J., 1950, PERCEPTION VISUAL WO, P3; HALLAM J, 1983, 8TH P IJCAI, P792; HEEGER DJ, 1986, 5TH P NAT C ART INT, P657; HILDRETH E, 1986, MAY P IEEE WORKSH MO, P137; JAIN R, 1987, IEEE T PATTERN ANAL, V9, P356, DOI 10.1109/TPAMI.1987.4767919; MARIMONT DH, 1986, MAY P IEEE COMP SOC, P7; MATTHIES L, 1988, JUN P IEEE COMP SOC, P366; Mikhail E.M., 1976, OBSERVATIONS LEAST S; NEGAHDARIPOUR S, 1987, IEEE T PATTERN ANAL, V9, P168, DOI 10.1109/TPAMI.1987.4767884; SUBBARAO M, 1986, MAY P WORKSH MOT REP, P157; WAXMAN AM, 1987, INT J COMPUT VISION, V1, P239, DOI 10.1007/BF00127823; WAXMAN AM, 1985, INT J ROBOT RES, V4, P95, DOI 10.1177/027836498500400307; WAXMAN AM, 1988, JUN P IEEE C COMP VI, P717; WAXMAN AM, 1984, 2ND P IEEE WORKSH CO, P49; [No title captured]	24	47	53	0	0	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	1989	3	1					33	49		10.1007/BF00054837	http://dx.doi.org/10.1007/BF00054837			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AE167					2022-12-18	WOS:A1989AE16700003
J	Zia, MZ; Stark, M; Schindler, K				Zia, M. Zeeshan; Stark, Michael; Schindler, Konrad			Towards Scene Understanding with Detailed 3D Object Representations	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							TRACKING; MODELS	Current approaches to semantic image and scene understanding typically employ rather simple object representations such as 2D or 3D bounding boxes. While such coarse models are robust and allow for reliable object detection, they discard much of the information about objects' 3D shape and pose, and thus do not lend themselves well to higher-level reasoning. Here, we propose to base scene understanding on a high-resolution object representation. An object class-in our case cars-is modeled as a deformable 3D wireframe, which enables fine-grained modeling at the level of individual vertices and faces. We augment that model to explicitly include vertex-level occlusion, and embed all instances in a common coordinate frame, in order to infer and exploit object-object interactions. Specifically, from a single view we jointly estimate the shapes and poses of multiple objects in a common 3D frame. A ground plane in that frame is estimated by consensus among different objects, which significantly stabilizes monocular 3D pose estimation. The fine-grained model, in conjunction with the explicit 3D scene model, further allows one to infer part-level occlusions between the modeled objects, as well as occlusions by other, unmodeled scene elements. To demonstrate the benefits of such detailed object class models in the context of scene understanding we systematically evaluate our approach on the challenging KITTI street scene dataset. The experiments show that the model's ability to utilize image evidence at the level of individual parts improves monocular 3D pose estimation w.r.t. both location and (continuous) viewpoint.	[Zia, M. Zeeshan; Schindler, Konrad] Swiss Fed Inst Technol, Zurich, Switzerland; [Zia, M. Zeeshan] Univ London Imperial Coll Sci Technol & Med, London, England; [Stark, Michael] Max Planck Inst Informat, D-66123 Saarbrucken, Germany	Swiss Federal Institutes of Technology Domain; ETH Zurich; Imperial College London; Max Planck Society	Zia, MZ (corresponding author), Swiss Fed Inst Technol, Zurich, Switzerland.	zeeshan.zia@imperial.ac.uk; stark@mpi-inf.mpg.de; konrad.schindler@geod.baug.ethz.ch		Pauldurai, Jona/0000-0002-7217-0872	Max Planck Center for Visual Computing Communication	Max Planck Center for Visual Computing Communication	This work has been supported by the Max Planck Center for Visual Computing & Communication.	Bao S. Y., 2011, CVPR; Belongie S., 2000, NIPS; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; BROOKS RA, 1981, ARTIF INTELL, V17, P285, DOI 10.1016/0004-3702(81)90028-X; Choi Wongun, 2013, CVPR; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Del Pero L., 2013, CVPR; Enzweiler M, 2010, PROC CVPR IEEE, P990, DOI 10.1109/CVPR.2010.5540111; Ess A, 2009, IEEE T PATTERN ANAL, V31, P1831, DOI 10.1109/TPAMI.2009.109; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fransens R., 2006, CVPR; Gao TS, 2011, PROC CVPR IEEE, P1361, DOI 10.1109/CVPR.2011.5995623; Geiger A., 2011, ADV NEURAL INFORM PR, V24; Geiger A., 2012, P IEEE COMP SOC C CO; Girshick R., 2011, ADV NEURAL INFORM PR, V24, P442; Gupta A, 2010, LECT NOTES COMPUT SC, V6311, P171, DOI 10.1007/978-3-642-15549-9_13; Haag M, 1999, INT J COMPUT VISION, V35, P295, DOI 10.1023/A:1008112528134; Hedau V, 2010, ECCV; Hejrati M., 2012, NIPS; Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KOLLER D, 1993, INT J COMPUT VISION, V10, P257, DOI 10.1007/BF01539538; Kwak S., 2011, ICCV; LEIBE B, 2006, CATEGORY LEVEL OBJEC; Leordeanu M, 2008, CVPR; Li Y, 2011, IEEE T PATTERN ANAL, V33, P1860, DOI 10.1109/TPAMI.2011.40; Liu XB, 2018, IEEE T PATTERN ANAL, V40, P710, DOI 10.1109/TPAMI.2017.2689007; LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1; Maji S., 2009, CVPR; MALIK J, 1987, INT J COMPUT VISION, V1, P73, DOI 10.1007/BF00128527; Meger D., 2011, BMVC; Oramas J., 2013, ICCV; PENTLAND AP, 1986, ARTIF INTELL, V28, P293, DOI 10.1016/0004-3702(86)90052-4; Pepik B., 2013, CVPR; Roberts Lawrence G, 1963, THESIS, P2; Schonborn S., 2013, GCPR; Silberman Nathan, 2012, EUR C COMP VIS, DOI 10.1007/978-3-642-33715-4_54; Stark M., 2010, BMVC; Sullivan G. D., 1995, IEEE WORKSH CONT BAS; Tang S., 2012, BMVC; Vedaldi A., 2009, NIPS; Villamizar M., 2011, BMVC, P201; Wang H., 2010, ECCV; Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207; Wojek C., 2013, PAMI; Xiang Y., 2013, 3DRR; Xiang Y., 2012, CVPR; Zhao YB, 2013, PROC CVPR IEEE, P3119, DOI 10.1109/CVPR.2013.401; Zia M. Z., 2014, CVPR; Zia M. Z., 2009, ICAR; Zia MZ, 2013, IEEE T PATTERN ANAL, V35, P2608, DOI 10.1109/TPAMI.2013.87; Zia MZ, 2013, PROC CVPR IEEE, P3326, DOI 10.1109/CVPR.2013.427	53	46	51	0	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	2015	112	2			SI		188	203		10.1007/s11263-014-0780-y	http://dx.doi.org/10.1007/s11263-014-0780-y			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	CE0TD		Green Published, Green Submitted			2022-12-18	WOS:000351518500005
J	Gavves, E; Fernando, B; Snoek, CGM; Smeulders, AWM; Tuytelaars, T				Gavves, Efstratios; Fernando, Basura; Snoek, Cees G. M.; Smeulders, Arnold W. M.; Tuytelaars, Tinne			Local Alignments for Fine-Grained Categorization	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Alignment; Image representation; Object classification		The aim of this paper is fine-grained categorization without human interaction. Different from prior work, which relies on detectors for specific object parts, we propose to localize distinctive details by roughly aligning the objects using just the overall shape. Then, one may proceed to the classification by examining the corresponding regions of the alignments. More specifically, the alignments are used to transfer part annotations from training images to unseen images (supervised alignment), or to blindly yet consistently segment the object in a number of regions (unsupervised alignment). We further argue that for the distinction of subclasses, distribution-based features like color Fisher vectors are better suited for describing localized appearance of fine-grained categories than popular matching oriented shape-sensitive features, like HOG. They allow capturing the subtle local differences between subclasses, while at the same time being robust to misalignments between distinctive details. We evaluate the local alignments on the CUB-2011 and on the Stanford Dogs datasets, composed of 200 and 120, visually very hard to distinguish bird and dog species. In our experiments we study and show the benefit of the color Fisher vector parameterization, the influence of the alignment partitioning, and the significance of object segmentation on fine-grained categorization. We, furthermore, show that by using object detectors as voters to generate object confidence saliency maps, we arrive at fully unsupervised, yet highly accurate fine-grained categorization. The proposed local alignments set a new state-of-the-art on both the fine-grained birds and dogs datasets, even without any human intervention. What is more, the local alignments reveal what appearance details are most decisive per fine-grained object category.	[Gavves, Efstratios; Snoek, Cees G. M.; Smeulders, Arnold W. M.] Univ Amsterdam, Amsterdam, Netherlands; [Fernando, Basura; Tuytelaars, Tinne] Katholieke Univ Leuven, ESAT PSI, iMinds, Leuven, Belgium	University of Amsterdam; IMEC; KU Leuven	Gavves, E (corresponding author), Univ Amsterdam, Amsterdam, Netherlands.	efstratios.gavves@gmail.com	Gavves, Efstratios/AAA-6992-2019; Tuytelaars, Tinne/B-4319-2015	Tuytelaars, Tinne/0000-0003-3307-9723; Fernando, Basura/0000-0002-6920-9916; Gavves, Efstratios/0000-0001-8947-1332	project IMPact BeeldCanon; project AXES; project STW STORY; project COGNIMUND; Dutch national program COMMIT	project IMPact BeeldCanon; project AXES; project STW STORY; project COGNIMUND; Dutch national program COMMIT	The projects IMPact BeeldCanon, AXES, STW STORY, COGNIMUND, and the Dutch national program COMMIT support this research.	Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28; [Anonymous], 2011, 1 WORKSH FIN GRAIN V; Arbelaez P, 2012, PROC CVPR IEEE, P3378, DOI 10.1109/CVPR.2012.6248077; Azizpour H, 2012, LECT NOTES COMPUT SC, V7572, P836, DOI 10.1007/978-3-642-33718-5_60; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Berg T, 2013, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2013.128; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; Bo L., 2010, P NEUR INF PROC SYST; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Branson S., 2011, P IEEE INT C COMP VI; Branson S., 2010, P EUR C COMP VIS; Branson S, 2014, INT J COMPUT VISION, V108, P3, DOI 10.1007/s11263-014-0698-4; Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231; Chai Y., 2012, P EUR C COMP VIS; Chai Y, 2013, IEEE I CONF COMP VIS, P321, DOI 10.1109/ICCV.2013.47; Chai YN, 2011, IEEE I CONF COMP VIS, P2579, DOI 10.1109/ICCV.2011.6126546; Cinbis RG, 2013, IEEE I CONF COMP VIS, P2968, DOI 10.1109/ICCV.2013.369; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N., 2005, HISTOGRAMS ORIENTED; Darwin C., 1859, ORIGINS SPECIES MEAN; Deng J., 2009, 2009 IEEE C COMP VIS, P248, DOI [DOI 10.1109/CVPR.2009.5206848, 10.1109/CVPR.2009.5206848]; DONAHUE J, 2013, TECHNICAL REPORT; Duan K., 2012, P IEEE C VIS PATT RE; Everingham M., 2007, PASCAL VIS OBJ CLASS; Farrell R., 2011, P IEEE INT C COMP VI; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Gavves E., 2013, P IEEE INT C COMP VI; Gavves E., 2012, P IEEE C COMP VIS PA; Gosselin P. H., 2013, RR8431 INRIA; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Jia Y., 2013, TECHNICAL REPORT; Lazebnik S., 2006, P IEEE C COMP VIS PA; Liu J., 2012, P EUR C COMP VIS; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maji S., 2013, TECHNICAL REPORT, P6; Maji S., 2008, P IEEE C VIS PATT RE; Manen  S., 2013, P IEEE INT C COMP VI; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Nilsback M. E., 2008, ICVGIP; Parikh D., 2011, P IEEE C COMP VIS PA; Parkhi O. M., 2012, P IEEE C COMP VIS PA; Perd'och M., 2009, P IEEE C COMP VIS PA; Perronnin F., 2010, P EUR C COMP VIS; ROSCH E, 1976, COGNITIVE PSYCHOL, V8, P382, DOI 10.1016/0010-0285(76)90013-X; Rother C., 2004, ACM T GRAPHICS GRABC; Sanchez J., 2011, P IEEE C COMP VIS PA; Shalev-Shwartz Shai, 2007, P INT C MACH LEARN; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; van de Sande K. E. A., 2010, IEEE T PATTERN ANAL; Vedaldi A., 2010, P INT C MULT ACM; Vedaldi A., 2009, P INT C VIS; Wah C., 2011, TECHNICAL REPORT, P5; Wah C., 2011, P IEEE INT C COMP VI; Xie L., 2013, P IEEE C COMP VIS; Yang S., 2012, P NEUR INF PROC SYST; Yao B., 2011, P IEEE C VIS PATT RE; Yao B., 2012, P IEEE C COMP VIS PA; Zhang N., 2013, P IEEE C COMP VIS; Zhang N., 2012, P IEEE C COMP VIS PA	60	46	50	0	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2015	111	2					191	212		10.1007/s11263-014-0741-5	http://dx.doi.org/10.1007/s11263-014-0741-5			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AZ6RD		Green Accepted			2022-12-18	WOS:000348345500004
J	Ren, X; Lin, ZC				Ren, Xiang; Lin, Zhouchen			Linearized Alternating Direction Method with Adaptive Penalty and Warm Starts for Fast Solving Transform Invariant Low-Rank Textures	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Transform invariant low-rank texutres; Linearized alternating direction method with adaptive penalty; Warm start; Singular value decomposition	DECOMPOSITION	Transform invariant low-rank textures (TILT) is a novel and powerful tool that can effectively rectify a rich class of low-rank textures in 3D scenes from 2D images despite significant deformation and corruption. The existing algorithm for solving TILT is based on the alternating direction method. It suffers from high computational cost and is not theoretically guaranteed to converge to a correct solution to the inner loop. In this paper, we propose a novel algorithm to speed up solving TILT, with guaranteed convergence for the inner loop. Our method is based on the recently proposed linearized alternating direction method with adaptive penalty. To further reduce computation, warm starts are also introduced to initialize the variables better and cut the cost on singular value decomposition. Extensive experimental results on both synthetic and real data demonstrate that this new algorithm works much more efficiently and robustly than the existing algorithm. It could be at least five times faster than the previous method.	[Ren, Xiang] Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA; [Lin, Zhouchen] Peking Univ, Key Lab Machine Percept MOE, Sch EECS, Beijing 100871, Peoples R China	University of Illinois System; University of Illinois Urbana-Champaign; Peking University	Lin, ZC (corresponding author), Peking Univ, Key Lab Machine Percept MOE, Sch EECS, Beijing 100871, Peoples R China.	xren7@illinois.edu; zlin@pku.edu.cn			National Natural Science Foundation of China [61272341, 61231002, 61121002]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	Z. Lin is supported by the National Natural Science Foundation of China (Grant Nos. 61272341, 61231002, and 61121002).	Bertsekas DP., 2002, INTRO PROBABILITY; Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970; Candes EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395; CHEN G, 1994, MATH PROGRAM, V64, P81, DOI 10.1007/BF01582566; Deng W., 2012, GLOBAL LINEAR CONVER, ptR12; DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954; He BS, 2012, SIAM J OPTIMIZ, V22, P313, DOI 10.1137/110822347; Lin Z., 2009, UILUENG092215; Lin Z., 2011, PROC INT 25 C NEURAL, P612, DOI DOI 10.1007/S11263-013-0611-6; Liu G., 2010, P 27 INT C MACHINE L, P663, DOI DOI 10.1109/ICDMW.2010.64; Mobahi H, 2011, IEEE WORKSH 3D REPR; Peng YG, 2010, PROC CVPR IEEE, P763, DOI 10.1109/CVPR.2010.5540138; PIERRA G, 1984, MATH PROGRAM, V28, P96, DOI 10.1007/BF02612715; Schindler G, 2008, PROC CVPR IEEE, P925; Toh KC, 2010, PAC J OPTIM, V6, P615; Wen ZW, 2013, MATH PROGRAM, V142, P397, DOI 10.1007/s10107-012-0584-1; Yang JF, 2011, SIAM J SCI COMPUT, V33, P250, DOI 10.1137/090777761; Zhang X., 2012, PATTERN RECOGNITION; Zhang Z, 2011, IEEE C COMP VIS PATT; Zhang ZD, 2012, INT J COMPUT VISION, V99, P1, DOI 10.1007/s11263-012-0515-x; Zhang ZM, 2011, PROC CVPR IEEE, P1497, DOI 10.1109/CVPR.2011.5995411; Zhao P, 2011, IEEE C COMP VIS PATT	24	46	51	0	20	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2013	104	1					1	14		10.1007/s11263-013-0611-6	http://dx.doi.org/10.1007/s11263-013-0611-6			14	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	179LY		Green Submitted			2022-12-18	WOS:000321523000001
J	Lu, ZW; Peng, YX				Lu, Zhiwu; Peng, Yuxin			Exhaustive and Efficient Constraint Propagation: A Graph-Based Learning Approach and Its Applications	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Pairwise constraint propagation; Semi-supervised classification; Constrained spectral clustering; Multi-source data; Cross-modal retrieval	NORMALIZED CUTS; IMAGE; SEGMENTATION; SHAPE	This paper presents a novel pairwise constraint propagation approach by decomposing the challenging constraint propagation problem into a set of independent semi-supervised classification subproblems which can be solved in quadratic time using label propagation based on -nearest neighbor graphs. Considering that this time cost is proportional to the number of all possible pairwise constraints, our approach actually provides an efficient solution for exhaustively propagating pairwise constraints throughout the entire dataset. The resulting exhaustive set of propagated pairwise constraints are further used to adjust the similarity matrix for constrained spectral clustering. Other than the traditional constraint propagation on single-source data, our approach is also extended to more challenging constraint propagation on multi-source data where each pairwise constraint is defined over a pair of data points from different sources. This multi-source constraint propagation has an important application to cross-modal multimedia retrieval. Extensive results have shown the superior performance of our approach.	[Lu, Zhiwu; Peng, Yuxin] Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China	Peking University	Peng, YX (corresponding author), Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China.	luzhiwu@pku.edu.cn; pengyuxin@pku.edu.cn	peng, yu/GXW-2071-2022; Peng, Yuxin/U-7376-2019	Lu, Zhiwu/0000-0003-0280-7724; Lu, Zhiwu/0000-0001-6429-7956	National Natural Science Foundation of China [61073084, 61202231]; Beijing Natural Science Foundation of China [4122035]; National Hi-Tech Research and Development Program (863 Program) of China [2012AA012503]; National Development and Reform Commission High-tech Program of China [[2010]3044]; National Key Technology Research and Development Program of China [2012BAH07B01]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Beijing Natural Science Foundation of China(Beijing Natural Science Foundation); National Hi-Tech Research and Development Program (863 Program) of China(National High Technology Research and Development Program of China); National Development and Reform Commission High-tech Program of China; National Key Technology Research and Development Program of China(National Key Technology R&D ProgramNational High Technology Research and Development Program of China)	The authors would like to thank Liwei Wang, Zhenyong Fu, and the anonymous reviewers for their valuable comments. This work was supported by National Natural Science Foundation of China under Grants 61073084 and 61202231, Beijing Natural Science Foundation of China under Grant 4122035, National Hi-Tech Research and Development Program (863 Program) of China under Grant 2012AA012503, National Development and Reform Commission High-tech Program of China under Grant [2010]3044, and National Key Technology Research and Development Program of China under Grant 2012BAH07B01.	BARTELS RH, 1972, COMMUN ACM, V15, P820, DOI 10.1145/361573.361582; Basu Sugato, 2004, KDD, P59, DOI DOI 10.1145/1014052.1014062; Bekkerman R, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383223; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bruno E, 2008, IEEE T PATTERN ANAL, V30, P1520, DOI 10.1109/TPAMI.2007.70801; Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800; Chen GL, 2009, INT J COMPUT VISION, V81, P317, DOI 10.1007/s11263-008-0178-9; Eaton E., 2010, P 19 ACM INT C INF K, P389, DOI DOI 10.1145/1871437.1871489; Eriksson A, 2007, 11 IEEE INT C COMP V, P1; Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2; Feng SL, 2004, PROC CVPR IEEE, P1002; Gajic Z., 1995, LYAPUNOV MATRIX EQUA; Ghanem B, 2010, INT J COMPUT VISION, V89, P40, DOI 10.1007/s11263-010-0321-2; Hoi S., 2006, P IEEE COMP SOC C CO, V2, P2072, DOI DOI 10.1109/CVPR.2006.167; Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Kamvar S. D., 2003, P 18 INT JOINT C ART, P561; Klein D., 2002, P 19 INT C MACH LEAR, P307; Kulis B., 2005, P 22 INT C MACH LEAR, P457, DOI DOI 10.1145/1102351.1102409; LANCASTER P, 1970, SIAM REV, V12, P544, DOI 10.1137/1012104; Law MHC, 2004, LECT NOTES COMPUT SC, V3138, P662; Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984; Li Z, 2008, PROC 25 INT C MACH L; Linli Xu, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2866, DOI 10.1109/CVPRW.2009.5206561; Liu W., 2010, KDD, P1139, DOI DOI 10.1145/1835804.183594; LU Z, 2008, P CVPR; Lu Z. W., 2008, P 23 NAT C ART INT, P665; Lu ZW, 2010, LECT NOTES COMPUT SC, V6316, P1; Lu ZW, 2011, IEEE T IMAGE PROCESS, V20, P1739, DOI 10.1109/TIP.2010.2103082; Ng AY, 2002, ADV NEUR IN, V14, P849; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Ordonez V, 2012, ADV NEURAL INFORM PR, V25, P1143; Rasiwasia N, 2010, ACM MM, DOI DOI 10.1145/1873951.1873987; Rasiwasia N, 2007, IEEE T MULTIMEDIA, V9, P923, DOI 10.1109/TMM.2007.900138; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Snoek CGM, 2005, MULTIMED TOOLS APPL, V25, P5, DOI 10.1023/B:MTAP.0000046380.27575.a5; Veksler O, 2008, LECT NOTES COMPUT SC, V5304, P454, DOI 10.1007/978-3-540-88690-7_34; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Wagstaff K., 2001, ICML, V1, P577, DOI DOI 10.1109/TPAMI.2002.1017616; Xing E., 2002, ADV NEURAL INFORM PR, V15, P505, DOI DOI 10.5555/2968618.2968683; Yu SX, 2004, IEEE T PATTERN ANAL, V26, P173, DOI 10.1109/TPAMI.2004.1262179; Zhiwu Lu, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2719, DOI 10.1109/CVPRW.2009.5206851; Zhou DY, 2004, ADV NEUR IN, V16, P321; Zhu Xiaojin., 2003, P ICLR, P912	45	46	49	1	33	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2013	103	3					306	325		10.1007/s11263-012-0602-z	http://dx.doi.org/10.1007/s11263-012-0602-z			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	155WJ		Green Submitted			2022-12-18	WOS:000319778800002
J	Albarelli, A; Rodola, E; Torsello, A				Albarelli, Andrea; Rodola, Emanuele; Torsello, Andrea			Imposing Semi-Local Geometric Constraints for Accurate Correspondences Selection in Structure from Motion: A Game-Theoretic Perspective	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Inlier selection; Game-Theory; Structure from Motion	CAMERA CALIBRATION; IMAGE; MODELS; SHAPE	Most Structure from Motion pipelines are based on the iterative refinement of an initial batch of feature correspondences. Typically this is performed by selecting a set of match candidates based on their photometric similarity; an initial estimate of camera intrinsic and extrinsic parameters is then computed by minimizing the reprojection error. Finally, outliers in the initial correspondences are filtered by enforcing some global geometric property such as the epipolar constraint. In the literature many different approaches have been proposed to deal with each of these three steps, but almost invariably they separate the first inlier selection step, which is based only on local image properties, from the enforcement of global geometric consistency. Unfortunately, these two steps are not independent since outliers can lead to inaccurate parameter estimation or even prevent convergence, leading to the well known sensitivity of all filtering approaches to the number of outliers, especially in the presence of structured noise, which can arise, for example, when the images present several repeated patterns. In this paper we introduce a novel stereo correspondence selection scheme that casts the problem into a Game-Theoretic framework in order to guide the inlier selection towards a consistent subset of correspondences. This is done by enforcing geometric constraints that do not depend on full knowledge of the motion parameters but rather on some semi-local property that can be estimated from the local appearance of the image features. The practical effectiveness of the proposed approach is confirmed by an extensive set of experiments and comparisons with state-of-the-art techniques.	[Albarelli, Andrea; Rodola, Emanuele; Torsello, Andrea] Univ Ca Foscari Venezia, Dipartimento Sci Ambientali, Venice, Italy	Universita Ca Foscari Venezia	Albarelli, A (corresponding author), Univ Ca Foscari Venezia, Dipartimento Sci Ambientali, Venice, Italy.	albarelli@unive.it; rodola@dsi.unive.it; torsello@unive.it	Torsello, Andrea/K-6352-2016; Rodola, Emanuele/M-4137-2016	Torsello, Andrea/0000-0001-9189-4924; Albarelli, Andrea/0000-0002-3659-5099; Rodola, Emanuele/0000-0003-0091-7241	European Commission, under FET [213250]	European Commission, under FET	We acknowledge the financial support of the Future and Emerging Technology (FET) Programme within the Seventh Framework Programme for Research of the European Commission, under FET-Open project SIMBAD grant no. 213250.	AGGARWAL JK, 1975, IEEE T COMPUT, V24, P966, DOI 10.1109/T-C.1975.224102; Albarelli A., 2009, P IEEE INT C COMP VI; Albarelli A., 2010, P 3D DAT PROC VIS TR; [Anonymous], 2006, CVPR 06 P IEEE COMP; Bay H., 2006, EUR C COMP VIS ECCV, P404, DOI [10.1007/11744023_32, DOI 10.1007/11744023_32]; Beardsley PA, 1997, INT J COMPUT VISION, V23, P235, DOI 10.1023/A:1007923216416; Bosch A, 2007, IEEE I CONF COMP VIS, P1863; Brown M, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P56, DOI 10.1109/3DIM.2005.81; Fermuller C., 1999, IEEE COMP SOC C COMP, V2, P637; Fitzgibbon A. W., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P311, DOI 10.1007/BFb0055675; Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161; Harris C. G., 1988, P 4 ALV VIS C, V15, P10, DOI [10.5244/C.2.23, DOI 10.5244/C.2.23]; HARTLEY RI, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1064; Heyden A, 1999, IMAGE VISION COMPUT, V17, P981, DOI 10.1016/S0262-8856(99)00002-5; Ke Y, 2004, PROC CVPR IEEE, P506; Levenberg K., 1944, Q APPL MATH, V2, P164, DOI 10.1090/qam/10666; LOWE, 2003, INT J COMPUT VISION, V20, P91; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mikolajczyk K, 2002, LECT NOTES COMPUT SC, V2350, P128, DOI 10.1007/3-540-47969-4_9; Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730; Pollefeys M., 1999, 3D DIG IM MOD INT C; Sarfraz AS, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P235; Seitz S.M., 2006, P IEEE COMPUTER SOC, P519; Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; Sturm P., 1996, LECT NOTES COMPUTER, V1065, P709, DOI [DOI 10.1007/3-540-61123-1, 10.1007/3-540-61123-1_183, DOI 10.1007/3-540-61123-1_183]; TAYLOR PD, 1978, MATH BIOSCI, V40, P145, DOI 10.1016/0025-5564(78)90077-9; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torr P., 1998, ICCV 98; Triggs B., 2000, LECT NOTES COMPUTER, V1883, P298, DOI [DOI 10.1007/3-540-44480-7, DOI 10.1007/3-540-44480-7_21]; TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109; Vedaldi A., 2008, VLFEAT OPEN PORTABLE; Vergauwen M, 2006, MACH VISION APPL, V17, P411, DOI 10.1007/s00138-006-0027-1; Weibull J.W., 1997, EVOLUTIONARY GAME TH; WEINSHALL D, 1995, IEEE T PATTERN ANAL, V17, P512, DOI 10.1109/34.391392; WENG JY, 1993, IEEE T PATTERN ANAL, V15, P864, DOI 10.1109/34.232074; WENG JY, 1992, IEEE T PATTERN ANAL, V14, P965, DOI 10.1109/34.159901; ZHANG ZY, 1995, IEEE T PATTERN ANAL, V17, P1129; ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4	42	46	46	0	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2012	97	1					36	53		10.1007/s11263-011-0432-4	http://dx.doi.org/10.1007/s11263-011-0432-4			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	897SD		Green Submitted			2022-12-18	WOS:000300675300004
J	Opelt, A; Pinz, A; Zisserman, A				Opelt, Andreas; Pinz, Axel; Zisserman, Andrew			Learning an alphabet of shape and appearance for multi-class object detection	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	24th Conference on Computer Vision and Pattern Recognition	JUN 17-22, 2006	New York, NY			generic object recognition; object categorization; category representation; visual alphabet; Boosting	RECOGNITION; FEATURES	We present a novel algorithmic approach to object categorization and detection that can learn category specific detectors, using Boosting, from a visual alphabet of shape and appearance. The alphabet itself is learnt incrementally during this process. The resulting representation consists of a set of category-specific descriptors-basic shape features are represented by boundary-fragments, and appearance is represented by patches-where each descriptor in combination with centroid vectors for possible object centroids (geometry) forms an alphabet entry. Our experimental results highlight several qualities of this novel representation. First, we demonstrate the power of purely shape-based representation with excellent categorization and detection results using a Boundary-Fragment-Model (BFM), and investigate the capabilities of such a model to handle changes in scale and viewpoint, as well as intra- and inter-class variability. Second, we show that incremental learning of a BFM for many categories leads to a sub-linear growth of visual alphabet entries by sharing of shape features, while this generalization over categories at the same time often improves categorization performance (over independently learning the categories). Finally, the combination of basic shape and appearance (boundary-fragments and patches) features can further improve results. Certain feature types are preferred by certain categories, and for some categories we achieve the lowest error rates that have been reported so far.	[Opelt, Andreas; Pinz, Axel] Graz Univ Technol, Inst Elect Measurement & Measurement Signal Proc, Graz, Austria; [Zisserman, Andrew] Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England	Graz University of Technology; University of Oxford	Pinz, A (corresponding author), Graz Univ Technol, Inst Elect Measurement & Measurement Signal Proc, Graz, Austria.	andreas.opelt@gmail.com; axel.pinz@tugraz.at; az@robots.ox.ac.uk						Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108; Amit Y, 2004, IEEE T PATTERN ANAL, V26, P1606, DOI 10.1109/TPAMI.2004.111; Amores J, 2005, PROC CVPR IEEE, P769; [Anonymous], 2003, P ICCV; [Anonymous], P ICCV; Bar-Hillel A, 2005, PROC CVPR IEEE, P702; Bart E, 2005, PROC CVPR IEEE, P672; Bernstein EJ, 2005, PROC CVPR IEEE, P734; BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107; BREU H, 1995, IEEE T PATTERN ANAL, V17, P529, DOI 10.1109/34.391389; Caputo B, 2004, INT C PATT RECOG, P132, DOI 10.1109/ICPR.2004.1334079; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Crandall D, 2005, PROC CVPR IEEE, P10; Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Deselaers T, 2005, PROC CVPR IEEE, P157; EPSTEIN B, 2005, P ICCV, V1, P220; EVERINGHAM M, 2005, LECT NOTES ARTIFICIA; FAN X, 2005, P CVPR, V1, P716; Fei-Fei L, 2004, P CVPR WORKSH GEN MO; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Fergus R, 2007, INT J COMPUT VISION, V71, P273, DOI 10.1007/s11263-006-8707-x; Fergus R, 2005, PROC CVPR IEEE, P380; Fergus R, 2004, LECT NOTES COMPUT SC, V3021, P242; Fergus R, 2003, PROC CVPR IEEE, P264; Ferrari V, 2006, LECT NOTES COMPUT SC, V3953, P14, DOI 10.1007/11744078_2; FERRARI V, 2004, P EUR C COMP VIS, P40; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Friedman J., 1998, ADDITIVE LOGISTIC RE; GAVRILA DM, 1999, P IEEE INT C COMP VI, P87, DOI DOI 10.1109/ICCV.1999.791202; Jurie F, 2004, PROC CVPR IEEE, P90; Kumar M. P., 2004, P BMVC; Leibe B, 2004, LECT NOTES COMPUT SC, V3175, P145; LEIBE B, 2004, ECCV WORKSH STAT LEA, P17; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Magee DR, 2002, IMAGE VISION COMPUT, V20, P581, DOI 10.1016/S0262-8856(02)00047-1; Marszalek M., 2006, P CVPR; MIKOLAJCZYK K, 2006, P CVPR; MUTCH J, 2006, P CVPR; NISTR D, 2006, P CVPR; OMMER B, 2006, P ECCV, V3, P316; Opelt A, 2004, LECT NOTES COMPUT SC, V3022, P71; OPELT A, 2006, P BMVC SEPT, V1, P117; OPELT A, 2006, PATTERN ANAL MACHINE, V28; OPELT A, 2006, P IEEE C COMP VIS PA, V1, P3; Opelt A, 2006, LECT NOTES COMPUT SC, V3952, P575; Quinn PC, 2001, J EXP CHILD PSYCHOL, V79, P78, DOI 10.1006/jecp.2000.2609; Sali E., 1999, BMVC99. Proceedings of the 10th British Machine Vision Conference, P203; Seemann E., 2006, P CVPR; Serre T, 2005, P CVPR; Shotton J, 2005, IEEE I CONF COMP VIS, P503; SHOTTON J, 2006, P EUR C COMP VIS, V1, P1, DOI DOI 10.1007/11744023_; THOMAS A, 2006, P CVPR; Thureson J, 2004, LECT NOTES COMPUT SC, V3022, P518; Torralba A., 2004, P CVPR; Tu ZW, 2005, IEEE I CONF COMP VIS, P1589; Vidal-Naquet M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P281; Wang G, 2006, P CVPR; WILLIAMS CKI, 2006, EDIINFRR0719 U ED SC; Winn J, 2005, IEEE I CONF COMP VIS, P1800; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; Zhang WS, 2005, IEEE I C EMBED SOFTW, P66	62	46	50	0	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	OCT	2008	80	1					16	44		10.1007/s11263-008-0139-3	http://dx.doi.org/10.1007/s11263-008-0139-3			29	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	344CB		Green Published, Bronze			2022-12-18	WOS:000258901900003
J	Zickler, T; Mallick, SP; Kriegman, DJ; Belhumeur, PN				Zickler, Todd; Mallick, Satya P.; Kriegman, David J.; Belhumeur, Peter N.			Color subspaces as photometric invariants	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						photometric invariants; shape invariants; color spaces; dichromatic reflection; multispectral imaging; surface reconstruction; photometric stereo; shape from shading; stereo; color-based segmentation; color-based optical flow	ILLUMINANT ESTIMATION; SPECULAR SURFACES; STEREO; SHAPE; REFLECTANCE; IMAGE; CONSTANCY; CHROMATICITY; HIGHLIGHTS	Complex reflectance phenomena such as specular reflections confound many vision problems since they produce image 'features' that do not correspond directly to intrinsic surface properties such as shape and spectral reflectance. A common approach to mitigate these effects is to explore functions of an image that are invariant to these photometric events. In this paper we describe a class of such invariants that result from exploiting color information in images of dichromatic surfaces. These invariants are derived from illuminant-dependent 'subspaces' of RGB color space, and they enable the application of Lambertian-based vision techniques to a broad class of specular, non-Lambertian scenes. Using implementations of recent algorithms taken from the literature, we demonstrate the practical utility of these invariants for a wide variety of applications, including stereo, shape from shading, photometric stereo, material-based segmentation, and motion estimation.	[Zickler, Todd] Harvard Univ, Cambridge, MA 02138 USA; [Mallick, Satya P.; Kriegman, David J.] Univ Calif San Diego, San Diego, CA 92103 USA; [Belhumeur, Peter N.] Columbia Univ, New York, NY 10027 USA	Harvard University; University of California System; University of California San Diego; Columbia University	Zickler, T (corresponding author), Harvard Univ, 33 Oxford St, Cambridge, MA 02138 USA.	zickler@eecs.harvard.edu						Ahmed A.H., 2006, P IEEE C COMP VIS PA, V2, P1817; BAKSHI S, 1994, IEEE IMAGE PROC, P130, DOI 10.1109/ICIP.1994.413545; Barnard K, 2002, IEEE T IMAGE PROCESS, V11, P985, DOI 10.1109/TIP.2002.802529; BARNARD K, 2002, IEEE T PATTERN ANAL, V11; Barron J, 2002, INT C PATT RECOG, P251, DOI 10.1109/ICPR.2002.1047444; Barsky S, 2003, IEEE T PATTERN ANAL, V25, P1239, DOI 10.1109/TPAMI.2003.1233898; Barsky S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P600, DOI 10.1109/ICCV.2001.937681; Bhat DN, 1998, INT J COMPUT VISION, V26, P91, DOI 10.1023/A:1007940725322; Birchfield S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1073, DOI 10.1109/ICCV.1998.710850; Black M. J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P231, DOI 10.1109/ICCV.1993.378214; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Boykov Y, 1998, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.1998.698673; Brainard DH, 1997, J OPT SOC AM A, V14, P1393, DOI 10.1364/JOSAA.14.001393; BRELSTAFF G, 1988, P IEEE INT C COMP VI, P297; COLEMAN EN, 1982, COMPUT VISION GRAPH, V18, P309, DOI 10.1016/0146-664X(82)90001-6; DAVIS J, 2005, P IEEE INT C COMP VI, V1; Davis JE, 2005, IEEE I CONF COMP VIS, P436; Finayson GD, 2001, IEEE T PATTERN ANAL, V23, P1209, DOI 10.1109/34.969113; FINLAYSON G, 2001, P EUR C COMP VIS, V1, P342; Finlayson GD, 1996, IEEE T PATTERN ANAL, V18, P1034, DOI 10.1109/34.541413; GERSHON R, 1987, THESIS U TORONTO; GROSSBERG M, 2003, P IEEE WORKSH COL PH; HEALEY G, 1989, J OPT SOC AM A, V6, P920, DOI 10.1364/JOSAA.6.000920; HERTZMANN A, 2003, P IEEE C COMP VIS PA; Hordley SD, 2006, J OPT SOC AM A, V23, P1008, DOI 10.1364/JOSAA.23.001008; HORDLEY SD, 2002, P EUR C COMP VIS, P823; IKEUCHI K, 1981, IEEE T PATTERN ANAL, V3, P661, DOI 10.1109/TPAMI.1981.4767167; Jensen HW, 2001, COMP GRAPH, P511, DOI 10.1145/383259.383319; Jin H., 2004, P IEEE C COMP VIS PA; Jin HL, 2005, INT J COMPUT VISION, V63, P175, DOI 10.1007/s11263-005-6876-7; KIM J, 2003, VISUAL CORRES USING; KLINKER GJ, 1988, INT J COMPUT VISION, V2, P7, DOI 10.1007/BF00836279; Koudelka ML, 2001, PROC CVPR IEEE, P568; LEE HC, 1986, J OPT SOC AM A, V3, P1694, DOI 10.1364/JOSAA.3.001694; LEE HC, 1990, IEEE T PATTERN ANAL, V12, P402, DOI 10.1109/34.50626; Lehmann TM, 2001, J OPT SOC AM A, V18, P2679, DOI 10.1364/JOSAA.18.002679; LI Y, 2002, ICPR 2002, V3, P573; LIM J, 2005, P IEEE INT C COMP VI; LIN S, 2002, EUR C COMP VIS, P210; LU J, 1999, INT J COMPUT VISION, V32, P1; Magda S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P391, DOI 10.1109/ICCV.2001.937652; MALLICK SP, 2006, P EUR C COMP VIS; Narasimhan SG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1387; Nayar SK, 1997, INT J COMPUT VISION, V21, P163, DOI 10.1023/A:1007937815113; Nayar SK, 1996, INT J COMPUT VISION, V17, P219, DOI 10.1007/BF00128232; NAYAR SK, 1990, IEEE T ROBOTIC AUTOM, V6, P418, DOI 10.1109/70.59367; Park JB, 2003, P SOC PHOTO-OPT INS, V5267, P163, DOI 10.1117/12.519400; RAGHEB H, 2001, P BRIT MACH VIS C, P541; Rosenberg C, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P239, DOI 10.1109/ICCV.2001.937524; Sapiro G, 1999, IEEE T PATTERN ANAL, V21, P1210, DOI 10.1109/34.809114; SATO Y, 1994, J OPT SOC AM A, V11, P2990, DOI 10.1364/JOSAA.11.002990; SCHLUNS K, 1993, P 7 INT C IM AN PROC, P505; SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409; Silver W, 1980, THESIS MIT; TAGARE HD, 1991, IEEE T PATTERN ANAL, V13, P133, DOI 10.1109/34.67643; TAN P, 2006, P IEEE C COMP VIS PA; Tan RT, 2004, J OPT SOC AM A, V21, P321, DOI 10.1364/JOSAA.21.000321; Tan RT, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P870; Tian YL, 1997, J OPT SOC AM A, V14, P397, DOI 10.1364/JOSAA.14.000397; Tominaga S, 2002, P IEEE, V90, P42, DOI 10.1109/5.982404; TOMINAGA S, 1989, J OPT SOC AM A, V6, P576, DOI 10.1364/JOSAA.6.000576; Tsumura N, 2003, ACM T GRAPHIC, V22, P770, DOI 10.1145/882262.882344; Tu P, 2003, PROC CVPR IEEE, P541; van de Weijer J, 2004, IEEE IMAGE PROC, P1835; WOLFF LB, 1991, IEEE T PATTERN ANAL, V13, P635, DOI 10.1109/34.85655; WOLFF LB, 1994, J OPT SOC AM A, V11, P3069, DOI 10.1364/JOSAA.11.003069; Woodham R. J., 1978, Proceedings of the Society of Photo-Optical Instrumentation Engineers, vol.155. Image Understanding Systems and Industrial Applications, P136; Yang RG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P576, DOI 10.1109/ICCV.2003.1238399; YOON K, 2006, P AS C COMP VIS, P761; Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70; Zhang L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P618, DOI 10.1109/ICCV.2003.1238405; ZHENG QF, 1991, IEEE T PATTERN ANAL, V13, P680, DOI 10.1109/34.85658; Zickler T, 2002, LECT NOTES COMPUT SC, V2352, P869; Zickler TE, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1411	74	46	50	0	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2008	79	1					13	30		10.1007/s11263-007-0087-3	http://dx.doi.org/10.1007/s11263-007-0087-3			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	291JQ		Green Submitted			2022-12-18	WOS:000255193500002
J	Wang, HC; Ahuja, N				Wang, Hongcheng; Ahuja, Narendra			A tensor approximation approach to dimensionality reduction	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						rank-R tensor approximation; multilinear analysis; dimensionality reduction; object recognition		Dimensionality reduction has recently been extensively studied for computer vision applications. We present a novel multilinear algebra based approach to reduced dimensionality representation of multidimensional data, such as image ensembles, video sequences and volume data. Before reducing the dimensionality we do not convert it into a vector as is done by traditional dimensionality reduction techniques like PCA. Our approach works directly on the multidimensional form of the data (matrix in 2D and tensor in higher dimensions) to yield what we call a Datum-as-Is representation. This helps exploit spatio-temporal redundancies with less information loss than image-as-vector methods. An efficient rank-R tensor approximation algorithm is presented to approximate higher-order tensors. We show that rank-R tensor approximation using Datum-as-Is representation generalizes many existing approaches that use image-as-matrix representation, such as generalized low rank approximation of matrices (GLRAM) (Ye, Y. in Mach. Learn. 61: 167-191, 2005), rank-one decomposition of matrices (RODM) (Shashua, A., Levin, A. in CVPR'01: Proceedings of the 2001 IEEE computer society conference on computer vision and pattern recognition, p. 42, 2001) and rank-one decomposition of tensors (RODT) (Wang, H., Ahuja, N. in ICPR '04: ICPR '04: Proceedings of the 17th international conference on pattern recognition (ICPR'04), vol. 1, pp. 44-47, 2004). Our approach yields the most compact data representation among all known image-as-matrix methods. In addition, we propose another rank-R tensor approximation algorithm based on slice projection of third-order tensors, which needs fewer iterations for convergence for the important special case of 2D image ensembles, e. g., video. We evaluated the performance of our approach vs. other approaches on a number of datasets with the following two main results. First, for a fixed compression ratio, the proposed algorithm yields the best representation of image ensembles visually as well as in the least squares sense. Second, proposed representation gives the best performance for object classification.	[Wang, Hongcheng] UTRC, Each Hartford, CT USA; [Ahuja, Narendra] UIUC, Urbana, IL USA	University of Illinois System; University of Illinois Urbana-Champaign	Wang, HC (corresponding author), UTRC, Each Hartford, CT USA.	wanghc@vision.ai.uiuc.edu; ahuja@vision.ai.uiuc.edu						Barlow HB, 1989, NEURAL COMPUT, V1, P295, DOI 10.1162/neco.1989.1.3.295; COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9; De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1324, DOI 10.1137/S0895479898346995; Hong W, 2005, IEEE I CONF COMP VIS, P764; JUTTEN C, 1991, SIGNAL PROCESS, V24, P1, DOI 10.1016/0165-1684(91)90079-X; Kofidis E, 2002, SIAM J MATRIX ANAL A, V23, P863, DOI 10.1137/S0895479801387413; KROONENBERG P, 1983, 3 MODE PRINICPAL COM; LATHAUWER LD, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI DOI 10.1137/S0895479896305696; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; SHASHUA A, 2001, CVPR, P42; SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519; Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Vasilescu MAO, 2003, PROC CVPR IEEE, P93; VASILESCU MAO, 2002, ECCV, P447; WANG H, 2005, CVPR 05, V2, P346; WANG H, 2004, INT C PATTERN RECOGN, V1, P44; Wang HC, 2005, ACM T GRAPHIC, V24, P527, DOI 10.1145/1073204.1073224; Xu D, 2005, PROC CVPR IEEE, P203; Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097; Ye J., 2004, P 10 ACM SIGKDD INT, P354, DOI DOI 10.1145/1014052.1014092; Ye JP, 2005, MACH LEARN, V61, P167, DOI 10.1007/s10994-005-3561-6	22	46	60	1	16	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2008	76	3					217	229		10.1007/s11263-007-0053-0	http://dx.doi.org/10.1007/s11263-007-0053-0			13	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	255VI					2022-12-18	WOS:000252685500001
J	Ran, Y; Weiss, I; Zheng, QF; Davis, LS				Ran, Yang; Weiss, Isaac; Zheng, Qinfen; Davis, Larry S.			Pedestrian detection via periodic motion analysis	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	3rd Workshop on Object Tracking and Classification Beyond the Visible Spectrum	JUN 22, 2006	New York, NY	IEEE		pedestrian detection; periodic motion; frequency estimation; cyclic gait pattern; phase-locked loop	SPECIAL SECTION; RECOGNITION	We describe algorithms for detecting pedestrians in videos acquired by infrared (and color) sensors. Two approaches are proposed based on gait. The first employs computationally efficient periodicity measurements. Unlike other methods, it estimates a periodic motion frequency using two cascading hypothesis testing steps to filter out non-cyclic pixels so that it works well for both radial and lateral walking directions. The extraction of the period is efficient and robust with respect to sensor noise and cluttered background. In order to integrate shape and motion, we convert the cyclic pattern into a binary sequence by Maximal Principal Gait Angle (MPGA) fitting in the second method. It does not require alignment and continuously estimates the period using a Phase-locked Loop. Both methods are evaluated by experimental results that measure performance as a function of size, movement direction, frame rate and sequence length.	Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA	University System of Maryland; University of Maryland College Park	Ran, Y (corresponding author), Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA.	rany@cfar.umd.edu; weiss@cfar.umd.edu; qinfen@cfar.umd.edu; lsd@cfar.umd.edu	ZHENG, Qin/T-2925-2019					ADELSON E, 1985, J OPTICAL SOC AM A, V2; Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744; ALLMEN MC, 1991, 1040 U WISC MAD COMP; BLANCHARD A, 1976, PHASE LOCKED LOOPS A; Boyd JE, 2004, COMPUT VIS IMAGE UND, V96, P35, DOI 10.1016/j.cviu.2004.04.004; Broggi A, 2000, PROCEEDINGS OF THE IEEE INTELLIGENT VEHICLES SYMPOSIUM 2000, P215, DOI 10.1109/IVS.2000.898344; Collins RT, 2000, IEEE T PATTERN ANAL, V22, P745, DOI 10.1109/TPAMI.2000.868676; Curiel DT, 2000, MOL THER, V1, P3, DOI 10.1006/mthe.1999.0004; Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681; Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726; Fang YJ, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, PROCEEDINGS, P505, DOI 10.1109/IVS.2003.1212963; Fukunaga Keinosuke, 2013, INTRO STAT PATTERN R, P4; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; HOGG D, 1983, IMAGE VISION COMPUT, V1, P5, DOI DOI 10.1016/0262-8856(83)90003-3; LIPTON J, 1998, WORKSH APPL COMP VIS, P8; LITTLE JJ, 1998, J COMPUTER VISION RE, V1, P24; Liu F, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P376, DOI 10.1109/ICCV.1998.710746; Maybank S, 2000, INT J COMPUT VISION, V37, P173, DOI 10.1023/A:1008151520284; NANDA H, 2002, IEEE INT VEH S VERS; NIYOGI SA, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P469, DOI 10.1109/CVPR.1994.323868; OREN M, 2003, IEEE C COMP VIS PATT, P193; Pai CJ, 2004, PATTERN RECOGN, V37, P1025, DOI 10.1016/j.patcog.2003.10.005; Papageorgiou C., 1998, P INT VEH, P241; Phillips PJ, 2002, INT C PATT RECOG, P385, DOI 10.1109/ICPR.2002.1044731; Polana R, 1997, INT J COMPUT VISION, V23, P261, DOI 10.1023/A:1007975200487; Quinn B.G., 2001, CA ST PR MA; ROHR K, 1994, CVGIP-IMAG UNDERSTAN, V59, P94, DOI 10.1006/ciun.1994.1006; Seitz SM, 1997, INT J COMPUT VISION, V25, P231, DOI 10.1023/A:1007928103394; TSAI PS, 1994, PATTERN RECOGNITION, V27; Viola P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P734; Wang FL, 2003, CHINESE LAW GOV, V36, P3, DOI 10.2753/CLG0009-460936043; Zhao L, 2000, IEEE T INTELL TRANSP, V1, P148, DOI 10.1109/6979.892151; ZHENG Q, 1991, IEEE INT C IM PROC, P218; Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152; [No title captured]	35	46	46	0	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	FEB	2007	71	2					143	160		10.1007/s11263-006-8575-4	http://dx.doi.org/10.1007/s11263-006-8575-4			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	098DN					2022-12-18	WOS:000241501300003
J	Nayar, SK; Branzoi, V; Boult, TE				Nayar, Shree K.; Branzoi, Vlad; Boult, Terry E.			Programmable imaging: Towards a flexible camera	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	IEEE-Computer-Society Conference on Computer Vision and Pattern Recognition	JUN, 2004	Washington, DC	IEEE Comp Soc		programmable imaging; flexible imaging; micro-mirror array; digital micro-mirror device; MEMS; adaptive optics; high dynamic range imaging; optical processing; feature detection; object recognition; field of view; resolution; multi-viewpoint imaging; stereo; catadioptric imaging; wide-angle imaging; purposive camera		In this paper, we introduce the notion of a programmable imaging system. Such an imaging system provides a human user or a vision system significant control over the radiometric and geometric characteristics of the system. This flexibility is achieved using a programmable array of micro-mirrors. The orientations of the mirrors of the array can be controlled with high precision over space and time. This enables the system to select and modulate rays from the scene's light field based on the needs of the application at hand. We have implemented a programmable imaging system that uses a digital micro-mirror device (DMD), which is used in digital light processing. Although the mirrors of this device can only be positioned in one of two states, we show that our system can be used to implement a wide variety of imaging functions, including, high dynamic range imaging, feature detection, and object recognition. We also describe how a micro-mirror array that allows full control over the orientations of its mirrors can be used to instantly change the field of view and resolution characteristics of the imaging system. We conclude with a discussion on the implications of programmable imaging for computer vision.	Columbia Univ, Dept Comp Sci, New York, NY 10027 USA; Univ Colorado, Dept Comp Sci, Colorado Springs, CO 80933 USA	Columbia University; University of Colorado System; University of Colorado at Colorado Springs	Nayar, SK (corresponding author), Columbia Univ, Dept Comp Sci, 450 Mudd Hall, New York, NY 10027 USA.	nayar@cs.columbia.edu; vlad@cs.columbia.edu; tboult@cs.uccs.edu	Boult, Terrance E./AAT-2134-2021	Boult, Terrance E./0000-0001-5007-2529				Castracane J, 1999, P SOC PHOTO-OPT INS, V3633, P234, DOI 10.1117/12.349332; Christensen MP, 2002, APPL OPTICS, V41, P6093, DOI 10.1364/AO.41.006093; Dudley D., 2003, EMERGING DIGITAL MIC; Ginosar R, 1992, United States Patent, Patent No. 5144442; Goodman J. W., 2005, MCGRAW HILL PHYS QUA; Grossberg MD, 2005, INT J COMPUT VISION, V61, P119, DOI 10.1023/B:VISI.0000043754.56350.10; HICKS R, 2003, COMMUNICATION; Hornbeck L.J., 1989, P SOC PHOTO-OPT INS, V1150, P86, DOI 10.1117/12.962188; HORNBECK LJ, 1995, MICROMACHINED DEVICE, V2642; HORNBECK LJ, 1988, SPAT LIGHT MOD APPS, V8; Kang SB, 2003, ACM T GRAPHIC, V22, P319, DOI 10.1145/882262.882270; Kearney KJ, 1998, P SOC PHOTO-OPT INS, V3292, P81, DOI 10.1117/12.305493; MALBET F, 1995, PUBL ASTRON SOC PAC, V107, P386, DOI 10.1086/133563; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; Nayar SK, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1168; Nayar SK, 2000, PROC CVPR IEEE, P472, DOI 10.1109/CVPR.2000.855857; NAYAR SK, 2002, P ECCV, V4, P636; Smith W. J., 1966, MODERN OPTICAL ENG; TURK M, 1991, P IEEE C COMP VIS PA, P586, DOI DOI 10.1109/CVPR.1991.139758; Tyson R. K., 1998, PRINCIPLES ADAPTIVE	20	46	50	0	15	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	OCT	2006	70	1					7	22		10.1007/s11263-005-3102-6	http://dx.doi.org/10.1007/s11263-005-3102-6			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	074QY		Green Submitted			2022-12-18	WOS:000239828100002
J	Nishino, K; Nayar, SK				Nishino, Ko; Nayar, Shree K.			Corneal imaging system: Environment from eyes	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	IEEE-Computer-Society Conference on Computer Vision and Pattern Recognition	JUN, 2004	Washington, DC	IEEE Comp Soc		eye; cornea; catadioptric imaging system; stereo; panorama; retinal projection	RECOGNITION	This paper provides a comprehensive analysis of exactly what visual information about the world is embedded within a single image of an eye. It turns out that the cornea of an eye and a camera viewing the eye form a catadioptric imaging system. We refer to this as a corneal imaging system. Unlike a typical catadioptric system, a corneal one is flexible in that the reflector (cornea) is not rigidly attached to the camera. Using a geometric model of the cornea based on anatomical studies, its 3D location and orientation can be estimated from a single image of the eye. Once this is done, a wide-angle view of the environment of the person can be obtained from the image. In addition, we can compute the projection of the environment onto the retina with its center aligned with the gaze direction. This foveated retinal image reveals what the person is looking at. We present a detailed analysis of the characteristics of the corneal imaging system including field of view, resolution and locus of viewpoints. When both eyes of a person are captured in an image, we have a stereo corneal imaging system. We analyze the epipolar geometry of this stereo system and show how it can be used to compute 3D structure. The framework we present in this paper for interpreting eye images is passive and non-invasive. It has direct implications for several fields including visual recognition, human-machine interfaces, computer graphics and human affect studies.	Drexel Univ, Dept Comp Sci, Philadelphia, PA 19104 USA; Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Drexel University; Columbia University	Nishino, K (corresponding author), Drexel Univ, Dept Comp Sci, 3141 Chestnut St, Philadelphia, PA 19104 USA.	kon@cs.drexel.edu; nayar@cs.columbia.edu						Baker S, 1999, INT J COMPUT VISION, V35, P175, DOI 10.1023/A:1008128724364; Baker TY, 1943, P PHYS SOC, V55, P0361, DOI 10.1088/0959-5309/55/5/302; BLANZ V, 1999, ACM SIGGRAPH 99; BOLT RA, 1982, ACM CHI, P360; BURKHARD DG, 1973, J OPT SOC AM, V63, P299, DOI 10.1364/JOSA.63.000299; Cornbleet S., 1984, MICROWAVE OPTICAL RA; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676; Davson H., 1990, PHYSL EYE; Debevec P, 2000, COMP GRAPH, P145, DOI 10.1145/344779.344855; Debevec P., 1998, ANN C SERIES, P189; Ebisawa Y, 1998, IEEE T INSTRUM MEAS, V47, P948, DOI 10.1109/19.744648; Ekman P., 1997, WHAT FACE REVEALS; Flom L., 1987, U.S. Patent, Patent No. [4641349, 4,641,349]; HALSTEAD MA, 1996, ACM SIGGRAPH 96, P335; HUTCHINSON TE, 1989, IEEE T SYST MAN CYB, V19, P1527, DOI 10.1109/21.44068; IKEUCHI K, 1994, IEEE T ROBOTIC AUTOM, V10, P368, DOI 10.1109/70.294211; Jacob R. J. K., 1990, SIGCHI Bulletin, P11; Kang ShaoZhong, 1997, Transactions of the Chinese Society of Agricultural Engineering, V13, P1; KAUFMAN PL, 2003, ADLER PHYSL EYE CLIN; Marschner SR, 1997, FIFTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS, AND APPLICATIONS, P262; NAYAR SK, 1988, SPIE OPTICS ILLUMINA, V2; Nene SA, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1087, DOI 10.1109/ICCV.1998.710852; Nishino K, 2004, PROC CVPR IEEE, P444; Nishino K, 2004, ACM T GRAPHIC, V23, P704, DOI 10.1145/1015706.1015783; OHNO, 2000, P S ETRA, P125; PAJDLA T, 2000, PANORAMIC VISION SEN; STEIN CP, 1995, ICCV, P230; Stiefelhagen R., 1997, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V6, P193, DOI 10.1142/S0218213097000116; Swaminathan R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P2, DOI 10.1109/ICCV.2001.937581; Tan KH, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P191, DOI 10.1109/ACV.2002.1182180; Tomkins Silvan S., 1992, AFFECT IMAGERY CONSC; Tsumura N, 2003, ELEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING - SYSTEMS, TECHNOLOGIES, APPLICATIONS, P77; VONHELMHOLTZ H, 1909, PHYSL OPTICS, V1; VONHELMHOLTZ H, 1909, PHYSL OPTICS, V2; Wang JG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P136; Wasserman S., 1994, SOCIAL NETWORK ANAL, DOI DOI 10.1017/CBO9780511815478; WESTHEIMER G, 1980, MED PHYSL, V1, P481; WOLFF LB, 1991, IEEE T PATTERN ANAL, V13, P635, DOI 10.1109/34.85655; WOLFF LB, 1990, IEEE T PATTERN ANAL, V12, P1059, DOI 10.1109/34.61705; XU LQ, 1998, BMVC, P58; YOUNG LR, 1975, BEHAV RES METH INSTR, V7, P397, DOI 10.3758/BF03201553	42	46	56	1	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	OCT	2006	70	1					23	40		10.1007/s11263-006-6274-9	http://dx.doi.org/10.1007/s11263-006-6274-9			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	074QY					2022-12-18	WOS:000239828100003
J	Bartoli, A; Sturm, P				Bartoli, A; Sturm, P			The 3D line motion matrix and alignment of line reconstructions	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						lines; reconstruction; motion		We study the problem of aligning two 3D line reconstructions in projective, affine, metric or Euclidean space. We introduce the 6 x 6 3D line motion matrix that acts on Plucker coordinates. We characterize its algebraic properties and its relation to the usual 4 x 4 point motion matrix, and propose various methods for estimating 3D motion from line correspondences, based on cost functions defined in images or 3D space. We assess the quality of the different estimation methods using simulated data and real images.	INRIA Rhone Alpes, F-38334 Saint Ismier, France		Bartoli, A (corresponding author), INRIA Rhone Alpes, 655 Av Europe, F-38334 Saint Ismier, France.	Adrien.Bartoli@inria.fr						ANDREFF N, 2000, INT C ROB AUT SAN FR; Bartoli A, 2001, PROC CVPR IEEE, P287; BUCHANAN T, 1992, P 2 EUR C COMP VIS S, P730; CANNY JF, 1986, PAMI, V8, P6, DOI DOI 10.1109/TPAMI.1986.4767851; Csurka G, 1999, COMPUT VIS IMAGE UND, V75, P260, DOI 10.1006/cviu.1999.0782; Demirdjian D, 2000, COMPUT VIS IMAGE UND, V78, P53, DOI 10.1006/cviu.1999.0827; Devernay F, 1996, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.1996.517084; FAUGERAS O, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P951, DOI 10.1109/ICCV.1995.466832; FAUGERAS O, 1987, P INT WORKSH MACH VI; Gill P. E., 1981, PRACTICAL OPTIMIZATI; Hager GD, 1998, COMPUT VIS IMAGE UND, V69, P23, DOI 10.1006/cviu.1997.0586; Hartley RI, 1997, INT J COMPUT VISION, V22, P125, DOI 10.1023/A:1007936012022; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Horaud R, 2000, IEEE T PATTERN ANAL, V22, P1446, DOI 10.1109/34.895977; HORAUD R, 1997, IEEE T ROBOTICS AUTO; HORN BKP, 1988, J OPT SOC AM A, V5, P1127, DOI 10.1364/JOSAA.5.001127; Liebowitz D, 1998, PROC CVPR IEEE, P482, DOI 10.1109/CVPR.1998.698649; LIU YC, 1990, IEEE T PATTERN ANAL, V12, P28, DOI 10.1109/34.41381; Luong QT, 1996, COMPUT VIS IMAGE UND, V64, P193, DOI 10.1006/cviu.1996.0055; Luong QT, 1996, INT J COMPUT VISION, V17, P43, DOI 10.1007/BF00127818; Navab N, 1997, INT J COMPUT VISION, V23, P17, DOI 10.1023/A:1007911807871; Schmid C, 1997, PROC CVPR IEEE, P666, DOI 10.1109/CVPR.1997.609397; SPETSAKIS ME, 1990, INT J COMPUT VISION, V4, P171, DOI 10.1007/BF00054994; TAYLOR CJ, 1995, IEEE T PATTERN ANAL, V17, P1021, DOI 10.1109/34.473228; Zhang Z., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P577, DOI 10.1109/ICCV.1990.139598; Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561; ZHANG ZY, 1995, IEEE T PATTERN ANAL, V17, P1129	27	46	53	3	12	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY-JUN	2004	57	3					159	178		10.1023/B:VISI.0000013092.07433.82	http://dx.doi.org/10.1023/B:VISI.0000013092.07433.82			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	766DR		Green Submitted			2022-12-18	WOS:000188330600001
J	Gramkow, C				Gramkow, C			On averaging rotations	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						averaging rotations; Riemannian metric; matrix; quaternion		In this paper two common approaches to averaging rotations are compared to a more advanced approach based on a Riemannian metric. Very often the barycenter of the quaternions or matrices that represent the rotations are used as an estimate of the mean. These methods neglect that rotations belong to a non-linear manifold and re-normalization or orthogonalization must be applied to obtain proper rotations. These latter steps have been viewed as ad hoc corrections for the errors introduced by assuming a vector space. The article shows that the two approximative methods can be derived from natural approximations to the Riemannian metric, and that the subsequent corrections are inherent in the least squares estimation.	TriVis Ltd, DK-5230 Odense, Denmark; INRIA, MOVI Grp, Grenoble, France	Inria	Gramkow, C (corresponding author), TriVis Ltd, Billedskaerervej 19, DK-5230 Odense, Denmark.							ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; Pennec X, 1998, LECT NOTES COMPUT SC, V1496, P1107, DOI 10.1007/BFb0056300; PENNEC X, 1998, 3371 I NAT RECH INF; UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573	5	46	47	0	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.		2001	42	1-2					7	16		10.1023/A:1011129215388	http://dx.doi.org/10.1023/A:1011129215388			10	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	437VX					2022-12-18	WOS:000169015200002
J	Deguchi, K				Deguchi, K			A direct interpretation of dynamic images with camera and object motions for vision guided robot control	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						visual servoing; motion images; eigen space method; camera motion control		A general scheme to represent the relation between dynamic images and camera and/or object motions is proposed for applications to visual control of robots. We consider the case where a moving camera observes moving objects in a static scene. The camera obtains images of the objects moving within the scene. Then, the possible combinations of the camera and the objects' poses and the obtained images are not arbitrary but constrained to each other. Here we represent this constraint as a lower dimensional hypersurface in the product space of the whole combination of their motion control parameters and image data. The visual control is interpreted as to find a path on this surface leading to their poses where a given goal image will be obtained. In this paper, we propose a visual control method to utilize tangential properties of this surface. First, we represent images with a composition of a small number of "eigen images" by using K-L (Karhunen-Loeve) expansion. Then, we consider to reconstruct the eigen space (the eigen image space) to achieve efficient and straightforward controls. Such reconstruction of the space results in the constraint surface being mostly flat within the eigen space. By this method, visual control of robots in a complex configuration is achieved without image processing to extract and correspond image features in dynamic images. The method also does not need camera or hand-eye calibrations. Experimental results of visual servoing with the proposed method show the feasibility and applicability of our newly proposed approach to a simultaneous control of camera self-motion and object motions.	Tohoku Univ, Grad Sch Informat Sci, Sendai, Miyagi 9808579, Japan	Tohoku University	Deguchi, K (corresponding author), Tohoku Univ, Grad Sch Informat Sci, Aoba Campus 01, Sendai, Miyagi 9808579, Japan.							DEGUCHI K, 1996, P 13 INT C PATT REC, V1, P302; Deguchi K., 1997, J ROBOTICS MECHATRON, V9, P104; ESPIAU B, 1992, IEEE T ROBOTIC AUTOM, V8, P313, DOI 10.1109/70.143350; HAMAMOTO Y, 1991, PATTERN RECOGN, V24, P681, DOI 10.1016/0031-3203(91)90035-4; HASHIMOTO K, 1993, VISUAL SERVOIN REAL; Hutchinson S, 1996, IEEE T ROBOTIC AUTOM, V12, P651, DOI 10.1109/70.538972; KINOSHITA K, 1994, P 12 INT C PATT REC, VA, P285; MURAKAMI H, 1982, IEEE T PATTERN ANAL, V4, P511, DOI 10.1109/TPAMI.1982.4767295; Murase H., 1993, Proceedings of IEEE Workshop on Qualitative Vision (Cat. No.93TH0521-5), P39, DOI 10.1109/WQV.1993.262951; WEISS LE, 1987, IEEE T ROBOTIC AUTOM, V3, P404, DOI 10.1109/JRA.1987.1087115	10	46	46	0	8	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2000	37	1					7	20		10.1023/A:1008151528479	http://dx.doi.org/10.1023/A:1008151528479			14	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	341FC					2022-12-18	WOS:000088579500002
J	Shi, PC; Sinusas, AJ; Constable, RT; Duncan, JS				Shi, PC; Sinusas, AJ; Constable, RT; Duncan, JS			Volumetric deformation analysis using mechanics-based data fusion: Applications in cardiac motion recovery	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						nonrigid motion; cardiac motion; continuum model; data fusion; physics-based vision; biomedical image analysis	VENTRICULAR WALL-MOTION; OPTICAL-FLOW; MYOCARDIAL DEFORMATION; FACIAL EXPRESSIONS; MAGNETIC-RESONANCE; IMAGE SEQUENCES; NONRIGID MOTION; VELOCITY-FIELDS; VISUAL-MOTION; TAGGED MRI	Non-rigid motion estimation from image sequences is essential in analyzing and understanding the dynamic behavior of physical objects. One important example is the dense field motion analysis of the cardiac wall, which could potentially help to better understand the physiological processes associated with heart disease and to provide improvement in patient diagnosis and treatment. In this paper, we present a new method of estimating volumetric deformation by integrating intrinsic instantaneous velocity data with geometrical token displacement information, based upon continuum mechanics principles. This object-dependent approach allows the incorporation of physically meaningful constraints into the ill-posed motion recovery problem, and the integration of the two disparate but complementary data sources overcomes some of the limitations of the single-image-source-based motion estimation approaches.	Yale Univ, Dept Diagnost Radiol, New Haven, CT 06520 USA; Yale Univ, Dept Elect Engn, New Haven, CT 06520 USA; Yale Univ, Dept Med, Cardiol Sect, New Haven, CT 06520 USA	Yale University; Yale University; Yale University	Shi, PC (corresponding author), Yale Univ, Dept Diagnost Radiol, New Haven, CT 06520 USA.		Constable, R. Todd/ABE-8038-2021; Sinusas, Albert J/A-7235-2009	Constable, R. Todd/0000-0001-5661-9521; 				Amini AA, 1998, IEEE T MED IMAGING, V17, P344, DOI 10.1109/42.712124; AMINI AA, 1992, IMAGE VISION COMPUT, V10, P418, DOI 10.1016/0262-8856(92)90027-Z; ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167; AXEL L, 1989, RADIOLOGY, V171, P841, DOI 10.1148/radiology.171.3.2717762; AZHARI H, 1993, AM J PHYSIOL, V264, pH205, DOI 10.1152/ajpheart.1993.264.1.H205; BAJCSY R, 1982, IEEE P 6 INT C PATT, P351; Bathe K. J., 1976, NUMERICAL METHODS FI; BATTITI R, 1991, INT J COMPUT VISION, V6, P133, DOI 10.1007/BF00128153; Black MJ, 1997, INT J COMPUT VISION, V25, P23, DOI 10.1023/A:1007977618277; BOLSON EL, 1980, P COMP CARD; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; Chakraborty A, 1999, IEEE T PATTERN ANAL, V21, P12, DOI 10.1109/34.745730; CHESEBRO JH, 1987, CIRCULATION, V76, P142, DOI 10.1161/01.CIR.76.1.142; CONSTABLE RT, 1994, MAGNET RESON MED, V32, P33, DOI 10.1002/mrm.1910320106; CORNELIUS N, 1983, DARPA IM UND WORKSH, P257; CROWLEY JL, 1987, IEEE T PATTERN ANAL, V9, P113, DOI 10.1109/TPAMI.1987.4767876; DECARLO G, 1996, SPAZ SOC-SPACE SOC, V18, P4; Denney T. S.  Jr., 1994, Proceedings of the IEEE Workshop on Biomedical Image Analysis (Cat. No.94TH0624-7), P51, DOI 10.1109/BIA.1994.315866; Do Carmo M., 1976, DIFFERENTIAL GEOMETR; Essa IA, 1997, IEEE T PATTERN ANAL, V19, P757, DOI 10.1109/34.598232; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Fung Y.C., 1977, 1 COURSE CONTINUUM M; GELBERG HJ, 1979, CIRCULATION, V59, P991, DOI 10.1161/01.CIR.59.5.991; GIBSON DG, 1976, BRIT HEART J, V38, P1010; GONCALVES L, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P764, DOI 10.1109/ICCV.1995.466861; GROSSMAN W, 1986, J AM COLL CARDIOL, V7, P327, DOI 10.1016/S0735-1097(86)80499-5; GUCCIONE JM, 1991, J BIOMECH ENG-T ASME, V113, P42, DOI 10.1115/1.2894084; HERFKENS R, 1991, P 10 ANN SMRM SAN FR, P163; Hildreth E., 1984, MEASUREMENT VISUAL M; HONDA H, 1994, AM J PHYSIOL, pH881; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Horowitz B., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P325, DOI 10.1109/CVPR.1991.139710; Huebner K.H., 1995, FINITE ELEMENT METHO, V3rd; HUMPHREY JD, 1989, J BIOMECH, V22, P377, DOI 10.1016/0021-9290(89)90052-3; HUNTER PJ, 1992, CRIT REV BIOMED ENG, V20, P403; HUNTER PJ, 1988, PROG BIOPHYS MOL BIO, V52, P101, DOI 10.1016/0079-6107(88)90004-1; KAMBHAMETTU C, 1994, CVGIP-IMAG UNDERSTAN, V60, P26, DOI 10.1006/ciun.1994.1029; MAILLOUX GE, 1987, IEEE T BIO-MED ENG, V34, P356, DOI 10.1109/TBME.1987.325967; Marr D., 1982, VISION; MCCULLOCH A, 1992, CRIT REV BIOMED ENG, V20, P427; McEachen JC, 1997, IEEE T MED IMAGING, V16, P270, DOI 10.1109/42.585761; Meyer FG, 1996, IEEE T MED IMAGING, V15, P453, DOI 10.1109/42.511749; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; Nastar C, 1996, IEEE T PATTERN ANAL, V18, P1067, DOI 10.1109/34.544076; NAYLER GL, 1986, J COMPUT ASSIST TOMO, V10, P715, DOI 10.1097/00004728-198609000-00001; NIYOGI SA, 1994, P WORKSH MOT NONR AR, P16; NOVAK VP, 1994, J BIOMECH, V27, P403, DOI 10.1016/0021-9290(94)90016-7; ODELL WG, 1995, RADIOLOGY, V195, P829, DOI 10.1148/radiology.195.3.7754016; OMENS JH, 1993, J BIOMECH, V26, P665, DOI 10.1016/0021-9290(93)90030-I; OWEN R, 1991, P IEEE C COMP VIS PA; PALANIAPPAN K, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P659, DOI 10.1109/ICCV.1995.466773; PAPADEMETRIS X, 1999, LNCS, V1163, P352; PARK J, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P700, DOI 10.1109/ICCV.1995.466870; PELC N J, 1991, Magnetic Resonance Quarterly, V7, P229; PELC NJ, 1992, P 11 ANN SOC MAGN RE, P18; SCLAROFF S, 1995, IEEE T PATTERN ANAL, V17, P545, DOI 10.1109/34.387502; SHI P, 1999, IN PRESS IEEE T MED; SHI P, 1996, THESIS YALE U NEW HA; SHI PC, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P687, DOI 10.1109/ICCV.1995.466872; SLAGER CJ, 1986, J AM COLL CARDIOL, V7, P317, DOI 10.1016/S0735-1097(86)80498-3; Smaill BH, 1991, THEORY HEART; SONG SM, 1991, IEEE T MED IMAGING, V10, P295, DOI 10.1109/42.97579; Spencer A. J. M., 1980, CONTINUUM MECH; TAUBIN G, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P852, DOI 10.1109/ICCV.1995.466848; TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659; Terzopoulos D., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P70, DOI 10.1109/CVPR.1991.139663; Tistarelli M., 1994, Proceedings of the IEEE Workshop on Biomedical Image Analysis (Cat. No.94TH0624-7), P100, DOI 10.1109/BIA.1994.315861; TSOTSOS JK, 1980, IEEE T PATTERN ANAL, V2, P563, DOI 10.1109/TPAMI.1980.6447704; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; WALDMAN LK, 1985, CIRC RES, V57, P152, DOI 10.1161/01.RES.57.1.152; WATSON DF, 1981, COMPUT J, V24, P167, DOI 10.1093/comjnl/24.2.167; WEDEEN VJ, 1992, MAGNET RESON MED, V27, P52, DOI 10.1002/mrm.1910270107; Xiong YL, 1997, INT J COMPUT VISION, V24, P163, DOI 10.1023/A:1007915105826; Yamada H., 1970, STRENGTH BIOL MAT; YOUNG AA, 1993, RADIOLOGY, V188, P101, DOI 10.1148/radiology.188.1.8511281; ZERHOUNI E, 1988, ANN M SOC MAGN RES I, P10	78	46	49	0	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	1999	35	1					87	107		10.1023/A:1008163112590	http://dx.doi.org/10.1023/A:1008163112590			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	265NY					2022-12-18	WOS:000084251300006
J	Thirion, JP				Thirion, JP			The extremal mesh and the understanding of 3D surfaces	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							SINGULARITIES	This paper is about a new concept for the description of 3D smooth surfaces: the extremal mesh. In previous works, we have shown how to extract the extremal lines from 3D images, which are the lines where one of the two principal surface curvatures is locally extremal. We have also shown how to extract the extremal points, which are specific points where the two principal curvatures are both extremal. The extremal mesh is the graph of the surface whose vertices are the extremal points and whose edges are the extremal lines: it is invariant with respect to rigid transforms. The good topological properties of this graph are ensured with a new local geometric invariant of 3D surfaces, that we call the Gaussian extremality, and which allows to overcome orientation problems encountered with previous definitions of the extremal lines and points. This paper presents also an algorithm to extract the extremal mesh from 3D images, and experiments with synthetic and real 3D medical images show that this graph can be extremely precise and stable.			Thirion, JP (corresponding author), INRIA,EPIDAURE,BP 93,2004 ROUTE LUCIOLES,F-06902 SOPHIA ANTIPOLIS,FRANCE.							BAJAJ CL, 1992, COMP GRAPH, V26, P79, DOI 10.1145/142920.134014; CUTTING CB, 1993, SPIE MATH METHODS ME, V2035, P30; Do Carmo M.P., 2016, DIFFERENTIAL GEOMETR, Vsecond; Koenderink J., 1990, SOLID SHAPE; Lorensen W. E., 1987, COMPUTER GRAPHICS, V21; MONGA O, 1993, IEEE C COMPUTER VISI; MONGA O, 1992, IEEE P CVPR 92; MORSE BS, 1993, LECT NOTES COMPUTER, V687, P112; PORTEOUS IR, 1983, P SYMP PURE MATH, V40, P379; PORTEOUS IR, 1987, MATH SURFACES, V2, P447; SANDER PT, 1992, IEEE T PATTERN ANAL, V14, P309, DOI 10.1109/34.120326; SUBSOL G, 1994, VISUALIZATION BIOMED; TAUBIN G, 1993, 4 INT C COMP VIS; THIRION J, 1992, 1672 INRIA; THIRION J, 1993, 2003 INRIA; THIRION JP, 1994, IEEE C COMP VIS PATT; THIRION JP, 1993, 1881 INRIA; VEMURI BC, 1986, IMAGE VISION COMPUT, V4, P107, DOI 10.1016/0262-8856(86)90029-6; Wyvill G., 1986, Visual Computer, V2, P227, DOI 10.1007/BF01900346	19	46	49	2	2	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	1996	19	2					115	128		10.1007/BF00055800	http://dx.doi.org/10.1007/BF00055800			14	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	VE939		Green Submitted			2022-12-18	WOS:A1996VE93900001
J	SWAIN, MJ; STRICKER, MA				SWAIN, MJ; STRICKER, MA			PROMISING DIRECTIONS IN ACTIVE VISION	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article								Active vision systems have mechanisms that can actively control camera parameters such as position, orientation, focus, zoom, aperture, and vergence (in a two-camera system) in response to the requirements of the task and external stimuli. They may also have features such as spatially variant (foveal) sensors. More broadly, active vision encompasses attention, selective sensing in space, resolution, and time, whether it is achieved by modifying physical camera parameters or the way data is processed after leaving the camera. In the active-vision paradigm, the basic components of the visual system are visual behaviors tightly integrated with the actions they support; these behaviors may not require elaborate categorical representations of the 3-D world. Because the cost of generating and updating a complete, detailed model of most environments is too high, this approach to vision is vital for achieving robust, real-time perception in the real world. In addition, active control of imaging parameters has been shown to simplify scene interpretation by eliminating the ambiguity present in single images. Important research areas in active vision include attention, foveal sensing, gaze control, eye-hand coordination, and integration with robot architectures.			SWAIN, MJ (corresponding author), UNIV CHICAGO,DEPT COMP SCI,ARTIFICIAL INTELLIGENCE LAB,CHICAGO,IL 60637, USA.								0	46	46	0	1	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	OCT	1993	11	2					109	126		10.1007/BF01469224	http://dx.doi.org/10.1007/BF01469224			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	MB329					2022-12-18	WOS:A1993MB32900002
J	Bian, JW; Lin, WY; Liu, Y; Zhang, L; Yeung, SK; Cheng, MM; Reid, I				Bian, Jia-Wang; Lin, Wen-Yan; Liu, Yun; Zhang, Le; Yeung, Sai-Kit; Cheng, Ming-Ming; Reid, Ian			GMS: Grid-Based Motion Statistics for Fast, Ultra-robust Feature Correspondence	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Feature matching; Epipolar geometry; Visual SLAM; Structure-from-motion; GMS	EPIPOLAR GEOMETRY; MODEL	Feature matching aims at generating correspondences across images, which is widely used in many computer vision tasks. Although considerable progress has been made on feature descriptors and fast matching for initial correspondence hypotheses, selecting good ones from them is still challenging and critical to the overall performance. More importantly, existing methods often take a long computational time, limiting their use in real-time applications. This paper attempts to separate true correspondences from false ones at high speed. We term the proposed method (GMS) grid-based motion Statistics, which incorporates the smoothness constraint into a statistic framework for separation and uses a grid-based implementation for fast calculation. GMS is robust to various challenging image changes, involving in viewpoint, scale, and rotation. It is also fast, e.g., take only 1 or 2 ms in a single CPU thread, even when 50K correspondences are processed. This has important implications for real-time applications. What's more, we show that incorporating GMS into the classic feature matching and epipolar geometry estimation pipeline can significantly boost the overall performance. Finally, we integrate GMS into the well-known ORB-SLAM system for monocular initialization, resulting in a significant improvement.	[Bian, Jia-Wang; Reid, Ian] Univ Adelaide, Adelaide, SA, Australia; [Bian, Jia-Wang; Reid, Ian] Australian Ctr Robot Vis, Brisbane, Qld, Australia; [Lin, Wen-Yan] Singapore Management Univ, Singapore, Singapore; [Liu, Yun; Cheng, Ming-Ming] Nankai Univ, Tianjin, Peoples R China; [Zhang, Le] Agcy Sci Technol & Res, Singapore, Singapore; [Yeung, Sai-Kit] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China	University of Adelaide; Australian Centre for Robotic Vision; Singapore Management University; Nankai University; Agency for Science Technology & Research (A*STAR); Hong Kong University of Science & Technology	Bian, JW (corresponding author), Univ Adelaide, Adelaide, SA, Australia.; Bian, JW (corresponding author), Australian Ctr Robot Vis, Brisbane, Qld, Australia.	jiawang.bian@gmail.com	Bian, Jia-Wang/AAH-4463-2019; Cheng, Ming-Ming/A-2527-2009; Bian, Jia-Wang/AAP-2274-2020	Bian, Jia-Wang/0000-0003-2046-3363; Cheng, Ming-Ming/0000-0001-5550-8758; Bian, Jia-Wang/0000-0003-2046-3363; Reid, Ian/0000-0001-7790-6423				[Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.445; Bian J.-W, 2019, PROC BRIT MACH VIS C; Bian JW, 2017, PROC CVPR IEEE, P2828, DOI 10.1109/CVPR.2017.302; Bradski G, 2000, DR DOBBS JOURNAL OF; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Causo A, 2018, IEEE INT CONF ROBOT, P7421; Cheng MM, 2016, LECT NOTES COMPUT SC, V9907, P867, DOI 10.1007/978-3-319-46487-9_53; Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Geiger A., 2012, P IEEE COMP SOC C CO; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; Heinly J, 2012, LECT NOTES COMPUT SC, V7573, P759, DOI 10.1007/978-3-642-33709-3_54; Knapitsch A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073599; Kushnir M, 2014, IEEE T PATTERN ANAL, V36, P2381, DOI 10.1109/TPAMI.2014.2339862; Lin WY, 2018, PROC CVPR IEEE, P5784, DOI 10.1109/CVPR.2018.00606; Lin WY, 2018, IEEE T PATTERN ANAL, V40, P34, DOI 10.1109/TPAMI.2017.2652468; Liu Y., 2018, INT JOINT C ART INT; Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849; Liu ZC, 2012, FRONTIERS IN PLURIPOTENT STEM CELLS RESEARCH AND THERAPEUTIC POTENTIALS: BENCH-TO-BEDSIDE, P16; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Ma JY, 2019, INT J COMPUT VISION, V127, P512, DOI 10.1007/s11263-018-1117-z; Ma JY, 2014, IEEE T IMAGE PROCESS, V23, P1706, DOI 10.1109/TIP.2014.2307478; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mishchuk Anastasiya, 2017, ADV NEURAL INFORM PR; Mishkin D, 2018, LECT NOTES COMPUT SC, V11213, P287, DOI 10.1007/978-3-030-01240-3_18; Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730; Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331; Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671; Ranftl R, 2018, LECT NOTES COMPUT SC, V11205, P292, DOI 10.1007/978-3-030-01246-5_18; Rousseeuw P. J., 1987, ROBUST REGRESSION OU; Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544; Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773; Vedaldi Andrea, 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249; Wilson K, 2014, LECT NOTES COMPUT SC, V8691, P61, DOI 10.1007/978-3-319-10578-9_5; Yi KM, 2018, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2018.00282; Yoon JS, 2018, PROC CVPR IEEE, P5060, DOI 10.1109/CVPR.2018.00531; Zhang H, 2019, P SAI INTELLIGENT SY, P1267; Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561	40	45	48	13	32	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2020	128	6					1580	1593		10.1007/s11263-019-01280-3	http://dx.doi.org/10.1007/s11263-019-01280-3			14	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	LQ3MN		hybrid, Green Published			2022-12-18	WOS:000534910600002
J	Zhang, CQ; Fu, HZ; Wang, J; Li, W; Cao, XC; Hu, QH				Zhang, Changqing; Fu, Huazhu; Wang, Jing; Li, Wen; Cao, Xiaochun; Hu, Qinghua			Tensorized Multi-view Subspace Representation Learning	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Multi-view representation learning; Subspace clustering; Low-rank tensor; Constraint matrix	MATRIX FACTORIZATION; SPARSE; ALGORITHM	Self-representation based subspace learning has shown its effectiveness in many applications. In this paper, we promote the traditional subspace representation learning by simultaneously taking advantages of multiple views and prior constraint. Accordingly, we establish a novel algorithm termed as Tensorized Multi-view Subspace Representation Learning. To exploit different views, the subspace representation matrices of different views are regarded as a low-rank tensor, which effectively models the high-order correlations of multi-view data. To incorporate prior information, a constraint matrix is devised to guide the subspace representation learning within a unified framework. The subspace representation tensor equipped with a low-rank constraint models elegantly the complementary information among different views, reduces redundancy of subspace representations, and then improves the accuracy of subsequent tasks. We formulate the model with a tensor nuclear norm minimization problem constrained with l(2,1)-norm and linear equalities. The minimization problem is efficiently solved by using an Augmented Lagrangian Alternating Direction Minimization method. Extensive experimental results on diverse multi-view datasets demonstrate the effectiveness of our algorithm.	[Zhang, Changqing; Hu, Qinghua] Tianjin Univ, Coll Intelligence & Comp, Tianjin Key Lab Machine Learning, Tianjin 300350, Peoples R China; [Fu, Huazhu] Incept Inst Artificial Intelligence, Abu Dhabi, U Arab Emirates; [Wang, Jing] Univ Greenwich, Sch Comp & Math Sci, London SE10 9LS, England; [Li, Wen] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China; [Cao, Xiaochun] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China	Tianjin University; University of Greenwich; University of Electronic Science & Technology of China; Chinese Academy of Sciences; Institute of Information Engineering, CAS	Cao, XC (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.	zhangchangqing@tju.edu.cn; hzfu@ieee.org; jing.wang@greenwich.ac.uk; liwenbnu@gmail.com; caoxiaochun@iie.ac.cn; hugingqing@gu.edu.cn	Fu, Huazhu/A-1411-2014	Fu, Huazhu/0000-0002-9702-5524	National Natural Science Foundation of China [61976151, 61732011, 61925602, U1636214]; Beijing Natural Science Foundation [4172068]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Beijing Natural Science Foundation(Beijing Natural Science Foundation)	This work is supported by the National Natural Science Foundation of China (Nos. 61976151, 61732011, 61925602 and U1636214), Beijing Natural Science Foundation (No. 4172068).	Abavisani M, 2018, INFORM FUSION, V39, P168, DOI 10.1016/j.inffus.2017.05.002; Andrew Galen, 2013, ICML; BARTELS RH, 1972, COMMUN ACM, V15, P820, DOI 10.1145/361573.361582; Basu Sugato, 2004, KDD, P59, DOI DOI 10.1145/1014052.1014062; Bickel S, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P19, DOI 10.1109/ICDM.2004.10095; Blaschko MB, 2008, PROC CVPR IEEE, P93, DOI 10.1109/cvpr.2008.4587586; Cai JF, 2010, SINGULAR VALUE THRES; Cao X., 2013, AAAI; Cao XC, 2015, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2015.7298657; Cao XC, 2015, IEEE T IMAGE PROCESS, V24, P4381, DOI 10.1109/TIP.2015.2463223; Chaudhuri K., 2009, PROC INT C MACHINE L, P129, DOI DOI 10.1145/1553374.1553391; Cheng B, 2011, IEEE I CONF COMP VIS, P2439, DOI 10.1109/ICCV.2011.6126528; Cheng MM, 2019, IEEE T IMAGE PROCESS, V28, P2399, DOI 10.1109/TIP.2018.2877937; Christopher D.M., 2008, INTRO INFORM RETRIEV; Collins MD, 2014, LECT NOTES COMPUT SC, V8691, P282, DOI 10.1007/978-3-319-10578-9_19; Cortes, 2009, NEURAL INF PROCESS S; DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909; De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696; De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1324, DOI 10.1137/S0895479898346995; De Sa V.R., 2005, ICML WORKSHOP LEARNI, P20; Ding Z, 2018, LEARNING REPRESENTAT; Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57; Elkahky A, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P278, DOI 10.1145/2736277.2741667; Gao HC, 2015, IEEE I CONF COMP VIS, P4238, DOI 10.1109/ICCV.2015.482; Greene D, 2009, LECT NOTES ARTIF INT, V5781, P423, DOI 10.1007/978-3-642-04180-8_45; Grigorios T., 2012, ICDM; Guo Y., 2013, AAAI, V1, P2; Hanghang Tong, 2005, 13th Annual ACM International Conference on Multimedia, P862, DOI 10.1145/1101149.1101337; Hu H, 2014, PROC CVPR IEEE, P3834, DOI 10.1109/CVPR.2014.484; HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075; Jing W, 2016, IEEE T CYBERNETICS, V47, P1; Kamvar S. D., 2003, P 18 INT JOINT C ART, P561; Kumar A., 2011, P 28 INT C MACH LEAR, P393, DOI DOI 10.5555/3104482.3104532; Kumar Abhishek, 2011, NEURIPS, P2, DOI DOI 10.5555/2986459.2986617; LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173; Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750; Li ZC, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2624140; Lin Z., 2010, ARXIV10095055, DOI DOI 10.1016/J.JSB.2012.10.010; Lin ZC, 2015, MACH LEARN, V99, P287, DOI 10.1007/s10994-014-5469-5; Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88; Liu HF, 2012, IEEE T PATTERN ANAL, V34, P1299, DOI 10.1109/TPAMI.2011.217; Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39; Liu XW, 2019, IEEE T PATTERN ANAL, V41, P2410, DOI 10.1109/TPAMI.2018.2879108; Lu Z, 2007, NEURAL COMPUT, V19, P1528, DOI 10.1162/neco.2007.19.6.1528; Ng AY, 2002, ADV NEUR IN, V14, P849; Ngiam Jiquan, 2011, ICML, DOI DOI 10.5555/3104482.3104569; Oh TH, 2015, PROC CVPR IEEE, P4484, DOI 10.1109/CVPR.2015.7299078; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Patel V. M., 2014, ICCV, P225; Quintana ES, 2001, SIAM J SCI COMPUT, V22, P1762, DOI 10.1137/S1064827598345679; Rangapuram S. S., 2012, AISTATS, V30, P90; Soleymani F, 2014, NUMER LINEAR ALGEBR, V21, P439, DOI 10.1002/nla.1890; Sui J, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-05432-w; Tang W, 2009, IEEE DATA MINING, P1016, DOI 10.1109/ICDM.2009.125; Tomioka R., 2010, ARXIV10100789; Wagstaff K., 2001, ICML, V1, P577, DOI DOI 10.1109/TPAMI.2002.1017616; Wang H, 2020, IEEE T KNOWL DATA EN, V32, P1116, DOI 10.1109/TKDE.2019.2903810; Wang HX, 2014, PROC CVPR IEEE, P4106, DOI 10.1109/CVPR.2014.523; Wang W., 2015, ON DEEP MULTI VIEW R, P1083; White Martha, 2012, ADV NEURAL INFORM PR, P1682; Wu BY, 2013, PROC CVPR IEEE, P3507, DOI 10.1109/CVPR.2013.450; Xia RK, 2014, AAAI CONF ARTIF INTE, P2149; Xia RK, 2014, AAAI CONF ARTIF INTE, P2156; Xie Y, 2018, INT J COMPUT VISION, V126, P1157, DOI 10.1007/s11263-018-1086-2; Yang E, 2018, IEEE T NEUR NET LEAR, V29, P5292, DOI 10.1109/TNNLS.2018.2793863; Zhan K, 2018, IEEE T CYBERNETICS, V48, P2887, DOI 10.1109/TCYB.2017.2751646; Zhang CQ, 2018, AAAI CONF ARTIF INTE, P4406; Zhang CQ, 2017, PROC CVPR IEEE, P4333, DOI 10.1109/CVPR.2017.461; Zhang CQ, 2017, IEEE T IMAGE PROCESS, V26, P648, DOI 10.1109/TIP.2016.2627806; Zhang TZ, 2013, IEEE I CONF COMP VIS, P281, DOI 10.1109/ICCV.2013.42; Zhang TZ, 2015, INT J COMPUT VISION, V111, P171, DOI 10.1007/s11263-014-0738-0; Zhang Z, 2019, IEEE T PATTERN ANAL, V41, P1774, DOI 10.1109/TPAMI.2018.2847335; Zhao HD, 2017, AAAI CONF ARTIF INTE, P2921; Zhao XR, 2014, PATTERN RECOGN LETT, V41, P73, DOI 10.1016/j.patrec.2013.12.003; Zhou C, 2014, ICME, P1, DOI [10.1109/WoWMoM.2014.6918928, DOI 10.1109/WOWMOM.2014.6918928]	76	45	45	4	25	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2020	128	8-9			SI		2344	2361		10.1007/s11263-020-01307-0	http://dx.doi.org/10.1007/s11263-020-01307-0		FEB 2020	18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	MZ8HG		Green Accepted			2022-12-18	WOS:000516328700001
J	Khoreva, A; Benenson, R; Ilg, E; Brox, T; Schiele, B				Khoreva, Anna; Benenson, Rodrigo; Ilg, Eddy; Brox, Thomas; Schiele, Bernt			Lucid Data Dreaming for Video Object Segmentation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Video object segmentation; Synthetic data; Data augmentation; Convolutional neural networks		Convolutional networks reach top quality in pixel-level video object segmentation but require a large amount of training data (1k-100k) to deliver such results. We propose a new training strategy which achieves state-of-the-art results across three evaluation datasets while using 20x-1000x less annotated data than competing methods. Our approach is suitable for both single and multiple object segmentation. Instead of using large training sets hoping to generalize across domains, we generate in-domain training data using the provided annotation on the first frame of each video to synthesize-lucid dream (in a lucid dream the sleeper is aware that he or she is dreaming and is sometimes able to control the course of the dream)-plausible future video frames. In-domain per-video training data allows us to train high quality appearance- and motion-based models, as well as tune the post-processing stage. This approach allows to reach competitive results even when training from only a single annotated frame, without ImageNet pre-training. Our results indicate that using a larger training set is not automatically better, and that for the video object segmentation task a smaller training set that is closer to the target domain is more effective. This changes the mindset regarding how many training samples and general objectness knowledge are required for the video object segmentation task.	[Khoreva, Anna; Schiele, Bernt] Max Planck Inst Informat, Saarbrucken, Germany; [Benenson, Rodrigo] Google, Menlo Pk, CA USA; [Ilg, Eddy; Brox, Thomas] Univ Freiburg, Freiburg, Germany	Max Planck Society; Google Incorporated; University of Freiburg	Khoreva, A (corresponding author), Max Planck Inst Informat, Saarbrucken, Germany.	khoreva@mpi-inf.mpg.de; benenson@google.com; ilg@cs.uni-freiburg.com; brox@cs.uni-freiburg.com; schiele@mpi-inf.mpg.de		Khoreva, Anna/0000-0003-4292-4810	Max Planck Society; DFG [BR 3815/7-1]	Max Planck Society(Max Planck SocietyFoundation CELLEX); DFG(German Research Foundation (DFG))	Open access funding provided by Max Planck Society. Eddy Ilg and Thomas Brox acknowledge funding by the DFG Grant BR 3815/7-1.	Aytekin C., 2015, ICIP; Bansal A., 2017, ARXIV170206506; Bertinetto L., 2016, ARXIV160609549; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; Breitenstein M. D., 2009, ICCV; Caelles S., 2017, CVPR; Chandra S., 2018, CVPR; Chang J., 2013, CVPR; Chen L.-C., 2017, P IEEE CVF C COMP VI, V6; Chen Liang-Chieh, 2016, ARXIV160600915; Chen W., 2016, 3D VISION 3DV; Cheng J., 2017, CVPR WORKSH; Danelljan M., 2015, ICCV WORKSH; Dosovitskiy Alexey, 2015, ICCV; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Faktor A., 2014, BMVC; Georgakis G., 2017, ARXIV170207836; Glorot X., 2010, P 13 INT C ART INT S, VVolume 9, P249; Grundmann M., 2010, CVPR; Gupta A., 2016, CVPR; Held D., 2016, ECCV; Henriques J. F., 2012, ECCV; Ilg E., 2017, CVPR; Jain S. D., 2016, HCOMP; Jain S. D., 2017, ARXIV170105384; Jain S. D., 2014, ECCV; Jampani V., 2016, ARXIV161205478; Khoreva A., 2017, CVPR WORKSH; Khoreva A, 2016, ARXIV161202646; Krahenbuhl P., 2011, P ADV NEUR INF PROC; Kristan M., 2016, ECCV WORKSH; Kristan M., 2014, ECCV WORKSH; Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79; Le T. N., 2017, CVPR WORKSHOPS; Li F., 2013, ICCV; Li X., 2017, CVPR WORKSH; Lin  Guosheng, 2016, ARXIV161106612; Luiten B. L. J., 2018, ACCV; Ma C., 2015, ICCV; Maerki N., 2016, CVPR; Mayer N., 2016, CVPR; Nagaraja N., 2015, ICCV; Nam H., 2016, ARXIV160807242; Nam H., 2016, CVPR; Papazoglou A., 2013, ICCV; Park D., 2015, CVPR WORKSH; Pathak D., 2016, ARXIV161206370; Perazzi F., 2016, CVPR; Perazzi F., 2015, ICCV; Pishchulin L., 2012, CVPR; Pohlen T., 2017, CVPR; Pont-Tuset J., 2017, ARXIV170400675; Pont-Tuset J., 2017, DAVIS CHALLENGE VIDE; Prest A., 2012, CVPR; Revaud J., 2015, CVPR; Richter S. R., 2016, ECCV; Rother C., 2004, SIGGRAPH; Shaban A., 2017, CVPR WORKSH; Sharir G., 2017, CVPR WORKSH; Simonyan Karen, 2015, INT C LEARN REPR; Song H., 2018, ECCV; Spina T. V., 2016, ARXIV160603369; Sun J., 2004, SIGGRAPH; Tang Kevin, 2012, ADV NEURAL INFORM PR, P647; Tang M., 2016, ECCV; Tang S., 2013, ICCV; Tao R., 2016, ARXIV160505863; Tokmakov P., 2016, ARXIV161207217; Tokmakov P., 2017, ICCV; Tsai Y. H., 2016, P IEEE C COMP VIS PA; Varol G., 2017, ARXIV170101370; Voigtlaender P., 2017, CVPR WORKSH; Voigtlaender P., 2017, BMVC; Vojir T., 2017, RES REPORT; Wang L., 2015, ICCV; Wang T., 2014, CVIU; Wang W., 2017, ARXIV170208634; Wang X., 2015, ICCV; Wu Z, 2016, CORR, P1; Xiao F., 2016, CVPR; Yu J. J., 2016, ARXIV160805842; Zhao H, 2017, P IEEE C COMPUTER VI; Zhao H., 2017, CVPR WORKSH; Zhu Y., 2017, ARXIV170202295	85	45	50	0	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2019	127	9					1175	1197		10.1007/s11263-019-01164-6	http://dx.doi.org/10.1007/s11263-019-01164-6			23	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	IL9YV		Green Submitted, hybrid			2022-12-18	WOS:000477642300001
J	Munda, G; Reinbacher, C; Pock, T				Munda, Gottfried; Reinbacher, Christian; Pock, Thomas			Real-Time Intensity-Image Reconstruction for Event Cameras Using Manifold Regularisation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Event camera; Denoising; Convex optimisation; Variational methods	SURFACES	Event cameras or neuromorphic cameras mimic the human perception system as they measure the per-pixel intensity change rather than the actual intensity level. In contrast to traditional cameras, such cameras capture new information about the scene at MHz frequency in the form of sparse events. The high temporal resolution comes at the cost of losing the familiar per-pixel intensity information. In this work we propose a variational model that accurately models the behaviour of event cameras, enabling reconstruction of intensity images with arbitrary frame rate in real-time. Our method is formulated on a per-event-basis, where we explicitly incorporate information about the asynchronous nature of events via an event manifold induced by the relative timestamps of events. In our experiments we verify that solving the variational model on the manifold produces high-quality images without explicitly estimating optical flow. This paper is an extended version of our previous work (Reinbacher et al. in British machine vision conference (BMVC), 2016) and contains additional details of the variational model, an investigation of different data terms and a quantitative evaluation of our method against competing methods as well as synthetic ground-truth data.	[Munda, Gottfried; Reinbacher, Christian; Pock, Thomas] Graz Univ Technol, Inst Comp Graph & Vis, Graz, Austria	Graz University of Technology	Munda, G (corresponding author), Graz Univ Technol, Inst Comp Graph & Vis, Graz, Austria.	Munda@icg.tugraz.at; Reinbacher@icg.tugraz.at; Pock@icg.tugraz.at			research initiative Mobile Vision; AIT; Austrian Federal Ministry of Science, Research and Economy HRSM Programme (BGB1.II) [292/2012]	research initiative Mobile Vision; AIT; Austrian Federal Ministry of Science, Research and Economy HRSM Programme (BGB1.II)	This work was supported by the research initiative Mobile Vision with funding from the AIT and the Austrian Federal Ministry of Science, Research and Economy HRSM Programme (BGB1.II Nr. 292/2012).	Bardow P., 2016, CVPR; Barua S., 2016, P IEEE REAL TIM SYST, P1; Benosman R, 2014, IEEE T NEUR NET LEAR, V25, P407, DOI 10.1109/TNNLS.2013.2273537; Chambolle A, 2004, J MATH IMAGING VIS, V20, P89; Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1; Cheng LT, 2000, J COMPUT PHYS, V175, P2002; Cook M, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P770, DOI 10.1109/IJCNN.2011.6033299; Delbruck T., 2007, INT S CIRC SYST; Gallego G., 2015, CORRARXIV151001972; Graber G., 2015, CVPR; Hartmann J., 2013, EUR C MOB ROB; Kim H, 2016, LECT NOTES COMPUT SC, V9910, P349, DOI 10.1007/978-3-319-46466-4_21; Kim Hanme, 2014, BMVC; Krueger M, 2008, LECT NOTES COMPUT SC, V5303, P350, DOI 10.1007/978-3-540-88688-4_26; Lai RJ, 2011, COMPUT VIS IMAGE UND, V115, P1647, DOI 10.1016/j.cviu.2011.05.011; Le T, 2007, J MATH IMAGING VIS, V27, P257, DOI 10.1007/s10851-007-0652-y; Lee John M, 2018, INTRO RIEMANNIAN MAN; Lichtsteiner P, 2008, IEEE J SOLID-ST CIRC, V43, P566, DOI 10.1109/JSSC.2007.914337; Lui LM, 2008, METHODS APPL ANAL, V15, P513; Milford M., 2015, PROBL MOB SENS WORKS; Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050; Mueggler E., 2014, INT C INT ROB SYST; Mueggler E., 2015, ROBOTICS SCI SYSTEMS; Mueggler E, 2016, ARXIV161008336; Ratner N., 2007, CVPR, p[2, 7]; Rebecq H., 2016, P BRIT MACH VIS C BM; Rebecq H, 2017, IEEE ROBOT AUTOM LET, V2, P593, DOI 10.1109/LRA.2016.2645143; Reinbacher C., 2016, BRIT MACH VIS C BMVC; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Stam J, 2003, ACM T GRAPHIC, V22, P724, DOI 10.1145/882262.882338; Steidl G, 2010, J MATH IMAGING VIS, V36, P168, DOI 10.1007/s10851-009-0179-5; Weikersdorfer David, 2013, Computer Vision Systems. 9th International Conference, ICVS 2013. Proceedings: LNCS 7963, P133, DOI 10.1007/978-3-642-39402-7_14; Wiesmann G., 2012, CVPR WORKSH; Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730	34	45	47	5	22	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	2018	126	12			SI		1381	1393		10.1007/s11263-018-1106-2	http://dx.doi.org/10.1007/s11263-018-1106-2			13	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	GZ3KT		Green Submitted, Green Published			2022-12-18	WOS:000449286200008
J	Patron-Perez, A; Lovegrove, S; Sibley, G				Patron-Perez, Alonso; Lovegrove, Steven; Sibley, Gabe			A Spline-Based Trajectory Representation for Sensor Fusion and Rolling Shutter Cameras	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Sensor fusion; Visual-inertial; SLAM; Rolling shutter; Calibration		The use of multiple sensors for ego-motion estimation is an approach often used to provide more accurate and robust results. However, when representing ego-motion as a discrete series of poses, fusing information of unsynchronized sensors is not straightforward. The framework described in this paper aims to provide a unified solution for solving ego-motion estimation problems involving high-rate unsynchronized devices. Instead of a discrete-time pose representation, we present a continuous-time formulation that makes use of cumulative cubic B-Splines parameterized in the Lie Algebra of the group . This trajectory representation has several advantages for sensor fusion: (1) it has local control, which enables sliding window implementations; (2) it is continuous, allowing predictions of inertial measurements; (3) it closely matches torque-minimal motions; (4) it has no singularities when representing rotations; (5) it easily handles measurements from multiple sensors arriving a different times when timestamps are available; and (6) it deals with rolling shutter cameras naturally. We apply this continuous-time framework to visual-inertial simultaneous localization and mapping and show that it can also be used to calibrate the entire system.	[Patron-Perez, Alonso] Flyby Media Inc, New York, NY 10010 USA; [Lovegrove, Steven] Surreal Vis, London, England; [Sibley, Gabe] Univ Colorado, Autonomous Robot & Percept Grp, Boulder, CO 80309 USA	University of Colorado System; University of Colorado Boulder	Patron-Perez, A (corresponding author), Flyby Media Inc, New York, NY 10010 USA.	alonso@flybymedia.com; steven@surreal.vision; gsibley@colorado.edu			NSF MRI grant [1337722]; Toyota Motor Engineering & Manufacturing North America, Inc; Google, Inc.	NSF MRI grant(National Science Foundation (NSF)NSF - Office of the Director (OD)); Toyota Motor Engineering & Manufacturing North America, Inc; Google, Inc.(Google Incorporated)	This work was made possible by generous support from NSF MRI grant 1337722, Toyota Motor Engineering & Manufacturing North America, Inc, and Google, Inc.	Agarwal S., 2012, CERES SOLVER TUTORIA; Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715; Anderson S., 2013, IEEE C ROB AUT; Baker S., 2010, C COMP VIS PATT REC; Bibby C., 2010, INT C ROB AUT; Comport A. I., 2007, INT C ROB AUT; Crouch P., 1999, Journal of Dynamical and Control Systems, V5, P397, DOI 10.1023/A:1021770717822; Dam E. B., 1998, DIKUTR985 U COP DEP; Davison A. J., 2003, INT C COMP VIS; Furgale P., 2012, INT C ROB AUT; Hedborg J., 2012, C COMP VIS PATT REC; Jia C., 2012, INT WORKSH MULT SIGN; Jones E., 2007, ICCV WORKSH DYN VIS; Kelly J, 2011, INT J ROBOT RES, V30, P56, DOI 10.1177/0278364910382802; Klein G., 2008, EUR C COMP VIS; Klein G, 2009, INT SYM MIX AUGMENT, P83, DOI 10.1109/ISMAR.2009.5336495; Klein George, 2007, P1; Lovegrove S, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.93; Martull S., 2012, ICPR WORKSH; Mei C, 2010, INT J COMPUT VISION, V94, P1, DOI DOI 10.1109/IPDPSW.2010.5470766; Meingast M., 2005, OMNIVIS WORKSH; Mirzaei FM, 2008, IEEE T ROBOT, V24, P1143, DOI 10.1109/TRO.2008.2004486; Montiel J., 2006, ROBOTICS SCI SYSTEMS; Myoung-Jun Kim, 1995, Computer Graphics Proceedings. SIGGRAPH 95, P369; Myoung-Jun Kim, 1995, Proceedings. Computer Animation '95, P72, DOI 10.1109/CA.1995.393545; Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513; Nuetzi G., 2010, INT C UNM AER VEH; Pietzsch T., 2008, BRIT MACH VIS C; Qin KH, 2000, VISUAL COMPUT, V16, P177, DOI 10.1007/s003710050206; Shoemake K., 1987, SIGGRAPH COURSE NOTE; Shoemaker K., 1985, Computer Graphics, V19, P245, DOI 10.1145/325165.325242; Strasdat H., 2010, ROB SCI SYST, DOI [10.15607/RSS.2010.VI.010, DOI 10.15607/RSS.2010.VI.010]; Strasdat H., 2012, THESIS IMPERIAL COLL; Strasdat H., 2011, INT C COMP VIS	36	45	51	0	16	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2015	113	3			SI		208	219		10.1007/s11263-015-0811-3	http://dx.doi.org/10.1007/s11263-015-0811-3			12	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	CK3BZ					2022-12-18	WOS:000356091900005
J	Wu, D; Velten, A; O'Toole, M; Masia, B; Agrawal, A; Dai, QH; Raskar, R				Wu, Di; Velten, Andreas; O'Toole, Matthew; Masia, Belen; Agrawal, Amit; Dai, Qionghai; Raskar, Ramesh			Decomposing Global Light Transport Using Time of Flight Imaging	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Light transport analysis; Direct/global separation; Time of flight imaging; Transient imaging; Femto-photography	CAPTURE; INVERSE; SHAPE	Global light transport is composed of direct and indirect components. In this paper, we take the first steps toward analyzing light transport using the high temporal resolution information of time of flight (ToF) images. With pulsed scene illumination, the time profile at each pixel of these images separates different illumination components by their finite travel time and encodes complex interactions between the incident light and the scene geometry with spatially-varying material properties. We exploit the time profile to decompose light transport into its constituent direct, subsurface scattering, and interreflection components. We show that the time profile is well modelled using a Gaussian function for the direct and interreflection components, and a decaying exponential function for the subsurface scattering component. We use our direct, subsurface scattering, and interreflection separation algorithm for five computer vision applications: recovering projective depth maps, identifying subsurface scattering objects, measuring parameters of analytical subsurface scattering models, performing edge detection using ToF images and rendering novel images of the captured scene with adjusted amounts of subsurface scattering.	[Wu, Di; O'Toole, Matthew; Masia, Belen; Raskar, Ramesh] MIT, Media Lab, Cambridge, MA 02139 USA; [Wu, Di] Tsinghua Univ, Beijing 100084, Peoples R China; [Velten, Andreas] Morgridge Inst Res, Madison, WI 53715 USA; [Velten, Andreas] Univ Wisconsin, Lab Opt & Computat Instrumentat, Madison, WI 53706 USA; [O'Toole, Matthew] Univ Toronto, Toronto, ON, Canada; [Masia, Belen] Univ Zaragoza, Zaragoza, Spain; [Agrawal, Amit] Mitsubishi Elect Res Labs, Cambridge, MA USA; [Dai, Qionghai] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China	Massachusetts Institute of Technology (MIT); Tsinghua University; University of Wisconsin System; University of Wisconsin Madison; The Morgridge Institute for Research, Inc.; University of Wisconsin System; University of Wisconsin Madison; University of Toronto; University of Zaragoza; Tsinghua University	Velten, A (corresponding author), Morgridge Inst Res, 330 North Orchard St, Madison, WI 53715 USA.	velten@gmail.com; raskar@media.mit.edu	Dai, Qionghai/ABD-5298-2021	Dai, Qionghai/0000-0001-7043-3061; Masia, Belen/0000-0003-0060-7278	DARPA through the DARPA YFA; Institute for Soldier Nanotechnologies; U.S. Army Research Office [W911NF-07-D-0004]; National Basic Research Project of China and the Key Project of NSFC [2010CB731800, 61120106003, 60932007]; NSERC PGS-D; GRAND NCE programs; FPU [TIN2010-21543]; NVIDIA	DARPA through the DARPA YFA; Institute for Soldier Nanotechnologies; U.S. Army Research Office; National Basic Research Project of China and the Key Project of NSFC; NSERC PGS-D(Natural Sciences and Engineering Research Council of Canada (NSERC)); GRAND NCE programs; FPU(Spanish Government); NVIDIA	The work of the MIT affiliated coauthors was funded by the Media Lab Consortium Members, DARPA through the DARPA YFA grant, and the Institute for Soldier Nanotechnologies and U.S. Army Research Office under contract W911NF-07-D-0004. The work of the Tsinghua affiliated coauthorswas supported by the National Basic Research Project (No. 2010CB731800) of China and the Key Project of NSFC (No. 61120106003 and 60932007). O'Toole received the support of the NSERC PGS-D and GRAND NCE programs. Masia was additionally funded by an FPU grant, project TIN2010-21543 and an NVIDIA Graduate Fellowship.	ABRAMSON N, 1978, OPT LETT, V3, P121, DOI 10.1364/OL.3.000121; [Anonymous], 2012, GUID STREAK CAM; Arvo J., 1993, SIGGRAPH; Bai JM, 2010, LECT NOTES COMPUT SC, V6312, P294; Brooker G., 2009, INTRO SENSORS RANGIN; Busck J, 2004, APPL OPTICS, V43, P4705, DOI 10.1364/AO.43.004705; Chen CH, 2007, IEEE C EVOL COMPUTAT, P1; Gleckler AD, 2000, P SOC PHOTO-OPT INS, V4035, P266, DOI 10.1117/12.397800; Gupta M, 2011, PROC CVPR IEEE, P713, DOI 10.1109/CVPR.2011.5995321; Gupta M, 2009, PROC CVPR IEEE, P2961; Gupta O, 2012, OPT EXPRESS, V20, P19096, DOI 10.1364/OE.20.019096; Heide F., 2013, ACM T GRAPHICS, V32; Holroyd M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778836; HUANG D, 1991, SCIENCE, V254, P1178, DOI 10.1126/science.1957169; Jarabo A., 2013, P CEIG; Kajiya J.T., 1986, SIGGRAPH, P143, DOI [DOI 10.1145/15922.15902, 10.1145/15886.15902, DOI 10.1145/15886.15902]; Liu SY, 2010, LECT NOTES COMPUT SC, V6312, P280; Mukaigawa Y, 2010, PROC CVPR IEEE, P153, DOI 10.1109/CVPR.2010.5540216; Naik N, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024205; Nayar SK, 2006, ACM T GRAPHIC, V25, P935, DOI 10.1145/1141911.1141977; Ng TT, 2012, INT J COMPUT VISION, V96, P235, DOI 10.1007/s11263-011-0467-6; O'Toole M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185535; Pandharkar R, 2011, PROC CVPR IEEE, P265, DOI 10.1109/CVPR.2011.5995465; Reddy D, 2012, LECT NOTES COMPUT SC, V7577, P596, DOI 10.1007/978-3-642-33783-3_43; Repasi E, 2009, APPL OPTICS, V48, P5956, DOI 10.1364/AO.48.005956; Seitz SM, 2005, IEEE I CONF COMP VIS, P1440; Sen P, 2005, ACM T GRAPHIC, V24, P745, DOI 10.1145/1073204.1073257; Velten A., 2012, ACM SIGGRAPH TALKS, V41; Velten A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461928; Velten A, 2012, NAT COMMUN, V3, DOI 10.1038/ncomms1747; Wang L. V., 2007, BIOMEDICAL OPTICS PR; Wetzstein G, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P391, DOI 10.1109/PG.2007.47; Wu D, 2012, LECT NOTES COMPUT SC, V7572, P542, DOI 10.1007/978-3-642-33718-5_39; Wyant JC, 2002, PROC SPIE, V4737, P98, DOI 10.1117/12.474947; Xia HY, 2009, OPT LETT, V34, P2108, DOI 10.1364/OL.34.002108; Zhang L, 2006, ACM T GRAPHIC, V25, P907, DOI 10.1145/1141911.1141974	36	45	45	2	32	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	2014	107	2			SI		123	138		10.1007/s11263-013-0668-2	http://dx.doi.org/10.1007/s11263-013-0668-2			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AD3QP		Green Submitted			2022-12-18	WOS:000333161200003
J	Yao, L; Suryanarayan, P; Qiao, M; Wang, JZ; Li, J				Yao, Lei; Suryanarayan, Poonam; Qiao, Mu; Wang, James Z.; Li, Jia			OSCAR: On-Site Composition and Aesthetics Feedback Through Exemplars for Photographers	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Mobile; Photo composition; Aesthetics rating; Color analysis; Digital photography		In this paper we describe a comprehensive system to enhance the aesthetic quality of the photographs captured by the mobile consumers. The system, named OSCAR, has been designed to provide on-site composition and aesthetics feedback through retrieved examples. We introduce three novel interactive feedback components. The first is the composition feedback which is qualitative in nature and responds by retrieving highly aesthetic exemplar images from the corpus which are similar in content and composition to the snapshot. The second is the color combination feedback which provides confidence on the snapshot to contain good color combinations. The third component is the overall aesthetics feedback which predicts the aesthetic ratings for both color and monochromatic images. An existing algorithm is used to provide ratings for color images, while new features and a new model are developed to treat monochromatic images. This system was designed keeping the next generation photography needs in mind and is the first of its kind. The feedback rendered is guiding and intuitive in nature. It is computed in situ while requiring minimal input from the user.	[Yao, Lei; Suryanarayan, Poonam; Wang, James Z.] Penn State Univ, Coll Informat Sci & Technol, University Pk, PA 16802 USA; [Li, Jia] Penn State Univ, Dept Comp Sci & Engn, Dept Stat, University Pk, PA 16802 USA; [Wang, James Z.] Natl Sci Fdn, Off Int Sci & Engn, Arlington, VA 22230 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park; National Science Foundation (NSF)	Yao, L (corresponding author), Penn State Univ, Coll Informat Sci & Technol, University Pk, PA 16802 USA.	luy112@ist.psu.edu; pzs126@psu.edu; muq103@cse.psu.edu; jwang@ist.psu.edu; jiali@stat.psu.edu		Wang, James/0000-0003-4379-4173	National Science Foundation [0347148, 0936948];  [0821527]; Div Of Information & Intelligent Systems [1110970] Funding Source: National Science Foundation; Office of Advanced Cyberinfrastructure (OAC) [0821527] Funding Source: National Science Foundation	National Science Foundation(National Science Foundation (NSF)); ; Div Of Information & Intelligent Systems(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE)); Office of Advanced Cyberinfrastructure (OAC)(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	We thank the reviewers and editors for their comments and suggestions. Undergraduate students Razvan Orendovici, John Schleicher, and David Zhang assisted in the prototype development. This material is based upon work supported by the National Science Foundation under Grant Nos. 0347148 and 0936948. The computational infrastructure was provided by the Foundation through Grant No. 0821527. Part of the work of J.Z. Wang is done while working at the Foundation. Any opinion, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.	Bhattacharya Subhabrata, 2010, P 18 ACM INT C MULTI, P271; Cohen-Or D, 2006, ACM T GRAPHIC, V25, P624, DOI 10.1145/1141911.1141933; Datta R., 2010, P INT C MULT INF RET, P421, DOI [10.1145/1743384.1743457, DOI 10.1145/1743384.1743457]; Datta R, 2006, LECT NOTES COMPUT SC, V3953, P288, DOI 10.1007/11744078_23; Davies H., 2010, CREATIVE BLACK WHITE; Feininger A., 1973, PRINCIPLES COMPOSITI; Fogarty J., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P141, DOI 10.1145/502348.502369; Folts J. A., 2005, HDB PHOTOGRAPHY; Gao XP, 2007, COLOR RES APPL, V32, P223, DOI 10.1002/col.20321; GERSHO A, 1979, IEEE T INFORM THEORY, V25, P373, DOI 10.1109/TIT.1979.1056067; Gill M, 2000, COLOR HARMONY PASTEL; Henri R, 2007, ART SPIRIT; ITTEN J, 1960, ART COLOR; Jia Li, 2000, Proceedings ACM Multimedia 2000, P147; Jia Li, 2011, Statistical Analysis and Data Mining, V4, P84, DOI 10.1002/sam.10109; Karatzoglou A., 2004, J STAT SOFTW, V11, P1, DOI 10.18637/jss.v011.i09; Ke Yan, 2006, 2006 IEEE COMPUTER S, V1, P419, DOI DOI 10.1109/CVPR.2006.303; Kisilev P., 2007, P IEEE INT C IM PROC, P117; KRAGES BPK, 2005, PHOTOGRAPHY ART COMP; Lamb J., 2010, SOCIAL STUDIES TEXAN, V26, P59; Li J, 2007, J MACH LEARN RES, V8, P1687; Liu LG, 2010, COMPUT GRAPH FORUM, V29, P469, DOI 10.1111/j.1467-8659.2009.01616.x; Luo YW, 2008, LECT NOTES COMPUT SC, V5304, P386; MALLOWS CL, 1972, ANN MATH STAT, V43, P508, DOI 10.1214/aoms/1177692631; Manav B, 2007, COLOR RES APPL, V32, P144, DOI 10.1002/col.20294; Meer P, 2001, IEEE T PATTERN ANAL, V23, P1351, DOI 10.1109/34.977560; Obrador P, 2010, P ACM MULT C, P561, DOI DOI 10.1145/1873951.1874; Obrador P., 2009, PROC 1 SIGMM WORKSHO, P65; Peters G, 2007, IEEE INT CONF INF VI, P316; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Russ J.C., 2006, IMAGE PROCESSING HDB, VFifth; Scholkopf B, 2007, P IEEE C ADV NEUR IN, P542; Speed Harold, 1972, PRACTICE SCI DRAWING; Sternberg R., 2008, COGNITIVE PSYCHOL; Suess B. J, 1995, MASTERING BLACK WHIT; Sutton T, 2004, QGIS DOCUMENTATION C; Taylor M., 1998, KODAK WORKSHOP SERIE; Tokumaru M, 2002, PROCEEDINGS OF THE 2002 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOL 1 & 2, P378, DOI 10.1109/FUZZ.2002.1005020; Tong HH, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P17, DOI 10.1109/ICME.2004.1394114; Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109; Warren B, 2002, PHOTOGRAPHY CONCISE; Wong L., 2009, P IEEE INT C IM PROC, P993	43	45	52	0	14	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	FEB	2012	96	3					353	383		10.1007/s11263-011-0478-3	http://dx.doi.org/10.1007/s11263-011-0478-3			31	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	885HK					2022-12-18	WOS:000299769400006
J	Wu, TF; Zhu, SC				Wu, Tianfu; Zhu, Song-Chun			A Numerical Study of the Bottom-Up and Top-Down Inference Processes in And-Or Graphs	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Bottom-up/Top-down inference; a-beta-gamma process; Information contribution; Hierarchical model; And-Or graph; Object parsing	OBJECT RECOGNITION; VISUAL FEATURES; SEGMENTATION; MODELS	This paper presents a numerical study of the bottom-up and top-down inference processes in hierarchical models using the And-Or graph as an example. Three inference processes are identified for each node A in a recursively defined And-Or graph in which stochastic context sensitive image grammar is embedded: the alpha(A) process detects node A directly based on image features, the beta(A) process computes node A by binding its child node(s) bottom-up and the gamma(A) process predicts node A top-down from its parent node(s). All the three processes contribute to computing node A from images in complementary ways. The objective of our numerical study is to explore how much information each process contributes and how these processes should be integrated to improve performance. We study them in the task of object parsing using And-Or graph formulated under the Bayesian framework. Firstly, we isolate and train the alpha(A), beta(A) and gamma(A) processes separately by blocking the other two processes. Then, information contributions of each process are evaluated individually based on their discriminative power, compared with their respective human performance. Secondly, we integrate the three processes explicitly for robust inference to improve performance and propose a greedy pursuit algorithm for object parsing. In experiments, we choose two hierarchical case studies: one is junctions and rectangles in low-to-middle-level vision and the other is human faces in high-level vision. We observe that (i) the effectiveness of the alpha(A), beta(A) and gamma(A) processes depends on the scale and occlusion conditions, (ii) the alpha(face) process is stronger than the alpha processes of facial components, while beta(junctions) and beta(rectangle) work much better than their alpha processes, and (iii) the integration of the three processes improves performance in ROC comparisons.	[Wu, Tianfu; Zhu, Song-Chun] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA; [Zhu, Song-Chun] Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90024 USA; [Wu, Tianfu; Zhu, Song-Chun] Lotus Hill Res Inst LHI, Ezhou, Peoples R China	University of California System; University of California Los Angeles; University of California System; University of California Los Angeles	Wu, TF (corresponding author), Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA.	tfwu@stat.ucla.edu; sczhu@stat.ucla.edu		Wu, Tianfu/0000-0001-8911-5506	NSF [IIS-0713652]; ONR [N00014-07-M-0287, DMS-0707055]; China 863 project [2008AA01Z126, 2009AA01Z331]; NSF China [60728203, 60832004]	NSF(National Science Foundation (NSF)); ONR(Office of Naval Research); China 863 project(National High Technology Research and Development Program of China); NSF China(National Natural Science Foundation of China (NSFC))	This work at UCLA was supported by NSF grants IIS-0713652, ONR grant N00014-07-M-0287, DMS-0707055, and the work at LHI was supported by China 863 project 2008AA01Z126 and 2009AA01Z331, NSF China grants 60728203 and 60832004. The authors are thankful to the reviewers for their constructive comments, to Dr. Yingnian Wu for the active basis code and extensive discussions, to Xiong Yang and other artistic people at LHI for their helping us prepare the data and human study, to Brandon Rothrock, Haifeng Gong, Zhangzhang Si for their discussions.	Amit Y, 2007, INT J COMPUT VISION, V75, P267, DOI 10.1007/s11263-006-0033-9; Avidan S, 2006, LECT NOTES COMPUT SC, V3954, P386; Aycinena M., 2008, LEARNING GRAMMATICAL; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; Blanchard G, 2005, ANN STAT, V33, P1155, DOI 10.1214/009053605000000174; Borenstein E, 2008, IEEE T PATTERN ANAL, V30, P2109, DOI 10.1109/TPAMI.2007.70840; Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357; DECHTER R, 1985, J ACM, V32, P505, DOI 10.1145/3828.3830; Demirci MF, 2006, INT J COMPUT VISION, V69, P203, DOI 10.1007/s11263-006-6993-y; Demirci MF, 2009, J MATH IMAGING VIS, V35, P103, DOI 10.1007/s10851-009-0157-y; Divvala S., 2009, CVPR 2009; Epshtein B, 2008, P NATL ACAD SCI USA, V105, P14298, DOI 10.1073/pnas.0800968105; Felzenszwalb PF, 2007, J ARTIF INTELL RES, V29, P153, DOI 10.1613/jair.2187; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; FELZENSZWALB PF, 2009, PAMI IN PRESS; Fergus R, 2007, INT J COMPUT VISION, V71, P273, DOI 10.1007/s11263-006-8707-x; Fidler S., 2008, CVPR; FINK M, 2003, NIPS; Fleuret F, 2008, J MACH LEARN RES, V9, P2549; Geman S, 2002, Q APPL MATH, V60, P707, DOI 10.1090/qam/1939008; Guo CE, 2007, COMPUT VIS IMAGE UND, V106, P5, DOI 10.1016/j.cviu.2005.09.004; Han F, 2009, IEEE T PATTERN ANAL, V31, P59, DOI 10.1109/TPAMI.2008.55; Heisele B, 2007, INT J COMPUT VISION, V74, P167, DOI 10.1007/s11263-006-0006-z; Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5; Jin Y., 2006, CVPR, V2, P2145; Kokkinos I., 2009, CVPR; LAMPERT CH, 2009, PAMI IN PRESS; Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434; Levin A, 2009, INT J COMPUT VISION, V81, P105, DOI 10.1007/s11263-008-0166-0; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Meinshausen N, 2009, ANN APPL STAT, V3, P38, DOI 10.1214/08-AOAS180; Olshen R., 1984, CLASSIFICATION REGRE; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819; Schneiderman Henry, 2002, INT J COMPUTER VISIO; Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56; Si ZZ, 2009, PROC CVPR IEEE, P272, DOI 10.1109/CVPRW.2009.5206770; Sudderth EB, 2008, INT J COMPUT VISION, V77, P291, DOI 10.1007/s11263-007-0069-5; Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0; Todorovic S, 2008, IEEE T PATTERN ANAL, V30, P2158, DOI 10.1109/TPAMI.2008.24; Todorovic S, 2008, INT J COMPUT VISION, V78, P47, DOI 10.1007/s11263-007-0077-5; Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951; Torralba A, 2007, IEEE T PATTERN ANAL, V29, P854, DOI 10.1109/TPAMI.2007.1055; Tu ZW, 2005, INT J COMPUT VISION, V63, P113, DOI 10.1007/s11263-005-6642-x; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; ULLMAN S, 1984, COGNITION, V18, P97, DOI 10.1016/0010-0277(84)90023-4; Ullman S, 2002, NAT NEUROSCI, V5, P682, DOI 10.1038/nn870; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wu T., 2007, CVPR; Wu YN, 2010, INT J COMPUT VISION, V90, P198, DOI 10.1007/s11263-009-0287-0; Yao B., 2007, EMMCVPR; Zhu SC, 2006, FOUND TRENDS COMPUT, V2, P259, DOI 10.1561/0600000018	51	45	50	0	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2011	93	2					226	252		10.1007/s11263-010-0346-6	http://dx.doi.org/10.1007/s11263-010-0346-6			27	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	740PD		Green Submitted			2022-12-18	WOS:000288806000007
J	Pizarro, L; Mrazek, P; Didas, S; Grewenig, S; Weickert, J				Pizarro, Luis; Mrazek, Pavel; Didas, Stephan; Grewenig, Sven; Weickert, Joachim			Generalised Nonlocal Image Smoothing	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Discrete variational methods; Nonlocal image smoothing; Neighbourhood filters; Nonlinear filtering	NONLINEAR DIFFUSION; DISCRETE REGULARIZATION; WEIGHTED GRAPHS; PRESERVING REGULARIZATION; NOISE REMOVAL; MEAN SHIFT; FILTER; ROBUST; FRAMEWORK; SPACE	We propose a discrete variational approach for image smoothing consisting of nonlocal data and smoothness constraints that penalise general dissimilarity measures defined on image patches. One of such dissimilarity measures is the weighted L (2) distance between patches. In such a case we derive an iterative neighbourhood filter that induces a new similarity measure in the photometric domain. It can be regarded as an extended patch similarity measure that evaluates not only the patch similarity of two chosen pixels, but also the similarity of their corresponding neighbours. This leads to a more robust smoothing process since the pixels selected for averaging are more coherent with the local image structure. By slightly modifying the way the similarities are computed we obtain two related filters: The NL-means filter of Buades et al. (SIAM Multiscale Model. Simul. 4(2):490-530, 2005b) and the NDS filter of Mrazek et al. (Geometric Properties for Incomplete Data, Computational Imaging and Vision, vol. 31, pp. 335-352, Springer, Dordrecht, 2006). In fact, the proposed approach can be considered as a generalisation of the latter filter to the space of patches. We also provide novel insights into relations of the NDS filter with diffusion/regularisation methods as well as with some recently proposed graph regularisation techniques. We evaluate our method for the task of denoising greyscale and colour images degraded with Gaussian and salt-and-pepper noise, demonstrating that it compares very well to other more sophisticated approaches.	[Pizarro, Luis; Grewenig, Sven; Weickert, Joachim] Univ Saarland, Math Image Anal Grp, Fac Math & Comp Sci, D-66041 Saarbrucken, Germany; [Pizarro, Luis] Univ London Imperial Coll Sci Technol & Med, Natl Heart & Lung Inst, London SW7 2AZ, England; [Pizarro, Luis] Univ London Imperial Coll Sci Technol & Med, Dept Comp, London SW7 2AZ, England; [Mrazek, Pavel] UPEK, Prague 13000 3, Czech Republic; [Didas, Stephan] Fraunhofer Inst Techno & Wirtschaftsmath, Abt Bildverarbeitung, D-67663 Kaiserslautern, Germany	Saarland University; Imperial College London; Imperial College London; Fraunhofer Gesellschaft	Pizarro, L (corresponding author), Univ Saarland, Math Image Anal Grp, Fac Math & Comp Sci, Bldg E1-1, D-66041 Saarbrucken, Germany.	pizarro@mia.uni-saarland.de; pavel.mrazek@upek.com; stephan.didas@itwm.fraunhofer.de; grewenig@mia.uni-saarland.de; weickert@mia.uni-saarland.de			German Academic Exchange Service (DAAD) [A/05/21715]; German Research Foundation (DFG) [WE 2602/7-1]	German Academic Exchange Service (DAAD)(Deutscher Akademischer Austausch Dienst (DAAD)); German Research Foundation (DFG)(German Research Foundation (DFG))	This work has been partially funded by the German Academic Exchange Service (DAAD), grant no. A/05/21715, and the German Research Foundation (DFG), project WE 2602/7-1. We thank Raymond Chan (The Chinese University of Hong Kong) for providing the Matlab implementation of Chan et al. (2005) and the anonymous reviewers for their comments and suggestions which helped improve the paper.	Aubert G., 2006, MATH PROBLEMS IMAGE, DOI 10.1007/978-0-387-44588-5; Aurich V., 1995, MUSTERERKENNUNG, P538; Awate SP, 2006, IEEE T PATTERN ANAL, V28, P364, DOI 10.1109/TPAMI.2006.64; Awate SP, 2005, PROC CVPR IEEE, P44; Azzabou N., 2007, P IEEE INT C COMP VI, P1; Bar L, 2006, INT J COMPUT VISION, V70, P279, DOI 10.1007/s11263-006-6468-1; Barash D, 2004, IMAGE VISION COMPUT, V22, P73, DOI 10.1016/j.imavis.2003.08.005; BERTERO M, 1988, P IEEE, V76, P869, DOI 10.1109/5.5962; BILCU RC, 2007, P SPIE, V6502; Bougleux S, 2007, LECT NOTES COMPUT SC, V4485, P128; Bougleux S, 2009, INT J COMPUT VISION, V84, P220, DOI 10.1007/s11263-008-0159-z; Brouwer LEJ, 1912, MATH ANN, V71, P97; Brox T, 2008, IEEE T IMAGE PROCESS, V17, P1083, DOI 10.1109/TIP.2008.924281; Brox T, 2007, LECT NOTES COMPUT SC, V4485, P13; Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024; Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38; Buades A, 2006, NUMER MATH, V105, P1, DOI [10.1007/s00211-006-0029-y, 10.1007/s00211-006-0029-v]; Cai JF, 2008, INVERSE PROBL IMAG, V2, P187; Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196; Chan TF, 2005, IMAGE PROCESSING AND ANALYSIS, P1, DOI 10.1137/1.9780898717877; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P231, DOI 10.1109/83.902288; Charbonnier P, 1997, IEEE T IMAGE PROCESS, V6, P298, DOI 10.1109/83.551699; CHATTERJEE P, 2008, P SPIE, V6814; Chen Y, 2008, J MATH IMAGING VIS, V30, P133, DOI 10.1007/s10851-007-0042-5; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568; Chu CK, 1998, J AM STAT ASSOC, V93, P526, DOI 10.2307/2670100; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Coupe P, 2008, IEEE T MED IMAGING, V27, P425, DOI 10.1109/TMI.2007.906087; Coupe P, 2008, I S BIOMED IMAGING, P1291, DOI 10.1109/ISBI.2008.4541240; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; Darbon J, 2008, I S BIOMED IMAGING, P1331, DOI 10.1109/ISBI.2008.4541250; Didas S, 2007, INVERSE PROBL IMAG, V1, P47, DOI 10.3934/ipi.2007.1.47; Didas S, 2007, ALGORITHMS FOR APPROXIMATION, PROCEEDINGS, P51, DOI 10.1007/978-3-540-46551-5_4; Didas S, 2006, LECT NOTES COMPUT SC, V4174, P101; Elad M, 2002, IEEE T IMAGE PROCESS, V11, P1141, DOI 10.1109/TIP.2002.801126; Elmoataz A., 2008, P INT WORKSH LOC NON, P11; Elmoataz A, 2008, IEEE T IMAGE PROCESS, V17, P1047, DOI 10.1109/TIP.2008.924284; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GILBOA G, 2006, CAM0657 U CAL LOS AN; Gilboa G, 2007, MULTISCALE MODEL SIM, V6, P595, DOI 10.1137/060669358; Gilboa G, 2008, MULTISCALE MODEL SIM, V7, P1005, DOI 10.1137/070698592; GOOSSENS B, 2008, P INT WORKSH LOC NON, P143; HAMPEL FR, 1986, ROBUST STAT PROBABIL; Hein M, 2007, J MACH LEARN RES, V8, P1325; HOLLAND PW, 1977, COMMUN STAT A-THEOR, V6, P813, DOI 10.1080/03610927708827533; Huber P., 1981, ROBUST STAT; JUNG M, 2009, CAM0909 U CAL LOS AN; Kervrann C, 2008, INT J COMPUT VISION, V79, P45, DOI 10.1007/s11263-007-0096-2; Kervrann C, 2007, LECT NOTES COMPUT SC, V4485, P520; Kervrann C, 2006, IEEE T IMAGE PROCESS, V15, P2866, DOI 10.1109/TIP.2006.877529; Kindermann S, 2005, MULTISCALE MODEL SIM, V4, P1091, DOI 10.1137/050622249; KLEINSCHMIDT O, 2008, P INT WORKSH LOC NON, P103; Koenderink JJ, 1999, INT J COMPUT VISION, V31, P159, DOI 10.1023/A:1008065931878; LECLERC YG, 1989, INT J COMPUT VISION, V3, P73, DOI 10.1007/BF00054839; LEE JS, 1983, COMPUT VISION GRAPH, V24, P255, DOI 10.1016/0734-189X(83)90047-6; Liu J, 2009, INT J COMPUT VISION, V85, P182, DOI 10.1007/s11263-009-0254-9; Liu YL, 2008, J COMPUT SCI TECH-CH, V23, P270, DOI 10.1007/s11390-008-9129-8; Lou YF, 2009, LECT NOTES COMPUT SC, V5716, P62; LOUPAS T, 1989, IEEE T CIRCUITS SYST, V36, P129, DOI 10.1109/31.16577; Mahmoudi M, 2005, IEEE SIGNAL PROC LET, V12, P839, DOI 10.1109/LSP.2005.859509; Mrazek P, 2003, INT J COMPUT VISION, V52, P189, DOI 10.1023/A:1022908225256; Mrazek P, 2006, COMP IMAG VIS, P335; MUMFORD D, 1994, COMPUTATIONAL IMAGIN, V1, P141; Nikolova M, 2005, MULTISCALE MODEL SIM, V4, P960, DOI 10.1137/040619582; NORDSTROM KN, 1990, IMAGE VISION COMPUT, V8, P318, DOI 10.1016/0262-8856(90)80008-H; Orchard J, 2008, IEEE IMAGE PROC, P1732, DOI 10.1109/ICIP.2008.4712109; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Peter JD, 2008, LECT NOTES COMPUT SC, V5359, P571, DOI 10.1007/978-3-540-89646-3_56; Peyre G, 2008, LECT NOTES COMPUT SC, V5304, P57, DOI 10.1007/978-3-540-88690-7_5; Pizarro L, 2007, LECT NOTES COMPUT SC, V4522, P601; Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; SAINTMARC P, 1991, IEEE T PATTERN ANAL, V13, P514, DOI 10.1109/34.87339; Scherzer O, 2000, J MATH IMAGING VIS, V12, P43, DOI 10.1023/A:1008344608808; Schnorr C., 1994, Journal of Mathematical Imaging and Vision, V4, P189, DOI 10.1007/BF01249896; Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710; Steidl G, 2004, SIAM J NUMER ANAL, V42, P686, DOI 10.1137/S0036142903422429; STEVENSON RL, 1994, IEEE T SYST MAN CYB, V24, P455, DOI 10.1109/21.278994; Ta VT, 2009, PATTERN RECOGN, V42, P1113, DOI 10.1016/j.patcog.2008.10.029; Tikhonov A.N., 1977, SOLUTION ILL POSED P; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; van de Weijer J, 2001, PROC CVPR IEEE, P428; van den Boomgaard R, 2002, INT C PATT RECOG, P927, DOI 10.1109/ICPR.2002.1048187; van Ginneken B, 2000, J VIS COMMUN IMAGE R, V11, P196, DOI 10.1006/jvci.1999.0445; VRSCAY ER, 2008, P INT WORKSH LOC NON, P61; Weickert J, 1997, LECT NOTES COMPUT SC, V1252, P3; WEICKERT J, 1994, EUR CON MAT, V9, P355; Weickert J, 2001, INT J COMPUT VISION, V45, P245, DOI 10.1023/A:1013614317973; Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1; Winkler G., 1999, Pattern Recognition and Image Analysis, V9, P749; Winkler G., 2003, IMAGE ANAL RANDOM FI; Yaroslavsky LP., 1985, DIGITAL PICTURE PROC; Zeidler, 1993, NONLINEAR FUNCTIONAL; Zhou D., 2004, ICML 2004 WORKSHOP S, P132; ZHOU D, 2008, INT WORKSH MIN LEARN; Zhou DY, 2005, LECT NOTES COMPUT SC, V3663, P361; ZIMMER S, 2008, P 2008 INT WORKSH LO, P135	97	45	46	1	20	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	OCT	2010	90	1					62	87		10.1007/s11263-010-0337-7	http://dx.doi.org/10.1007/s11263-010-0337-7			26	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	616GA		Green Submitted			2022-12-18	WOS:000279195800004
J	Li, R; Tian, TP; Sclaroff, S; Yang, MH				Li, Rui; Tian, Tai-Peng; Sclaroff, Stan; Yang, Ming-Hsuan			3D Human Motion Tracking with a Coordinated Mixture of Factor Analyzers	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						3D human body tracking; Particle filtering; High-dimensional state space; Variational methods	PEOPLE	A major challenge in applying Bayesian tracking methods for tracking 3D human body pose is the high dimensionality of the pose state space. It has been observed that the 3D human body pose parameters typically can be assumed to lie on a low-dimensional manifold embedded in the high-dimensional space. The goal of this work is to approximate the low-dimensional manifold so that a low-dimensional state vector can be obtained for efficient and effective Bayesian tracking. To achieve this goal, a globally coordinated mixture of factor analyzers is learned from motion capture data. Each factor analyzer in the mixture is a "locally linear dimensionality reducer" that approximates a part of the manifold. The global parametrization of the manifold is obtained by aligning these locally linear pieces in a global coordinate system. To enable automatic and optimal selection of the number of factor analyzers and the dimensionality of the manifold, a variational Bayesian formulation of the globally coordinated mixture of factor analyzers is proposed. The advantages of the proposed model are demonstrated in a multiple hypothesis tracker for tracking 3D human body pose. Quantitative comparisons on benchmark datasets show that the proposed method produces more accurate 3D pose estimates over time than those obtained from two previously proposed Bayesian tracking methods.	[Li, Rui; Tian, Tai-Peng; Sclaroff, Stan] Boston Univ, Dept Comp Sci, Boston, MA 02215 USA; [Yang, Ming-Hsuan] Univ Calif, Merced, CA 95344 USA	Boston University; University of California System; University of California Merced	Li, R (corresponding author), Boston Univ, Dept Comp Sci, 111 Cummington St, Boston, MA 02215 USA.	lir@cs.bu.edu; tian@cs.bu.edu; sclaroff@cs.bu.edu; mhyang@ieee.org	Yang, Ming-Hsuan/T-9533-2019; Yang, Ming-Hsuan/AAE-7350-2019	Yang, Ming-Hsuan/0000-0003-4848-2304; 				Agarwal A., 2004, P EUR C COMP VIS, V3, P54; Balan A. O., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P349; Beal M.J., 2003, VARIATIONAL ALGORITH; Belkin M, 2002, ADV NEUR IN, V14, P585; Bishop CM, 1998, NEURAL COMPUT, V10, P215, DOI 10.1162/089976698300017953; Black M. J., 2006, CS0608 BROWN U; Brand Matthew, 2002, ADV NEURAL INFORM PR, P961; CHAM TJ, 1999, P COMP VIS PATT REC, V2, P239; Cheeseman P., 1996, ADV KNOWLEDGE DISCOV, ppp153; Choo K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P321, DOI 10.1109/ICCV.2001.937643; DESILVA V, 2003, ADV NEURAL INFORM PR, V15, P705; Deutscher J, 2000, PROC CVPR IEEE, P126, DOI 10.1109/CVPR.2000.854758; Elgammal A, 2004, PROC CVPR IEEE, P681; Elgammal A, 2009, IEEE T PATTERN ANAL, V31, P520, DOI 10.1109/TPAMI.2008.101; Ghahramani Zoubin, 1996, CRGTR961 U TOR; Ioffe S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P690, DOI 10.1109/ICCV.2001.937589; JEFFERYS WH, 1992, AM SCI, V80, P64; Jenkins O. C., 2004, P 21 INT C MACH LEAR, P56, DOI DOI 10.1145/1015330; Ju SX, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P38, DOI 10.1109/AFGR.1996.557241; KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572; Lan XY, 2004, PROC CVPR IEEE, P722; Lawrence ND, 2004, ADV NEUR IN, V16, P329; LI R, 2006, P EUR C COMP VIS ECC, V2, P137; Li R, 2007, IEEE I CONF COMP VIS, P1687; LIN RS, 2006, P EUR C COMP VIS ECC, V3, P239; MacCormick J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P572, DOI 10.1109/ICCV.1999.791275; MacKay DJC, 1996, FUND THEOR, V62, P221; MACKAY DJC, 1992, NEURAL COMPUT, V4, P415, DOI 10.1162/neco.1992.4.3.448; Mori G, 2002, LECT NOTES COMPUT SC, V2352, P666; POPPE R, 2007, ONL P WORKSH EV ART; Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016; Ramanan D, 2007, IEEE T PATTERN ANAL, V29, P65, DOI 10.1109/TPAMI.2007.250600; Rasmussen CE, 2000, ADV NEUR IN, V12, P554; Richardson S, 1997, J ROY STAT SOC B MET, V59, P731, DOI 10.1111/1467-9868.00095; ROWEIS R, 2001, ADV NEURAL INFORM PR, P889; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Safonova A, 2004, ACM T GRAPHIC, V23, P514, DOI 10.1145/1015706.1015754; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750; Sidenbladh H., 2000, LNCS, V2, P702; Sigal L, 2004, PROC CVPR IEEE, P421; Sminchisescu C, 2001, PROC CVPR IEEE, P447; SMINCHISESCU C, 2004, P INT C MACH LEARN, P140; Snelson E., 2006, ADV NEURAL INFORM PR, V18, P1259; Stenger B, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1063; Sullivan J, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P323, DOI 10.1109/ICCV.2001.937536; TEH WY, 2002, ADV NEURAL INFORM PR, P841; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tian T. P., 2005, 2005029 BOST U; TIAN TP, 2005, LEARN WORKSH CONJ CV; Urtasun R, 2005, IEEE I CONF COMP VIS, P403; URTASUN R, 2008, P IEEE INT C MACH LE; Urtasun R., 2006, 2006 IEEE COMP SOC C, V1, P238, DOI DOI 10.1109/CVPR.2006.15; Verbeek JJ, 2006, PATTERN RECOGN, V39, P1864, DOI 10.1016/j.patcog.2006.04.011; Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167; Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0	57	45	46	0	12	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2010	87	1-2			SI		170	190		10.1007/s11263-009-0283-4	http://dx.doi.org/10.1007/s11263-009-0283-4			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	539GP		Green Published, Bronze			2022-12-18	WOS:000273242300010
J	Sigal, L; Black, MJ				Sigal, Leonid; Black, Michael J.			Guest Editorial: State of the Art in Image- and Video-Based Human Pose and Motion Estimation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Editorial Material												ls@cs.toronto.edu		Black, Michael/0000-0001-6077-4540				BERGTHOLDT M, 2010, INT J COMPUTER VISIO, V87; Bo L, 2008, IEEE C COMP VIS PATT; BO L, 2010, INT J COMPUTER VISIO, V87; BO L, 2009, IEEE C COMP VIS PATT; BRUBAKER M, 2010, INT J COMPUTER VISIO, V87; Corazza S., 2010, INT J COMPUTER VISIO, V87; GALL J, 2010, INT J COMPUTER VISIO, V87; HOWE N, 2008, EVALUATING RECOGNITI; Lee C. S., 2010, INT J COMPUTER VISIO, V87; LI R, 2010, INT J COMPUTER VISIO, V87; PEURSUM P, 2010, INT J COMPUTER VISIO, V87; POPPE R, 2009, EVALUATING EXAMPLE B; Sigal L., 2010, INT J COMPUTER VISIO, V87; Urtasun R., 2008, IEEE C COMP VIS PATT	14	45	46	0	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2010	87	1-2			SI		1	3		10.1007/s11263-009-0293-2	http://dx.doi.org/10.1007/s11263-009-0293-2			3	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	539GP					2022-12-18	WOS:000273242300001
J	Lobay, A; Forsyth, DA				Lobay, A; Forsyth, DA			Shape from texture without boundaries	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						shape from texture; texture; computer vision; surface fitting; structure from motion; auto-calibration; interest point methods	GENERAL-METHOD; ORIENTATION; ISOTROPY	We describe a shape from texture method that constructs an estimate of surface geometry using only the deformation of individual texture elements. Our method does not need to use either the boundary of the observed surface or any assumption about the overall distribution of elements. The method assumes that surface texture elements are drawn from a number of different types, each of fixed shape. Neither the shape of the elements nor the number of types need be known in advance. We show that, with this assumption and assuming a generic, scaled orthographic view and texture, each type of texture element can be reconstructed in a frontal coordinate system from image instances. Interest-point methods supply a method of simultaneously obtaining instances of each texture element automatically and defining each type of element. Furthermore, image instances that have been marked in error can be identified and ignored using the Expectation-Maximization algorithm. A further EM procedure yields a surface reconstruction and a relative irradiance map from the data. We provide numerous examples of reconstructions for images of real scenes, show a comparison between our reconstruction and range maps, and demonstrate that the reconstructions display geometric and irradiance phenomena that can be observed in the original image.	Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA	University of California System; University of California Berkeley	Lobay, A (corresponding author), Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA.	daf@cs.berkeley.edu						AHUJA N, 1983, COMPUT SURV, V15, P84; AHUJA N, 1983, PATTERN MODELS; ALOIMONOS Y, 1986, IEEE C COMP VIS PATT, P584; [Anonymous], 1987, ACM SIGGRAPH COMPUTE, DOI [10.1145/37402.37427, DOI 10.1145/37402.37427]; Bajcsy R., 1976, COMPUT GRAPHICS IMAG, V5, P52, DOI DOI 10.1016/S0146-664X(76)80005-6; Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821; BERG TL, 2004, P NIPS; BLAKE A, 1990, ARTIF INTELL, V45, P323, DOI 10.1016/0004-3702(90)90011-N; BRIDSON R, 2003, SCA 03, P28; BRIDSON R, 2002, COMPUTER GRAPHICS P, P594; CHOE Y, 1991, IEEE T PATTERN ANAL, V13, P907, DOI 10.1109/34.93809; Clerc M, 2002, IEEE T PATTERN ANAL, V24, P536, DOI 10.1109/34.993560; CLERC M, 1999, INT C COMP VIS, P405; Daley D.J., 2008, INTRO THEORY POINT P, V2; FITZGIBBON AW, 2002, P 7 EUR C COMP VIS; Forsyth DA, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P447, DOI 10.1109/ICCV.2001.937659; Forsyth DA, 2002, PRENT HALL PROF TECH; FORSYTH DA, 2002, P ECCV, V3, P225; GARDING J, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P733, DOI 10.1109/ICCV.1995.466865; GARDING J, 1992, LECT NOTES COMPUT SC, V588, P630; Hastie T, 2009, ELEMENTS STAT LEARNI; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; House DH, 2000, CLOTH MODELLING ANIM; KOENDERINK JJ, 1983, J OPT SOC AM, V73, P843, DOI 10.1364/JOSA.73.000843; Krumm J., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P354, DOI 10.1109/ICCV.1990.139549; KRUMM J, 1992, IEEE C COMP VIS PATT, P284; LAZEBNIK S, 2003, IEEE C COMP VIS PATT; LAZEBNIK S, 2003, INT C COMP VIS; Lee KM, 1998, PROC CVPR IEEE, P402, DOI 10.1109/CVPR.1998.698637; LEUNG T, 1996, EUR C COMP VIS, P546; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu R, 1998, APPL OPTICS, V37, P5974, DOI 10.1364/AO.37.005974; LU R, 1999, ICCV, P2; Malik J, 1997, INT J COMPUT VISION, V23, P149, DOI 10.1023/A:1007958829620; Malik J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P918, DOI 10.1109/ICCV.1999.790346; MIKOLAJCZK K, 2003, IEEE C COMP VIS PATT; Miller EG, 2000, PROC CVPR IEEE, P464, DOI 10.1109/CVPR.2000.855856; MILLER T, 2004, P IEEE C COMP VIS PA; Mundy J. L., 1994, Applications of Invariance in Computer Vision. Second Joint European - US Workshop Proceedings, P89; Pont SC, 2002, LECT NOTES COMPUT SC, V2353, P808; Pritchard D, 2003, COMPUT GRAPH FORUM, V22, P263, DOI 10.1111/1467-8659.00673; PRITCHARD D, 2003, THESIS U BRIT COLUMB; Rosenholtz R, 1997, VISION RES, V37, P2283, DOI 10.1016/S0042-6989(96)00121-6; SAKAI K, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P527, DOI 10.1109/CVPR.1994.323877; SCHACHTER B, 1980, IEEE T PATTERN ANAL, V2, P169, DOI 10.1109/TPAMI.1980.4766995; SCHACHTER B, 1979, COMPUT VISION GRAPH, V10, P95, DOI 10.1016/0146-664X(79)90044-3; Schaffalitzky F, 1999, LECT NOTES COMPUT SC, V1681, P165; Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215; STONE JV, 1995, IEEE T PATTERN ANAL, V17, P713, DOI 10.1109/34.391414; SUPER BJ, 1995, IEEE T PATTERN ANAL, V17, P333, DOI 10.1109/34.385983; Triggs B., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P89, DOI 10.1007/BFb0055661; WITKIN AP, 1981, ARTIF INTELL, V17, P17, DOI 10.1016/0004-3702(81)90019-9	53	45	47	0	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	2006	67	1					71	91		10.1007/s11263-006-4068-8	http://dx.doi.org/10.1007/s11263-006-4068-8			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	037BS					2022-12-18	WOS:000237122300004
J	Koenderink, JJ; VanDoorn, AJ				Koenderink, JJ; VanDoorn, AJ			The generic bilinear calibration-estimation problem	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							MOTION; SHAPE; SURFACES; AFFINE; IMAGES	We identify a very general, recurring pattern in a number of well known problems in biological and machine vision. Many problems are of a peculiar double-sided nature: One attempts to estimate certain properties of the environment using a certain type of equipment and simultaneously one attempts to calibrate the same equipment on the structure of the environment. At first sight this appears the kind of the chicken and the egg problem that might well prove to be insoluble. However, due to basic constraints that universally apply (e.g., the world is only three-dimensional), a solution-up to a certain class of ambiguity transformations-often exists. The more complicated the problem is, the less important the remaining ambiguity will be, at least in a relative sense. Many well known problems are special in that they can be cast in bilinear form, sometimes after transformation or the introduction of dummy variables. Instances include photometric stereo, photometric estimations (e.g., of lightness), local (differential) image operators, a variety of photogrammetric problems, etc. It turns out that many of these problems-and together these make up a large fraction of the generic problems in machine vision today-can be cast in a simple universal framework. This framework enables one to handle arbitrarily large (that is, not minimal, consistent configurations), noisy (thus inconsistent) date sets automatically. The level at which prior information (either of a deterministic or a statistical nature) is used (assumptions such as constant albedo, rigidity, uniform distributions, etc.) is clearly separated as an additional, typically nonlinear, stage.			Koenderink, JJ (corresponding author), UNIV UTRECHT,HELMHOLTZ INST,BUYS BALLOT LAB,POB 80 000,NL-3508 TA UTRECHT,NETHERLANDS.							BORGES CF, 1991, J OPT SOC AM A, V8, P1319, DOI 10.1364/JOSAA.8.001319; Chasles M., 1855, NOUV ANN MATH, V14, P50; FAUGERAS O, 1995, J OPT SOC AM A, V12, P465, DOI 10.1364/JOSAA.12.000465; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; GERSHUN A, 1937, RGE, V42, P5; HAYAKAWA H, 1994, J OPT SOC AM A, V11, P3079, DOI 10.1364/JOSAA.11.003079; Horn B.K.P., 1989, SHAPE SHADING; JUDD DB, 1964, J OPT SOC AM, V54, P1031, DOI 10.1364/JOSA.54.001031; Klein F., 1939, ELEMENTARY MATH ADV; KOENDERINK JJ, 1987, BIOL CYBERN, V56, P247, DOI 10.1007/BF00365219; KOENDERINK JJ, 1980, OPT ACTA, V27, P981, DOI 10.1080/713820338; KOENDERINK JJ, 1992, IEEE T PATTERN ANAL, V14, P597, DOI 10.1109/34.141551; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; KOENDERINK JJ, 1993, J OPT SOC AM A, V10, P844, DOI 10.1364/JOSAA.10.000844; KONTSEVICH LL, 1994, J OPT SOC AM A, V11, P1047, DOI 10.1364/JOSAA.11.001047; KRUPPA E, 1913, STZ BER AKAD WI MN 2, V122, P1913; LAND EH, 1962, P ROY I GT BRITAIN, V39, P1; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; MALONEY LT, 1986, J OPT SOC AM A, V3, P29, DOI 10.1364/JOSAA.3.000029; Moon P, 1939, J OPT SOC AM, V29, P108, DOI 10.1364/JOSA.29.000108; OSORIO D, 1992, BIOL CYBERN, V67, P217, DOI 10.1007/BF00204394; PENTLAND AP, 1982, J OPT SOC AM, V72, P448, DOI 10.1364/JOSA.72.000448; RYDFALK M, 1987, LITHISYI0866 LINK U; SHASHUA A, 1992, 1363 MIT ART INT LAB; SPARR G, 1990, 19903 TR LUND I TECH; Stolfi J., 1991, ORIENTED PROJECTIVE; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; Wolfram S., 1991, MATH SYSTEM DOING MA; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479	32	45	47	0	2	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	JUN-JUL	1997	23	3					217	234		10.1023/A:1007971132346	http://dx.doi.org/10.1023/A:1007971132346			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	XN801					2022-12-18	WOS:A1997XN80100002
J	MURRAY, DW; BRADSHAW, KJ; MCLAUCHLAN, PF; REID, ID; SHARKEY, PM				MURRAY, DW; BRADSHAW, KJ; MCLAUCHLAN, PF; REID, ID; SHARKEY, PM			DRIVING SACCADE TO PURSUIT USING IMAGE MOTION	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							OPTICAL-FLOW; ANIMATE VISION; PERCEPTION; OBSERVER; FIELD	Within the context of active vision, scant attention has been paid to the execution of motion saccades-rapid re-adjustments of the direction of gaze to attend to moving objects. In this paper we first develop a methodology for, and give real-time demonstrations of, the use of motion detection and segmentation processes to initiate ''capture saccades'' towards a moving object. The saccade is driven by both position and velocity of the moving target under the assumption of constant target velocity, using prediction to overcome the delay introduced by visual processing. We next demonstrate the use of a first order approximation to the segmented motion field to compute bounds on the time-to-contact in the presence of looming motion. If the bound falls below a safe limit, a ''panic saccade'' is fired, moving the camera away from the approaching object. We then describe the use of image motion to realize smooth pursuit, tracking using velocity information alone, where the camera is moved so as to null a single constant image motion fitted within a central image region. Finally, we glue together capture saccades with smooth pursuit, thus effecting changes in both what is being attended to and how it is being attended to. To couple the different visual activities of waiting, saccading, pursuing and panicking, we use a finite state machine which provides inherent robustness outside of visual processing and provides a means of making repeated exploration. We demonstrate in repeated trials that the transition from saccadic motion to tracking is more likely to succeed using position and velocity control, than when using position alone.			MURRAY, DW (corresponding author), UNIV OXFORD, DEPT ENGN SCI, PARKS RD, OXFORD OX1 3PJ, ENGLAND.			Reid, Ian/0000-0001-7790-6423				ALOIMONOS J, 1987, INT J COMPUT VISION, V1, P333; BAJCSY R, 1988, P IEEE, V76, P996, DOI 10.1109/5.5968; BAJCSY R, 1992, CVGIP-IMAG UNDERSTAN, V56, P31, DOI 10.1016/1049-9660(92)90083-F; BAJCSY R, 1985, 3RD P WORKSH COMP VI; Ballard D. H., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P524, DOI 10.1109/CCV.1988.590033; BALLARD DH, 1991, ARTIF INTELL, V48, P57, DOI 10.1016/0004-3702(91)90080-4; BALLARD DH, 1989, IMAGE VISION COMPUT, V7, P3, DOI 10.1016/0262-8856(89)90013-9; BALLARD DH, 1992, CVGIP-IMAG UNDERSTAN, V56, P3, DOI 10.1016/1049-9660(92)90081-D; Birnbaum L., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P49, DOI 10.1109/ICCV.1993.378236; BROWN C, 1990, BIOL CYBERN, V63, P61, DOI 10.1007/BF00202454; BROWN C, 1990, IEEE T SYST MAN CYB, V20, P518, DOI 10.1109/21.52563; BROWN CM, 1988, TR257 U ROCH COMP SC; CAMPANI M, 1992, CVGIP-IMAG UNDERSTAN, V56, P90, DOI 10.1016/1049-9660(92)90088-K; CAMPANI M, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P22; Carpenter RHS, 1988, MOVEMENTS EYES; CIPOLLA R, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P616; CIPOLLA R, 1992, 2ND P EUR C COMP VIS, P187; Clark J. J., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P514, DOI 10.1109/CCV.1988.590032; FENNEMA CL, 1979, COMPUT VISION GRAPH, V9, P301, DOI 10.1016/0146-664X(79)90097-2; FERMULLER C, 1993, INT J COMPUT VISION, V11, P165, DOI 10.1007/BF01469227; Grosso E., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P395, DOI 10.1109/ICCV.1993.378188; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; KOENDERINK JJ, 1975, OPT ACTA, V22, P773, DOI 10.1080/713819112; MCLAUCHLAN PF, 1993, WP3OXFORD9301122D U; MCLAUCHLAN PF, 1993, SPIE SENSOR FUSION, V6; MCLAUCHLAN PF, 1992, 3 BMVC LEEDS, P357; NELSON RC, 1991, INT J COMPUT VISION, V7, P33, DOI 10.1007/BF00130488; OLSON TJ, 1991, INT J COMPUT VISION, V7, P67, DOI 10.1007/BF00130490; PAHLAVAN K, 1992, CVGIP-IMAG UNDERSTAN, V56, P41, DOI 10.1016/1049-9660(92)90084-G; RIMEY RD, 1992, 2ND P EUR C COMP VIS, P542; SHARKEY PM, 1993, MECHATRONICS, V3, P517, DOI 10.1016/0957-4158(93)90021-S; SHARKEY PM, 1993, SPIE SENSOR FUSION, V6; SHARKEY PM, 1992, 2ND P INT C AUT ROB; SWAIN MJ, 1993, INT J COMPUT VISION, V11, P109, DOI 10.1007/BF01469224; VERRI A, 1989, IEEE T PATTERN ANAL, V11, P490, DOI 10.1109/34.24781; VERRI A, 1987, 1ST P INT C COMP VIS, P171; Yarbus A. L., 1967, EYE MOVEMENTS VISION, P171	37	45	46	0	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	1995	16	3					205	228		10.1007/BF01539627	http://dx.doi.org/10.1007/BF01539627			24	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	TC768					2022-12-18	WOS:A1995TC76800002
J	Lv, FF; Li, Y; Lu, F				Lv, Feifan; Li, Yu; Lu, Feng			Attention Guided Low-Light Image Enhancement with a Large Scale Low-Light Simulation Dataset	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Low-light image enhancement; Low-light simulation; Synthetic dataset; Attention guidance; Deep neural network	QUALITY ASSESSMENT; CONTRAST ENHANCEMENT; RETINEX	Low-light image enhancement is challenging in that it needs to consider not only brightness recovery but also complex issues like color distortion and noise, which usually hide in the dark. Simply adjusting the brightness of a low-light image will inevitably amplify those artifacts. To address this difficult problem, this paper proposes a novel end-to-end attention-guided method based on multi-branch convolutional neural network. To this end, we first construct a synthetic dataset with carefully designed low-light simulation strategies. The dataset is much larger and more diverse than existing ones. With the new dataset for training, our method learns two attention maps to guide the brightness enhancement and denoising tasks respectively. The first attention map distinguishes underexposed regions from well lit regions, and the second attention map distinguishes noises from real textures. With their guidance, the proposed multi-branch decomposition-and-fusion enhancement network works in an input adaptive way. Moreover, a reinforcement-net further enhances color and contrast of the output image. Extensive experiments on multiple datasets demonstrate that our method can produce high fidelity enhancement results for low-light images and outperforms the current state-of-the-art methods by a large margin both quantitatively and visually.	[Lv, Feifan; Lu, Feng] Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China; [Li, Yu] Tencent PCG, Appl Res Ctr ARC, Shenzhen 518066, Peoples R China; [Lu, Feng] Peng Cheng Lab, Shenzhen 518066, Peoples R China	Beihang University; Peng Cheng Laboratory	Lu, F (corresponding author), Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.; Lu, F (corresponding author), Peng Cheng Lab, Shenzhen 518066, Peoples R China.	lufeng@buaa.edu.cn		LI, Yu/0000-0003-1865-8276; Lu, Feng/0000-0001-9064-7964	National Natural Science Foundation of China (NSFC) [61972012, 61732016]	National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC))	This work was supported by National Natural Science Foundation of China (NSFC) under Grant 61972012 and 61732016.	Abadi Martin, 2016, arXiv; Abdulla W., 2017, GITHUB REPOSITORY, DOI DOI 10.1109/CVPR.2017.106; Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548; Azzari L, 2016, IEEE SIGNAL PROC LET, V23, P1086, DOI 10.1109/LSP.2016.2580600; Bileschi S. M., 2006, STREETSCENES SCENE U; Bronstein A.M, 2017, ARXIV PREPRINT ARXIV; Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218; Celik T, 2011, IEEE T IMAGE PROCESS, V20, P3431, DOI 10.1109/TIP.2011.2157513; Chen C, 2018, PROC CVPR IEEE, P3291, DOI 10.1109/CVPR.2018.00347; Chen JW, 2018, PROC CVPR IEEE, P3155, DOI 10.1109/CVPR.2018.00333; Chen QF, 2017, IEEE I CONF COMP VIS, P2516, DOI 10.1109/ICCV.2017.273; Chen YS, 2018, PROC CVPR IEEE, P6306, DOI 10.1109/CVPR.2018.00660; Chen ZY, 2006, IEEE T IMAGE PROCESS, V15, P2290, DOI 10.1109/TIP.2006.875204; Chollet F., 2015, KERAS; Dabov K, 2006, PROC SPIE, V6064, DOI 10.1117/12.643267; Dai D., 2019, INT J COMPUT VISION; Dai DX, 2018, IEEE INT C INTELL TR, P3819, DOI 10.1109/ITSC.2018.8569387; DE STOUTZ E, 2018, P EUROPEAN C COMPUTE, P260; Dong X, 2011, IEEE INT CON MULTI; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304; Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031; Gharbi M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073592; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Grossberg MD, 2004, IEEE T PATTERN ANAL, V26, P1272, DOI 10.1109/TPAMI.2004.88; Grubinger M., 2006, INT WORKSHOP ONTOIMA, V2; Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450; Hasler D, 2003, P SOC PHOTO-OPT INS, V5007, P87, DOI 10.1117/12.477378; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; Hui Z., 2018, EUR C COMP VIS WORKS; Ibrahim H, 2007, IEEE T CONSUM ELECTR, V53, P1752, DOI 10.1109/TCE.2007.4429280; Ignatov A, 2017, IEEE I CONF COMP VIS, P3297, DOI 10.1109/ICCV.2017.355; Jiang Y., 2019, ARXIV PREPRINT ARXIV; Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272; Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356; King DB, 2015, ACS SYM SER, V1214, P1; LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Lee CH, 2013, 2013 INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P43, DOI 10.1109/SITIS.2013.19; Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059; Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu J., 2018, P BRIT MECH VIS C, P1; Loh YP, 2019, COMPUT VIS IMAGE UND, V178, P30, DOI 10.1016/j.cviu.2018.10.010; Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008; Lv FF, 2020, AAAI CONF ARTIF INTE, V34, P11725; Lv J. W. Feifan, 2018, BR MACH VIS C; Ma, 2017, ARXIV E PRINTS; Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920; Mertens T, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P382, DOI 10.1109/PG.2007.17; Nakai K, 2013, I S INTELL SIG PROC, P445, DOI 10.1109/ISPACS.2013.6704591; Pech-Pacheco JL, 2000, INT C PATT RECOG, P314, DOI 10.1109/ICPR.2000.903548; Radenovic F, 2016, PROC CVPR IEEE, P5488, DOI 10.1109/CVPR.2016.592; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P4364, DOI 10.1109/TIP.2019.2910412; Ren XT, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351427; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Sakaridis C, 2019, IEEE I CONF COMP VIS, P7373, DOI 10.1109/ICCV.2019.00747; Sharma V, 2018, PROC CVPR IEEE, P4033, DOI 10.1109/CVPR.2018.00424; Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Tao L, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP); Tao L, 2017, IEEE IMAGE PROC, P3215; Tian CW, 2020, NEURAL NETWORKS, V121, P461, DOI 10.1016/j.neunet.2019.08.022; Wang RX, 2019, PROC CVPR IEEE, P6842, DOI 10.1109/CVPR.2019.00701; Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309; Wang WJ, 2018, IEEE INT CONF AUTOMA, P751, DOI 10.1109/FG.2018.00118; Wang Y, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2015, DOI 10.1145/3343031.3350983; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wang Z, 2019, ARXIV E PRINTS ARXIV; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Xiong RQ, 2017, IEEE T IMAGE PROCESS, V26, DOI [10.1109/TIP.2016.2621478, 10.1109/TIP.2017.2689999]; Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208; Yamashita H, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.4.043017; Yeganeh H, 2013, IEEE T IMAGE PROCESS, V22, P657, DOI 10.1109/TIP.2012.2221725; Ying ZQ, 2017, IEEE INT CONF COMP V, P3015, DOI 10.1109/ICCVW.2017.356; Ying Zhenqiang, 2017, ARXIV171100591; Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068; Zhang YH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1632, DOI 10.1145/3343031.3350926	83	44	44	21	66	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2021	129	7					2175	2193		10.1007/s11263-021-01466-8	http://dx.doi.org/10.1007/s11263-021-01466-8		MAY 2021	19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	SQ8CW		Green Submitted			2022-12-18	WOS:000648223000001
J	Li, HY; Liu, Y; Ouyang, WL; Wang, XG				Li, Hongyang; Liu, Yu; Ouyang, Wanli; Wang, Xiaogang			Zoom Out-and-In Network with Map Attention Decision for Region Proposal and Object Detection	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Computer vision; Deep learning; Object detection; Region proposals		In this paper, we propose a zoom-out-and-in network for generating object proposals. A key observation is that it is difficult to classify anchors of different sizes with the same set of features. Anchors of different sizes should be placed accordingly based on different depth within a network: smaller boxes on high-resolution layers with a smaller stride while larger boxes on low-resolution counterparts with a larger stride. Inspired by the conv/deconv structure, we fully leverage the low-level local details and high-level regional semantics from two feature map streams, which are complimentary to each other, to identify the objectness in an image. A map attention decision (MAD) unit is further proposed to aggressively search for neuron activations among two streams and attend the most contributive ones on the feature learning of the final loss. The unit serves as a decision-maker to adaptively activate maps along certain channels with the solely purpose of optimizing the overall training loss. One advantage of MAD is that the learned weights enforced on each feature channel is predicted on-the-fly based on the input context, which is more suitable than the fixed enforcement of a convolutional kernel. Experimental results on three datasets demonstrate the effectiveness of our proposed algorithm over other state-of-the-arts, in terms of average recall for region proposal and average precision for object detection.	[Li, Hongyang; Liu, Yu; Wang, Xiaogang] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China; [Ouyang, Wanli] Univ Sydney, Sydney, NSW, Australia	Chinese University of Hong Kong; University of Sydney	Li, HY (corresponding author), Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.	yangli@ee.cuhk.edu.hk; yuliu@ee.cuhk.edu.hk; wanli.ouyang@sydney.edu.au; xgwang@ee.cuhk.edu.hk	Ouyang, Wanli/I-7135-2018	Ouyang, Wanli/0000-0002-9163-2761	Hong Kong Ph.D. Fellowship scheme	Hong Kong Ph.D. Fellowship scheme	We would like to thank reviewers for helpful comments, S. Gidaris, X. Tong and K. Kang for fruitful discussions along the way, W. Yang for proofreading the manuscript. H. Li is funded by the Hong Kong Ph.D. Fellowship scheme. We are also grateful for SenseTime Group Ltd. donating the resource of GPUs at time of this project.	Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arbelaez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49; Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314; Chavali N, 2016, PROC CVPR IEEE, P835, DOI 10.1109/CVPR.2016.97; Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414; Chi Z., 2016, ARXIV 1612 06053; Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89; Dai Jifeng, 2016, ADV NEURAL INFORM PR, P379, DOI DOI 10.1016/J.JPOWSOUR.2007.02.075; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Endres I, 2014, IEEE T PATTERN ANAL, V36, P222, DOI 10.1109/TPAMI.2013.122; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Fu C. -Y., 2017, ARXIV170106659; Ghodrati A., 2016, ARXIV160604702; Gidaris Spyros, 2016, ARXIV160604446; Girshick R., 2015, ICCV; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Graves A, 2016, NATURE, V538, P471, DOI 10.1038/nature20101; Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642; Hayder Z, 2016, PROC CVPR IEEE, P2565, DOI 10.1109/CVPR.2016.281; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; He Kaiming, 2014, ECCV; He S., 2015, ICCV; Hosang J, 2016, IEEE T PATTERN ANAL, V38, P814, DOI 10.1109/TPAMI.2015.2465908; Huang Jonathan, 2017, P IEEE C COMP VIS PA, P7310, DOI DOI 10.1109/CVPR.2017.351; Humayun A., 2014, CVPR; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Jie H., 2017, P IEEE C COMP VIS PA, P99; Jie ZQ, 2016, IEEE T IMAGE PROCESS, V25, P4525, DOI 10.1109/TIP.2016.2593342; Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98; Krahenbuhl P, 2014, LECT NOTES COMPUT SC, V8693, P725, DOI 10.1007/978-3-319-10602-1_47; Krahenbuhl P, 2015, PROC CVPR IEEE, P1574, DOI 10.1109/CVPR.2015.7298765; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kuo WC, 2015, IEEE I CONF COMP VIS, P2479, DOI 10.1109/ICCV.2015.285; Li H., 2017, ARXIV170205711; Li HY, 2016, PR MACH LEARN RES, V48; Lin T.-Y., 2017, PROC CVPR IEEE, P936, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu Y, 2017, IEEE I CONF COMP VIS, P4127, DOI 10.1109/ICCV.2017.442; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Manen S., 2013, ICCV; Mekker M, 2017, IEEE INT C INTELL TR; Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29; Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178; Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5; Pinheiro Pedro O., 2015, ADV NEURAL INFORM PR, V3, P5; Pont-Tuset J., 2015, CVPR; Redmon J., 2016, IEEE C COMPUTER VISI, DOI [10.1109/CVPR.2017.690, DOI 10.1109/CVPR.2017.690]; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Sun C, 2016, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2016.379; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Wang X., 2017, ARXIV170206890; Wang XB, 2017, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2017.8; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	59	44	46	2	18	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2019	127	3					225	238		10.1007/s11263-018-1101-7	http://dx.doi.org/10.1007/s11263-018-1101-7			14	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	HM5CT		Green Submitted			2022-12-18	WOS:000459493200001
J	Muller, M; Casser, V; Lahoud, J; Smith, N; Ghanem, B				Muller, Matthias; Casser, Vincent; Lahoud, Jean; Smith, Neil; Ghanem, Bernard			Sim4CV: A Photo-Realistic Simulator for Computer Vision Applications	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Simulator; Unreal Engine 4; Object tracking; Autonomous driving; Deep learning; Imitation learning	TRACKING	We present a photo-realistic training and evaluation simulator (Sim4CV) (http://www.sim4cv.org) with extensive applications across various fields of computer vision. Built on top of the Unreal Engine, the simulator integrates full featured physics based cars, unmanned aerial vehicles (UAVs), and animated human actors in diverse urban and suburban 3D environments. We demonstrate the versatility of the simulator with two case studies: autonomous UAV-based tracking of moving objects and autonomous driving using supervised learning. The simulator fully integrates both several state-of-the-art tracking algorithms with a benchmark evaluation tool and a deep neural network architecture for training vehicles to drive autonomously. It generates synthetic photo-realistic datasets with automatic ground truth annotations to easily extend existing real-world datasets and provides extensive synthetic data variety through its ability to reconfigure synthetic worlds on the fly using an automatic world generation tool.	[Muller, Matthias; Casser, Vincent; Lahoud, Jean; Smith, Neil; Ghanem, Bernard] KAUST, Elect Engn, Visual Comp Ctr, Thuwal, Saudi Arabia	King Abdullah University of Science & Technology	Muller, M (corresponding author), KAUST, Elect Engn, Visual Comp Ctr, Thuwal, Saudi Arabia.	matthias.mueller.2@kaust.edu.sa; vincent.casser@gmail.com; jean.lahoud@kaust.edu.sa; neilsmith@kaust.edu.sa; bernard.ghanem@kaust.edu.sa		Mueller, Matthias/0000-0001-5249-8734; Lahoud, Jean/0000-0003-0315-6484	King Abdullah University of Science and Technology (KAUST) Office of Sponsored Research through the VCC	King Abdullah University of Science and Technology (KAUST) Office of Sponsored Research through the VCC(King Abdullah University of Science & Technology)	This work was supported by the King Abdullah University of Science and Technology (KAUST) Office of Sponsored Research through the VCC funding.	Andersson Olov, 2017, 31 AAAI C ART INT AA; [Anonymous], 2015, ARXIV151104668; [Anonymous], P EUR C COMP VIS WOR; Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226; Battaglia PW, 2013, P NATL ACAD SCI USA, V110, P18327, DOI 10.1073/pnas.1306572110; Bojarski M., 2016, ARXIV160407316; Brockman G., 2016, OPENAI GYM; Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI [10.1109/ICCV.2015.104, 10.1109/ICCV.2015.312]; COLLINS R, 2005, IEEE INT WORKSH PERF; Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29; Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490; Dosovitskiy A., 2017, C ROBOT LEARNING, P1; Fu CH, 2014, IEEE INT CONF ROBOT, P5441, DOI 10.1109/ICRA.2014.6907659; Furrer F, 2016, STUD COMPUT INTELL, V625, P595, DOI 10.1007/978-3-319-26054-9_23; GAIDON A, 2016, PROC CVPR IEEE, P4340, DOI DOI 10.1109/CVPR.2016.470; Gaszczak A, 2011, PROC SPIE, V7878, DOI 10.1117/12.876663; Ha S, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2682626; Hamalainen P, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2767002; Hamalainen P, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601218; Hejrati M, 2014, PROC CVPR IEEE, P2449, DOI 10.1109/CVPR.2014.314; Ju E, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2516971.2516976; Kendall AG, 2014, INT CONF UNMAN AIRCR, P404, DOI 10.1109/ICUAS.2014.6842280; Koutnik J, 2013, GECCO'13: PROCEEDINGS OF THE 2013 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P1061; Koutnik Jan, 2014, ONLINE EVOLUTION DEE, P260, DOI [10.1007/978-3-319-08864-8_25, DOI 10.1007/978-3-319-08864-8_25]; Lecun Y., 2006, ADV NEURAL INFORM PR, V18, P739; Lerer A., 2016, ARXIV160301312V1; Levine S., 2016, CAD2RL REAL SINGLE I; Li AN, 2016, IEEE T PATTERN ANAL, V38, P335, DOI 10.1109/TPAMI.2015.2417577; Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905; Lillicrap T., 2016, INT C MACH LEARN; Lim H, 2015, IEEE INT CONF ROBOT, P2182, DOI 10.1109/ICRA.2015.7139487; Marin J, 2010, PROC CVPR IEEE, P137, DOI 10.1109/CVPR.2010.5540218; Mnih V., 2016, INT C MACH LEARN, DOI DOI 10.5555/3045390.3045594; Movshovitz-Attias Y., 2014, P BRIT MACH VIS C, DOI [10.5244/C.28.53, DOI 10.5244/C.28.53]; Mueller M., 2016, IEEE ICC; Mueller M., 2017, P IEEE C COMP VIS PA; Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27; Naseer T, 2013, IEEE INT C INT ROBOT, P624, DOI 10.1109/IROS.2013.6696416; Nussberger A, 2014, INT CONF UNMAN AIRCR, P1284, DOI 10.1109/ICUAS.2014.6842386; Pepik B, 2012, PROC CVPR IEEE, P3362, DOI 10.1109/CVPR.2012.6248075; Pestana J, 2013, IEEE INT SYMP SAFE; Pollard Thomas, 2012, 2012 IEEE COMP SOC C, P15, DOI DOI 10.1109/CVPRW.2012.6239201; Pomerleau D.A., 1989, ALVINN AUTONOMOUS LA; Portmann J, 2014, IEEE INT CONF ROBOT, P1794, DOI 10.1109/ICRA.2014.6907094; Prabowo YA, 2015, 5TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING AND INFORMATICS 2015, P247, DOI 10.1109/ICEEI.2015.7352505; Prokaj J, 2014, PROC CVPR IEEE, P1186, DOI 10.1109/CVPR.2014.155; Qadir A., 2011, INF AER C, DOI [10.2514/6.2011-1503, DOI 10.2514/6.2011-1503]; Qiu W, 2017, ACM MULTIMEDIA OPEN; Richter SR, 2016, LECT NOTES COMPUT SC, V9906, P102, DOI 10.1007/978-3-319-46475-6_7; Roberto deSouza Cesar, 2017, IEEE C COMP VIS PATT; Ros G., 2016, CVPR; Schoeler M., 2015, ARXIV150800835; Shah S., 2017, FSR; Shah U, 2016, TENTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS AND IMAGE PROCESSING (ICVGIP 2016), DOI 10.1145/3009977.3010047; Smeulders A. W. M., 2014, IEEE T PATTERN ANAL, V37, DOI DOI 10.1109/TPAMI.2013.230; Smolyanskiy Nikolai, 2017, ARXIV170502550; Tan J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601121; Trilaksono BR, 2011, AIRCR ENG AEROSP TEC, V83, P407, DOI 10.1108/00022661111173289; Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312; Wymann B., 2014, TORCS OPEN RACING CA; Zhang J., 2014, P EUR C COMP VIS ECC	61	44	46	2	28	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2018	126	9			SI		902	919		10.1007/s11263-018-1073-7	http://dx.doi.org/10.1007/s11263-018-1073-7			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	GQ3HQ		Green Submitted			2022-12-18	WOS:000441553300002
J	Denis, L; Thiebaut, E; Soulez, F; Becker, JM; Mourya, R				Denis, Loic; Thiebaut, Eric; Soulez, Ferreol; Becker, Jean-Marie; Mourya, Rahul			Fast Approximations of Shift-Variant Blur	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Blur; Deconvolution; Inverse problems; Image restoration; PSF	POINT-SPREAD FUNCTION; RESTORATION; IMAGE; SPACE; DECONVOLUTION; MODELS	Image deblurring is essential in high resolution imaging, e.g., astronomy, microscopy or computational photography. Shift-invariant blur is fully characterized by a single point-spread-function (PSF). Blurring is then modeled by a convolution, leading to efficient algorithms for blur simulation and removal that rely on fast Fourier transforms. However, in many different contexts, blur cannot be considered constant throughout the field-of-view, and thus necessitates to model variations of the PSF with the location. These models must achieve a trade-off between the accuracy that can be reached with their flexibility, and their computational efficiency. Several fast approximations of blur have been proposed in the literature. We give a unified presentation of these methods in the light of matrix decompositions of the blurring operator. We establish the connection between different computational tricks that can be found in the literature and the physical sense of corresponding approximations in terms of equivalent PSFs, physically-based approximations being preferable. We derive an improved approximation that preserves the same desirable low complexity as other fast algorithms while reaching a minimal approximation error. Comparison of theoretical properties and empirical performances of each blur approximation suggests that the proposed general model is preferable for approximation and inversion of a known shift-variant blur.	[Denis, Loic; Becker, Jean-Marie; Mourya, Rahul] Univ Lyon, F-42023 St Etienne, France; [Denis, Loic; Becker, Jean-Marie; Mourya, Rahul] CNRS, UMR 5516, Lab Hubert Curien, F-42000 St Etienne, France; [Denis, Loic; Becker, Jean-Marie; Mourya, Rahul] Univ St Etienne, F-42000 St Etienne, France; [Thiebaut, Eric; Soulez, Ferreol] Univ Lyon, F-69000 Lyon, France; [Thiebaut, Eric; Soulez, Ferreol] Univ Lyon 1, F-69622 Villeurbanne, France; [Thiebaut, Eric; Soulez, Ferreol] Observ Lyon, Ctr Rech Astrophys Lyon, F-69561 St Genis Laval, France; [Thiebaut, Eric; Soulez, Ferreol] Ecole Normale Super Lyon, CNRS, UMR 5574, F-69007 Lyon, France	Centre National de la Recherche Scientifique (CNRS); CNRS - Institute for Engineering & Systems Sciences (INSIS); Universite Jean Monnet; Universite Jean Monnet; UDICE-French Research Universities; Universite Claude Bernard Lyon 1; Centre National de la Recherche Scientifique (CNRS); CNRS - National Institute for Earth Sciences & Astronomy (INSU); Ecole Normale Superieure de Lyon (ENS de LYON)	Denis, L (corresponding author), Univ Lyon, F-42023 St Etienne, France.	loic.denis@univ-st-etienne.fr; eric.thiebaut@univ-lyon1.fr; ferreol.soulez@univ-lyon1.fr; jean-marie.becker@univ-st-etienne.fr; r.mourya@univ-st-etienne.fr	Mourya, Rahul/AAH-6455-2020; Denis, Loic/O-5871-2019; Soulez, ferreol/AAG-1001-2020; Denis, Loïc/B-5591-2009	Mourya, Rahul/0000-0003-4502-5810; Denis, Loic/0000-0001-9216-8318; Soulez, ferreol/0000-0001-5678-1182; Denis, Loïc/0000-0001-9216-8318	Project MiTiV - French National Research Agency [ANR DEFI 09-EMER-008-01]; program "Investissements d'Avenir" [ANR-11-IDEX-0007]; Region Rhone-Alpes	Project MiTiV - French National Research Agency(French National Research Agency (ANR)); program "Investissements d'Avenir"(French National Research Agency (ANR)); Region Rhone-Alpes(Region Auvergne-Rhone-Alpes)	This work has been supported by Project MiTiV funded by the French National Research Agency (ANR DEFI 09-EMER-008-01). It has been performed in part within the framework of the LABEX PRIMES (ANR-11-LABX-0063) of Universite de Lyon, within the program "Investissements d'Avenir" (ANR-11-IDEX-0007) operated by the French National Research Agency (ANR). Rahul Mourya acknowledges a PhD Grant funded by the Region Rhone-Alpes.	Almeida MSC, 2009, IEEE IMAGE PROC, P1301, DOI 10.1109/ICIP.2009.5413592; AYERS GR, 1988, OPT LETT, V13, P547, DOI 10.1364/OL.13.000547; Bardsley J, 2006, OPT EXPRESS, V14, P1767, DOI 10.1364/OE.14.001767; Ben Hadj S, 2013, INT CONF ACOUST SPEE, P915, DOI 10.1109/ICASSP.2013.6637782; Blomgren P, 1998, IEEE T IMAGE PROCESS, V7, P304, DOI 10.1109/83.661180; Calvetti D, 2000, P SOC PHOTO-OPT INS, V4116, P364, DOI 10.1117/12.406515; Campisi P., 2007, BLIND IMAGE DECONVOL; Chacko N, 2013, J OPT SOC AM A, V30, P2012, DOI 10.1364/JOSAA.30.002012; Chakrabarti A, 2010, PROC CVPR IEEE, P2512, DOI 10.1109/CVPR.2010.5539954; Chuang YY, 2001, PROC CVPR IEEE, P264; Cresci G, 2005, ASTRON ASTROPHYS, V438, P757, DOI 10.1051/0004-6361:20052890; Delbracio M, 2012, INT J COMPUT VISION, V96, P175, DOI 10.1007/s11263-011-0460-0; DEMOMENT G, 1989, IEEE T ACOUST SPEECH, V37, P2024, DOI 10.1109/29.45551; Denis L, 2011, IEEE IMAGE PROC; Escande P., 2014, ARXIV14041023; Fish DA, 1996, J OPT SOC AM A, V13, P464, DOI 10.1364/JOSAA.13.000464; Flicker RC, 2005, J OPT SOC AM A, V22, P504, DOI 10.1364/JOSAA.22.000504; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Frigo M, 1999, ACM SIGPLAN NOTICES, V34, P169, DOI 10.1145/301631.301661; Gilad E, 2006, J COMPUT PHYS, V216, P326, DOI 10.1016/j.jcp.2005.12.003; Goodman J, 2008, INTRO FOURIER OPTICS; GREENSPAN H, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P222, DOI 10.1109/CVPR.1994.323833; Hirsch M, 2010, PROC CVPR IEEE, P607, DOI 10.1109/CVPR.2010.5540158; Levin A., 2007, ADV NEURAL INFORM PR, P841; Maalouf E, 2011, J OPT SOC AM A, V28, P1864, DOI 10.1364/JOSAA.28.001864; MAHAJAN VN, 1994, APPL OPTICS, V33, P8121, DOI 10.1364/AO.33.008121; Martin CD, 2012, AM MATH MON, V119, P838, DOI 10.4169/amer.math.monthly.119.10.838; Matakos A, 2013, IEEE T IMAGE PROCESS, V22, P2019, DOI 10.1109/TIP.2013.2244218; Miraut D, 2012, EURASIP J ADV SIG PR, P1, DOI 10.1186/1687-6180-2012-193; Mugnier LM, 2001, J OPT SOC AM A, V18, P862, DOI 10.1364/JOSAA.18.000862; Nagy JG, 1998, SIAM J SCI COMPUT, V19, P1063, DOI 10.1137/S106482759528507X; Nagy JG, 2004, NUMER ALGORITHMS, V36, P73, DOI 10.1023/B:NUMA.0000027762.08431.64; Ng J, 2007, IEEE T ULTRASON FERR, V54, P550, DOI 10.1109/TUFFC.2007.278; NOCEDAL J, 1980, MATH COMPUT, V35, P773, DOI 10.1090/S0025-5718-1980-0572855-7; PERONA P, 1995, IEEE T PATTERN ANAL, V17, P488, DOI 10.1109/34.391394; Preza C, 2004, J OPT SOC AM A, V21, P1593, DOI 10.1364/JOSAA.21.001593; Reeves SJ, 2005, IEEE T IMAGE PROCESS, V14, P1448, DOI 10.1109/TIP.2005.854474; RICHARDSON WH, 1972, J OPT SOC AM, V62, P55, DOI 10.1364/JOSA.62.000055; Rogers A, 2011, ASTROPHYS J, V743, DOI 10.1088/0004-637X/743/1/68; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Sorel M, 2008, IEEE T IMAGE PROCESS, V17, P105, DOI 10.1109/TIP.2007.912928; Soulez F, 2007, J OPT SOC AM A, V24, P3708, DOI 10.1364/JOSAA.24.003708; Soulez F, 2012, 2012 9TH IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), P1735, DOI 10.1109/ISBI.2012.6235915; TITTERINGTON DM, 1985, ASTRON ASTROPHYS, V144, P381; Wang J, 2007, FOUND TRENDS COMPUT, V3, P97, DOI 10.1561/0600000019; Wei JN, 2014, IEEE T IMAGE PROCESS, V23, P1965, DOI 10.1109/TIP.2014.2311657; Whyte O, 2010, PROC CVPR IEEE, P491, DOI 10.1109/CVPR.2010.5540175; Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278	51	44	44	0	18	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	2015	115	3					253	278		10.1007/s11263-015-0817-x	http://dx.doi.org/10.1007/s11263-015-0817-x			26	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	CW6EH		Green Submitted			2022-12-18	WOS:000365089800002
J	Yang, QX; Ahuja, N; Tan, KH				Yang, Qingxiong; Ahuja, Narendra; Tan, Kar-Han			Constant Time Median and Bilateral Filtering	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Bilateral filtering; Edge-preserving smoothing; Recursive filtering	MULTISCALE IMAGE SEGMENTATION; INTEGRATED EDGE; PHOTOGRAPHY; FLASH	This paper formulates both the median filter and bilateral filter as a cost volume aggregation problem whose computational complexity is independent of the filter kernel size. Unlike most of the previous works, the proposed framework results in a general bilateral filter that can have arbitrary spatial and arbitrary range filter kernels. This bilateral filter takes about 3.5 s to exactly filter a one megapixel 8-bit grayscale image on a 3.2 GHz Intel Core i7 CPU. In practice, the intensity/range and spatial domain can be downsampled to improve the efficiency. This compression can maintain very high accuracy (e.g., 40 dB) but over faster.	[Yang, Qingxiong] City Univ Hong Kong, Kowloon Tong, Hong Kong, Peoples R China; [Ahuja, Narendra] Univ Illinois, Champaign, IL USA; [Tan, Kar-Han] Hewlett Packard Labs, Palo Alto, CA USA	City University of Hong Kong; University of Illinois System; University of Illinois Urbana-Champaign; Hewlett-Packard	Yang, QX (corresponding author), City Univ Hong Kong, Kowloon Tong, Hong Kong, Peoples R China.	liiton.research@gmail.com	Yang, Qingxiong/K-1729-2015	Yang, Qingxiong/0000-0002-4378-2335; Tan, Kar Han/0000-0001-9294-2932	Research Grants Council of Hong Kong [CityU 122212]; HP lab	Research Grants Council of Hong Kong(Hong Kong Research Grants Council); HP lab	This work was supported in part by a GRF Grant from the Research Grants Council of Hong Kong (Project No. CityU 122212) and a grant from HP lab.	Adams A, 2010, COMPUT GRAPH FORUM, V29, P753, DOI 10.1111/j.1467-8659.2009.01645.x; Adams A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531327; Ahuja N, 1996, IEEE T PATTERN ANAL, V18, P1211, DOI 10.1109/34.546258; CHEN J, 2007, SIGGRAPH, V26; DAVIS LS, 1978, IEEE T SYST MAN CYB, V8, P705; Deriche R., 1992, ICIP 92. Proceedings of the 2nd Singapore International Conference on Image Processing, P263; DURAND F, 2002, SIGGRAPH, V21; Eisemann E, 2004, ACM T GRAPHIC, V23, P673, DOI 10.1145/1015706.1015778; Elad M, 2002, IEEE T IMAGE PROCESS, V11, P1141, DOI 10.1109/TIP.2002.801126; Fattal R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531328; Gastal ESL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964964; He KM, 2010, LECT NOTES COMPUT SC, V6311, P1; Huber P., 1981, ROBUST STAT; Kass M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778837; LEV A, 1977, IEEE T SYST MAN CYB, V7, P435, DOI 10.1109/TSMC.1977.4309740; Paris S, 2008, FOUND TRENDS COMPUT, V4, P1, DOI 10.1561/0600000020; Paris S, 2009, INT J COMPUT VISION, V81, P24, DOI 10.1007/s11263-007-0110-8; Perreault S, 2007, IEEE T IMAGE PROCESS, V16, P2389, DOI 10.1109/TIP.2007.902329; Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777; Pham T.Q., 2005, P INT C MULT EXP; Porikli F., 2008, CVPR; Smith J. O., 2007, INTRO DIGITAL FILTER; Tabb M, 1997, IEEE T IMAGE PROCESS, V6, P642, DOI 10.1109/83.568922; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; Viola P, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P747; Weiss B, 2006, ACM T GRAPHIC, V25, P519, DOI 10.1145/1141911.1141918; Yang QX, 2012, LECT NOTES COMPUT SC, V7572, P399, DOI 10.1007/978-3-642-33718-5_29; Yang QX, 2012, PROC CVPR IEEE, P1402, DOI 10.1109/CVPR.2012.6247827; Yang QX, 2010, LECT NOTES COMPUT SC, V6314, P87, DOI 10.1007/978-3-642-15561-1_7; Yin L, 1996, IEEE T CIRCUITS-II, V43, P157, DOI 10.1109/82.486465	30	44	45	1	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2015	112	3					307	318		10.1007/s11263-014-0764-y	http://dx.doi.org/10.1007/s11263-014-0764-y			12	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	CG3EA					2022-12-18	WOS:000353159600003
J	Kawakami, R; Zhao, HX; Tan, RT; Ikeuchi, K				Kawakami, Rei; Zhao, Hongxun; Tan, Robby T.; Ikeuchi, Katsushi			Camera Spectral Sensitivity and White Balance Estimation from Sky Images	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Camera spectral sensitivity; White balance; Photometric calibration; Radiometric calibration; Color correction; Sky; Turbidity	COLOR; ILLUMINATION; CALIBRATION; SHAPE	Photometric camera calibration is often required in physics-based computer vision. There have been a number of studies to estimate camera response functions (gamma function), and vignetting effect from images. However less attention has been paid to camera spectral sensitivities and white balance settings. This is unfortunate, since those two properties significantly affect image colors. Motivated by this, a method to estimate camera spectral sensitivities and white balance setting jointly from images with sky regions is introduced. The basic idea is to use the sky regions to infer the sky spectra. Given sky images as the input and assuming the sun direction with respect to the camera viewing direction can be extracted, the proposed method estimates the turbidity of the sky by fitting the image intensities to a sky model. Subsequently, it calculates the sky spectra from the estimated turbidity. Having the sky values and their corresponding spectra, the method estimates the camera spectral sensitivities together with the white balance setting. Precomputed basis functions of camera spectral sensitivities are used in the method for robust estimation. The whole method is novel and practical since, unlike existing methods, it uses sky images without additional hardware, assuming the geolocation of the captured sky is known. Experimental results using various real images show the effectiveness of the method.	[Kawakami, Rei; Zhao, Hongxun; Ikeuchi, Katsushi] Univ Tokyo, Inst Ind Sci, Tokyo, Japan; [Tan, Robby T.] Univ Utrecht, Dept Informat & Comp Sci, Utrecht, Netherlands	University of Tokyo; Utrecht University	Kawakami, R (corresponding author), Univ Tokyo, Inst Ind Sci, Tokyo, Japan.	rei@cvl.iis.u-tokyo.ac.jp; zhao@cvl.iis.u-tokyo.ac.jp; R.T.Tan@uu.nl; ki@cvl.iis.u-tokyo.ac.jp	Tan, Robby T./F-8826-2017	Tan, Robby T./0000-0001-7532-6919	Japan Society for the Promotion of Science (JSPS)	Japan Society for the Promotion of Science (JSPS)(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of Science)	This work was in part supported by the Japan Society for the Promotion of Science (JSPS) through the "Funding Program for Next Generation World-Leading Researchers (NEXT Program)," initiated by the Council for Science and Technology Policy (CSTP).	Barnard K, 2002, COLOR RES APPL, V27, P152, DOI 10.1002/col.10050; Buil C., 2005, COMP TEST CANON 10D; Chaiwiwatworakul P, 2004, ENERG BUILDINGS, V36, P650, DOI 10.1016/j.enbuild.2004.01.032; Chakrabarti A., 2009, P BRIT MACH VIS C; Debevec P., 2000, ACM T GRAPHICS SIGGR; Ebner M, 2007, GECCO 2007: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2, P642; Finlayson GD, 1998, SIXTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P90; Frieden R, 2012, PROBABILITY STAT OPT; Haber T, 2009, PROC CVPR IEEE, P627, DOI 10.1109/CVPRW.2009.5206753; Hara K, 2005, IEEE T PATTERN ANAL, V27, P493, DOI 10.1109/TPAMI.2005.82; Hordley SD, 2006, COLOR RES APPL, V31, P303, DOI 10.1002/col.20226; HUBEL PM, 1994, SECOND IS&T/SID COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P45; IKEUCHI K, 1981, IEEE T PATTERN ANAL, V3, P661, DOI 10.1109/TPAMI.1981.4767167; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; JUDD DB, 1964, J OPT SOC AM, V54, P1031, DOI 10.1364/JOSA.54.001031; Kawakami R, 2009, PROC CVPR IEEE, P635, DOI 10.1109/CVPRW.2009.5206645; Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968; Kuthirummal S, 2008, LECT NOTES COMPUT SC, V5305, P74, DOI 10.1007/978-3-540-88693-8_6; Lalonde JF, 2009, IEEE I CONF COMP VIS, P183, DOI 10.1109/ICCV.2009.5459163; Lalonde JF, 2010, INT J COMPUT VISION, V88, P24, DOI 10.1007/s11263-009-0291-4; Li YZ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1366, DOI 10.1109/ICCV.2003.1238649; Lin S, 2004, PROC CVPR IEEE, P938; Lopez-Moreno J, 2010, COMPUT GRAPH-UK, V34, P698, DOI 10.1016/j.cag.2010.08.004; McCartney E. J., 1976, SCIENCE; PARKKINEN JPS, 1989, J OPT SOC AM A, V6, P318, DOI 10.1364/JOSAA.6.000318; PEREZ R, 1993, SOL ENERGY, V50, P235, DOI 10.1016/0038-092X(93)90017-I; PRATT WK, 1976, APPL OPTICS, V15, P73, DOI 10.1364/AO.15.000073; Preetham A., 1999, ACM T GRAPHICS SIGGR; Ramanath R, 2005, IEEE SIGNAL PROC MAG, V22, P34, DOI 10.1109/MSP.2005.1407713; Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629; Sato I, 2003, IEEE T PATTERN ANAL, V25, P290, DOI 10.1109/TPAMI.2003.1182093; Sharma G., 1993, P TRANSF TRANSP COL, P103; Slater D, 1998, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.1998.698595; Snavely N., 2006, ACM T GRAPHICS SIGGR; TAKAMATSU J, 2008, P COMP VIS PATT REC; Tan RT, 2004, J OPT SOC AM A, V21, P321, DOI 10.1364/JOSAA.21.000321; Thomson M, 2001, COLOR RES APPL, V26, P442, DOI 10.1002/col.1064; Van de Weijer J, 2007, IEEE T IMAGE PROCESS, V16, P2207, DOI 10.1109/TIP.2007.901808; Vora P. L., 1997, HPL9754; WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479; Wyszecki Gunter, 1982, COLOR SCI, V8; Yu Y., 1998, ACM T GRAPHICS SIGGR; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284; Zhao H., 2009, M IM REC UND; Zhao H., 2013, SPECTRAL SENSITIVITY	45	44	45	1	33	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	2013	105	3					187	204		10.1007/s11263-013-0632-1	http://dx.doi.org/10.1007/s11263-013-0632-1			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	208EN		hybrid			2022-12-18	WOS:000323659900001
J	Budd, C; Huang, P; Klaudiny, M; Hilton, A				Budd, Chris; Huang, Peng; Klaudiny, Martin; Hilton, Adrian			Global Non-rigid Alignment of Surface Sequences	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Non-rigid surface alignment; Surface tracking; Non-sequential tracking; 3D video; 3D mesh sequences; 4D modelling	MOTION CAPTURE; SHAPE; VIDEO	This paper presents a general approach based on the shape similarity tree for non-sequential alignment across databases of multiple unstructured mesh sequences from non-rigid surface capture. The optimal shape similarity tree for non-rigid alignment is defined as the minimum spanning tree in shape similarity space. Non-sequential alignment based on the shape similarity tree minimises the total non-rigid deformation required to register all frames in a database into a consistent mesh structure with surfaces in correspondence. This allows alignment across multiple sequences of different motions, reduces drift in sequential alignment and is robust to rapid non-rigid motion. Evaluation is performed on three benchmark databases of 3D mesh sequences with a variety of complex human and cloth motion. Comparison with sequential alignment demonstrates reduced errors due to drift and improved robustness to large non-rigid deformation, together with global alignment across multiple sequences which is not possible with previous sequential approaches.	[Budd, Chris; Huang, Peng; Klaudiny, Martin; Hilton, Adrian] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England	University of Surrey	Hilton, A (corresponding author), Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.	c.budd@surrey.ac.uk; p.huang@surrey.ac.uk; m.klaudiny@surrey.ac.uk; a.hilton@surrey.ac.uk	Hilton, Adrian/N-3736-2014	Hilton, Adrian/0000-0003-4223-238X	UK EPSRC Visual Media Platform Grant; EU IST FP7 project i3Dpost; EU IST FP7 project SCENE; EPSRC [EP/F02827X/1] Funding Source: UKRI; Engineering and Physical Sciences Research Council [EP/F02827X/1] Funding Source: researchfish	UK EPSRC Visual Media Platform Grant(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EU IST FP7 project i3Dpost; EU IST FP7 project SCENE; EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This research was support by the UK EPSRC Visual Media Platform Grant and EU IST FP7 projects i3Dpost and SCENE.	Ahmed N., 2008, C COMP VIS PATT REC; Baran I., 2009, P ACM SIGGRAPH; Beeler T., 2011, P ACM SIGGRAPH; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Botsch M, 2008, IEEE T VIS COMPUT GR, V14, P213, DOI 10.1109/TVCG.2007.1054; Bradley D., 2010, P ACM SIGGRAPH; Bradley D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360698; Bronstein AM, 2007, IEEE T VIS COMPUT GR, V13, P902, DOI 10.1109/TVCG.2007.1041; Budd C., 2009, EUR C VIS MED PROC; Budd C., 2011, IEEE C 3D IM PROC VI; Cagniart C., 2010, C COMP VIS PATT REC; Cagniart C., 2010, EUR C COMP VIS; Carceroni RL, 2002, INT J COMPUT VISION, V49, P175, DOI 10.1023/A:1020145606604; Carranza J, 2003, ACM T GRAPHIC, V22, P569, DOI 10.1145/882262.882309; de Aguiar E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360697; Elad A, 2003, IEEE T PATTERN ANAL, V25, P1285, DOI 10.1109/TPAMI.2003.1233902; Enqvist O., 2011, IEEE WORKSH OMN VIS; Furukawa Y., 2010, C COMP VIS PATT REC; Gal R, 2007, IEEE T VIS COMPUT GR, V13, P261, DOI 10.1109/TVCG.2007.45; Gatzke T., 2005, SHAPE MODELLING APPL; Gherhadi R., 2010, P 7 EUR C VIS MED PR; Huang P., 2009, IEEE INT C COMP VIS; Huang P, 2011, PROC CVPR IEEE; Huang P, 2010, INT J COMPUT VISION, V89, P362, DOI 10.1007/s11263-010-0319-9; Iyer N., 2005, COMPUTER AIDED DESIG, V37; Kruskal J. B., 1956, P AM MATH SOC, V7, P48, DOI [DOI 10.1090/S0002-9939-1956-0078686-7, 10.2307/2033241]; Ling HB, 2005, IEEE I CONF COMP VIS, P1466; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Moeslund TB, 2011, VISUAL ANAL HUMANS L, V1st; Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002; Neumann J, 2002, INT J COMPUT VISION, V47, P181, DOI 10.1023/A:1014597925429; Pons JP, 2007, INT J COMPUT VISION, V72, P179, DOI 10.1007/s11263-006-8671-5; PRIM RC, 1957, AT&T TECH J, V36, P1389, DOI 10.1002/j.1538-7305.1957.tb01515.x; Pritchard D, 2003, COMPUT GRAPH FORUM, V22, P263, DOI 10.1111/1467-8659.00673; Salzmann M., 2007, IEEE T PATTERN ANAL; Scholz V, 2005, COMPUT GRAPH FORUM, V24, P439, DOI 10.1111/j.1467-8659.2005.00869.x; Sorkine O., 2006, COMPUTER GRAPHICS FO, V25; Starck J, 2005, IEEE I CONF COMP VIS, P1387; Starck J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P915; Starck J, 2007, IEEE I CONF COMP VIS, P2189; Starck J, 2007, IEEE COMPUT GRAPH, V27, P21, DOI 10.1109/MCG.2007.68; Stoll Carsten, 2010, ACM SIGGRAPH ASIA, P2; Sumner R., 2004, P ACM SIGGRAPH; Tevs A., 2011, ACM T GRAPHICS; Tung T., 2010, C COMP VIS PATT REC; Vedula S, 2005, IEEE T PATTERN ANAL, V27, P475, DOI 10.1109/TPAMI.2005.63; Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696; Wand M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1516522.1516526; White R, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239485; Zeng Y., 2010, C COMP VIS PATT REC; Zhang L., 2004, P ACM SIGGRAPH, P546	53	44	46	0	14	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2013	102	1-3					256	270		10.1007/s11263-012-0553-4	http://dx.doi.org/10.1007/s11263-012-0553-4			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	097VO		Green Submitted, hybrid, Green Published			2022-12-18	WOS:000315501800015
J	Dornaika, F; Davoine, F				Dornaika, Fadi; Davoine, Franck			Simultaneous facial action tracking and expression recognition in the presence of head motion	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						simultaneous tracking and recognition; face and facial feature tracking; facial expression recognition; particle filtering	CLASSIFICATION; SEQUENCES	The recognition of facial gestures and expressions in image sequences is an important and challenging problem. Most of the existing methods adopt the following paradigm. First, facial actions/features are retrieved from the images, then the facial expression is recognized based on the retrieved temporal parameters. In contrast to this mainstream approach, this paper introduces a new approach allowing the simultaneous retrieval of facial actions and expression using a particle filter adoptingmulti-class dynamics that are conditioned on the expression. For each frame in the video sequence, our approach is split into two consecutive stages. In the first stage, the 3D head pose is retrieved using a deterministic registration technique based on Online Appearance Models. In the second stage, the facial actions as well as the facial expression are simultaneously retrieved using a stochastic framework based on second-order Markov chains. The proposed fast scheme is either as robust as, or more robust than existing ones in a number of respects. We describe extensive experiments and provide evaluations of performance to show the feasibility and robustness of the proposed approach.	[Dornaika, Fadi] Inst Geog Natl, Lab MATIS, F-94165 Saint Mande, France; [Davoine, Franck] CNRS, UTC, Heudiasyc Mixed Res Unit, F-60205 Compiegne, France	Centre National de la Recherche Scientifique (CNRS)	Dornaika, F (corresponding author), Inst Geog Natl, Lab MATIS, 2 Ave Pasteur, F-94165 Saint Mande, France.	fadi.dornaika@ign.fr; fdavoine@hds.utc.fr		Davoine, Franck/0000-0002-8587-6997				Ahlberg J, 2002, EURASIP J APPL SIG P, V2002, P566, DOI 10.1155/S1110865702203078; BARTLERR M, 2004, IEEE INT C SYST MAN; BASCLE B, 1998, P IEEE INT C COMP VI; Blake A., 2000, ACTIVE CONTOURS; BLANZ V, 2003, IEEE T PATTERN ANAL, P1; CHANDRASIRI NP, 2004, IEEE INT C AUT FAC G; Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X; Dornaika F, 2005, IEEE I CONF COMP VIS, P1733, DOI 10.1109/ICCV.2005.225; Dornaika F., 2006, IEEE T CIRCUITS SYST, V16; DORNAIKA F, 2005, IEEE INT C IM PROC; Ekman P., 1978, FACIAL ACTION CODING, DOI [10.1037/t27734-000, DOI 10.1037/T27734-000]; Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3; Gokturk S. B., 2002, IEEE INT C AUT FAC G; Huang Y., 2002, 16 INT C PATT REC; Huber P., 1981, ROBUST STAT; ISARF M, 1998, P IEEE INT C COMP VI; Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903; Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102; LIAO WK, 2005, IEEE WORKSH VIS HUM; Ljung L., 1987, SYSTEM IDENTIFICATIO; LU L, 2001, P IEEE WORKSH MOD VE; Lu XG, 2006, IEEE T PATTERN ANAL, V28, P31, DOI 10.1109/TPAMI.2006.15; Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413; MORENO F, 2002, IEEE INT C PATT REC; North B, 2000, IEEE T PATTERN ANAL, V22, P1016, DOI 10.1109/34.877523; Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976; Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962; WANG Y, 2004, IEEE INT C PATTERN R; Wen Z., 2003, IEEE INT C COMP VIS; Yacoob Y, 1996, IEEE T PATTERN ANAL, V18, P636, DOI 10.1109/34.506414; YILMAZ A, 2002, IEEE INT C PATT REC; Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699, DOI 10.1109/TPAMI.2005.93; Zhou SH, 2003, COMPUT VIS IMAGE UND, V91, P214, DOI 10.1016/S1077-3142(03)00080-8; Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152	34	44	48	0	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2008	76	3					257	281		10.1007/s11263-007-0059-7	http://dx.doi.org/10.1007/s11263-007-0059-7			25	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	255VI					2022-12-18	WOS:000252685500004
J	Steidl, G; Didas, S; Neumann, J				Steidl, Gabriele; Didas, Stephan; Neumann, Julia			Splines in higher order TV regularization	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	5th International Conference on Scale-Space and PDE Methods in Computer Vision	APR 07-09, 2005	Hofgeismar, GERMANY	German Pattern Recognit Soc		higher order TV regularization; splines; support vector regression; Legendre-Fenchel dualization taut-string algorithm	TOTAL VARIATION MINIMIZATION; EQUIVALENCE; DIFFUSION; SPACE	Splines play an important role as solutions of various interpolation and approximation problems that minimize special functionals in some smoothness spaces. In this paper, we show in a strictly discrete Setting that splines of degree m - 1 solve also a minimization problem with quadratic data term and m-th order total variation (TV) regularization term. In contrast to problems with quadratic regularization terms involving m-th order derivatives, the spline knots are not known in advance but depend on the input data and the regularization parameter lambda. More precisely, the spline knots are determined by the contact points of the m-th discrete antiderivative of the solution with the tube of width 2 lambda around the m-th discrete antiderivative of the input data. We point out that the dual formulation of our minimization problem can be considered as support vector regression problem in the discrete counterpart of the Sobolev space W-2,0(m).. From this point of view, the solution of our minimization problem has a sparse representation in terms of discrete fundamental splines.	Univ Mannheim, Fac Math & Comp Sci, D-68131 Mannheim, Germany; Univ Saarland, Math Image Anal Grp, Fac Math & Comp Sci, D-66123 Saarbrucken, Germany	University of Mannheim; Saarland University	Steidl, G (corresponding author), Univ Mannheim, Fac Math & Comp Sci, D-68131 Mannheim, Germany.	steidl@math.uni-mannheim.de; didas@mia.uni-saarland.de; jneumarm@uni-mannheim.de						Chambolle A, 1997, NUMER MATH, V76, P167, DOI 10.1007/s002110050258; Chambolle A, 2004, J MATH IMAGING VIS, V20, P89; CHAN R, IN PRESS IEEE T IMAG; Chan T, 2000, SIAM J SCI COMPUT, V22, P503, DOI 10.1137/S1064827598344169; Chan TF, 1999, SIAM J SCI COMPUT, V20, P1964, DOI 10.1137/S1064827596299767; Davies PL, 2001, ANN STAT, V29, P1, DOI 10.1214/aos/996986501; DIDAS S, 2004, THESIS U SAARLANDES; DUCHON J, 1997, CONSTRUCTIVE THEORY, P85; Girosi F, 1998, NEURAL COMPUT, V10, P1455, DOI 10.1162/089976698300017269; Hinterberger W, 2003, J MATH IMAGING VIS, V19, P219, DOI 10.1023/A:1026276804745; HINTERBERGER W, 2003, VARIATIONAL METHODS; Hintermuller M, 2004, SIAM J APPL MATH, V64, P1311, DOI 10.1137/S0036139903422784; Hyman JM, 1997, COMPUT MATH APPL, V33, P81, DOI 10.1016/S0898-1221(97)00009-6; KIMELDORF G, 1971, J MATH ANAL APPL, V33, P82, DOI 10.1016/0022-247X(71)90184-3; Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229; Mammen E, 1997, ANN STAT, V25, P387; MANGASARIAN OL, 1973, SIAM J NUMER ANAL, V10, P448, DOI 10.1137/0710039; Mehrotra S, 1992, SIAM J OPTIMIZ, V2, P575, DOI 10.1137/0802028; Nielsen M, 1997, J MATH IMAGING VIS, V7, P291, DOI 10.1023/A:1008282127190; Nikolova M, 2004, J MATH IMAGING VIS, V20, P99, DOI 10.1023/B:JMIV.0000011920.58935.9c; Rockafellar R. T., 1970, CONVEX ANAL; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Schnorr C, 1998, J MATH IMAGING VIS, V8, P271, DOI 10.1023/A:1008278718907; Steidl G, 2006, COMPUTING, V76, P135, DOI 10.1007/s00607-005-0129-z; Steidl G, 2005, LECT NOTES COMPUT SC, V3459, P515; Steidl G, 2004, SIAM J NUMER ANAL, V42, P686, DOI 10.1137/S0036142903422429; Unser M, 2005, IEEE T SIGNAL PROCES, V53, P2146, DOI 10.1109/TSP.2005.847821; Vapnik V.N, 1998, STAT LEARNING THEORY; Vogel C. R., 2002, FRONT APPL MATH, DOI DOI 10.1137/1.9780898717570; Wahba G., 1990, SPLINE MODELS OBSERV; WELK M, 2005, SCALE SPACE PDE METH; Yip A.M., 2003, SOLUTION DYNAMICS CA; You YL, 2000, IEEE T IMAGE PROCESS, V9, P1723, DOI 10.1109/83.869184	34	44	46	0	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	2006	70	3					241	255		10.1007/s11263-006-8066-7	http://dx.doi.org/10.1007/s11263-006-8066-7			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	091VL					2022-12-18	WOS:000241056300005
J	Ngo, CW; Pong, TC; Zhang, HJ				Ngo, CW; Pong, TC; Zhang, HJ			Motion-based video representation for scene change detection	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						scene change detection; spatio-temporal slice; keyframe formation; background reconstruction	IMAGE RETRIEVAL	In this paper, we present a new framework to automatically group similar shots into one scene, where a scene is generally referred to as a group of shots taken place in the same site. Two major components in this framework are based on the motion characterization and background segmentation. The former component leads to an effective video representation scheme by adaptively selecting and forming keyframes. The later is considered novel in that background reconstruction is incorporated into the detection of scene change. These two components, combined with the color histogram intersection, establish our basic concept on assessing the similarity of scenes.	City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China; Hong Kong Univ Sci & Technol, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China; Microsoft Res Asia, Beijing Sigma Ctr 5F, Beijing 100080, Peoples R China	City University of Hong Kong; Hong Kong University of Science & Technology; Microsoft; Microsoft Research Asia	Ngo, CW (corresponding author), City Univ Hong Kong, Dept Comp Sci, Tat Chee Ave, Kowloon, Hong Kong, Peoples R China.	cwngo@cs.cityu.edu.hk; tcpong@cs.ust.hk; hjzhang@microsoft.com		Ngo, Chong Wah/0000-0003-4182-8261				Corridoni JM, 1998, PATTERN RECOGN, V31, P2027, DOI 10.1016/S0031-3203(98)00061-2; FLICKNER M, 1995, IEEE COMPUT, V28, P23, DOI DOI 10.1109/2.410146; GUDIVADA VN, 1995, COMPUTER, V28, P18, DOI 10.1109/2.410145; Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P580, DOI 10.1109/76.767124; Huang JC, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P526, DOI 10.1109/ICIP.1998.727252; Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197; JAHNE B, 1991, SPATIOTEMPORAL IMAGE; Ngo C. W., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P36, DOI 10.1109/CVPR.1999.786914; NGO CW, 2000, COMPUTER VISION PATT, V2, P768; NGO CW, 2000, AS C COMP VIS, V1, P246; NGO CW, 2001, IEEE T CIRCUITS SYST; NGO CW, 2000, THESIS HONG KONG U S; Rui Y, 1998, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS, P237, DOI 10.1109/MMCS.1998.693648; Sahouria E, 1999, IEEE T CIRC SYST VID, V9, P1290, DOI 10.1109/76.809163; SANTINI S, 1999, IEEE T PATTERN ANAL; SUNDARAM H, 2000, ACM MULTIMEDIA; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; Yeo BL, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pB260; Yeung MM, 1997, IEEE T CIRC SYST VID, V7, P771, DOI 10.1109/76.633496	19	44	48	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	2002	50	2					127	142		10.1023/A:1020341931699	http://dx.doi.org/10.1023/A:1020341931699			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	597DX		Green Published			2022-12-18	WOS:000178207800003
J	Pighin, F; Szeliski, R; Salesin, DH				Pighin, F; Szeliski, R; Salesin, DH			Modeling and animating realistic faces from images	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						facial animation; performance-driven animation; image-based modeling; model-based tracking; analysis by synthesis	SEQUENCES	We present a new set of techniques for modeling and animating realistic faces from photographs and videos. Given a set of face photographs taken simultaneously, our modeling technique allows the interactive recovery of a textured 3D face model. By repeating this process for several facial expressions, we acquire a set of face models that can be linearly combined to express a wide range of expressions. Given a video sequence, this linear face model can be used to estimate the face position, orientation, and facial expression at each frame. We illustrate these techniques on several datasets and demonstrate robust estimations of detailed face geometry and motion.	Univ So Calif, Inst Creat Technol, Los Angeles, CA 90089 USA; Microsoft Res, Redmond, WA USA; Univ Washington, Dept Comp Sci, Seattle, WA 98195 USA	University of Southern California; Microsoft; University of Washington; University of Washington Seattle	Pighin, F (corresponding author), Univ So Calif, Inst Creat Technol, Los Angeles, CA 90089 USA.	Pighin@ict.usc.edu						AKIMOTO T, 1993, IEEE COMPUT GRAPH, V13, P16, DOI 10.1109/38.232096; *AL, 1995, AL V7 0; ANJYO K, 1992, COMP GRAPH, V26, P111, DOI 10.1145/142920.134021; Ballard D.H., 1982, COMPUTER VISION; BLACK MJ, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P374, DOI 10.1109/ICCV.1995.466915; BLAKE A, 1998, ACTIVE CONTROURS APP; BLANZ T, 1999, SIGGRAPH 99 C P ACM; BREGLER C, 1997, SIGGRAPH 97 C P, P353; *BRIGHT START TECH, 1993, BEG READ SOFTW; CASCIA ML, 1998, P IEEE C COMP VIS PA; CHEN D, 1995, 1995 S INT 3D GRAPH, P43; CHOI CS, 1994, IEEE T CIRC SYST VID, V4, P257, DOI 10.1109/76.305871; Covell M, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P122, DOI 10.1109/AFGR.1996.557253; *CYB, 1990, 4020 RGB 3D SCANN CO; DEBEVEC P, 2000, SIGGRAPH 2000 C P AC, P35; Debevec P. E., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P11, DOI 10.1145/237170.237191; DeCarlo D, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P113, DOI 10.1109/ICCV.1998.710708; DEVERNAY F, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P208, DOI 10.1109/CVPR.1994.323831; Edwards GJ, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P300, DOI 10.1109/AFGR.1998.670965; Essa IA, 1997, IEEE T PATTERN ANAL, V19, P757, DOI 10.1109/34.598232; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; FUA P, 1988, P EUR C COMP VIS, P188; Golub G. H., 1996, MATRIX COMPUTATION; Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200; Guenin BM, 1998, P IEEE SEMICOND THER, P55, DOI 10.1109/STHERM.1998.660387; Hager GD, 1996, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.1996.517104; HALLINAN P, 1994, P IEEE C COMP VIS PA, P58; HANRAHAN P, 1993, SIGGRAPH 93, P165, DOI DOI 10.1145/166117.166139; Ip HHS, 1996, VISUAL COMPUT, V12, P254, DOI 10.1007/s003710050063; Jones MJ, 1998, PROC CVPR IEEE, P820, DOI 10.1109/CVPR.1998.698699; Kass M., 1987, International Journal of Computer Vision, V1, P321, DOI 10.1007/BF00133570; KOCH RM, 1996, SIGGRAPH 96 C P, P421; KURIHARA T, 1991, COMPUTER ANIMATION, V91, P45; LANITIS A, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P368, DOI 10.1109/ICCV.1995.466919; Lawson C. L., 1974, SOLVING LEAST SQUARE; LECLERC Y, 1991, P IEEE C COMP VIS PA; Lee S, 1996, IEEE T VIS COMPUT GR, V2, P337, DOI 10.1109/2945.556502; LEE S. Y., 1995, SIGGRAPH 95, P439; LEE Y, 1995, SIGGRAPH 95 C P, P55; LENGAGNE R, 1998, P 3 INT C AUT FAC GE; LI HB, 1993, IEEE T PATTERN ANAL, V15, P545, DOI 10.1109/34.216724; MATSUNO K, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P352, DOI 10.1109/ICCV.1995.466917; Moffitt F. H., 1980, PHOTOGRAMMETRY; NIELSON GM, 1993, IEEE COMPUT GRAPH, V13, P60, DOI 10.1109/38.180119; OSTBY E, 1997, COMMUNICATION; PARKE FI, 1974, THESIS U UTAH SALT L; PARKE FI, 1972, P ACM ANN C; PIGHIN F, 1999, P INT C COMP VIS; PIGHIN F, 1998, SIGGRAPH P, P75; Press W., 1992, NUMERICAL RECIPES C, VSecond edition.; PROESMAN M, 1996, INT C IM PROC; PULLI K, 1997, P 8 EUR WORKSH REND; Rosenblum R. E., 1991, Journal of Visualization and Computer Animation, V2, P141, DOI 10.1002/vis.4340020410; SCHODL A, 1998, WORKSH PERC US INT P, P43; Slama CC., 1980, MANUAL PHOTOGRAMMETR, V4th edn; Szeliski R., 1994, Journal of Visual Communication and Image Representation, V5, P10, DOI 10.1006/jvci.1994.1002; Szeliski R., 1997, SIGGRAPH 97, P251; TERZOPOULOS D, 1993, IEEE T PATTERN ANAL, V15, P569, DOI 10.1109/34.216726; Thomas Frank, 1995, ILLUSION LIFE; THORISSON K, 1997, 1 ACM INT C AUT AG; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Vannier M. W., 1983, Computer Graphics, V17, P263, DOI 10.1145/964967.801157; VETTER T, 1998, P EUR C COMP VIS, P499; WATANABE Y, 1992, IEEE COMPUT GRAPH, V12, P47, DOI 10.1109/38.135883; Williams L., 1990, Computer Graphics, V24, P235, DOI 10.1145/97880.97906; YU Y, 1998, SIGGRAPH 98, P207	66	44	52	0	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	2002	50	2					143	169		10.1023/A:1020393915769	http://dx.doi.org/10.1023/A:1020393915769			27	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	597DX					2022-12-18	WOS:000178207800004
J	Toyama, K; Hager, GD				Toyama, K; Hager, GD			Incremental focus of attention for robust vision-based tracking	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						visual tracking; real-time tracking; robust tracking; face tracking	MOTION TRACKING; OBJECTS; PURSUIT; MODELS; SEARCH; SYSTEM	We present the Incremental Focus of Attention (IFA) architecture for robust, adaptive, real-time motion tracking. IFA systems combine several visual search and vision-based tracking algorithms into a layered hierarchy. The architecture controls the transitions between layers and executes algorithms appropriate to the visual environment at hand: When conditions are good, tracking is accurate and precise; as conditions deteriorate, more robust, yet less accurate algorithms take over; when tracking is lost altogether, layers cooperate to perform a rapid search for the target and continue tracking. Implemented IFA systems are extremely robust to most common types of temporary visual disturbances. They resist minor visual perturbances and recover quickly after full occlusions, illumination changes, major distractions, and target disappearances. Analysis of the algorithm's recovery times are supported by simulation results and experiments on real data. In particular, examples show that recovery times after lost tracking depend primarily on the number of objects visually similar to the target in the field of view.	Microsoft Corp, Res, Redmond, WA 98052 USA; Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA	Microsoft; Johns Hopkins University	Toyama, K (corresponding author), Microsoft Corp, Res, 1 Microsoft Way, Redmond, WA 98052 USA.	kentoy@microsoft.com; hager@cs.jhu.edu	Hager, Gregory D/A-3222-2010	Toyama, Kentaro/0000-0002-9128-2255				Bar-Shalom Y, 1993, ESTIMATION TRACKING; Bar-Shalom Y., 1988, TRACKING DATA ASS; BLAKE A, 1993, P INT C COMP VIS, P421; BRADSHAW KJ, 1994, IMAGE VISION COMPUT, V12, P155, DOI 10.1016/0262-8856(94)90067-1; BURRIDGE RR, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 2, P292, DOI 10.1109/IROS.1995.526175; Burridge RR, 1999, INT J ROBOT RES, V18, P534, DOI 10.1177/02783649922066385; Burt P. J., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P305, DOI 10.1109/ICPR.1990.119374; BURT PS, 1988, P 11 INT C PATT REC, P977; Concepcion V, 1996, PATTERN RECOGN, V29, P1543, DOI 10.1016/0031-3203(96)00013-1; COOMBS D, 1993, INT J COMPUT VISION, V11, P147, DOI 10.1007/BF01469226; Crowley JL, 1997, PROC CVPR IEEE, P640, DOI 10.1109/CVPR.1997.609393; CULHANE SM, 1992, LECT NOTES COMPUT SC, V588, P551; FEITEN W, 1997, P 8 INT S ROB RES; GENNERY DB, 1992, INT J COMPUT VISION, V7, P243, DOI 10.1007/BF00126395; Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606; Hager GD, 1998, COMPUT VIS IMAGE UND, V69, P23, DOI 10.1006/cviu.1997.0586; HAGER GD, 1996, CVPRDEMO PROGRAM; HUBER E, 1995, IEEE INT CONF ROBOT, P2340, DOI 10.1109/ROBOT.1995.525610; ISARD M, 1998, P 5 EUR C COMP VIS, V1, P893; ISARD M, 1996, P EUR C COMP VIS CAM, V1, P343; Kahn RE, 1996, PROC CVPR IEEE, P734, DOI 10.1109/CVPR.1996.517154; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KOSAKA A, 1995, IEEE INT CONF ROBOT, P2637, DOI 10.1109/ROBOT.1995.525655; LOWE DG, 1992, INT J COMPUT VISION, V8, P113, DOI 10.1007/BF00127170; Maki A, 1996, P INT C PATT REC; MURRAY D, 1994, IEEE T PATTERN ANAL, V16, P449, DOI 10.1109/34.291452; Neisser U., 1967, COGNITIVE PSYCHOL; NISHIHARA HK, 1996, CVPR DEMO PROGRAM; Nordlund P, 1996, IMAGE VISION COMPUT, V14, P265, DOI 10.1016/0262-8856(95)01051-3; OLIVER N, 1997, P COMP VIS PATT REC; PAHLAVAN K, 1992, CVGIP-IMAG UNDERSTAN, V56, P41, DOI 10.1016/1049-9660(92)90084-G; PROKOPOWICZ P, 1994, 9405 U CHIC; Raja Y, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P228, DOI 10.1109/AFGR.1998.670953; Rasmussen C., 1996, RR1114 DCS YAL U; REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177; TERZOPOULOS D, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P801, DOI 10.1109/ICCV.1995.466856; Terzopoulos D., 1992, ACTIVE VISION; Toyama K, 1996, IEEE INT CONF ROBOT, P2636, DOI 10.1109/ROBOT.1996.506560; TOYAMA K, 1997, P 14 NAT C ART INT A, P3; TOYAMA K, 1998, P INT C COMP VIS PAT; TOYAMA K, 1998, THESIS YALE U; TREISMAN A, 1985, COMPUT VISION GRAPH, V31, P156, DOI 10.1016/S0734-189X(85)80004-9; Tsotsos J.K., 1993, SPATIAL VISION HUMAN; Tsotsos John K., 1995, P207; TURK M, 1996, P AUT FAC GEST REC; UHLIN T, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P679, DOI 10.1109/ICCV.1995.466873; VINCZE M, 1996, P INT C PATT REC; WIXSON LE, 1994, INT J COMPUT VISION, V12, P209, DOI 10.1007/BF01421203; WOLFE JM, 1994, PSYCHON B REV, V1, P202, DOI 10.3758/BF03200774; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236	51	44	61	1	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	1999	35	1					45	63		10.1023/A:1008159011682	http://dx.doi.org/10.1023/A:1008159011682			19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	265NY					2022-12-18	WOS:000084251300004
J	GOSHTASBY, A				GOSHTASBY, A			DESIGN AND RECOVERY OF 2-D AND 3-D SHAPES USING RATIONAL GAUSSIAN CURVES AND SURFACES	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							GLOBAL DEFORMATIONS; IMAGE SEGMENTATION; RECOGNITION; OBJECTS; MODELS; REPRESENTATION; INTERPOLATION; SUPERQUADRICS; SYSTEM; VISION	A new representation for parametric curves and surfaces is introduced here. It is in rational form and uses Gaussian bases. This representation allows design of 2-D and 3-D shapes, and makes recovery of shapes from noisy image data possible. The standard deviations of Gaussians in a curve or surface control the smoothness of a recovered shape. The control points of a surface in this representation are not required to form a regular grid and a scattered set of control points is sufficient to reconstruct a surface. Examples of shape design, shape recovery, and image segmentation using the proposed representation are given.			GOSHTASBY, A (corresponding author), UNIV ILLINOIS, DEPT ELECT ENGN & COMP SCI, CHICAGO, IL 60680 USA.							AGIN GJ, 1976, IEEE T COMPUT, V25, P439, DOI 10.1109/TC.1976.1674626; BAJCSY R, 1983, J COMPUT ASSIST TOMO, V7, P618, DOI 10.1097/00004728-198308000-00008; Barr A. H., 1981, IEEE Computer Graphics and Applications, V1, P11, DOI 10.1109/MCG.1981.1673799; BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881; BESL PJ, 1988, P IEEE, V76, P936, DOI 10.1109/5.5966; BHANU B, 1985, MAR P IEEE INT C ROB, P411; BIDASARIA HB, 1992, CVGIP-GRAPH MODEL IM, V54, P97, DOI 10.1016/1049-9652(92)90058-6; Binford T. O., 1982, INT J ROBOT RES, V1, P18; BINFORD TO, 1971, P IEEE C SYSTEMS CON; Blinn J. F., 1982, Computer Graphics, V16, DOI 10.1145/965145.801290; BROOKS RA, 1983, IEEE T PATTERN ANAL, V5, P140, DOI 10.1109/TPAMI.1983.4767366; CASTLEMAN KR, 1981, DIGITAL IMAGE PROCES; CHIN RT, 1986, COMPUT SURV, V18, P67, DOI 10.1145/6462.6464; CHOW CK, 1972, COMPUT BIOMED RES, V5, P388, DOI 10.1016/0010-4809(72)90070-5; DELINGETTE H, 1992, IMAGE VISION COMPUT, V10, P132, DOI 10.1016/0262-8856(92)90065-B; EPSTEIN M, 1980, NUMER ANAL, V17, P238; Farin, 1987, GEOMETRIC MODELING A, P3; FARIN G, 1992, IEEE COMPUT GRAPH, V12, P78, DOI 10.1109/38.156017; Farin G., 1988, CURVES SURFACES COMP; FARIN GE, 1991, NURBS CURVE SURFACE; FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302; Faux ID, 1979, COMPUTATIONAL GEOMET; FISHER R, 1987, IMAGE VISION COMPUT, V5, P98, DOI 10.1016/0262-8856(87)90034-5; GORDON WJ, 1974, J ACM, V21, P293, DOI 10.1145/321812.321824; GOSHTASBY A, 1990, COMPUT VISION GRAPH, V52, P264, DOI 10.1016/0734-189X(90)90058-4; GOSHTASBY A, 1992, IEEE T MED IMAGING, V11, P507, DOI 10.1109/42.192686; GOSHTASBY A, 1993, IN PRESS COMPUTER AI; GRIMSON WEL, 1983, COMPUT VISION GRAPH, V22, P39, DOI 10.1016/0734-189X(83)90095-6; HALL EL, 1982, COMPUTER, V15, P42; Ichida K., 1977, ACM Transactions on Mathematical Software, V3, P164, DOI 10.1145/355732.355737; Jain A. K., 1989, FUNDAMENTALS DIGITAL; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Kochanek D. H. U., 1984, Computers & Graphics, V18, P33; KUAN DT, 1986, TECHNIQUES 3 D MACHI, P219; LAURENDEAU D, 1987, IEEE T ROBOTIC AUTOM, V3, P459, DOI 10.1109/JRA.1987.1087125; LEE ETY, 1989, COMPUT AIDED DESIGN, V21, P363, DOI 10.1016/0010-4485(89)90003-1; LOOP CT, 1989, ACM T GRAPHIC, V8, P204, DOI 10.1145/77055.77059; Lorensen W. E., 1987, COMPUT GRAPH, V21, P163, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422]; MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030; MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020; MURAKI S, 1991, COMP GRAPH, V25, P227, DOI 10.1145/127719.122743; NEVATIA R, 1977, ARTIF INTELL, V8, P77, DOI 10.1016/0004-3702(77)90006-6; PENTLAND AP, 1990, INT J COMPUT VISION, V4, P107, DOI 10.1007/BF00127812; PIEGL L, 1991, IEEE COMPUT GRAPH, V11, P55, DOI 10.1109/38.67702; POLLARD SB, 1987, IMAGE VISION COMPUT, V5, P73, DOI 10.1016/0262-8856(87)90030-8; POLLARD SB, 1989, INT J ROBOT RES, V8, P3, DOI 10.1177/027836498900800401; PONCE J, 1989, IEEE T PATTERN ANAL, V11, P951, DOI 10.1109/34.35498; RAJA NS, 1992, IMAGE VISION COMPUT, V10, P179, DOI 10.1016/0262-8856(92)90069-F; SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9; Sarkar B., 1991, Computer-Aided Geometric Design, V8, P267, DOI 10.1016/0167-8396(91)90016-5; SCHAGEN IP, 1980, INT J COMPUT MATH, V8, P63, DOI 10.1080/00207168008803191; SOLINA F, 1990, IEEE T PATTERN ANAL, V12, P131, DOI 10.1109/34.44401; STOCKMAN G, 1985, 85023 MICH STAT U DE; Sugihara K., 1986, MACHINE INTERPRETATI; TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659; TERZOPOULOS D, 1988, ARTIF INTELL, V36, P91, DOI 10.1016/0004-3702(88)90080-X; TERZOPOULOS D, 1988, IEEE T PATTERN ANAL, V10, P417, DOI 10.1109/34.3908; VARADY T, 1987, MATH SURFACES, P203; YANOWITZ SD, 1989, COMPUT VISION GRAPH, V46, P82, DOI 10.1016/S0734-189X(89)80017-9; ZUCKER SW, 1981, IEEE T PATTERN ANAL, V3, P324, DOI 10.1109/TPAMI.1981.4767105	61	44	50	0	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	1993	10	3					233	256		10.1007/BF01539537	http://dx.doi.org/10.1007/BF01539537			24	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	LP386					2022-12-18	WOS:A1993LP38600002
J	Dendorfer, P; Osep, A; Milan, A; Schindler, K; Cremers, D; Reid, I; Roth, S; Leal-Taixe, L				Dendorfer, Patrick; Osep, Aljosa; Milan, Anton; Schindler, Konrad; Cremers, Daniel; Reid, Ian; Roth, Stefan; Leal-Taixe, Laura			MOTChallenge: A Benchmark for Single-Camera Multiple Target Tracking	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Multi-object-tracking; Evaluation; MOTChallenge; Computer vision; MOTA	ONLINE MULTIOBJECT TRACKING; MULTITARGET TRACKING; PHD FILTER; ASSOCIATION; FEATURES	Standardized benchmarks have been crucial in pushing the performance of computer vision algorithms, especially since the advent of deep learning. Although leaderboards should not be over-claimed, they often provide the most objective measure of performance and are therefore important guides for research. We present MOTChallenge, a benchmark for single-camera Multiple Object Tracking (MOT) launched in late 2014, to collect existing and new data and create a framework for the standardized evaluation of multiple object tracking methods. The benchmark is focused on multiple people tracking, since pedestrians are by far the most studied object in the tracking community, with applications ranging from robot navigation to self-driving cars. This paper collects the first three releases of the benchmark: (i) MOT15, along with numerous state-of-the-art results that were submitted in the last years, (ii) MOT16, which contains new challenging videos, and (iii) MOT17, that extends MOT16 sequences with more precise labels and evaluates tracking performance on three different object detectors. The second and third release not only offers a significant increase in the number of labeled boxes, but also provide labels for multiple object classes beside pedestrians, as well as the level of visibility for every single object of interest. We finally provide a categorization of state-of-the-art trackers and a broad error analysis. This will help newcomers understand the related work and research trends in the MOT community, and hopefully shed some light into potential future research directions.	[Dendorfer, Patrick; Osep, Aljosa; Cremers, Daniel; Leal-Taixe, Laura] Tech Univ Munich, Munich, Germany; [Milan, Anton] Amazon Res, Tubingen, Germany; [Schindler, Konrad] Swiss Fed Inst Technol, Zurich, Switzerland; [Reid, Ian] Univ Adelaide, Adelaide, SA, Australia; [Roth, Stefan] Tech Univ Darmstadt, Darmstadt, Germany	Technical University of Munich; Swiss Federal Institutes of Technology Domain; ETH Zurich; University of Adelaide; Technical University of Darmstadt	Dendorfer, P (corresponding author), Tech Univ Munich, Munich, Germany.	patrick.dendorfer@tum.de; aljosa.osep@tum.de; antmila@amazon.com; schindler@ethz.ch; cremers@tum.de; ian.reid@adelaide.edu.au; stefan.roth@vision.tu-darmstadt.de; leal.taixe@tum.de	Leal-Taixe, Laura/HFZ-8079-2022	Leal-Taixe, Laura/0000-0001-8709-1133; Reid, Ian/0000-0001-7790-6423	Projekt DEAL	Projekt DEAL	Open Access funding enabled and organized by Projekt DEAL.	Alahi Alexandre, 2014, CVPR, P2203; Andriluka M., 2010, C COMP VIS PATT REC; Andriluka M., 2018, C COMP VIS PATT REC; Babaee M, 2019, NEUROCOMPUTING, V368, P69, DOI 10.1016/j.neucom.2019.08.008; Bae S.-H., 2014, C COMP VIS PATT REC; Bae SH, 2018, IEEE T PATTERN ANAL, V40, P595, DOI 10.1109/TPAMI.2017.2691769; Baisa N. L, 2018, INT JOINT C COMP VIS; Baisa N. L, 2019, ARXIV190803945; Baisa NL, 2019, 2019 22ND INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION 2019); Baisa NL, 2019, J VIS COMMUN IMAGE R, V59, P257, DOI 10.1016/j.jvcir.2019.01.026; Baisa NL, 2019, ARXIV191205949; Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191; Ban Y., 2016, EUR C COMP VIS WORKS; Battaglia Peter W, 2016, ARXIV161200222; Benfold B., 2011, INT C COMP VIS; Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309; Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003; Bewley A, 2016, IEEE INT CONF ROBOT, P2212, DOI 10.1109/ICRA.2016.7487371; Bochinski E., 2017, INT C ADV VID SIGN B; Boragule A., 2017, INT C ADV VID SIGN B; Chang Ming-Fang, 2019, P IEEE CVF C COMP VI, P6; Chen J., 2017, C COMP VIS PATT REC; Chen L, 2018, IEEE INT CON MULTI; Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145; Choi WG, 2015, IEEE I CONF COMP VIS, P3029, DOI 10.1109/ICCV.2015.347; Chu P., 2019, WINT C APPL COMP VIS; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Dave Achal, 2020, ECCV; Dendorfer P., 2019, ARXIV190604567CS; Dendorfer P., 2020, MOT20 BENCHMARK MULT, pabs/2003.09003; Dicle C, 2013, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2013.286; Dollar P., 2009, C COMP VIS PATT REC; Dollar P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479; Eiselein V., 2012, INT C ADV VID SIGN B; Ess A., 2008, C COMP VIS PATT REC; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Fagot-Bouquet L., 2015, INT C IM PROC; Fagot-Bouquet L., 2016, EUR C COMP VIS WORKS; Fang K, 2018, IEEE WINT CONF APPL, P466, DOI 10.1109/WACV.2018.00057; Felzenszwalb P. F., 2006, C COMP VIS PATT REC; Ferryman J., 2010, INT C ADV VID SIGN B; Ferryman J., 2009, INT WORKSH PERF EV T; Fu ZY, 2019, IEEE T MULTIMEDIA, V21, P2277, DOI 10.1109/TMM.2019.2902480; Fu ZY, 2018, IEEE ACCESS, V6, P14764, DOI 10.1109/ACCESS.2018.2816805; Geiger A., 2012, P IEEE COMP SOC C CO; Geiger A, 2014, IEEE T PATTERN ANAL, V36, P1012, DOI 10.1109/TPAMI.2013.185; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Hadsell R, 2006, IEEE C COMP VIS PATT, V2, P1735; Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45; Henriques J. a., 2011, INT C COMP VIS; Henschel R., 2019, C COMP VIS PATT REC; Henschel Roberto, 2018, IEEE C COMP VIS PATT; Huang GS, 2007, 2007 7TH IEEE CONFERENCE ON NANOTECHNOLOGY, VOL 1-3, P7, DOI 10.1109/NANO.2007.4601129; Ju J, 2017, J OPT SOC AM A, V34, P280, DOI 10.1364/JOSAA.34.000280; Ju J, 2017, IET COMPUT VIS, V11, P87, DOI 10.1049/iet-cvi.2016.0068; Karunasekera H, 2019, IEEE ACCESS, V7, P104423, DOI 10.1109/ACCESS.2019.2932301; Kesten R., 2019, LYFT LEVEL 5 AV DATA; Keuper M, 2020, IEEE T PATTERN ANAL, V42, P140, DOI 10.1109/TPAMI.2018.2876253; Kieritz H., 2016, INT C ADV VID SIGN B; Kristan M, 2015, LECT NOTES COMPUT SC, V8926, P191, DOI 10.1007/978-3-319-16181-5_14; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; Kutschbach T., 2017, INT C ADV VID SIGN B; Lan L, 2018, IEEE T IMAGE PROCESS, V27, P4585, DOI 10.1109/TIP.2018.2843129; Le N., 2016, EUR C COMP VIS WORKS; Leal-Taixe L., 2014, C COMP VIS PATT REC; Leal-Taixe Laura, 2011, INT C COMP VIS WORKS, V1, P2; Lee S, 2019, IEEE ACCESS, V7, P8181, DOI 10.1109/ACCESS.2018.2889442; Lee SH, 2018, IEEE ACCESS, V6, P67316, DOI 10.1109/ACCESS.2018.2879535; Levinkov E., 2017, C COMP VIS PATT REC; Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935; Li Y., 2009, C COMP VIS PATT REC; Liu QK, 2019, IEEE ACCESS, V7, P76489, DOI 10.1109/ACCESS.2019.2921975; Long C., 2017, INT C IM PROC; Loumponias K., 2018, INT C SIGN IM TECHN; Ma C., 2018, INT C MULT EXP; Ma L., 2018, P AS C COMP VIS; Mahgoub H, 2017, INT J ADV COMPUT SC, V8, P217; Maksai A., 2019, C COMP VIS PATT REC; Mane SS, 2019, INT NANOELECTR CONF; Manen S, 2016, IEEE WINT CONF APPL; Mathias M., 2014, EUR C COMP VIS WORKS; McLaughlin N., 2015, WINT C APPL COMP VIS; Milan A., 2013, C COMP VIS PATT REC; Milan A., 2017, C ART INT; Milan A., 2015, C COMP VIS PATT REC; Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103; Nguyen Thi Lan Anh F. N., 2017, INT C ADV VID SIGN B; Pedersen M., 2020, C COMP VIS PATT REC; Pirsiavash H., 2011, C COMP VIS PATT REC; REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rezatofighi H., 2015, INT C COMP VIS; Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sadeghian A, 2017, IEEE I CONF COMP VIS, P300, DOI 10.1109/ICCV.2017.41; Sanchez-Matilla R., 2019, INT C IM PROC; Sanchez-Matilla R, 2016, LECT NOTES COMPUT SC, V9914, P84, DOI 10.1007/978-3-319-48881-3_7; Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977; Schuhmacher D, 2008, IEEE T SIGNAL PROCES, V56, P3447, DOI 10.1109/TSP.2008.920469; Seitz S.M., 2006, C COMP VIS PATT REC; Shen H, 2020, IEEE T SYST MAN CY-S, V50, P4796, DOI 10.1109/TSMC.2018.2866632; Sheng H., 2017, ADV MULTIMEDIA INFOR, V127; Sheng H, 2019, IEEE ACCESS, V7, P2107, DOI 10.1109/ACCESS.2018.2881019; Shi XC, 2019, INT J COMPUT VISION, V127, P1063, DOI 10.1007/s11263-018-01147-z; Smith K., 2005, WORKSH EMP EV METH C; Son J., 2017, C COMP VIS PATT REC; Song Y., 2018, INT C ADV VID SIGN B; Song Y., 2016, INT C CONS EL; Song YM, 2019, IEEE ACCESS, V7, P165103, DOI 10.1109/ACCESS.2019.2953276; Stiefelhagen R., 2006, MULTIMODAL TECHNOLOG; Sun Pei, 2020, C COMP VIS PATT REC; Tang S., 2016, EUR C COMP VIS WORKS; Tang S., 2015, C COMP VIS PATT REC; Tang S., 2017, C COMP VIS PATT REC; Tao Y, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON UNIVERSAL VILLAGE (IEEE UV 2018); Taskar B, 2004, ADV NEUR IN, V16, P25; Thrun S, 2002, COMMUN ACM, V45, P52, DOI 10.1145/504729.504754; Tian W, 2020, IEEE T INTELL TRANSP, V21, P374, DOI 10.1109/TITS.2019.2892413; Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347; Wang B., 2016, C COMP VIS PATT REC; Wang G., 2019, INT C MULT; Wen LY, 2020, COMPUT VIS IMAGE UND, V193, DOI 10.1016/j.cviu.2020.102907; Wojke N., 2016, INT C ROB AUT; Wu B., 2006, C COMP VIS PATT REC; Wu HF, 2019, PATTERN RECOGN, V94, P25, DOI 10.1016/j.patcog.2019.04.018; Xiang J, 2021, IEEE T CIRC SYST VID, V31, P275, DOI 10.1109/TCSVT.2020.2975842; Xu JJ, 2019, INT CONF AGRO-GEOINF; Xu Y., 2020, C COMP VIS PATT REC; Yang M, 2017, IEEE T IMAGE PROCESS, V26, P5667, DOI 10.1109/TIP.2017.2745103; Yang M, 2016, COMPUT VIS IMAGE UND, V153, P16, DOI 10.1016/j.cviu.2016.05.003; Yoon J. H., 2016, INT C COMP VIS PATT; Yoon JH, 2015, IEEE WINT CONF APPL, P33, DOI 10.1109/WACV.2015.12; Yoon K, 2020, IEEE ACCESS, V8, P38060, DOI 10.1109/ACCESS.2020.2975912; Yoon K, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030559; Yoon Y., 2018, INT C ADV VID SIGN B; Yoon Y., 2019, ARXIV190700831; Yoon Y.-C., 2018, INT C CONS EL AS; Zhang L., 2008, C COMP VIS PATT REC; Zhang Y, 2020, IEEE T IMAGE PROCESS, V29, P6694, DOI 10.1109/TIP.2020.2993073; Zhou H, 2019, IEEE T CIRC SYST VID, V29, P1011, DOI 10.1109/TCSVT.2018.2825679; Zhou X., 2018, BRIT MACH VIS C; Zhu J., 2018, EUR C COMP VIS WORKS	157	43	45	8	26	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	2021	129	4					845	881		10.1007/s11263-020-01393-0	http://dx.doi.org/10.1007/s11263-020-01393-0		DEC 2020	37	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	RB3QK		hybrid, Green Submitted, Green Published			2022-12-18	WOS:000601485200003
J	Nguyen, TV; Zhao, Q; Yan, SC				Nguyen, Tam V.; Zhao, Qi; Yan, Shuicheng			Attentive Systems: A Survey	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Attentive systems; Visual attention; Salient region/object detection; Interestingness; Scene understanding; Computer graphics; Image retargeting; Feature pooling; Multimedia; Compression	SALIENT OBJECT DETECTION; VISUAL-ATTENTION; DISCRIMINANT SALIENCY; SCENE CLASSIFICATION; SELECTIVE ATTENTION; MODEL; GAZE; INFORMATION; RECOGNITION; TRACKING	Visual saliency analysis detects salient regions/objects that attract human attention in natural scenes. It has attracted intensive research in different fields such as computer vision, computer graphics, and multimedia. While many such computational models exist, the focused study of what and how applications can be beneficial is still lacking. In this article, our ultimate goal is thus to provide a comprehensive review of the applications using saliency cues, the so-called attentive systems. We would like to provide a broad vision about saliency applications and what visual saliency can do. We categorize the vast amount of applications into different areas such as computer vision, computer graphics, and multimedia. Intensively covering 200+ publications we survey (1) key application trends, (2) the role of visual saliency, and (3) the usability of saliency into different tasks.	[Nguyen, Tam V.] Univ Dayton, Dayton, OH 45469 USA; [Zhao, Qi] Univ Minnesota, Minneapolis, MN USA; [Yan, Shuicheng] Natl Univ Singapore, Singapore, Singapore	University of Dayton; University of Minnesota System; University of Minnesota Twin Cities; National University of Singapore	Nguyen, TV (corresponding author), Univ Dayton, Dayton, OH 45469 USA.	tamnguyen@udayton.edu; qzhao@umn.edu; eleyans@nus.edu.sg	Nguyen, Tam/AAU-6504-2020; Yan, Shuicheng/HCI-1431-2022	Nguyen, Tam/0000-0003-0236-7992; 				Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596; Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28; Alkan S, 2007, BRIT J EDUC TECHNOL, V38, P538, DOI 10.1111/j.1467-8535.2007.00721.x; Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461; Bahdanau D., 2014, ARXIV14090473, p1409.0473; Bailey R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559757; Baluja S, 1997, ROBOT AUTON SYST, V22, P329, DOI 10.1016/S0921-8890(97)00046-8; Batra D, 2010, PROC CVPR IEEE, P3169, DOI 10.1109/CVPR.2010.5540080; Belardinelli A., 2008, THESIS; Bhattacharya S., 2010, P 18 ACM INT C MULT, P271; Borji A., 2012, PROC IEEE COMPUT SOC, P23; Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833; Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89; Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30; Borji A, 2011, IEEE INT CONF ROBOT, P1902; Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60; Breazeal C, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P1146; Bruce N., 2005, P 18 INT C NEUR INF, P155; Butko Nicholas J., 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2751, DOI 10.1109/CVPRW.2009.5206540; Chamaret C, 2008, INT C PATT RECOG, P1450; Chen JX, 2015, IEEE T IMAGE PROCESS, V24, P1076, DOI 10.1109/TIP.2014.2383326; Chen JX, 2011, PROC CVPR IEEE, P609, DOI 10.1109/CVPR.2011.5995675; Chen Q, 2012, PROC CVPR IEEE, P3426, DOI 10.1109/CVPR.2012.6248083; Chen YX, 2014, IEEE T CIRC SYST VID, V24, P1992, DOI 10.1109/TCSVT.2014.2329380; Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Chia AYS, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024190; Choi J., 2016, CORR; Choi J, 2014, IEEE IMAGE PROC, P1096, DOI 10.1109/ICIP.2014.7025218; Courty N, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P1024; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dankers A., 2007, INT C COMP VIS SYST; DeCarlo D, 2002, ACM T GRAPHIC, V21, P769, DOI 10.1145/566570.566650; Desingh K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.98; Donoser M, 2009, IEEE I CONF COMP VIS, P817, DOI 10.1109/ICCV.2009.5459296; Drewes H., 2007, P 4 INT C MOB TECHN, V07, P364, DOI [10.1145/1378063.1378122, DOI 10.1145/1378063.1378122]; Ehinger KA, 2009, VIS COGN, V17, P945, DOI 10.1080/13506280902834720; El-Nasr MS, 2009, IEEE T COMP INTEL AI, V1, P145, DOI 10.1109/TCIAIG.2009.2024532; Elazary L, 2008, J VISION, V8, DOI 10.1167/8.3.3; Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Feng SH, 2010, SIGNAL PROCESS, V90, P1, DOI 10.1016/j.sigpro.2009.05.017; Frintrop S, 2006, LECT NOTES ARTIF INT, V3899, P1; Frintrop S., 2011, PALADYN J BEHAV ROBO, V2, P64, DOI [10.2478/s13230-011-0018-4, DOI 10.2478/S13230-011-0018-4]; Frintrop S, 2008, IEEE T ROBOT, V24, P1054, DOI 10.1109/TRO.2008.2004977; Frintrop S, 2014, INT C PATT RECOG, P2329, DOI 10.1109/ICPR.2014.404; Frintrop S, 2010, INT J SOC ROBOT, V2, P53, DOI 10.1007/s12369-009-0035-1; Frintrop S, 2009, IEEE INT CONF ROBOT, P758; Fritz G., 2004, Attention and Performance in Computational Vision. Second International Workshop, WAPCV 2004. Revised Selected Papers (Lecture Notes in Computer Science Vol. 3368), P29; Gadde R., 2011, IJCAI; Gao D., 2004, ADV NEURAL INFORM PR, V17, P481; Gao DS, 2009, IEEE T PATTERN ANAL, V31, P989, DOI 10.1109/TPAMI.2009.27; Gao Y, 2015, IEEE T MULTIMEDIA, V17, P359, DOI 10.1109/TMM.2015.2389616; Gautier J, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P81, DOI 10.1109/PCS.2012.6213291; Geng Zhang, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P193; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929; Goferman S, 2010, COMPUT GRAPH FORUM, V29, P459, DOI 10.1111/j.1467-8659.2009.01615.x; Goldberg C, 2012, COMPUT GRAPH FORUM, V31, P265, DOI 10.1111/j.1467-8659.2012.03005.x; Graves Alex, 2013, ARXIV13080850 CORR; Gupta R, 2013, SIGNAL PROCESS-IMAGE, V28, P1006, DOI 10.1016/j.image.2013.07.003; Han S, 2010, VISION RES, V50, P2295, DOI 10.1016/j.visres.2010.05.034; Haque A, 2016, PROC CVPR IEEE, P1229, DOI 10.1109/CVPR.2016.138; Harel J., 2006, PAPER PRESENTED INT, P545, DOI DOI 10.7551/MITPRESS/7503.003.0073; Heidemann G, 2004, MACH VISION APPL, V16, P64, DOI 10.1007/s00138-004-0157-2; Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407; Hong BW, 2003, LECT NOTES COMPUT SC, V2879, P730; Hong R., 2010, ACM MULTIMEDIA; Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267; Hou X., 2008, NIPS, P681; Huang H, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024189; iLab C., 2010, NEUR VIS; Ishiguro Y., 2010, P 1 ACM AUGM HUM INT, V1, P25; Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Jacobson N, 2010, IEEE T IMAGE PROCESS, V19, P2924, DOI 10.1109/TIP.2010.2050928; Ji QG, 2013, SIGNAL PROCESS-IMAGE, V28, P241, DOI 10.1016/j.image.2012.11.008; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Jiang M., 2015, J VISION, V15, P221; Jiang M., 2015, CVPR; Johnson-Roberson M, 2010, IEEE INT C INT ROBOT, P1165, DOI 10.1109/IROS.2010.5649872; Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855; Kanan C, 2010, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2010.5539947; Karpathy A, 2013, IEEE INT CONF ROBOT, P2088, DOI 10.1109/ICRA.2013.6630857; Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118; Klaser Alexander, 2008, P BMVC; Klein DA, 2010, IEEE INT C INT ROBOT, P772, DOI 10.1109/IROS.2010.5650583; KOCH C, 1985, HUM NEUROBIOL, V4, P219; Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177; Krahenbuhl P, 2014, LECT NOTES COMPUT SC, V8693, P725, DOI 10.1007/978-3-319-10602-1_47; Lance B., 2004, AAMAS WORKSH EMP AG; Lance BJ, 2010, IEEE COMPUT GRAPH, V30, P62, DOI 10.1109/MCG.2010.43; Lang CY, 2012, LECT NOTES COMPUT SC, V7573, P101, DOI 10.1007/978-3-642-33709-3_8; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86; Lee CH, 2005, ACM T GRAPHIC, V24, P659, DOI 10.1145/1073204.1073244; Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820; Li A, 2013, PROC SPIE, V8878, DOI 10.1117/12.2030719; Li HL, 2008, J VIS COMMUN IMAGE R, V19, P320, DOI 10.1016/j.jvcir.2008.04.001; Li L., 2008, ACM MULTIMEDIA, P1027; Li L., 2010, P 19 INT C WORLD WID, P1273; Li L, 2013, IEEE MULTIMEDIA, V20, P13, DOI 10.1109/MMUL.2013.15; Li LS, 2010, MULTIMED TOOLS APPL, V49, P145, DOI 10.1007/s11042-009-0399-0; Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43; Liu H., 2008, P 16 ACM INT C MULT, P379; Liu HT, 2009, IEEE IMAGE PROC, P3097, DOI 10.1109/ICIP.2009.5414466; Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70; Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410; Luebke D., 2016, ACM T GRAPHIC, V35; Luong M., 2015, ARXIV150804025; Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410; Mahadevan V, 2009, PROC CVPR IEEE, P1007, DOI 10.1109/CVPRW.2009.5206573; Marchesotti L, 2009, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2009.5459467; Margolin R, 2013, VISUAL COMPUT, V29, P381, DOI 10.1007/s00371-012-0740-x; Martin-Martin A., 2014, EC3 WORKING PAPERS, V17; Mateescu V.A., 2014, P 1 INT WORKSH PERC, P15, DOI DOI 10.1145/2662996.2663009; Mathe S., 2013, CORR; Mathe S, 2012, LECT NOTES COMPUT SC, V7573, P842, DOI 10.1007/978-3-642-33709-3_60; Meger D, 2008, ROBOT AUTON SYST, V56, P503, DOI 10.1016/j.robot.2008.03.008; Mei T, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2071396.2071402; Mertsching B., 1998, Proceedings of NC 1998. International ICSC/IFAC Symposium on Neural Computation, P469; Mishra AK, 2012, IEEE T PATTERN ANAL, V34, P639, DOI 10.1109/TPAMI.2011.171; Mitri S, 2005, IEEE INT CONF ROBOT, P125; Mnih V., 2014, NEURAL INFORM PROCES, DOI DOI 10.48550/ARXIV.1406.6247; Moosmann F., 2006, ECCV WORKSH REPR US; Muhl C, 2007, LECT NOTES ARTIF INT, V4667, P264; Muratov O, 2012, COMM CONTR SIGN PROC, P1, DOI [10.1109/ISCCSP.2012.6217880, DOI 10.1109/ISCCSP.2012.6217880]; Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506; Nagai Y, 2008, INT C DEVEL LEARN, P1, DOI 10.1109/DEVLRN.2008.4640796; Navalpakkam V., 2006, P IEEE COMPUTER SOC, V2, P2049, DOI DOI 10.1109/CVPR.2006.54; Nguyen T., 2012, ACM MULTIMEDIA, P1331; Nguyen T. V., 2013, P 21 ACM INT C MULTI, P987; Nguyen T. V., 2017, INT JOINT C ART INT; Nguyen TV, 2015, AAAI CONF ARTIF INTE, P4286; Nguyen TV, 2015, IEEE T CIRC SYST VID, V25, P77, DOI 10.1109/TCSVT.2014.2333151; Nguyen TV, 2013, IEEE T MULTIMEDIA, V15, P1910, DOI 10.1109/TMM.2013.2272919; Ni BB, 2014, IEEE T MULTIMEDIA, V16, P1779, DOI 10.1109/TMM.2014.2329275; Ninassi A., 2007, IM PROC 2007 ICIP 20, V2, P2; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Ouerhani N, 2001, 11TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P416, DOI 10.1109/ICIAP.2001.957045; Ouerhani  N., 2005, P EUR C MOB ROB ECMR, P8; Papadopoulos DP, 2014, LECT NOTES COMPUT SC, V8693, P361, DOI 10.1007/978-3-319-10602-1_24; Parikh N, 2010, J NEURAL ENG, V7, DOI 10.1088/1741-2560/7/1/016006; Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743; Perra D, 2015, PROC CVPR IEEE, P4146, DOI 10.1109/CVPR.2015.7299042; Nguyen P, 2013, IEEE INT CON MULTI; Qin CC, 2014, NEUROCOMPUTING, V129, P378, DOI 10.1016/j.neucom.2013.09.021; Qingshan Li, 2011, 2011 International Conference on Multimedia Technology, P5068; Queiroz RB, 2007, LECT NOTES ARTIF INT, V4722, P401; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819; Roberts R., 2012, SPIE DEFENSE SECURIT; Rosenholtz R, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/1870076.1870080; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Rutishauser U, 2004, PROC CVPR IEEE, P37; Sadaka NG, 2009, IEEE IMAGE PROC, P3113, DOI 10.1109/ICIP.2009.5414460; Salah AA, 2002, IEEE T PATTERN ANAL, V24, P420, DOI 10.1109/34.990146; Scheier C., 1997, IEEE INT S IND EL, V1, P48; SCHNEIDER W, 1977, PSYCHOL REV, V84, P1, DOI 10.1037/0033-295X.84.1.1; Setlur Vidya, 2005, P 4 INT C MOB UB MUL, P59, DOI DOI 10.1145/1149488.1149499; Shen CY, 2014, LECT NOTES COMPUT SC, V8695, P33, DOI 10.1007/978-3-319-10584-0_3; Shen H, 2013, CHINESE J AERONAUT, V26, P1211, DOI 10.1016/j.cja.2013.07.038; SHIFFRIN RM, 1977, PSYCHOL REV, V84, P127, DOI 10.1037/0033-295X.84.2.127; Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40; Siagian C, 2009, IEEE T ROBOT, V25, P861, DOI 10.1109/TRO.2009.2022424; Simoncelli E. P., 1996, FDN VISION; Srivatsa RS, 2015, IEEE IMAGE PROC, P4481, DOI 10.1109/ICIP.2015.7351654; STALDER S, 2012, P AS C COMP VIS, P43; Stentiford F., 2003, ELECT IMAGING, P221; Sugano Y, 2010, PROC CVPR IEEE, P2667, DOI 10.1109/CVPR.2010.5539984; Suh B, 2003, P 16 ANN ACM S USER, P95, DOI [10.1145/964696.964707, DOI 10.1145/964696.964707]; Tanaka R., 2015, P 3 ACM S SPAT US IN, P61, DOI [10.1145/2788940.2788951, DOI 10.1145/2788940.2788951]; Tatler BW, 2011, J VISION, V11, DOI 10.1167/11.5.5; Vig E, 2012, LECT NOTES COMPUT SC, V7578, P84, DOI 10.1007/978-3-642-33786-4_7; Vijayakumar S, 2001, IROS 2001: PROCEEDINGS OF THE 2001 IEEE/RJS INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2332, DOI 10.1109/IROS.2001.976418; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang Heng, 2009, BMVC, P1; Wang Jingdong, 2006, 2006 IEEE COMP SOC C, V1, P347; WOLFE JM, 1994, PSYCHON B REV, V1, P202, DOI 10.3758/BF03200774; Wong L.-K., 2012, P ACM INT C MULT, P845; Wong L.-K., 2011, IEEE WORKSH APPL COM, P73; Wong LK, 2009, IEEE IMAGE PROC, P997, DOI 10.1109/ICIP.2009.5413825; Xu Jia, 2015, IEEE C COMP VIS PATT; Xu K., 2013, ACM T GRAPHIC, V32; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153; Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10; Yun KW, 2013, PROC CVPR IEEE, P739, DOI 10.1109/CVPR.2013.101; Zhai Y., 2006, PROC14TH ACM INT C M, DOI [10.1145/1180639.1180824, DOI 10.1145/1180639.1180824]; Zhang GX, 2009, COMPUT GRAPH FORUM, V28, P1897, DOI 10.1111/j.1467-8659.2009.01568.x; Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26; Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32; Zhang XC, 2015, PROC CVPR IEEE, P4511, DOI 10.1109/CVPR.2015.7299081; Zhao R., 2015, CORR; Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314; Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460; Zhou B., 2014, CORR, V1412, P6856; Zhou Bolei, 2014, ADV NEURAL INFORM PR, P7, DOI DOI 10.5555/2968826.2968881; Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26	206	43	44	0	18	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2018	126	1					86	110		10.1007/s11263-017-1042-6	http://dx.doi.org/10.1007/s11263-017-1042-6			25	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science	FS6MC					2022-12-18	WOS:000419910500005
J	Kulkarni, K; Evangelidis, G; Cech, J; Horaud, R				Kulkarni, Kaustubh; Evangelidis, Georgios; Cech, Jan; Horaud, Radu			Continuous Action Recognition Based on Sequence Alignment	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Action recognition; Video segmentation; Example-based recognition; Template matching; Dynamic programming; Dynamic time warping; Bag of words	ALGORITHM; SEARCH; MODELS; HMM	Continuous action recognition is more challenging than isolated recognition because classification and segmentation must be simultaneously carried out. We build on the well known dynamic time warping framework and devise a novel visual alignment technique, namely dynamic frame warping (DFW), which performs isolated recognition based on per-frame representation of videos, and on aligning a test sequence with a model sequence. Moreover, we propose two extensions which enable to perform recognition concomitant with segmentation, namely one-pass DFW and two-pass DFW. These two methods have their roots in the domain of continuous recognition of speech and, to the best of our knowledge, their extension to continuous visual action recognition has been overlooked. We test and illustrate the proposed techniques with a recently released dataset (RAVEL) and with two public-domain datasets widely used in action recognition (Hollywood-1 and Hollywood-2). We also compare the performances of the proposed isolated and continuous recognition algorithms with several recently published methods.	[Kulkarni, Kaustubh; Evangelidis, Georgios; Horaud, Radu] INRIA Grenoble Rhone Alpes, Montbonnot St Martin, France; [Cech, Jan] Czech Tech Univ, Ctr Machine Percept, CR-16635 Prague, Czech Republic	Czech Technical University Prague	Horaud, R (corresponding author), INRIA Grenoble Rhone Alpes, Montbonnot St Martin, France.	Kaustubh.Kulkarni@inria.fr; Georgios.Evangelidis@inria.fr; cechj@cmp.felk.cvut.cz; Radu.Horaud@inria.fr	Horaud, Radu/AAR-5982-2021	Horaud, Radu/0000-0001-5232-024X	European project HUMAVIPS [247525]; ERC Advanced Grant VHIA [340113]; Czech Science Foundation Project GACR	European project HUMAVIPS; ERC Advanced Grant VHIA; Czech Science Foundation Project GACR	The authors acknowledge support from the European project HUMAVIPS #247525 (2010-2013) and from the ERC Advanced Grant VHIA #340113 (2014-2019). J. Cech acknowledges support from the Czech Science Foundation Project GACR.	Alameda-Pineda X, 2013, J MULTIMODAL USER IN, V7, P79, DOI 10.1007/s12193-012-0111-y; Alon J, 2009, IEEE T PATTERN ANAL, V31, P1685, DOI 10.1109/TPAMI.2008.203; Blackburn J, 2007, LECT NOTES COMPUT SC, V4814, P285; Boyd S., 2004, CONVEX OPTIMIZATION, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441.001, 10.1017/cbo97805118044 41]; Brendel W, 2010, LECT NOTES COMPUT SC, V6312, P721, DOI 10.1007/978-3-642-15552-9_52; Chen SSB, 2001, SIAM REV, V43, P129, DOI 10.1137/S1064827596304010; Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678; Escalera S., 2013, CHALEARN MULT GEST R; Evangelidis GD, 2008, IEEE T PATTERN ANAL, V30, P1858, DOI 10.1109/TPAMI.2008.113; Gales M, 2007, FOUND TRENDS SIGNAL, V1, P195, DOI 10.1561/2000000004; Gill PR, 2011, IEEE T SIGNAL PROCES, V59, P4595, DOI 10.1109/TSP.2011.2161292; Gong D, 2011, IEEE I CONF COMP VIS, P571, DOI 10.1109/ICCV.2011.6126290; Hienz H, 1999, LECT NOTES ARTIF INT, V1739, P185; Ikizler N, 2009, IMAGE VISION COMPUT, V27, P1515, DOI 10.1016/j.imavis.2009.02.002; Jain M, 2013, PROC CVPR IEEE, P2555, DOI 10.1109/CVPR.2013.330; Jiang YG, 2012, LECT NOTES COMPUT SC, V7576, P425, DOI 10.1007/978-3-642-33715-4_31; Kulkarni K., 2008, 1 INT WORKSH MACH LE; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; LEE CH, 1989, IEEE T ACOUST SPEECH, V37, P1649, DOI 10.1109/29.46547; Liang RH, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P558, DOI 10.1109/AFGR.1998.671007; Lv F., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383131; Lv F, 2006, LECT NOTES COMPUT SC, V3954, P359; Manning C.D., 2008, INTRO INFORM RETRIEV; Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557; Minh Hoai, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3265, DOI 10.1109/CVPR.2011.5995470; Morency L. -P., 2007, P I C COMP VI PATT R, P1, DOI DOI 10.1109/CVPR.2007.383299; Muller M., 2007, INFORM RETRIEVAL MUS, V3, P69, DOI [10.1007/978-3-540- 74048-3_4, DOI 10.1007/978-3-540-74048-3]; Ney H, 1999, IEEE SIGNAL PROC MAG, V16, P64, DOI 10.1109/79.790984; NEY H, 1984, IEEE T ACOUST SPEECH, V32, P263, DOI 10.1109/TASSP.1984.1164320; Ning HZ, 2008, LECT NOTES COMPUT SC, V5303, P419, DOI 10.1007/978-3-540-88688-4_31; Rabiner L., 1993, FUNDAMENTALS SPEECH; SAKOE H, 1979, IEEE T ACOUST SPEECH, V27, P588, DOI 10.1109/TASSP.1979.1163310; Sanchez-Riera J., 2012, LNCS; Shi QF, 2011, INT J COMPUT VISION, V93, P22, DOI 10.1007/s11263-010-0384-0; Sivic J, 2009, IEEE T PATTERN ANAL, V31, P591, DOI 10.1109/TPAMI.2008.111; Sminchisescu C, 2006, COMPUT VIS IMAGE UND, V104, P210, DOI 10.1016/j.cviu.2006.07.014; Solmaz B, 2013, MACH VISION APPL, V24, P1473, DOI 10.1007/s00138-012-0449-x; Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811; Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108; Ullah M. M., 2010, BRIT MACH VIS C, V10, P95; Vail D L, 2007, P 6 INT JOINT C AUT, P235, DOI DOI 10.1145/1329125.1329409; Vintsyuk T. K., 1971, Cybernetics, V7, P361; Vogler C, 2001, COMPUT VIS IMAGE UND, V81, P358, DOI 10.1006/cviu.2000.0895; Vogler C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P363, DOI 10.1109/ICCV.1998.710744; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Young S., 1989, 38 U CAMBR DEP ENG; Young S., 1993, TECHNICAL REPORT; Young S., 2009, TECHNICAL REPORT; Zhou F., 2009, ADV NEURAL INFORM PR, V22, P2286	50	43	45	0	22	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2015	112	1					90	114		10.1007/s11263-014-0758-9	http://dx.doi.org/10.1007/s11263-014-0758-9			25	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	CC4YC		Green Submitted			2022-12-18	WOS:000350361500005
J	Mainali, P; Lafruit, G; Yang, Q; Geelen, B; Van Gool, L; Lauwereins, R				Mainali, Pradip; Lafruit, Gauthier; Yang, Qiong; Geelen, Bert; Van Gool, Luc; Lauwereins, Rudy			SIFER: Scale-Invariant Feature Detector with Error Resilience	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Scale-invariant; Feature; Invariant; Keypoint; Registration	CORNER DETECTION; IMAGE-ANALYSIS	We present a new method to extract scale-invariant features from an image by using a Cosine Modulated Gaussian (CM-Gaussian) filter. Its balanced scale-space atom with minimal spread in scale and space leads to an outstanding scale-invariant feature detection quality, albeit at reduced planar rotational invariance. Both sharp and distributed features like corners and blobs are reliably detected, irrespective of various image artifacts and camera parameter variations, except for planar rotation. The CM-Gaussian filters are approximated with the sum of exponentials as a single, fixed-length filter and equal approximation error over all scales, providing constant-time, low-cost image filtering implementations. The approximation error of the corresponding digital signal processing is below the noise threshold. It is scalable with the filter order, providing many quality-complexity trade-off working points. We validate the efficiency of the proposed feature detection algorithm on image registration applications over a wide range of testbench conditions.	[Mainali, Pradip; Lafruit, Gauthier; Yang, Qiong; Geelen, Bert; Lauwereins, Rudy] Interuniv Microelect Ctr VZW IMEC, B-3001 Louvain, Belgium; [Mainali, Pradip; Van Gool, Luc] Univ Louvain, ESAT, B-3001 Louvain, Belgium	IMEC	Mainali, P (corresponding author), Interuniv Microelect Ctr VZW IMEC, Kapeldreef 75, B-3001 Louvain, Belgium.	Pradip.Mainali@imec.be; Gauthier.Lafruit@imec.be; Qiong.Yang@imec.be; Bert.Geelen@imec.be; Luc.VanGool@esat.kuleuven.be; Rudy.Lauwereins@imec.be			IWT SBO-project [100021]	IWT SBO-project(Institute for the Promotion of Innovation by Science and Technology in Flanders (IWT))	The authors would like to thank Rachid Deriche from INRIA, Prof. Lucas J. Van Vliet and Prof. Ian T. Young from TU/Delft for discussions and answering our emails regarding the approximation design methods for the filters. Author Bert Geelen was supported by IWT SBO-project 100021 "CHAMELEON".	Aanaes H, 2012, INT J COMPUT VISION, V97, P18, DOI 10.1007/s11263-011-0473-8; Alahi A., 2012, IEEE C COMP VIS PATT, VNew York; Bay H., 2011, SURF IMPLEMENTATION; Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32; Beaudet P. R., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition, P579; Bendale P., 2010, P BRIT MACH VIS C AB, P491; Brown M, 2002, BRIT MACH VIS C, DOI DOI 10.5244/C.16.23; Cornelis N, 2008, PROC CVPR IEEE, P1013; Crete F, 2007, PROC SPIE, V6492, DOI 10.1117/12.702790; DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644; Deng HL, 2007, PROC CVPR IEEE, P25; Deriche R., 1993, RECURSIVELY IMPLEMEN; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Forstner W., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P383, DOI 10.1007/BFb0028370; Gao XT, 2007, IEEE T CIRC SYST VID, V17, P868, DOI 10.1109/TCSVT.2007.897473; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; HARTLEY R, 2000, MULTIPLE VIEW GEOMET, P87; HORAUD R, 1990, LECT NOTES COMPUT SC, V427, P374; Huang FC, 2012, IEEE T CIRC SYST VID, V22, P340, DOI 10.1109/TCSVT.2011.2162760; Kadir T., 2004, EUR C COMP VIS; Kovesi P., 2003, AUSTR PATT REC SOC C; LINDEBERG T, 1990, IEEE T PATTERN ANAL, V12, P234, DOI 10.1109/34.49051; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mainali P., 2010, IEEE T CIRCUIT SYSTE, V21, P87; Mallat S., 2008, WAVELET TOUR SIGNAL; MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030; Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384; Maver J, 2010, IEEE T PATTERN ANAL, V32, P1211, DOI 10.1109/TPAMI.2009.105; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Mikolajczyk K., 2007, OXFORD DATA SET; Mokhtarian F, 1998, IEEE T PATTERN ANAL, V20, P1376, DOI 10.1109/34.735812; Moreno P., 2005, P 5 INT C VIS IM IM; Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479; Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275; Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446; Shilat E, 1997, PROC CVPR IEEE, P976, DOI 10.1109/CVPR.1997.609446; Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710; Tack N, 2012, PROC SPIE, V8266, DOI 10.1117/12.908172; Tola E., 2008, P 2008 IEEE C COMP V, P1, DOI DOI 10.1109/CVPR.2008.4587673; Tomasi C, 1991, CMUCS91132; Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8; Vedaldi A., 2011, OPEN SOURCE SIFT IMP; Young IT, 2002, IEEE T SIGNAL PROCES, V50, P2798, DOI 10.1109/TSP.2002.804095	45	43	46	0	20	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2013	104	2					172	197		10.1007/s11263-013-0622-3	http://dx.doi.org/10.1007/s11263-013-0622-3			26	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	189FD					2022-12-18	WOS:000322251800004
J	Toshev, A; Taskar, B; Daniilidis, K				Toshev, Alexander; Taskar, Ben; Daniilidis, Kostas			Shape-Based Object Detection via Boundary Structure Segmentation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Shape representation; Shape matching; Object recognition and detection; Object segmentation	APPROXIMATION ALGORITHMS; RECOGNITION; SIMILARITY; COMPONENTS; TEXTURE	We address the problem of object detection and segmentation using global holistic properties of object shape. Global shape representations are highly susceptible to clutter inevitably present in realistic images, and thus can be applied robustly only using a precise segmentation of the object. To this end, we propose a figure/ground segmentation method for extraction of image regions that resemble the global properties of a model boundary structure and are perceptually salient. Our shape representation, called the chordiogram, is based on geometric relationships of object boundary edges, while the perceptual saliency cues we use favor coherent regions distinct from the background. We formulate the segmentation problem as an integer quadratic program and use a semidefinite programming relaxation to solve it. The obtained solutions provide a segmentation of the object as well as a detection score used for object recognition. Our single-step approach achieves state-of-the-art performance on several object detection and segmentation benchmarks.	[Toshev, Alexander] Google Res, Mountain View, CA 94043 USA; [Taskar, Ben; Daniilidis, Kostas] Univ Penn, Grasp Lab, Philadelphia, PA 19104 USA	Google Incorporated; University of Pennsylvania	Toshev, A (corresponding author), Google Res, 1600 Amphitheatre Pkwy, Mountain View, CA 94043 USA.	toshev@google.com; taskar@cis.upenn.edu; kostas@cis.upenn.edu		Daniilidis, Kostas/0000-0003-0498-0758	National Science Foundation [NSF-OIA-1028009, NSF-DGE-0966142]; Army Research Laboratory [W911NF-10-2-0016]; DARPA	National Science Foundation(National Science Foundation (NSF)); Army Research Laboratory(United States Department of DefenseUS Army Research Laboratory (ARL)); DARPA(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA))	This work has been partially supported by the National Science Foundation grants NSF-OIA-1028009 and NSF-DGE-0966142 and by the Army Research Laboratory accomplished under the Robotics CTA Cooperative Agreement Number W911NF-10-2-0016. Ben Taskar was also supported by the DARPA Computer Science Study Group Award. Parts of the results presented in this paper have previously appeared in Toshev et al. (2010).	Basri R, 1998, VISION RES, V38, P2365, DOI 10.1016/S0042-6989(98)00043-1; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; Binford T.O., 1971, IEEE C SYST CONTR MI; BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6; Borenstein E., 2004, IEEE COMP SOC C COMP; Boyd S, 2004, CONVEX OPTIMIZATION; Carlsson S., 1999, INT WORKSH SHAP CONT; Chekuri C, 2005, SIAM J DISCRETE MATH, V18, P608, DOI 10.1137/S0895480101396937; FELZENSZWALB PF, 2007, IEEE COMP SOC C COMP; Ferrari V., 2006, EUR C COMP VIS; Ferrari V., 2007, IEEE COMP SOC C COMP; Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144; Fritz M., 2008, IEEE COM SOC C COMP; Goemans MX, 1995, J ACM, V42, P1115, DOI 10.1145/227683.227684; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Gorelick L, 2009, INT J COMPUT VISION, V83, P211, DOI 10.1007/s11263-009-0216-2; Grant M., 2014, CVX MATLAB SOFTWARE; GRIMSON WEL, 1987, IEEE T PATTERN ANAL, V9, P469, DOI 10.1109/TPAMI.1987.4767935; GU C, 2009, IEEE COMP SOC C COMP; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Indyk P., 2003, 3 INT WORKSH STAT CO; Joachims T., 1999, ADV KERNEL METHODS S; KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741; Koffka K., 1935, PRINCIPLES GESTALT P; LAMDAN Y, 1990, IEEE T ROBOTIC AUTOM, V6, P578, DOI 10.1109/70.62047; Latecki L., 2000, IEEE COMP SOC C COMP; Latecki LJ, 2000, IEEE T PATTERN ANAL, V22, P1185, DOI 10.1109/34.879802; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; LEORDEANU M, 2007, IEEE COMP SOC C COMP; LEVIN A, 2006, EUR C COMP VIS; Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41; Lu C., 2009, INT C COMP VIS; MAJI S, 2009, IEEE COMP SOC C COMP; MALISIEWICZ T, 2008, IEEE COMP SOC C COMP; Marr D., 2010, VISION COMPUTATIONAL; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; McNeill G., 2006, IEEE COMP SOC C COMP; MOKHTARIAN F, 1997, IMAGE DATABASES MULT, P51, DOI DOI 10.1142/9789812797988_; Opelt A., 2006, EUR C COMP VIS; Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648; Palmer S.E., 1999, VISION SCI PHOTONS P; PENTLAND AP, 1986, ARTIF INTELL, V28, P293, DOI 10.1016/0004-3702(86)90052-4; Pizer SM, 1999, IEEE T MED IMAGING, V18, P851, DOI 10.1109/42.811263; Ravishankar S., 2008, EUR C COMP VIS; Ren X., 2005, NEURAL INFORM PROCES; Russell Bryan C., 2006, IEEE COMP SOC C COMP; Schoenemann T., 2007, INT C COMP VIS; Sebastian TB, 2003, IEEE T PATTERN ANAL, V25, P116, DOI 10.1109/TPAMI.2003.1159951; Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924; Shapiro L., 1979, CS79011R VIRG TECH; Shi J, 2005, IEEE COMP SOC C COMP; Shotton J., 2005, INT C COMP VIS; Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1; Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703; Srinivasan P., 2010, IEEE COMP SOC C COMP; Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766; Toshev A., 2010, IEEE COMP SOC C COMP; Trinh NH, 2011, INT J COMPUT VISION, V94, P215, DOI 10.1007/s11263-010-0412-0; Tu Z., 2004, 7 EUR C COMP VIS; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; YOSHIDA K, 1982, IEEE T CONSUM ELECTR, V28, P202, DOI 10.1109/TCE.1982.353911; Zhang DS, 2003, MULTIMEDIA SYST, V9, P15, DOI 10.1007/s00530-002-0075-y; Zhu Q., 2008, EUR C COMP VIS; [No title captured]	67	43	48	2	40	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2012	99	2					123	146		10.1007/s11263-012-0521-z	http://dx.doi.org/10.1007/s11263-012-0521-z			24	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	943RU					2022-12-18	WOS:000304143700001
J	Puig, L; Bastanlar, Y; Sturm, P; Guerrero, JJ; Barreto, J				Puig, Luis; Bastanlar, Yalin; Sturm, Peter; Guerrero, J. J.; Barreto, Joao			Calibration of Central Catadioptric Cameras Using a DLT-Like Approach	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Omnidirectional vision; Camera calibration; Lifted coordinates; Structure from motion; Central catadioptric systems		In this study, we present a calibration technique that is valid for all single-viewpoint catadioptric cameras. We are able to represent the projection of 3D points on a catadioptric image linearly with a 6x10 projection matrix, which uses lifted coordinates for image and 3D points. This projection matrix can be computed from 3D-2D correspondences (minimum 20 points distributed in three different planes). We show how to decompose it to obtain intrinsic and extrinsic parameters. Moreover, we use this parameter estimation followed by a non-linear optimization to calibrate various types of cameras. Our results are based on the sphere camera model which considers that every central catadioptric system can be modeled using two projections, one from 3D points to a unitary sphere and then a perspective projection from the sphere to the image plane. We test our method both with simulations and real images, and we analyze the results performing a 3D reconstruction from two omnidirectional images.	[Puig, Luis; Guerrero, J. J.] Univ Zaragoza, DIIS, Zaragoza, Spain; [Puig, Luis; Guerrero, J. J.] Univ Zaragoza, Inst Invest Ingn Aragon I3A, Zaragoza, Spain; [Bastanlar, Yalin] Middle E Tech Univ, Inst Informat, TR-06531 Ankara, Turkey; [Barreto, Joao] Univ Coimbra, ISR DEEC, Coimbra, Portugal; [Sturm, Peter] INRIA Rhone Alpes, Grenoble, France; [Sturm, Peter] Lab Jean Kuntzmann, Grenoble, France	University of Zaragoza; University of Zaragoza; Middle East Technical University; Universidade de Coimbra; UDICE-French Research Universities; Communaute Universite Grenoble Alpes; Institut National Polytechnique de Grenoble; Universite Grenoble Alpes (UGA); Centre National de la Recherche Scientifique (CNRS); Inria	Puig, L (corresponding author), Univ Zaragoza, DIIS, Zaragoza, Spain.	lpuig@unizar.es; yalinb@ii.metu.edu.tr; Peter.Sturm@inrialpes.fr; jguerrer@unizar.es; jpbar@deec.uc.pt	Puig, Luis/B-4336-2014; Guerrero, Jose J/K-5435-2014; Barreto, Joao P/I-2845-2012; Bastanlar, Yalin/AAA-7114-2022	Guerrero, Jose J/0000-0001-5209-2267; Barreto, Joao P/0000-0001-5220-9170; Bastanlar, Yalin/0000-0002-3774-6872	French ANR; Portuguese Science Foundation [PTDC/EEA-ACR/68887/2006]; TUBITAK; Spanish MICINN;  [DPI2009-14664-C02-01]	French ANR(French National Research Agency (ANR)); Portuguese Science Foundation(Portuguese Foundation for Science and Technology); TUBITAK(Turkiye Bilimsel ve Teknolojik Arastirma Kurumu (TUBITAK)); Spanish MICINN(Ministry of Science and Innovation, Spain (MICINN)Spanish Government); 	The authors are grateful for researcher exchange support of TUBITAK and Spanish MICINN, which was used for the joint research presented here. This work was also supported by project DPI2009-14664-C02-01. Peter Sturm acknowledges support by the French ANR project CAVIAR. Joao P. Barreto is grateful for support from the Portuguese Science Foundation through grant PTDC/EEA-ACR/68887/2006.	Abdel-Aziz Y., 1971, P S CLOSE RANGE PHOT, P1, DOI [10.14358/PERS.81.2.103, DOI 10.1080/10671188.1967.10616517]; Baker S, 1999, INT J COMPUT VISION, V35, P175, DOI 10.1023/A:1008128724364; BARRETO J, 2006, IEEE P C COMP VIS PA, V1, P1258; Barreto JP, 2006, COMPUT VIS IMAGE UND, V103, P208, DOI 10.1016/j.cviu.2006.06.003; Barreto JP, 2005, IEEE T PATTERN ANAL, V27, P1327, DOI 10.1109/TPAMI.2005.163; BASTANLAR Y, 2008, P 8 WORKSH OMN VIS 2; BUCHANAN T, 1988, COMPUT VISION GRAPH, V42, P130, DOI 10.1016/0734-189X(88)90146-6; CAUCHOIS C, 1999, P IEEE INT C ROB AUT, V2, P1287; Chahl JS, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P104, DOI 10.1109/OMNVIS.2000.853815; Derrien S, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P85, DOI 10.1109/OMNVIS.2000.853811; FAUGERAS O, 1993, ARTIFICIAL INTELLIGE; Geyer C, 2002, LECT NOTES COMPUT SC, V2351, P140; Geyer C, 2001, PROC CVPR IEEE, P279; Geyer C, 2002, IEEE T PATTERN ANAL, V24, P687, DOI 10.1109/34.1000241; Geyer Christopher, 2000, LNCS, P445, DOI DOI 10.1007/3-540-45053-X_29; Hartley R., 2004, ROBOTICA; Heikkila J, 1997, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.1997.609468; Horn R.A., 2013, TOPICS MATRIX ANAL, DOI DOI 10.1017/CBO9780511840371; Horn R. A., 1986, MATRIX ANAL; Kang SB, 2000, PROC CVPR IEEE, P201, DOI 10.1109/CVPR.2000.855820; Kannala J, 2004, INT C PATT RECOG, P10, DOI 10.1109/ICPR.2004.1333993; LHUILLIER M, 2007, IEEE C COMP VIS PATT, P1; Mei C, 2007, IEEE INT CONF ROBOT, P3945, DOI 10.1109/ROBOT.2007.364084; NAGAHARA H, 2003, COMP VIS PATT REC WO, V7, P86, DOI DOI 10.1109/CVPRW.2003.10070; ORGHIDAN R, 2003, C COMP VIS PATT REC, V7, P70; Scaramuzza D, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P5695, DOI 10.1109/IROS.2006.282372; Scotti G, 2005, IEE P-VIS IMAGE SIGN, V152, P250, DOI 10.1049/ip-vis:20041302; Sturm P, 2002, THIRD WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P37, DOI 10.1109/OMNVIS.2002.1044489; STURM P, 2008, P 10 EUR C COMP VIS, V4, P609; Svoboda T, 2002, INT J COMPUT VISION, V49, P23, DOI 10.1023/A:1019869530073; SWAMINATHAN R, 2001, NONSINGLE VIEWPOINT; Tardif JP, 2006, LECT NOTES COMPUT SC, V3954, P186; TOEPFER C, 2007, P 11 INT C COMP VIS, P1	33	43	49	0	28	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2011	93	1					101	114		10.1007/s11263-010-0411-1	http://dx.doi.org/10.1007/s11263-010-0411-1			14	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	738WJ		Green Submitted			2022-12-18	WOS:000288673000006
J	Spain, M; Perona, P				Spain, Merrielle; Perona, Pietro			Measuring and Predicting Object Importance	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Visual recognition; Object recognition; Importance; Perception; Keywording; Saliency; Rank aggregation; Amazon Mechanical Turk	ATTENTION; SELECTION; MODEL	How important is a particular object in a photograph of a complex scene? We propose a definition of importance and present two methods for measuring object importance from human observers. Using this ground truth, we fit a function for predicting the importance of each object directly from a segmented image; our function combines a large number of object-related and image-related features. We validate our importance predictions on 2,841 objects and find that the most important objects may be identified automatically. We find that object position and size are particularly informative, while a popular measure of saliency is not.			Spain, M (corresponding author), 1200 E Calif Blvd,MC 136-93, Pasadena, CA 91125 USA.	spain@caltech.edu			National Science Foundation; Office of Naval Research [N00014-06-1-0734]; National Institutes of Health [R01 DA022777]	National Science Foundation(National Science Foundation (NSF)); Office of Naval Research(Office of Naval Research); National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	This material is based upon work supported under a National Science Foundation Graduate Research Fellowship, Office of Naval Research grant N00014-06-1-0734, and National Institutes of Health grant R01 DA022777.	[Anonymous], 2007, CALTECH 256 OBJECT C; Dwork C., 2001, P 10 INT C WORLD WID, P613, DOI [10.1145/371920.372165, DOI 10.1145/371920.372165]; Einhauser W, 2008, J VISION, V8, DOI 10.1167/8.2.2; Elazary L, 2008, J VISION, V8, DOI 10.1167/8.3.3; Everingham M., 2008, PASCAL VISUAL OBJECT; Fei-Fei L, 2007, J VISION, V7, DOI 10.1167/7.1.10; Fog A, 2008, COMMUN STAT-SIMUL C, V37, P258, DOI 10.1080/03610910701790269; Fowlkes C, 2003, PROC CVPR IEEE, P54; Grauman K, 2005, IEEE I CONF COMP VIS, P1458; Hastie T., 2009, ELEMENTS STAT LEARNI, DOI [10.1007/978-0-387-84858-7, DOI 10.1007/978-0-387-84858-7]; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Jaccard P., 1901, B SOC VAUD SCI NAT, V37, P547, DOI [10.5169/seals-266450, DOI 10.5169/SEALS-266450]; Kendall M. G., 1962, RANK CORRELATION MET; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Lebanon G., 2002, P 19 INT C MACH LEAR, P363; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MANLY BFJ, 1974, BIOMETRICS, V30, P281, DOI 10.2307/2529649; MAYER M, 1985, INVESTIGATIVE OPHTHA, V26; RABINOVICH A, 2006, CVPR, P1130; Rabinovich A, 2007, IEEE I CONF COMP VIS, P1237, DOI 10.1109/iccv.2007.4408986; Rensink RA, 1997, PSYCHOL SCI, V8, P368, DOI 10.1111/j.1467-9280.1997.tb00427.x; Russell B., 2005, LABELME DATABASE WEB; Russell BC, 2007, NIPS; SHORE S, 2005, STEPHEN SHORE AM SUR; Shore Stephen, 2005, UNCOMMON PLACES COMP; Sorokin A., 2008, CVPR; SPAIN M, 2008, P EUR C COMP VIS ECC; Stein A.N., 2008, CVPR; Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; von Ahn Luis, 2004, P SIGCHI C HUM FACT, DOI [10.1145/985692.985733, DOI 10.1145/985692.985733]; Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001; Zhang H, 2006, 2006 IEEE COMP SOC C, P2126, DOI [10.1109/CVPR.2006.301, DOI 10.1109/CVPR.2006.301]	35	43	50	0	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2011	91	1					59	76		10.1007/s11263-010-0376-0	http://dx.doi.org/10.1007/s11263-010-0376-0			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	705HB	32719573	Green Accepted			2022-12-18	WOS:000286118400004
J	Lee, CS; Elgammal, A				Lee, C. -S.; Elgammal, A.			Coupled Visual and Kinematic Manifold Models for Tracking	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Visual manifold; Human motion tracking; Kinematic manifold; Manifold learning; Bayesian tracking; Pose estimation	3D HUMAN MOTION; RECOGNITION; SHAPE	In this paper, we consider modeling data lying on multiple continuous manifolds. In particular, we model the shape manifold of a person performing a motion observed from different viewpoints along a view circle at a fixed camera height. We introduce a model that ties together the body configuration (kinematics) manifold and visual (observations) manifold in a way that facilitates tracking the 3D configuration with continuous relative view variability. The model exploits the low-dimensionality nature of both the body configuration manifold and the view manifold, where each of them are represented separately. The resulting representation is used for tracking complex motions within a Bayesian framework, in which the model provides a low-dimensional state representation as well as a constrained dynamic model for both body configuration and view variations. Experimental results estimating the 3D body posture from a single camera are presented for the HUMANEVA dataset and other complex motion video sequences.	[Lee, C. -S.] Yeungnam Univ, Sch Elect Engn Commun Engn & Comp Sci, Dept Elect Engn, Gyongsan, South Korea; [Elgammal, A.] Rutgers State Univ, Dept Comp Sci, Piscataway, NJ USA	Yeungnam University; Rutgers State University New Brunswick	Lee, CS (corresponding author), Yeungnam Univ, Sch Elect Engn Commun Engn & Comp Sci, Dept Elect Engn, Gyongsan, South Korea.	chansu@ynu.ac.kr; elgammal@cs.rutgers.edu						Agarwal A, 2004, PROC CVPR IEEE, P882; Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744; Black M. J., 2006, CS0608 BROWN U; Brand M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1237, DOI 10.1109/ICCV.1999.790422; CAMPBELL LW, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P624, DOI 10.1109/ICCV.1995.466880; Christoudias CM, 2005, PROC CVPR IEEE, P1067; Darrell T., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P335, DOI 10.1109/CVPR.1993.341109; Elgammal A, 2004, PROC CVPR IEEE, P681; Elgammal A, 2004, PROC CVPR IEEE, P478; Elgammal A, 2007, COMPUT VIS IMAGE UND, V106, P31, DOI 10.1016/j.cviu.2005.09.010; Elgammal A, 2009, IEEE T PATTERN ANAL, V31, P520, DOI 10.1109/TPAMI.2008.101; Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716; Gavrila DM, 1996, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.1996.517056; Grauman K, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P641; HOGG D, 1983, IMAGE VISION COMPUT, V1, P5, DOI DOI 10.1016/0262-8856(83)90003-3; Kakadiaris IA, 1996, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.1996.517057; LATHAUWER LD, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI DOI 10.1137/S0895479896305696; Lawrence N. D., 2004, P ADV NEUR INF PROC; Lee CS, 2006, INT C PATT RECOG, P489; LEE CS, 2005, WORKSH DYN VIS; Li R, 2007, IEEE I CONF COMP VIS, P1687; Lin RS, 2006, LECT NOTES COMPUT SC, V3952, P245; Magnus J. R., 1988, WILEY SERIES PROBABI; Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002; MOON K, 2006, P CVPR, P198; MORARIU VI, 2006, P IEEE C COMP VIS PA, P545; Mori G, 2002, LECT NOTES COMPUT SC, V2352, P666; MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486; OROURKE J, 1980, IEEE T PATTERN ANAL, V2, P522, DOI 10.1109/TPAMI.1980.6447699; POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326; Rahimi A, 2005, PROC CVPR IEEE, P868; REHG JM, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P612, DOI 10.1109/ICCV.1995.466882; ROHR K, 1994, CVGIP-IMAG UNDERSTAN, V59, P94, DOI 10.1006/ciun.1994.1006; Rosales R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P378, DOI 10.1109/ICCV.2001.937543; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Schlkopf B., 2002, LEARNING KERNELS SUP; Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750; Shakhnarovich G, 2002, LECT NOTES COMPUT SC, V2352, P851, DOI 10.1007/3-540-47977-5_56; Sidenbladh H., 2000, LNCS, V2, P702; Sminchisescu C, 2005, PROC CVPR IEEE, P390; SMINCHISESCU C, 2004, P INT C MACH LEARN, P140; Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tian T.P., 2005, WORKSH LEARN COMP VI; Urtasun R, 2005, IEEE I CONF COMP VIS, P403; Urtasun R., 2006, 2006 IEEE COMP SOC C, V1, P238, DOI DOI 10.1109/CVPR.2006.15; Vasilescu M.A.O., 2002, P EUR C COMP VIS, P447; Vasilescu MAO, 2002, INT C PATT RECOG, P456, DOI 10.1109/ICPR.2002.1047975; WANG J, 2005, P ADV NEURAL INFORM; Yacoob Y, 1999, COMPUT VIS IMAGE UND, V73, P232, DOI 10.1006/cviu.1998.0726	50	43	44	0	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2010	87	1-2			SI		118	139		10.1007/s11263-009-0266-5	http://dx.doi.org/10.1007/s11263-009-0266-5			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	539GP		Green Submitted			2022-12-18	WOS:000273242300007
J	Ottlik, A; Nagel, HH				Ottlik, A.; Nagel, H. -H.			Initialization of model-based vehicle tracking in video sequences of inner-city intersections	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						tracking; model-based; road-vehicle; Kalman-filter; initialization; traffic videos; optical-flow-field segmentation	RECOGNITION; MOTION	A fully automatic initialization approach for 3D-model-based vehicle tracking has been developed, based on Edge-Element and Optical-Flow association. An entire automatic initialization and tracking system incorporating this approach achieves results comparable to those obtained by earlier experiments based on semi-interactive initialization, provided the assessment criteria are roughly equivalent. Experiences with a large testing sample-about 15 minutes of inner-city traffic videos-are discussed in detail.	[Ottlik, A.; Nagel, H. -H.] Univ Karlsruhe, Inst Algorithmen & Kognit Syst, D-76128 Karlsruhe, Germany	Helmholtz Association; Karlsruhe Institute of Technology	Nagel, HH (corresponding author), Univ Karlsruhe, Inst Algorithmen & Kognit Syst, Postfach 6980, D-76128 Karlsruhe, Germany.	nagel@iaks.uni-karlsruhe.de			European Union [CogViSys-IST-2000-29404, 6thFP-IST027110]	European Union(European Commission)	The investigations have been partially supported by the European Union FP5-Project CogViSys-IST-2000-29404 and by the European Union Project HERMES (6thFP-IST027110).	Collins RT, 2000, IEEE T PATTERN ANAL, V22, P745, DOI 10.1109/TPAMI.2000.868676; Dahlkamp H, 2007, INT J COMPUT VISION, V73, P139, DOI 10.1007/s11263-006-9786-4; Haag M, 1999, INT J COMPUT VISION, V35, P295, DOI 10.1023/A:1008112528134; Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274; Kastrinaki V, 2003, IMAGE VISION COMPUT, V21, P359, DOI 10.1016/S0262-8856(03)00004-0; Kumar P, 2004, LECT NOTES COMPUT SC, V3021, P376; Leibe B, 2006, LECT NOTES COMPUT SC, V4174, P192; Magee DR, 2004, IMAGE VISION COMPUT, V22, P143, DOI 10.1016/S0262-8856(03)00145-8; Middendorf M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P178, DOI 10.1109/ICCV.2001.937515; MIDDENDORF M, 2004, AUSWERTUNG LOKALER G; Nadimi S, 2004, IEEE T PATTERN ANAL, V26, P1079, DOI 10.1109/TPAMI.2004.51; Nagel HH, 2004, AI MAG, V25, P31; NAGEL HH, 1988, IMAGE VISION COMPUT, V6, P59, DOI 10.1016/0262-8856(88)90001-7; OTTLIK A, 2005, DISSERTATIONEN KUNST, V291; Pece AEC, 2006, IMAGE VISION COMPUT, V24, P301, DOI 10.1016/j.imavis.2005.07.024; Pece AEC, 2006, IMAGE VISION COMPUT, V24, P1218, DOI 10.1016/j.imavis.2005.06.013; Pece AV, 2002, LECT NOTES COMPUT SC, V2350, P3; RENNO J, 2006, P 6 IEEE INT WORKSH, P97; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; Sun ZH, 2006, IEEE T PATTERN ANAL, V28, P694, DOI 10.1109/TPAMI.2006.104; Tan TN, 1998, INT J COMPUT VISION, V27, P5, DOI 10.1023/A:1007924428535	22	43	48	0	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	2008	80	2					211	225		10.1007/s11263-007-0112-6	http://dx.doi.org/10.1007/s11263-007-0112-6			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	348DA		Green Submitted			2022-12-18	WOS:000259190000003
J	Ogale, AS; Aloimonos, Y				Ogale, Abhijit S.; Aloimonos, Yiannis			A roadmap to the integration of early visual modules	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	Early Cognitive Vision Workshop	MAY 29-JUN 01, 2004	Isle Skye, SCOTLAND	ECOVISION			STEREO DISPARITY; MOTION; COMPUTATION; WINDOW	By examining the problem of image correspondence (binocular stereo and optical flow) and its relationship with other modules such as segmentation, shape and depth estimation, occlusion detection, and local signal processing, we argue that early visual modules are entangled in chicken-and-egg relationships, and unraveling these necessitates a compositional approach. In this paper, we present compositional algorithms which can match images containing slanted surfaces and images having different contrast, while simultaneously solving other problems as part of the same process. Ultimately, our goal is to motivate the application of the compositional approach to unify many other early visual modules. Experimental results have been presented on a large variety of stereo and motion images, including images with contrast mismatch and images containing untextured slanted surfaces.	Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA	University System of Maryland; University of Maryland College Park	Ogale, AS (corresponding author), Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA.	ogale@cfar.umd.edu; yiannis@cfar.umd.edu	Aloimonos, Yiannis/AAI-2969-2020	Aloimonos, Yiannis/0000-0002-8152-4281				Aloimonos Y., 1989, INTEGRATION VISUAL M; Alvarez L, 2002, LECT NOTES COMPUT SC, V2350, P721; BARNARD ST, 1989, INT J COMPUT VISION, V3, P17, DOI 10.1007/BF00054836; Barron J.L., 1994, INT J COMPUT VISION, V12, P236; Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141; Beauchemin SS, 2000, J MATH IMAGING VIS, V13, P155, DOI 10.1023/A:1011220130307; Birchfield S, 1998, IEEE T PATTERN ANAL, V20, P401, DOI 10.1109/34.677269; Black MJ, 2000, INT J COMPUT VISION, V38, P231, DOI 10.1023/A:1008195307933; Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov Y, 1998, IEEE T PATTERN ANAL, V20, P1283, DOI 10.1109/34.735802; Egnal G, 2002, IEEE T PATTERN ANAL, V24, P1127, DOI 10.1109/TPAMI.2002.1023808; FLEET DJ, 1991, CVGIP-IMAG UNDERSTAN, V53, P198, DOI 10.1016/1049-9660(91)90027-M; FLEET DJ, 1994, 1994 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS - HUMANS, INFORMATION AND TECHNOLOGY, VOLS 1-3, P48, DOI 10.1109/ICSMC.1994.399810; Fusiello A, 1997, PROC CVPR IEEE, P858, DOI 10.1109/CVPR.1997.609428; Galvin B., 1998, P BRIT MACH VIS CONV; GEIGER D, 1992, LECT NOTES COMPUT SC, V588, P425; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; JENKIN M, 1988, COMPUTATIONAL PROCES; JULESZ B, 1971, FDN CYCLOPEA PERCEPT; KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690; Kim J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1033, DOI 10.1109/ICCV.2003.1238463; Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668; Liu HC, 1998, COMPUT VIS IMAGE UND, V72, P271, DOI 10.1006/cviu.1998.0675; Mitiche A, 1996, INT J COMPUT VISION, V19, P29, DOI 10.1007/BF00131147; Nestares O, 1998, J ELECTRON IMAGING, V7, P166, DOI 10.1117/1.482638; Ogale AS, 2005, INT J COMPUT VISION, V65, P147, DOI 10.1007/s11263-005-3672-3; Ogale AS, 2005, IEEE T PATTERN ANAL, V27, P988, DOI 10.1109/TPAMI.2005.123; Ogale AS, 2004, PROC CVPR IEEE, P568; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955; QIAN N, 1994, NEURAL COMPUT, V6, P390, DOI 10.1162/neco.1994.6.3.390; Roy S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P492, DOI 10.1109/ICCV.1998.710763; SANGER TD, 1988, BIOL CYBERN, V59, P405, DOI 10.1007/BF00336114; Scharstein D, 1998, INT J COMPUT VISION, V28, P155, DOI 10.1023/A:1008015117424; Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977; SZELISKI R, 1990, INT J COMPUT VISION, V5, P271, DOI 10.1007/BF00126502; Tao H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P532, DOI 10.1109/ICCV.2001.937562; WENG J, 1994, INT J COMPUT VISION, P211	39	43	45	0	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	2007	72	1					9	25		10.1007/s11263-006-8890-9	http://dx.doi.org/10.1007/s11263-006-8890-9			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	122QR					2022-12-18	WOS:000243242000002
J	Damon, J				Damon, J			Determining the geometry of boundaries of objects from medial data	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Blum medial axis; skeletal structures; intrinsic geometry; relative geometry; radial shape operator; grassfire flow; radial flow; geometric medial map; relative critical set	2-DIMENSIONAL IMAGES; SKELETAL STRUCTURES; SYMMETRY SETS; SHAPE; SEGMENTATION; SMOOTHNESS; RIDGES; CORES; 3D	We consider a region Omega in R-2 or R-3 with generic smooth boundary B and Blum medial axis M, on which is defined a multivalued "radial vector field" U from points x on M to the points of tangency of the sphere at x with B. We introduce a "radial shape operator" S-rad and an "edge shape operator" S-E which measure how U bends along M. These are not traditional differential geometric shape operators, nonetheless we derive all local differential geometric invariants of 8 from these operators. This allows us to define from (M, U) a "geometric medial map" on M which corresponds, via a "radial map" from M to B, to the differential geometric properties of B. The geometric medial map also includes a description of the relative geometry of B. This is defined using the "relative critical set" of the radius function r on M. This set consists of a network of curves on M which describe where B is thickest and thinnest. It is computed using the covariant derivative of the tangential component of the unit radial vector field. We further determine how these invariants are related to the differential geometric invariants of M and how these invariants change under deforming diffeomorphisms of M.	Univ N Carolina, Dept Math, Chapel Hill, NC 27599 USA	University of North Carolina; University of North Carolina Chapel Hill	Damon, J (corresponding author), Univ N Carolina, Dept Math, Chapel Hill, NC 27599 USA.	jndamon@email.unc.edu						BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; Bogaevsky IA, 2002, PHYSICA D, V173, P1, DOI 10.1016/S0167-2789(02)00652-8; BRUCE JW, 1986, P ROY SOC EDINB A, V104, P179, DOI 10.1017/S030821050001917X; Bruce JW, 1996, INT J COMPUT VISION, V18, P195, DOI 10.1007/BF00123141; BRUCE JW, 1985, P ROY SOC EDINB A, V101, P163, DOI 10.1017/S0308210500026263; Damon J, 2004, COMPOS MATH, V140, P1657, DOI 10.1112/S0010437X04000570; Damon J, 2003, ANN I FOURIER, V53, P1941, DOI 10.5802/aif.1997; Damon J, 1999, J MATH IMAGING VIS, V10, P163, DOI 10.1023/A:1008379107611; Damon J, 1998, SIAM J APPL MATH, V59, P97, DOI 10.1137/S0036139997318032; DAMON J, UNPUB GENERIC GEOMET; DAMON J, UNPUB GLOBAL GEOMETR; EBERLY D, 1996, SERIES COMPUTATIONAL; Giblin P, 2000, MATHEMATICS OF SURFACES IX, P306; GOLUBITSKY M, 1974, SPRINGER GRADUATE TE; KELLER R, 1999, THESIS U N CAROLINA; KIMIA B., 1990, 3 DIMENSIONAL COMPUT; MATHER JN, 1983, P SYMP PURE MATH, V40, P199; MILLER J., 1998, THESIS U N CAROLINA; NACKMAN LR, 1985, IEEE T PATTERN ANAL, V7, P187, DOI 10.1109/TPAMI.1985.4767643; NACKMAN LR, 1982, THESIS U N CAROLINA; Pizer SM, 2003, INT J COMPUT VISION, V55, P155, DOI 10.1023/A:1026135101267; Pizer SM, 2003, INT J COMPUT VISION, V55, P85, DOI 10.1023/A:1026313132218; Pizer SM, 1999, IEEE T MED IMAGING, V18, P851, DOI 10.1109/42.811263; Pizer SM, 1998, COMPUT VIS IMAGE UND, V69, P55, DOI 10.1006/cviu.1997.0563; Siddiqi K, 2002, INT J COMPUT VISION, V48, P215, DOI 10.1023/A:1016376116653; Siersma D., 1999, BANACH CTR PUBLICATI, V50, P267, DOI 10.4064/-50-1-267-276; Sotomayor J., 1999, BANACH CTR PUBLICATI, V50, P277, DOI [10.4064/-50-1-277-285, DOI 10.4064/-50-1-277-285]; SZEKELY G, 1994, P 2 INT WORKSH VIS F, P532; VANMANEN M, 2003, CURVATURE TORSION FO; VANMANEN M, 2003, THESIS U UTRECHT; YOMDIN J, 1981, COMPOS MATH, V43, P225; Yushkevich P, 2003, IMAGE VISION COMPUT, V21, P17, DOI 10.1016/S0262-8856(02)00135-X; YUSHKEVICH P, 2002, P 1 GEN MOD BAS WORK, P11; [No title captured]; [No title captured]	35	43	45	0	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2005	63	1					45	64		10.1007/s11263-005-4946-5	http://dx.doi.org/10.1007/s11263-005-4946-5			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	907WS		Green Submitted			2022-12-18	WOS:000227749400003
J	Katz, RA; Pizer, SM				Katz, RA; Pizer, SM			Untangling the Blum Medial Axis Transform	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						medial; medial analysis; form analysis; Blum MAT; object part hierarchies	SHAPE-DESCRIPTION; RECEPTIVE-FIELDS; HYPERCOMPLEX; CAT	For over 30 years, Blum's Medial Axis Transform ( MAT) has proven to be an intriguing tool for analyzing and computing with form, but it is one that is notoriously difficult to apply in a robust and stable way. It is well documented how a tiny change to an object's boundary can cause a large change in its MAT. There has also been great difficulty in using the MAT to decompose an object into a hierarchy of parts reflecting the natural parts-hierarchy that we perceive. This paper argues that the underlying cause of these problems is that medial representations embody both the substance of each part of an object and the connections between adjacent parts. A small change in an object's boundary corresponds to a small change in its substance but may involve a large change in its connection information. The problems with Blum's MAT are generated because it does not explicitly represent this dichotomy of information. To use the Blum MAT to it's full potential, this paper presents a method for separating the substance and connection information of an object. This provides a natural parts-hierarchy while eliminating instabilities due to small boundary changes. The method also allows for graded, fuzzy classifications of object parts to match the ambiguity in human perception of many objects.	Univ N Carolina, Chapel Hill, NC 27515 USA	University of North Carolina; University of North Carolina Chapel Hill	Katz, RA (corresponding author), Univ N Carolina, Chapel Hill, NC 27515 USA.							August J., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P42, DOI 10.1109/CVPR.1999.784606; BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0; Blum H., 1967, MODELS PERCEPTION SP, P362, DOI DOI 10.1142/S0218654308001154; BRADY M, 1984, INT J ROBOT RES, V3, P36, DOI 10.1177/027836498400300302; BRUCE JW, 1985, P ROY SOC EDINB A, V101, P163, DOI 10.1017/S0308210500026263; Burbeck CA, 1996, VISION RES, V36, P361, DOI 10.1016/0042-6989(95)00106-9; KATZ R, 2002, THESIS U N CAROLINA; KOVACS I, 1994, NATURE, V370, P644, DOI 10.1038/370644a0; MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020; Ogniewicz R., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P63, DOI 10.1109/CVPR.1992.223226; ORBAN GA, 1979, J NEUROPHYSIOL, V42, P818, DOI 10.1152/jn.1979.42.3.818; ORBAN GA, 1979, J NEUROPHYSIOL, V42, P833, DOI 10.1152/jn.1979.42.3.833; PIZER S, 1998, COMPUTER VISION IMAG, V69, P53; PIZER SM, 1987, IEEE T PATTERN ANAL, V9, P505, DOI 10.1109/TPAMI.1987.4767938; Shaked D, 1998, COMPUT VIS IMAGE UND, V69, P156, DOI 10.1006/cviu.1997.0598; SZEKELY G, 1996, THESIS I KOMMUNIKATI	16	43	43	0	3	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	NOV-DEC	2003	55	2-3					139	153		10.1023/A:1026183017197	http://dx.doi.org/10.1023/A:1026183017197			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	732YN					2022-12-18	WOS:000185973300005
J	Neumann, J; Aloimonos, Y				Neumann, J; Aloimonos, Y			Spatio-temporal stereo using multi-resolution subdivision surfaces	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						multi-view stereo; 3D motion flow; motion estimation; subdivision surfaces; spatio-temporal image analysis		We present a method to automatically extract spatio-temporal descriptions of moving objects from synchronized and calibrated multi-view sequences. The object is modeled by a time-varying multi-resolution subdivision surface that is fitted to the image data using spatio-temporal multi-view stereo information, as well as contour constraints. The stereo data is utilized by computing the normalized correlation between corresponding spatio-temporal image trajectories of surface patches, while the contour information is determined using incremental segmentation of the viewing volume into object and background. We globally optimize the shape of the spatio-temporal surface in a coarse-to-fine manner using the multi-resolution structure of the subdivision mesh. The method presented incorporates the available image information in a unified framework and automatically reconstructs accurate spatio-temporal representations of complex non-rigidly moving objects.	Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA	University System of Maryland; University of Maryland College Park	Neumann, J (corresponding author), Univ Maryland, Ctr Automat Res, College Pk, MD 20742 USA.	jneumann@cfar.umd.edu; yiannis@cfar.umd.edu	Aloimonos, Yiannis/AAI-2969-2020	Aloimonos, Yiannis/0000-0002-8152-4281				BONET JSD, 1990, P ICCV SEPT; CARCERONI RL, 2001, P INT C COMP VIS JUN; Essa IA, 1997, IEEE T PATTERN ANAL, V19, P757, DOI 10.1109/34.598232; FAUGERAS O, 1998, P 5 EUR C COMP VIS, P379; Fua P, 2000, INT J COMPUT VISION, V38, P153, DOI 10.1023/A:1008105802790; Hoppe H., 1994, P SIGGRAPH 94, P295, DOI DOI 10.1145/192161.192233; Horn B., 1986, ROBOT VISION, P1; HUBELI A, 2000, 335 ETH ZUR I SCI CO; Kakadiaris IA, 1998, INT J COMPUT VISION, V30, P191, DOI 10.1023/A:1008071332753; KOBBELT L, 2000, EUR 2000 P; Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; Loop C., 1987, SMOOTH SUBDIVISION S; Malassiotis S, 1997, COMPUT VIS IMAGE UND, V65, P79, DOI 10.1006/cviu.1996.0481; MANDAL C, 1999, P ACM SIGGRAPH; Matusik Wojciech, 2000, P ACM SIGGRAPH; Plankers R, 2001, COMPUT VIS IMAGE UND, V81, P285, DOI 10.1006/cviu.2000.0891; SCHRODER P, 2000, SUBDIVISION MODELING; SEITZ S, 1999, INT J COMPUTER V NOV, P25; SPIES H, 2000, P EUR C COMP VIS DUB; STAM J, 1999, EVALUATION LOOP SUBD; TAUBIN G, 1995, P ACM SIGGRAPH; VEDULA S, 1998, P INT C VIRT SYST MU; Vedula S., 2000, P IEEE C COMP VIS PA; VEDULA S, 1999, P INT C COMP VIS COR; Zhang Y, 2000, PROC CVPR IEEE, P674, DOI 10.1109/CVPR.2000.854939; ZORIN D, 1997, P ACM SIGGRAPH	28	43	44	1	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR-JUN	2002	47	1-3					181	193		10.1023/A:1014597925429	http://dx.doi.org/10.1023/A:1014597925429			13	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	530JN					2022-12-18	WOS:000174354700014
J	Fermuller, C; Aloimonos, Y				Fermuller, C; Aloimonos, Y			Observability of 3D motion	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						3D motion estimation; error analysis; epipolar constraint; positive depth constraint	RECOVERING 3-D MOTION; NOISY FLOW FIELD; OPTICAL-FLOW; 3-DIMENSIONAL MOTION; INHERENT AMBIGUITIES; IMAGE; PERCEPTION; EGOMOTION; ALGORITHM; OBJECTS	This paper examines the inherent difficulties in observing 3D rigid motion from image sequences. It does so without considering a particular estimator. Instead, it presents a statistical analysis of all the possible computational models which can be used for estimating 3D motion from an image sequence. These computational models are classified according to the mathematical constraints that they employ and the characteristics of the imaging sensor (restricted field of view and full field of view). Regarding the mathematical constraints, there exist two principles relating a sequence of images taken by a moving camera. One is the "epipolar constraint," applied to motion fields, and the other the "positive depth" constraint, applied to normal flow fields. 3D motion estimation amounts to optimizing these constraints over the image. A statistical modeling of these constraints leads to functions which are studied with regard to their topographic structure, specifically as regards the errors in the 3D motion parameters at the places representing the minima of the functions. For conventional video cameras possessing a restricted field of view, the analysis shows that for algorithms in both classes which estimate all motion parameters simultaneously, the obtained solution has an error such that the projections of the translational and rotational errors on the image plane are perpendicular to each other. Furthermore, the estimated projection of the translation on the image lies on a line through the origin and the projection of the real translation. The situation is different for a camera with a full (360 degree) field of view (achieved by a panoramic sensor or by a system of conventional cameras). In this case, at the locations of the minima of the above two functions, either the translational or the rotational error becomes zero, while in the case of a restricted held of view both errors are non-zero. Although some ambiguities still remain in the full field of view case, the implication is that visual navigation tasks, such as visual servoing, involving 3D motion estimation are easier to solve by employing panoramic vision. Also, the analysis makes it possible to compare properties of algorithms that first estimate the translation and on the basis of the translational result estimate the rotation, algorithms that do the opposite, and algorithms that estimate all motion parameters simultaneously, thus providing a sound framework for the observability of 3D motion. Finally, the introduced framework points to new avenues for studying the stability of image-based servoing schemes.	Univ Maryland, Inst Adv Comp Studies, Ctr Automat Res, Comp Vis Lab, College Pk, MD 20742 USA; Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA	University System of Maryland; University of Maryland College Park; University System of Maryland; University of Maryland College Park	Fermuller, C (corresponding author), Univ Maryland, Inst Adv Comp Studies, Ctr Automat Res, Comp Vis Lab, College Pk, MD 20742 USA.		Aloimonos, Yiannis/AAI-2969-2020	Aloimonos, Yiannis/0000-0002-8152-4281				ADIV G, 1989, IEEE T PATTERN ANAL, V11, P477, DOI 10.1109/34.24780; ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; ALOIMONOS J, 1988, INT J COMPUT VISION, V2, P171, DOI 10.1007/BF00133699; ALOIMONOS J, 1990, P DARPA IMAGE UNDERS, P816; BAJCSY R, 1988, P IEEE, V76, P996, DOI 10.1109/5.5968; BALLARD DH, 1992, CVGIP-IMAG UNDERSTAN, V56, P3, DOI 10.1016/1049-9660(92)90081-D; BALLARD DH, 1983, COMPUT VISION GRAPH, V22, P95, DOI 10.1016/0734-189X(83)90097-X; BANDOPADHAY A, 1986, THESIS U ROCHESTER; BURGER W, 1990, IEEE T PATTERN ANAL, V12, P1040, DOI 10.1109/34.61704; CHAUMETTE F, 1998, LNCIS SERIES, V237, P66, DOI DOI 10.1007/BFB0109663; DANIILIDIS K, 1990, IMAGE VISION COMPUT, V8, P297, DOI 10.1016/0262-8856(90)80006-F; DANIILIDIS K, 1997, VISUAL NAVIGATION BI, pCH4; DANIILIDIS K, 1992, THESIS U KARLSRUHE G; DEAN TL, 1991, PLANNING CONTROL; Dutta R., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P106, DOI 10.1109/ICCV.1990.139504; ESPIAU B, 1992, IEEE T ROBOTIC AUTOM, V8, P313, DOI 10.1109/70.143350; Faugeras O. D., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P25; FEDDEMA J, 1989, IEEE INT C ROB AUT I, V2, P832; FEDDEMA JT, 1993, VISUAL SERVOING, P105; FERMULLER C, 1995, INT J COMPUT VISION, V15, P7, DOI 10.1007/BF01450848; FERMULLER C, 1995, SCIENCE, V270, P1973, DOI 10.1126/science.270.5244.1973; HAGER GD, 1994, P IEEE RSJ GI INT C, V1, P164; HEEGER DJ, 1992, INT J COMPUT VISION, V7, P95, DOI 10.1007/BF00128130; Horaud R, 1998, IEEE T ROBOTIC AUTOM, V14, P525, DOI 10.1109/70.704214; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1988, INT J COMPUT VISION, V2, P51, DOI 10.1007/BF00836281; HORN BKP, 1990, INT J COMPUT VISION, V4, P59, DOI 10.1007/BF00137443; Hutchinson S, 1996, IEEE T ROBOTIC AUTOM, V12, P651, DOI 10.1109/70.538972; JEPSON AD, 1990, RBCVTR9036 U TOR; KOENDERINK JJ, 1994, PATTERN RECOGN LETT, V15, P439, DOI 10.1016/0167-8655(94)90134-1; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; MAYBANK S, 1993, THEORY RECONSTRUCTIO; MAYBANK SJ, 1986, IMAGE VISION COMPUT, V4, P38, DOI 10.1016/0262-8856(86)90006-5; MAYBANK SJ, 1987, THESIS U LONDON; NELSON BJ, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P829, DOI 10.1109/CVPR.1994.323907; PHILIP J, 1991, IEEE T PATTERN ANAL, V13, P61, DOI 10.1109/34.67631; PRAZDNY K, 1981, COMPUT VISION GRAPH, V17, P238, DOI 10.1016/0146-664X(81)90004-6; PRAZDNY K, 1980, BIOL CYBERN, V36, P87, DOI 10.1007/BF00361077; RIEGER JH, 1985, J OPT SOC AM A, V2, P354, DOI 10.1364/JOSAA.2.000354; SHARMA R, 1995, IEEE INT C ROB  AUT, V1, P172; Spetsakis M. E., 1989, Proceedings. Workshop on Visual Motion (IEEE Cat. No.89CH2716-9), P229, DOI 10.1109/WVM.1989.47114; SPETSAKIS ME, 1988, P 2 INT C COMP VIS, P449; THOMAS JI, 1993, P DARPA IM UND WORKS, P691; YOUNG GSJ, 1992, IEEE T PATTERN ANAL, V14, P995, DOI 10.1109/34.159903; ZHUANG XH, 1986, J OPT SOC AM A, V3, P1492, DOI 10.1364/JOSAA.3.001492	45	43	43	0	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2000	37	1					43	63		10.1023/A:1008177429387	http://dx.doi.org/10.1023/A:1008177429387			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	341FC					2022-12-18	WOS:000088579500004
J	Zhang, W; Bergholm, F				Zhang, W; Bergholm, F			Multi-scale blur estimation and edge type classification for scene analysis	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						signatures; edge classification; blur estimation; edge attribute estimation; edge type; scale space; depth-from-focus; junctions	DEPTH	Signatures, in this work, are multi-scale representations of local gray-level information, tied to places in gray scale images where regional differences are locally maximal. The information may involve the regional differences themselves (called Gaussian differences or signed normalized gradient magnitudes, (Kern, 1988)), or, distance relations between edges (apparent width measurements), or, absence of edges in pulse edge pairs, at coarser scales. Using signatures involves the classical problem mentioned by Marr and others of relating information across scales. A novel result is that a fruitful way of doing this is to build scale paths from coarse-to-fine exploiting edge focusing and associate with pixel positions, along these paths, the three quantities Gaussian differences, apparent width and the binary information absence/presence of edges (in edge-pairs). Such a structure, if used together with proper conditional tests, serves the purpose of classifying edges with respect to profile-type, and can also be used for measuring global contrast, degree of diffuseness, deblurred line width, and qualitative labels such as diffuse versus sharp. The structure is used simultaneously for labelling tasks and quantitative measurements. Theory on apparent widths, absence/presence of edges in pulse edge pairs is developed. For measuring diffuseness and global contrast from Gaussian difference signatures a linear least squares approach is suggested. Extensive experimental results are presented. Possible applications are in image segementation, junction analysis, and depth-from-defocus. For the purpose of distinguishing between objects and illumination phenomena, such as diffuse shadow edges, classification of contours with respect to diffuseness seems useful.	KTH,DEPT NUMER ANAL & COMP SCI,COMPUTAT VIS & ACT PRECEPT LAB,STOCKHOLM,SWEDEN	Royal Institute of Technology								ADJOUADI M, 1985, P 4 SCAND C TRONDH N, P821; BACK S, 1989, 11 DAGM S MUST; BERGHOLM F, 1987, IEEE T PATTERN ANAL, V9, P726, DOI 10.1109/TPAMI.1987.4767980; BERGHOLM F, 10262 FRAUNH I INF D; BERGHOLM F, 1991, TRITANAP9105 ROYAL I; CANNY J, 1986, IEEE T PAMI, V8; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; GROSSMANN P, 1987, PATTERN RECOGN LETT, V5, P63, DOI 10.1016/0167-8655(87)90026-2; GULCH E, 1990, REPORT OEEPE TEST FE; KISWORO M, 1994, IEEE T PATTERN ANAL, V16, P405, DOI 10.1109/34.277593; Kmenta J., 1971, ELEMENTS ECONOMETRIC, V2nd; KRON AF, 1988, IEEE T PAMI, V10, P610; LAI SH, 1992, IEEE T PATTERN ANAL, V14, P405, DOI 10.1109/34.126803; Lindeberg T., 1994, SCALE SPACE THEORY C; LU Y, 1992, IEEE T PATTERN ANAL, V14, P450, DOI 10.1109/34.126806; MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909; MALLAT S, 1992, IEEE T INFORM THEORY, V38, P617, DOI 10.1109/18.119727; MARR DG, 1976, PHILOS T ROY SOC LON, V275, P97; PAHLAVAN K, CVGIP-IMAG UNDERSTAN, V56, P41; PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940; Perona P., 1990, P 3 ICCV OS JAP; RAMAN SV, 1993, CVGIP-IMAG UNDERSTAN, V57, P81, DOI 10.1006/ciun.1993.1005; ROHR K, 1992, INT J COMPUT VISION, V9, P213, DOI 10.1007/BF00133702; ROHR K, 1992, IMAGE VISION COMPUT, V10, P66, DOI 10.1016/0262-8856(92)90001-J; ROHR K, 1990, 12 DAGM S MUST; SJOBERG F, 1988, PATTERN RECOGN LETT, V7, P181, DOI 10.1016/0167-8655(88)90063-3; Watt R. J., 1988, VISUAL PROCESSING CO; WATT RJ, 1985, VISION RES, V25, P1661, DOI 10.1016/0042-6989(85)90138-5; WILLIAMS DJ, 1990, COMPUT VISION GRAPH, V51, P256, DOI 10.1016/0734-189X(90)90003-E; WILLIAMS DJ, 1993, CVGIP-GRAPH MODEL IM, V55, P311, DOI 10.1006/cgip.1993.1021; WILLIAMS DJ, 1990, 10TH P INT C PATT RE, P942; WITKIN AP, 1982, P AAAI 82, P36; WITKIN AP, 1982, P IJCAI, P1019; ZHANG W, 1991, P SCIA 91, P435; ZHANG W, 1993, P 4 INT C COMP VIS B, P183; ZHANG W, 1995, TRITANAP9518 NADA KT; ZHANG W, 1993, TRITANAP9330 NADA RO	38	43	44	0	1	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	SEP-OCT	1997	24	3					219	250		10.1023/A:1007923307644	http://dx.doi.org/10.1023/A:1007923307644			32	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	XY026					2022-12-18	WOS:A1997XY02600002
J	NEGAHDARIPOUR, S; LEE, S				NEGAHDARIPOUR, S; LEE, S			MOTION RECOVERY FROM IMAGE SEQUENCES USING ONLY 1ST ORDER OPTICAL-FLOW INFORMATION	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article								The primary goal in motion vision is to extract information about the motion and shape of an object in a scene that is encoded in the optic flow. While many solutions to this problem, both iterative and in closed form, have been proposed, practitioners still view the problem as unsolved, since these methods, for the most part, cannot deal with some important aspects of realistic scenes. Among these are comlex unsegmented scenes, nonsmooth objects, and general motion of the camera. In addition, the performance of many methods degrades ungracefully as the quality of the data deteriorates. Here, we will derive a closed-form solution for motion estimation based on the first-order information from two image regions with distinct flow "structures." A unique solution is guaranteed when these corespond to two surface patches with different normal vectors. Given an image sequence, we will show how the image may be segmented into regions with the necessary properties, optical flow is computed for these regions, and motion parameters are calculated. The method can be applied to arbitrary scenes and any camera motion. We will show theoretically why the method is more robust than other proposed techniques that require the knowledge of the full flow or information up to the second-order terms of it. Experimental results are presented to support the theoretical derivations.	UNIV MIAMI,DEPT ELECT & COMP ENGN,CORAL GABLES,FL 33124; UNIV WASHINGTON,DEPT ELECT ENGN,SEATTLE,WA 98195	University of Miami; University of Washington; University of Washington Seattle								ADIV G, 1985, IEEE T PATT ANAL MAC, V7; ADIV G, 1985, JUN P C COMP VIS PAT; ALOIMONOS J, 1984, 2ND P WORKSH COMP VI; ALOIMONOS J, 1986, JUN P C COMP VIS PAT; [Anonymous], 1974, CLUSTER ANAL; BALLARD DH, 1983, COMPUT VIS GRAPH IMA, V22; BHARWANI S, 1986, P IEEE WORKHSOP MOTI; BOLLES RC, 1987, INT J COMPUT VIS, V1; BROIDA TJ, 1986, IEEE T PATT ANAL MAC, V8; BRUSS AR, 1983, COMP VIS GRAPH IMAGE, V21; BUXTON BF, 1984, 6TH P EUR C ART INT; DICKMANNS ED, 1989, 2ND P INT C INT AUT; HAY JC, 1966, PSYCHOL REV, V73; HEEGER DJ, 1990, 3RD P INT C COMP VIS; HEEL J, 1990, P SPIE S ELECTRON IM; Horn B, 1981, ARTIFICIAL INTELLIGE, V17; HORN BKP, 1987, INT J COMPUT VIS, V1; JAIN R, 1983, IEEE T PATT ANAL MAC, V5; JERIAN C, 1984, IEEE T PATT ANAL MAC, V6; KANATANI K, 1985, COMPUT VIS GRAPH IMA, V29; LAWTON D, 1983, COMPUT VIS GRAPHICS, V22; LEGUILLOUX Y, 1986, JUN P C COMP VIS PAT; LONGUETHIGGINS HC, 1984, P ROY SOC LONDON B, V223; LONGUETHIGGINS HC, 1990, P ROY SOC LONDON B, V208; MATTHIES L, 1989, INT J COMPUT VIS, V3; NEGAHDARIPOUR S, 1992, UNPUB ERROR ANAL STR; NEGAHDARIPOUR S, 1988, JUN P C COMP VIS PAT; NEGAHDARIPOUR S, 1987, IEEE T PATT ANAL MAC, V9; NEGAHDARIPOUR S, 1986, THESIS MIT CAMBRIDGE; NEGAHDARIPOUR S, 1989, COMPUT VIIS GRAPH IM, V46; PRAZDNY K, 1979, 6TH P INT JOINT C AR; SETHI IK, 1984, CRLTR1084 U MICH; SHARIAT H, 1986, P WORKSHOP MOTION RE; SUBBARAO M, 1987, 1ST P INT C COMP VIS; SUBBARAO M, 1985, 3RD P IEEE WORKSH CO; SUBBARAO M, 1990, COMPUT VIS GRAPH IMA, V50; TOMASI C, 1990, 3RD P INT C COMP VIS; TSAI RY, 1984, IEEE T PATT ANAL MAC, V6; TSAI RY, 1982, IEEE T ACOUSTICS SPE, V30; ULLMAN S, 1983, MIT706 AI LAB MEM; WAXMAN AM, 1985, INT J ROBOT RES, V4; WAXMAN AM, 1987, INT J COMPUT VIS, V1; WEBB JA, 1981, COMPUTER         AUG; WOHN K, 1986, AUG P AAAI 86 C	44	43	44	0	0	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	1992	9	3					163	184		10.1007/BF00133700	http://dx.doi.org/10.1007/BF00133700			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	KC414					2022-12-18	WOS:A1992KC41400001
J	DEWEERTH, SP				DEWEERTH, SP			ANALOG VLSI CIRCUITS FOR STIMULUS LOCALIZATION AND CENTROID COMPUTATION	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							ORIENTATION	An analog aggregation network that extracts the position of a stimulus in a sensory field is presented. This network is integrated with photodiodes in a VLSI circuit that performs stimulus localization through the computation of the centroid of a visual image. In this implementation, bipolar transistors and global subtraction are used to produce a high-precision centroid implementation. Theory for the localization of a bright visual stimulus is developed, and the theoretical predictions are compared to experimental data taken from the 160X160-pixel centroid circuit. Finally, the applications of these circuits to more complex feature extraction and to sensorimotor feedback systems are discussed.	CALTECH, PHYS COMPUTAT LAB, PASADENA, CA 91125 USA	California Institute of Technology								DeWeerth S. P., 1988, Advanced Research in VLSI. Proceedings of the Fifth MIT Conference, P259; DEWEERTH SP, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P1336, DOI 10.1109/ROBOT.1991.131798; DEWEERTH SP, 1991, THESIS CALTECH PASAD; Lazzaro J., 1988, ADV NEURAL INFORMATI, V1, P703; MAHER MAC, 1989, IEEE T CIRCUITS SYST, V36, P643, DOI 10.1109/31.31311; Mead, 1989, ANALOG VLSI NEURAL S; Mead C., 1985, 1985 Chapel Hill Conference on Very Large Scale Integration, P463; MEAD CA, 1988, NEURAL NETWORKS, V1, P91, DOI 10.1016/0893-6080(88)90024-X; NOORLAG DJW, 1982, IEEE T ELECTRON DEV, V29, P158, DOI 10.1109/T-ED.1982.20675; PETERSSON GP, 1978, IEEE J SOLID-ST CIRC, V13, P392, DOI 10.1109/JSSC.1978.1051063; POGGIO T, 1976, Quarterly Reviews of Biophysics, V9, P377; REICHARDT W, 1976, Q REV BIOPHYS, V9, P311, DOI 10.1017/S0033583500002523; SIVILOTTI MA, 1987 P STANF VLSI C, P295; SPARKS D, 1983, P C VIS BRAIN COOPER; STANDLEY DL, 1991, IEEE J SOLID-ST CIRC, V26, P1853, DOI 10.1109/4.104177; Tanner J. E., 1986, THESIS CALTECH PASAD; VITTOZ EA, 1985, DESIGN MOS VLSI CIRC, P104; WYATT JL, 1992, 1992 P IEEE INT S CI	18	43	43	0	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	1992	8	3					191	202		10.1007/BF00055151	http://dx.doi.org/10.1007/BF00055151			12	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	JU903					2022-12-18	WOS:A1992JU90300003
J	OLSON, TJ; COOMBS, DJ				OLSON, TJ; COOMBS, DJ			REAL-TIME VERGENCE CONTROL FOR BINOCULAR ROBOTS	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							STEREO	In binocular systems, vergence is the process of adjusting the angle between the eyes (or cameras) so that both eyes are directed at the same world point. Its utility is most obvious for foveate systems such as the human visual system, but it is a useful strategy for nonfoveate binocular robots as well. Here, we discuss the vergence problem and outline a general approach to vergence control, consisting of a control loop driven by an algorithm that estimates the vergence error. As a case study, this approach is used to verge the eyes of the Rochester Robot in real time. Vergence error is estimated with the cepstral disparity filter. The cepstral filter is analyzed, and it is shown in this application to be equivalent to correlation with an adaptive prefilter; carrying this idea to its logical conclusion converts the cepstral filter into phase correlation. The demonstration system uses a PD controller in cascade with the error estimator. An efficient real-time implementation of the error estimator is discussed, and empirical measures of the performance of both the disparity estimator and the overall system are presented.	UNIV VIRGINIA,DEPT COMP SCI,CHARLOTTESVILLE,VA 22903; UNIV ROCHESTER,DEPT COMP SCI,ROCHESTER,NY 14627	University of Virginia; University of Rochester								ABBOTT AL, 1988, 2ND P INT C COMP VIS; Aloimonos J., 1987, International Journal of Computer Vision, V1, P333, DOI 10.1007/BF00133571; BAJCSY R, 1986, 4TH P IEEE WORKSH CO; BALLARD DH, 1989, 11TH P INT JOINT C A; BALLARD DH, 1988, 2ND P INT C COMP VIS; BANDYOPADHAY A, 1986, THESIS U ROCHESTER; BANDYOPADHAY A, TR221 COMP SCI DEP; Bar-Shalom Y., 1988, TRACKING DATA ASS; BARNARD ST, 1982, ACM COMPUT SURV, V14, P553, DOI DOI 10.1145/356893.356896; Bogert B.P., 1963, P S TIM SER AN, V15, P209; BROOKS RA, 1986, IEEE T ROBOTIC AUTOM, V2, P14, DOI 10.1109/JRA.1986.1087032; BROOKS RA, 1987, P WORKSHOP F ARTIFIC, P1; BROWN C, 1990, IMAGE VISION COMPUT, V8, P10, DOI 10.1016/0262-8856(90)90050-F; BROWN CM, 1990, BIOL CYBERNETICS, V63; BROWN CM, 1988, 257 U ROCH COMP SCI; BROWN CM, 1990, IEEE T SYST MAN CYBE; CLARK J, 1988, 2ND P INT C COMP VIS; COOMBS DJ, 1989, P TOPICAL M IMAGE UN; COOMBS DJ, 1990, 5TH P IEEE INT S INT; COOMBS DJ, 1991, IEEE CONT SYST M JUN; DORF RC, 1980, MODERN CONTROL SYSTE; ERKELENS C, 1989, P ROY SOC LONDON; ERKELENS CJ, 1984, J PHYSL, V379, P145; FLEET DJ, 1989, TR8929 U TOR DEP COM; GEIGER D, 1987, 1ST P INT C COMP VIS, P306; Horn B., 1986, ROBOT VISION, P1; HOWARD I, 1989, EXPT BRAIN RES; Jepson A. D., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P398, DOI 10.1109/CVPR.1989.37877; Krotkov EP, 1989, ACTIVE COMPUTER VISI; Kuglin C. D., 1975, Proceedings of the 1975 International Conference on Cybernetics and Society, P163; MAXWELL JS, 1990, ABST SOC NEUR; MILES FA, 1990, HEAD NECK SENSORY MO; NISHIHARA HK, 1984, OPT ENG, V23, P536, DOI 10.1117/12.7973334; OLSON TJ, 1991, IN PRESS OCT P IEEE; OLSON TJ, 1989, CVPR 89, P404; PAIGE G D, 1990, Investigative Ophthalmology and Visual Science, V31, P121; PAIGE GD, 1990, ANN ARVO M; Pearson J. J., 1977, Proceedings of the Society of Photo-Optical Instrumentation Engineers, vol.119. Applications of Digital Image Processing, P197; RIMEY RD, 1990, SEP P DARPA IM UND W; ROBINSON DA, 1987, VISION BRAIN COOPERA; ROJER AS, 1990, JUN P INT C PATT REC; SNYDER L H, 1990, Investigative Ophthalmology and Visual Science, V31, P121; TILLEY DG, 1990, 315 U ROCH COMP SCI; TISTARELLI M, 1990, P EUROP C COMPUT VIS; TSOTSOS JK, 1988, INT J COMPUT VISION, V1; VANDERSPIEGEL J, 1989, ANALOG VLSI IMPLEMEN; Yarbus A. L., 1967, EYE MOVEMENTS VISION, P171; YESHURUN Y, 1989, IEEE T PATT ANAL MAC, V11; 1987, DSP PRODUCT DATABOOK	50	43	44	0	2	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	1991	7	1					67	89		10.1007/BF00130490	http://dx.doi.org/10.1007/BF00130490			23	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	GY893		Green Submitted			2022-12-18	WOS:A1991GY89300005
J	Yu, HY; Li, GR; Zhang, WG; Huang, QM; Du, DW; Tian, Q; Sebe, NC				Yu, Hongyang; Li, Guorong; Zhang, Weigang; Huang, Qingming; Du, Dawei; Tian, Qi; Sebe, Nicu			The Unmanned Aerial Vehicle Benchmark: Object Detection, Tracking and Baseline	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						UAV; Object detection; Single object tracking; Multiple object tracking	MULTITARGET	With the increasing popularity of Unmanned Aerial Vehicles (UAVs) in computer vision-related applications, intelligent UAV video analysis has recently attracted the attention of an increasing number of researchers. To facilitate research in the UAV field, this paper presents a UAV dataset with 100 videos featuring approximately 2700 vehicles recorded under unconstrained conditions and 840k manually annotated bounding boxes. These UAV videos were recorded in complex real-world scenarios and pose significant new challenges, such as complex scenes, high density, small objects, and large camera motion, to the existing object detection and tracking methods. These challenges have encouraged us to define a benchmark for three fundamental computer vision tasks, namely, object detection, single object tracking (SOT) and multiple object tracking (MOT), on our UAV dataset. Specifically, our UAV benchmark facilitates evaluation and detailed analysis of state-of-the-art detection and tracking methods on the proposed UAV dataset. Furthermore, we propose a novel approach based on the so-called Context-aware Multi-task Siamese Network (CMSN) model that explores new cues in UAV videos by judging the consistency degree between objects and contexts and that can be used for SOT and MOT. The experimental results demonstrate that our model could make tracking results more robust in both SOT and MOT, showing that the current tracking and detection methods have limitations in dealing with the proposed UAV benchmark and that further research is indeed needed.	[Yu, Hongyang; Huang, Qingming] Harbin Inst Technol, Harbin, Heilongjiang, Peoples R China; [Li, Guorong; Huang, Qingming; Du, Dawei] Univ Chinese Acad Sci, Beijing, Peoples R China; [Zhang, Weigang] Harbin Inst Technol, Weihai, Peoples R China; [Tian, Qi] Univ Texas San Antonio, San Antonio, TX USA; [Sebe, Nicu] Univ Trento, Trento, Italy; [Huang, Qingming] Chinese Acad Sci, Key Lab Big Data Min & Knowledge Management, Beijing, Peoples R China; [Huang, Qingming] Chinese Acad Sci, Inst Comp, Key Lab Intelligent Informat Proc IIP, Beijing, Peoples R China	Harbin Institute of Technology; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Harbin Institute of Technology; University of Texas System; University of Texas at San Antonio (UTSA); University of Trento; Chinese Academy of Sciences; Chinese Academy of Sciences	Huang, QM (corresponding author), Harbin Inst Technol, Harbin, Heilongjiang, Peoples R China.; Li, GR; Huang, QM (corresponding author), Univ Chinese Acad Sci, Beijing, Peoples R China.; Huang, QM (corresponding author), Chinese Acad Sci, Key Lab Big Data Min & Knowledge Management, Beijing, Peoples R China.; Huang, QM (corresponding author), Chinese Acad Sci, Inst Comp, Key Lab Intelligent Informat Proc IIP, Beijing, Peoples R China.	liguorong@ucas.ac.cn; qmhuang@ucas.ac.cn	Zhang, Weigang/GZA-9095-2022	Zhang, Weigang/0000-0003-0042-7074; Sebe, Niculae/0000-0002-6597-7248	National Natural Science Foundation of China [61620106009, 61836002, U1636214, 61931008, 61772494, 61976069]; CAS [QYZDJ-SSW-SYS013]; Italy-China collaboration project TALENT [2018YFE0118400]; University of Chinese Academy of Sciences; Youth Innovation Promotion Association CAS; ARO [W911NF-15-1-0290]; NEC Laboratory of America; NEC Laboratory of Blippar	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); CAS(Chinese Academy of Sciences); Italy-China collaboration project TALENT; University of Chinese Academy of Sciences(Chinese Academy of Sciences); Youth Innovation Promotion Association CAS; ARO; NEC Laboratory of America; NEC Laboratory of Blippar	This work was supported in part by National Natural Science Foundation of China under Grant 61620106009, Grant 61836002, Grant U1636214, Grant 61931008, Grant 61772494 and Grant 61976069, in part by Key Research Program of Frontier Sciences, CAS: QYZDJ-SSW-SYS013, in part by the Italy-China collaboration project TALENT: 2018YFE0118400, in part by the University of Chinese Academy of Sciences, in part by Youth Innovation Promotion Association CAS, in part by ARO grants W911NF-15-1-0290 and Faculty Research Gift Awards by NEC Laboratories of America and Blippar.	Bae SH, 2014, PROC CVPR IEEE, P1218, DOI 10.1109/CVPR.2014.159; Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309; Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56; Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003; Bochinski E, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS); Choi WG, 2015, IEEE I CONF COMP VIS, P3029, DOI 10.1109/ICCV.2015.347; Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202; Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036; Danelljan M., 2016, ARXIV161109224; Danelljan M, 2016, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2016.159; Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29; Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dicle C, 2013, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2013.286; Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155; Du DW, 2018, LECT NOTES COMPUT SC, V11214, P375, DOI 10.1007/978-3-030-01249-6_23; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Fan HH, 2017, IEEE I CONF COMP VIS, P736, DOI 10.1109/ICCV.2017.86; Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2017.128; Geiger A., 2012, P IEEE COMP SOC C CO; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45; Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390; Hsieh M., 2017, ICCV; Hwang S, 2015, PROC CVPR IEEE, P1037, DOI 10.1109/CVPR.2015.7298706; Izadinia H, 2012, LECT NOTES COMPUT SC, V7577, P100, DOI 10.1007/978-3-642-33783-3_8; Kalra I., 2019, IEEE FG 2019, P1, DOI DOI 10.1109/FG.2019.8756593; Kong T, 2017, PROC CVPR IEEE, P5244, DOI 10.1109/CVPR.2017.557; Kristan M, 2017, IEEE INT CONF COMP V, P1949, DOI 10.1109/ICCVW.2017.230; Kristan M, 2015, LECT NOTES COMPUT SC, V8926, P191, DOI 10.1007/978-3-319-16181-5_14; Leal-Taixe L., 2015, ARXIV; Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515; Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352; Milan A., 2016, MOT16 BENCHMARK MULT; Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103; Muller M, 2018, LECT NOTES COMPUT SC, V11205, P310, DOI 10.1007/978-3-030-01246-5_19; Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152; Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27; MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003; NAM H, 2016, PROC CVPR IEEE, P4293, DOI DOI 10.1109/CVPR.2016.465; Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689; Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2; Robicquet A, 2016, LECT NOTES COMPUT SC, V9912, P549, DOI 10.1007/978-3-319-46484-8_33; Shu G, 2012, PROC CVPR IEEE, P1815, DOI 10.1109/CVPR.2012.6247879; Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230; Solera F, 2015, 2015 12TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS); Son J., 2017, CVPR; Song YB, 2018, PROC CVPR IEEE, P8990, DOI 10.1109/CVPR.2018.00937; Song YB, 2017, IEEE I CONF COMP VIS, P2574, DOI 10.1109/ICCV.2017.279; Tang SY, 2017, PROC CVPR IEEE, P3701, DOI 10.1109/CVPR.2017.394; Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158; Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531; Wang LJ, 2016, PROC CVPR IEEE, P1373, DOI 10.1109/CVPR.2016.153; Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357; Wang N, 2018, PROC CVPR IEEE, P4844, DOI 10.1109/CVPR.2018.00509; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; Wen LY, 2020, COMPUT VIS IMAGE UND, V193, DOI 10.1016/j.cviu.2020.102907; Wojke N, 2017, IEEE IMAGE PROC, P3645; Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226; Xia GS, 2018, PROC CVPR IEEE, P3974, DOI 10.1109/CVPR.2018.00418; Yoon JH, 2016, PROC CVPR IEEE, P1392, DOI 10.1109/CVPR.2016.155; Yoon JH, 2015, IEEE WINT CONF APPL, P33, DOI 10.1109/WACV.2015.12; Yu HY, 2018, NEUROCOMPUTING, V292, P28, DOI 10.1016/j.neucom.2018.02.068; Yun S, 2017, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2017.148; Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9; Zhang TZ, 2017, PROC CVPR IEEE, P4819, DOI 10.1109/CVPR.2017.512; Zhong BN, 2019, IEEE T IMAGE PROCESS, V28, P2331, DOI 10.1109/TIP.2018.2885238; Zhou QQ, 2019, IEEE T MULTIMEDIA, V21, P1183, DOI 10.1109/TMM.2018.2875360; Zhu Pengfei, 2018, ARXIV180407437, P2	78	42	47	22	70	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2020	128	5					1141	1159		10.1007/s11263-019-01266-1	http://dx.doi.org/10.1007/s11263-019-01266-1		DEC 2019	19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	LL3BW					2022-12-18	WOS:000500723700001
J	Liu, ZY; Qiao, H; Yang, X; Hoi, SCH				Liu, Zhi-Yong; Qiao, Hong; Yang, Xu; Hoi, Steven C. H.			Graph Matching by Simplified Convex-Concave Relaxation Procedure	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Graph matching; Combinatorial optimization; Deterministic annealing; Graduated optimization; Feature correspondence		The convex and concave relaxation procedure (CCRP) was recently proposed and exhibited state-of-the-art performance on the graph matching problem. However, CCRP involves explicitly both convex and concave relaxations which typically are difficult to find, and thus greatly limit its practical applications. In this paper we propose a simplified CCRP scheme, which can be proved to realize exactly CCRP, but with a much simpler formulation without needing the concave relaxation in an explicit way, thus significantly simplifying the process of developing CCRP algorithms. The simplified CCRP can be generally applied to any optimizations over the partial permutation matrix, as long as the convex relaxation can be found. Based on two convex relaxations, we obtain two graph matching algorithms defined on adjacency matrix and affinity matrix, respectively. Extensive experimental results witness the simplicity as well as state-of-the-art performance of the two simplified CCRP graph matching algorithms.	[Liu, Zhi-Yong; Qiao, Hong; Yang, Xu] Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Beijing, Peoples R China; [Hoi, Steven C. H.] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore	Chinese Academy of Sciences; Institute of Automation, CAS; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Liu, ZY (corresponding author), Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Beijing, Peoples R China.	zhiyong.liu@ia.ac.cn; hong.qiao@ia.ac.cn; xu.yang@ia.ac.cn; chhoi@ntu.edu.sg	HOI, Steven C. H./A-3736-2011; zhang, liwen/L-7005-2016		National Science Foundation of China (NSFC) [61375005, 61033011, 61210009]; Singapore MOE [RG33/11]	National Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Singapore MOE(Ministry of Education, Singapore)	The authors thank Dr. Feng Zhou at Carnegie Mellon University for some helpful discussions on his factorized graph matching algorithm Zhou and De la Torre (2012). Many thanks also go to the anonymous reviewers and associate editor whose comments and suggestions greatly improved the manuscripts. This work was supported by the National Science Foundation of China (NSFC) (grants 61375005, 61033011, 61210009), and by Singapore MOE tier 1 research grant (RG33/11).	Boyd S., 2004, CONVEX OPTIMIZATION, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441.001, 10.1017/cbo97805118044 41]; Cho M., 2010, COMP VIS ECCV 2010; Cho M., 2013, ICCV 2013 IEEE INT C; Cho M, 2012, PROC CVPR IEEE, P398, DOI 10.1109/CVPR.2012.6247701; Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228; Cour T., 2007, P ADV NEURAL INFORM, P313; Demirci MF, 2006, INT J COMPUT VISION, V69, P203, DOI 10.1007/s11263-006-6993-y; Duchenne O, 2011, IEEE I CONF COMP VIS, P1792, DOI 10.1109/ICCV.2011.6126445; Egozi A, 2013, IEEE T PATTERN ANAL, V35, P18, DOI 10.1109/TPAMI.2012.51; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Frank M., 1956, NAVAL RES LOGISTICS, V3, P95, DOI [DOI 10.1002/NAV.3800030109, 10.1002/nav.3800030109]; GEIGER D, 1991, INT J COMPUT VISION, V6, P227, DOI 10.1007/BF00115697; Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619; Kuhn H.W., 1955, NAV RES LOGIST Q, V2, P83, DOI [10.1002/nav.3800020109, DOI 10.1002/NAV.3800020109]; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; Leordeanu M., 2009, ADV NEURAL INFORM PR; Leordeanu M, 2012, INT J COMPUT VISION, V96, P28, DOI 10.1007/s11263-011-0442-2; Liu CL, 2011, PROC INT CONF DOC, P37, DOI 10.1109/ICDAR.2011.17; Liu Z.Y., 2012, J MACHINE LEARNING R, V25, P237; Liu ZY, 2012, IEEE T PATTERN ANAL, V34, P1451, DOI 10.1109/TPAMI.2012.45; Maciel J, 2003, IEEE T PATTERN ANAL, V25, P187, DOI 10.1109/TPAMI.2003.1177151; Philbin J, 2011, INT J COMPUT VISION, V95, P138, DOI 10.1007/s11263-010-0363-5; Ravikumar P., 2006, INT C MACH LEARN; Rose K, 1998, P IEEE, V86, P2210, DOI 10.1109/5.726788; Suh Y., 2012, COMP VIS ECCV 2012; Tian Y., 2012, COMP VIS ECCV 2012; Torresani L, 2008, LECT NOTES COMPUT SC, V5303, P596, DOI 10.1007/978-3-540-88688-4_44; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; Zaslavskiy M, 2009, IEEE T PATTERN ANAL, V31, P2227, DOI 10.1109/TPAMI.2008.245; Zhou F, 2013, PROC CVPR IEEE, P2922, DOI 10.1109/CVPR.2013.376; Zhou F, 2012, PROC CVPR IEEE, P127, DOI 10.1109/CVPR.2012.6247667	32	42	44	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2014	109	3					169	186		10.1007/s11263-014-0707-7	http://dx.doi.org/10.1007/s11263-014-0707-7			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AN1QL		Green Published			2022-12-18	WOS:000340358600001
J	Schmaltz, C; Peter, P; Mainberger, M; Ebel, F; Weickert, J; Bruhn, A				Schmaltz, Christian; Peter, Pascal; Mainberger, Markus; Ebel, Franziska; Weickert, Joachim; Bruhn, Andres			Understanding, Optimising, and Extending Data Compression with Anisotropic Diffusion	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Image compression; Edge-enhancing anisotropic diffusion (EED); Partial differential equations (PDEs); Subdivision; JPEG 2000; Kanizsa triangle	IMAGE COMPRESSION; SCALE-SPACE; REGULARIZATION; INTERPOLATION; RECONSTRUCTION	GaliA double dagger et al. (Journal of Mathematical Imaging and Vision 31:255-269, 2008) have shown that compression based on edge-enhancing anisotropic diffusion (EED) can outperform the quality of JPEG for medium to high compression ratios when the interpolation points are chosen as vertices of an adaptive triangulation. However, the reasons for the good performance of EED remained unclear, and they could not outperform the more advanced JPEG 2000. The goals of the present paper are threefold: Firstly, we investigate the compression qualities of various partial differential equations. This sheds light on the favourable properties of EED in the context of image compression. Secondly, we demonstrate that it is even possible to beat the quality of JPEG 2000 with EED if one uses specific subdivisions on rectangles and several important optimisations. These amendments include improved entropy coding, brightness and diffusivity optimisation, and interpolation swapping. Thirdly, we demonstrate how to extend our approach to 3-D and shape data. Experiments on classical test images and 3-D medical data illustrate the high potential of our approach.	[Schmaltz, Christian; Peter, Pascal; Mainberger, Markus; Ebel, Franziska; Weickert, Joachim; Bruhn, Andres] Univ Saarland, Fac Math & Comp Sci, D-66041 Saarbrucken, Germany	Saarland University	Schmaltz, C (corresponding author), Univ Saarland, Fac Math & Comp Sci, Campus E1-7, D-66041 Saarbrucken, Germany.	schmaltz@mia.uni-saarland.de		Huth, Franziska/0000-0003-1393-5641				Acar T., 1994, P SPIE VIS COMM IM P, V2308; Alter F, 2005, J MATH IMAGING VIS, V23, P199, DOI 10.1007/s10851-005-6467-9; Aly HA, 2005, IEEE T IMAGE PROCESS, V14, P1647, DOI 10.1109/TIP.2005.851684; [Anonymous], 2007, TECHNICAL REPORT; [Anonymous], 1959, P TECH GROUP AUT AUT; ARONSSON G, 1967, ARK MAT, V6, P551, DOI 10.1007/BF02591928; AURICH V, 1996, MUSTEREKENNUNG, P138; Bae E, 2010, LECT NOTES COMPUT SC, V5862, P1, DOI 10.1007/978-3-642-11620-9_1; Battiato S, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P572, DOI 10.1109/ICIAP.2003.1234111; Belahmidi A, 2004, IEEE IMAGE PROC, P649; Belhachmi Z, 2009, SIAM J APPL MATH, V70, P333, DOI 10.1137/080716396; Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972; Bornemann F, 2007, J MATH IMAGING VIS, V28, P259, DOI 10.1007/s10851-007-0017-6; Borzi A, 2005, INT J COMPUT VISION, V64, P203, DOI 10.1007/s11263-005-1844-9; Bougleux S., 2009, P 10 INT C COMP VIS; Bourdon P, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P729; Bourne R, 2010, FUNDAMENTALS OF DIGITAL IMAGING IN MEDICINE, P1, DOI 10.1007/978-1-84882-087-6; BRUCKSTEIN AM, 1993, CIS9316 COMP SCI DEP; Bruhn A, 2006, COMP IMAG VIS, P283; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; CARLSSON S, 1988, SIGNAL PROCESS, V15, P57, DOI 10.1016/0165-1684(88)90028-X; Caselles V, 1998, IEEE T IMAGE PROCESS, V7, P376, DOI 10.1109/83.661188; CATTE F, 1992, SIAM J NUMER ANAL, V32, P1895; Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P436, DOI 10.1006/jvci.2001.0487; Chan TF, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P391, DOI 10.1109/ICIP.2000.899404; Charbonnier P, 1997, IEEE T IMAGE PROCESS, V6, P298, DOI 10.1109/83.551699; Demaret L, 2006, SIGNAL PROCESS, V86, P1604, DOI 10.1016/j.sigpro.2005.09.003; Desai U. Y., 1996, 1584 MIT ART INT LAB; Dipperstein M., 2009, MICHAEL DIPPERSTEINS; Distasi R, 1997, IEEE T COMMUN, V45, P1095, DOI 10.1109/26.623074; Elder JH, 1999, INT J COMPUT VISION, V34, P97, DOI 10.1023/A:1008183703117; Facciolo G., 2006, P 2006 BRIT MACH VIS, P1049; FORD GE, 1996, P 13 AS C SIGN SYST, V2, P926; Galic I, 2005, LECT NOTES COMPUT SC, V3752, P37; Galic I, 2008, J MATH IMAGING VIS, V31, P255, DOI 10.1007/s10851-008-0087-0; Gourlay A. R., 1970, Journal of the Institute of Mathematics and Its Applications, V6, P375; HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898; HUMMEL R, 1989, IEEE T ACOUST SPEECH, V37, P2111, DOI 10.1109/29.45555; Johansen P., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P215; Kanters F, 2005, LECT NOTES COMPUT SC, V3459, P431; Kopilovic I, 2005, OPT ENG, V44, DOI 10.1117/1.1849242; KUNT M, 1985, P IEEE, V73, P549, DOI 10.1109/PROC.1985.13184; Lillholm M, 2003, INT J COMPUT VISION, V52, P73, DOI 10.1023/A:1022995822531; Liu D, 2007, IEEE T CIRC SYST VID, V17, P1273, DOI 10.1109/TCSVT.2007.903663; Mahoney Matt, 2009, DATA COMPRESSION PRO; MAHONEY MV, 2005, CS200516 FLOR I TECH; Mainberger M, 2012, LECT NOTES COMPUT SC, V6667, P26, DOI 10.1007/978-3-642-24785-9_3; Mainberger M, 2009, LECT NOTES COMPUT SC, V5702, P476, DOI 10.1007/978-3-642-03767-2_58; Malgouyres F, 2001, SIAM J NUMER ANAL, V39, P1, DOI 10.1137/S0036142999362286; MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909; Masnou S, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P259, DOI 10.1109/ICIP.1998.999016; National Electrical Manufacturers Association, 2004, 352004 PS NAT EL MAN; Pennebaker William B, 1992, JPEG STILL IMAGE DAT; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Peter P., 2012, P DAGM OAGM 2012 S P; Rane SD, 2003, IEEE T IMAGE PROCESS, V12, P296, DOI 10.1109/TIP.2002.804264; RISSANEN JJ, 1976, IBM J RES DEV, V20, P198, DOI 10.1147/rd.203.0198; ROTEM D, 1986, IEEE T ACOUST SPEECH, V34, P1269, DOI 10.1109/TASSP.1986.1164922; Roussos A, 2007, LECT NOTES COMPUT SC, V4485, P104; Schmaltz C, 2009, LECT NOTES COMPUT SC, V5748, P452, DOI 10.1007/978-3-642-03798-6_46; Sole A, 2004, IEEE T IMAGE PROCESS, V13, P1245, DOI 10.1109/TIP.2004.832864; STROBACH P, 1991, IEEE T SIGNAL PROCES, V39, P1380, DOI 10.1109/78.136544; SULLIVAN GJ, 1994, IEEE T IMAGE PROCESS, V3, P327, DOI 10.1109/83.287030; Taubman D. S., 2002, JPEG 2000 IMAGE COMP; Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596; Tschumperle D, 2005, IEEE T PATTERN ANAL, V27, P506, DOI 10.1109/TPAMI.2005.87; Tschumperle D, 2006, INT J COMPUT VISION, V68, P65, DOI 10.1007/s11263-006-5631-z; Tsuji H, 2002, IEEE IMAGE PROC, P85; Tsuji H., 2007, Systems and Computers in Japan, V38, P34, DOI 10.1002/scj.20566; Weickert J, 2006, VISUALIZATION AND PROCESSING OF TENSOR FIELDS, P315, DOI 10.1007/3-540-31272-2_19; Weickert J, 1999, J MATH IMAGING VIS, V10, P237, DOI 10.1023/A:1008344623873; Weickert J., 1999, HDB COMPUTER VISION, V2, P423; WEICKERT J, 1996, COMP SUPPL, V11, P221; WEICKERT J, 2002, CONT MATH, V313, P251; WELCH TA, 1984, COMPUTER, V17, P8, DOI 10.1109/MC.1984.1659158; Wu F., 2007, 2007 IEEE INT C IMAG, V2, P369, DOI [10.1109/ICIP.2007.4379169, DOI 10.1109/ICIP.2007.4379169]; Wu YD, 2009, INTERNATIONAL JOINT CONFERENCE ON COMPUTATIONAL SCIENCES AND OPTIMIZATION, VOL 1, PROCEEDINGS, P816, DOI 10.1109/CSO.2009.470; XIE Z, 2007, P SPIE, V6697	78	42	42	0	15	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2014	108	3					222	240		10.1007/s11263-014-0702-z	http://dx.doi.org/10.1007/s11263-014-0702-z			19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AH8NO		Green Submitted			2022-12-18	WOS:000336394900004
J	Bok, Y; Jeong, Y; Choi, DG; Kweon, IS				Bok, Yunsu; Jeong, Yekeun; Choi, Dong-Geol; Kweon, In So			Capturing Village-level Heritages with a Hand-held Camera-Laser Fusion Sensor	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Sensor fusion; Large-scale 3D reconstruction; e-Heritage; Camera-laser calibration; Ego-motion estimation	3D; REGISTRATION	Preserving a heritage as a digital archive is as important as preserving its physical structure. The digital preservation is essential for massive heritages which are often defenceless against various types of destruction and require frequent restorations. However, capturing heritages gets exceedingly harder as their scale grows. In this paper, we present a novel approach to reconstruct a massive-scale structure using a hand-held fusion sensor system. The approach includes new methods on calibration, motion estimation, and accumulated error reduction. The proposed sensor system consists of four cameras and two 2D laser scanners to obtain a wide field-of-view. A new calibration method successfully achieves a much lower reprojection error compared to the previous method. A motion estimation method provides accurate and robust relative poses by fully utilizing plenty observations. At the last stage, the accumulated error reduction removes the drift occurred over tens of thousands frames by adopting weak GPS prior and loop closing. Therefore the system is able to capture and geo-register large heritage architectures of square kilometers size. Furthermore, because no assumption or restriction is made, the user can freely move the system and can control the level of detail of the digital heritage without any effort. To demonstrate the performance, we have captured several important Korean heritages including Gyeongbok-Gung, the royal palace of Korea. The experimental result shows that the estimated route fits Google's satellite image and DGPS data while the detailed appearances of representative constructions are captured and preserved well.	[Bok, Yunsu; Jeong, Yekeun; Choi, Dong-Geol; Kweon, In So] Korea Adv Inst Sci & Technol, Dept Elect Engn, Taejon 305701, South Korea	Korea Advanced Institute of Science & Technology (KAIST)	Bok, Y (corresponding author), Korea Adv Inst Sci & Technol, Dept Elect Engn, Taejon 305701, South Korea.	ysbok@rcv.kaist.ac.kr; ykjeong@rcv.kaist.ac.kr; dgchoi@rcv.kaist.ac.kr; iskweon@ee.kaist.ac.kr	Kweon, In So/C-2023-2011		Global Research Network of National Research Foundation of Korea [D00096(I00363)]	Global Research Network of National Research Foundation of Korea(National Research Foundation of Korea)	This research is supported by the Global Research Network program (No. D00096(I00363)) of National Research Foundation of Korea. The authors would like to thank Joon-Young Lee for his help on system implementation and outdoor experiments.	Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148; Banno A, 2008, INT J COMPUT VISION, V78, P207, DOI 10.1007/s11263-007-0104-6; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bok Y, 2007, IEEE INT CONF ROBOT, P4721, DOI 10.1109/ROBOT.2007.364206; Collins RT, 1996, PROC CVPR IEEE, P358, DOI 10.1109/CVPR.1996.517097; Cornelis N, 2008, INT J COMPUT VISION, V78, P121, DOI 10.1007/s11263-007-0081-9; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Frueh C, 2005, INT J COMPUT VISION, V61, P159, DOI 10.1023/B:VISI.0000043756.03810.dd; HARALICK RM, 1994, INT J COMPUT VISION, V13, P331, DOI 10.1007/BF02028352; Levenberg K., 1944, Q APPL MATH, V2, P164, DOI 10.1090/qam/10666; Nister D, 2004, PROC CVPR IEEE, P560; Pfaff P, 2007, IEEE INT CONF ROBOT, P4807, DOI 10.1109/ROBOT.2007.364220; Pollefeys M, 2008, INT J COMPUT VISION, V78, P143, DOI 10.1007/s11263-007-0086-4; Sharp GC, 2004, IEEE T PATTERN ANAL, V26, P1037, DOI 10.1109/TPAMI.2004.49; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; Zhang Q., 2004, PROC IEEERSJ INT C I, P2301, DOI 10.1109/IROS.2004.1389752; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718	18	42	46	0	22	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2011	94	1					36	53		10.1007/s11263-010-0397-8	http://dx.doi.org/10.1007/s11263-010-0397-8			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	760JM					2022-12-18	WOS:000290320600004
J	Rosman, G; Bronstein, MM; Bronstein, AM; Kimmel, R				Rosman, Guy; Bronstein, Michael M.; Bronstein, Alexander M.; Kimmel, Ron			Nonlinear Dimensionality Reduction by Topologically Constrained Isometric Embedding	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Dimensionality reduction; Isomap; Differential geometry; Machine learning; Image manifolds	CONVERGENCE; INFERENCE; STRESS	Many manifold learning procedures try to embed a given feature data into a flat space of low dimensionality while preserving as much as possible the metric in the natural feature space. The embedding process usually relies on distances between neighboring features, mainly since distances between features that are far apart from each other often provide an unreliable estimation of the true distance on the feature manifold due to its non-convexity. Distortions resulting from using long geodesics indiscriminately lead to a known limitation of the Isomap algorithm when used to map non-convex manifolds. Presented is a framework for nonlinear dimensionality reduction that uses both local and global distances in order to learn the intrinsic geometry of flat manifolds with boundaries. The resulting algorithm filters out potentially problematic distances between distant feature points based on the properties of the geodesics connecting those points and their relative distance to the boundary of the feature manifold, thus avoiding an inherent limitation of the Isomap algorithm. Since the proposed algorithm matches non-local structures, it is robust to strong noise. We show experimental results demonstrating the advantages of the proposed approach over conventional dimensionality reduction techniques, both global and local in nature.	[Rosman, Guy; Bronstein, Michael M.; Bronstein, Alexander M.; Kimmel, Ron] Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Technion Israel Institute of Technology	Rosman, G (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.	rosman@cs.technion.ac.il; mbron@cs.technion.ac.il; bron@cs.technion.ac.il; ron@cs.technion.ac.il	Bronstein, Michael/G-5415-2010	Bronstein, Michael/0000-0002-1262-7252				Aharon M, 2006, INT J COMPUT VISION, V67, P297, DOI 10.1007/s11263-006-5166-3; Belkin M, 2002, ADV NEUR IN, V14, P585; Belton D., 2007, ISPRS IMAGE ENG VISI, V61, P307; Borg I., 1997, MODERN MULTIDIMENSIO; Brand M, 2005, LECT NOTES ARTIF INT, V3720, P47, DOI 10.1007/11564096_10; Brandes U, 2007, LECT NOTES COMPUT SC, V4372, P42; Bronstein AM, 2006, P NATL ACAD SCI USA, V103, P1168, DOI 10.1073/pnas.0508601103; Bronstein AM, 2005, INT J COMPUT VISION, V64, P5, DOI 10.1007/s11263-005-1085-y; Bronstein MM, 2006, NUMER LINEAR ALGEBR, V13, P149, DOI 10.1002/nla.475; CABAY S, 1976, SIAM J NUMER ANAL, V13, P734, DOI 10.1137/0713060; Chalmers M, 1996, IEEE VISUAL, P127, DOI 10.1109/VISUAL.1996.567787; Choi H, 2007, PATTERN RECOGN, V40, P853, DOI 10.1016/j.patcog.2006.04.025; Coifman RR, 2005, P NATL ACAD SCI USA, V102, P7426, DOI 10.1073/pnas.0500334102; Cormen T.H., 1990, INTRO ALGORITHMS 2 V; De Leeuw J, 1977, RECENT DEV STAT, P133; De Silva Vin., 2004, SPARSE MULTIDIMENSIO; De Silva Vin, 2002, NIPS 02 P 15 INT C N, V15, P705, DOI DOI 10.5555/2968618.2968708; DELEEUW J, 1984, PSYCHOMETRIKA, V49, P111, DOI 10.1007/BF02294209; DELEEUW J, 1988, J CLASSIF, V5, P163, DOI 10.1007/BF01897162; Dijkstra EW, 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]; Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100; Duda R.O., 2000, PATTERN CLASSIFICATI; Eddy R., 1979, INFORM LINKAGE APPL, P387; Elad A, 2003, IEEE T PATTERN ANAL, V25, P1285, DOI 10.1109/TPAMI.2003.1233902; Eldar Y, 1997, IEEE T IMAGE PROCESS, V6, P1305, DOI 10.1109/83.623193; Freedman D, 2002, IEEE T PATTERN ANAL, V24, P1349, DOI 10.1109/TPAMI.2002.1039206; GONZALEZ TF, 1985, THEOR COMPUT SCI, V38, P293, DOI 10.1016/0304-3975(85)90224-5; GUTTMAN L, 1968, PSYCHOMETRIKA, V33, P469, DOI 10.1007/BF02290164; Guy G, 1997, IEEE T PATTERN ANAL, V19, P1265, DOI 10.1109/34.632985; Haque A, 2007, J COMPUT PHYS, V226, P1710, DOI 10.1016/j.jcp.2007.06.012; HOCHBAUM DS, 1985, MATH OPER RES, V10, P180, DOI 10.1287/moor.10.2.180; Kearsley AJ, 1998, COMPUTATION STAT, V13, P369; Kimmel R, 1998, P NATL ACAD SCI USA, V95, P8431, DOI 10.1073/pnas.95.15.8431; Mesina M., 1977, Computer Methods in Applied Mechanics and Engineering, V10, P165, DOI 10.1016/0045-7825(77)90004-4; Platt J. C., 2004, MSRTR200426; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; SCHWARTZ EL, 1989, IEEE T PATTERN ANAL, V11, P1005, DOI 10.1109/34.35506; SIDI A, 1991, J COMPUT APPL MATH, V36, P305, DOI 10.1016/0377-0427(91)90013-A; SMITH DA, 1987, SIAM REV, V29, P199, DOI 10.1137/1029042; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tong WS, 2004, IEEE T PATTERN ANAL, V26, P594, DOI 10.1109/TPAMI.2004.1273934; Weinberger KQ, 2004, PROC CVPR IEEE, P988; WEINBERGER KQ, 2005, P 10 INT WORKSH ART; Williams CKI, 2002, MACH LEARN, V46, P11, DOI 10.1023/A:1012485807823; Zigelman G, 2002, IEEE T VIS COMPUT GR, V8, P198, DOI 10.1109/2945.998671; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]	60	42	46	0	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2010	89	1					56	68		10.1007/s11263-010-0322-1	http://dx.doi.org/10.1007/s11263-010-0322-1			13	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	584RF					2022-12-18	WOS:000276769500004
J	Foulonneau, A; Charbonnier, P; Heitz, F				Foulonneau, Alban; Charbonnier, Pierre; Heitz, Fabrice			Multi-Reference Shape Priors for Active Contours	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	9th European Conference on Computer Vision (ECCV 2006)	MAY 07-13, 2006	Graz, AUSTRIA	Adv Comp Vis, Graz Univ Technol, Univ Ljubljana		Active contours; Segmentation; Region-based approach; Legendre moments; Shape constraint; Shape derivative; Multi-reference model; Geometric invariance	IMAGE-ANALYSIS; SEGMENTATION; DRIVEN; MODELS	In this paper, we present a new way of constraining the evolution of an active contour with respect to a set of fixed reference shapes. This approach is based on a description of shapes by the Legendre moments computed from their characteristic function. This provides a region-based representation that can handle arbitrary shape topologies. Moreover, exploiting the properties of moments, it is possible to include intrinsic affine invariance in the descriptor, which solves the issue of shape alignment without increasing the number of d.o.f. of the initial problem and allows introducing geometric shape variabilities. Our new shape prior is based on a distance, in terms of descriptors, between the evolving curve and the reference shapes. Minimizing the corresponding shape energy leads to a geometric flow that does not rely on any particular representation of the contour and can be implemented with any contour evolution algorithm. We introduce our prior into a two-class segmentation functional, showing its benefits on segmentation results in presence of severe occlusions and clutter. Examples illustrate the ability of the model to deal with large affine deformation and to take into account a set of reference shapes of different topologies.	[Foulonneau, Alban; Charbonnier, Pierre] Lab Ponts & Chaussees, ERA LCPC 27, F-67035 Strasbourg, France; [Heitz, Fabrice] Univ Strasbourg 1, CNRS, Lab Sci Image Informat & Teledetect, UMR 7005, F-67400 Illkirch Graffenstaden, France	Centre National de la Recherche Scientifique (CNRS); UDICE-French Research Universities; Universites de Strasbourg Etablissements Associes; Universite de Strasbourg	Foulonneau, A (corresponding author), Lab Ponts & Chaussees, ERA LCPC 27, 11 Rue Jean Mentelin,BP 9, F-67035 Strasbourg, France.	Alban.Foulonneau@uha.fr; Pierre.Charbonnier@equipement.gouv.fr; heitz@lsiit.u-strasbg.fr	HEITZ, Fabrice/R-4100-2017; Charbonnier, Pierre/H-4037-2016	HEITZ, Fabrice/0000-0002-3004-0957; Charbonnier, Pierre/0000-0002-9374-5647				Aubert G, 2003, SIAM J APPL MATH, V63, P2128, DOI 10.1137/S0036139902408928; Bresson X, 2006, INT J COMPUT VISION, V68, P145, DOI 10.1007/s11263-006-6658-x; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Chen YM, 2002, INT J COMPUT VISION, V50, P315, DOI 10.1023/A:1020878408985; Cremers D, 2006, INT J COMPUT VISION, V66, P67, DOI 10.1007/s11263-005-3676-z; Cremers D, 2003, PATTERN RECOGN, V36, P1929, DOI 10.1016/S0031-3203(03)00056-6; Cremers D, 2002, INT J COMPUT VISION, V50, P295, DOI 10.1023/A:1020826424915; Cremers D, 2006, INT J COMPUT VISION, V69, P335, DOI 10.1007/s11263-006-7533-5; Foulonneau A, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P413; FOULONNEAU A, 2008, RRAF0108; FOULONNEAU A, 2004, THESIS U L PASTEUR S; Foulonneau A, 2006, IEEE T PATTERN ANAL, V28, P1352, DOI 10.1109/TPAMI.2006.154; Foulonneau A, 2006, LECT NOTES COMPUT SC, V3952, P601; GASTAUD M, 2003, RR200307FRI3S; Leventon ME, 2000, PROC CVPR IEEE, P316, DOI 10.1109/CVPR.2000.855835; Liao SX, 1996, IEEE T PATTERN ANAL, V18, P254, DOI 10.1109/34.485554; Mansouri AR, 2004, IEEE T IMAGE PROCESS, V13, P853, DOI 10.1109/TIP.2004.826128; Mukundan R., 1998, MOMENTS FUNCTIONS IM; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; PEI SC, 1995, IMAGE VISION COMPUT, V13, P711, DOI 10.1016/0262-8856(95)98753-G; Precioso F, 2002, EURASIP J APPL SIG P, V2002, P555, DOI 10.1155/S1110865702203121; Riklin-Raviv T, 2004, LECT NOTES COMPUT SC, V2034, P50; Rousson M, 2002, LECT NOTES COMPUT SC, V2351, P78; Srivastava A, 2005, IEEE T PATTERN ANAL, V27, P590, DOI 10.1109/TPAMI.2005.86; Szekely G, 1996, Med Image Anal, V1, P19, DOI 10.1016/S1361-8415(96)80003-X; TALENTI G, 1987, INVERSE PROBL, V3, P501, DOI 10.1088/0266-5611/3/3/016; TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920; TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659; Tsai A, 2003, IEEE T MED IMAGING, V22, P137, DOI 10.1109/TMI.2002.808355; Unal G, 2002, IEEE T IMAGE PROCESS, V11, P1405, DOI 10.1109/TIP.2002.804568; Zhang T, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1056, DOI 10.1109/ICCV.2003.1238466	33	42	43	0	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2009	81	1					68	81		10.1007/s11263-008-0163-3	http://dx.doi.org/10.1007/s11263-008-0163-3			14	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	387RI		Green Submitted			2022-12-18	WOS:000261968900005
J	Okutomi, M; Katayama, Y; Oka, S				Okutomi, M; Katayama, Y; Oka, S			A simple stereo algorithm to recover precise object boundaries and smooth surfaces	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						multi-baseline stereo; 3-D reconstruction; boundary overreach; offset window; occlusion; camera selection	ADAPTIVE WINDOW; MULTIPLE	For recovering precise object boundaries in area-based stereo matching, there are two problems. One is the so-called "occlusion problem". This can be avoided if we can select only "visible" cameras among many cameras used. Another one is the problem called "boundary overreach", i.e. the recovered object boundary turns out to be wrongly located away from the real one due to the window's coverage beyond a boundary. This is especially harmful to segmenting objects using depth information. A few approaches have been proposed to solve this problem. However, these techniques tend to degrade on smooth surfaces. That is, there seems to be a trade-off problem between recovering precise object edges and obtaining smooth surfaces. In this paper, we propose a new simple method to solve these problems. Using multiple stereo pairs and multiple windowing, our method detects the region where the boundary overreach is likely to occur (let us call it "BO region") and adopts appropriate methods for the BO and non-BO regions. Although the proposed method is quite simple, the experimental results have shown that it is very effective at recovering both sharp object edges at their correct locations and smooth object surfaces. We also present a sound analysis of the boundary overreach which has not been clearly explained in the past.	Tokyo Inst Technol, Grad Sch Informat Sci & Engn, Meguro Ku, Tokyo 1528552, Japan	Tokyo Institute of Technology	Okutomi, M (corresponding author), Tokyo Inst Technol, Grad Sch Informat Sci & Engn, Meguro Ku, 2-12-1 O Okayama, Tokyo 1528552, Japan.							COCHRAN SD, 1992, IEEE T PATTERN ANAL, V14, P981, DOI 10.1109/34.159902; Fusiello A, 1997, PROC CVPR IEEE, P858, DOI 10.1109/CVPR.1997.609428; Kanade T, 1996, PROC CVPR IEEE, P196, DOI 10.1109/CVPR.1996.517074; KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690; KANADE T, 1991, P ICRA, V16, P1088; Nakamura Y, 1996, PROC CVPR IEEE, P371, DOI 10.1109/CVPR.1996.517099; ODA K, 1997, OPTICAL 3 D MEASUREM, V4, P109; Okutomi M., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P190, DOI 10.1109/ICCV.1990.139519; OKUTOMI M, 1992, INT J COMPUT VISION, V7, P143, DOI 10.1007/BF00128133; Park JI, 1998, SIGNAL PROCESS-IMAGE, V14, P7, DOI 10.1016/S0923-5965(98)00025-3; Sara R, 1997, PROC CVPR IEEE, P852, DOI 10.1109/CVPR.1997.609427	11	42	45	0	6	KLUWER ACADEMIC PUBL	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	APR-JUN	2002	47	1-3					261	273		10.1023/A:1014510328154	http://dx.doi.org/10.1023/A:1014510328154			13	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	530JN					2022-12-18	WOS:000174354700019
J	Sullivan, J; Blake, A; Isard, M; MacCormick, J				Sullivan, J; Blake, A; Isard, M; MacCormick, J			Bayesian object localisation in images	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						vision; object location; Monte Carlo; filter-bank; statistical independence	NATURAL IMAGES; DECOMPOSITION; ALGORITHMS; DIFFUSION; MODELS	A Bayesian approach to intensity-based object localisation is presented that employs a teamed probabilistic model of image filter-bank output, applied via Monte Carlo methods, to escape the inefficiency of exhaustive search. An adequate probabilistic account of image data requires intensities both in the foreground (i.e, over the object), and in the background, to be modelled. Some previous approaches to object localisation by Monte Carlo methods have used models which, we claim, do not fully address the issue of the statistical independence of image intensities. It is addressed here by applying to each image a bank of filters whose outputs are approximately statistically independent. Distributions of the responses of individual filters, over foreground and background, are learned from training data. These distributions are then used to define a joint distribution for the output of the filter bank, conditioned on object configuration, and this serves as an observation likelihood for use in probabilistic inference about localisation. The effectiveness of probabilistic object localisation in image clutter, using Bayesian Localisation, is illustrated. Because it is a Monte Carlo method, it produces not simply a single estimate of object configuration, but an entire sample from the posterior distribution for the configuration. This makes sequential inference of configuration possible. Two examples are illustrated here: coarse to fine scale inference, and propagation of configuration estimates over time, in image sequences.	Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England	University of Oxford	Sullivan, J (corresponding author), Univ Oxford, Dept Engn Sci, Parks Rd, Oxford OX1 3PJ, England.							Bartels RH, 1987, INTRO SPLINES USE CO; BASCLE B, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P302, DOI 10.1109/ICCV.1995.466925; BAUMBERG A, 1995, P BRIT MACH VIS C, V2, P413; Belhumeur PN, 1998, INT J COMPUT VISION, V28, P245, DOI 10.1023/A:1008005721484; Bell AJ, 1997, ADV NEUR IN, V9, P831; BEYMER D, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P500, DOI 10.1109/ICCV.1995.466898; BLACK MJ, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P374, DOI 10.1109/ICCV.1995.466915; BLAKE A, 1995, ARTIF INTELL, V78, P179, DOI 10.1016/0004-3702(95)00032-1; Blake A., 1998, ACTIVE CONTOURS, DOI [10.1007/978-1-4471-1555-7, DOI 10.1007/978-1-4471-1555-7]; BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792; BURT PJ, 1983, COMPUT VISION GRAPH, V21, P368, DOI 10.1016/S0734-189X(83)80049-8; FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379; GELFAND AE, 1990, J AM STAT ASSOC, V85, P398, DOI 10.2307/2289776; Geman D, 1996, IEEE T PATTERN ANAL, V18, P1, DOI 10.1109/34.476006; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GEWEKE J, 1989, ECONOMETRICA, V57, P1317, DOI 10.2307/1913710; GRENANDER U, 1994, J R STAT SOC B, V56, P549; Grenander U., 1976, LECT PATTERN THEORY, V1; GRENANDER U, 1976, LECT PATTERN THEORY, V3; Grenander U., 1991, HANDS PATTERN THEORE; GRENANDER U, 1976, LECT PATTERN THEORY, V2; HAGER G, 1996, P 4 EUR C COMP VIS, P507; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; ISARD M, 1996, P EUR C COMP VIS, P343; Kitagawa Genshiro, 2021, J COMPUT GRAPH STAT, V5, P1, DOI [DOI 10.2307/1390750, 10.2307/1390750]; LIU JS, 1995, J AM STAT ASSOC, V90, P567, DOI 10.2307/2291068; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; MATTHIES L, 1989, INT J COMPUT VISION, V3, P209, DOI 10.1007/BF00133032; Mumford D., 1996, PERCEPTION BAYESIAN, P25; NEAL R, 2000, IN PRESS STAT COMPUT; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; PERONA P, 1992, LECT NOTES COMPUT SC, V588, P3, DOI 10.1016/0262-8856(92)90011-Q; RIPLEY B, 1992, P 15 JAHR GES KLASS; Scharstein D, 1998, INT J COMPUT VISION, V28, P155, DOI 10.1023/A:1008015117424; SHIRAI Y, 1985, P 3 INT S ROB RES, P27; STORVIK G, 1994, IEEE T PATTERN ANAL, V16, P976, DOI 10.1109/34.329011; Sullivan J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1068, DOI 10.1109/ICCV.1999.790391; SULLIVAN J, 2000, P 6 EUR C COMP VIS D, V2, P307; SZELISKI R, 1990, INT J COMPUT VISION, V5, P271, DOI 10.1007/BF00126502; VETTER T, 1996, P 4 EUR C COMP VIS C, P652; VIOLA P, 1993, P 5 INT C COMP VIS, P16; WITKIN A, 1987, INT J COMPUT VISION, V1, P133, DOI 10.1007/BF00123162; Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420; Zhu SC, 1997, IEEE T PATTERN ANAL, V19, P1236, DOI 10.1109/34.632983	46	42	44	0	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2001	44	2					111	135		10.1023/A:1011818912717	http://dx.doi.org/10.1023/A:1011818912717			25	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	492BX					2022-12-18	WOS:000172148300002
J	Chiuso, A; Brockett, R; Soatto, S				Chiuso, A; Brockett, R; Soatto, S			Optimal structure from motion: Local ambiguities and global estimates	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						structure from motion; alternating minimization; least-squares; sphere; optical flow; bilinear optimization	ALGORITHMS; CONSTRAINTS	"Structure From Motion" (SFM) refers to the problem of estimating spatial properties of a three-dimensional scene from the motion of its projection onto a two-dimensional surface, such as the retina. We present an analysis of SFM which results in algorithms that are provably convergent and provably optimal with respect to a chosen norm. In particular, we cast SFM as the minimization of a high-dimensional quadratic cost function, and show how it is possible to reduce it to the minimization of a two-dimensional function whose stationary points are in one-to-one correspondence with those of the original cost function. As a consequence, we can plot the reduced cost function and characterize the configurations of structure and motion that result in local minima. As an example, we discuss two local minima that are associated with well-known visual illusions. Knowledge of the topology of the residual in the presence of such local minima allows us to formulate minimization algorithms that, in addition to provably converge to stationary points of the original cost function, can switch between different local extrema in order to converge to the global minimum, under suitable conditions. We also offer an experimental study of the distribution of the estimation error in the presence of noise in the measurements, and characterize the sensitivity of the algorithm using the structure of Fisher's Information matrix.	Washington Univ, Dept Elect Engn, Elect Syst & Signals Res Lab, St Louis, MO 63130 USA; Univ Padua, Dipartimento Elettron & Informat, I-35100 Padua, Italy; Harvard Univ, Div Appl Sci, Cambridge, MA 02139 USA; Univ Calif Los Angeles, Henry Samueli Sch Engn, Dept Comp Sci, Los Angeles, CA 90095 USA	Washington University (WUSTL); University of Padua; Harvard University; University of California System; University of California Los Angeles	Chiuso, A (corresponding author), Washington Univ, Dept Elect Engn, Elect Syst & Signals Res Lab, 1 Brookings Dr 1127, St Louis, MO 63130 USA.	chiuso@dei.unipd.it		CHIUSO, ALESSANDRO/0000-0002-4410-6101				ADIV G, 1989, IEEE T PATTERN ANAL, V11, P477, DOI 10.1109/34.24780; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; BERGEN J, 1995, P IEEE WORKSH VIS SC, P10; DURRET R, 1995, PROBABILITY THEORY E; Faugeras Olivier, 1993, 3 DIMENSIONAL VISION, P2; GOLUB GH, 1973, SIAM J NUMER ANAL, V10, P413, DOI 10.1137/0710036; JEPSON AD, 1992, SPATIAL VISION HUMAN; Kanatani K., 1993, GEOMETRIC COMPUTATIO; KUMAR R, 1994, INT C PATT RECOG, P685, DOI 10.1109/ICPR.1994.576402; LIU R, 1998, P IEEE, V86; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Lucas Bruce, 1981, IJCAI; Luong QT, 1996, INT J COMPUT VISION, V17, P43, DOI 10.1007/BF00127818; Ma Y, 2000, INT J COMPUT VISION, V36, P71, DOI 10.1023/A:1008124507881; Morrison D. F., 1990, MULTIVARIATE STAT ME; O'Sullivan JA., 1998, CODES CURVES SIGNALS, P173, DOI 10.1007/978-1-4615-5121-8_13; OLIENSIS J, 1996, P IEEE C COMP VIS PA; POELMAN C, 1994, LNCS, V810; Rao C. R, 1973, LINEAR STAT INFERENC; SAWHNEY HS, 1994, P INT C PATTERN RECO; SNYDER DL, 1992, IEEE T SIGNAL PROCES, V40, P1143, DOI 10.1109/78.134477; Soatto S, 1997, INT J COMPUT VISION, V22, P235, DOI 10.1023/A:1007930700152; SPETSAKIS ME, 1992, IEEE T PATTERN ANAL, V14, P959, DOI 10.1109/34.161355; Szeliski R., 1994, Journal of Visual Communication and Image Representation, V5, P10, DOI 10.1006/jvci.1994.1002; SZELISKI R, 1996, P EUR C COMP VIS; THOMAS I, 1994, 9426 IRCS U PENNS; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; VANOVERSCHEE P, 1993, AUTOMATICA, V29, P649, DOI 10.1016/0005-1098(93)90061-W; WENG JY, 1993, IEEE T PATTERN ANAL, V15, P864, DOI 10.1109/34.232074; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779; YOUNG GS, 1992, IEEE T PATTERN ANAL, P14; ZHANG T, 1999, THESIS STANFORD U, P164; ZHANG T, 1999, P IEEE INT C COMP VI	33	42	42	0	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2000	39	3					195	228		10.1023/A:1026563712076	http://dx.doi.org/10.1023/A:1026563712076			34	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	382EJ					2022-12-18	WOS:000165809800002
J	Drummond, T; Cipolla, R				Drummond, T; Cipolla, R			Application of Lie algebras to visual servoing	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						visual servoing; active contours; affine geometry; lie groups; lie algebras	VISION	A novel approach to visual servoing is presented, which takes advantage of the structure of the Lie algebra of affine transformations. The aim of this project is to use feedback from a visual sensor to guide a robot arm to a target position. The target position is learned using the principle of 'teaching by showing' in which the supervisor places the robot in the correct target position and the system captures the necessary information to be able to return to that position. The sensor is placed in the end effector of the robot, the 'camera-in-hand' approach, and thus provides direct feedback of the robot motion relative to the target scene via observed transformations of the scene. These scene transformations are obtained by measuring the affine deformations of a target planar contour (under the weak perspective assumption), captured by use of an active contour, or snake. Deformations of the snake are constrained using the Lie groups of affine and projective transformations. Properties of the Lie algebra of affine transformations are exploited to provide a novel method for integrating observed deformations of the target contour. These can be compensated with appropriate robot motion using a non-linear control structure. The local differential representation of contour deformations is extended to allow accurate integration of an extended series of small perturbations. This differs from existing approaches by virtue of the properties of the Lie algebra representation which implicitly embeds knowledge of the three-dimensional world within a two-dimensional image-based system. These techniques have been implemented using a video camera to control a 5 DoF robot arm. Experiments with this implementation are presented, together with a discussion of the results.	Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England	University of Cambridge	Drummond, T (corresponding author), Univ Cambridge, Dept Engn, Trumpington St, Cambridge CB2 1PZ, England.	twd20@eng.cam.ac.uk; cipolla@eng.cam.ac.uk	Arandjelović, Ognjen/V-5255-2019; Drummond, Tom/A-4696-2011	Arandjelović, Ognjen/0000-0002-9314-194X; Drummond, Tom/0000-0001-8204-5904; Cipolla, Roberto/0000-0002-8999-2151				BARD C, 1995, INT J ROBOT RES, V14, P445, DOI 10.1177/027836499501400504; Basri R, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P863, DOI 10.1109/ICCV.1998.710818; Cipolla R, 1997, INT J ROBOT RES, V16, P77, DOI 10.1177/027836499701600106; Colombo C, 1999, IEEE T SYST MAN CY A, V29, P92, DOI 10.1109/3468.736363; Corke PI, 1996, IEEE T ROBOTIC AUTOM, V12, P671, DOI 10.1109/70.538973; Couvignou PA, 1996, J INTELL ROBOT SYST, V17, P195, DOI 10.1007/BF00776509; CROSS G, 1996, P BRIT MACH VIS C BM, V2, P425; ESPIAU B, 1992, IEEE T ROBOTIC AUTOM, V8, P313, DOI 10.1109/70.143350; Hager GD, 1996, IEEE T ROBOTIC AUTOM, V12, P649; HORAUD R, 1995, INT J ROBOT RES, V14, P195, DOI 10.1177/027836499501400301; Hutchinson S, 1996, IEEE T ROBOTIC AUTOM, V12, P651, DOI 10.1109/70.538972; ISARD M, 1996, P EUR C COMP VIS, P343; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KINOSHITA K, 1998, P INT C COMP VIS ICC, P883; KOENDERINK JJ, 1975, OPT ACTA, V22, P773, DOI 10.1080/713819112; Malis E, 1999, IEEE T ROBOTIC AUTOM, V15, P238, DOI 10.1109/70.760345; Nayar SK, 1996, IEEE T ROBOTIC AUTOM, V12, P750, DOI 10.1109/70.538979; PARK FC, 1995, INT J ROBOT RES, V14, P609, DOI 10.1177/027836499501400606; SANTRA RN, 1995, ADV POLYM TECH, V14, P59, DOI 10.1002/adv.1995.060140106; SATTINGER DH, 1986, LIE GROUPS ALGEBRAS, V61; WEISS LE, 1987, IEEE T ROBOTIC AUTOM, V3, P404, DOI 10.1109/JRA.1987.1087115; Wilson WJ, 1996, IEEE T ROBOTIC AUTOM, V12, P684, DOI 10.1109/70.538974; YOSHIMI BH, 1995, IEEE T ROBOTIC AUTOM, V11, P516, DOI 10.1109/70.406936; [No title captured]; [No title captured]	25	42	45	0	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2000	37	1					21	41		10.1023/A:1008125412549	http://dx.doi.org/10.1023/A:1008125412549			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	341FC					2022-12-18	WOS:000088579500003
J	WIXSON, LE; BALLARD, DH				WIXSON, LE; BALLARD, DH			USING INTERMEDIATE OBJECTS TO IMPROVE THE EFFICIENCY OF VISUAL-SEARCH	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article								When using a mobile camera to search for a target object, it is often important to maximize the efficiency of the search. We consider a method for increasing efficiency by searching only those subregions that are especially likely to contain the object. These subregions are identified via spatial relationships. Searches that use this method repeatedly find an ''intermediate'' object that commonly participates in a spatial relationship with the target object, and then look for the target in the restricted region specified by this relationship. Intuitively, such searches, called indirect searches, seem likely to provide efficiency increases when the intermediate objects can be recognized at low resolutions and hence can be found with little extra overhead, and when they significantly restrict the area that must be searched for the target. But what is the magnitude of this increase, and upon what other factors does efficiency depend? Although the idea of exploiting spatial relationships has been used in vision systems before, few have quantitatively examined these questions. We present a mathematical model of search efficiency that identifies the factors affecting efficiency and can be used to predict their effects. The model predicts that, in typical situations, indirect search provides up to an 8-fold increase in efficiency. Besides being useful as an analysis tool, the model is also suitable for use in an on-line system for selecting intermediate objects.			WIXSON, LE (corresponding author), UNIV ROCHESTER,DEPT COMP SCI,ROCHESTER,NY 14627, USA.							ALOIMONOS JY, 1990, AAAI WORKSH QUAL VIS, P1; [Anonymous], 1987, SEARCH PROBLEMS; BAJCSY R, 1988, P IEEE, V76, P996, DOI 10.1109/5.5968; Ballard D.H., 1982, COMPUTER VISION; BALLARD DH, 1992, CVGIP-IMAG UNDERSTAN, V56, P3, DOI 10.1016/1049-9660(92)90081-D; BARROW HG, 1976, MSYS SYSTEM REASONIN; BOLLE RM, 1989, DATA MODEL DRIVEN FO; BOLLES R, 1977, 5TH P INT JOINT C AR; BURT PJ, 1988, P IEEE, V76, P1006, DOI 10.1109/5.5971; Garey M. R., 1978, COMPUTERS INTRACTABI; GARVEY TD, 1976, 117 SRI INT TECHN NO; JOHNSON DT, 1982, 6TH EUR M CYB SYST R; LARSEN RJ, 1981, INTRO MATH STATISTIC; MAVER J, 1993, IEEE T PATTERN ANAL, V15, P417, DOI 10.1109/34.211463; REECE DA, 1991, CMUCS91199 CARN MELL; REECE DA, 1992, CMUCS92139 CARN MELL; RIMEY RD, 1992, 2ND P EUR C COMP VIS; RIMEY RD, 1994, INT J COMPUT VISION, V2, P173; RUSSELL DM, 1978, 38 U ROCH COMP SCI D; SARACHIK KB, 1993, JUN P C COMP VIS PAT; SWAIN MJ, 1992, JUN P IEEE C COMP VI; SWAIN MJ, 1990, 360 U ROCH COMP SCI; TARABANIS K, 1992, MVP SENSOR PLANNING; TSOTSOS JK, 1992, INT J COMP VIS, V7, P2; VANTEES HL, 1968, DETECTION ESTIMATION, V1; WILKES D, 1992, P IEEE C COMPUT VIS; WIXSON LE, 1994, THESIS U ROCHESTER C; WIXSON LE, 1989, SPIE SENSOR FUSION 2, V1198; WIXSON LE, 1992, 434 U ROCH COMP SCI	29	42	44	0	3	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	APR	1994	12	2-3					209	230		10.1007/BF01421203	http://dx.doi.org/10.1007/BF01421203			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	NL558					2022-12-18	WOS:A1994NL55800004
J	Mohan, R; Valada, A				Mohan, Rohit; Valada, Abhinav			EfficientPS: Efficient Panoptic Segmentation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Panoptic segmentation; Semantic segmentation; Instance segmentation; Scene understanding		Understanding the scene in which an autonomous robot operates is critical for its competent functioning. Such scene comprehension necessitates recognizing instances of traffic participants along with general scene semantics which can be effectively addressed by the panoptic segmentation task. In this paper, we introduce the Efficient Panoptic Segmentation (EfficientPS) architecture that consists of a shared backbone which efficiently encodes and fuses semantically rich multi-scale features. We incorporate a new semantic head that aggregates fine and contextual features coherently and a new variant of Mask R-CNN as the instance head. We also propose a novel panoptic fusion module that congruously integrates the output logits from both the heads of our EfficientPS architecture to yield the final panoptic segmentation output. Additionally, we introduce the KITTI panoptic segmentation dataset that contains panoptic annotations for the popularly challenging KITTI benchmark. Extensive evaluations on Cityscapes, KITTI, Mapillary Vistas and Indian Driving Dataset demonstrate that our proposed architecture consistently sets the new state-of-the-art on all these four benchmarks while being the most efficient and fast panoptic segmentation architecture to date.	[Mohan, Rohit; Valada, Abhinav] Univ Freiburg, Freiburg, Germany	University of Freiburg	Valada, A (corresponding author), Univ Freiburg, Freiburg, Germany.	mohan@cs.uni-freiburg.de; valada@cs.uni-freiburg.de	Valada, Abhinav/ABE-8411-2021	Valada, Abhinav/0000-0003-4710-3114	European Union's Horizon 2020 research and innovation program [871449-OpenDR]; Google Cloud research grant	European Union's Horizon 2020 research and innovation program; Google Cloud research grant(Google Incorporated)	This work was partly funded by the European Union's Horizon 2020 research and innovation program under grant agreement No 871449-OpenDR and a Google Cloud research grant.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Arbelaez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49; Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615; Bai M, 2017, PROC CVPR IEEE, P2858, DOI 10.1109/CVPR.2017.305; Berg A.C., 2015, ARXIV150604579; Bowen Cheng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12472, DOI 10.1109/CVPR42600.2020.01249; Brostow Gabriel J., 2008, ECCV, P44, DOI [10.1007/978-3-540-88682-2_5, DOI 10.1007/978-3-540-88682-2_5]; Bulo SR, 2017, PROC CVPR IEEE, P7082, DOI 10.1109/CVPR.2017.749; Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709; Chollet F., 2017, PROC CVPR IEEE, P1251, DOI DOI 10.1109/CVPR.2017.195; Cipoll Roberto, 2008, PROC CVPR IEEE, P1; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89; Dai JF, 2016, LECT NOTES COMPUT SC, V9910, P534, DOI 10.1007/978-3-319-46466-4_32; de Geus, 2018, ARXIV180902110; Gao NY, 2019, IEEE I CONF COMP VIS, P642, DOI 10.1109/ICCV.2019.00073; GEIGER A, 2013, INT J ROBOT RES, V5, P79; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Glorot X., 2010, PROC MACH LEARN RES, P249; Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642; Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20; He K, 2017, P IEEE INT C COMPUTE, DOI DOI 10.1109/ICCV.2017.322; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He XM, 2014, PROC CVPR IEEE, P296, DOI 10.1109/CVPR.2014.45; Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Kaiser L., 2017, ARXIV PREPRINT ARXIV; Kim H.Y, 2018, ARXIV181010327; Kirillov A, 2019, PROC CVPR IEEE, P6392, DOI 10.1109/CVPR.2019.00656; Kirillov A, 2019, PROC CVPR IEEE, P9396, DOI 10.1109/CVPR.2019.00963; Koltun V, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472; Kontschieder P, 2011, IEEE I CONF COMP VIS, P2190, DOI 10.1109/ICCV.2011.6126496; Li J, 2018, PROCEEDINGS OF THE 2018 ACM/SPEC INTERNATIONAL CONFERENCE ON PERFORMANCE ENGINEERING (ICPE '18), P229, DOI 10.1145/3184407.3184410; Li QZ, 2018, LECT NOTES COMPUT SC, V11219, P106, DOI 10.1007/978-3-030-01267-0_7; Li X, 2020, PSYCHOTHER RES, V30, P604, DOI [10.1080/10503307.2019.1649730, 10.1145/3300061.3345434]; Li YW, 2019, PROC CVPR IEEE, P7019, DOI 10.1109/CVPR.2019.00719; Li Y, 2017, PROC CVPR IEEE, P4438, DOI 10.1109/CVPR.2017.472; Lin T.-Y., 2017, PROC CVPR IEEE, P936, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913; Liu Shu, 2017, P IEEE INT C COMP VI, P3496; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Neuhold G, 2017, IEEE I CONF COMP VIS, P5000, DOI 10.1109/ICCV.2017.534; Paszke A, 2019, ADV NEURAL INF PROCE, DOI DOI 10.48550/ARXIV.1912.01703; Pinheiro Pedro O., 2015, ADV NEURAL INFORM PR, V3, P5; Plath N., 2009, P 26 ANN INT C MACHI, P817, DOI [10.1145/1553374.1553479, DOI 10.1145/1553374.1553479]; Porzi Lorenzo, 2019, CVPR; Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI 10.1109/ICPHM.2017.7998297; Radwan N, 2018, ARXIV180806887; Ren MY, 2017, PROC CVPR IEEE, P293, DOI 10.1109/CVPR.2017.39; Romera-Paredes B, 2016, LECT NOTES COMPUT SC, V9910, P312, DOI 10.1007/978-3-319-46466-4_19; Ros G, 2015, IEEE WINT CONF APPL, P231, DOI 10.1109/WACV.2015.38; Rota Bul S., 2018, P C COMP VIS PATT RE, P5639, DOI DOI 10.1109/CVPR.2018.00591; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Silberman N, 2014, LECT NOTES COMPUT SC, V8689, P616, DOI 10.1007/978-3-319-10590-1_40; Sofiiuk K, 2019, IEEE I CONF COMP VIS, P7354, DOI 10.1109/ICCV.2019.00745; Sturgess P., 2009, P BRIT MACH VIS C, P1; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Tan Mingxing, 2019, BRIT MACH VIS C BMVC; Tian Z, 2019, PROC CVPR IEEE, P3121, DOI 10.1109/CVPR.2019.00324; Tighe J, 2014, PROC CVPR IEEE, P3748, DOI 10.1109/CVPR.2014.479; Tighe J, 2013, PROC CVPR IEEE, P3001, DOI 10.1109/CVPR.2013.386; Tu ZW, 2005, INT J COMPUT VISION, V63, P113, DOI 10.1007/s11263-005-6642-x; Uhrig J, 2016, LECT NOTES COMPUT SC, V9796, P14, DOI 10.1007/978-3-319-45886-1_2; Valada Abhinav, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4644, DOI 10.1109/ICRA.2017.7989540; Valada A., 2018, WORKSH LEARN INF ROB, V1, P3; VALADA A, 2016, IEEE RSJ INT C INT R; Valada A, 2020, INT J COMPUT VISION, V128, P1239, DOI 10.1007/s11263-019-01188-y; Varma G, 2019, IEEE WINT CONF APPL, P1743, DOI 10.1109/WACV.2019.00190; Wu YX, 2020, INT J COMPUT VISION, V128, P742, DOI 10.1007/s11263-019-01198-w; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Xu P, 2016, MACH VISION APPL, V27, P331, DOI 10.1007/s00138-014-0649-7; Yang TJ, 2019, INT EL DEVICES MEET; Yao J, 2012, PROC CVPR IEEE, P702, DOI 10.1109/CVPR.2012.6247739; Yu F., 2016, P ICLR 2016; Zhang CX, 2010, LECT NOTES COMPUT SC, V6314, P708, DOI 10.1007/978-3-642-15561-1_51; Zhang ZY, 2016, PROC CVPR IEEE, P669, DOI 10.1109/CVPR.2016.79; Zurn J., 2019, ARXIV191203227	85	41	42	5	31	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2021	129	5					1551	1579		10.1007/s11263-021-01445-z	http://dx.doi.org/10.1007/s11263-021-01445-z		FEB 2021	29	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	RY0YC		hybrid, Green Submitted			2022-12-18	WOS:000622275300002
J	Zhang, H; Riggan, BS; Hu, SW; Short, NJ; Patel, VM				Zhang, He; Riggan, Benjamin S.; Hu, Shuowen; Short, Nathaniel J.; Patel, Vishal M.			Synthesis of High-Quality Visible Faces from Polarimetric Thermal Faces using Generative Adversarial Networks	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Face synthesis; Heterogeneous face recognition; Polarimetric data; Thermal face recognition; Deep learning; Generative adversarial networks	RECOGNITION	The large domain discrepancy between faces captured in polarimetric (or conventional) thermal and visible domains makes cross-domain face verification a highly challenging problem for human examiners as well as computer vision algorithms. Previous approaches utilize either a two-step procedure (visible feature estimation and visible image reconstruction) or an input-level fusion technique, where different Stokes images are concatenated and used as a multi-channel input to synthesize the visible image given the corresponding polarimetric signatures. Although these methods have yielded improvements, we argue that input-level fusion alone may not be sufficient to realize the full potential of the available Stokes images. We propose a generative adversarial networks based multi-stream feature-level fusion technique to synthesize high-quality visible images from polarimetric thermal images. The proposed network consists of a generator sub-network, constructed using an encoder-decoder network based on dense residual blocks, and a multi-scale discriminator sub-network. The generator network is trained by optimizing an adversarial loss in addition to a perceptual loss and an identity preserving loss to enable photo realistic generation of visible images while preserving discriminative characteristics. An extended dataset consisting of polarimetric thermal facial signatures of 111 subjects is also introduced. Multiple experiments evaluated on different experimental protocols demonstrate that the proposed method achieves state-of-the-art performance. Code will be made available at https://github.com/hezhangsprinter.	[Zhang, He] Rutgers State Univ, Dept ECE, 94 Brett Rd, Piscataway, NJ 08854 USA; [Riggan, Benjamin S.; Hu, Shuowen] US Army, CCDC Army Res Lab, 2800 Powder Mill Rd, Adelphi, MD 20783 USA; [Short, Nathaniel J.] Booz Allen Hamilton, Mclean, VA USA; [Patel, Vishal M.] Johns Hopkins Univ, Dept ECE, Baltimore, MD USA	Rutgers State University New Brunswick; Booz Allen Hamilton Holding Corporation; Johns Hopkins University	Zhang, H (corresponding author), Rutgers State Univ, Dept ECE, 94 Brett Rd, Piscataway, NJ 08854 USA.	he.zhang92@rutgers.edu; benjamin.s.riggan.civ@mail.mil; shuowen.hu.civ@mail.mil; short_nathaniel@bah.com; vpatel36@jhu.edu	Riggan, Benjamin/AAG-6282-2021		ARO [W911NF-16-1-0126]	ARO	This work was supported by an ARO Grant W911NF-16-1-0126.	[Anonymous], 2018, P BMVC; [Anonymous], 2016, ARXIV160908661; Berthelot D., 2017, BEGAN BOUNDARY EQUIL, DOI DOI 10.48550/ARXIV.1703.10717; Bodla N, 2017, IEEE WINT CONF APPL, P586, DOI 10.1109/WACV.2017.71; Chen J, 2016, MOB INF SYST, V2016, DOI 10.1155/2016/5894752; Chen JC, 2018, INT J COMPUT VISION, V126, P272, DOI 10.1007/s11263-017-1029-3; Chen X, 2005, COMPUT VIS IMAGE UND, V99, P332, DOI 10.1016/j.cviu.2005.03.001; Di X., 2019, ABS190100889 CORR; Ding H, 2017, IEEE INT CONF AUTOMA, P118, DOI 10.1109/FG.2017.23; Dong Yi, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163093; Espinosa-Duro V, 2013, COGN COMPUT, V5, P119, DOI 10.1007/s12559-012-9163-2; Gao F, 2017, ARXIV171200899; Gonzalez-Sosa E, 2017, IEEE T INF FOREN SEC, V12, P2078, DOI 10.1109/TIFS.2017.2695979; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gurton KP, 2014, OPT LETT, V39, P3857, DOI 10.1364/OL.39.003857; HE R, 2017, IEEE T PATTERN ANAL, P1; He R., 2019, ARXIV190203565; Hu S, 2016, 2016 IEEE 27TH ANNUAL INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), P1195; Hu SW, 2015, J OPT SOC AM A, V32, P431, DOI 10.1364/JOSAA.32.000431; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Iranmanesh S.M., 2018, DEEP CROSS POLARIMET; Isola P., 2016, 2017 IEEE C COMP VIS; Jetchev Nikolay, 2016, ARXIV161108207; Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43; Karacan L., 2016, ARXIV161200215; Kingma D.P, P 3 INT C LEARNING R; Klare B., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1513, DOI 10.1109/ICPR.2010.374; Klare BF, 2013, IEEE T PATTERN ANAL, V35, P1410, DOI 10.1109/TPAMI.2012.229; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Lezama J, 2017, PROC CVPR IEEE, P6807, DOI 10.1109/CVPR.2017.720; Li SZ, 2013, IEEE COMPUT SOC CONF, P348, DOI 10.1109/CVPRW.2013.59; Maas A.L., 2013, P ICML, V30, P3, DOI DOI 10.1016/0010-0277(84)90022-2; Mahendran A, 2015, PROC CVPR IEEE, P5188, DOI 10.1109/CVPR.2015.7299155; Meyers E, 2008, INT J COMPUT VISION, V76, P93, DOI 10.1007/s11263-007-0058-8; Mirza M., 2014, ARXIV; Nair V, 2010, P 27 INT C MACHINE L, P807; Nicolo F, 2012, IEEE T INF FOREN SEC, V7, P1717, DOI 10.1109/TIFS.2012.2213813; Parkhi Omkar M., 2015, BRIT MACH VIS C; Gonzales EP, 2017, PENSAM MARGEN, P1; Peng CL, 2016, IEEE T NEUR NET LEAR, V27, P2201, DOI 10.1109/TNNLS.2015.2464681; Peng X., 2018, ARXIV180509707; Peng X., 2017, P IEEE INT C COMP VI; Peng X, 2016, LECT NOTES COMPUT SC, V9905, P38, DOI 10.1007/978-3-319-46448-0_3; Perera P., 2017, ARXIV171109334; Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI 10.1109/ICPHM.2017.7998297; Radford A., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.1051/0004-6361/201527329; Ranjan R, 2018, IEEE SIGNAL PROC MAG, V35, P66, DOI 10.1109/MSP.2017.2764116; Ranjan R, 2017, IEEE INT CONF AUTOMA, P17, DOI 10.1109/FG.2017.137; Riggan BS, 2016, INT CONF BIOMETR THE; Riggan BS, 2016, IEEE WINT CONF APPL; Riggan BS, 2015, IEEE ACCESS, V3, P1620, DOI 10.1109/ACCESS.2015.2479620; Salimans T, 2016, ADV NEUR IN, V29; Sarfraz M. S., 2015, P BRIT MACHINE VISIO; Sarfraz MS, 2017, INT J COMPUT VISION, V122, P426, DOI 10.1007/s11263-016-0933-2; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Short N, 2015, OPT LETT, V40, P882, DOI 10.1364/OL.40.000882; Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206; Song LX, 2018, AAAI CONF ARTIF INTE, P7355; Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Tran L, 2017, PROC CVPR IEEE, P1283, DOI 10.1109/CVPR.2017.141; Tyo JS, 2006, APPL OPTICS, V45, P5453, DOI 10.1364/AO.45.005453; Wang L., 2018, IEEE INT C AUT FAC G; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wu X., 2018, ARXIV180901936; Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032; Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164; Xu H, 2016, ADV METEOROL, V2016, DOI 10.1155/2016/1246590; Xu T, 2017, ARXIV171110485; Yang XT, 2018, AAAI CONF ARTIF INTE, P7485; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang H., 2017, P EUR C COMP VIS ECC; Zhang H., 2017, IJCB; Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747; Zhang H, 2020, IEEE T CIRC SYST VID, V30, P3943, DOI 10.1109/TCSVT.2019.2920407; Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337; Zhang ZZ, 2018, PROC CVPR IEEE, P9242, DOI 10.1109/CVPR.2018.00963; Zhao J, 2016, 2016 IEEE MTT-S INTERNATIONAL WIRELESS SYMPOSIUM (IWS), DOI 10.1109/ICSSSM.2016.7538614; Zhu Y., 2017, ARXIV171201381	81	41	41	0	14	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2019	127	6-7			SI		845	862		10.1007/s11263-019-01175-3	http://dx.doi.org/10.1007/s11263-019-01175-3			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	HZ0JD		Green Submitted			2022-12-18	WOS:000468525900017
J	Baatz, G; Koser, K; Chen, D; Grzeszczuk, R; Pollefeys, M				Baatz, Georges; Koeser, Kevin; Chen, David; Grzeszczuk, Radek; Pollefeys, Marc			Leveraging 3D City Models for Rotation Invariant Place-of-Interest Recognition	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Location recognition		Given a cell phone image of a building we address the problem of place-of-interest recognition in urban scenarios. Here, we go beyond what has been shown in earlier approaches by exploiting the nowadays often available 3D building information (e.g. from extruded floor plans) and massive street-level image data for database creation. Exploiting vanishing points in query images and thus fully removing 3D rotation from the recognition problem allows then to simplify the feature invariance to a purely homothetic problem, which we show enables more discriminative power in feature descriptors than classical SIFT. We rerank visual word based document queries using a fast stratified homothetic verification that in most cases boosts the correct document to top positions if it was in the short list. Since we exploit 3D building information, the approach finally outputs the camera pose in real world coordinates ready for augmenting the cell phone image with virtual 3D information. The whole system is demonstrated to outperform traditional approaches on city scale experiments for different sources of street-level image data and a challenging set of cell phone images.	[Baatz, Georges; Koeser, Kevin; Pollefeys, Marc] Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland; [Chen, David] Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA; [Grzeszczuk, Radek] Nokia Res Palo Alto, Palo Alto, CA USA	Swiss Federal Institutes of Technology Domain; ETH Zurich; Stanford University; Nokia Corporation; Nokia Bell Labs	Baatz, G (corresponding author), Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland.	gbaatz@inf.ethz.ch; kevin.koeser@inf.ethz.ch; dmchen@stanford.edu; radek.grzeszczuk@nokia.com; marc.pollefeys@inf.ethz.ch	Pollefeys, Marc/I-7607-2013					[Anonymous], BMVC; Baatz G., 2010, ECCV; BAY H, 2008, COMPUTER VISION IMAG, V110; Bishop C. M., 2006, PATTERN RECOGN, P123; CAO Y, 2009, IEEE WORKSH APPL COM; Chandrasekhar V., 2009, CVPR; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; Irschara A., 2009, CVPR; Jegou H., 2008, ECCV; Knopp J., 2010, ECCV; Kosecka J., 2002, ECCV; KOSER K, 2007, WORKSH 3D REPR REC I; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Nister D., 2006, CVPR; Perdoch M., 2009, CVPR; Philbin J., 2007, CVPR; Robertson D., 2004, BMVC; Schindler G., 2007, CVPR; Schindler G., 2008, CVPR, P2; Sivic J., 2003, ICCV; Takacs G., 2010, CVPR; Wu C., 2008, CVPR; WU C, 2008, WORKSH SEARCH 3D CVP; Zamir A. R., 2010, ECCV; Zhang W., 2006, 3DPVT; Zhu Z., 2008, CVPR	27	41	45	1	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	FEB	2012	96	3					315	334		10.1007/s11263-011-0458-7	http://dx.doi.org/10.1007/s11263-011-0458-7			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	885HK		Green Published			2022-12-18	WOS:000299769400004
J	Raguram, R; Wu, CC; Frahm, JM; Lazebnik, S				Raguram, Rahul; Wu, Changchang; Frahm, Jan-Michael; Lazebnik, Svetlana			Modeling and Recognition of Landmark Image Collections Using Iconic Scene Graphs	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Landmark reconstruction; Photo collection reconstruction; Landmark recognition; Location recognition; Image clustering; Structure from motion		This article presents an approach for modeling landmarks based on large-scale, heavily contaminated image collections gathered from the Internet. Our system efficiently combines 2D appearance and 3D geometric constraints to extract scene summaries and construct 3D models. In the first stage of processing, images are clustered based on low-dimensional global appearance descriptors, and the clusters are refined using 3D geometric constraints. Each valid cluster is represented by a single iconic view, and the geometric relationships between iconic views are captured by an iconic scene graph. Using structure from motion techniques, the system then registers the iconic images to efficiently produce 3D models of the different aspects of the landmark. To improve coverage of the scene, these 3D models are subsequently extended using additional, non-iconic views. We also demonstrate the use of iconic images for recognition and browsing. Our experimental results demonstrate the ability to process datasets containing up to 46,000 images in less than 20 hours, using a single commodity PC equipped with a graphics card. This is a significant advance towards Internet-scale operation.	[Raguram, Rahul; Wu, Changchang; Frahm, Jan-Michael; Lazebnik, Svetlana] Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27599 USA	University of North Carolina; University of North Carolina Chapel Hill	Raguram, R (corresponding author), Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27599 USA.	rraguram@cs.unc.edu; ccwu@cs.unc.edu; jmf@cs.unc.edu; lazebnik@cs.unc.edu			DARPA ASSIST; NSF [IIS-0916829, IIS-0845629, CNS-0751187]; U.S. government; Microsoft	DARPA ASSIST; NSF(National Science Foundation (NSF)); U.S. government; Microsoft(Microsoft)	This research was supported in part by DARPA ASSIST program, NSF grants IIS-0916829, IIS-0845629, and CNS-0751187, and other funding from the U.S. government. Svetlana Lazebnik was supported by the Microsoft Research Faculty Fellowship. We would also like to thank our collaborators Marc Pollefeys, Xiaowei Li, Christopher Zach, and Tim Johnson.	Agarwal S., 2009, ICCV; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Beder C, 2006, LECT NOTES COMPUT SC, V4174, P657; Berg T.L., 2007, AUTOMATIC RANKING IC; Berg T. L., 2009, 2 INT VIS WORKSH IEE; Blanz V, 1999, PERCEPTION, V28, P575, DOI 10.1068/p2897; Chum O., 2007, ICCV; Collins Brendan, 2008, ECCV; Crandall David J, 2009, P INT C WORLD WID WE, DOI DOI 10.1145/1526709.1526812; Denton T, 2004, INT C PATT RECOG, P273, DOI 10.1109/ICPR.2004.1334159; Douze M., 2009, P ACM INT C IMAGE VI; Fergus R., 2004, ECCV; Frahm J.-M., 2006, P COMP VIS PATT REC, V1, P453, DOI DOI 10.1109/CVPR.2006.235; Haber T., 2009, P CVPR; Hall PM, 2005, P BRIT MACH VIS C, P839; Hays J., 2007, SIGGRAPH; Jing Y, 2008, IEEE T PATTERN ANAL, V30, P1877, DOI 10.1109/TPAMI.2008.121; Kennedy L., 2008, P 17 INT WORLD WID W; Kennedy L., 2006, MULT INF RETR WORKSH, P2006; Li L.-J., 2007, CVPR; Li Xiaowei, 2008, ECCV, P2; Li Y., 2009, ICCV; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Ni K., 2007, ICCV; Nister D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17; Nister D., 2006, CVPR; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Palmer S. E., 1981, ATTENTION PERFORM, V9, P135; Philbin J., 2008, P IND C COMP VIS GRA; Philbin J., 2008, CVPR; Raguram R., 2008, ECCV; Raguram R., 2008, WORKSH INT VIS CVPR; Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414; Schroff F., 2007, ICCV; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Sigurbjornsson B, 2008, WWW; Simon I., 2007, ICCV; Snavely N., 2008, CVPR; Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; Sontag S., 1977, PHOTOGRAPHY CLASSICS; Torralba A., 2008, CVPR; Torresani L., 2010, CVPR; Van Gool, 2008, P INT C CONT BAS IM, P47, DOI DOI 10.1145/1386352.1386363; Weinshall D., 1994, IM UND WORKSH; Zheng Y.T., 2009, CVPR	46	41	41	0	26	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	2011	95	3					213	239		10.1007/s11263-011-0445-z	http://dx.doi.org/10.1007/s11263-011-0445-z			27	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	913AD		Green Submitted			2022-12-18	WOS:000301842800001
J	Yerushalmy, I; Hel-Or, H				Yerushalmy, Ido; Hel-Or, Hagit			Digital Image Forgery Detection Based on Lens and Sensor Aberration	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Image forgery; Camera based forgery detection; Chromatic aberration; Lens artifacts; Purple blooming; Lateral chromatic aberration		A new approach to detecting forgery in digital photographs is suggested. The method does not necessitate adding data to the image (such as a Digital Watermark) nor require other images for comparison or training. The fundamental assumption in the presented approach is the notion that image features arising from the image acquisition process itself or due to the physical structure and characteristics of digital cameras, are inherent proof of authenticity and they are sensitive to image manipulation as well as being difficult to forge synthetically. Typically, such features do not affect image content nor quality and are often invisible to the inexperienced eye. The approach presented in this work is based on the effects introduced in the acquired image by the optical and sensing systems of the camera. Specifically, it exploits image artifacts that are due to chromatic aberrations as indicators for evaluating image authenticity.	[Yerushalmy, Ido; Hel-Or, Hagit] Univ Haifa, Dept Comp Sci, IL-31999 Haifa, Israel	University of Haifa	Hel-Or, H (corresponding author), Univ Haifa, Dept Comp Sci, IL-31999 Haifa, Israel.	ido.yerushalmy@gmail.com; hagit@cs.haifa.ac.il						Born M., 1999, PRINCIPLES OPTICS EL, DOI [10.1017/CBO9781139644181, DOI 10.1017/CBO9781139644181]; Criminisi A, 2008, P BRIT MACH VIS C; CUTZU F, 2003, P IEEE C COMP VIS PA; DALY D, 2001, MICROLENS ARRAYS; Fridrich J., 2003, DIG FOR RES WORKSH, P1; Gonzalez R.C., 2006, DIGITAL IMAGE PROCES; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; Jahne B., 2005, DIGITAL IMAGE PROCES; Jenkins F. A., 2001, FUNDAMENTALS OPTICS, V4th; Johnson M. K., 2006, P ACM MULT SEC WORKS; Johnson M.K., 2005, P ACM MULTIMEDIA SEC, P1, DOI [DOI 10.1145/1073170.1073171, DOI 10.1145/0731701073171]; Lyu S, 2005, IEEE T SIGNAL PROCES, V53, P845, DOI 10.1109/TSP.2004.839896; LYU S, 2004, P NAT AC SCI; Muller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5; NEGAHDARIPOUR S, 1989, COMPUT VISION GRAPH, V46, P303, DOI 10.1016/0734-189X(89)90035-2; Ochi S., 1997, CHARGE COUPLED DEVIC; PARR R, 2006, DIGITAL PHOTOGRAPHY; Pedrotti F., 2006, INTRO OPTICS; Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P3948, DOI 10.1109/TSP.2005.855406; Ray S. F., 2002, APPL PHOTOGRAPHIC OP, DOI 10.4324/9780080499253; Rousseeuw PJ, 2003, ROBUST REGRESSION OU; RUDOLF K, 1992, OPTICS PHOTOGRAPHY; Smith W. J., 2007, MODERN OPTICAL ENG, V4th; Szummer M., 1998, P IEEE INT WORKSH CO; VANWALREE P, 2009, PHOTOGRAPHIC OPTICS; Vapnik V.N, 2000, NATURE STAT LEARNING, V2nd; WANG W, 2006, P ACM MULT SEC WORKS; WOLFGANG RB, 1996, P IEEE INT C IM PROC; Wyszecki G., 2000, COLOR SCI CONCEPTS M, V2nd	30	41	48	1	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2011	92	1					71	91		10.1007/s11263-010-0403-1	http://dx.doi.org/10.1007/s11263-010-0403-1			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	729GH					2022-12-18	WOS:000287936200004
J	Lian, ZH; Rosin, PL; Sun, XF				Lian, Zhouhui; Rosin, Paul L.; Sun, Xianfang			Rectilinearity of 3D Meshes	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Rectilinearity; Shape measurement; 3D shape retrieval; Pose normalization	MODEL RETRIEVAL; SHAPE; CIRCULARITY; ELLIPTICITY	In this paper, we propose and evaluate a novel shape measure describing the extent to which a 3D polygon mesh is rectilinear. The rectilinearity measure is based on the maximum ratio of the surface area to the sum of three orthogonal projected areas of the mesh. It has the following desirable properties: 1) the estimated rectilinearity is always a number from (0,1]; 2) the measure is invariant under scale, rotation, and translation; 3) the 3D objects can be either open or closed meshes, and we can also deal with degenerate meshes; 4) the measure is insensitive to noise, stable under small topology errors, and robust against face deletion and mesh simplification. Moreover, a genetic algorithm (GA) can be applied to compute the approximate rectilinearity efficiently. We find that the calculation of rectilinearity can be used to normalize the pose of 3D meshes, and in many cases it performs better than the principal component analysis (PCA) based method. By applying a simple selection criterion, the combination of these two methods results in a new pose normalization algorithm which not only provides a higher successful alignment rate but also corresponds better with intuition. Finally, we carry out several experiments showing that both the rectilinearity based pose normalization preprocessing and the combined signatures, which consist of the rectilinearity measure and other shape descriptors, can significantly improve the performance of 3D shape retrieval.	[Lian, Zhouhui; Sun, Xianfang] Beihang Univ, Sch Automat Sci & Elect Engn, Beijing, Peoples R China; [Lian, Zhouhui; Rosin, Paul L.; Sun, Xianfang] Cardiff Univ, Cardiff Sch Comp Sci, Cardiff, S Glam, Wales	Beihang University; Cardiff University	Lian, ZH (corresponding author), Beihang Univ, Sch Automat Sci & Elect Engn, Beijing, Peoples R China.	lianzhouhui@yahoo.com.cn; Paul.Rosin@cs.cardiff.ac.uk; Xianfang.Sun@cs.cardiff.ac.uk	Lian, Zhouhui/D-8432-2012; Sun, Xianfang/D-2346-2010	Sun, Xianfang/0000-0002-6114-0766; Rosin, Paul/0000-0002-4965-3884	China Scholarship Council; NSFC [60674030]	China Scholarship Council(China Scholarship Council); NSFC(National Natural Science Foundation of China (NSFC))	This work was supported by China Scholarship Council and NSFC Grant 60674030.	Ankerst M, 1999, Proc Int Conf Intell Syst Mol Biol, P34; Bribiesca E, 2008, PATTERN RECOGN, V41, P543, DOI 10.1016/j.patcog.2007.06.029; Bustos B, 2006, INT J DIGIT LIBRARIE, V6, P39, DOI 10.1007/s00799-005-0122-3; CHAOUCH M, 2008, P IEEE INT C SHAP MO, P187; CHAOUCH M, 2006, P IEEE INT C SHAP MO, P36; CHAOUCH M, 2007, P ICIP 07, V6, P373; Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669; Corney J, 2002, IEEE COMPUT GRAPH, V22, P65, DOI 10.1109/MCG.2002.999789; Fink E, 1996, INFORM SCIENCES, V92, P175, DOI 10.1016/0020-0255(96)00056-4; FU H, 2008, P INT C COMP GRAPH I; Gal R, 2007, IEEE T VIS COMPUT GR, V13, P261, DOI 10.1109/TVCG.2007.45; HARALICK RM, 1974, IEEE T SYST MAN CYB, VSMC4, P394, DOI 10.1109/TSMC.1974.5408463; Holland JH, 1992, ADAPTATION NATURAL A, DOI DOI 10.7551/MITPRESS/1090.001.0001; Kazhdan M., 2003, Symposium on Geometry Processing, P156; Kazhdan M, 2004, ALGORITHMICA, V38, P201, DOI 10.1007/s00453-003-1050-5; Kazhdan M, 2007, IEEE T PATTERN ANAL, V29, P1221, DOI 10.1109/TPAMI.2007.1032; Krinidis S, 2008, IEEE T IMAGE PROCESS, V17, P1007, DOI 10.1109/TIP.2008.922415; Laga H, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P75; Lee CH, 2005, ACM T GRAPHIC, V24, P659, DOI 10.1145/1073204.1073244; LEOU JJ, 1987, PATTERN RECOGN, V20, P571, DOI 10.1016/0031-3203(87)90028-8; Levin DT, 2001, PERCEPT PSYCHOPHYS, V63, P676, DOI 10.3758/BF03194429; Lian Zhouhui, 2008, P 1 ACM INT C MULT I, P395, DOI 10.1145/1460096.1460161; Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2; OHBUCHI R, 2006, P WSCG 2006; Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648; Paquet E, 2000, SIGNAL PROCESS-IMAGE, V16, P103, DOI 10.1016/S0923-5965(00)00020-5; Paquet E, 1999, IMAGE VISION COMPUT, V17, P157, DOI 10.1016/S0262-8856(98)00119-X; Petitjean M., 2003, Entropy, V5, DOI 10.3390/e5030271; Podolak J, 2006, ACM T GRAPHIC, V25, P549, DOI 10.1145/1141911.1141923; PROFFITT D, 1982, PATTERN RECOGN, V15, P383, DOI 10.1016/0031-3203(82)90041-3; Rosin PL, 2008, COMPUT VIS IMAGE UND, V109, P176, DOI 10.1016/j.cviu.2007.09.010; Rosin PL, 2003, MACH VISION APPL, V14, P172, DOI 10.1007/s00138-002-0118-6; Rosin PL, 1999, MACH VISION APPL, V11, P191, DOI 10.1007/s001380050101; RUGGERI MR, 2008, P EUR WORKS IN PRESS; Shih JL, 2007, PATTERN RECOGN, V40, P283, DOI 10.1016/j.patcog.2006.04.034; Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504; Shilane P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1243980.1243981; Sundar H, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P130, DOI 10.1109/smi.2003.1199609; Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0; Tangelder JWH, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P119; Vazquez PP, 2003, COMPUT GRAPH FORUM, V22, P689, DOI 10.1111/j.1467-8659.2003.00717.x; Vranic D., 2005, P IEEE INT C MULT EX; Vranic DV, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P293, DOI 10.1109/MMSP.2001.962749; Yamauchi H, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P265; Yang YB, 2007, IEEE T SYST MAN CY C, V37, P1081, DOI 10.1109/TSMCC.2007.905756; Zhang C, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P935, DOI 10.1109/ICIP.2001.958278; Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008; Zunic J, 2004, IEEE T PATTERN ANAL, V26, P923, DOI 10.1109/TPAMI.2004.19; Zunic J, 2003, IEEE T PATTERN ANAL, V25, P1193, DOI 10.1109/TPAMI.2003.1227997; [No title captured]; 2004, SPHARMONICKIT2 7; 2008, STANFORD 3D SCANNING	52	41	42	2	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2010	89	2-3			SI		130	151		10.1007/s11263-009-0295-0	http://dx.doi.org/10.1007/s11263-009-0295-0			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	594OS					2022-12-18	WOS:000277547600002
J	Bougleux, S; Elmoataz, A; Melkemi, M				Bougleux, Sebastien; Elmoataz, Abderrahim; Melkemi, Mahmoud			Local and Nonlocal Discrete Regularization on Weighted Graphs for Image and Mesh Processing	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Discrete variational problems on graphs; Discrete diffusion processes; Smoothing; Denoising; Simplification	TOTAL VARIATION MINIMIZATION; DIFFUSION; EQUATIONS; SURFACES; FILTER; COLOR	We propose a discrete regularization framework on weighted graphs of arbitrary topology, which unifies local and nonlocal processing of images, meshes, and more generally discrete data. The approach considers the problem as a variational one, which consists in minimizing a weighted sum of two energy terms: a regularization one that uses the discrete p-Dirichlet form, and an approximation one. The proposed model is parametrized by the degree p of regularity, by the graph structure and by the weight function. The minimization solution leads to a family of simple linear and nonlinear processing methods. In particular, this family includes the exact expression or the discrete version of several neighborhood filters, such as the bilateral and the nonlocal means filter. In the context of images, local and nonlocal regularizations, based on the total variation models, are the continuous analog of the proposed model. Indirectly and naturally, it provides a discrete extension of these regularization methods for any discrete data or functions.	[Bougleux, Sebastien] ENSICAEN, Equipe Image, CNRS, GREYC,UMR 6072, F-14050 Caen, France; [Elmoataz, Abderrahim] Univ Caen, Equipe Image, CNRS, GREYC,UMR 6072, F-14050 Caen, France; [Melkemi, Mahmoud] Univ Haute Alsace, LMIA, Equipe MAGE, F-68093 Mulhouse, France	Centre National de la Recherche Scientifique (CNRS); Universite de Caen Normandie; Centre National de la Recherche Scientifique (CNRS); Universite de Caen Normandie; Universites de Strasbourg Etablissements Associes; Universite de Haute-Alsace (UHA)	Bougleux, S (corresponding author), ENSICAEN, Equipe Image, CNRS, GREYC,UMR 6072, 6 Bd Marechal Juin, F-14050 Caen, France.	sebastien.bougleux@greyc.ensicaen.fr; abder@greyc.ensicaen.fr; mahmoud.melkemi@uha.fr	Bougleux, Sébastien/AAG-6982-2019	Bougleux, Sébastien/0000-0002-4581-7570				ALVAREZ L, 1993, ARCH RATION MECH AN, V123, P199, DOI 10.1007/BF00375127; Arbelaez PA, 2004, J MATH IMAGING VIS, V20, P43, DOI 10.1023/B:JMIV.0000011318.77653.44; Aubert G., 2006, MATH PROBLEMS IMAGE; Bajaj CL, 2003, ACM T GRAPHIC, V22, P4, DOI 10.1145/588272.588276; Barash D, 2002, IEEE T PATTERN ANAL, V24, P844, DOI 10.1109/TPAMI.2002.1008390; Bensoussan A, 2005, J CONVEX ANAL, V12, P13; Bobenko Alexander I, 2005, EUR S GEOM PROC, P101; BOUGLEUX S, 2007, 4 INT S VOR DIAGR SC, P48; BOUGLEUX S, 2005, LNCS, V3656, P745; Bougleux S, 2007, LECT NOTES COMPUT SC, V4485, P128; BROX T, 2007, LNCS, V4485, P12; Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024; Chambolle A, 2005, LECT NOTES COMPUT SC, V3757, P136, DOI 10.1007/11585978_10; Chan T., 2005, IMAGE PROCESSING ANA; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P231, DOI 10.1109/83.902288; CHUNG F, 1997, CBMS REG C SER MATH, V92, P1; Clarenz U, 2000, IEEE VISUAL, P397, DOI 10.1109/VISUAL.2000.885721; COIFMAN R, 2006, P SPIE, V6232; COIFMAN R, 2005, P NATL ACAD SCI, V102; Cvetkovic DM., 1980, SPECTRA GRAPHS THEOR; Darbon J, 2004, LECT NOTES COMPUT SC, V3322, P548; Desbrun M, 2000, PROC GRAPH INTERF, P145; Fleishman S, 2003, ACM T GRAPHIC, V22, P950, DOI 10.1145/882262.882368; GILBOA G, 2007, 0723 UCLA; Gilboa G, 2007, MULTISCALE MODEL SIM, V6, P595, DOI 10.1137/060669358; Griffin LD, 2000, P ROY SOC A-MATH PHY, V456, P2995, DOI 10.1098/rspa.2000.0650; Hein M, 2007, J MACH LEARN RES, V8, P1325; Hildebrandt K, 2004, COMPUT GRAPH FORUM, V23, P391, DOI 10.1111/j.1467-8659.2004.00770.x; Jones TR, 2003, ACM T GRAPHIC, V22, P943, DOI 10.1145/882262.882367; Kervrann C, 2007, LECT NOTES COMPUT SC, V4485, P520; Kimmel R, 2000, INT J COMPUT VISION, V39, P111, DOI 10.1023/A:1008171026419; KINDERMANN S, 2005, SIAM MULTISCALE MODE, V4, P1091; LEE JS, 1983, COMPUT VISION GRAPH, V24, P255, DOI 10.1016/0734-189X(83)90047-6; Lezoray O, 2007, COMPUT VIS IMAGE UND, V107, P38, DOI 10.1016/j.cviu.2006.11.015; Lopez-Perez L, 2004, LECT NOTES COMPUT SC, V3117, P135; Meila M, 2001, ADV NEUR IN, V13, P873; Meyer F, 2001, INT J PATTERN RECOGN, V15, P1089, DOI 10.1142/S0218001401001337; Mrazek P, 2006, COMP IMAG VIS, P335; OSHER S, 2000, ANAL COMPUTATIONAL M, P751; Paragios N., 2005, HDB MATH MODELS COMP; Paris S, 2007, SIGGRAPH 07 ACM SIGG; PEYRE G, 2008, SIAM MULTISCALE MODE, V7, P731; Requardt M, 1998, J PHYS A-MATH GEN, V31, P7997, DOI 10.1088/0305-4470/31/39/014; REQUARDT M, 1997, NEW APPROACH FUNCTIO; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710; Sochen N, 2001, J MATH IMAGING VIS, V14, P195, DOI 10.1023/A:1011277827470; SZLAM AD, 2006, YALEDCSTR1365; Tasdizen T, 2003, ACM T GRAPHIC, V22, P1012, DOI 10.1145/944020.944024; Taubin G, 1995, P SIGGRAPH, V95, P351, DOI DOI 10.1145/218380.218473; Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815; Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1; Xu GL, 2004, COMPUT AIDED GEOM D, V21, P767, DOI 10.1016/j.cagd.2004.07.007; YAGOU H, 2002, P GEOM MOD PROC GMP, P195; Yoshizawa S, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P38; Zhou DY, 2005, LECT NOTES COMPUT SC, V3663, P361	57	41	41	0	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2009	84	2					220	236		10.1007/s11263-008-0159-z	http://dx.doi.org/10.1007/s11263-008-0159-z			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	451NO					2022-12-18	WOS:000266477100008
J	Banno, A; Masuda, T; Oishi, T; Ikeuchi, K				Banno, A.; Masuda, T.; Oishi, T.; Ikeuchi, K.			Flying laser range sensor for large-scale site-modeling and its applications in Bayon digital archival projectl	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						large-scale 3D scenes; cultural sites; moving range sensors; alignment; shape rectification	REGISTRATION; AFFINE	We have been conducting a project to digitize the Bayon temple, located at the center of Angkor-Thom in the kingdom of Cambodia. This is a huge structure, more than 150 meters long on all sides and up to 45 meters high. Digitizing such a large-scale object in fine detail requires developing new types of sensors for obtaining data of various kinds related to irregular positions such as the very high parts of the structure occluded from the ground. In this article, we present a sensing system with a moving platform, referred to as the Flying Laser Range Sensor (FLRS), for obtaining data related to these high structures from above them. The FLRS, suspended beneath a balloon, can be maneuvered freely in the sky and can measure structures invisible from the ground. The obtained data, however, has some distortion due to the movement of the sensor during the scanning process. In order to remedy this issue, we have developed several new rectification algorithms for the FLRS. One method is an extension of the 3D alignment algorithm to estimate not only rotation and translation but also motion parameters. This algorithm compares range data of overlapping regions from ground-based sensors and our FLRS. Another method accurately estimates the FLRS's position by combining range data and image sequences from a video camera mounted on the FLRS. We evaluate these algorithms using a IS-based method and verify that both methods achieve much higher accuracy than previous methods.	[Banno, A.; Masuda, T.] Univ Tokyo, Grad Sch Informat Sci & Technol, Meguro Ku, Tokyo 1538505, Japan; [Oishi, T.; Ikeuchi, K.] Univ Tokyo, Grad Sch Interdisciplinary Informat Studies, Meguro Ku, Tokyo 1538505, Japan	University of Tokyo; University of Tokyo	Banno, A (corresponding author), Univ Tokyo, Grad Sch Informat Sci & Technol, Meguro Ku, 4-6-1 Komaba, Tokyo 1538505, Japan.	vanno@cvl.iis.u-tokyo.ac.jp; tom@cvl.iis.u-tokyo.ac.jp; oishi@cvl.iis.u-tokyo.ac.jp; ki@cvl.iis.u-tokyo.ac.jp	Banno, Atsuhiko/K-7254-2016	Banno, Atsuhiko/0000-0002-6394-5947; Oishi, Takeshi/0000-0002-2010-2608				Banno A, 2005, IEEE I CONF COMP VIS, P792; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BROWN D, 1976, 13 C ISPRS HELS; Christy S, 1996, IEEE T PATTERN ANAL, V18, P1098, DOI 10.1109/34.544079; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269; Feldmar J, 1996, INT J COMPUT VISION, V18, P99, DOI 10.1007/BF00054998; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; HAHNEL D, 2003, P INT JOINT C ART IN; HAN M, 1999, CMURITR9922; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; HIROTA Y, 2004, P 6 AS C COMP VIS AC, V2, P658; Ikeuchi K., 2003, P 2 IEEE ACM INT S M; Jacobs D. A. H., 1977, STATE ART NUMERICAL; JAIN V, 2007, IN PRESS INT J SHAPE; Kawakami R, 2005, IEEE I CONF COMP VIS, P1200; Kurazume R., 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P99; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030; Masuda T, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P369, DOI 10.1109/3DIM.2005.74; MATSUI K, 2005, INT C INT ROB SYST I; MILLER R, 1998, 5 INT C INT AUT SYST; MIYAZAKI D, 2005, P 6 INT C VIRT SYST, P138; Morevec H.P., 1977, INT JOINT C ART INT, V2, P584; Nishino K., 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P454; Oishi T, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P476, DOI 10.1109/3DIM.2005.41; Oishi T, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P195, DOI 10.1109/IM.2003.1240250; Polak E., 1971, COMPUTATIONAL METHOD; Press W. H., 1988, NUMERICAL RECIPES; Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423; Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710; Stoer J, 2013, INTRO NUMERICAL ANAL; Szeliski R, 1996, INT J COMPUT VISION, V18, P171, DOI 10.1007/BF00055001; Thrun S., 2003, P 4 INT C FIELD SERV; WHEELER MD, 1995, IEEE T PATTERN ANAL, V17, P252, DOI 10.1109/34.368190; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149; [No title captured]	37	41	41	0	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2008	78	2-3					207	222		10.1007/s11263-007-0104-6	http://dx.doi.org/10.1007/s11263-007-0104-6			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	275RK		Green Submitted			2022-12-18	WOS:000254089100006
J	Todorovic, S; Ahuja, N				Todorovic, Sinisa; Ahuja, Narendra			Region-based hierarchical image matching	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						image matching; edit-distance graph matching; many-to-many matching; maximum subtree isomorphism; segmentation trees; transitive closures; association graphs; maximum weight cliques	ATTRIBUTED RELATIONAL GRAPHS; INTEGRATED EDGE; SEGMENTATION; RECOGNITION	This paper presents an approach to region-based hierarchical image matching, where, given two images, the goal is to identify the largest part in image 1 and its match in image 2 having the maximum similarity measure defined in terms of geometric and photometric properties of regions ( e. g., area, boundary shape, and color), as well as region topology ( e. g., recursive embedding of regions). To this end, each image is represented by a tree of recursively embedded regions, obtained by a multiscale segmentation algorithm. This allows us to pose image matching as the tree matching problem. To overcome imaging noise, one-to-one, many-to-one, and many-to-many node correspondences are allowed. The trees are first augmented with new nodes generated by merging adjacent sibling nodes, which produces directed acyclic graphs (DAGs). Then, transitive closures of the DAGs are constructed, and the tree matching problem reformulated as finding a bijection between the two transitive closures on DAGs, while preserving the connectivity and ancestor-descendant relationships of the original trees. The proposed approach is validated on real images showing similar objects, captured under different types of noise, including differences in lighting conditions, scales, or viewpoints, amidst limited occlusion and clutter.	[Todorovic, Sinisa; Ahuja, Narendra] Univ Illinois, Beckman Inst Adv Sci & Technol, Comp Vis & Robot Lab, Urbana, IL 61801 USA	University of Illinois System; University of Illinois Urbana-Champaign	Todorovic, S (corresponding author), Univ Illinois, Beckman Inst Adv Sci & Technol, Comp Vis & Robot Lab, 405 N Mathews Ave, Urbana, IL 61801 USA.	sintod@vision.ai.uiuc.edu; ahuja@vision.ai.uiuc.edu						Ahuja N, 1996, IEEE T PATTERN ANAL, V18, P1211, DOI 10.1109/34.546258; ARORA H, 2006, ICPR; Barrow H. G., 1976, Information Processing Letters, V4, P83, DOI 10.1016/0020-0190(76)90049-1; Basri R, 1997, INT J COMPUT VISION, V25, P145, DOI 10.1023/A:1007919917506; Bomze IM, 2000, IEEE T NEURAL NETWOR, V11, P1228, DOI 10.1109/72.883403; BOMZE IM, 1999, HDB COMBINATORIAL S, VA, P1; Bunke H, 1983, PATTERN RECOGN LETT, V1, P245, DOI 10.1016/0167-8655(83)90033-8; Bunke H, 2000, PATTERN RECOGN LETT, V21, P163, DOI 10.1016/S0167-8655(99)00143-9; Cohen L., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P416, DOI 10.1109/CVPR.1989.37880; Cohen S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1076, DOI 10.1109/ICCV.1999.790393; Demirci MF, 2004, LECT NOTES COMPUT SC, V3021, P322; ESHERA MA, 1986, IEEE T PATTERN ANAL, V8, P604, DOI 10.1109/TPAMI.1986.4767835; Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185; Fuh C.-S., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P130, DOI 10.1109/CVPR.1989.37840; Glantz R, 2004, INT J PATTERN RECOGN, V18, P397, DOI 10.1142/S0218001404003265; Golland P, 2000, PROC CVPR IEEE, P10, DOI 10.1109/CVPR.2000.855792; Keselman Y, 2005, IEEE T PATTERN ANAL, V27, P1141, DOI 10.1109/TPAMI.2005.139; Keselman Y, 2003, PROC CVPR IEEE, P850; LIU T, 1999, P 7 IEEE INT C COMP, V1, P456; MEDIONI G, 1985, COMPUT VISION GRAPH, V31, P2, DOI 10.1016/S0734-189X(85)80073-6; MOTZKIN TS, 1965, CANADIAN J MATH, V17, P533, DOI 10.4153/CJM-1965-053-6; PARDALOS PM, 1994, J GLOBAL OPTIM, V4, P301, DOI 10.1007/BF01098364; Pelillo M, 1999, NEURAL COMPUT, V11, P1933, DOI 10.1162/089976699300016034; Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105; Pelillo M, 2002, IEEE T PATTERN ANAL, V24, P1535, DOI 10.1109/TPAMI.2002.1046176; PELILLO M, 2001, LECT NOTES COMPUTER, V2059, P583; PERRIN B, 1998, P ACCV 98 JAN, V2, P323; Randriamasy S., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P736, DOI 10.1109/CVPR.1991.139806; RICHARD WC, 2005, IEEE T PATTERN ANAL, V27, P1112; Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P59, DOI 10.1109/ICCV.1998.710701; SANFELIU A, 1983, IEEE T SYST MAN CYB, V13, P353, DOI 10.1109/TSMC.1983.6313175; Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shokoufandeh A, 2005, IEEE T PATTERN ANAL, V27, P1125, DOI 10.1109/TPAMI.2005.142; Sonka M., 2014, IMAGE PROCESSING ANA; Tabb M, 1997, IEEE T IMAGE PROCESS, V6, P642, DOI 10.1109/83.568922; Torsello A, 2006, IEEE T PATTERN ANAL, V28, P954, DOI 10.1109/TPAMI.2006.125; Torsello A, 2005, IEEE T PATTERN ANAL, V27, P1087, DOI 10.1109/TPAMI.2005.146; Torsello A, 2002, LECT NOTES COMPUT SC, V2352, P822; Torsello A, 2003, PATTERN RECOGN LETT, V24, P1089, DOI 10.1016/S0167-8655(02)00255-6; TSAI WH, 1979, IEEE T SYST MAN CYB, V9, P757, DOI 10.1109/TSMC.1979.4310127; UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778; Yang MH, 2002, IEEE T PATTERN ANAL, V24, P1061, DOI 10.1109/TPAMI.2002.1023803; Yang XG, 1999, IEEE T IMAGE PROCESS, V8, P332, DOI 10.1109/83.748889	44	41	43	0	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2008	78	1					47	66		10.1007/s11263-007-0077-5	http://dx.doi.org/10.1007/s11263-007-0077-5			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	270YE					2022-12-18	WOS:000253755300004
J	Schechner, YY; Nayar, SK				Schechner, YY; Nayar, SK			Generalized mosaicing: High dynamic range in a wide field of view	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						sensors; inverse problems; image fusion; mosaicing; mosaicking; machine vision; physics based vision; SNR; vignetting; panorama	IMAGE MOSAICS	We present an approach that significantly enhances the capabilities of traditional image mosaicking. The key observation is that as a camera moves, it senses each scene point multiple times. We rigidly attach to the camera an optical filter with spatially varying properties, so that multiple measurements are obtained for each scene point under different optical settings. Fusing the data captured in the multiple images yields an image mosaic that includes additional information about the scene. We refer to this approach as generalized mosaicing. In this paper we show that this approach can significantly extend the optical dynamic range of any given imaging system by exploiting vignetting effects. We derive the optimal vignetting configuration and implement it using an external filter with spatially varying transmittance. We also derive efficient scene sampling conditions as well as ways to self calibrate the vignetting effects. Maximum likelihood is used for image registration and fusion. In an experiment we mounted such a filter on a standard 8-bit video camera, to obtain an image panorama with dynamic range comparable to imaging with a 16-bit camera.	Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel; Columbia Univ, Dept Comp Sci, New York, NY 10027 USA	Technion Israel Institute of Technology; Columbia University	Schechner, YY (corresponding author), Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel.							Aggarwal M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P2, DOI 10.1109/ICCV.2001.937492; BALLARD RD, 2001, NATL GEOGR, V199, P61; BATSON RM, 1987, PHOTOGRAMM ENG REM S, V53, P1211; BERNSTEIN R, 1976, IBM J RES DEV, V20, P40, DOI 10.1147/rd.201.0040; Burt P. J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P173, DOI 10.1109/ICCV.1993.378222; BURT PJ, 1983, ACM T GRAPHIC, V2, P217, DOI 10.1145/245.247; Capel D, 1998, PROC CVPR IEEE, P885, DOI 10.1109/CVPR.1998.698709; CHAPRA SC, 1998, NUMERICAL METHODS EN, P443; Coorg S, 2000, INT J COMPUT VISION, V37, P259, DOI 10.1023/A:1008184124789; CURLANDER JC, 1984, IEEE T GEOSCI REMOTE, V22, P106, DOI 10.1109/TGRS.1984.350601; DAVIS A, 1998, TECHONLINE REV, V2; Debevec P., 1997, P ACM SIGGRAPH 1997, DOI [DOI 10.1145/258734.258884, 10.1145/258734.258884]; Duplaquet ML, 1998, P SOC PHOTO-OPT INS, V3387, P369, DOI 10.1117/12.316427; Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574; *EDM IND OPT, 2002, E41960 EDM IND OPT, P89; Eustice R, 2002, PROCEEDINGS OF THE 2002 INTERNATIONAL SYMPOSIUM ON UNDERWATER TECHNOLOGY, P141, DOI 10.1109/UT.2002.1002415; Fardo A, 2002, IEEE IMAGE PROC, P633; Farid H, 1998, J OPT SOC AM A, V15, P1777, DOI 10.1364/JOSAA.15.001777; Fattal R, 2002, ACM T GRAPHIC, V21, P249; Garcia R, 2001, IEEE INT CONF ROBOT, P2779, DOI 10.1109/ROBOT.2001.933043; Grossberg MD, 2002, LECT NOTES COMPUT SC, V2353, P189; Hansen M., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P54, DOI 10.1109/ACV.1994.341288; Hsu S, 2002, IEEE COMPUT GRAPH, V22, P44, DOI 10.1109/38.988746; Irani M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P959, DOI 10.1109/ICCV.1998.710832; Irani M, 1998, P IEEE, V86, P905, DOI 10.1109/5.664279; Irani M, 1996, SIGNAL PROCESS-IMAGE, V8, P327, DOI 10.1016/0923-5965(95)00055-0; Kang S.B., 2000, P ECCV, P640; Khoo IC, 1999, OPT EXPRESS, V4, P432, DOI 10.1364/OE.4.000432; KWOK R, 1990, INT J REMOTE SENS, V11, P209, DOI 10.1080/01431169008955014; LADA CJ, 1991, ASTROPHYS J, V374, P533, DOI 10.1086/170142; Landy M.S., 1991, COMPUTATIONAL MODELS; Larson GW, 1997, IEEE T VIS COMPUT GR, V3, P291, DOI 10.1109/2945.646233; Mann S, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P193, DOI 10.1109/ICIP.1996.560417; MANN S, 1995, IS&T'S 48TH ANNUAL CONFERENCE - IMAGING ON THE INFORMATION SUPERHIGHWAY, FINAL PROGRAM AND PROCEEDINGS, P442; Marshall JA, 1996, J OPT SOC AM A, V13, P681, DOI 10.1364/JOSAA.13.000681; Mitsunaga T., P 1999 IEEE COMP SOC, P374; Nayar SK, 2000, PROC CVPR IEEE, P472, DOI 10.1109/CVPR.2000.855857; Negahdaripour S, 1998, PROCEEDINGS OF THE 1998 WORKSHOP ON AUTONOMOUS UNDERWATER VEHICLES, (AUV '98), P191, DOI 10.1109/AUV.1998.744455; OGIERS W, 1997, P60280MSRP002 IMEC 1; Peleg S, 2001, IEEE T PATTERN ANAL, V23, P279, DOI 10.1109/34.910880; RAJAGOPALAN AN, 1995, P INT C IM PROC WASH, V3, P636; REYNOSO EM, 1995, ASTRON J, V110, P318, DOI 10.1086/117522; Sawhney HS, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P56; Schechner YY, 2002, IEEE T PATTERN ANAL, V24, P1334, DOI 10.1109/TPAMI.2002.1039205; Schechner YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P17, DOI 10.1109/ICCV.2001.937494; SCHWARTZ J, 1999, PHOTONICS SPECTR SEP; SHARMA RK, 1997, SOC INFORMATION DISP, V28, P951; Shum HY, 2000, INT J COMPUT VISION, V36, P101, DOI 10.1023/A:1008195814169; Smolic A, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P872, DOI 10.1109/ICIP.2001.958259; Socolinsky D. A., 2000, Proceedings of the IASTED International Conference. Signal and Image Processing, P349; SODERBLOM LA, 1978, ICARUS, V34, P446, DOI 10.1016/0019-1035(78)90037-4; Surya G., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P61, DOI 10.1109/CVPR.1993.340978; Tabiryan N, 2002, LASER FOCUS WORLD, V38, P105; Thevenaz P, 2000, IEEE T IMAGE PROCESS, V9, P2083, DOI 10.1109/83.887976; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; USON JM, 1990, SCIENCE, V250, P539, DOI 10.1126/science.250.4980.539; Vasavada AR, 1998, ICARUS, V135, P265, DOI 10.1006/icar.1998.5984; Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918	59	41	52	0	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL-AUG	2003	53	3					245	267		10.1023/A:1023082924255	http://dx.doi.org/10.1023/A:1023082924255			23	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	678DY					2022-12-18	WOS:000182850800003
J	Pajdla, T				Pajdla, T			Stereo with oblique cameras	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						non-central camera; stereo panorama; epipolar geometry; spread		Mosaics acquired by pushbroom cameras, stereo panoramas, omnivergent mosaics, and spherical mosaics can be viewed as images taken by non-central cameras, i.e. cameras that project along rays that do not all intersect at one point. It has been shown that in order to reduce the correspondence search in mosaics to a one-parametric search along curves, the rays of the non-central cameras have to lie in double ruled epipolar surfaces. In this work, we introduce the oblique stereo geometry, which has non-intersecting double ruled epipolar surfaces. We analyze the configurations of mutually oblique rays that see every point in space. These configurations, called oblique cameras, are the most non-central cameras among all cameras. We formulate the assumption under which two oblique cameras posses oblique stereo geometry and show that the epipolar surfaces are non-intersecting double ruled hyperboloids and two lines. We show that oblique cameras, and the corresponding oblique stereo geometry, exist and give an example of a physically realizable oblique stereo geometry. We introduce linear oblique cameras as those which can be generated by a linear mapping from points in space to camera rays and characterize those collineations which generate them. We show that all linear oblique cameras are obtained by a collineation from one example of an oblique camera. Finally, we relate oblique cameras to spreads known from incidence geometries.	Czech Tech Univ, Fac Elect Engn, Dept Cybernet, Ctr Machine Percept, Prague 12135 2, Czech Republic	Czech Technical University Prague	Pajdla, T (corresponding author), Czech Tech Univ, Fac Elect Engn, Dept Cybernet, Ctr Machine Percept, Karlovo Nam 13, Prague 12135 2, Czech Republic.	pajdla@cmp.felk.cvut.cz	Pajdla, Tomas/K-7954-2013	Pajdla, Tomas/0000-0001-6325-0072				BUEKENHOUT E, 1995, HDB INCIDENCE GEOMET; FRIEDBERG SH, 1997, LINEAR ALGEBRA; Gupta R, 1997, IEEE T PATTERN ANAL, V19, P963, DOI 10.1109/34.615446; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Hazewinkel M., 1995, ENCY MATH, V1; Hilbert D., 1999, GEOMETRY IMAGINATION, V2; Hirschfeld J., 1998, OXFORD MATH MONOGRAP; Knarr N, 1995, LECT NOTES MATH, V1611; KOHOUT V, 2001, COMMUNICATION; Nayar SK, 2000, PROC CVPR IEEE, P388; Pajdla T, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P85, DOI 10.1109/SMBV.2001.988766; PAJDLA T, 2001, CTRCMP200114 RR; PAJDLA T, 2001, CTUCMP200110 RR; PAJDLA T, 2001, COMP VIS WINT WORKSH, P223; Peleg S, 2001, IEEE T PATTERN ANAL, V23, P279, DOI 10.1109/34.910880; RADEMACHER P, 1998, SIGGRAPH 98, P199; Seitz SM, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P26, DOI 10.1109/ICCV.2001.937495; SHUM H, 1999, ICCV99, P22; WATANABE M, 1996, ECCV96, V2, P439; [No title captured]	20	41	41	1	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR-JUN	2002	47	1-3					161	170		10.1023/A:1014593824520	http://dx.doi.org/10.1023/A:1014593824520			10	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	530JN					2022-12-18	WOS:000174354700012
J	Sato, T; Kanbara, M; Yokoya, N; Takemura, H				Sato, T; Kanbara, M; Yokoya, N; Takemura, H			Dense 3-D reconstruction of an outdoor scene by hundreds-baseline stereo using a hand-held video camera	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						3-D model reconstruction; monocular image sequence; marker; natural feature; multi-baseline stereo		Three-dimensional (3-D) models of outdoor scenes are widely used for object recognition, navigation, mixed reality, and so on. Because such models are often made manually with high costs, automatic 3-D reconstruction has been widely investigated. In related work, a dense 3-D model is generated by using a stereo method. However, such approaches cannot use several hundreds images together for dense depth estimation because it is difficult to accurately calibrate a large number of cameras. In this paper, we propose a dense 3-D reconstruction method that first estimates extrinsic camera parameters of a hand-held video camera, and then reconstructs a dense 3-D model of a scene. In the first process, extrinsic camera parameters are estimated by tracking a small number of predefined markers of known 3-D positions and natural features automatically. Then, several hundreds dense depth maps obtained by multi-baseline stereo are combined together in a voxel space. So, we can acquire a dense 3-D model of the outdoor scene accurately by using several hundreds input images captured by a hand-held video camera.	Nara Inst Sci & Technol, Grad Sch Informat Sci, Nara 6300101, Japan; Osaka Univ, Cybermedia Ctr, Osaka 5600048, Japan	Nara Institute of Science & Technology; Osaka University	Sato, T (corresponding author), Nara Inst Sci & Technol, Grad Sch Informat Sci, 8916-5 Takayama, Nara 6300101, Japan.	tomoka-s@is.aist-nara.ac.jp; masay-ka@is.aist-nara.ac.jp; yokoya@is.aist-nara.ac.jp; takemura@cmc.osaka-u.ac.jp	Takemura, Haruo/AAG-9369-2019; Kanbara, Masayuki/ABD-7780-2021	Takemura, Haruo/0000-0002-4645-6439				BARNARD ST, 1982, COMPUT SURV, V14, P553, DOI 10.1145/356893.356896; Beardsley PA, 1997, INT J COMPUT VISION, V23, P235, DOI 10.1023/A:1007923216416; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Kumar R, 2000, IEEE IMAGE PROC, P17, DOI 10.1109/ICIP.2000.900881; Morris DD, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P696, DOI 10.1109/ICCV.1998.710793; OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639; OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955; POLEMAN J, 1993, CMUCS93219; Pollefeys M, 2000, PROC SPIE, V3958, P215, DOI 10.1117/12.380044; ROTH G, 2000, P 13 INT C VIS INT, P87; Sato T., 2001, P 14 INT C VIS INT, P157; Sawhney HS, 1999, IEEE WORKSHOP ON MULTI-VIEW MODELING & ANALYSIS OF VISUAL SCENES (MVIEW'99). PROCEEDINGS, P21, DOI 10.1109/MVIEW.1999.781079; Schmid C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P230, DOI 10.1109/ICCV.1998.710723; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Tsai R.Y., 1986, P IEEE C COMP VIS PA, P364; Yokoya N, 1999, IEICE T INF SYST, VE82D, P523; YOKOYA N, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL I, P642, DOI 10.1109/ICPR.1992.201643	17	41	42	0	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR-JUN	2002	47	1-3					119	129		10.1023/A:1014537706773	http://dx.doi.org/10.1023/A:1014537706773			11	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	530JN					2022-12-18	WOS:000174354700009
J	Ma, Y; Kosecka, J; Sastry, S				Ma, Y; Kosecka, J; Sastry, S			Linear differential algorithm for motion recovery: A geometric approach	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						differential epipolar constraint; differential essential matrix; optical flow; motion estimation	SUBSPACE METHODS; PROJECTIONS; FLOW	The aim of this paper is to explore a linear geometric algorithm for recovering the three dimensional motion of a moving camera from image velocities. Generic similarities and differences between the discrete approach and the differential approach are clearly revealed through a parallel development of an analogous motion estimation theory previously explored in Vieville, T. and Faugeras, O.D. 1995. In Proceedings of Fifth International Conference on Computer Vision, pp. 750-756; Zhuang, X. and Haralick, R.M. 1984. In Proceedings of the First International Conference on Artificial Intelligence Applications, pp. 366-375. We present a precise characterization of the space of differential essential matrices, which gives rise to a novel eigenvalue-decomposition-based 3D velocity estimation algorithm from the optical flow measurements. This algorithm gives a unique solution to the motion estimation problem and serves as a differential counterpart of the well-known SVD-based 3D displacement estimation algorithm for the discrete case. Since the proposed algorithm only involves linear algebra techniques, it may be used to provide a fast initial guess for more sophisticated nonlinear algorithms (Ma et al., 1998c. Electronic Research Laboratory Memorandum, UC Berkeley, UCB/ERL(M98/37)). Extensive simulation results are presented for evaluating the performance of our algorithm in terms of bias and sensitivity of the estimates with respect to different noise levels in image velocity measurements.	Univ Calif Berkeley, Elect Res Lab, Berkeley, CA 94720 USA	University of California System; University of California Berkeley	Ma, Y (corresponding author), Univ Calif Berkeley, Elect Res Lab, Berkeley, CA 94720 USA.	mayi@robotics.eecs.berkeley.edu; janka@robotics.eecs.berkeley.edu; sastry@robotics.eecs.berkeley.edu						BROOKS MJ, IN PRESS DETERMINING; BRUSS AR, 1983, COMPUT VISION GRAPH, V21, P3, DOI 10.1016/S0734-189X(83)80026-7; DANIILIDIS K, 1990, IMAGE VISION COMPUT, V8, P297, DOI 10.1016/0262-8856(90)80006-F; HEEGER DJ, 1992, INT J COMPUT VISION, V7, P95, DOI 10.1007/BF00128130; HUANG TS, 1989, IEEE T PATTERN ANAL, V11, P1310, DOI 10.1109/34.41368; JEPSON AD, 1993, SPATIAL VISION IN HUMANS AND ROBOTS, P39; KANATANI K, 1993, INT J COMPUT VISION, V11, P267, DOI 10.1007/BF01469345; Kanatani K., 1993, GEOMETRIC COMPUTATIO; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; LONGUETHIGGINS HC, 1986, PROC R SOC SER B-BIO, V227, P399, DOI 10.1098/rspb.1986.0030; MA Y, 1998, M9837 UCBERL; MA Y, 1998, M9864 UCBERL; MA Y, 1998, M9838 UCBERL; MAYBANK S, 1993, SPRINGER SERIES INFO; MCLAUCHLAN PF, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P314, DOI 10.1109/ICCV.1995.466923; Murray R. M., 1994, MATH INTRO ROBOTIC M; Ponce J, 1998, INT J COMPUT VISION, V28, P223, DOI 10.1023/A:1008053620575; Soatto S, 1996, IEEE T AUTOMAT CONTR, V41, P393, DOI 10.1109/9.486640; SOATTO S, UNPUB INT J COMPUTER; SUBBARAO M, 1985, 3RD WORKSH COMP VIS, P129; Tian TY, 1996, PROC CVPR IEEE, P315, DOI 10.1109/CVPR.1996.517091; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; TOSCANI G, 1986, P IEEE C ROB AUT, P221; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; VIEVILLE T, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P750, DOI 10.1109/ICCV.1995.466863; WAXMAN AM, 1987, INT J COMPUT VISION, V1, P239, DOI 10.1007/BF00127823; ZHUANG X, 1984, P 1 INT C ART INT AP, P366; ZHUANG XH, 1988, COMPUT VISION GRAPH, V42, P334, DOI 10.1016/S0734-189X(88)80043-4	28	41	41	0	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2000	36	1					71	89		10.1023/A:1008124507881	http://dx.doi.org/10.1023/A:1008124507881			19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	280DJ					2022-12-18	WOS:000085086700004
J	KANATANI, K				KANATANI, K			3-D INTERPRETATION OF OPTICAL-FLOW BY RENORMALIZATION	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							3-DIMENSIONAL MOTION PARAMETERS; MULTIPLE INTERPRETATIONS; CURVED SURFACES; IMAGE FLOW; OBJECTS; ALGORITHM; SCENE	This article studies 3-D interpretation of optical flow induced by a general camera motion relative to a surface of general shape. First, we describe, using the ''image sphere representation,'' an analytical procedure that yields an exact solution when the data are exact: we solve the epipolar equation written in terms of the essential parameters and the twisted optical flow. Introducing a simple model of noise, we then show that the solution is ''statistically biased.'' In order to remove the statistical bias, we propose an algorithm called renormalization, which automatically adjusts to unknown image noise. A brief discussion is also given to the critical surface that yields ambiguous 3-D interpretations and the use of the image plane representation.			KANATANI, K (corresponding author), GUNMA UNIV, DEPT COMP SCI, KIRYU, GUNMA 376, JAPAN.							ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; BRUSS AR, 1983, COMPUT VISION GRAPH, V21, P3, DOI 10.1016/S0734-189X(83)80026-7; DANIILIDIS K, 1990, IMAGE VISION COMPUT, V8, P297, DOI 10.1016/0262-8856(90)80006-F; DRESCHLER L, 1982, COMPUT VISION GRAPH, V20, P199, DOI 10.1016/0146-664X(82)90081-8; HEEGER DJ, 1992, INT J COMPUT VISION, V7, P95, DOI 10.1007/BF00128130; HORN BKP, 1987, INT J COMPUT VISION, V1, P259, DOI 10.1007/BF00127824; HORN BKP, 1990, INT J COMPUT VISION, V4, P59, DOI 10.1007/BF00137443; HUANG TS, 1989, IEEE T PATTERN ANAL, V11, P1310, DOI 10.1109/34.41368; Kanatani K., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P599, DOI 10.1109/ICCV.1993.378156; KANATANI K, 1991, CVGIP-IMAG UNDERSTAN, V54, P333, DOI 10.1016/1049-9660(91)90034-M; KANATANI K, 1993, IEEE T PATTERN ANAL, V15, P37, DOI 10.1109/34.184773; KANATANI K, IN PRESS IEEE T PATT; Kanatani K., 1993, GEOMETRIC COMPUTATIO; Kanatani Kenichi, 1990, GROUP THEORETICAL ME, P4; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; LONGUETHIGGINS HC, 1988, P ROY SOC LOND A MAT, V418, P1, DOI 10.1098/rspa.1988.0071; MAYBANK SJ, 1985, P ROY SOC LOND A MAT, V401, P317, DOI 10.1098/rspa.1985.0101; MAYBANK SJ, 1991, IMAGE VISION COMPUT, V9, P93, DOI 10.1016/0262-8856(91)90018-K; NEGAHDARIPOUR S, 1990, IEEE T PATTERN ANAL, V12, P1025, DOI 10.1109/34.61703; NEGAHDARIPOUR S, 1989, INT J COMPUT VISION, V3, P293, DOI 10.1007/BF00132601; PRAZDNY K, 1981, COMPUT VISION GRAPH, V17, P238, DOI 10.1016/0146-664X(81)90004-6; REIGER JH, 1984, J OPT SOC AM A, V2, P165; SUBBARAO M, 1988, INT J COMPUT VISION, V2, P77, DOI 10.1007/BF00836282; TAGAWA N, 1991, IEICE IE90108PRU9013, P23; TAGAWA N, IN PRESS IEICE T INF; TAGAWA N, 1993, IEICE IE92136PRU9215, P25; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; WAXMAN AM, 1987, INT J COMPUT VISION, V1, P239, DOI 10.1007/BF00127823; WENG JY, 1989, IEEE T PATTERN ANAL, V11, P451, DOI 10.1109/34.24779; YASUMOTO Y, 1986, IEEE T PATTERN ANAL, V8, P464, DOI 10.1109/TPAMI.1986.4767810; ZHUANG X, 1983, COMPUT VIS GRAPHICS, V21, P3	32	41	42	0	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	1993	11	3					267	282		10.1007/BF01469345	http://dx.doi.org/10.1007/BF01469345			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	MD681					2022-12-18	WOS:A1993MD68100003
J	HORN, BKP				HORN, BKP			MOTION FIELDS ARE HARDLY EVER AMBIGUOUS	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article									MIT,ARTIFICIAL INTELLIGENCE LAB,CAMBRIDGE,MA 02139; UNIV HAWAII MANOA,DEPT ELECT ENGN,HONOLULU,HI 96822	Massachusetts Institute of Technology (MIT); University of Hawaii System; University of Hawaii Manoa				/0000-0003-3434-391X				BRANDENBERGER A, 1947, THESIS EIDGENOSSISCH; BRUSS AR, 1983, COMPUT VISION GRAPH, V21, P3, DOI 10.1016/S0734-189X(83)80026-7; Gosh SK, 1972, THEORY STEREOPHOTOGR; HAY JC, 1966, PSYCHOL REV, V73, P550, DOI 10.1037/h0023863; Hilbert D., 1952, GEOMETRY IMAGINATION; HOFMANN W, 1949, THESIS TH MUNCHEN; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1987, UNPUB INT J COMP VIS, V1; KORN GA, 1972, MATH HDB ENG SCI; LONGUETHIGGINS HC, 1984, PROC R SOC SER B-BIO, V223, P165, DOI 10.1098/rspb.1984.0088; LONGUETHIGGINS HC, 1984, 1ST IEEE P C ART INT; MAYBANK SJ, 1985, P ROY SOC LOND A MAT, V401, P317, DOI 10.1098/rspa.1985.0101; MAYBANK SJ, 1984, 6TH P EUR C ART INT, P641; NEGAHDARIPOUR S, 1987, IEEE T PATTERN ANAL, V9, P168, DOI 10.1109/TPAMI.1987.4767884; NEGAHDARIPOUR S, 1986, THESIS MIT; SCHWIDEFSKY K, 1973, OUTLINE PHOTOGRAMMET; SUBBARAO M, 1985, IN PRESS COMPUTER VI; Tsai R. Y., 1984, IEEE T PAMI, V6; WAXMAN AM, 1986, CARTR190STR1633 U MA; Wolf P.R, 1983, ELEMENTS PHOTOGRAMME	20	41	43	0	0	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.		1987	1	3					259	274						16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	M2050					2022-12-18	WOS:A1987M205000005
J	Song, JK; He, T; Gao, LL; Xu, X; Hanjalic, A; Shen, HT				Song, Jingkuan; He, Tao; Gao, Lianli; Xu, Xing; Hanjalic, Alan; Shen, Heng Tao			Unified Binary Generative Adversarial Network for Image Retrieval and Compression	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Binary codes; Image retrieval; Image compression; Generative adversarial network	QUANTIZATION; CODES	Binary codes have often been deployed to facilitate large-scale retrieval tasks, but not that often for image compression. In this paper, we propose a unified framework, BGAN+, that restricts the input noise variable of generative adversarial networks to be binary and conditioned on the features of each input image, and simultaneously learns two binary representations per image: one for image retrieval and the other serving as image compression. Compared to related methods that attempt to learn a single binary code serving both purposes, we demonstrate that choosing for two codes leads to more effective representations due to less concessions needed when balancing the requirements. The added value of using a unified framework compared to two separate frameworks lies in the synergy in data representation that is beneficial for both learning processes. When devising this framework, we also address another challenge in learning binary codes, namely that of learning supervision. While the most striking successes in image retrieval using binary codes have mostly involved discriminative models requiring labels, the proposed BGAN+ framework learns the binary codes in an unsupervised fashion, yet more effectively than the state-of-the-art supervised approaches. The proposed BGAN+ framework is evaluated on three benchmark datasets for image retrieval and two datasets on image compression. The experimental results show that BGAN+ outperforms the existing retrieval methods with significant margins and achieves promising performance for image compression, especially for low bit rates.	[Song, Jingkuan; Gao, Lianli; Xu, Xing; Shen, Heng Tao] Univ Elect Sci & Technol China, Ctr Future Media, Chengdu 611731, Sichuan, Peoples R China; [Song, Jingkuan; Gao, Lianli; Xu, Xing; Shen, Heng Tao] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Sichuan, Peoples R China; [He, Tao] Monash Univ, Clayton, Vic 3800, Australia; [Hanjalic, Alan] Delft Univ Technol, Delft, Netherlands	University of Electronic Science & Technology of China; University of Electronic Science & Technology of China; Monash University; Delft University of Technology	Gao, LL; Shen, HT (corresponding author), Univ Elect Sci & Technol China, Ctr Future Media, Chengdu 611731, Sichuan, Peoples R China.; Gao, LL; Shen, HT (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Sichuan, Peoples R China.	jingkuan.song@gmail.com; tao.he@monash.edu; lianli.gao@uestc.edu.cn; xing.xu@uestc.edu.cn; a.hanjalic@tudelft.nl; shenhengtao@hotmail.com	Shen, Heng Tao/ABD-5331-2021	Hanjalic, Alan/0000-0002-5771-2549; song, jingkuan/0000-0002-2549-8322	Fundamental Research Funds for the Central Universities [ZYGX2019J073]; National Natural Science Foundation of China [61772116, 61872064, 61632007, 61602049]; Open Project of Zhejiang Lab [2019KD0AB05]	Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Open Project of Zhejiang Lab	This work is supported by the Fundamental Research Funds for the Central Universities (Grant No. ZYGX2019J073), the National Natural Science Foundation of China (Grant No. 61772116, No. 61872064, No.61632007, No. 61602049), The Open Project of Zhejiang Lab (Grant No.2019KD0AB05).	Agustsson E., 2017, ARXIV170400648 CORR; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2005, THESIS MIT CAMBRIDGE; Baig MH, 2017, ADV NEUR IN, V30; Balle Johannes, 2016, ARXIV161101704; Bellard M, 2017, BPG IMAGE FORMAT; Brown M, 2011, IEEE T PATTERN ANAL, V33, P43, DOI 10.1109/TPAMI.2010.54; Cao Y, 2018, PROC CVPR IEEE, P1287, DOI 10.1109/CVPR.2018.00140; Cao Y, 2016, AAAI CONF ARTIF INTE, P3457; Cao ZJ, 2017, IEEE I CONF COMP VIS, P5609, DOI 10.1109/ICCV.2017.598; Chua Tat-Seng, 2009, P ACM INT C IM VID R, P1, DOI DOI 10.1145/1646396.1646452; Collobert R., 2008, P 25 ICML, V25, P160, DOI DOI 10.1145/1390156.1390177; Dai B, 2017, PR MACH LEARN RES, V70; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deng L, 2013, IEEE INT NEW CIRC; Duan YQ, 2017, PROC CVPR IEEE, P4857, DOI 10.1109/CVPR.2017.516; Evgeniou A., 2007, ADV NEURAL INF PROCE, V19, P41, DOI DOI 10.2139/SSRN.1031158; Farvardin Nariman, 1994, IEEE T INFORM THEORY, V40, P287; Franzen Rich, 1999, KODAK LOSSLESS TRUE, V4; Gao LL, 2020, IEEE T PATTERN ANAL, V42, P1112, DOI 10.1109/TPAMI.2019.2894139; Ge TZ, 2014, LECT NOTES COMPUT SC, V8695, P250, DOI 10.1007/978-3-319-10584-0_17; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gong Y., 2012, ADV NEURAL INFORM PR, P1196; Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Google, 2017, WEBP COMPR TECHN; Grubb G, 2008, DISTRIBUTIONS OPERAT; Gu SM, 2013, INT CONF MACH LEARN, P108, DOI 10.1109/ICMLC.2013.6890453; Gu Y, 2016, P ACM MULT C, P272, DOI DOI 10.1145/2964284.2967225; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23; He T, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2477; Heo JP, 2015, IEEE T PATTERN ANAL, V37, P2304, DOI 10.1109/TPAMI.2015.2408363; Huiskes M. J., 2010, P INT C MULT INF RET, P527, DOI DOI 10.1145/1743384.1743475; Irie G, 2014, PROC CVPR IEEE, P2123, DOI 10.1109/CVPR.2014.272; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Jin ZM, 2013, IEEE I CONF COMP VIS, P257, DOI 10.1109/ICCV.2013.39; Khosla Aditya, 2011, 1 WORKSH FIN GRAIN V, P6; Kingma D.P, P 3 INT C LEARNING R; Kingma D. P., 2013, AUTO ENCODING VARIAT; Krizhevsky A, 2009, LEARNING MULTIPLE LA; Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947; Larsen ABL, 2016, PR MACH LEARN RES, V48; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Li MH, 2018, PROC CVPR IEEE, P6644, DOI 10.1109/CVPR.2018.00695; Li W., 2016, INT JOINT C ARTIFICI, P1711; Lin GS, 2014, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2014.253; Lin GS, 2013, IEEE I CONF COMP VIS, P2552, DOI 10.1109/ICCV.2013.317; Lin KV, 2016, PROC CVPR IEEE, P1183, DOI 10.1109/CVPR.2016.133; Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862; Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227; Liu L, 2017, PROC CVPR IEEE, P5140, DOI 10.1109/CVPR.2017.546; Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912; Liu XL, 2014, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2014.275; Long Mingsheng, 2015, ARXIV150602117; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lu YX, 2017, PROC CVPR IEEE, P1131, DOI 10.1109/CVPR.2017.126; Misra I, 2016, PROC CVPR IEEE, P3994, DOI 10.1109/CVPR.2016.433; Nemirovski A, 2009, SIAM J OPTIMIZ, V19, P1574, DOI 10.1137/070704277; Nilsback M-E., 2006, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2006., DOI 10.1109/CVPR.2006.42]; Norouzi M., 2011, INT C MACHINE LEARNI, P353; Norouzi M, 2013, PROC CVPR IEEE, P3017, DOI 10.1109/CVPR.2013.388; Odena A, 2016, DISTILL, DOI [10.23915/distill.00003.-URL, 10.23915/distill.00003]; Rabbani M, 2002, SIGNAL PROCESS-IMAGE, V17, P3, DOI 10.1016/S0923-5965(01)00024-8; Radford A., 2015, ARXIV PREPRINT ARXIV, DOI DOI 10.1051/0004-6361/201527329; Rippel O, 2017, PR MACH LEARN RES, V70; Ruder Sebastian, 2017, ARXIV170605098; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X; Shen FM, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P595, DOI 10.1145/3077136.3080767; Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598; Song J., 2013, P 2013 ACM SIGMOD IN, P785, DOI [10.1145/2463676.2465274, DOI 10.1145/2463676.2465274]; Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077; Song Jingkuan, 2018, AAAI; Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103; Do TT, 2016, LECT NOTES COMPUT SC, V9909, P219, DOI 10.1007/978-3-319-46454-1_14; Theis Lucas, 2017, INT C LEARN REPR; Toderici G., 2016, ARXIV160805148; Toderici George, 2015, ARXIV151106085; Todeschini G, 2017, INVENTIONS-BASEL, V2, DOI 10.3390/inventions2030014; WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089; Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326; Wang J, 2010, MICROOPTICS AND NANOOPTICS FABRICATION, P127; Wang Jianfeng, 2013, P 21 ACM INT C MULTI, P133; Wang J, 2017, IEEE INFOCOM SER, DOI 10.1007/s12083-017-0556-6; Wang J, 2013, IEEE I CONF COMP VIS, P3032, DOI 10.1109/ICCV.2013.377; Wang X., 2016, P AS C COMP VIS, P70; Wang Z, 2003, CONF REC ASILOMAR C, P1398; Weiss P, 2008, INT CONF ACOUST SPEE, P1173, DOI 10.1109/ICASSP.2008.4517824; WINTZ PA, 1972, PR INST ELECTR ELECT, V60, P809, DOI 10.1109/PROC.1972.8780; Xia RK, 2014, AAAI CONF ARTIF INTE, P2156; Yuan X, 2018, LECT NOTES COMPUT SC, V11208, P141, DOI 10.1007/978-3-030-01225-0_9; Zhang PC, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P173, DOI 10.1145/2600428.2609600; Zhao F, 2015, PROC CVPR IEEE, P1556, DOI 10.1109/CVPR.2015.7298763; Zhu H, 2016, AAAI CONF ARTIF INTE, P2415; Zieba M, 2018, ADV NEUR IN, V31	95	40	41	1	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2020	128	8-9			SI		2243	2264		10.1007/s11263-020-01305-2	http://dx.doi.org/10.1007/s11263-020-01305-2		FEB 2020	22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	MZ8HG		Green Submitted			2022-12-18	WOS:000516304300003
J	Paulin, M; Mairal, J; Douze, M; Harchaoui, Z; Perronnin, F; Schmid, C				Paulin, Mattis; Mairal, Julien; Douze, Matthijs; Harchaoui, Zaid; Perronnin, Florent; Schmid, Cordelia			Convolutional Patch Representations for Image Retrieval: An Unsupervised Approach	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Low-level image description; Instance-level retrieval; Convolutional Neural Networks	SCALE	Convolutional neural networks (CNNs) are able to model local stationary structures in natural images in a multi-scale fashion, when learning all model parameters with supervision. While excellent performance was achieved for image classification when large amounts of labeled visual data are available, their success for unsupervised tasks such as image retrieval has been moderate so far.Our paper focuses on this latter setting and explores several methods for learning patch descriptors without supervision with application to matching and instance-level retrieval. To that effect, we propose a new family of patch representations, based on the recently introduced convolutional kernel networks. We show that our descriptor, named Patch-CKN, performs better than SIFT as well as other convolutional networks learned by artificially introducing supervision and is significantly faster to train. To demonstrate its effectiveness, we perform an extensive evaluation on standard benchmarks for patch and image retrieval where we obtain state-of-the-art results. We also introduce a new dataset called RomePatches, which allows to simultaneously study descriptor performance for patch and image retrieval.	[Paulin, Mattis; Mairal, Julien; Schmid, Cordelia] Inria Grenoble, Lab Jean Kuntzmann, Thoth Team, Rhone Alpes, Montbonnot St M, France; [Douze, Matthijs; Perronnin, Florent] Facebook AI Res, Menlo Pk, CA USA; [Harchaoui, Zaid] NYU, New York, NY USA	UDICE-French Research Universities; Communaute Universite Grenoble Alpes; Institut National Polytechnique de Grenoble; Universite Grenoble Alpes (UGA); Centre National de la Recherche Scientifique (CNRS); Inria; Facebook Inc; New York University	Paulin, M (corresponding author), Inria Grenoble, Lab Jean Kuntzmann, Thoth Team, Rhone Alpes, Montbonnot St M, France.	mattis.paulin@inria.fr	Mairal, Julien/AAL-5611-2021		"Allegro" (ERC); "Titan" (CNRS-Mastodons); "Macaron" [ANR-14-CE23-0003-01]; CIFAR; Xerox Research Center Europe; NVIDIA Corporation	"Allegro" (ERC); "Titan" (CNRS-Mastodons); "Macaron"; CIFAR(Canadian Institute for Advanced Research (CIFAR)); Xerox Research Center Europe; NVIDIA Corporation	This work was partially supported by projects "Allegro" (ERC), "Titan" (CNRS-Mastodons), "Macaron" (ANR-14-CE23-0003-01), CIFAR, and a Xerox Research Center Europe collaboration contract. We wish to thank Fischer et al. (2014), Babenko et al. (2014), and Gong et al. (2014), Herve Jegou, Ben Recht, for their helpful discussions and comments. We gratefully acknowledge the support of NVIDIA Corporation with the donation of the GPUs used for this research.	Agrawal P., 2015, IEEE C COMP VIS PATT; Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207; Babenko A, 2015, IEEE I CONF COMP VIS, P1269, DOI 10.1109/ICCV.2015.150; Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38; Bach FR, 2003, J MACH LEARN RES, V3, P1, DOI 10.1162/153244303768966085; Bay H., 2006, EUR C COMP VIS ECCV, P404, DOI [10.1007/11744023_32, DOI 10.1007/11744023_32]; Bottou Leon, 2012, NEURAL NETWORKS TRIC, P421, DOI [10.1007/978-3-642-35289-8_25, DOI 10.1007/978-3-642-35289-8_25]; Brown M, 2011, IEEE T PATTERN ANAL, V33, P43, DOI 10.1109/TPAMI.2010.54; Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56; Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202; Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172; Coates Adam, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P561, DOI 10.1007/978-3-642-35289-8_30; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Donahue J, 2014, PR MACH LEARN RES, V32; Dong JM, 2015, PROC CVPR IEEE, P5097, DOI 10.1109/CVPR.2015.7299145; Dosovitskiy A., 2014, ADV NEURAL INFORM PR, V27, P766, DOI [DOI 10.1109/TPAMI.2015.2496141, 10.48550/arXiv.1406.6909]; Erhan D., 2009, 20 INT C ART INT STA; Erhan D, 2010, J MACH LEARN RES, V11, P625; Fischer P, 2014, ARXIV14055769; Fox D., 2010, ADV NEURAL INFORM PR, V23, P244; Gong YC, 2014, LECT NOTES COMPUT SC, V8692, P529, DOI 10.1007/978-3-319-10593-2_35; Goroshin R., 2014, ADV NEURAL INFORM PR; Jayaraman D., 2015, IEEE C COMP VIS PATT; Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24; Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235; Jegou H, 2012, LECT NOTES COMPUT SC, V7573, P774, DOI 10.1007/978-3-642-33709-3_55; Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Jia Y., 2014, P 22 ACM INT C MULT, P675; Jiang W., 2014, IEEE C COMP VIS PATT; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y., 1989, ADV NEURAL INFORM PR, V2; Li YP, 2010, LECT NOTES COMPUT SC, V6312, P791; Long J.L., 2014, P C NEUR INF PROC SY, V27, P1601; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mairal J., 2014, FDN TRENDS COMPUTER; Mairal J., 2014, ADV NEURAL INFORM PR, V27, P2627; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Ng JYH., 2015, DEEPVISION WORKSH; Nister D, 2006, IEEE COMP SOC C COMP, V2, P2161, DOI DOI 10.1109/CVPR.2006.264; Paulin M, 2015, IEEE I CONF COMP VIS, P91, DOI 10.1109/ICCV.2015.19; Perd'och M, 2009, PROC CVPR IEEE, P9, DOI 10.1109/CVPRW.2009.5206529; Perronnin F, 2010, PROC CVPR IEEE, P2297, DOI 10.1109/CVPR.2010.5539914; Perronnin F, 2007, PROC CVPR IEEE, P2272; Peters J, 2017, ADAPT COMPUT MACH LE; Philbin J., 2010, EUR C COMP VIS; Philbin J, 2008, PROC CVPR IEEE, P2285; Rahimi A, 2007, PROC 20 INT C NEURAL, P1177, DOI DOI 10.5555/2981562.2981710; Razavian Ali Sharif, 2014, P IEEE C COMP VIS PA, P806, DOI DOI 10.1109/CVPRW.2014.131; Simo-Serra E, 2015, ICCV; Simonyan K, 2014, IEEE T PATTERN ANAL, V36, P1573, DOI 10.1109/TPAMI.2014.2301163; Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77; Tolias Giorgos, 2016, ARXIV151105879, P1; Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017; Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153; Wang ZH, 2011, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2011.6126294; Williams CKI, 2001, ADV NEUR IN, V13, P682; Winder S, 2009, PROC CVPR IEEE, P178, DOI 10.1109/CVPRW.2009.5206839; YOSINSKI J, 2014, ADV NEURAL INFORM PR, P3320, DOI DOI 10.1109/IJCNN.2016.7727519; ZAGORUYKO S, 2015, 2015 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2015.7299064; Zbontar J, 2015, PROC CVPR IEEE, P1592, DOI 10.1109/CVPR.2015.7298767	66	40	42	0	12	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2017	121	1					149	168		10.1007/s11263-016-0924-3	http://dx.doi.org/10.1007/s11263-016-0924-3			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	EI3HN		Green Submitted			2022-12-18	WOS:000392380900007
J	Vineet, V; Warrell, J; Torr, PHS				Vineet, Vibhav; Warrell, Jonathan; Torr, Philip H. S.			Filter-Based Mean-Field Inference for Random Fields with Higher-Order Terms and Product Label-Spaces	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Object class segmentation; Dense stereo reconstruction; Mean-field methods; Higher order potentials; Bilateral filters; CRF	MULTICLASS	Recently, a number of cross bilateral filtering methods have been proposed for solving multi-label problems in computer vision, such as stereo, optical flow and object class segmentation that show an order of magnitude improvement in speed over previous methods. These methods have achieved good results despite using models with only unary and/or pairwise terms. However, previous work has shown the value of using models with higher-order terms e. g. to represent label consistency over large regions, or global co-occurrence relations. We show how these higher-order terms can be formulated such that filter-based inference remains possible. We demonstrate our techniques on joint stereo and object labelling problems, as well as object class segmentation, showing in addition for joint object-stereo labelling how our method provides an efficient approach to inference in product label-spaces. We show that we are able to speed up inference in these models around 10-30 times with respect to competing graph-cut/move-making methods, as well as maintaining or improving accuracy in all cases. We showresults on PascalVOC-10 for object class segmentation, and Leuven for joint object-stereo labelling.	[Vineet, Vibhav] Oxford Brookes Univ, Oxford OX3 0BP, England; [Warrell, Jonathan] MIAS CSIR, Pretoria, South Africa; [Torr, Philip H. S.] Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England	Oxford Brookes University; University of Oxford	Vineet, V (corresponding author), Oxford Brookes Univ, Oxford OX3 0BP, England.	vibhav.vineet-2010@brookes.ac.uk; jwarrell@csir.co.za; philip.torr@eng.ox.ac.uk			EPSRC; IST programme of the European Community, under the PAS-CAL2 Network of Excellence; Royal Society Wolfson Research Merit Award; Engineering and Physical Sciences Research Council [EP/I001107/1] Funding Source: researchfish; EPSRC [EP/I001107/1] Funding Source: UKRI	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); IST programme of the European Community, under the PAS-CAL2 Network of Excellence; Royal Society Wolfson Research Merit Award(Royal Society of London); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	We thank Paul Sturgess for his discussion on SIFT-flow based initialization. The work was supported by the EPSRC and the IST programme of the European Community, under the PAS-CAL2 Network of Excellence. Professor Philip H. S. Torr is in receipt of a Royal Society Wolfson Research Merit Award.	Adams A, 2010, COMPUT GRAPH FORUM, V29, P753, DOI 10.1111/j.1467-8659.2009.01645.x; Bai X., 2007, ICCV; Bleyer M., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3081, DOI 10.1109/CVPR.2011.5995581; Bleyer M, 2012, LECT NOTES COMPUT SC, V7576, P467, DOI 10.1007/978-3-642-33715-4_34; Borenstein E., 2006, CVPR, V1, P969, DOI DOI 10.1109/CVPR.2006.276; Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114; Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Criminisi A, 2008, LECT NOTES COMPUT SC, V5302, P99, DOI 10.1007/978-3-540-88682-2_9; Everingham M., 2011, PASCAL VISUAL OBJECT; Galleguillos C., 2008, CVPR; Gastal ESL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964964; Goldluecke B, 2010, LECT NOTES COMPUT SC, V6315, P225, DOI 10.1007/978-3-642-15555-0_17; Gonfaus J. M., 2010, IEEE CVPR; Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233; Koller D., 2009, PROBABILISTIC GRAPHI; Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200; Komodakis Nikos, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2985, DOI 10.1109/CVPRW.2009.5206846; Komodakis N, 2011, IEEE T PATTERN ANAL, V33, P531, DOI 10.1109/TPAMI.2010.108; Krahenbuhl P., 2011, ADV NEURAL INF PROCE, V24, P109; Kumar M. P., 2008, P ANN C NEUR INF PRO, P889; Kumar M. P., 2007, IEEE CVPR; Kumar MP, 2011, J MACH LEARN RES, V12, P31; Kumar MP, 2005, PROC CVPR IEEE, P18; Ladicky L., 2010, BMVC, P1; Ladicky L., 2010, ECCV; Ladicky L, 2009, IEEE I CONF COMP VIS, P739, DOI 10.1109/ICCV.2009.5459248; Ladicky L, 2010, LECT NOTES COMPUT SC, V6315, P239, DOI 10.1007/978-3-642-15555-0_18; Lan X., 2009, ECCV, P269; Liu C., 2008, EUR C COMP VIS ECCV; LIU CJ, 2009, CVPR; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Paris S, 2008, FOUND TRENDS COMPUT, V4, P1, DOI 10.1561/0600000020; Payet N., 2010, NIPS; Potetz B, 2008, COMPUT VIS IMAGE UND, V112, P39, DOI 10.1016/j.cviu.2008.05.007; Rabinovich A., 2007, ICCV; Rhemann C, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995372; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Rother C., 2009, CVPR; Rother C, 2009, PROC CVPR IEEE, P1382, DOI 10.1109/CVPRW.2009.5206739; Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1; Singaraju D., 2008, CVPR; Torralba A, 2007, IEEE T PATTERN ANAL, V29, P854, DOI 10.1109/TPAMI.2007.1055; Toyoda T, 2008, IEEE T PATTERN ANAL, V30, P1483, DOI 10.1109/TPAMI.2008.105; Turner R. E., 2011, BAYESIAN TIME SERIES, P109; VEKSLER O, 2007, CVPR; Weiss Y, 2001, NEU INF PRO, P229; Woodford O, 2009, IEEE T PATTERN ANAL, V31, P2115, DOI 10.1109/TPAMI.2009.131	48	40	44	0	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	2014	110	3			SI		290	307		10.1007/s11263-014-0708-6	http://dx.doi.org/10.1007/s11263-014-0708-6			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AT2HL					2022-12-18	WOS:000344754500005
J	Avrithis, Y; Tolias, G				Avrithis, Yannis; Tolias, Giorgos			Hough Pyramid Matching: Speeded-Up Geometry Re-ranking for Large Scale Image Retrieval	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Image retrieval; Spatial verification; Relaxed spatial matching; Hough pyramid matching; Geometric re-ranking	FEATURES; MODEL	Exploiting local feature shape has made geometry indexing possible, but at a high cost of index space, while a sequential spatial verification and re-ranking stage is still indispensable for large scale image retrieval. In this work we investigate an accelerated approach for the latter problem. We develop a simple spatial matching model inspired by Hough voting in the transformation space, where votes arise from single feature correspondences. Using a histogram pyramid, we effectively compute pair-wise affinities of correspondences without ever enumerating all pairs. Our Hough pyramid matching algorithm is linear in the number of correspondences and allows for multiple matching surfaces or non-rigid objects under one-to-one mapping. We achieve re-ranking one order of magnitude more images at the same query time with superior performance compared to state of the art methods, while requiring the same index space. We show that soft assignment is compatible with this matching scheme, preserving one-to-one mapping and further increasing performance.	[Avrithis, Yannis; Tolias, Giorgos] Natl Tech Univ Athens, Zografos, Greece	National Technical University of Athens	Tolias, G (corresponding author), Natl Tech Univ Athens, Iroon Polytexneiou 9, Zografos, Greece.	iavr@image.ntua.gr; gtolias@image.ntua.gr	Tolias, Giorgos/O-9939-2017	Tolias, Giorgos/0000-0002-9570-3870				[Anonymous], 2006, P 2006 IEEE COMP SOC; Avrithis Y., 2010, FEATURE MAP HASHING; Avrithis Y., 2010, RETRIEVING LANDMARK; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Bay H., 2006, ECCV; Belongie S., 2000, NIPS, V12, P827; Berg A.C., 2005, CVPR; Cao Y, 2010, PROC CVPR IEEE, P3352, DOI 10.1109/CVPR.2010.5540021; Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P2089, DOI 10.1109/TPAMI.2007.1126; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568; Chum O., 2007, ICCV; Enqvist O., 2009, ICCV; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Grauman K, 2007, J MACH LEARN RES, V8, P725; Indyk Piotr, 2003, WORKSHOP STAT COMPUT; Jegou H., 2009, CVPR; Jegou H., 2008, ECCV; Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57; Jiang H., 2009, CVPR, P2399; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482; Lin Z, 2010, LECT NOTES COMPUT SC, V6316, P294, DOI 10.1007/978-3-642-15567-3_22; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikulik A., 2010, ECCV; Olsson Carl, 2007, CVPR, P2; Perdoch M., 2009, CVPR; Philbin J., 2007, CVPR; Philbin J., 2008, CVPR; Raguram R., 2011, ICCV; Sahbi H., 2008, CVPR; SCOTT GL, 1991, P ROY SOC B-BIOL SCI, V244, P21, DOI 10.1098/rspb.1991.0045; Shen X, 2012, C COMP VIS PATT REC, DOI DOI 10.1109/CVPR.2012.6248031; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; Tolias G., 2011, ICCV; Vedaldi A., 2008, CVPR; Vedaldi Andrea, 2008, ECCV; WU Z, 2009, CVPR; Zhang YM, 2011, PROC CVPR IEEE, P809, DOI 10.1109/CVPR.2011.5995528; Zhou W, 2010, SPATIAL CODING LARGE	39	40	45	0	12	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2014	107	1					1	19		10.1007/s11263-013-0659-3	http://dx.doi.org/10.1007/s11263-013-0659-3			19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AB2RT		Green Submitted			2022-12-18	WOS:000331640500001
J	Yan, T; Lau, RWH; Xu, Y; Huang, LS				Yan, Tao; Lau, Rynson W. H.; Xu, Yun; Huang, Liusheng			Depth Mapping for Stereoscopic Videos	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Stereoscopic videos; Depth mapping; Image warping; Video processing	SYSTEM	Stereoscopic videos have become very popular in recent years. Most of these videos are developed primarily for viewing on large screens located at some distance away from the viewer. If we watch these videos on a small screen located near to us, the depth range of the videos will be seriously reduced, which can significantly degrade the 3D effects of these videos. To address this problem, we propose a linear depth mapping method to adjust the depth range of a stereoscopic video according to the viewing configuration, including pixel density and distance to the screen. Our method tries to minimize the distortion of stereoscopic image contents after depth mapping, by preserving the relationship of neighboring features and preventing line and plane bending. It also considers the depth and motion coherences. While depth coherence ensures smooth changes of the depth field across frames, motion coherence ensures smooth content changes across frames. Our experimental results show that the proposed method can improve the stereoscopic effects while maintaining the quality of the output videos.	[Yan, Tao; Xu, Yun; Huang, Liusheng] Univ Sci & Technol China, Hefei 230026, Peoples R China; [Yan, Tao; Lau, Rynson W. H.] City Univ Hong Kong, Kowloon Tong, Hong Kong, Peoples R China	Chinese Academy of Sciences; University of Science & Technology of China, CAS; City University of Hong Kong	Lau, RWH (corresponding author), City Univ Hong Kong, Kowloon Tong, Hong Kong, Peoples R China.	yantao@mail.ustc.edu.cn; rynson.lau@cityu.edu.hk; xuyun@ustc.edu.cn; lshuang@ustc.edu.cn	Yan, Tao/AAA-3884-2020	Yan, Tao/0000-0002-9162-8551; LAU, Rynson W H/0000-0002-8957-8129	Research Grants Council of Hong Kong (RGC) [CityU 116010]; City University of Hong Kong [7002768]	Research Grants Council of Hong Kong (RGC)(Hong Kong Research Grants Council); City University of Hong Kong(City University of Hong Kong)	We would like to thank Qingxiong Yang for some useful suggestions and some insightful discussions on issues related to our work, and Antoni Chan for some comments. We would also like to thank Manuel Lang for helping produce some test videos using their system. The work presented in this paper was partially supported by a GRF grant from the Research Grants Council of Hong Kong (RGC Reference Number: CityU 116010) and a SRG grant from City University of Hong Kong (Project Number: 7002768).	Bouguet Jean yves, 2000, PYRAMIDAL IMPLEMENTA, P1; Chang CH, 2011, IEEE T MULTIMEDIA, V13, P589, DOI 10.1109/TMM.2011.2116775; Chauvier L., 2010, IBC C; CORMACK R, 1985, PERCEPT PSYCHOPHYS, V38, P375, DOI 10.3758/BF03207166; Guttmann M, 2009, IEEE I CONF COMP VIS, P136, DOI 10.1109/ICCV.2009.5459158; Heinzle S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964989; Koppal SJ, 2011, IEEE COMPUT GRAPH, V31, P20, DOI 10.1109/MCG.2010.37; Lambooij M, 2011, DISPLAYS, V32, P209, DOI 10.1016/j.displa.2011.05.012; Lambooij M, 2009, J IMAGING SCI TECHN, V53, DOI 10.2352/J.ImagingSci.Technol.2009.53.3.030201; Lang M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778812; Liao M., 2011, IEEE T VISUALIZATION, V17, P2035; Lin H., 2011, ACM SIGGRAPH ASIA SK; Liu C.W., 2011, P 19 ACM INT C MULT, P253; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Niu YZ, 2010, PROC CVPR IEEE, P537, DOI 10.1109/CVPR.2010.5540169; Smolic A, 2011, P IEEE, V99, P607, DOI 10.1109/JPROC.2010.2098350; Takeda T, 1999, VISION RES, V39, P2087, DOI 10.1016/S0042-6989(98)00258-2; Wang J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330512; Wang L., 2008, 2008 IEEE C COMPUTER, P1; Wang YS, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964983; Ward B, 2011, IEEE COMPUT GRAPH, V31, P36, DOI 10.1109/MCG.2010.103; Zilly F, 2011, P IEEE, V99, P590, DOI 10.1109/JPROC.2010.2095810	22	40	44	0	15	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2013	102	1-3					293	307		10.1007/s11263-012-0593-9	http://dx.doi.org/10.1007/s11263-012-0593-9			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	097VO		hybrid			2022-12-18	WOS:000315501800017
J	Csurka, G; Perronnin, F				Csurka, Gabriela; Perronnin, Florent			An Efficient Approach to Semantic Segmentation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Image segmentation; Object recognition; Pattern recognition; Fisher kernel; PASCAL VOC		We consider the problem of semantic segmentation, i.e. assigning each pixel in an image to a set of pre-defined semantic object categories. State-of-the-art semantic segmentation algorithms typically consist of three components: a local appearance model, a local consistency model and a global consistency model. These three components are generally integrated into a unified probabilistic framework. While it enables at training time a joint estimation of the model parameters and while it ensures at test time a globally consistent labeling of the pixels, it also comes at a high computational cost. We propose a simple approach to semantic segmentation where the three components are decoupled (this journal submission is an extended version of the following conference paper: G. Csurka and F. Perronnin, "A simple high performance approach to semantic segmentation", BMVC, 2008). For the local appearance model, we make use of the Fisher kernel. While this framework was shown to lead to high accuracy for image classification, to our best knowledge this is its first application to the segmentation problem. The semantic segmentation process is then guided by a low-level segmentation which enforces local consistency. Finally, to enforce image-level consistency we use global image classifiers: if an image as a whole is unlikely to contain an object class, then the corresponding class is not considered in the segmentation pipeline. The decoupling of the components makes our system very efficient both at training and test time. An efficient training enables to estimate the model parameters on large quantities of data. Especially, we explain how our system can leverage weakly labeled data, i.e. images for which we do not have pixel-level labels but either object bounding boxes or even only image-level labels. We believe that an important contribution of this paper is to show that even a simple decoupled system can provide state-of-the-art performance on the PASCAL VOC 2007, PASCAL VOC 2008 and MSRC 21 datasets.	[Csurka, Gabriela; Perronnin, Florent] Xerox Res Ctr Europe, F-38240 Meylan, France	Xerox	Perronnin, F (corresponding author), Xerox Res Ctr Europe, 6 Chemin Maupertuis, F-38240 Meylan, France.	Florent.Perronnin@xrce.xerox.com			French National Project Omnia [ANR-06-CIS6-01]	French National Project Omnia	This work was supported in part by the French National Project Omnia ANR-06-CIS6-01.	[Anonymous], 2007, PASCAL VISUAL OBJECT; BORENSTEIN E, 2006, CVPR 2006; CAO L, 2007, ICCV 2007; Csurka G., 2004, ECCV WORKSHOPS; EVERINGHAM M, 2007, PASCAL VISUAL OBJE 1; Everingham M., 2008, PASCAL VISUAL OBJECT; Farquhar J., 2005, TECHNICAL REPORT; HE X, 2004, CVPR 2004; JAAKKOLA T, 1999, NIPS 1999; Krishnapuram B, 2005, IEEE T PATTERN ANAL, V27, P957, DOI 10.1109/TPAMI.2005.127; KUMAR S, 2005, ICCV 2005; LARLUS D, 2007, VISAPP, V2; LARLUS D, 2009, IJCV; Lazebnik S., 2009, CVPR; Leibe B., 2004, STAT LEARNING COMPUT; Li L., 2009, CVPR 2009; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; MAJI S, 2008, CVPR 2008; Pawan Kumar M., 2005, CVPR 2005; PERRONNIN F, 2006, ECCV 2006; PERRONNIN F, 2007, CVPR 2007; ROTHER C, 2004, SIGRAPH 2004; SHEIKH YA, 2007, ICCV 2007; Shotton J., 2006, ECCV 2006; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; VEDALDI A, 2009, ICCV 2009; VEDALDI A, 2008, ECCV 2008; Verbeek J, 2007, NIPS 2007; Verbeek J, 2007, CVPR 2007; WANG G, 2009, ICCV 2009; WINN J, 2005, ICCV 2005; YANG L, 2007, CVPR 2007	32	40	50	3	27	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	2011	95	2					198	212		10.1007/s11263-010-0344-8	http://dx.doi.org/10.1007/s11263-010-0344-8			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	815YN					2022-12-18	WOS:000294566000006
J	Trinh, NH; Kimia, BB				Trinh, Nhon H.; Kimia, Benjamin B.			Skeleton Search: Category-Specific Object Recognition and Segmentation Using a Skeletal Shape Model	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Recognition; Segmentation; Skeleton; Shock graph; Dynamic programming; Generative shape model; Categorization; Top-down modeling	VISUAL FORM; APPEARANCE; REPRESENTATION; ALGORITHM; GRAPHS; PARTS	We describe a top-down object detection and segmentation approach that uses a skeleton-based shape model and that works directly on real images. The approach is based on three components. First, we propose a fragment-based generative model for shape that is based on the shock graph and has minimal dependency among its shape fragments. The model is capable of generating a wide variation of shapes as instances of a given object category. Second, we develop a progressive selection mechanism to search among the generated shapes for the category instances that are present in the image. The search begins with a large pool of candidates identified by a dynamic programming (DP) algorithm and progressively reduces it in size by applying series of criteria, namely, local minimum criterion, extent of shape overlap, and thresholding of the objective function to select the final object candidates. Third, we propose the Partitioned Chamfer Matching (PCM) measure to capture the support of image edges for a hypothesized shape. This measure overcomes the shortcomings of the Oriented Chamfer Matching and is robust against spurious edges, missing edges, and accidental alignment between the image edges and the shape boundary contour. We have evaluated our approach on the ETHZ dataset and found it to perform well in both object detection and object segmentation tasks.	[Trinh, Nhon H.] SRI Int Sarnoff, Princeton, NJ 08540 USA; [Kimia, Benjamin B.] Brown Univ, Providence, RI 02912 USA	SRI International; Brown University	Trinh, NH (corresponding author), SRI Int Sarnoff, 201 Washington Rd, Princeton, NJ 08540 USA.	nhon.trinh@sri.edu; kimia@lems.brown.edu			US National Foundation [NSF 0957045]	US National Foundation	The authors gratefully acknowledge the support of US National Foundation Grant NSF 0957045.	ADLURU N, 2005, ICC 05, V2, P1466; Adluru N, 2009, INT J COMPUT VISION, V83, P12, DOI 10.1007/s11263-009-0208-2; Amit Y, 1996, IEEE T PATTERN ANAL, V18, P225, DOI 10.1109/34.485529; BAI X, 2009, ICCV 09; Balan A. O., 2006, 2006 IEEE COMPUTER S, V1, P758; BARROW HG, 1977, P 5 INT JOINT C ART; Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558; Berg AC, 2005, PROC CVPR IEEE, P26; Bertele U., 1972, NONSERIAL DYNAMIC PR; Bishop C. M., 2006, J ELECT IMAG, V16, P140; Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2; Coughlan J, 2000, COMPUT VIS IMAGE UND, V78, P303, DOI 10.1006/cviu.2000.0842; Csurka G., 2004, ECCV INT WORKSH STAT; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Demirci MF, 2009, IEEE T PATTERN ANAL, V31, P944, DOI 10.1109/TPAMI.2008.267; Dorko G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P634; Everingham M, 2009, PASCAL VISUAL OBJECT; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Felzenszwalb PF, 2005, IEEE T PATTERN ANAL, V27, P208, DOI 10.1109/TPAMI.2005.35; FELZENSZWALB PF, 2007, CVPR 07; Fergus R, 2003, PROC CVPR IEEE, P264; Ferrari V, 2006, LECT NOTES COMPUT SC, V3953, P14, DOI 10.1007/11744078_2; Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144; Geman S, 2001, IEEE T INFORM THEORY, V47, P549, DOI 10.1109/18.910574; Giblin PJ, 2003, IEEE T PATTERN ANAL, V25, P895, DOI 10.1109/TPAMI.2003.1206518; Giblin PJ, 2003, INT J COMPUT VISION, V54, P143, DOI 10.1023/A:1023761518825; Gu CH, 2009, PROC CVPR IEEE, P1030, DOI 10.1109/CVPRW.2009.5206727; HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073; Jain V, 2007, COMPUT VIS IMAGE UND, V108, P230, DOI 10.1016/j.cviu.2006.11.024; Jiang XY, 2001, IEEE T PATTERN ANAL, V23, P1144; Jurie F, 2005, IEEE I CONF COMP VIS, P604; Jurie F, 2004, PROC CVPR IEEE, P90; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; KELLY MF, 1995, ICCV; Kimia B. B., 2003, International Journal of Computer Vision, V54, P159; Kimia B. B., 1991, THESIS MCGILL U MONT; KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741; Kimia BB, 2003, J PHYSIOL-PARIS, V97, P155, DOI 10.1016/j.jphysparis.2003.09.003; KIMIA BB, 1990, LECT NOTES COMPUT SC, V427, P402, DOI 10.1007/BFb0014889; KIMIA BB, 2009, OBJECT CATEGORIZATIO, P430; KOVESI PD, 2009, MATLAB OCTAVE FUNCTI; Kumar MP, 2005, PROC CVPR IEEE, P18; KUMAR MP, 2004, BMVC, P789; KUMAR MP, 2004, IND C COMP VIS GRAPH, P158; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Leibe B, 2004, LECT NOTES COMPUT SC, V3175, P145; LEORDEANU M, 2007, CVPR 07; Liang Lin, 2007, 2007 11th IEEE International Conference on Computer Vision, P1; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Maji S, 2009, PROC CVPR IEEE, P1038, DOI 10.1109/CVPRW.2009.5206693; Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mori G, 2005, IEEE I CONF COMP VIS, P1417; Nilsson D, 1998, STAT COMPUT, V8, P159, DOI 10.1023/A:1008990218483; Olson CF, 1997, IEEE T IMAGE PROCESS, V6, P103, DOI 10.1109/83.552100; OMMER B, 2009, ICCV 09; Opelt A., 2006, P IEEE C COMP VIS PA, P3; Opelt A, 2008, INT J COMPUT VISION, V80, P16, DOI 10.1007/s11263-008-0139-3; Opelt A, 2006, LECT NOTES COMPUT SC, V3952, P575; OZCANLI OC, 2006, CVPR 06, P935; Ozcanli Ozge C., 2007, P BIRT MACH VIS C, P1030; RAMANAN D, 2007, NIPS 06; Sala Pablo, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4562979; Sebastian T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P755, DOI 10.1109/ICCV.2001.937602; Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924; Selinger A, 1999, COMPUT VIS IMAGE UND, V76, P83, DOI 10.1006/cviu.1999.0788; Sharvit D, 1998, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES - PROCEEDINGS, P56, DOI 10.1109/IVL.1998.694496; SHOTTON J, 2005, ICCV, P281; Shotton J, 2008, IEEE T PATTERN ANAL, V30, P1270, DOI 10.1109/TPAMI.2007.70772; Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1; SIDDIQI K, 1995, IEEE T PATTERN ANAL, V17, P239, DOI 10.1109/34.368189; Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703; Siddiqi K, 1996, PROC CVPR IEEE, P507, DOI 10.1109/CVPR.1996.517119; Siddiqi K, 1996, PERCEPTION, V25, P399, DOI 10.1068/p250399; Siddiqi K, 2001, VISION RES, V41, P1153, DOI 10.1016/S0042-6989(00)00274-1; Tek H, 2003, INT J COMPUT VISION, V54, P35, DOI 10.1023/A:1023753317008; Thomas A, 2007, IEEE I CONF COMP VIS, P23; Todorovic S, 2006, CVPR, P927; Torralba A, 2004, PROC CVPR IEEE, P762; Torsello A, 2006, IEEE T PATTERN ANAL, V28, P954, DOI 10.1109/TPAMI.2006.125; TORSELLO A, 2008, CVPR 08; Triesch J, 2002, IMAGE VISION COMPUT, V20, P937, DOI 10.1016/S0262-8856(02)00100-2; TRINH N, 2007, ICCV 07; Trinh N. H., 2010, P CVPR WORKSH STRUCT; TRINH NH, 2009, BMVC 09; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Winn J, 2005, IEEE I CONF COMP VIS, P756; YANOVER C, 2004, NIPS 03; YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169; ZHANG J, 2006, CVPR 06, P1536; Zhu QH, 2008, LECT NOTES COMPUT SC, V5303, P774; Zhu SC, 1996, INT J COMPUT VISION, V20, P187	93	40	41	0	15	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2011	94	2					215	240		10.1007/s11263-010-0412-0	http://dx.doi.org/10.1007/s11263-010-0412-0			26	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	775VB					2022-12-18	WOS:000291490400004
J	Wang, Y; Gupta, M; Zhang, S; Wang, S; Gu, XF; Samaras, D; Huang, PS				Wang, Yang; Gupta, Mohit; Zhang, Song; Wang, Sen; Gu, Xianfeng; Samaras, Dimitris; Huang, Peisen			High resolution tracking of non-rigid motion of densely sampled 3D data using harmonic maps	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						vision and graphics; face and gesture; registration; motion analysis and tracking	REGISTRATION; RECOGNITION; COMPUTATION; SHAPES	We present a novel automatic method for high resolution, non-rigid dense 3D point tracking. High quality dense point clouds of non-rigid geometry moving at video speeds are acquired using a phase-shifting structured light ranging technique. To use such data for the temporal study of subtle motions such as those seen in facial expressions, an efficient non-rigid 3D motion tracking algorithm is needed to establish inter-frame correspondences. The novelty of this paper is the development of an algorithmic framework for 3D tracking that unifies tracking of intensity and geometric features, using harmonic maps with added feature correspondence constraints. While the previous uses of harmonic maps provided only global alignment, the proposed introduction of interior feature constraints allows to track non-rigid deformations accurately as well. The harmonic map between two topological disks is a diffeomorphism with minimal stretching energy and bounded angle distortion. The map is stable, insensitive to resolution changes and is robust to noise. Due to the strong implicit and explicit smoothness constraints imposed by the algorithm and the high-resolution data, the resulting registration/deformation field is smooth, continuous and gives dense one-to-one inter-frame correspondences. Our method is validated through a series of experiments demonstrating its accuracy and efficiency.	[Wang, Yang; Gupta, Mohit] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA; [Wang, Sen; Gu, Xianfeng; Samaras, Dimitris] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA; [Zhang, Song; Huang, Peisen] SUNY Stony Brook, Dept Mech Engn, Stony Brook, NY 11794 USA	Carnegie Mellon University; State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook; State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook	Wang, Y (corresponding author), Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.	wangy@cs.cmu.edu; mohitg@cs.cmu.edu; song.zhang@sunysb.edu; swang@cs.sunysb.edu; gu@cs.sunysb.edu; samaras@cs.sunysb.edu; peisen.huang@sunysb.edu	Zhang, Song/C-5294-2012	Zhang, Song/0000-0001-8452-4837; Gu, Xianfeng/0000-0001-8226-5851				AKGUL YS, 1999, INT C COMP VIS, P765; Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311; Basu S, 1998, SPEECH COMMUN, V26, P131, DOI 10.1016/S0167-6393(98)00055-7; Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; BLACK MJ, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P374, DOI 10.1109/ICCV.1995.466915; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Brand M, 2001, PROC CVPR IEEE, P315; Bronstein AM, 2006, SIAM J SCI COMPUT, V28, P1812, DOI 10.1137/050639296; Bronstein AM, 2006, P NATL ACAD SCI USA, V103, P1168, DOI 10.1073/pnas.0508601103; Bronstein AM, 2005, INT J COMPUT VISION, V64, P5, DOI 10.1007/s11263-005-1085-y; CHAI J, 2003, ACM SIGGRAPHE EUR S, P193; CHEN Y, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P2724, DOI 10.1109/ROBOT.1991.132043; Davis J, 2003, PROC CVPR IEEE, P359; DeCarlo D, 2002, IEEE T PATTERN ANAL, V24, P814, DOI 10.1109/TPAMI.2002.1008387; DIMITRIJEVIC M, 2004, IEEE P INT C CVPR, V2, P1034; Eck M., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P173, DOI 10.1145/218380.218440; EELLS J, 1964, AM J MATH, V86, P109, DOI 10.2307/2373037; Essa IA, 1997, IEEE T PATTERN ANAL, V19, P757, DOI 10.1109/34.598232; Evans LC, 1998, GRAD STUD MATH; Gokturk SB, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P701, DOI 10.1109/ICCV.2001.937695; Goldenstein SK, 2003, IEEE T PATTERN ANAL, V25, P801, DOI 10.1109/TPAMI.2003.1206510; Gu XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P701; Guenin BM, 1998, P IEEE SEMICOND THER, P55, DOI 10.1109/STHERM.1998.660387; Huang C, 2004, CELL CYCLE, V3, P4, DOI 10.4161/cc.3.1.601; HUANG X, 2004, IEEE WORKSH ART NONR; HUANG X, 2003, INT C MED IMAG COMPU, P926; Hughes T.J.R., 1987, FINITE ELEMENT METHO; KALBERER GA, 2001, IEEE C COMP AN; Lien JJJ, 1998, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.1998.698704; LITKE N, 2005, EUR S GEOM PROC, P207; Noh JY, 2001, COMP GRAPH, P277, DOI 10.1145/383259.383290; ONEILL B, 2001, ELEMENTARY DIFFERENT; PIGHIN FH, 1999, ICCV, P143; Ramanan D, 2003, PROC CVPR IEEE, P467; Rittscher J, 2002, IMAGE VISION COMPUT, V20, P905, DOI 10.1016/S0262-8856(02)00099-9; RUSINKIEWICZ S, 2002, ACM SIGGRAPH COMPUTE, V1281, P438; Schoen R., 1997, P C LECT NOT GEOM TO, VII; SHARON E, 2004, IEEE COMPUTER VISION, V2, P350; TAO H, 1999, P COMP VIS PATT REC, V1, P611; Tomasi C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1441; Torresani L, 2001, PROC CVPR IEEE, P493; Wang Y, 2004, COMPUT GRAPH FORUM, V23, P677, DOI 10.1111/j.1467-8659.2004.00800.x; Wen Z, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1343, DOI 10.1109/ICCV.2003.1238646; WITKIN A, 1987, INT J COMPUT VISION, V1, P133, DOI 10.1007/BF00123162; Xiao J, 2004, PROC CVPR IEEE, P535; Yezzi AJ, 2003, INT J COMPUT VISION, V53, P153, DOI 10.1023/A:1023048024042; ZHANG D, 1999, P IEEE COMP SOC C CO, V2, P524; Zhang L, 2004, ACM T GRAPHIC, V23, P548, DOI 10.1145/1015706.1015759; ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149	50	40	42	0	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2008	76	3					283	300		10.1007/s11263-007-0063-y	http://dx.doi.org/10.1007/s11263-007-0063-y			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	255VI					2022-12-18	WOS:000252685500005
J	Amiaz, T; Kiryati, N				Amiaz, T.; Kiryati, N.			Piecewise-smooth dense optical flow via level sets	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						optical flow; piecewise-smoothness; level-sets; variational methods	VARIATIONAL APPROACH; COMPUTATION; SEGMENTATION; FRAMEWORK	We propose a new algorithm for dense optical flow computation. Dense optical flow schemes are challenged by the presence of motion discontinuities. In state of the art optical flow methods, over-smoothing of flow discontinuities accounts for most of the error. A breakthrough in the performance of optical flow computation has recently been achieved by Brox et al. Our algorithm embeds their functional within a two phase active contour segmentation framework. Piecewise-smooth flow fields are accommodated and flow boundaries are crisp. Experimental results show the superiority of our algorithm with respect to alternative techniques. We also study a special case of optical flow computation, in which the camera is static. In this case we utilize a known background image to separate the moving elements in the sequence from the static elements. Tests with challenging real world sequences demonstrate the performance gains made possible by incorporating the static camera assumption in our algorithm.	Tel Aviv Univ, Sch Elect Engn, IL-69978 Tel Aviv, Israel	Tel Aviv University	Amiaz, T (corresponding author), Tel Aviv Univ, Sch Elect Engn, IL-69978 Tel Aviv, Israel.	nk@eng.tau.ac.il		Kiryati, Nahum/0000-0003-1436-2275				AMBROSIO L, 1990, COMMUN PUR APPL MATH, V43, P999, DOI 10.1002/cpa.3160430805; Amiaz T, 2005, IEEE IMAGE PROC, P2661; ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167; Andrews R.J., 2003, P WORKSH DIG IM COMP, P135; Aubert G., 2002, MATH PROBLEMS IMAGE; BAR L, 2005, TAU DANCE; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006; Black MJ, 2000, INT J COMPUT VISION, V38, P231, DOI 10.1023/A:1008195307933; Borshukov GD, 1997, IEEE T IMAGE PROCESS, V6, P1591, DOI 10.1109/83.641420; BROWNRIGG DRK, 1984, COMMUN ACM, V27, P807, DOI 10.1145/358198.358222; Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3; Bruhn A, 2005, LECT NOTES COMPUT SC, V3459, P279; Cremers D, 2005, INT J COMPUT VISION, V62, P249, DOI 10.1007/s11263-005-4882-4; DERVIEUX A, 1979, LECT NOTES MATH, V771, P145; FLEET DJ, 1990, INT J COMPUT VISION, V5, P77, DOI 10.1007/BF00056772; Galvin B., 1998, P BRIT MACH VIS C SO; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; KOLLNIG H, 1994, LECT NOTES COMPUTER, V801, P338; Lucas B.D., 1981, P INT JOINT C ART IN, P121, DOI DOI 10.5334/JORS.BL; Memin E, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P933, DOI 10.1109/ICCV.1998.710828; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; NESI P, 1993, IMAGE VISION COMPUT, V11, P419, DOI 10.1016/0262-8856(93)90046-J; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Paragios N, 2005, COMPUT VIS IMAGE UND, V97, P259, DOI 10.1016/j.cviu.2003.04.001; Spies H, 2002, COMPUT VIS IMAGE UND, V85, P209, DOI 10.1006/cviu.2002.0970; Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076; WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981; Weickert J, 2001, J MATH IMAGING VIS, V14, P245, DOI 10.1023/A:1011286029287	30	40	43	0	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2006	68	2					111	124		10.1007/s11263-005-6206-0	http://dx.doi.org/10.1007/s11263-005-6206-0			14	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	055CK					2022-12-18	WOS:000238427400001
J	Wolf, L; Zomet, A				Wolf, Lior; Zomet, Assaf			Wide baseline matching between unsynchronized video sequences	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	Workshop on Vision and Modelling of Dynamic Scenes held in Conjuction with the European Conference on Computer Vision	2002	Copenhagen, DENMARK			structure from motion; video synchronization; wide base-line matching	IMAGE	3D reconstruction of a dynamic scene from features in two cameras usually requires synchronization and correspondences between the cameras. These may be hard to achieve due to occlusions, different orientation, different scales. etc. In this work we present an algorithm for reconstructing a dynamic scene from sequences acquired by two uncalibrated non-synchronized fixed affine cameras. It is assumed that (possibly) different points are tracked in the two sequences. The only constraint relating the two cameras is that every 3D point tracked in one sequence can be described as a linear combination of some of the 3D points tracked in the other sequence. Such constraint is useful, for example, for articulated objects. We may track some points on an arm in the first sequence, and some other points on the same arm in the second sequence. On the other extreme, this model can be used for generally moving points tracked in both sequences without knowing the correct permutation. In between, this model can cover non-rigid bodies with local rigidity constraints. We present linear algorithms for synchronizing the two sequences and reconstructing the 3D points tracked in both views. Outlier points are automatically detected and discarded. The algorithm can handle both 3D objects and planar objects in a unified framework, therefore avoiding numerical problems existing in other methods.	MIT, Ctr Biol & Computat Learning, Cambridge, MA 02139 USA; Columbia Univ, Dept Comp Sci, New York, NY USA	Massachusetts Institute of Technology (MIT); Columbia University	Wolf, L (corresponding author), MIT, Ctr Biol & Computat Learning, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	liorwolf@mit.edu; zomet@cs.columbia.edu						Brand M, 2001, PROC CVPR IEEE, P456; Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941; Caspi Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P76, DOI 10.1109/ICCV.2001.937607; Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999; DORNAIKA F, 1999, CVPR99, P70; Frahm J.-M., 1996, EUR C COMP VIS CAMBR, P2; Golub Gene H., 2013, MATRIX COMPUTATION, V3; IRANI M, 1999, IEEE INT C COMP VIS; Kanatani K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P586, DOI 10.1109/ICCV.2001.937679; LEVENTON M, 1998, 9806 MITS EL RES LAB; Schaffalitzky F, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P636, DOI 10.1109/ICCV.2001.937686; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; TUYTELAARS T, 2000, BRIT MACH VIS C; Vetter T, 1997, IEEE T PATTERN ANAL, V19, P733, DOI 10.1109/34.598230; VIDAL R, 2004, COMPUTER VISION PATT; Wolf L, 2002, LECT NOTES COMPUT SC, V2351, P370; ZELNIKMANOR L, 2003, COMPUTER VISION PATT	17	40	43	0	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2006	68	1					43	52		10.1007/s11263-005-4841-0	http://dx.doi.org/10.1007/s11263-005-4841-0			10	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	052JB					2022-12-18	WOS:000238228900004
J	Heiler, M; Schnorr, C				Heiler, M; Schnorr, C			Natural image statistics for natural image segmentation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						image segmentation; natural image statistics; level sets	TEXTURE; ENSEMBLES; REGIONS; DRIVEN	We integrate a model for filter response statistics of natural images into a variational framework for image segmentation. Incorporated in a sound probabilistic distance measure, the model drives level sets toward meaningful segmentations of complex textures and natural scenes. Despite its enhanced descriptive power, our approach preserves the efficiency of level set based segmentation since each region comprises two model parameters only. Analyzing thousands of natural images we select suitable filter banks, validate the statistical basis of our model, and demonstrate that it outperforms variational segmentation methods using second-order statistics.	Univ Mannheim, Dept Math & Comp Sci, Comp Vis Graph & Pattern Recognit Grp, D-68131 Mannheim, Germany	University of Mannheim	Heiler, M (corresponding author), Univ Mannheim, Dept Math & Comp Sci, Comp Vis Graph & Pattern Recognit Grp, D-68131 Mannheim, Germany.	heiler@uni-mannheim.de						BELONGIE S, 1998, P ICCV; Brodatz P., 1966, TEXTURES PHOTOGRAPHI; Buccigrossi RW, 1999, IEEE T IMAGE PROCESS, V8, P1688, DOI 10.1109/83.806616; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; CHAN WCW, 2000, P SOC PHOTO-OPT INS, V1, P2; CREMERS D, 2004, IN PRESS P ECCV; Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185; FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808; Geusebroek J-M, 2003, P 9 INT C COMP VIS I, V1, P130, DOI [10.1109/ICCV.2003.1238326, DOI 10.1109/ICCV.2003.1238326]; *GMBV, 2002, 1 INT WORKSH GEN MOD; Hansen MH, 2001, J AM STAT ASSOC, V96, P746, DOI 10.1198/016214501753168398; Heeger D.J., 1995, P 22 ANN C COMP GRAP, P229, DOI DOI 10.1145/218380.218446; HUANG J, 1999, P IEEE C COMP VIS PA, V1, P541; Jehan-Besson S, 2003, INT J COMPUT VISION, V53, P45, DOI 10.1023/A:1023031708305; Joshi RL, 1995, IEEE T CIRC SYST VID, V5, P515, DOI 10.1109/76.475894; Keuchel J, 2003, IEEE T PATTERN ANAL, V25, P1364, DOI 10.1109/TPAMI.2003.1240111; KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855; LECLERC YG, 1989, INT J COMPUT VISION, V3, P73, DOI 10.1007/BF00054839; LIU X, 2000, TEXTURE CLASSIFICATI; LoPresto SM, 1997, IEEE DATA COMPR CONF, P221, DOI 10.1109/DCC.1997.582045; MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463; Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; MUMFORD D, 1994, GEOMETRY DRIVEN DIFF, P135; Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068; PICARD R, 1995, VISTEX VISION TEXTUR; Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983; Puzicha J, 1999, PATTERN RECOGN LETT, V20, P899, DOI 10.1016/S0167-8655(99)00056-2; Puzicha J., 1999, P IEEE INT C COMP VI, P1165, DOI DOI 10.1109/ICCV.1999.790412; Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261; REININGER RC, 1983, IEEE T COMMUN, V31, P835, DOI 10.1109/TCOM.1983.1095893; RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5; Rousson M, 2003, PROC CVPR IEEE, P699; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; SIMON J, 1980, NUMER FUNC ANAL OPT, V2, P649, DOI 10.1080/01630563.1980.10120631; Simoncelli EP, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL I, P379; SIMONCELLI EP, 1995, 2 INT C IM P WASH DC; Sokolowski J., 1991, INTRO SHAPE OPTIMIZA; Srivastava A, 2002, IEEE T PATTERN ANAL, V24, P1200, DOI 10.1109/TPAMI.2002.1033212; Tang M, 2001, IEEE T PATTERN ANAL, V23, P1366, DOI 10.1109/34.977561; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; van Hateren JH, 1998, P ROY SOC B-BIOL SCI, V265, P359, DOI 10.1098/rspb.1998.0303; Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076; Wainwright MJ, 2001, APPL COMPUT HARMON A, V11, P89, DOI 10.1006/acha.2000.0350; WALLACE CS, 1968, COMPUT J, V11, P185, DOI 10.1093/comjnl/11.2.185; WU Y, 2003, 3 INT WORKSH TEXT AN, P107; Wu YN, 2000, INT J COMPUT VISION, V38, P247, DOI 10.1023/A:1008199424771; Zhu SC, 2000, IEEE T PATTERN ANAL, V22, P554, DOI 10.1109/34.862195; Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420; Zhu SC, 1997, IEEE T PATTERN ANAL, V19, P1236, DOI 10.1109/34.632983; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	52	40	41	0	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2005	63	1					5	19		10.1007/s11263-005-4944-7	http://dx.doi.org/10.1007/s11263-005-4944-7			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	907WS		Green Accepted			2022-12-18	WOS:000227749400001
J	Wang, HZ; Suter, D				Wang, HZ; Suter, D			MDPE: A very robust estimator for model fitting and range image segmentation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						robust estimation; breakdown point; model fitting; range image segmentation; least median of squares; residual consensus; adaptive least kth order squares; mean shift; random sample consensus; Hough transform	COMPUTER VISION; HOUGH TRANSFORM; MEAN SHIFT; REGRESSION	In this paper, we propose a novel and highly robust estimator, called MDPE1 (Maximum Density Power Estimator). This estimator applies nonparametric density estimation and density gradient estimation techniques in parametric estimation ("model fitting"). MDPE optimizes an objective function that measures more than just the size of the residuals. Both the density distribution of data points in residual space and the size of the residual corresponding to the local maximum of the density distribution, are considered as important characteristics in our objective function. MDPE can tolerate more than 85% outliers. Compared with several other recently proposed similar estimators, MDPE has a higher robustness to outliers and less error variance. We also present a new range image segmentation algorithm, based on a modified version of the MDPE (Quick-MDPE), and its performance is compared to several other segmentation methods. Segmentation requires more than a simple minded application of an estimator, no matter how good that estimator is: our segmentation algorithm overcomes several difficulties faced with applying a statistical estimator to this task.	Monash Univ, Dept Elect & Comp Syst Engn, Clayton, Vic 3800, Australia	Monash University	Wang, HZ (corresponding author), Monash Univ, Dept Elect & Comp Syst Engn, Clayton, Vic 3800, Australia.	hanzi.wang@eng.monash.edu.au; d.suter@eng.monash.edu.au	Wang, Hanzi/F-8796-2012	Suter, David/0000-0001-6306-3023				Bab-Hadiashar A, 1999, ROBOTICA, V17, P649, DOI 10.1017/S0263574799001812; Chen HF, 2002, LECT NOTES COMPUT SC, V2350, P236; CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Comaniciu D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1197, DOI 10.1109/ICCV.1999.790416; Comaniciu D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P438, DOI 10.1109/ICCV.2001.937550; Comaniciu D, 1997, PROC CVPR IEEE, P750, DOI 10.1109/CVPR.1997.609410; Comaniciu D, 1999, PATTERN ANAL APPL, V2, P22, DOI 10.1007/s100440050011; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FITZGIBBON AW, 1995, HIGH LEVEL CAD MODEL; FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330; GHOSAL S, 1994, IEEE T PA, V13, P14; Gregory R. L., 1970, INTELLIGENT EYE; HOFFMAN R, 1987, IEEE T PATTERN ANAL, V9, P608, DOI 10.1109/TPAMI.1987.4767955; Hoover A, 1996, IEEE T PATTERN ANAL, V18, P673, DOI 10.1109/34.506791; Hough P.V., 1962, US Patent, Patent No. [US3069654A, 3069654, 3,069,654]; Huber P., 1981, ROBUST STAT; HUBER PJ, 1973, ANN STAT, V1, P799, DOI 10.1214/aos/1176342503; ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1; JIANG XY, 1994, MACH VISION APPL, V7, P115, DOI 10.1007/BF01215806; LEAVERS VF, 1993, CVGIP-IMAG UNDERSTAN, V58, P250, DOI 10.1006/ciun.1993.1041; Lee KM, 1998, IEEE T PATTERN ANAL, V20, P200, DOI 10.1109/34.659940; LUMIA R, 1983, COMPUT VISION GRAPH, V22, P287, DOI 10.1016/0734-189X(83)90071-3; Miller JV, 1996, PROC CVPR IEEE, P300, DOI 10.1109/CVPR.1996.517089; Neisser U., 1967, COGNITIVE PSYCHOL; ROTH G, 1991, P 4 INT C GEN ALG, P487; ROTH G, 1990, P 10 C PATT REC, V1, P826; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718; Silverman B.W., 1986, DENSITY ESTIMATION S, V26; STEWART CV, 1995, IEEE T PATTERN ANAL, V17, P925, DOI 10.1109/34.464558; Stewart CV, 1999, SIAM REV, V41, P513, DOI 10.1137/S0036144598345802; Stewart CV, 1997, IEEE T PATTERN ANAL, V19, P818, DOI 10.1109/34.608280; TORDOFF B, 2002, 7 EUR C COMP VIS, V1, P82; Wand M.P., 1995, KERNEL SMOOTHING; Wang H, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P178; WANG H, 2002, 7 INT C CONTR AUT RO, P326; Wang HZ, 2003, PATTERN RECOGN LETT, V24, P2953, DOI 10.1016/S0167-8655(03)00156-9; WANI MA, 1994, IEEE T PATTERN ANAL, V16, P314, DOI 10.1109/34.276131; YU XM, 1994, IEEE T PATTERN ANAL, V16, P530, DOI 10.1109/34.291443	40	40	42	0	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2004	59	2					139	166		10.1023/B:VISI.0000022287.61260.b0	http://dx.doi.org/10.1023/B:VISI.0000022287.61260.b0			28	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	842DR					2022-12-18	WOS:000222983800002
J	Zhang, ZY; Liu, ZC; Adler, D; Cohen, MF; Hanson, E; Shan, Y				Zhang, ZY; Liu, ZC; Adler, D; Cohen, MF; Hanson, E; Shan, Y			Robust and rapid generation of animated faces from video images: A model-based modeling approach	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						face modeling; facial animation; geometric modeling; structure from motion; model-based bundle adjustment; head tracking	SEQUENCES; MOTION; HEADS	We have developed an easy-to-use and cost-effective system to construct textured 3D animated face models from videos with minimal user interaction. This is a particularly challenging task for faces due to a lack of prominent textures. We develop a robust system by following a model-based approach: we make full use of generic knowledge of faces in head motion determination, head tracking, model fitting, and multiple-view bundle adjustment. Our system first takes, with an ordinary video camera, images of a face of a person sitting in front of the camera turning their head from one side to the other. After five manual clicks on two images to indicate the position of the eye corners, nose tip and mouth corners, the system automatically generates a realistic looking 3D human head model that can be animated immediately (different poses, facial expressions and talking). A user, with a PC and a video camera, can use our system to generate his/her face model in a few minutes. The face model can then be imported in his/her favorite game, and the user sees themselves and their friends take part in the game they are playing. We have demonstrated the system on a laptop computer live at many events, and constructed face models for hundreds of people. It works robustly under various environment settings.	Microsoft Res, Redmond, WA 98052 USA	Microsoft	Zhang, ZY (corresponding author), Microsoft Res, 1 Microsoft Way, Redmond, WA 98052 USA.	zhang@microsoft.com; zliu@microsoft.com	zhang, zheng/HCH-9684-2022					AKIMOTO T, 1993, IEEE COMPUT GRAPH, V13, P16, DOI 10.1109/38.232096; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Black MJ, 1997, INT J COMPUT VISION, V25, P23, DOI 10.1023/A:1007977618277; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Dariush B, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P248, DOI 10.1109/AFGR.1998.670956; DeCarlo D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P67, DOI 10.1145/280814.280823; DiPaola S., 1991, Journal of Visualization and Computer Animation, V2, P129, DOI 10.1002/vis.4340020406; Ekman P., 2002, FACIAL ACTION CODING; Essa IA, 1997, IEEE T PATTERN ANAL, V19, P757, DOI 10.1109/34.598232; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Fua P, 1999, COMPUT VIS IMAGE UND, V75, P247, DOI 10.1006/cviu.1999.0778; Fua P, 2000, INT J COMPUT VISION, V38, P153, DOI 10.1023/A:1008105802790; Fua P., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P188, DOI 10.1007/BFb0055667; Fua P, 1999, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P4, DOI 10.1109/CGI.1999.777889; Gill P. E., 1981, PRACTICAL OPTIMIZATI; Guenin BM, 1998, P IEEE SEMICOND THER, P55, DOI 10.1109/STHERM.1998.660387; Harris C. G., 1988, P 4 ALV VIS C, V15, P10, DOI [10.5244/C.2.23, DOI 10.5244/C.2.23]; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; Ip HHS, 1996, VISUAL COMPUT, V12, P254, DOI 10.1007/s003710050063; KANG SB, 1999, UNPUB APPEARANCE BAS; KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570; Lanitis A, 1997, IEEE T PATTERN ANAL, V19, P743, DOI 10.1109/34.598231; Lee WS, 1998, LECT NOTES ARTIF INT, V1537, P254; Lee Y., 1993, Proceedings Graphics Interface '93, P1; Lee Y., 1995, COMPUTER GRAPHICS, P55; Lewis J. P., 1989, Computer Graphics, V23, P263, DOI 10.1145/74334.74360; Liu Z., 2000, P 3 INT C VIS COMP M, P58; LIU Z, 2001, P IEEE WORKSH HUM MO, P73; Liu ZC, 2001, COMP GRAPH, P271; MAGNENEATTHALMA.N, 1989, VISUAL COMPUT, P32; More J., 1977, LECT NOTES MATH, V630; Parke F. I., 1972, ACM NAT C; Parke F. I., 1974, THESIS U UTAH; PARKE FI, 1996, COMPUTER FACIAL ANIM; Pighin F., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P75, DOI 10.1145/280814.280825; Platt S. M., 1981, Computer Graphics, V15, P245, DOI 10.1145/965161.806812; Rousseeuw P.J., 1987, ROBUST REGRESSION OU; Shakunaga T, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P94, DOI 10.1109/AFGR.1998.670931; Shan Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P644, DOI 10.1109/ICCV.2001.937687; TAO H, 1999, P COMP VIS PATT REC, V1, P611; TERZOPOULOS D, 1990, VISUALIZATION COMPUT, P73; Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962; TODD JT, 1980, SCI AM, V242, P132, DOI 10.1038/scientificamerican0280-132; Vetter T, 1997, IEEE T PATTERN ANAL, V19, P733, DOI 10.1109/34.598230; Waters, 2005, COMPUT GRAPH, V21, P17, DOI [10.1145/37402.37405, DOI 10.1145/37402.37405]; Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561; Zhang ZY, 1997, J OPT SOC AM A, V14, P2938, DOI 10.1364/JOSAA.14.002938; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718; Zhang ZY, 1998, IEEE T PATTERN ANAL, V20, P717, DOI 10.1109/34.689302; ZHENG JY, 1994, IEEE T PATTERN ANAL, V16, P163, DOI 10.1109/34.273734	51	40	57	0	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2004	58	2					93	119		10.1023/B:VISI.0000015915.50080.85	http://dx.doi.org/10.1023/B:VISI.0000015915.50080.85			27	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	829FY					2022-12-18	WOS:000222034000002
J	Hagedoorn, M; Veltkamp, RC				Hagedoorn, M; Veltkamp, RC			Reliable and efficient pattern matching using an affine invariant metric	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						geometric pattern matching; metric; affine invariance		We present a new pattern similarity measure that behaves well under affine transformations. Our similarity measure is useful for pattern matching since it is defined on patterns with multiple components, satisfies the metric properties, is invariant under affine transformations, and is robust with respect to perturbation and occlusion. We give an algorithm, based on hierarchical subdivision of transformation space, which minimises our measure under the group of affine transformations, given two patterns. In addition, we present results obtained using an implementation of this algorithm.	Univ Utrecht, Dept Comp Sci, NL-3584 CH Utrecht, Netherlands	Utrecht University	Hagedoorn, M (corresponding author), Univ Utrecht, Dept Comp Sci, Padualaan 14, NL-3584 CH Utrecht, Netherlands.							ALT H, 1988, DISCRETE COMPUT GEOM, V3, P237, DOI 10.1007/BF02187910; ALT H, 1995, INT J COMPUT GEOM AP, V5, P75, DOI 10.1142/S0218195995000064; Alt H., 1991, P 7 ANN S COMP GEOM, P186; ALT H, 1996, LNCS, V1136, P320; AYACHE N, 1987, INT J COMPUT VISION, V1, P107, DOI 10.1007/BF00123161; Chen Z, 1996, CANCER GENE THER, V3, P18; De Berg Mark, 1997, COMPUTATIONAL GEOMET; DEBERG M, 1996, P 7 ANN INT S ALG CO; Efrat A., 1996, Proceedings of the Twelfth Annual Symposium on Computational Geometry, FCRC '96, P301, DOI 10.1145/237218.237399; EFRAT A, 1996, P 7 INT S ALG COMP, P115; Gardner WF, 1996, IEEE T PATTERN ANAL, V18, P1115, DOI 10.1109/34.544082; Hagedoorn M., 1997, Proceedings of the Thirteenth Annual Symposium on Computational Geometry, P406, DOI 10.1145/262839.263030; HAGEDOORN M, 1999, DISCRETE GEOMETRY CO; Huttenlocher D. P., 1992, Proceedings of the Eighth Annual Symposium on Computational Geometry, P110, DOI 10.1145/142675.142700; HUTTENLOCHER DP, 1993, DISCRETE COMPUT GEOM, V9, P267, DOI 10.1007/BF02189323; MEHROTRA R, 1995, IEEE COMPUT, V28, P55; MONTGOMERY D, 1964, TOPOLOGICAL TRANSFOR; MORI S, 1992, IEEE P           JUL, P1029; Mount DM, 1996, COMPUT VIS IMAGE UND, V64, P53, DOI 10.1006/cviu.1996.0045; Rucklidge W, 1996, LECT NOTES COMPUTER; SMALL CG, 1996, STAT THEORY SHAPES; SPRINZAK J, 1994, PATTERN RECOGN LETT, V15, P337, DOI 10.1016/0167-8655(94)90081-7; WOLFSON HJ, 1990, P 1 EUR C COMP VIS, P526	23	40	40	0	2	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	APR	1999	31	2-3					203	225		10.1023/A:1008022116857	http://dx.doi.org/10.1023/A:1008022116857			23	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	209NA					2022-12-18	WOS:000081053100008
J	Florack, L; Niessen, W; Nielsen, M				Florack, L; Niessen, W; Nielsen, M			The intrinsic structure of optic flow incorporating measurement duality	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							SCALE-SPACE; VISUAL-SYSTEM; MOTION; FIELD; COMPUTATION; INFORMATION; GEOMETRY; CURVES; IMAGES	The purpose of this article is to define optic flow for scalar and density images without using a priori knowledge other than its defining conservation principle, and to incorporate measurement duality, notably the scale-space paradigm, It is argued that the design of optic flow based applications may benefit from a manifest separation between factual image structure on the one hand, and goal-specific details and hypotheses about image flow formation on the other. The approach is based on a physical symmetry principle known as gauge invariance, Data-independent models can be incorporated by means of admissible gauge conditions, each of which may single out a distinct solution, but all of which must be compatible with the evidence supported by the image data. The theory is illustrated by examples and verified by simulations, and performance is compared to several techniques reported in the literature.	Univ Utrecht, Dept Comp Sci, NL-3508 TB Utrecht, Netherlands; Univ Utrecht Hosp, Image Sci Inst, NL-3584 CX Utrecht, Netherlands; Univ Copenhagen, DIKU, DK-2100 Copenhagen, Denmark	Utrecht University; Utrecht University; Utrecht University Medical Center; University of Copenhagen	Florack, L (corresponding author), Univ Utrecht, Dept Comp Sci, POB 80089, NL-3508 TB Utrecht, Netherlands.	Luc.Florack@cs.ruu.nl; Wiro.Niessen@cv.ruu.nl; malte@diku.dk						AMINI A, 1994, P EUR C COMP VIS, P125; ARNSPANG J, 1993, IMAGE VISION COMPUT, V11, P577, DOI 10.1016/0262-8856(93)90023-A; ARNSPANG J, 1988, 882 U COP DEP COMP S; ARNSPANG J, 1991, THESIS U UTRECHT UTR; ARNSPANG J, 1988, 881 U COP DEP COMP S; BABAUD J, 1986, IEEE T PATTERN ANAL, V8, P26, DOI 10.1109/TPAMI.1986.4767749; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Bourbaki N, 1964, ELEMENTS MATH; Choquet-Bruhat Y, 1991, ANAL MANIFOLDS PHY 1; DELOGNE P, 1996, P INT C IM PROC LAUS; Devlaminck V, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL I, P125, DOI 10.1109/ICIP.1996.559448; DHAEYER J, 1986, COMPUT VISION GRAPH, V34, P166, DOI 10.1016/S0734-189X(86)80057-3; EKLUNDH JO, 1994, LECT NOTES COMPUTER, V800; FAUGERAS O, 1993, INT J COMPUT VISION, V10, P125, DOI 10.1007/BF01420734; FITZPATRICK JM, 1988, COMPUT VISION GRAPH, V44, P155, DOI 10.1016/S0734-189X(88)80003-3; FLEET DJ, 1990, INT J COMPUT VISION, V5, P77, DOI 10.1007/BF00056772; Florack L, 1996, INT J COMPUT VISION, V18, P61, DOI 10.1007/BF00126140; Florack L, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL I, P469, DOI 10.1109/ICIP.1996.559535; Florack L. M. J., 1993, Journal of Mathematical Imaging and Vision, V3, P327, DOI 10.1007/BF01664793; Florack L. M. J., 1994, Journal of Mathematical Imaging and Vision, V4, P325, DOI 10.1007/BF01262401; FLORACK LMJ, 1992, IMAGE VISION COMPUT, V10, P376, DOI 10.1016/0262-8856(92)90024-W; FLORACK LMJ, 1992, NATO ASI SERIES F, V126, P651; FLORACK LMJ, 1995, ERCIM0995R039 INESC; FLORACK LMJ, 1994, ERCIM0794R033 INRIA; FLORACK LMJ, 1994, INRIARR2350; Gibson James J., 1950, PERCEPTION VISUAL WO, P3; Gilmore R., 1993, CATASTROPHE THEORY S; HILDRETH E, 1983, MEASUREMENT VISUAL M; HILDRETH EC, 1984, ARTIF INTELL, V23, P309, DOI 10.1016/0004-3702(84)90018-3; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HORN BKP, 1993, ARTIF INTELL, V59, P81, DOI 10.1016/0004-3702(93)90173-9; Johansen P., 1994, Journal of Mathematical Imaging and Vision, V4, P57, DOI 10.1007/BF01250004; Koenderink J. J., 1992, Journal of Visual Communication and Image Representation, V3, P1, DOI 10.1016/1047-3203(92)90026-P; Koenderink J. J., 1988, Cybernetics and Systems '88. Proceedings of the Ninth European Meeting on Cybernetics and Systems Research, P481; Koenderink J. J., 1984, LIMITS PERCEPTION, P495; KOENDERINK JJ, 1992, J OPT SOC AM A, V9, P530, DOI 10.1364/JOSAA.9.000530; KOENDERINK JJ, 1975, OPT ACTA, V22, P773, DOI 10.1080/713819112; KOENDERINK JJ, 1990, BIOL CYBERN, V63, P291, DOI 10.1007/BF00203452; KOENDERINK JJ, 1988, BIOL CYBERN, V58, P163, DOI 10.1007/BF00364136; KOENDERINK JJ, 1986, VISION RES, V26, P161, DOI 10.1016/0042-6989(86)90078-7; KOENDERINK JJ, 1990, PSYCHOL RES-PSYCH FO, V52, P122, DOI 10.1007/BF00877519; KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371; KOENDERINK JJ, 1991, ARTIFICIAL NEURAL NETWORKS, VOLS 1 AND 2, P93; KOENDERINK JJ, 1986, CYBERNET SYST, P871; KOENDERINK JJ, 1988, NEURAL COMPUTERS, P111; Koenderink JJ, 1992, ARTIFICIAL BIOL VISI, P1; KOENDERINK JJ, 1988, ORG NEURAL NETWORKS, P185; LEE DN, 1980, PHILOS T R SOC B, V290, P169, DOI 10.1098/rstb.1980.0089; LEE DN, 1976, PERCEPTION, V5, P437, DOI 10.1068/p050437; LINDEBERG T, 1993, INT J COMPUT VISION, V11, P283, DOI 10.1007/BF01469346; LINDEBERG T, 1990, IEEE T PATTERN ANAL, V12, P234, DOI 10.1109/34.49051; Lindeberg T., 1992, Journal of Mathematical Imaging and Vision, V1, P65, DOI 10.1007/BF00135225; LINDEBERG T, 1993, IEEE T PATTERN ANAL, V15, P1068, DOI 10.1109/34.254063; LINDEBERG T, 1990, J VIS COMMUN IMAGE R, V2, P55; LINDEBERG T, 1994, KLUWER INT SERIES EN; Marr D., 1982, VISION; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; NAGEL HH, 1987, ARTIF INTELL, V33, P299, DOI 10.1016/0004-3702(87)90041-5; NAGEL HH, 1992, BASIC RES SERIES, P193; NIELSEN M, 1996, 9617 U COP DEP COMP; NIESSEN W, 1996, GAUSSIAN SCALE SPACE; Niessen WJ, 1997, COMPUT VIS IMAGE UND, V65, P259, DOI 10.1006/cviu.1996.0582; NIESSEN WJ, 1996, P COP WORKSH GAUSS S, P72; OKUTOMI M, 1992, INT J COMPUT VISION, V7, P143, DOI 10.1007/BF00128133; Oreifej O., 2013, DIFFERENTIAL GEOMETR; OTTE M, 1994, P 3 EUR C COMP VIS S, P51; Poston T., 2014, CATASTROPHE THEORY I; Press WH, 1988, NUMERICAL RECIPES C; SCHWARTZ L, 1966, THEORIE DSTRIBUTIONS; Spivak M., 1965, CALCULUS MANIFOLDS, DOI DOI 10.1201/9780429501906; Tistarelli M, 1996, IEEE T PATTERN ANAL, V18, P1243, DOI 10.1109/34.546260; TISTARELLI M, 1994, P 3 EUR C COMP VIS S, P61; TRETIAK O, 1984, P 7 INT C PATT REC M, P16; TREVES F, 1969, TOPOLOGICAL VECTOR S; URAS S, 1988, BIOL CYBERN, V60, P79, DOI 10.1007/BF00202895; VERRI A, 1989, IEEE T PATTERN ANAL, V11, P490, DOI 10.1109/34.24781; VERRI A, 1990, J OPT SOC AM A, V7, P912, DOI 10.1364/JOSAA.7.000912; WEBER J, 1995, INT J COMPUT VISION, V14, P67, DOI 10.1007/BF01421489; WERKHOVEN P, 1990, BIOL CYBERN, V63, P185, DOI 10.1007/BF00195857; Witkin A.P., 1983, P 8 INT JOINT C ART, P1019, DOI DOI 10.1007/978-3-8348-9190-729; [No title captured]	83	40	40	1	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	1998	27	3					263	286		10.1023/A:1007922215235	http://dx.doi.org/10.1023/A:1007922215235			24	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	ZL840					2022-12-18	WOS:000073477400004
J	Meer, P; Lenz, R; Ramakrishna, S				Meer, P; Lenz, R; Ramakrishna, S			Efficient invariant representations	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						invariance; feature correspondence; indexing; geometric hashing	AFFINE; VISION; RATIO	Invariant representations are frequently used in computer vision algorithms to eliminate the effect of an unknown transformation of the data. These representations, however, depend on the order in which the features are considered in the computations. We introduce the class of projective/permutation p(2)-invariants which are insensitive to the labeling of the feature set. A general method to compute the p(2)-invariant of a point set (or of its dual) in the n-dimensional projective space is given. The one-to-one mapping between n + 3 points and the components of their p(2)-invariant representation makes it possible to design correspondence algorithms with superior tolerance to positional errors. An algorithm for coplanar points in projective correspondence is described as an application, and its performance is investigated. The use of p(2)-invariants as an indexing tool in object recognition systems may also be of interest.	Rutgers State Univ, Dept Elect & Comp Engn, Piscataway, NJ 08855 USA; Linkoping Univ, Dept Elect Engn, Image Proc Lab, S-58183 Linkoping, Sweden	Rutgers State University New Brunswick; Linkoping University	Meer, P (corresponding author), Rutgers State Univ, Dept Elect & Comp Engn, POB 909, Piscataway, NJ 08855 USA.							ALEFELD G, 1983, INTRO INTERVA COMPUT; ASTROM E, 1995, P 9 SCAND C IM AN UP, P1053; BIGLIERI E, 1989, SIGNAL PROCESS, V18, P277, DOI 10.1016/0165-1684(89)90039-X; BRILL MH, 1983, COMPUT VISION GRAPH, V23, P92, DOI 10.1016/0734-189X(83)90055-5; Carlsson S., 1995, Proceedings IEEE Workshop on Representation of Visual Scenes (In Conjunction with ICCV'95) (Cat. No.95TB8126), P85, DOI 10.1109/WVRS.1995.476856; Carlsson S., 1994, Applications of Invariance in Computer Vision. Second Joint European - US Workshop Proceedings, P145; CHELLAPPA R, 1993, P 1993 IM UND WORKSH, P205; Efron B., 1994, MONOGR STAT APPL PRO, DOI DOI 10.1007/978-1-4899-4541-9; FAUGERAS O, 1995, J OPT SOC AM A, V12, P465, DOI 10.1364/JOSAA.12.000465; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Golub G. H., 1996, MATRIX COMPUTATIONS; GRIMSON WEL, 1994, INT J COMPUT VISION, V13, P7, DOI 10.1007/BF01420793; Haralick R.M., 1993, COMPUTER ROBOT VISIO, VI; Hartley R. I., 1993, P DARPA IM UND WORKS, P745; HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921; Jacobs DW, 1996, IEEE T PATTERN ANAL, V18, P23, DOI 10.1109/34.476008; KANATANI K, 1991, CVGIP-IMAG UNDERSTAN, V54, P333, DOI 10.1016/1049-9660(91)90034-M; LAMDAN Y, 1990, IEEE T ROBOTIC AUTOM, V6, P578, DOI 10.1109/70.62047; Lamdan Y., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P22, DOI 10.1109/CVPR.1991.139655; LENZ R, 1994, PATTERN RECOGN, V27, P1523, DOI 10.1016/0031-3203(94)90130-9; Maybank S. J., 1994, Applications of Invariance in Computer Vision. Second Joint European - US Workshop Proceedings, P453; MAYBANK SJ, 1995, INT J COMPUT VISION, V14, P199, DOI 10.1007/BF01679682; Meer P., 1994, Applications of Invariance in Computer Vision. Second Joint European - US Workshop Proceedings, P473; MORIN L, 1994, SYNT STRUCT PATT REC; MORIN L, 1993, THESIS I NATL POLYTE; Mundy J., 1992, GEOMETRIC INVARIANCE; MUNDY JL, 1994, P DARPA IM UND WORKS, P1393; MUNDY JL, 1994, LECT NOTES COMPUTER, V825; QUAN L, 1995, IEEE T PATTERN ANAL, V17, P34; RAMAKRISHNA S, 1994, CE105 DEP EL COMP EN; Rothwell C, 1997, COMPUT VIS IMAGE UND, V68, P37, DOI 10.1006/cviu.1997.0525; Rothwell C. A., 1994, Applications of Invariance in Computer Vision. Second Joint European - US Workshop Proceedings, P397; SPRINGER CE, 1965, GEOMETRY ANAL PROJEC; ZHANG S, 1996, ARTIF INTELL, V78, P87; ZHENG Q, 1992, P 11 IAPR INT C PATT, V1, P193; ZISSERMAN A, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P183, DOI 10.1109/ICCV.1995.466788	36	40	43	0	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	FEB	1998	26	2					137	152		10.1023/A:1007944826230	http://dx.doi.org/10.1023/A:1007944826230			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	ZC477					2022-12-18	WOS:000072583200004
J	Faugeras, O; Robert, L				Faugeras, O; Robert, L			What can two images tell us about a third one?	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article								This paper discusses the problem of predicting image features in an image from image features in two other images and the epipolar geometry between the three images. We adopt the most general camera model of perspective projection and show that a point can be predicted in the third image as a bilinear function of its images in the first two cameras, that the tangents to three corresponding curves are related by a trilinear function, and that the curvature of a curve in the third image is a linear function of the curvatures at the corresponding points in the other two images. Our analysis relies heavily on the use of the fundamental matrix which has been recently introduced (Faugeras et al, 1992) and on the properties of a special plane which we call the trifocal plane. Though the trinocular geometry of points and lines has been very recently addressed, our use of the differential properties of curves for prediction is unique. We thus completely solve the following problem: given two views of an object, predict what a third view would look like. The problem and its solution bear upon several areas of computer vision, stereo, motion analysis, and model-based object recognition. Our answer is quite general since it assumes the general perspective projection model for image formation and requires only the knowledge of the epipolar geometry for the triple of views. We show that in the special case of orthographic projection our results for points reduce to those of Ullman and Basri (Ullman and Basri, 1991). We demonstrate on synthetic as well as on real data the applicability of our theory.			Faugeras, O (corresponding author), INRIA,2004 ROUTE LUCIOLES,BP93,F-06902 SOPHIA ANTIPOLIS,FRANCE.							AYACHE N, 1987, 1ST P INT C COMP VIS, P422; BARRETT EB, 1992, GEOMETRIC INVARIANCE, pCH14; BASRI R, 1993, P IM UND WORKSH, P875; DERICHE R, 1987, INT J COMPUT VISION, V2, P15; FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P321; FAUGERAS OD, 1992, SPRINGERVERLAG LECT, V588, P563; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Hartley R., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P761, DOI 10.1109/CVPR.1992.223179; HARTLEY R, 1994, P IM UND WORKSH MONT; ITO M, 1986, IEEE T PATTERN ANAL, V8, P524, DOI 10.1109/TPAMI.1986.4767817; KANATANI K, 1991, CVGIP-IMAG UNDERSTAN, V54, P333, DOI 10.1016/1049-9660(91)90034-M; Kitamura Y., 1990, Advanced Robotics, V4, P29, DOI 10.1163/156855390X00035; LUONG QT, 1993, 1894 INRIA; MILENKOVIC VJ, 1985, P DARPA IM UND WORKS, P163; MOHR R, 1990, PATTERN RECOGN, V12, P39; MOHR R, 1992, P DARPA ESPRIT WORKS, P440; Mundy J., 1992, GEOMETRIC INVARIANCE; Pietikainen M., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P2; PIETIKAINEN M, 1987, P NATO ADV WORKSH RE; QUAN L, 1994, P 3 EUR C COMP VIS S, P459; ROBERT L, 1993, THESIS ECOLE POLYTEC; ROBERT L, 1991, C COMP VIS PATT REC, P57; Semple J.G, 1952, ALGEBRAIC PROJECTIVE; SHASHUA A, 1994, IN PRESS IEEE T PATT; SHASHUA A, 1993, P INT C COMP VIS BER, P583; SHASHUA A, 1993, TECHNICAL REPORT AI, V1405; ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234; YACHIDA M, 1986, ROBOTICS RES, P11; YANG D, 1992, P BRIT MACH VIS C LE, P327	29	40	43	0	2	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	APR	1996	18	1					5	19		10.1007/BF00126137	http://dx.doi.org/10.1007/BF00126137			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	UJ409		Green Submitted			2022-12-18	WOS:A1996UJ40900001
J	ALOIMONOS, Y; DURIC, Z				ALOIMONOS, Y; DURIC, Z			ESTIMATING THE HEADING DIRECTION USING NORMAL FLOW	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							MOTION; IMAGE; FIELD	If an observer is moving rigidly with bounded rotation then normal flow measurements (i.e., the spatiotemporal derivatives of the image intensity function) give rise to a constraint on the oberver's translation. This novel constraint gives rise to a robust, qualitative solution to the problem of recovering the observer's heading direction, by providing an area where the Focus of Expansion lies. If the rotation of the observer is large then the solution area is large too, while small rotation causes the solution area to be small, thus giving rise to a robust solution. In the paper the relationship between the solution area and the rotation and translation vectors is studied and experimental results using synthetic and real calibrated image sequences are presented. This work demonstrates that the algorithm developed in (Horn and Weldon 1987) for the case of pure translation, if appropriately modified, results in a robust algorithm that works in the case of general rigid motion with bounded rotation. Subsequently, it has the potential to replace expensive accelerometers, inertial systems and inaccurate odometers in practical navigational systems for the problem of kinetic stabilization, which is a prerequisite for any other navigational ability.	UNIV MARYLAND,INST ADV COMP STUDIES,COLLEGE PK,MD 20742	University System of Maryland; University of Maryland College Park	ALOIMONOS, Y (corresponding author), UNIV MARYLAND,DEPT COMP SCI,CTR AUTOMAT RES,COMP VIS LAB,COLLEGE PK,MD 20742, USA.		Aloimonos, Yiannis/AAI-2969-2020	Aloimonos, Yiannis/0000-0002-8152-4281				Aloimonos J., 1984, Proceedings of the Workshop on Computer Vision: Representation and Control, P72; ALOIMONOS J, 1989, INTEGRATION VISUAL M; ALOIMONOS J, 1992, CVGIP IMAGE UNDERSTA, V56; ALOIMONOS J, 1990, P DARPA IMAGE UNDERS, P816; ALOIMONOS J, 1988, INT J COMPUT VISION, V2, P333; [Anonymous], 1986, EVASION DIVISAS HIST; BALLARD DH, 1984, ARTIF INTELL, V22, P235, DOI 10.1016/0004-3702(84)90052-3; BLAKE A, 1992, COMMUNICATION; BRUSS AR, 1983, COMPUT VISION GRAPH, V21, P3, DOI 10.1016/S0734-189X(83)80026-7; BURGER W, 1990, IEEE T PATTERN ANAL, V12, P1040, DOI 10.1109/34.61704; DURIC Z, 1993, 4TH P ICCV BERL, P363; FAUGERAS OD, 1990, INT J COMPUT VISION, V4, P225, DOI 10.1007/BF00054997; FERMULLER C, 1993, ACTIVE PERCEPTION; FERMULLER C, 1993, THESIS TU VIENNA; FRANCOIS E, 1990, IMAGE VISION COMPUT, V8, P279, DOI 10.1016/0262-8856(90)80004-D; Horn B. K. P., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P2; HORN BKP, 1990, INT J COMPUT VISION, V4, P59, DOI 10.1007/BF00137443; KOENDERINK JJ, 1975, OPT ACTA, V22, P773, DOI 10.1080/713819112; KORN GA, 1968, MATH HDB ENG SCI; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; Marr D., 1982, VISION; MAYBANK SJ, 1985, P ROY SOC LOND A MAT, V401, P317, DOI 10.1098/rspa.1985.0101; NEGAHDARIPOUR S, 1986, THESIS MIT; NELSON RC, 1989, IEEE T PATTERN ANAL, V11, P1102, DOI 10.1109/34.42840; NELSON RC, 1988, BIOL CYBERN, V58, P261, DOI 10.1007/BF00364131; SPETSAKIS ME, 1990, INT J COMPUT VISION, V4, P171, DOI 10.1007/BF00054994; SPETSAKIS ME, 1988, P INT C COMPUTER VIS; SPETSAKIS ME, 1989, CARTR482 U MARYL CTR; THOMPSON WB, 1992, CVGIP-IMAG UNDERSTAN, V56, P69, DOI 10.1016/1049-9660(92)90086-I; TISTARELLI M, 1992, CVGIP-IMAG UNDERSTAN, V56, P87; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; WEINSHALL D, 1991, IEEE T PATTERN ANAL, V13, P1236, DOI 10.1109/34.106997; WEINSHALL D, 1990, COMPUT VISION GRAPH, V49, P222, DOI 10.1016/0734-189X(90)90138-L; WENG J, 1987, P IEEE COMPUTER SOC; WHITE G, 1987, P IEEE WORKSHOP COMP, P132; YOUNG GS, 1988, P IEEE C COMPUTER VI; ZISSERMAN A, 1990, P WORKSHOP QUALITATI, P41	39	40	41	0	2	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	1994	13	1					33	56		10.1007/BF01420794	http://dx.doi.org/10.1007/BF01420794			24	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	PK120					2022-12-18	WOS:A1994PK12000002
J	NELSON, RC				NELSON, RC			QUALITATIVE DETECTION OF MOTION BY A MOVING OBSERVER	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							OPTICAL-FLOW; SEQUENCES; OBJECTS	Two complementary methods for the detection of moving objects by a moving observer are described. The first is based on the fact that, in a rigid environment, the projected velocity at any point in the image is constrained to lie on a 1-D locus in velocity space whose parameters depend only on the observer motion. If the observer motion is known, an independently moving object can, in principle, be detected because its projected velocity is unlikely to fall on this locus. We show how this principle can be adapted to use partial information about the motion field and observer motion that can be rapidly computed from real image sequences. The second method utilizes the fact that the apparent motion of a fixed point due to smooth observer motion changes slowly, while the apparent motion of many moving objects such as animals or maneuvering vehicles may change rapidly. The motion field at a given time can thus be used to place constraints on the future motion field which, if violated, indicate the presence of an autonomously maneuvering object. In both cases, the qualitative nature of the constraints allows the methods to be used with the inexact motion information typically available from real-image sequences. Implementations of the methods that run in real time on a parallel pipelined image processing system are described.	UNIV ROCHESTER,DEPT COMP SCI,ROCHESTER,NY 14627	University of Rochester								Adiv G., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P70; ALOIMONOS Y, 1990, P AAAI WORKSHOP QUAL, P1; ANANDAN P, 1985, 3RD P WORKSH COMP VI, P186; Anderson C., 1985, P SPIE C INTELIGENT, P300; Barnard ST, 1980, IEEE T PAMI, V2, P330, DOI [10.1109/TPAMI.1980.4767032, DOI 10.1109/TPAMI.1980.4767032]; BHANU B, 1989, P DARPA IMAGE UNDERS, P370; BOLLES RC, 1987, P INT JOINT C INTELL, P7; BROWN CM, 1989, P DARPA IM UND WORKS, P651; BROWN CM, 1988, TR257 U ROCH COMP SC; BROWN CM, 1988, TR259 U ROCH COMP SC; BURT PJ, 1989, P IEEE WORKSHOP MOTI; COOMBS DJ, 1989, P TOPICAL M IMAGE UN; DINSTEIN I, 1988, PATTERN RECOGN LETT, V8, P347, DOI 10.1016/0167-8655(88)90085-2; Heeger D. J., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P435, DOI 10.1109/CCV.1988.590020; HEEGER DJ, 1987, 1ST P INT C COMP VIS, P181; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; JAIN RC, 1984, IEEE T PATTERN ANAL, V6, P624, DOI 10.1109/TPAMI.1984.4767575; LITTLE JJ, 1988, TR905 UBC DEP COMP S, P454; LONGUETHIGGINS HC, 1981, NATURE, P293; MOROVEC HP, 1979, 6TH P INT JOINT C AR, P598; NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833; NAGEL HH, 1983, COMPUT VISION GRAPH, V21, P85, DOI 10.1016/S0734-189X(83)80030-9; Nelson R, 1988, THESIS U MARYLAND; NELSON RC, 1989, IEEE T PATTERN ANAL, V11, P1102, DOI 10.1109/34.42840; NELSON RC, 1988, BIOL CYBERN, V58, P261, DOI 10.1007/BF00364131; NELSON RC, 1988, TR2087 U MAR COMP SC; PRAZDNY K, 1981, COMPUT VISION GRAPH, V17, P238, DOI 10.1016/0146-664X(81)90004-6; PRAZDNY K, 1980, BIOL CYBERN, V36, P87, DOI 10.1007/BF00361077; SCHUNCK BG, 1984, IEEE WORKSHOP COMPUT, P58; THOMPSON WB, 1990, INT J COMPUT VISION, V4, P39, DOI 10.1007/BF00137442; THOMPSON WB, 1986, MAY WORKSH MOT REPRE; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; TSAI RY, 1981, IEEE ASSP, V30, P525; ULLMAN S, 1979, P ROY SOC LOND B BIO, V203, P404; URAS S, 1988, BIOL CYBERN, V60, P79, DOI 10.1007/BF00202895; VERRI A, 1987, 1ST P INT C COMP VIS, P171; WAXMAN AM, 1987, ADV COMPUTER VISION	37	40	40	0	5	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	1991	7	1					33	46		10.1007/BF00130488	http://dx.doi.org/10.1007/BF00130488			14	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	GY893		Green Submitted			2022-12-18	WOS:A1991GY89300003
J	WAXMAN, AM; KAMGARPARSI, B; SUBBARAO, M				WAXMAN, AM; KAMGARPARSI, B; SUBBARAO, M			CLOSED-FORM SOLUTIONS TO IMAGE FLOW EQUATIONS FOR 3D STRUCTURE AND MOTION	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article									UNIV MARYLAND,CTR AUTOMAT RES,COMP VIS LAB,COLLEGE PK,MD 20742	University System of Maryland; University of Maryland College Park								ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284; ADIV G, 1984, OCT P DARPA IM UND W, P113; ANDERSON CH, 1985, SEP P SPIE C INT ROB; Aris R., 1962, VECTORS TENSORS BASI; BANDYOPADHYAY A, 1985, 168 U ROCH DEP COMP; BRAUNSTEIN M, 1976, DEPTH PERCEPTION MOT; BRAUNSTEIN ML, 1983, APR P WORKSH MOT REP, P119; BUXTON BF, 1984, 6TH P EUR C ART INT, P631; DONER J, 1984, J EXP PSYCHOL HUMAN, V10, P1; FLEET DJ, 1985, OCT P IEEE COMP VIS, P179; Gibson J., 1979, ECOLOGICAL APPROACH; Gibson JJ., 1966, SENSES CONSIDERED PE; HAY JC, 1966, PSYCHOL REV, V73, P550, DOI 10.1037/h0023863; HILDRETH EC, 1983, APR P WORKSH MOT REP, P26; HOFFMAN DD, 1985, J OPT SOC AM A, V2, P350, DOI 10.1364/JOSAA.2.000350; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HUANG TS, 1983, IMAGE SEQUENCE PROCE; JENKIN MRM, 1984, RBCVTR833 U TOR DEP; JOHANSSON G, 1975, SCI AM, V232, P76, DOI 10.1038/scientificamerican0675-76; KANATANI K, 1985, DEC P DARPA IM UND W, P107; KOENDERINK JJ, 1975, OPT ACTA, V22, P773, DOI 10.1080/713819112; KOENDERINK JJ, 1976, J OPT SOC AM, V66, P717, DOI 10.1364/JOSA.66.000717; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; LONGUETHIGGINS HC, 1984, PROC R SOC SER B-BIO, V223, P165, DOI 10.1098/rspb.1984.0088; MARR D, 1981, PROC R SOC SER B-BIO, V211, P151, DOI 10.1098/rspb.1981.0001; Marr D., 1982, VISION; MAYBANK SJ, 1985, P ROY SOC LOND A MAT, V401, P317, DOI 10.1098/rspa.1985.0101; MCCONNELL AJ, 1957, APPLICATIONS TENSOR; Mitiche A., 1984, First Conference on Artificial Intelligence Applications (Cat. No. 84CH2107-1), P156; MURRAY DW, 1987, IEEE T PATTERN ANAL, V9, P220, DOI 10.1109/TPAMI.1987.4767896; NAGEL HH, 1985, 3RD P INT S ROB RES; NAGEL HH, 1983, ACM MOTION WORKSHOP, P59; PRAZDNY K, 1980, BIOL CYBERN, V36, P87, DOI 10.1007/BF00361077; REGAN D, 1979, VISION RES, V19, P1331, DOI 10.1016/0042-6989(79)90205-0; REGAN D, 1979, SCIENCE, V205, P311, DOI 10.1126/science.451604; REGAN D, 1985, J OPT SOC AM A, V2, P280, DOI 10.1364/JOSAA.2.000280; RICHARDS W, 1985, J OPT SOC AM A, V2, P343, DOI 10.1364/JOSAA.2.000343; SCHUNCK BG, 1984, APR P WORKSH COMP VI, P58; SCHUNCK BG, 1986, MAY P WORKSH MOT REP, P89; SUBBARAO M, 1986, COMPUT VISION GRAPH, V36, P208, DOI 10.1016/0734-189X(86)90076-9; SUBBARAO M, 1986, THESIS U MARYLAND; SUBBARAO M, 1986, UNPUB INT J COMPUTER; SUBBARAO M, 1985, OCT P WORKSH COMP VI, P129; THOMPSON WB, 1985, IEEE T PATTERN ANAL, V7, P374, DOI 10.1109/TPAMI.1985.4767677; TODD JT, 1985, J EXP PSYCHOL HUMAN, V11, P689, DOI 10.1037/0096-1523.11.6.689; TSAI RY, 1981, R922 U ILL COORD SCI; TSAI RY, 1981, R921 U ILL COORD SCI; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; ULLMAN S, 1982, MIT721 ART INT LAB M; WALLACH H, 1953, J EXP PSYCHOL, V45, P205, DOI 10.1037/h0056880; WAXMAN AM, 1986, IEEE T PATTERN ANAL, V8, P715, DOI 10.1109/TPAMI.1986.4767853; WAXMAN AM, 1985, INT J ROBOT RES, V4, P72, DOI 10.1177/027836498500400306; WAXMAN AM, 1985, INT J ROBOT RES, V4, P95, DOI 10.1177/027836498500400307; WAXMAN AM, 1984, OCT P DARPA IM UND W, P130; WAXMAN AM, 1983, 24 U MAR CENT AUT RE; WAXMAN AM, 1984, 58 U MAR CENT AUT RE; WAXMAN AM, 1984, APR P WORKSH COMP VI, P49; WAXMAN AM, IN PRESS ADV COMPUTE; WAXMAN AM, 1985, 119 U MAR CENT AUT R; Winger R., 1962, PROJECTIVE GEOMETRY; WOHN K, 1987, UNPUB COMPUTER V JAN; WOHN K, 134 U MAR CENT AUT R; WOHN K, 1984, THESIS U MARYLAND	64	40	41	0	4	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.		1987	1	3					239	258						20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	M2050					2022-12-18	WOS:A1987M205000004
J	Li, Y; Wang, G; Ji, XY; Xiang, Y; Fox, D				Li, Yi; Wang, Gu; Ji, Xiangyang; Xiang, Yu; Fox, Dieter			DeepIM: Deep Iterative Matching for 6D Pose Estimation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						3D object recognition; 6D object pose estimation; Object tracking	OBJECT RECOGNITION; REGISTRATION; HISTOGRAMS	Estimating 6D poses of objects from images is an important problem in various applications such as robot manipulation and virtual reality. While direct regression of images to object poses has limited accuracy, matching rendered images of an object against the input image can produce accurate results. In this work, we propose a novel deep neural network for 6D pose matching named DeepIM. Given an initial pose estimation, our network is able to iteratively refine the pose by matching the rendered image against the observed image. The network is trained to predict a relative pose transformation using a disentangled representation of 3D location and 3D orientation and an iterative training process. Experiments on two commonly used benchmarks for 6D pose estimation demonstrate that DeepIM achieves large improvements over state-of-the-art methods. We furthermore show that DeepIM is able to match previously unseen objects.	[Li, Yi; Fox, Dieter] Univ Washington, Seattle, WA 98195 USA; [Li, Yi; Wang, Gu; Ji, Xiangyang] Tsinghua Univ, Beijing, Peoples R China; [Li, Yi; Wang, Gu; Ji, Xiangyang] BNRist, Beijing, Peoples R China; [Xiang, Yu; Fox, Dieter] NVIDIA, Seattle, WA USA	University of Washington; University of Washington Seattle; Tsinghua University	Li, Y (corresponding author), Univ Washington, Seattle, WA 98195 USA.; Li, Y (corresponding author), Tsinghua Univ, Beijing, Peoples R China.; Li, Y (corresponding author), BNRist, Beijing, Peoples R China.	yili.matrix@gmail.com; wangg16@mails.tsinghua.edu.cn; xyji@tsinghua.edu.cn; yux@nvidia.com; dieterf@nvidia.com	Wang, Gu/ABG-9917-2021	Wang, Gu/0000-0002-0759-0782	Siemens Grant; National Key R&D Program of China [2017YFB1002202]; NSFC [61620106005, 61325003]; Beijing Municipal Sci. & Tech. Commission [Z181100008918014]; THU Initiative Scientific Research Program	Siemens Grant; National Key R&D Program of China; NSFC(National Natural Science Foundation of China (NSFC)); Beijing Municipal Sci. & Tech. Commission; THU Initiative Scientific Research Program	We thank Lirui Wang at University of Washington for his contribution in this project. This work was funded in part by a Siemens Grant. We would also like to thank NVIDIA for generously providing the DGX station used for this research via the NVIDIA Robotics Lab and the UW NVIDIA AI Lab (NVAIL). This work was also Supported by National Key R&D Program of China 2017YFB1002202, NSFC Projects 61620106005, 61325003, Beijing Municipal Sci. & Tech. Commission Z181100008918014 and THU Initiative Scientific Research Program.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; BESL PJ, 1992, P SOC PHOTO-OPT INS, V1611, P586, DOI 10.1117/12.57955; Brachmann E, 2016, PROC CVPR IEEE, P3364, DOI 10.1109/CVPR.2016.366; Brachmann E, 2014, LECT NOTES COMPUT SC, V8690, P536, DOI 10.1007/978-3-319-10605-2_35; Calli B, 2015, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P510, DOI 10.1109/ICAR.2015.7251504; Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512; Collet A, 2011, INT J ROBOT RES, V30, P1284, DOI 10.1177/0278364911401765; Costante G, 2018, IEEE ROBOT AUTOM LET, V3, P1735, DOI 10.1109/LRA.2018.2803211; Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Deng XK, 2019, ROBOTICS: SCIENCE AND SYSTEMS XV; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Garon M, 2017, IEEE T VIS COMPUT GR, V23, P2410, DOI 10.1109/TVCG.2017.2734599; Garon M, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P189, DOI [10.1109/ISMAR-Adjunct.2016.0073, 10.1109/ISMAR-Adjunct.2016.64]; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gu CH, 2010, LECT NOTES COMPUT SC, V6315, P408; Hinterstoisser S, 2016, LECT NOTES COMPUT SC, V9907, P834, DOI 10.1007/978-3-319-46487-9_51; Hinterstoisser S, 2012, IEEE T PATTERN ANAL, V34, P876, DOI 10.1109/TPAMI.2011.206; Hinterstoisser Stefan, 2012, P AS C COMP VIS, P2, DOI DOI 10.1007/978-3-642-37331-2_42; Hodan T, 2017, IEEE WINT CONF APPL, P880, DOI 10.1109/WACV.2017.103; Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655; Jurie F, 2001, PROC CVPR IEEE, P791; Kehl W, 2017, IEEE I CONF COMP VIS, P1530, DOI 10.1109/ICCV.2017.169; Kendall A, 2017, PROC CVPR IEEE, P6555, DOI 10.1109/CVPR.2017.694; Krull A, 2015, IEEE I CONF COMP VIS, P954, DOI 10.1109/ICCV.2015.115; Lin CH, 2017, PROC CVPR IEEE, P2252, DOI 10.1109/CVPR.2017.242; Liu MY, 2010, PROC CVPR IEEE, P1696, DOI 10.1109/CVPR.2010.5539837; Lowe D.G., 1999, P IEEE INT C COMP VI, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410; Manhardt F, 2018, LECT NOTES COMPUT SC, V11218, P833, DOI 10.1007/978-3-030-01264-9_49; Mellado N, 2014, COMPUT GRAPH FORUM, V33, P205, DOI 10.1111/cgf.12446; Mian AS, 2006, IEEE T PATTERN ANAL, V28, P1584, DOI 10.1109/TPAMI.2006.213; Michel F., 2017, P IEEE C COMPUTER VI; Mousavian A., 2017, PROC CVPR IEEE, P7074, DOI DOI 10.1109/CVPR.2017.597; Nister D, 2005, MACH VISION APPL, V16, P321, DOI 10.1007/s00138-005-0006-y; Oberweger M, 2015, IEEE I CONF COMP VIS, P3316, DOI 10.1109/ICCV.2015.379; Rad M, 2017, IEEE I CONF COMP VIS, P3848, DOI 10.1109/ICCV.2017.413; Redmon J, 2016, YOU ONLY LOOK ONCE U, DOI [DOI 10.1109/CVPR.2016.91, 10.1109/CVPR.2016.91]; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rothganger F, 2006, INT J COMPUT VISION, V66, P231, DOI 10.1007/s11263-005-3674-1; Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423; Rusu RB, 2009, IEEE INT CONF ROBOT, P1848; Salvi J, 2007, IMAGE VISION COMPUT, V25, P578, DOI 10.1016/j.imavis.2006.05.012; Saxena Aseem, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3817, DOI 10.1109/ICRA.2017.7989442; Shotton J, 2013, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2013.377; Sundermeyer M, 2018, LECT NOTES COMPUT SC, V11210, P712, DOI 10.1007/978-3-030-01231-1_43; Tam GKL, 2013, IEEE T VIS COMPUT GR, V19, P1199, DOI 10.1109/TVCG.2012.310; TEKIN B, 2017, ARXIV171108848; Theiler PW, 2015, ISPRS J PHOTOGRAMM, V109, P126, DOI 10.1016/j.isprsjprs.2015.08.007; Tjaden H, 2017, IEEE I CONF COMP VIS, P124, DOI 10.1109/ICCV.2017.23; Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1_26; Tremblay Jonathan, 2018, CORL; Wang C, 2019, PROC CVPR IEEE, P3338, DOI 10.1109/CVPR.2019.00346; Wang S, 2017, INT CONF ACOUST SPEE, P436, DOI 10.1109/ICASSP.2017.7952193; Wei Liu, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9905, P21, DOI 10.1007/978-3-319-46448-0_2; WU ZR, 2015, PROC CVPR IEEE, P1912, DOI DOI 10.1109/CVPR.2015.7298801; Xiang Y, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV; Yang JL, 2016, IEEE T PATTERN ANAL, V38, P2241, DOI 10.1109/TPAMI.2015.2513405; Zhou QY, 2016, LECT NOTES COMPUT SC, V9906, P766, DOI 10.1007/978-3-319-46475-6_47	61	39	40	5	32	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2020	128	3			SI		657	678		10.1007/s11263-019-01250-9	http://dx.doi.org/10.1007/s11263-019-01250-9		NOV 2019	22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	KU1MV		Green Submitted			2022-12-18	WOS:000494408100002
J	Henderson, P; Ferrari, V				Henderson, Paul; Ferrari, Vittorio			Learning Single-Image 3D Reconstruction by Generative Modelling of Shape, Pose and Shading	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Single-image 3D reconstruction; Generative models; Shape from shading; Neural networks		We present a unified framework tackling two problems: class-specific 3D reconstruction from a single image, and generation of new 3D shape samples. These tasks have received considerable attention recently; however, most existing approaches rely on 3D supervision, annotation of 2D images with keypoints or poses, and/or training with multiple views of each object instance. Our framework is very general: it can be trained in similar settings to existing approaches, while also supporting weaker supervision. Importantly, it can be trained purely from 2D images, without pose annotations, and with only a single view per instance. We employ meshes as an output representation, instead of voxels used in most prior work. This allows us to reason over lighting parameters and exploit shading information during training, which previous 2D-supervised methods cannot. Thus, our method can learn to generate and reconstruct concave object classes. We evaluate our approach in various settings, showing that: (i) it learns to disentangle shape from pose and lighting; (ii) using shading in the loss improves performance compared to just silhouettes; (iii) when using a standard single white light, our model outperforms state-of-the-art 2D-supervised methods, both with and without pose supervision, thanks to exploiting shading cues; (iv) performance improves further when using multiple coloured lights, even approaching that of state-of-the-art 3D-supervised methods; (v) shapes produced by our model capture smooth surfaces and fine details better than voxel-based approaches; and (vi) our approach supports concave classes such as bathtubs and sofas, which methods based on silhouettes cannot learn.	[Henderson, Paul] IST Austria, Klosterneuburg, Austria; [Ferrari, Vittorio] Google Res, Zurich, Switzerland	Institute of Science & Technology - Austria; Google Incorporated	Henderson, P (corresponding author), IST Austria, Klosterneuburg, Austria.	paul@pmh47.net; vittoferrari@google.com	Henderson, Paul/AAK-7867-2021	Henderson, Paul/0000-0002-5198-7445	Institute of Science and Technology (IST Austria)	Institute of Science and Technology (IST Austria)	Open access funding provided by Institute of Science and Technology (IST Austria).	Achlioptas P, 2018, PR MACH LEARN RES, V80; Balashova E, 2018, ISTORIYA-ELEKTRON, V9, DOI 10.18254/S0002203-2-1; Barron JT, 2015, IEEE T PATTERN ANAL, V37, P1670, DOI 10.1109/TPAMI.2014.2377712; BROADHURST A, 2001, P INT C COMP VIS; Chang Angel X., 2015, arXiv; Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38; DEBONET JS, 1999, P INT C COMP VIS; Ding M, 2010, IEEE ICC; Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264; Furukawa Y, 2013, FOUND TRENDS COMPUT, V9, P1, DOI 10.1561/0600000052; GADELHA M, 2018, P EUR C COMP VIS; Gadelha M, 2017, INT CONF 3D VISION, P402, DOI 10.1109/3DV.2017.00053; GARGALLO P, 1999, P INT C COMP VIS; GIRDHAR R, 2016, P EUR C COMP VIS; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; GOURAUD H, 1971, IEEE T COMPUT, VC 20, P623, DOI 10.1109/T-C.1971.223313; Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030; Gwak J, 2017, INT CONF 3D VISION, P263, DOI 10.1109/3DV.2017.00038; HENDERSON P, 2018, P BRIT MACH VIS C; Higgins I., 2017, P INT C LEARN REPR T; Horn Berthold K. P., 1975, PSYCHOL COMPUTER VIS, P115; Huang HB, 2015, COMPUT GRAPH FORUM, V34, P25, DOI 10.1111/cgf.12694; Insafutdinov E., 2018, ABS181009381 CORR; JiajunWu Chengkai Zhang, 2016, ADV NEURAL INFORM PR, V29, DOI DOI 10.5555/3157096.3157106; KANAZAWA A, 2018, P EUR C COMP VIS; Kar A, 2015, PROC CVPR IEEE, P1966, DOI 10.1109/CVPR.2015.7298807; Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411; Kingma D.P, P 3 INT C LEARNING R; Lambert J. H., 1760, PHOTOMETRIA; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; Li J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073637; Loper MM, 2014, LECT NOTES COMPUT SC, V8695, P154, DOI 10.1007/978-3-319-10584-0_11; Lu YK, 2017, I C OPT COMMUN NETW; MANDIKAL P, 2018, P BRIT MACH VIS C; Mousavian A., 2017, PROC CVPR IEEE, P7074, DOI DOI 10.1109/CVPR.2017.597; Nash C, 2017, COMPUT GRAPH FORUM, V36, P1, DOI 10.1111/cgf.13240; Niu CJ, 2018, PROC CVPR IEEE, P4521, DOI 10.1109/CVPR.2018.00475; Novotny D, 2017, IEEE I CONF COMP VIS, P5228, DOI 10.1109/ICCV.2017.558; Rezende DJ, 2016, ADV NEUR IN, V29; Rezende DJ, 2014, PR MACH LEARN RES, V32, P1278; Richter SR, 2018, PROC CVPR IEEE, P1936, DOI 10.1109/CVPR.2018.00207; Seitz S., 2006, 2006 IEEE COMP SOC C, V1, P519, DOI [10.1109/CVPR.2006.19, DOI 10.1109/CVPR.2006.19]; Shin Daeyun, 2018, P IEEE C COMP VIS PA; Soltani AA, 2017, PROC CVPR IEEE, P2511, DOI 10.1109/CVPR.2017.269; Tan QY, 2018, JCI INSIGHT, V3, DOI 10.1172/jci.insight.95882; Tulsiani S, 2017, PROC CVPR IEEE, P1466, DOI 10.1109/CVPR.2017.160; Tulsiani Shubham, 2018, P IEEE C COMP VIS PA; Vicente S, 2014, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2014.13; WANG N, 2018, P EUR C COMP VIS; Wiles Olivia, 2017, P BMVC; Xie JW, 2018, PROC CVPR IEEE, P8629, DOI 10.1109/CVPR.2018.00900; YANG G, 2018, P EUR C COMP VIS; Zeng MY, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301296; Zhang CH, 2017, SCI ADV, V3, DOI 10.1126/sciadv.1700225; Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284; ZHU JY, 2018, ADV NEURAL INFORM PR	58	39	42	0	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	2020	128	4			SI		835	854		10.1007/s11263-019-01219-8	http://dx.doi.org/10.1007/s11263-019-01219-8		OCT 2019	20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	LC5TN		Green Submitted, Green Accepted, hybrid			2022-12-18	WOS:000491042100002
J	Qin, Y; Feng, MY; Lu, HC; Cottrell, GW				Qin, Yao; Feng, Mengyang; Lu, Huchuan; Cottrell, Garrison W.			Hierarchical Cellular Automata for Visual Saliency	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Saliency detection; Hierarchical Cellular Automata; Deep contrast features; Bayesian framework	OBJECT DETECTION; REGION DETECTION; INTEGRATION; FEATURES	Saliency detection, finding the most important parts of an image, has become increasingly popular in computer vision. In this paper, we introduce Hierarchical Cellular Automata (HCA)-a temporally evolving model to intelligently detect salient objects. HCA consists of two main components: Single-layer Cellular Automata (SCA) and Cuboid Cellular Automata (CCA). As an unsupervised propagation mechanism, Single-layer Cellular Automata can exploit the intrinsic relevance of similar regions through interactions with neighbors. Low-level image features as well as high-level semantic information extracted from deep neural networks are incorporated into the SCA to measure the correlation between different image patches. With these hierarchical deep features, an impact factor matrix and a coherence matrix are constructed to balance the influences on each cell's next state. The saliency values of all cells are iteratively updated according to a well-defined update rule. Furthermore, we propose CCA to integrate multiple saliency maps generated by SCA at different scales in a Bayesian framework. Therefore, single-layer propagation and multi-scale integration are jointly modeled in our unified HCA. Surprisingly, we find that the SCA can improve all existing methods that we applied it to, resulting in a similar precision level regardless of the original results. The CCA can act as an efficient pixel-wise aggregation algorithm that can integrate state-of-the-art methods, resulting in even better results. Extensive experiments on four challenging datasets demonstrate that the proposed algorithm outperforms state-of-the-art conventional methods and is competitive with deep learning based approaches.	[Qin, Yao; Cottrell, Garrison W.] Univ Calif San Diego, San Diego, CA 92103 USA; [Feng, Mengyang; Lu, Huchuan] Dalian Univ Technol, Dalian, Peoples R China	University of California System; University of California San Diego; Dalian University of Technology	Lu, HC (corresponding author), Dalian Univ Technol, Dalian, Peoples R China.	yaq007@eng.ucsd.edu; mengyangfeng@gmail.com; lhchuan@dlut.edu.cn; gary@eng.ucsd.edu		Feng, Mengyang/0000-0002-7112-4655; Cottrell, Garrison/0000-0001-7538-1715	National Natural Science Foundation of China [61725202, 61528101, 61472060]; Guangzhou Science and Technology Planning Project [201704030051]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Guangzhou Science and Technology Planning Project	MY Feng and HC Lu were supported in part by the National Natural Science Foundation of China under Grants 61725202, 61528101, 61472060. YQ and GWC were also partially supported by Guangzhou Science and Technology Planning Project (Grant No. 201704030051).	Achanta R., 2010, TECHNICAL REPORT; Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596; Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226; Batty M., 2007, CITIES COMPLEXITY UN; Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30; Bruce N., 2005, P 18 INT C NEUR INF, P155; Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193; Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344; Chopard B., 2005, CELLULAR AUTOMATA MO, V6; Cowburn RP, 2000, SCIENCE, V287, P1466, DOI 10.1126/science.287.5457.1466; de Almeida C. M., 2003, Computers, Environment and Urban Systems, V27, P481, DOI 10.1016/S0198-9715(02)00042-X; Ding YY, 2011, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2011.5995445; Donahue J, 2014, PR MACH LEARN RES, V32; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929; Gong C, 2015, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2015.7298868; Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20; Hou X, 2007, 2007 IEEE C COMP VIS, V800, P1, DOI DOI 10.1109/CVPR.2007.383267; Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558; Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500; Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209; Jiang HZ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.110; Jiang ZL, 2013, PROC CVPR IEEE, P2043, DOI 10.1109/CVPR.2013.266; Kanan C, 2010, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2010.5539947; Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118; Kim J, 2016, LECT NOTES COMPUT SC, V9908, P455, DOI 10.1007/978-3-319-46493-0_28; Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184; Li N., 2014, P IEEE C COMP VIS PA; Li X, 2016, IEEE T IMAGE PROCESS, V25, P3919, DOI 10.1109/TIP.2016.2579306; Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370; Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43; Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Mahadevan V, 2009, PROC CVPR IEEE, P1007, DOI 10.1109/CVPRW.2009.5206573; Marchesotti L, 2009, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2009.5459467; Martins ACR, 2008, INT J MOD PHYS C, V19, P617, DOI 10.1142/S0129183108012339; Ng AY, 2002, ADV NEUR IN, V14, P849; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Pan QH, 2017, INT J MOD PHYS C, V28, DOI 10.1142/S0129183117500036; Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743; Pinheiro PO, 2014, PR MACH LEARN RES, V32; Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606; Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27; Reinagel P, 1999, NETWORK-COMP NEURAL, V10, P341, DOI 10.1088/0954-898X/10/4/304; Scharfenberger C, 2013, PROC CVPR IEEE, P979, DOI 10.1109/CVPR.2013.131; Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758; Shi KY, 2013, PROC CVPR IEEE, P2115, DOI 10.1109/CVPR.2013.275; Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40; Smith III A.R., 1972, J COMPUT SYST SCI, V6, P233, DOI DOI 10.1016/S0022-0000(72)80004-7; Sun J, 2011, IEEE I CONF COMP VIS, P1511, DOI 10.1109/ICCV.2011.6126409; Sun J, 2012, IEEE IMAGE PROC, P1085, DOI 10.1109/ICIP.2012.6467052; Szegedy C, 2013, ADV NEURAL INFORM PR, P2553; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Tong N, 2015, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2015.7298798; Tong N, 2015, PATTERN RECOGN, V48, P3258, DOI 10.1016/j.patcog.2014.12.005; von Neumann J., 1951, GEN LOGICAL THEORY A; Von Neumann J., 1966, IEEE T NEURAL NETW, V5, P3; Wang L, 2011, IEEE I CONF COMP VIS, P105, DOI 10.1109/ICCV.2011.6126231; Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938; Wang QS, 2016, PROC CVPR IEEE, P535, DOI 10.1109/CVPR.2016.64; WOLFRAM S, 1983, REV MOD PHYS, V55, P601, DOI 10.1103/RevModPhys.55.601; Xie YL, 2013, IEEE T IMAGE PROCESS, V22, P1689, DOI 10.1109/TIP.2012.2216276; Xie YL, 2011, IEEE IMAGE PROC, P645, DOI 10.1109/ICIP.2011.6116634; Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153; Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407; Yang JM, 2012, PROC CVPR IEEE, P2296, DOI 10.1109/CVPR.2012.6247940; Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731; Zhou F., 2014, P IEEE C COMP VIS PA; Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360; Zou WB, 2015, IEEE I CONF COMP VIS, P406, DOI 10.1109/ICCV.2015.54	78	39	43	0	19	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2018	126	7					751	770		10.1007/s11263-017-1062-2	http://dx.doi.org/10.1007/s11263-017-1062-2			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	GH0DS		Green Submitted			2022-12-18	WOS:000433072800005
J	Kovashka, A; Parikh, D; Grauman, K				Kovashka, Adriana; Parikh, Devi; Grauman, Kristen			WhittleSearch: Interactive Image Search with Relative Attribute Feedback	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Content-based image search; Interactive image search; Active selection; Relative attributes	RELEVANCE FEEDBACK; RETRIEVAL; QUERY; SCENE	We propose a novel mode of feedback for image search, where a user describes which properties of exemplar images should be adjusted in order to more closely match his/her mental model of the image sought. For example, perusing image results for a query "black shoes", the user might state, "Show me shoe images like these, but sportier." Offline, our approach first learns a set of ranking functions, each of which predicts the relative strength of a nameable attribute in an image (e.g., sportiness). At query time, the system presents the user with a set of exemplar images, and the user relates them to his/her target image with comparative statements. Using a series of such constraints in the multi-dimensional attribute space, our method iteratively updates its relevance function and re-ranks the database of images. To determine which exemplar images receive feedback from the user, we present two variants of the approach: one where the feedback is user-initiated and another where the feedback is actively system-initiated. In either case, our approach allows a user to efficiently "whittle away" irrelevant portions of the visual feature space, using semantic language to precisely communicate her preferences to the system. We demonstrate our technique for refining image search for people, products, and scenes, and we show that it outperforms traditional binary relevance feedback in terms of search speed and accuracy. In addition, the ordinal nature of relative attributes helps make our active approach efficient-both computationally for the machine when selecting the reference images, and for the user by requiring less user interaction than conventional passive and active methods.	[Kovashka, Adriana] Univ Pittsburgh, Pittsburgh, PA 15260 USA; [Parikh, Devi] Virginia Tech, Blacksburg, VA 24061 USA; [Grauman, Kristen] Univ Texas Austin, Austin, TX 78712 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Virginia Polytechnic Institute & State University; University of Texas System; University of Texas Austin	Kovashka, A (corresponding author), Univ Pittsburgh, 5325 Sennott Sq,210 South Bouquet St, Pittsburgh, PA 15260 USA.	kovashka@cs.pitt.edu; parikh@vt.edu; grauman@cs.utexas.edu			ONR YIP Award [N00014-12-1-0754]; Google Faculty Research Award	ONR YIP Award; Google Faculty Research Award(Google Incorporated)	We thank the anonymous reviewers for their helpful feedback and suggestions. This research was supported by ONR YIP Award N00014-12-1-0754 (K.G. and A.K.) and Google Faculty Research Award (D.P.).	Berg T., 2010, P EUR C COMP VIS ECC; Biswas A., 2013, P IEEE C COMP VIS PA; BRANSON S., 2010, P EUR C COMP VIS ECC; Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596; Douze M., 2011, P IEEE C COMP VIS PA; Farhadi A., 2009, P IEEE C COMP VIS PA; Ferecatu M., 2007, P IEEE INT C COMP VI; FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146; Geman D, 2001, IEEE T INFORM THEORY, V47, P1075, DOI 10.1109/18.915664; Iqbal Q., 2002, P INT C CONTR AUT RO; Jarvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418; Jayaraman D., 2014, P IEEE C COMP VIS PA; Joachims T., 2006, P ACM SIGKDD C KNOWL; Joachims T., 2002, P ACM SIGKDD C KNOWL; Kovashka A., 2012, P IEEE C COMP VIS PA; Kovashka A., 2011, P IEEE INT C COMP VI; Kovashka A., 2013, P IEEE INT C COMP VI; Kulkarni P., 2014, P WINT C APPL COMP V; Kumar N., 2009, P IEEE INT C COMP VI; Kumar N., 2008, P EUR C COMP VIS ECC; Kurita T., 1993, P INT C DOC AN REC I; Lampert C. H., 2009, P IEEE C COMP VIS PA; Li B., 2001, P INT C MULT EXP ICM; Ma W., 1997, P INT C IM PROC ICIP; MacArthur S., 2000, P IEEE WORKSH CONT B; Maji S., 2012, P EUR C COMP VIS ECC; Mensink T., 2011, P IEEE C COMP VIS PA; Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Parikh D., 2013, P IEEE INT C COMP VI; Parikh D., 2011, P IEEE C COMP VIS PA; Parkash A., 2012, P EUR C COMP VIS ECC; Patterson G, 2014, INT J COMPUT VISION, V108, P59, DOI 10.1007/s11263-013-0695-z; Platt JC, 2000, ADV NEUR IN, P61; Rasiwasia N, 2007, IEEE T MULTIMEDIA, V9, P923, DOI 10.1109/TMM.2007.900138; Rastegari M., 2013, P IEEE C COMP VIS PA; Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510; Saleh B., 2013, P IEEE C COMP VIS PA; Scheirer Walter J, 2012, P IEEE C COMP VIS PA; Siddiquie Behjat, 2011, P IEEE C COMP VIS PA; Smith J., 2003, P INT C MULT EXP ICM; Sznitman R, 2010, IEEE T PATTERN ANAL, V32, P1914, DOI 10.1109/TPAMI.2010.106; Tieu Kinh, 2000, P IEEE C COMP VIS PA; Tong S., 2001, P ACM INT C MULT; VIJAYANARASIMHA.S, 2010, P IEEE C COMP VIS PA; Wah C., 2013, P IEEE C COMP VIS PA; Wah C., 2014, P IEEE C COMP VIS PA; Wang X, 2011, P IEEE C COMP VIS PA; Wang Y., 2010, P EUR C COMP VIS ECC; Zavesky E., 2008, P ACM INT C MULT INF; Zhang C, 2002, IEEE T MULTIMEDIA, V4, P260, DOI 10.1109/TMM.2002.1017738; Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3	52	39	47	1	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	2015	115	2					185	210		10.1007/s11263-015-0814-0	http://dx.doi.org/10.1007/s11263-015-0814-0			26	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	CS7SL		Green Submitted			2022-12-18	WOS:000362285700006
J	Ma, CG; Cao, X; Tong, X; Dai, QH; Lin, S				Ma, Chenguang; Cao, Xun; Tong, Xin; Dai, Qionghai; Lin, Stephen			Acquisition of High Spatial and Spectral Resolution Video with a Hybrid Camera System	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Multispectral video capture; Hybrid camera system	COLOR	We present a hybrid camera system for capturing video at high spatial and spectral resolutions. Composed of an red, green, and blue (RGB) video camera, a grayscale video camera and a few optical elements, the hybrid camera system simultaneously records two video streams: an RGB video with high spatial resolution, and a multispectral (MS) video with lowspatial resolution. After registration of the two video streams, our system propagates the MS information into the RGB video to produce a video with both high spectral and spatial resolution. This propagation between videos is guided by color similarity of pixels in the spectral domain, proximity in the spatial domain, and the consistent color of each scene point in the temporal domain. The propagation algorithm, based on trilateral filtering, is designed to rapidly generate output video from the captured data at frame rates fast enough for real-time video analysis tasks such as tracking and surveillance. We evaluate the proposed system using both simulations with ground truth data and on real-world scenes. The accuracy of spectral capture is examined through comparisons with ground truth and with a commercial spectrometer. The utility of this high resolution MS video data is demonstrated on the applications of dynamic white balance adjustment, object tracking, and separating the appearance contributions of different illumination sources. The various high resolution MS video datasets that we captured will be made publicly available to facilitate research on dynamic spectral data analysis.	[Ma, Chenguang; Dai, Qionghai] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China; [Cao, Xun] Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210008, Jiangsu, Peoples R China; [Tong, Xin; Lin, Stephen] Microsoft Res Asia, Beijing, Peoples R China	Tsinghua University; Nanjing University; Microsoft; Microsoft Research Asia	Cao, X (corresponding author), Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210008, Jiangsu, Peoples R China.	ChenguangMa2011@gmail.com; caoxun@nju.edu.cn; xtong@microsoft.com; qionghaidai@tsinghua.edu.cn; stevelin@microsoft.com	Dai, Qionghai/ABD-5298-2021	Dai, Qionghai/0000-0001-7043-3061	National Basic Research Project [2010CB731800]; NSFC [61035002, 61371166]	National Basic Research Project(National Basic Research Program of China); NSFC(National Natural Science Foundation of China (NSFC))	The authors thank Yanxiang Lan, Hao Du and Moshe Ben-Ezra for helpful discussions on implementation issues, Tao Yue for assistance in experimentation, the National Basic Research Project (No. 2010CB731800) and the Key Project of NSFC (No. 61035002), The NSFC Grant No. 61371166, and the reviewers for their constructive comments.	Angelopoulou E, 2001, PROC SPIE, V4299, P243, DOI 10.1117/12.429495; [Anonymous], P AS C COMP VIS; Brady D. J., 2006, SPIE, V6246; Brox T., 2004, ECCV; BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7; Cao X, 2011, PROC CVPR IEEE, P297, DOI 10.1109/CVPR.2011.5995418; Cao X, 2011, IEEE T PATTERN ANAL, V33, P2423, DOI 10.1109/TPAMI.2011.80; Chi C, 2010, INT J COMPUT VISION, V86, P140, DOI 10.1007/s11263-008-0176-y; Darling BA, 2011, NINETEENTH COLOR AND IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, AND APPLICATIONS, P345; DESCOUR M, 1995, APPL OPTICS, V34, P4817, DOI 10.1364/AO.34.004817; Du H., 2009, P ICCV; Fletcher-Holmes DW, 2005, J OPT A-PURE APPL OP, V7, pS298, DOI 10.1088/1464-4258/7/6/007; Habel R, 2012, COMPUT GRAPH FORUM, V31, P449, DOI 10.1111/j.1467-8659.2012.03024.x; Hagen N, 2008, APPL OPTICS, V47, pF85, DOI 10.1364/AO.47.000F85; James J.F., 2007, SPECTROGRAPH DESIGN; Johnson WR, 2006, APPL OPTICS, V45, P1898, DOI 10.1364/AO.45.001898; Kim MH, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185534; Kittle DS, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.7.071403; Mooney JM, 1997, J OPT SOC AM A, V14, P2951, DOI 10.1364/JOSAA.14.002951; Mrozack A, 2012, OPT EXPRESS, V20, P2297, DOI 10.1364/OE.20.002297; Nvidia C., 2007, COMPUTE UNIFIED DEVI; Park J.-I., 2007, ICCV, P3; Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7; Schechner YY, 2002, IEEE T PATTERN ANAL, V24, P1334, DOI 10.1109/TPAMI.2002.1039205; Shen L., 2008, P IEEE C COMPUTER VI, P1; Smits B., 1999, Journal of Graphics Tools, V4, P11, DOI 10.1080/10867651.1999.10487511; Vandervlugt C., 2007, SPIE, V6565; Volin C., 2000, MWIR SPECTROMETER OP; Wagadarikar A, 2008, APPL OPTICS, V47, pB44, DOI 10.1364/AO.47.000B44; Wagadarikar AA, 2009, OPT EXPRESS, V17, P6368, DOI 10.1364/OE.17.006368; Yamaguchi M., 2006, SPIE IS T ELECT IMAG, V6062; YANG Q, 2009, CVPR	33	39	45	2	23	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	2014	110	2			SI		141	155		10.1007/s11263-013-0690-4	http://dx.doi.org/10.1007/s11263-013-0690-4			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AY5UE					2022-12-18	WOS:000347636400005
J	Sapienza, M; Cuzzolin, F; Torr, PHS				Sapienza, Michael; Cuzzolin, Fabio; Torr, Philip H. S.			Learning Discriminative Space-Time Action Parts from Weakly Labelled Videos	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Action classification; Localisation; Multiple instance learning; Deformable part models; Space-time videos		Current state-of-the-art action classification methods aggregate space-time features globally, from the entire video clip under consideration. However, the features extracted may in part be due to irrelevant scene context, or movements shared amongst multiple action classes. This motivates learning with local discriminative parts, which can help localise which parts of the video are significant. Exploiting spatio-temporal structure in the video should also improve results, just as deformable part models have proven highly successful in object recognition. However, whereas objects have clear boundaries which means we can easily define a ground truth for initialisation, 3D space-time actions are inherently ambiguous and expensive to annotate in large datasets. Thus, it is desirable to adapt pictorial star models to action datasets without location annotation, and to features invariant to changes in pose such as bag-of-feature and Fisher vectors, rather than low-level HoG. Thus, we propose local deformable spatial bag-of-features in which local discriminative regions are split into a fixed grid of parts that are allowed to deform in both space and time at test-time. In our experimental evaluation we demonstrate that by using local space-time action parts in a weakly supervised setting, we are able to achieve state-of-the-art classification performance, whilst being able to localise actions even in the most challenging video datasets.	[Sapienza, Michael; Cuzzolin, Fabio] Oxford Brookes Univ, Dept Comp & Commun Technol, Oxford OX33 1HX, England; [Torr, Philip H. S.] Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England	Oxford Brookes University; University of Oxford	Sapienza, M (corresponding author), Oxford Brookes Univ, Dept Comp & Commun Technol, Oxford OX33 1HX, England.	michael.sapienza-2011@brookes.ac.uk; fabio.cuzzolin@brookes.ac.uk; philiptorr@hotmail.com	Sapienza, Michael/R-7304-2019	Sapienza, Michael/0000-0001-8876-8492	Engineering and Physical Sciences Research Council [EP/I001107/1, EP/I018719/1] Funding Source: researchfish; EPSRC [EP/I001107/1, EP/I018719/1] Funding Source: UKRI	Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))		Andrews S., 2002, SUPPORT VECTOR MACHI, P561; Blank M, 2005, IEEE I CONF COMP VIS, P1395; Boureau Y. L., 2010, IEEE INT C COMP VIS; Bronstein AM, 2009, INT J COMPUT VISION, V81, P281, DOI 10.1007/s11263-008-0172-2; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33; Dollar P., 2005, P IEEE INT WORKSH VI, P65, DOI [DOI 10.1109/VSPETS.2005.1570899, 10.1109/VSPETS.2005.1570899]; Duchenne O, 2009, IEEE I CONF COMP VIS, P1491, DOI 10.1109/ICCV.2009.5459279; Felzenszwalb P. F., 2004, TECHNICAL REPORT; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Gaidon A, 2011, PROC CVPR IEEE; Gilbert A, 2009, IEEE I CONF COMP VIS, P925, DOI 10.1109/ICCV.2009.5459335; Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407; Jhuang H, 2007, IEEE I CONF COMP VIS, P1253; Jiang ZL, 2012, IEEE T PATTERN ANAL, V34, P533, DOI 10.1109/TPAMI.2011.147; Ke Y, 2010, INT J COMPUT VISION, V88, P339, DOI 10.1007/s11263-009-0308-z; Klaser A., 2012, P EUR C COMP VIS, V6553, P219; Klaser Alexander, 2008, BMVC; Kliper-Gross O., 2012, P EUR C COMP VIS; Kuehne H., 2011, P INT C COMP VIS, DOI DOI 10.1109/ICCV.2011.6126543; Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378; Laptev I., 2007, P INT C COMP VIS; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; Le QV, 2011, PROC CVPR IEEE; Lin HT, 2007, MACH LEARN, V68, P267, DOI 10.1007/s10994-007-5018-6; Liu J., 2009, P BRIT MACH VIS C; Marszalek M., 2009, IEEE INT C COMP VIS; Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331; Parizi S., 2012, IEEE INT C COMP VIS; Perronnin F., 2012, IEEE INT C COMP VIS; Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11; Platt JC, 2000, ADV NEUR IN, P61; Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014; Rokhlin V, 2009, SIAM J MATRIX ANAL A, V31, P1100, DOI 10.1137/080736417; Sapienza M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.123; Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462; Scovanner P., 2007, ACM MM, P357; Shalev-Shwartz S, 2011, MATH PROGRAM, V127, P3, DOI 10.1007/s10107-010-0420-4; Vedaldi A., 2010, IEEE INT C COMP VIS; Vedaldi A., 2008, VLFEAT OPEN PORTABLE; Vig E., 2012, P EUR C COMP VIS; Viola P., 2005, ADV NEURAL INFORM PR, P1417; Wang Heng, 2009, BMVC, P1; Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002; Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48; Yeffet L., 2009, P INT C COMP VIS	48	39	39	0	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	OCT	2014	110	1			SI		30	47		10.1007/s11263-013-0662-8	http://dx.doi.org/10.1007/s11263-013-0662-8			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AQ0BZ					2022-12-18	WOS:000342448000004
J	Andriluka, M; Roth, S; Schiele, B				Andriluka, Mykhaylo; Roth, Stefan; Schiele, Bernt			Discriminative Appearance Models for Pictorial Structures	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Object detection; People detection; Articulated pose estimation; Pictorial structures; Discriminative models		In this paper we consider people detection and articulated pose estimation, two closely related and challenging problems in computer vision. Conceptually, both of these problems can be addressed within the pictorial structures framework (Felzenszwalb and Huttenlocher in Int. J. Comput. Vis. 61(1):55-79, 2005; Fischler and Elschlager in IEEE Trans. Comput. C-22(1):67-92, 1973), even though previous approaches have not shown such generality. A principal difficulty for such a general approach is to model the appearance of body parts. The model has to be discriminative enough to enable reliable detection in cluttered scenes and general enough to capture highly variable appearance. Therefore, as the first important component of our approach, we propose a discriminative appearance model based on densely sampled local descriptors and AdaBoost classifiers. Secondly, we interpret the normalized margin of each classifier as likelihood in a generative model and compute marginal posteriors for each part using belief propagation. Thirdly, non-Gaussian relationships between parts are represented as Gaussians in the coordinate system of the joint between the parts. Additionally, in order to cope with shortcomings of tree-based pictorial structures models, we augment our model with additional repulsive factors in order to discourage overcounting of image evidence. We demonstrate that the combination of these components within the pictorial structures framework results in a generic model that yields state-of-the-art performance for several datasets on a variety of tasks: people detection, upper body pose estimation, and full body pose estimation.	[Andriluka, Mykhaylo; Schiele, Bernt] MPI Informat, Stuhlsatzenhausweg 85, D-66123 Saarbrucken, Germany; [Roth, Stefan] Tech Univ Darmstadt, Dept Comp Sci, D-64283 Darmstadt, Germany	Max Planck Society; Technical University of Darmstadt	Andriluka, M (corresponding author), MPI Informat, Stuhlsatzenhausweg 85, D-66123 Saarbrucken, Germany.	andriluka@mpi-inf.mpg.de; sroth@cs.tu-darmstadt.de; schiele@mpi-inf.mpg.de		Roth, Stefan/0000-0001-9002-9832	DFG GRK [1362]	DFG GRK(German Research Foundation (DFG))	The authors are thankful to Krystian Mikolajczyk for his shape context implementation, Christian Wojek for AdaBoost code and helpful suggestion, and Joris Mooij for the libDAI library. Mykhaylo Andriluka gratefully acknowledges a scholarship from DFG GRK 1362 "Cooperative, Adaptive and Responsive Monitoring in Mixed Mode Environments".	Andriluka M., 2009, IEEE C COMP VIS PAT; Andriluka M., 2010, IEEE C COMP VIS PAT; Andriluka M., 2008, IEEE C COMP VIS PAT; Belongie S., 2001, ADV NEUR INF PROC SY; Bergtholdt Martin, 2010, International Journal of Computer Vision, V87, P93, DOI 10.1007/s11263-009-0209-1; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Buehler P., 2008, BRIT MACH VIS C BMVC; Crandall D., 2005, IEEE C COMP VIS PAT; Eichner M, 2009, P BRIT MACH VIS C, P31, DOI [10.5244/C.23.3, DOI 10.5244/C.23.3]; Everingham M., 2008, PASCAL VISUAL OBJECT; Felzenszwalb P. F., 2008, IEEE C COMP VIS PAT; Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; Ferrari V., 2009, IEEE C COMP VIS PAT; Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468; Ferrari V, 2009, LECT NOTES COMPUT SC, V5604, P128, DOI 10.1007/978-3-642-03061-1_7; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504; Gall J., 2009, IEEE C COMP VIS PAT; Guan P, 2009, IEEE I CONF COMP VIS, P1381, DOI 10.1109/iccv.2009.5459300; Ionescu C, 2009, IEEE I CONF COMP VIS, P1157, DOI 10.1109/ICCV.2009.5459346; Jiang H., 2008, IEEE C COMP VIS PAT; Jiang H, 2009, IEEE I CONF COMP VIS, P1357, DOI 10.1109/ICCV.2009.5459307; Jie L., 2009, ADV NEUR INF PROC SY; Johnson S., 2009, 2 IEEE INT WORKSH MA; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; Kumar P., 2009, IEEE INT C COMP VIS; Lan X., 2005, IEEE INT C COMP VIS; LEE HJ, 1985, COMPUT VISION GRAPH, V30, P148, DOI 10.1016/0734-189X(85)90094-5; Lee M. W., 2004, IEEE C COMP VIS PAT; Leibe B., 2005, IEEE C COMP VIS PAT; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mikolajczyk K., 2006, IEEE C COMP VIS PAT; Mooij J. M., 2009, LIBDAI 0 2 2 FREE OP; Ramanan D., 2007, P ADV NEUR INF PROC; Ramanan D., 2006, IEEE C COMP VIS PAT; Ren Xiaofeng, 2005, IEEE INT C COMP VIS; Ronfard R., 2002, EUR C COMP VIS ECCV; Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Sapp B., 2010, IEEE C COMP VIS PAT; Sigal L., 2006, IEEE C COMP VIS PAT; Sigal L, 2006, LECT NOTES COMPUT SC, V4069, P185; Sudderth E. B., 2005, ADV NEUR INF PROC SY; Taylor CJ, 2000, PROC CVPR IEEE, P677, DOI 10.1109/CVPR.2000.855885; Tran D., 2008, P ADV NEUR INF PROC; Triggs B., 2005, IEEE C COMP VIS PAT; Tu ZW, 2005, INT J COMPUT VISION, V63, P113, DOI 10.1007/s11263-005-6642-x; Urtasun R., 2006, IEEE C COMP VIS PAT; Viola P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P734; Wang Y., 2008, EUR C COMP VIS ECCV; Yao B., 2010, EUR C COMP VIS ECCV; Zhang J., 2006, IEEE C COMP VIS PAT; Zhang Xiao, 2009, IEEE INT C COMP VIS	56	39	44	0	26	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2012	99	3					259	280		10.1007/s11263-011-0498-z	http://dx.doi.org/10.1007/s11263-011-0498-z			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	950NI					2022-12-18	WOS:000304655600002
J	Philbin, J; Sivic, J; Zisserman, A				Philbin, James; Sivic, Josef; Zisserman, Andrew			Geometric Latent Dirichlet Allocation on a Matching Graph for Large-scale Image Datasets	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Object discovery; Large-scale retrieval; Topic/generative models		Given a large-scale collection of images our aim is to efficiently associate images which contain the same entity, for example a building or object, and to discover the significant entities. To achieve this, we introduce the Geometric Latent Dirichlet Allocation (gLDA) model for unsupervised discovery of particular objects in unordered image collections. This explicitly represents images as mixtures of particular objects or facades, and builds rich latent topic models which incorporate the identity and locations of visual words specific to the topic in a geometrically consistent way. Applying standard inference techniques to this model enables images likely to contain the same object to be probabilistically grouped and ranked. Additionally, to reduce the computational cost of applying the gLDA model to large datasets, we propose a scalable method that first computes a matching graph over all the images in a dataset. This matching graph connects images that contain the same object, and rough image groups can be mined from this graph using standard clustering techniques. The gLDA model can then be applied to generate a more nuanced representation of the data. We also discuss how "hub images" (images representative of an object or landmark) can easily be extracted from our matching graph representation. We evaluate our techniques on the publicly available Oxford buildings dataset (5K images) and show examples of automatically mined objects. The methods are evaluated quantitatively on this dataset using a ground truth labeling for a number of Oxford landmarks. To demonstrate the scalability of the matching graph method, we show qualitative results on two larger datasets of images taken of the Statue of Liberty (37K images) and Rome (1M+ images).	[Philbin, James; Zisserman, Andrew] Univ Oxford, Dept Engn Sci, Visual Geometry Grp, Oxford OX1 3PJ, England; [Sivic, Josef] CNRS ENS INRIA, UMR 8548, INRIA Willow Project, Lab Informat,Ecole Normale Super, Paris, France	University of Oxford; Centre National de la Recherche Scientifique (CNRS); UDICE-French Research Universities; PSL Research University Paris; Ecole Normale Superieure (ENS)	Philbin, J (corresponding author), Univ Oxford, Dept Engn Sci, Visual Geometry Grp, Parks Rd, Oxford OX1 3PJ, England.	james@robots.ox.ac.uk; josef@di.ens.fr; az@robots.ox.ac.uk			EPSRC; Microsoft; Royal Academy of Engineering; ERC [228180]; ANR [ANR-07-BLAN-0331-01]	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Microsoft(Microsoft); Royal Academy of Engineering(Royal Academy of Engineering - UK); ERC(European Research Council (ERC)European Commission); ANR(French National Research Agency (ANR))	We are grateful for discussions with Michael Berry and Michael Isard, and for financial support from EPSRC, Microsoft, the Royal Academy of Engineering, ERC grant VisRec No. 228180 and ANR grant ANR-07-BLAN-0331-01.	Agarwal Sameer, 2009, P ICCV; [Anonymous], P CVPR; [Anonymous], 2003, P ICCV; [Anonymous], P ICCV; Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463; CAO L, 2007, P ICCV; Chum O., 2007, P ICCV; Chum O., 2007, P CIVR; Cormen T.H., 1990, INTRO ALGORITHMS 2 V; CUMMINS M, 2007, P IEEE INT C ROB AUT; Fergus R., 2005, P ICCV; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101; Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950; Kim G., 2009, NIPS; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Philbin J., 2007, P CVPR; Philbin J., 2008, P IND C COMP VIS GRA; Quelhas P, 2005, IEEE I CONF COMP VIS, P883; RUSSELL B, 2006, P CVPR; Wang X., 2007, NIPS; WINN J, 2005, P ICCV; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]; [No title captured]	46	39	39	0	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	2011	95	2					138	153		10.1007/s11263-010-0363-5	http://dx.doi.org/10.1007/s11263-010-0363-5			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	815YN		Green Submitted			2022-12-18	WOS:000294566000003
J	Hasinoff, S; Kutulakos, K				Hasinoff, Samuel W.; Kutulakos, Kiriakos N.			Confocal Stereo	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	9th European Conference on Computer Vision (ECCV 2006)	MAY 07-13, 2006	Graz, AUSTRIA	Adv Comp Vis, Graz Univ Technol, Univ Ljubljana		Defocus; Depth from focus; Depth from defocus; 3D reconstruction; Stereo; Camera calibration; Wide-aperture lenses	DEPTH; FOCUS; RECONSTRUCTION; CALIBRATION; DEFOCUS; FILTERS; SHAPE	We present confocal stereo, a new method for computing 3D shape by controlling the focus and aperture of a lens. The method is specifically designed for reconstructing scenes with high geometric complexity or fine-scale texture. To achieve this, we introduce the confocal constancy property, which states that as the lens aperture varies, the pixel intensity of a visible in-focus scene point will vary in a scene-independent way, that can be predicted by prior radiometric lens calibration. The only requirement is that incoming radiance within the cone subtended by the largest aperture is nearly constant. First, we develop a detailed lens model that factors out the distortions in high resolution SLR cameras (12MP or more) with large-aperture lenses (e.g., f1.2). This allows us to assemble an AxF aperture-focus image (AFI) for each pixel, that collects the undistorted measurements over all A apertures and F focus settings. In the AFI representation, confocal constancy reduces to color comparisons within regions of the AFI, and leads to focus metrics that can be evaluated separately for each pixel. We propose two such metrics and present initial reconstruction results for complex scenes, as well as for a scene with known ground-truth shape.	[Hasinoff, Samuel W.; Kutulakos, Kiriakos N.] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada	University of Toronto	Hasinoff, S (corresponding author), Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada.	hasinoff@cs.toronto.edu; kyros@cs.toronto.edu						ADELSON EH, 1992, IEEE T PATTERN ANAL, V14, P99, DOI 10.1109/34.121783; Asada N, 1998, IEEE T PATTERN ANAL, V20, P155, DOI 10.1109/34.659933; Asada N, 1998, INT J COMPUT VISION, V26, P153, DOI 10.1023/A:1007996810301; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972; Bhasin SS, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P488, DOI 10.1109/ICCV.2001.937556; Bouguet J.Y., 2015, CAMERA CALIBRATION T; Darrell T., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P504, DOI 10.1109/CVPR.1988.196282; Debevec P., 1997, P ACM SIGGRAPH 1997, DOI [DOI 10.1145/258734.258884, 10.1145/258734.258884]; Farid H, 1998, J OPT SOC AM A, V15, P1777, DOI 10.1364/JOSAA.15.001777; Favaro P, 2005, IEEE T PATTERN ANAL, V27, P406, DOI 10.1109/TPAMI.2005.43; Favaro P, 2003, PROC CVPR IEEE, P579; Favaro P, 2003, PROC CVPR IEEE, P179; Favaro P, 2003, INT J COMPUT VISION, V52, P25, DOI 10.1023/A:1022366408068; FAVARO P, 2002, P EUR C COMP VIS, V2, P735; Fitzgibbon A, 2005, INT J COMPUT VISION, V63, P141, DOI 10.1007/s11263-005-6643-9; FRASER CS, 1992, PHOTOGRAMM ENG REM S, V58, P851; GREEN P, 2007, P ACM SIGGRAPH; Grossberg MD, 2004, IEEE T PATTERN ANAL, V26, P1272, DOI 10.1109/TPAMI.2004.88; HASINOFF SW, 2007, P INT C COMP VIS; HEALEY GE, 1994, IEEE T PATTERN ANAL, V16, P267, DOI 10.1109/34.276126; Hertzmann A, 2005, IEEE T PATTERN ANAL, V27, P1254, DOI 10.1109/TPAMI.2005.158; Isaksen A, 2000, COMP GRAPH, P297, DOI 10.1145/344779.344929; JIN H, 2002, P ECCV, V2, P18; Kang S.B., 2000, LNCS, V1843, P640; KROTKOV E, 1987, INT J COMPUT VISION, V1, P223, DOI 10.1007/BF00127822; KUBOTA A, 2004, P EUR S REND; Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954; Levin A., 2007, P ACM SIGGRAPH; Levoy M, 2004, ACM T GRAPHIC, V23, P825, DOI 10.1145/1015706.1015806; Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199; McGuire M, 2005, ACM T GRAPHIC, V24, P567, DOI 10.1145/1073204.1073231; MORENONOGUER F, 2007, P ACM SIGGRAPH; Nair H. N., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P309, DOI 10.1109/CVPR.1992.223258; Nayar SK, 1996, IEEE T PATTERN ANAL, V18, P1186, DOI 10.1109/34.546256; NG R, 2005, P SIGGRAPH, P735; PARIS S, 2004, P SIGGRAPH C, P712; Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207; PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940; Rajagopalan AN, 1999, IEEE T PATTERN ANAL, V21, P577, DOI 10.1109/34.777369; Schechner YY, 2000, INT J COMPUT VISION, V39, P141, DOI 10.1023/A:1008175127327; SUBBARAO M, 1994, INT J COMPUT VISION, V13, P271, DOI 10.1007/BF02028349; Vaish V, 2006, P 2006 IEEE COMP SOC, V2, P2331, DOI DOI 10.1109/CVPR.2006.244; VEERARAGHAVAN A, 2007, P ACM SIGGRAPH; Watanabe M, 1997, IEEE T PATTERN ANAL, V19, P1360, DOI 10.1109/34.643894; Watanabe M, 1998, INT J COMPUT VISION, V27, P203, DOI 10.1023/A:1007905828438; Webb RH, 1996, REP PROG PHYS, V59, P427, DOI 10.1088/0034-4885/59/3/003; WEI Y, 2005, P ACM SIGGRAPH, P816; WILLSON R, 1994, THESIS CARNEGIE MELL; WILLSON RG, 1994, P SOC PHOTO-OPT INS, V2350, P170, DOI 10.1117/12.189130; WILLSON RG, 1994, J OPT SOC AM A, V11, P2946, DOI 10.1364/JOSAA.11.002946; Xiong YL, 1997, INT J COMPUT VISION, V22, P25, DOI 10.1023/A:1007927810205; ZHANG L, 2006, P ACM SIGGRAPH, P907; ZITNICK CL, 2004, P ACM SIGGRAPH, P600, DOI DOI 10.1145/1186562.1015766; TECHNICAL INNOVATION	56	39	42	0	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2009	81	1					82	104		10.1007/s11263-008-0164-2	http://dx.doi.org/10.1007/s11263-008-0164-2			23	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	387RI					2022-12-18	WOS:000261968900006
J	Liu, HR; Latecki, LJ; Liu, WY				Liu, Hairong; Latecki, Longin Jan; Liu, Wenyu			A unified curvature definition for regular, polygonal, and digital planar curves	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						curvature; multi-scale; corner detection; curve evolution	SHAPE REPRESENTATION; CORNER DETECTION; ANGLE DETECTION; MULTISCALE; ALGORITHM	In this paper, we propose a new definition of curvature, called visual curvature. It is based on statistics of the extreme points of the height functions computed over all directions. By gradually ignoring relatively small heights, a multi-scale curvature is obtained. The theoretical properties and the experiments presented demonstrate that multi-scale visual curvature is stable, even in the presence of significant noise. To our best knowledge, the proposed definition of visual curvature is the first ever that applies to regular curves as defined in differential geometry as well as to turn angles of polygonal curves. Moreover, it yields stable curvature estimates of curves in digital images even under sever distortions. We also show a relation between multi-scale visual curvature and convexity of simple closed curves.	[Liu, Hairong; Liu, Wenyu] Huazhong Univ Sci & Technol, Wuhan 430074, Hubei, Peoples R China; [Latecki, Longin Jan] Temple Univ, Philadelphia, PA 19122 USA; [Liu, Hairong] Microsoft Res Asia, Beijing 100080, Peoples R China	Huazhong University of Science & Technology; Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University; Microsoft; Microsoft Research Asia	Liu, HR (corresponding author), Huazhong Univ Sci & Technol, Luoyu Rd,1037, Wuhan 430074, Hubei, Peoples R China.	lhrbss@gmail.com; latecki@temple.edu; liuwy@hust.edu.cn	Liu, Wenyu/AAG-1426-2019; Liu, Hairong/I-6695-2012	Liu, Wenyu/0000-0002-4582-7488; Latecki, Longin Jan/0000-0002-5102-8244	Ministry of Education of China [20070487028]; Key Scientific and Technical Innovation Project, Ministry of Education of China [705038]; NSF [IIS-0534929]; DOE [DE-FG52-06NA27508]	Ministry of Education of China(Ministry of Education, China); Key Scientific and Technical Innovation Project, Ministry of Education of China(Ministry of Education, China); NSF(National Science Foundation (NSF)); DOE(United States Department of Energy (DOE))	This work is supported by Doctoral Fund of Ministry of Education of China (NO: 20070487028), and the Cultivation Fund of the Key Scientific and Technical Innovation Project, Ministry of Education of China (NO: 705038). This work was also supported by the NSF under Grant No. IIS-0534929 and by the DOE under Grant No. DE-FG52-06NA27508.	Adamek T, 2004, IEEE T CIRC SYST VID, V14, P742, DOI 10.1109/TCSVT.2004.826776; ANDERSON IM, 1984, IEEE T PATTERN ANAL, V6, P27, DOI 10.1109/TPAMI.1984.4767472; ANSARI N, 1991, PATTERN RECOGN, V24, P441, DOI 10.1016/0031-3203(91)90057-C; ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; Aslan C, 2005, IEEE I CONF COMP VIS, P1339; Bai X, 2007, IEEE T PATTERN ANAL, V29, P449, DOI 10.1109/TPAMI.2007.59; Belyaev A., 2004, PLANE SPACE CURVES C; BENGTSSON A, 1991, IEEE T PATTERN ANAL, V13, P85, DOI 10.1109/34.67634; BEUS HL, 1987, PATTERN RECOGN, V20, P291, DOI 10.1016/0031-3203(87)90004-5; Boutin M, 2000, INT J COMPUT VISION, V40, P235, DOI 10.1023/A:1008139427340; Calabi E, 1998, INT J COMPUT VISION, V26, P107, DOI 10.1023/A:1007992709392; CARTAN E, 1935, LAMETHODE REPERE MOB; CEDERBERG RLT, 1978, INT C PATT REC KYOT, P576; CHETVERIKOV D, 1999, P 23 WORKSH AUSTR PA, P175; COEURJOLLY D, 2001, LNCS, V2059, P303; Cong G, 1998, INT C PATT RECOG, P708, DOI 10.1109/ICPR.1998.711242; Dudek G, 1997, COMPUT VIS IMAGE UND, V68, P170, DOI 10.1006/cviu.1997.0533; DUNHAM JG, 1986, IEEE T PATTERN ANAL, V8, P67, DOI 10.1109/TPAMI.1986.4767753; FREEMAN H, 1977, IEEE T COMPUT, V26, P297, DOI 10.1109/TC.1977.1674825; GUMHOLD S, 2004, DESIGNING OPTIMAL CU; HERMANN S, 2003, IMAGE VISION COMPUT, P108; HERMANN S, 2007, INT C COMP THEOR APP; HERMANN S, 2005, INT C IM VIS COMP IV, P272; KATZIR N, 1994, IEEE T PATTERN ANAL, V16, P513, DOI 10.1109/34.291446; Kovalevsky V, 2001, INT J PATTERN RECOGN, V15, P1183, DOI 10.1142/S0218001401001283; KRUSE B, 1978, INT C PATT REC KYOT, P642; Latecki LJ, 1998, PATTERN RECOGN, V31, P607, DOI 10.1016/S0031-3203(97)00071-X; Lewiner T, 2004, XVII BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P250, DOI 10.1109/SIBGRA.2004.1352968; LEWINER T, 2004, CURVATURE ESTIMATION; Lowe D. G., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P558, DOI 10.1109/CCV.1988.590036; LU F, 1991, INT CONF ACOUST SPEE, P2469, DOI 10.1109/ICASSP.1991.150901; Marji M., 2003, THESIS; MEDIONI G, 1986, IEEE INT C ROB AUT, V3, P764; MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591; Mokhtarian F, 1998, IEEE T PATTERN ANAL, V20, P1376, DOI 10.1109/34.735812; PAVLIDIS T, 1980, IEEE T PATTERN ANAL, V2, P301, DOI 10.1109/TPAMI.1980.4767029; Pinheiro AMG, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P538, DOI 10.1109/ICIP.2000.899475; RATTARANGSI A, 1992, IEEE T PATTERN ANAL, V14, P430, DOI 10.1109/34.126805; ROSENFELD A, 1975, IEEE T COMPUT, V24, P940, DOI 10.1109/T-C.1975.224342; ROSENFELD A, 1973, IEEE T COMPUT, VC 22, P875, DOI 10.1109/TC.1973.5009188; SANKAR PV, 1978, COMPUT VISION GRAPH, V7, P403, DOI 10.1016/S0146-664X(78)80006-9; Utcke S, 2003, LECT NOTES COMPUT SC, V2695, P657; WANG Y, 1999, IEEE T IMAGE PROCESS, V8; WORRING M, 1993, CVGIP-IMAG UNDERSTAN, V58, P366, DOI 10.1006/ciun.1993.1048; YUILLE AL, 1989, COMPUT VISION GRAPH, V45, P68, DOI 10.1016/0734-189X(89)90071-6	45	39	49	0	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	OCT	2008	80	1					104	124		10.1007/s11263-008-0131-y	http://dx.doi.org/10.1007/s11263-008-0131-y			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	344CB					2022-12-18	WOS:000258901900008
J	Johnson, A; Willson, R; Cheng, Y; Goguen, J; Leger, C; Sanmartin, M; Matthies, L				Johnson, Andrew; Willson, Reg; Cheng, Yang; Goguen, Jay; Leger, Chris; Sanmartin, Miguel; Matthies, Larry			Design through operation of an image-based velocity estimation system for mars landing	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						velocity estimation; feature tracking; computer vision; robotics; Mars lander; Mars Exploration Rover; DIMES		During the Mars Exploration Rover (MER) landings, the Descent Image Motion Estimation System (DIMES) was used for horizontal velocity estimation. The DIMES algorithm combined measurements from a descent camera, a radar altimeter, and an inertial measurement unit. To deal with large changes in scale and orientation between descent images, the algorithm used altitude and attitude measurements to rectify images to a level ground plane. Feature selection and tracking were employed in the rectified images to compute the horizontal motion between images. Differences of consecutive motion estimates were then compared to inertial measurements to verify correct feature tracking. DIMES combined sensor data from multiple sources in a novel way to create a low-cost, robust, and computationally efficient velocity estimation solution, and DIMES was the first robotics vision system used to control a spacecraft during planetary landing. This paper presents the design and implementation of the DIMES algorithm, the assessment of the algorithm performance using a high fidelity Monte Carlo simulation, validation of performance using field test data and the detailed results from the two landings on Mars. DIMES was used successfully during both MER landings. In the case of Spirit, had DIMES not been used onboard, the total velocity would have been at the limits of the airbag capability. Fortunately, DIMES computed the actual steady state horizontal velocity and it was used by the thruster firing logic to reduce the total velocity prior to landing. For Opportunity. DIMES computed the correct velocity, and the velocity was small enough that the lander performed no action to remove it.	CALTECH, Jet Propuls Lab, Pasadena, CA 91125 USA	California Institute of Technology; National Aeronautics & Space Administration (NASA); NASA Jet Propulsion Laboratory (JPL)	Johnson, A (corresponding author), CALTECH, Jet Propuls Lab, Pasadena, CA 91125 USA.		Goguen, Jay/E-5389-2018					Amidi O, 1999, ROBOT AUTON SYST, V28, P185, DOI 10.1016/S0921-8890(99)00016-0; AZARBAYEJANI A, 1995, IEEE T PATTERN ANAL, V17, P562, DOI 10.1109/34.387503; BANK T, 2001, P 24 ANN AAS GUID CO; Bosse M, 1997, IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, P1028, DOI 10.1109/ITSC.1997.660615; BURATTI BJ, 1984, ICARUS, V59, P392, DOI 10.1016/0019-1035(84)90109-X; Chen K, 2001, NAT MED, V7, P331, DOI 10.1038/85480; CHENG Y, 2005, P IEEE C COMP VIS PA; Corke P, 2004, J ROBOTIC SYST, V21, P43, DOI 10.1002/rob.10127; GENNERY D, 2001, CALIBRATION ORIENTAT; HAPKE B, 1986, ICARUS, V67, P264, DOI 10.1016/0019-1035(86)90108-9; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Hartley R., 2003, MULTIPLE VIEW GEOMET; JOHNSON AE, 1999, P 5 INT S ART INT RO, P627; Johnson Andrew, 2005, P IEEE INT C ROB AUT; KUBOTA T, 1999, P 5 INT S ART INT RO; MAKI J, 1999, J GEOPHYS RES, V104; Maki JN, 2003, J GEOPHYS RES-PLANET, V108, DOI 10.1029/2003JE002077; MALIN MC, 1992, J GEOPHYS RES-PLANET, V97, P7699, DOI 10.1029/92JE00340; Moravec H. P., 1977, P 5 INT JOINT C ART; Oliensis J, 2002, IEEE T PATTERN ANAL, V24, P1618, DOI 10.1109/TPAMI.2002.1114853; RAISZADEH B, 2004, P AIAA SPAC FLIGHT M; Roumeliotis SI, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P4326, DOI 10.1109/ROBOT.2002.1014441; SANMARTIN A, 2005, P 28 AAS G C C; Saripalli S, 2003, IEEE T ROBOTIC AUTOM, V19, P371, DOI 10.1109/TRA.2003.810239; Shakernia O, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P2793, DOI 10.1109/ROBOT.2002.1013655; SHUSTER MD, 1981, J GUID CONTROL, V4, P70, DOI 10.2514/3.19717; SMITH GH, 2001, SPIE, V4441, P118; WILLIAMS B, 2003, J HOPKINS APL, V23; Willson R., 2005, P 8 INT S ART INT RO; WLLSON R, 2005, P 8 INT S ART INT RO	30	39	48	0	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2007	74	3					319	341		10.1007/s11263-006-0022-z	http://dx.doi.org/10.1007/s11263-006-0022-z			23	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	192YG					2022-12-18	WOS:000248239400007
J	Seitz, SM; Kim, J				Seitz, SM; Kim, J			The space of all stereo images	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						stereo; panorama; mosaic; cyclograph; pushbroom; multi-view geometry		A theory of stereo image formation is presented that enables a complete classification of all possible stereo views, including non-perspective varieties. Towards this end, the notion of epipolar geometry is generalized to apply to multiperspective images. It is shown that any stereo pair must consist of rays lying on one of three varieties of quadric surfaces. A unified representation is developed to model all classes of stereo views, based on the concept of a quadric view. The benefits include a unified treatment of projection and triangulation operations for all stereo views. The framework is applied to derive new types of stereo image representations with unusual and useful properties. Experimental examples of these images are constructed and used to obtain 3D binocular object reconstructions.	Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA	University of Washington; University of Washington Seattle	Seitz, SM (corresponding author), Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA.	seitz@cs.washington.edu; jwkim@cs.washington.edu						Baker S, 1999, INT J COMPUT VISION, V35, P175, DOI 10.1023/A:1008128724364; Bergen J. R., 1991, COMPUTATIONAL MODELS, V1, P8; BOLLES RC, 1987, INT J COMPUT VISION, V1, P7, DOI 10.1007/BF00128525; DAVIDHAZY A, 1987, IND PHOTOGRAPHY; Gupta R, 1997, IEEE T PATTERN ANAL, V19, P963, DOI 10.1109/34.615446; HILBERT D, 1991, GEOMETRY IMAGINATION; ISHIGURO H, 1992, IEEE T PATTERN ANAL, V14, P257, DOI 10.1109/34.121792; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; LOOP C, 1999, P COMP VIS PATT REC; McMillan L., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P39, DOI 10.1145/218380.218398; Nayar SK, 2000, PROC CVPR IEEE, P388; PAJDLA T, 2001, P COMP VIS WINT WORK, P223; Peleg S, 1997, PROC CVPR IEEE, P338, DOI 10.1109/CVPR.1997.609346; Peleg S, 2000, PROC CVPR IEEE, P208, DOI 10.1109/CVPR.2000.855821; Peleg S., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P395, DOI 10.1109/CVPR.1999.786969; Rademacher P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P199, DOI 10.1145/280814.280871; Roy S, 1997, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.1997.609355; SHUM HY, 1999, P 7 INT C COMP VIS, P22; SHUM HY, 1999, P INT C COMP VIS, P14; SVOBODA T, 1998, P 5 EUR C COMP VIS, P218; Wood D. N., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P243, DOI 10.1145/258734.258859; Zitnick CL, 2000, IEEE T PATTERN ANAL, V22, P675, DOI 10.1109/34.865184	22	39	44	1	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2002	48	1					21	38		10.1023/A:1014851111084	http://dx.doi.org/10.1023/A:1014851111084			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	534UM					2022-12-18	WOS:000174606100004
J	Mulligan, J; Isler, V; Daniilidis, K				Mulligan, J; Isler, V; Daniilidis, K			Trinocular stereo: A real-time algorithm and its evaluation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						trinocular stereo; telepresence; ground-truth evaluation; error metrics		In telepresence applications each user is immersed in a rendered 3D-world composed from representations transmitted from remote sites. The challenge is to compute dense range data at high frame rates, since participants cannot easily communicate if the processing cycle or network latencies are long. Moreover, errors in new stereoscopic views of the remote 3D-world should be hardly perceptible. To achieve the required speed and accuracy, we use trinocular stereo, a matching algorithm based on the sum of modified normalized cross-correlations, and subpixel disparity interpolation. To increase speed we use Intel IPL functions in the pre-processing steps of background subtraction and image rectification as well as a four-processor parallelization. To evaluate our system we have developed a test-bed which provides a set of registered dense "ground-truth" laser data and image data from multiple views.	Univ Colorado, Dept Comp Sci, Boulder, CO 80309 USA; Univ Penn, GRASP Lab, Philadelphia, PA 19104 USA	University of Colorado System; University of Colorado Boulder; University of Pennsylvania	Mulligan, J (corresponding author), Univ Colorado, Dept Comp Sci, Boulder, CO 80309 USA.	janem@cs.colorado.edu; isleri@grasp.cis.upenn.edu; kostas@grasp.cis.upenn.edu		Daniilidis, Kostas/0000-0003-0498-0758				Ayache N, 1991, ARTIFICIAL VISION MO; Banks J, 2001, INT J ROBOT RES, V20, P512, DOI 10.1177/02783640122067525; BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984; Belhumeur PN, 1996, INT J COMPUT VISION, V19, P237, DOI 10.1007/BF00055146; Cheung GKM, 2000, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2000.854944; DHOND UR, 1989, IEEE T SYST MAN CYB, V19, P1489, DOI 10.1109/21.44067; FAUGERAS O, 1993, 3 DIMENSIONAL COMP V; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; Kutulakos K. N., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P307, DOI 10.1109/ICCV.1999.791235; Lanier J, 2001, SCI AM, V284, P66, DOI 10.1038/scientificamerican0401-66; LECLERC Y, 2000, P 6 EUR C COMP VIS D, P282; MARTINS FCM, 1999, IEEE ICCV99 FRAM RAT; MATTHIES L, 1992, INT J COMPUT VISION, V8, P71, DOI 10.1007/BF00126401; Moezzi S, 1997, IEEE MULTIMEDIA, V4, P18, DOI 10.1109/93.580392; Mulligan J, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P105, DOI 10.1109/ISAR.2000.880933; MULLIGAN J, 2000, P 6 EUR C COMP VIS D, P220; MULLIGAN J, 2001, P INT C COMP VIS VAN; Narayanan PJ, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P3, DOI 10.1109/ICCV.1998.710694; OHTA Y, 1986, P 8 INT C PATT REC I, V1, P519; OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955; RASKAR R, 1998, ACM SIGGRAPH, P179; Scharstein Daniel, 2001, P IEEE WORKSH STER M; Seitz SM, 1997, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.1997.609462; SEZLISKI R, 1999, WORKSH VIS ALG; Snow D., 2000, IEEE C COMP VIS PATT; SZELISKI R, 1999, P INT C COMP VIS KER; [No title captured]	27	39	40	0	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR-JUN	2002	47	1-3					51	61		10.1023/A:1014525320885	http://dx.doi.org/10.1023/A:1014525320885			11	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	530JN					2022-12-18	WOS:000174354700004
J	Shimshoni, I; Moses, Y; Lindenbaum, M				Shimshoni, I; Moses, Y; Lindenbaum, M			Shape reconstruction of 3D bilaterally symmetric surfaces	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						shape recovery; shape-from-shading; stereo; bilaterally symmetric objects	PHOTOMETRIC STEREO; RECOVERY	The paper presents a new approach for shape recovery based on integrating geometric and photometric information. We consider 3D bilaterally symmetric objects, that is, objects which are symmetric with respect to a plane (e.g., faces), and their reconstruction from a single image. Both the viewpoint and the illumination are not necessarily frontal. Furthermore, no correspondence between symmetric points is required. The basic idea is that an image taken from a general, non frontal viewpoint, under non-frontal illumination can be regarded as a pair of images. Each image of the pair is one half of the object, taken from different viewing positions and with different lighting directions. Thus, one-image-variants of geometric stereo and of photometric stereo can be used. Unlike the separate invocation of these approaches, which require point correspondence between the two images, we show that integrating the photometric and geometric information suffice to yield a dense correspondence between pairs of symmetric points, and as a result, a dense shape recovery of the object. Furthermore, the unknown lighting and viewing parameters, are also recovered in this process. Unknown distant point light source, Lambertian surfaces, unknown constant albedo, and weak perspective projection are assumed. The method has been implemented and tested experimentally on simulated and real data.	Technion Israel Inst Technol, Dept Ind Engn & Management, IL-32000 Haifa, Israel; Interdisciplinary Ctr, Dept Comp Sci, IL-46150 Herzliya, Israel; Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel	Technion Israel Institute of Technology; Reichman University; Technion Israel Institute of Technology	Shimshoni, I (corresponding author), Technion Israel Inst Technol, Dept Ind Engn & Management, IL-32000 Haifa, Israel.							BASRI R, 1999, INT J COMPUT VISION, V33, P1; BLAKE A, 1985, IMAGE VISION COMPUT, V3, P183, DOI 10.1016/0262-8856(85)90006-X; CHAM T, 1995, IMAGE VISION COMPUT, V5, P439; CRYER JE, 1995, PATTERN RECOGN, V28, P1033, DOI 10.1016/0031-3203(94)00183-M; Faugeras Olivier, 1993, 3 DIMENSIONAL COMPUT, P2; FREIBERG SA, 1986, COMPUTER VISION GRAP, V34, P138; FUA P, 1993, P DARPA IM UND WORKS, P1097; GOFMAN Y, 1996, ICPR; GORDON GG, 1989, P SPIE INTELLENT ROB, V1192; Gross AD, 1996, IEEE T PATTERN ANAL, V18, P161, DOI 10.1109/34.481541; HAYAKAWA H, 1994, J OPT SOC AM A, V11, P3079, DOI 10.1364/JOSAA.11.003079; Horn B.K.P., 1989, SHAPE SHADING; HORN BKP, 1986, COMPUT VISION GRAPH, V33, P174, DOI 10.1016/0734-189X(86)90114-3; Horn BKP, 1986, COMPUTER VISION; HOUGEN DR, 1993, P INT C COMP VIS, P148; Moses Y, 1998, INT J COMPUT VISION, V29, P233, DOI 10.1023/A:1008088813977; MUKHERJEE DP, 1993, 198893 OUEL U OXF DE; ONN R, 1990, INT J COMPUT VISION, V5, P105, DOI 10.1007/BF00056773; PONCE J, 1990, COMPUT VISION GRAPH, V52, P328, DOI 10.1016/0734-189X(90)90079-B; Rothwell C.A., 1995, OBJECT RECOGNITION I; Shimshoni I., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P76, DOI 10.1109/ICIAP.1999.797574; SHIMSHONI I, 1997, CIS97101997 TECHN; Takacs B, 1997, PATTERN RECOGN, V30, P1623, DOI 10.1016/S0031-3203(96)00159-8; Woodham R.J., 1979, IMAGE UNDERSTANDING, V155, P136; ZABRODSKY H, 1993, THESIS HEBREW U JERU; ZHANG Z, 1998, P INT C PATT REC, pSAP1; ZISSERMAN A, 1995, ARTIF INTELL, V78, P239, DOI 10.1016/0004-3702(95)00023-2	27	39	40	0	4	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2000	39	2					97	110		10.1023/A:1008118909580	http://dx.doi.org/10.1023/A:1008118909580			14	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	359FD					2022-12-18	WOS:000089600100003
J	Kahl, F; Heyden, A				Kahl, F; Heyden, A			Affine structure and motion from points, lines and conics	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						reconstruction; affine cameras; matching constraints; closure constraints; factorization methods; multiple view tensors	GEOMETRY; 3D	In this paper several new methods for estimating scene structure and camera motion from an image sequence taken by affine cameras are presented. All methods can incorporate both point, line and conic features in a unified manner. The correspondence between features in different images is assumed to be known. Three new tensor representations are introduced describing the viewing geometry for two and three cameras. The centred affine epipoles can be used to constrain the location of corresponding points and conics in two images. The third order, or alternatively, the reduced third order centred affine tensors can be used to constrain the locations of corresponding points, lines and conics in three images. The reduced third order tensors contain only 12 components compared to the 16 components obtained when reducing the trifocal tensor to affine cameras. A new factorization method is presented. The novelty lies in the ability to handle not only point features, but also line and conic features concurrently. Another complementary method based on the so-called closure constraints is also presented. The advantage of this method is the ability to handle missing data in a simple and uniform manner. Finally, experiments performed on both simulated and real data are given, including a comparison with other methods.	Lund Univ, Ctr Math Sci, S-22100 Lund, Sweden	Lund University	Kahl, F (corresponding author), Lund Univ, Ctr Math Sci, Box 118, S-22100 Lund, Sweden.	fredrik@maths.lth.se; heyden@maths.lth.se						ATKINSON KB, 1996, CLOSE RANGE PHOTOGRA; BRETZNER L, 1998, P 5 EUR C COMP VIS F; FAUGERAS OD, 1992, P 2 EUR C COMP VIS S, P563; HEYDEN A, 1995, THESIS LUND I TECHNO; Jacobs D, 1997, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.1997.609321; KAHL F, 1998, P 5 EUR C COMP VIS F; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; MA SD, 1993, INT J COMPUT VISION, V10, P7; MAYBANK S, 1993, THEORY RECONSTRUCTIO; MCLAUCHLAN PF, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P314, DOI 10.1109/ICCV.1995.466923; Mundy J., 1992, GEOMETRIC INVARIANCE; QIAN L, 1997, IEEE T PATTERN ANAL, V19; Quan L, 1998, PROC CVPR IEEE, P172, DOI 10.1109/CVPR.1998.698605; Semple J.G, 1952, ALGEBRAIC PROJECTIVE; SHAPIRO LS, 1995, INT J COMPUT VISION, V16, P147, DOI 10.1007/BF01539553; SHAPIRO LS, 1995, AFFINE ANAL IMAGE SE; Shashua A, 1996, IEEE T PATTERN ANAL, V18, P873, DOI 10.1109/34.537342; SPARR G, 1996, P INT C PATT REC VIE; STURM P, 1996, P EUR C COMP VIS, P709; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; Torr P.H.S., 1995, THESIS U OXFORD; Triggs B, 1997, IMAGE VISION COMPUT, V15, P617, DOI 10.1016/S0262-8856(97)00016-4; TRIGGS B, 1996, P C COMP VIS PATT RE; WENG JY, 1992, IEEE T PATTERN ANAL, V14, P318, DOI 10.1109/34.120327	24	39	39	0	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	1999	33	3					163	180		10.1023/A:1008192713051	http://dx.doi.org/10.1023/A:1008192713051			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	248WM					2022-12-18	WOS:000083299800001
J	Li, BY; Gou, YB; Gu, SH; Liu, JZ; Zhou, JT; Peng, X				Li, Boyun; Gou, Yuanbiao; Gu, Shuhang; Liu, Jerry Zitao; Zhou, Joey Tianyi; Peng, Xi			You Only Look Yourself: Unsupervised and Untrained Single Image Dehazing Neural Network	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Single image dehazing; Unsupervised learning; Untrained neural network		In this paper, we study two challenging and less-touched problems in single image dehazing, namely, how to make deep learning achieve image dehazing without training on the ground-truth clean image (unsupervised) and an image collection (untrained). An unsupervised model will avoid the intensive labor of collecting hazy-clean image pairs, and an untrained model is a "real" single image dehazing approach which could remove haze based on the observed hazy image only and no extra images are used. Motivated by the layer disentanglement, we propose a novel method, called you only look yourself (YOLY) which could be one of the first unsupervised and untrained neural networks for image dehazing. In brief, YOLY employs three joint subnetworks to separate the observed hazy image into several latent layers, i.e., scene radiance layer, transmission map layer, and atmospheric light layer. After that, three layers are further composed to the hazy image in a self-supervised manner. Thanks to the unsupervised and untrained characteristics of YOLY, our method bypasses the conventional training paradigm of deep models on hazy-clean pairs or a large scale dataset, thus avoids the labor-intensive data collection and the domain shift issue. Besides, our method also provides an effective learning-based haze transfer solution thanks to its layer disentanglement mechanism. Extensive experiments show the promising performance of our method in image dehazing compared with 14 methods on six databases. The code could be accessed at www.pengxi.me.	[Li, Boyun; Gou, Yuanbiao; Peng, Xi] Sichuan Univ, Coll Comp Sci, Chengdu, Peoples R China; [Gu, Shuhang] Univ Sydney, Sch Elect & Informat Engn, Sydney, NSW, Australia; [Liu, Jerry Zitao] TAL AI Lab, Beijing, Peoples R China; [Zhou, Joey Tianyi] ASTAR, Inst High Performance Comp, Singapore, Singapore	Sichuan University; University of Sydney; Agency for Science Technology & Research (A*STAR); A*STAR - Institute of High Performance Computing (IHPC)	Peng, X (corresponding author), Sichuan Univ, Coll Comp Sci, Chengdu, Peoples R China.	liboyun.gm@gmail.com; gouyuanbiao@gmail.com; shuhanggu@gmail.com; liuzitao@100tal.com; joey.tianyi.zhou@gmail.com; pengx.gm@gmail.com	Li, Boyun/ADL-0750-2022; Peng, Xi/B-9002-2012	Peng, Xi/0000-0002-5727-2790	NFSC [U19A2081, U19A2078, 61625204,, 61836006]; Fundamental Research Funds for the Central Universities [YJ201949]; Fund of Sichuan University Tomorrow Advancing Life; A*STAR AME Programmatic [A18A1b0045]	NFSC(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); Fund of Sichuan University Tomorrow Advancing Life; A*STAR AME Programmatic(Agency for Science Technology & Research (A*STAR))	The authors would thank to the anonymous reviewers for the constructive comments and valuable suggestions that greatly improve this work. This work was supported in part by NFSC under Grants U19A2081, U19A2078, 61625204, and 61836006; in part by the Fundamental Research Funds for the Central Universities under Grant YJ201949; in part by the Fund of Sichuan University Tomorrow Advancing Life; and in part by A*STAR AME Programmatic under Grant A18A1b0045	Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119; Ancuti C, 2018, IEEE COMPUT SOC CONF, P1004, DOI 10.1109/CVPRW.2018.00134; Ancuti C, 2018, LECT NOTES COMPUT SC, V11182, P620, DOI 10.1007/978-3-030-01449-0_52; Berman D., 2017, COMP PHOT ICCP 2017, P1; Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185; Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681; Chen C, 2016, LECT NOTES COMPUT SC, V9906, P576, DOI 10.1007/978-3-319-46475-6_36; Gandelsman Y, 2019, PROC CVPR IEEE, P11018, DOI 10.1109/CVPR.2019.01128; Gou Y., 2020, ADV NEURAL INF PROCE, V33, P17129; Hahner M, 2019, IEEE INT C INTELL TR, P3675, DOI 10.1109/ITSC.2019.8917518; He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]; Heckel R., 2019, PROC INT C LEARN REP, P1; Jimmy Ba, 2015, ADAM METHOD STOCHAST; Kingma D.P, P 3 INT C LEARNING R; Krull A, 2019, PROC CVPR IEEE, P2124, DOI 10.1109/CVPR.2019.00223; Lehtinen J, 2018, PR MACH LEARN RES, V80; Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951; Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511; Li R, 2018, IEEE C COMP VIS PATT; Li Y, 2015, IEEE I CONF COMP VIS, P226, DOI 10.1109/ICCV.2015.34; Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741; Mei K., 2018, P AS C COMP VIS, P203; Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82; Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306; Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835; Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10; Sakaridis C, 2018, LECT NOTES COMPUT SC, V11217, P707, DOI 10.1007/978-3-030-01261-8_42; Sakaridis C, 2018, INT J COMPUT VISION, V126, P973, DOI 10.1007/s11263-018-1072-8; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643; Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251; Ulyanov D, 2018, PROC CVPR IEEE, P9446, DOI 10.1109/CVPR.2018.00984; Zhang H, 2017, ARXIV COMPUTER VISIO; Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747; Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337; Zhu HY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1234; Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191	37	38	38	10	38	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2021	129	5					1754	1767		10.1007/s11263-021-01431-5	http://dx.doi.org/10.1007/s11263-021-01431-5		MAR 2021	14	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	RY0YC		Green Submitted			2022-12-18	WOS:000625841400002
J	Zhang, YH; Guo, XJ; Ma, JY; Liu, W; Zhang, JW				Zhang, Yonghua; Guo, Xiaojie; Ma, Jiayi; Liu, Wei; Zhang, Jiawan			Beyond Brightening Low-light Images	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Low-light image enhancement; Image decomposition; Image restoration; Light manipulation	HISTOGRAM EQUALIZATION; RETINEX	Images captured under low-light conditions often suffer from (partially) poor visibility. Besides unsatisfactory lightings, multiple types of degradation, such as noise and color distortion due to the limited quality of cameras, hide in the dark. In other words, solely turning up the brightness of dark regions will inevitably amplify pollution. Thus, low-light image enhancement should not only brighten dark regions, but also remove hidden artifacts. To achieve the goal, this work builds a simple yet effective network, which, inspired by Retinex theory, decomposes images into two components. Following a divide-and-conquer principle, one component (illumination) is responsible for light adjustment, while the other (reflectance) for degradation removal. In such a way, the original space is decoupled into two smaller subspaces, expecting for better regularization/learning. It is worth noticing that our network is trained with paired images shot under different exposure conditions, instead of using any ground-truth reflectance and illumination information. Extensive experiments are conducted to demonstrate the efficacy of our design and its superiority over the state-of-the-art alternatives, especially in terms of the robustness against severe visual defects and the flexibility in adjusting light levels. Our code is made publicly available at .	[Zhang, Yonghua; Guo, Xiaojie; Zhang, Jiawan] Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China; [Ma, Jiayi] Wuhan Univ, Elect Informat Sch, Wuhan 430072, Peoples R China; [Liu, Wei] Tencent AI Lab, Shenzhen 519000, Peoples R China	Tianjin University; Wuhan University; Tencent	Guo, XJ (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China.	zhangyonghua@tju.edu.cn; xj.max.guo@gmail.com; jyma2010@gmail.com; wl2223@columbia.edu; jwzhang@tju.edu.cn	Guo, Xiaojie/AAC-3114-2022	Liu, Wei/0000-0002-3865-8145	National Natural Science Foundation of China [61772512, 62072327]; National Key Research and Development Program of China [2019YFC1521200]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Key Research and Development Program of China	This work was supported in part by the National Natural Science Foundation of China under Grant Nos. 61772512 and 62072327, and in part by the National Key Research and Development Program of China under Grant No. 2019YFC1521200.	Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734; BRADLEY RA, 1952, BIOMETRIKA, V39, P324, DOI 10.2307/2334029; Bychkovsky V, 2011, PROC CVPR IEEE, P97; Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681; Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218; Chen C, 2018, PROC CVPR IEEE, P3291, DOI 10.1109/CVPR.2018.00347; Chen YS, 2018, PROC CVPR IEEE, P6306, DOI 10.1109/CVPR.2018.00660; Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743; Cheng HD, 2004, DIGIT SIGNAL PROCESS, V14, P158, DOI 10.1016/j.dsp.2003.07.002; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; Dong C, 2015, IEEE I CONF COMP VIS, P576, DOI 10.1109/ICCV.2015.73; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; Dong XC, 2011, INT C PAR DISTRIB SY, P9, DOI 10.1109/ICPADS.2011.115; Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304; Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031; Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366; Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450; Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047; Ignatov A, 2018, IEEE COMPUT SOC CONF, P804, DOI 10.1109/CVPRW.2018.00112; Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272; Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356; LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108; Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059; Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511; Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539; Liu J., 2018, P BRIT MECH VIS C, P1; Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008; Ma, 2017, ARXIV E PRINTS; Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920; Mateescu VA, 2016, IEEE MULTIMEDIA, V23, P82, DOI 10.1109/MMUL.2015.59; Mechrez R, 2019, MACH VISION APPL, V30, P189, DOI 10.1007/s00138-018-01000-w; Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726; Pisano ED, 1998, J DIGIT IMAGING, V11, P193, DOI 10.1007/BF03178082; Rahman S, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0138-1; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070; STEVENS SS, 1957, PSYCHOL REV, V64, P153, DOI 10.1037/h0046162; TURGAY C, 2011, IEEE T IMAGE PROCESS, V20, P3431; Wang RX, 2019, PROC CVPR IEEE, P6842, DOI 10.1109/CVPR.2019.00701; Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309; Wang WJ, 2018, IEEE INT CONF AUTOMA, P751, DOI 10.1109/FG.2018.00118; Wang ZG, 2009, DISPLAYS, V30, P133, DOI 10.1016/j.displa.2009.03.006; Xie J., 2012, ADV NEURAL INFORM PR, P341, DOI DOI 10.1109/AGRO-GEOINFORMATICS.2012.6311605; Xiong RQ, 2017, IEEE T IMAGE PROCESS, V26, DOI [10.1109/TIP.2016.2621478, 10.1109/TIP.2017.2689999]; Ying ZQ, 2017, IEEE INT CONF COMP V, P3015, DOI 10.1109/ICCVW.2017.356; Ying Zhenqiang, 2017, ARXIV171100591; Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891; Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187; Zhang X, 2018, INT C LEARN REPR; Zhang YH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1632, DOI 10.1145/3343031.3350926	51	38	43	14	36	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	2021	129	4					1013	1037		10.1007/s11263-020-01407-x	http://dx.doi.org/10.1007/s11263-020-01407-x		JAN 2021	25	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	RB3QK					2022-12-18	WOS:000605541100003
J	Gehrig, D; Rebecq, H; Gallego, G; Scaramuzza, D				Gehrig, Daniel; Rebecq, Henri; Gallego, Guillermo; Scaramuzza, Davide			EKLT: Asynchronous Photometric Feature Tracking Using Events and Frames	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	15th European Conference on Computer Vision (ECCV)	SEP 08-14, 2018	Munich, GERMANY			Asynchronous; Low latency; High dynamic range; Dynamic vision sensor; Event camera; Feature tracking; Maximum likelihood; Generative model; Low-level vision	VISUAL ODOMETRY; VISION; SLAM	We present EKLT, a feature tracking method that leverages the complementarity of event cameras and standard cameras to track visual features with high temporal resolution. Event cameras are novel sensors that output pixel-level brightness changes, called "events". They offer significant advantages over standard cameras, namely a very high dynamic range, no motion blur, and a latency in the order of microseconds. However, because the same scene pattern can produce different events depending on the motion direction, establishing event correspondences across time is challenging. By contrast, standard cameras provide intensity measurements (frames) that do not depend on motion direction. Our method extracts features on frames and subsequently tracks them asynchronously using events, thereby exploiting the best of both types of data: the frames provide a photometric representation that does not depend on motion direction and the events provide updates with high temporal resolution. In contrast to previous works, which are based on heuristics, this is the first principled method that uses intensity measurements directly, based on a generative event model within a maximum-likelihood framework. As a result, our method produces feature tracks that are more accurate than the state of the art, across a wide variety of scenes.	[Gehrig, Daniel; Rebecq, Henri; Gallego, Guillermo; Scaramuzza, Davide] Univ Zurich, Dept Informat, Robot & Percept Grp, Zurich, Switzerland; [Gehrig, Daniel; Rebecq, Henri; Gallego, Guillermo; Scaramuzza, Davide] Univ Zurich, Dept Neuroinformat, Zurich, Switzerland; [Gehrig, Daniel; Rebecq, Henri; Gallego, Guillermo; Scaramuzza, Davide] Swiss Fed Inst Technol, Zurich, Switzerland	University of Zurich; University of Zurich; Swiss Federal Institutes of Technology Domain; ETH Zurich	Gehrig, D (corresponding author), Univ Zurich, Dept Informat, Robot & Percept Grp, Zurich, Switzerland.; Gehrig, D (corresponding author), Univ Zurich, Dept Neuroinformat, Zurich, Switzerland.; Gehrig, D (corresponding author), Swiss Fed Inst Technol, Zurich, Switzerland.	daniel.gehrig18@gmail.com	Gallego, Guillermo/I-7131-2012	Gallego, Guillermo/0000-0002-2672-9241; Rebecq, Henri/0000-0002-6577-9735				Agarwal S., 2010, CERES SOLVER; Alzugaray I, 2018, IEEE ROBOT AUTOM LET, V3, P3177, DOI 10.1109/LRA.2018.2849882; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Bardow P., IEEE C COMP VIS PATT, P884; Barranco Francisco, 2015, INT C COMP VIS ICCV, V2; Benosman R, 2012, NEURAL NETWORKS, V27, P32, DOI 10.1016/j.neunet.2011.11.001; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Brandli C, 2014, IEEE J SOLID-ST CIRC, V49, P2333, DOI 10.1109/JSSC.2014.2342715; Bryner S, 2019, IEEE INT CONF ROBOT, P325, DOI 10.1109/ICRA.2019.8794255; Chaudhry R., IEEE C COMP VIS PATT, P1932; Clady X, 2017, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00594; Clady X, 2015, NEURAL NETWORKS, V66, P91, DOI 10.1016/j.neunet.2015.02.013; Delmerico J., 2019, IEEE INT C ROB AUT I; Evangelidis GD, 2008, IEEE T PATTERN ANAL, V30, P1858, DOI 10.1109/TPAMI.2008.113; Forster C, 2017, IEEE T ROBOT, V33, P249, DOI 10.1109/TRO.2016.2623335; Gallego G, 2022, IEEE T PATTERN ANAL, V44, P154, DOI 10.1109/TPAMI.2020.3008413; Gallego G, 2018, PROC CVPR IEEE, P3867, DOI 10.1109/CVPR.2018.00407; Gallego G, 2018, IEEE T PATTERN ANAL, V40, P2402, DOI 10.1109/TPAMI.2017.2769655; Gallego G, 2017, IEEE ROBOT AUTOM LET, V2, P632, DOI 10.1109/LRA.2016.2647639; Gallego Guillermo, 2015, ARXIV151001972; Gehrig D, 2018, LECT NOTES COMPUT SC, V11216, P766, DOI 10.1007/978-3-030-01258-8_46; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Kim Hanme, 2014, BRIT MACH VIS C BMVC, DOI [10.5244/C.28.26, DOI 10.5244/C.28.26]; Klein G, 2009, INT SYM MIX AUGMENT, P83, DOI 10.1109/ISMAR.2009.5336495; Kogler J., ADV THEORY APPL STER, P165; Kueng B, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P16, DOI 10.1109/IROS.2016.7758089; Lagorce X, 2015, IEEE T NEUR NET LEAR, V26, P1710, DOI 10.1109/TNNLS.2014.2352401; Lichtsteiner Patrick, 2008, IEEE Journal of Solid-State Circuits, V43, P566, DOI 10.1109/JSSC.2007.914337; Lucas BD., 1981, ITERATIVE IMAGE REGI, P674, DOI DOI 10.5555/1623264.1623280; Maqueda AI, 2018, PROC CVPR IEEE, P5419, DOI 10.1109/CVPR.2018.00568; Mueggler E, 2017, INT J ROBOT RES, V36, P142, DOI 10.1177/0278364917691115; Mueggler E, 2014, IEEE INT C INT ROBOT, P2761, DOI 10.1109/IROS.2014.6942940; Mueggler Elias, 2017, BRIT MACH VIS C BMVC; Munda G, 2018, INT J COMPUT VISION, V126, P1381, DOI 10.1007/s11263-018-1106-2; Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671; Ni ZJ, 2015, NEURAL COMPUT, V27, P925, DOI 10.1162/NECO_a_00720; Ni ZJ, 2012, IEEE T ROBOT, V28, P1081, DOI 10.1109/TRO.2012.2198930; Rebecq H., 2017, BRIT MACH VIS C BMVC, P1; Rebecq H, 2019, PROC CVPR IEEE, P3852, DOI 10.1109/CVPR.2019.00398; Rebecq H, 2018, INT J COMPUT VISION, V126, P1394, DOI 10.1007/s11263-017-1050-6; Rebecq H, 2017, IEEE ROBOT AUTOM LET, V2, P593, DOI 10.1109/LRA.2016.2645143; Reinbacher C., 2016, P BRIT MACH VIS C; Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34; Scheerlinck Cedric, 2018, AS C COMP VIS ACCV; Tedaldi D, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON EVENT-BASED CONTROL, COMMUNICATION, AND SIGNAL PROCESSING (EBCCSP), DOI 10.1109/EBCCSP.2016.7605086; Vasco V, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4144, DOI 10.1109/IROS.2016.7759610; Vidal AR, 2018, IEEE ROBOT AUTOM LET, V3, P994, DOI 10.1109/LRA.2018.2793357; Zhou HY, 2009, COMPUT VIS IMAGE UND, V113, P345, DOI 10.1016/j.cviu.2008.08.006; Zhu A. Z., 2018, IEEE ROBOT AUTOM LET, V3, P2032, DOI [DOI 10.1109/LRA.2018.2800793, 10.1109/lra.2018.2800793]; Zhu A. Z., 2017, 2017 IEEE INT C ROB, P4465, DOI [DOI 10.1109/ICRA.2017.7989517, 10.1109/ICRA.2017.7989517]	50	38	41	8	25	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2020	128	3			SI		601	618		10.1007/s11263-019-01209-w	http://dx.doi.org/10.1007/s11263-019-01209-w			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	KU1MV		Green Accepted			2022-12-18	WOS:000519475600004
J	Deng, JK; Roussos, A; Chrysos, G; Ververas, E; Kotsia, I; Shen, J; Zafeiriou, S				Deng, Jiankang; Roussos, Anastasios; Chrysos, Grigorios; Ververas, Evangelos; Kotsia, Irene; Shen, Jie; Zafeiriou, Stefanos			The Menpo Benchmark for Multi-pose 2D and 3D Facial Landmark Localisation and Tracking	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						2D face alignment; 3D face alignment; Menpo challenge	FACE ALIGNMENT	In this article, we present the Menpo 2D and Menpo 3D benchmarks, two new datasets for multi-pose 2D and 3D facial landmark localisation and tracking. In contrast to the previous benchmarks such as 300W and 300VW, the proposed benchmarks contain facial images in both semi-frontal and profile pose. We introduce an elaborate semi-automatic methodology for providing high-quality annotations for both the Menpo 2D and Menpo 3D benchmarks. In Menpo 2D benchmark, different visible landmark configurations are designed for semi-frontal and profile faces, thus making the 2D face alignment full-pose. In Menpo 3D benchmark, a united landmark configuration is designed for both semi-frontal and profile faces based on the correspondence with a 3D face model, thus making face alignment not only full-pose but also corresponding to the real-world 3D space. Based on the considerable number of annotated images, we organised Menpo 2D Challenge and Menpo 3D Challenge for face alignment under large pose variations in conjunction with CVPR 2017 and ICCV 2017, respectively. The results of these challenges demonstrate that recent deep learning architectures, when trained with the abundant data, lead to excellent results. We also provide a very simple, yet effective solution, named Cascade Multi-view Hourglass Model, to 2D and 3D face alignment. In our method, we take advantage of all 2D and 3D facial landmark annotations in a joint way. We not only capitalise on the correspondences between the semi-frontal and profile 2D facial landmarks but also employ joint supervision from both 2D and 3D facial landmarks. Finally, we discuss future directions on the topic of face alignment.	[Deng, Jiankang; Chrysos, Grigorios; Ververas, Evangelos; Shen, Jie; Zafeiriou, Stefanos] Imperial Coll London, Dept Comp, London, England; [Roussos, Anastasios] Univ Exeter, Dept Comp Sci, Exeter, Devon, England; [Kotsia, Irene] Middlesex Univ London, Dept Comp Sci, London, England; [Zafeiriou, Stefanos] Univ Oulu, Ctr Machine Vis & Signal Anal, Oulu, Finland	Imperial College London; University of Exeter; Middlesex University; University of Oulu	Deng, JK (corresponding author), Imperial Coll London, Dept Comp, London, England.	j.deng16@imperial.ac.uk	Chrysos, Grigorios/ABE-2026-2021	Chrysos, Grigorios/0000-0002-0650-1856	Imperial College London; EPSRC [EP/N007743/1 (FACER2VM)]; Google Faculty Fellowship; EPSRC [EP/N007743/1] Funding Source: UKRI	Imperial College London(General Electric); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Google Faculty Fellowship(Google Incorporated); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	Jiankang Deng was supported by the President's Scholarship of Imperial College London. This work was partially funded by the EPSRC Project EP/N007743/1 (FACER2VM) and a Google Faculty Fellowship to Dr. Zafeiriou. We thank the NVIDIA Corporation for donating several Titan Xp GPUs used in this work.	Abadi M., TENSORFLOW LARGE SCA; Alabort-i Medina J., 2016, INT J COMPUT VISION, P1; [Anonymous], 2015, P IEEE INT C COMP VI; [Anonymous], 2010, PATTERN RECOGNITION; Antonakos E, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2431445; Asthana A, 2014, PROC CVPR IEEE, P1859, DOI 10.1109/CVPR.2014.240; Belhumeur PN, 2013, IEEE T PATTERN ANAL, V35, P2930, DOI 10.1109/TPAMI.2013.23; Booth J, 2018, INT J COMPUT VISION, V126, P233, DOI 10.1007/s11263-017-1009-7; Booth James, 2016, CVPR; Booth James, 2017, CVPR; Bulat A., 2017, ICCV; Burger T, 2007, VISAPP 2007: PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOLUME IU/MTSV, P5; Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191; Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249; Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3; Chen X., 2017, CVPR WORKSH; Cheng SY, 2017, IMAGE VISION COMPUT, V58, P3, DOI 10.1016/j.imavis.2016.10.007; Chrysos GG, 2018, INT J COMPUT VISION, V126, P198, DOI 10.1007/s11263-017-0999-5; Chung J. S., 2016, P AS C COMP VIS, P87; Chung JS, 2017, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2017.367; COLEMAN TF, 1961, SIAM, V6, P1040, DOI DOI 10.1137/S1052623494240456; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Crispell D, 2017, IEEE INT CONF COMP V, P2512, DOI 10.1109/ICCVW.2017.295; Cristinacce D, 2006, BMVC; Deng J., 2018, FG; Deng JK, 2016, IMAGE VISION COMPUT, V47, P19, DOI 10.1016/j.imavis.2015.11.005; Deng Jiankang, 2017, ARXIV170806023; Eleftheriadis S., 2016, CVPR WORKSH; Eleftheriadis S, 2016, IEEE T IMAGE PROCESS, V25, P5727, DOI 10.1109/TIP.2016.2615288; Feng Y., 2018, ECCV; Feng Z. H., 2017, CVPR WORKSH; Ghiasi Golnaz, 2015, ARXIV150608347; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Guler Riza Alp, 2017, CVPR; Haoqiang Fan, 2016, Image and Vision Computing, V47, P27, DOI 10.1016/j.imavis.2015.11.004; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He Z., 2017, CVPR WORKSH; Honari S., 2018, IEEE C COMP VIS PATT; Huang G. B., 2008, WORKSH FACES REAL LI; Jain V, 2010, FDDB BENCHMARK FACE; Jeni LA, 2016, LECT NOTES COMPUT SC, V9914, P511, DOI 10.1007/978-3-319-48881-3_35; Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90; Kasinski Andrzej, 2008, IMAGE PROCESSING AND, V13, P59; Kavukcuoglu K, 2015, ADV NEURAL INF PROCE, P2017; Koestinger M., 2011, ICCV WORKSH, DOI [10.1109/ICCVW.2011.6130513, DOI 10.1109/ICCVW.2011.6130513]; Kowalski M., 2017, CVPR WORKSH; Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49; Liu YJ, 2017, IEEE INT CONF COMP V, P1619, DOI 10.1109/ICCVW.2017.190; Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425; Messer K., 2005, P 2 INT C AUD VID BA, VVolume 964, P965; Milborrow S, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P380; Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29; Phillips PJ, 2005, PROC CVPR IEEE, P947; Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218; Sagonas C, 2016, IMAGE VISION COMPUT, V47, P3, DOI 10.1016/j.imavis.2016.01.002; Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59; Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4; Shao X., 2017, CVPR WORKSH; Shen J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1003, DOI 10.1109/ICCVW.2015.132; Shu ZX, 2017, PROC CVPR IEEE, P5444, DOI 10.1109/CVPR.2017.578; Szegedy C., 2017, P 31 AAAI C ART INT, V4, P12; Tadmor O., 2016, ADV NEURAL INFORM PR, P1388; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Trigeorgis G, 2016, PROC CVPR IEEE, P4177, DOI 10.1109/CVPR.2016.453; Tzimiropoulos G, 2013, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2013.79; WEBB JA, 1982, ARTIF INTELL, V19, P107, DOI 10.1016/0004-3702(82)90023-6; Wu W., 2017, CVPR WORKSH; Xiao S., 2017, CVPR WORKSH; Xiong P., 2017, ICCV WORKSH; Xiong XH, 2015, PROC CVPR IEEE, P2664, DOI 10.1109/CVPR.2015.7298882; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Yan JJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P392, DOI 10.1109/ICCVW.2013.126; Yang J., ICCVW; Yang J., 2017, CVPR WORKSH; Zadeh A., 2017, ICCV WORKSH, V7; Zadeh Amir, 2017, CVPR WORKSH; Zafeiriou S., 2017, ICCV WORKSH; Zafeiriou S., 2017, CVPR WORKSH; Zafeiriou S, 2017, IEEE COMPUT SOC CONF, P2116, DOI 10.1109/CVPRW.2017.263; Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360; Zhang ZP, 2016, IEEE T PATTERN ANAL, V38, P918, DOI 10.1109/TPAMI.2015.2469286; Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7; Zhou EJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P386, DOI 10.1109/ICCVW.2013.58; Zhu SZ, 2016, PROC CVPR IEEE, P3409, DOI 10.1109/CVPR.2016.371; Zhu SZ, 2015, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2015.7299134; Zhu X., 2016, CVPR; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014; Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23	91	38	39	1	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2019	127	6-7			SI		599	624		10.1007/s11263-018-1134-y	http://dx.doi.org/10.1007/s11263-018-1134-y			26	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	HZ0JD		Green Accepted, Green Published, hybrid			2022-12-18	WOS:000468525900005
J	Gonzalez-Garcia, A; Modolo, D; Ferrari, V				Gonzalez-Garcia, Abel; Modolo, Davide; Ferrari, Vittorio			Do Semantic Parts Emerge in Convolutional Neural Networks?	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						CNNs for computer vision; Semantic object parts; Object class recognition; Analysis of CNNs		Semantic object parts can be useful for several visual recognition tasks. Lately, these tasks have been addressed using Convolutional Neural Networks (CNN), achieving outstanding results. In this work we study whether CNNs learn semantic parts in their internal representation. We investigate the responses of convolutional filters and try to associate their stimuli with semantic parts. We perform two extensive quantitative analyses. First, we use ground-truth part bounding-boxes from the PASCAL-Part dataset to determine how many of those semantic parts emerge in the CNN. We explore this emergence for different layers, network depths, and supervision levels. Second, we collect human judgements in order to study what fraction of all filters systematically fire on any semantic part, even if not annotated in PASCAL-Part. Moreover, we explore several connections between discriminative power and semantics. We find out which are the most discriminative filters for object recognition, and analyze whether they respond to semantic parts or to other image patches. We also investigate the other direction: we determine which semantic parts are the most discriminative and whether they correspond to those parts emerging in the network. This enables to gain an even deeper understanding of the role of semantic parts in the network.	[Gonzalez-Garcia, Abel; Modolo, Davide; Ferrari, Vittorio] Univ Edinburgh, Sch Informat, IPAB, Crichton St 10, Edinburgh EH8 9AB, Midlothian, Scotland	University of Edinburgh	Gonzalez-Garcia, A (corresponding author), Univ Edinburgh, Sch Informat, IPAB, Crichton St 10, Edinburgh EH8 9AB, Midlothian, Scotland.	a.gonzalez-garcia@sms.ed.ac.uk; davide.modolo@gmail.com; vittorio.ferrari@ed.ac.uk						Agrawal P, 2014, LECT NOTES COMPUT SC, V8695, P329, DOI 10.1007/978-3-319-10584-0_22; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; [Anonymous], 2015, CVPR; Chen L, 2014, PROC CVPR IEEE, P1027, DOI 10.1109/CVPR.2014.135; Christian Szegedy, 2014, Arxiv, DOI arXiv:1312.6199; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Eigen D., 2013, ICLR WORKSHOP; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Ferrari V, 2015, BMVC; Girshick R., 2015, ICCV; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; He K., 2014, ECCV; Jia Y., 2013, CAFFE OPEN SOURCE CO; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Liu J., 2014, ECCV; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mahendran A, 2015, PROC CVPR IEEE, P5188, DOI 10.1109/CVPR.2015.7299155; Mitchell M, 1996, INTRO GENETIC ALGORI; Oquab M, 2015, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2015.7298668; Parkhi O., 2011, ICCV; Parkhi OM, 2012, PROC CVPR IEEE, P3498, DOI 10.1109/CVPR.2012.6248092; Pearson Karl, 1895, P R SOC LOND, V58, P240, DOI DOI 10.1098/RSPL.1895.0041; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Simon M., 2014, ACCV; Simon M, 2015, IEEE I CONF COMP VIS, P1143, DOI 10.1109/ICCV.2015.136; Simonyan K., 2014, ICLR WORKSHOP; Sun Min, 2011, ICCV; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Ukita N, 2012, CVPR; Vedaldi A., 2014, CVPR; Xiao T, 2015, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2015.7298885; YOSINSKI J, 2014, ADV NEURAL INFORM PR, P3320, DOI DOI 10.1109/IJCNN.2016.7727519; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang N, 2013, IEEE I CONF COMP VIS, P729, DOI 10.1109/ICCV.2013.96; Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54; Zhou Bolei, 2015, OBJECT DETECTORS EME, P2; Zhou Bolei, 2014, ADV NEURAL INFORM PR, P7, DOI DOI 10.5555/2968826.2968881	41	38	38	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2018	126	5					476	494		10.1007/s11263-017-1048-0	http://dx.doi.org/10.1007/s11263-017-1048-0			19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	FZ0UP		hybrid, Green Accepted, Green Submitted			2022-12-18	WOS:000427289200002
J	Palmero, C; Clapes, A; Bahnsen, C; Mogelmose, A; Moeslund, TB; Escalera, S				Palmero, Cristina; Clapes, Albert; Bahnsen, Chris; Mogelmose, Andreas; Moeslund, Thomas B.; Escalera, Sergio			Multi-modal RGB-Depth-Thermal Human Body Segmentation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Human body segmentation; RGB; Depth; Thermal	MOTION; COLOR; CUTS	This work addresses the problem of human body segmentation from multi-modal visual cues as a first stage of automatic human behavior analysis. We propose a novel RGB-depth-thermal dataset along with a multi-modal segmentation baseline. The several modalities are registered using a calibration device and a registration algorithm. Our baseline extracts regions of interest using background subtraction, defines a partitioning of the foreground regions into cells, computes a set of image features on those cells using different state-of-the-art feature extractions, and models the distribution of the descriptors per cell using probabilistic models. A supervised learning algorithm then fuses the output likelihoods over cells in a stacked feature vector representation. The baseline, using Gaussian mixture models for the probabilistic modeling and Random Forest for the stacked learning, is superior to other state-of-the-art methods, obtaining an overlap above 75 % on the novel dataset when compared to the manually annotated ground-truth of human segmentations.	[Palmero, Cristina; Clapes, Albert; Escalera, Sergio] UB, Dept Matemat Aplicada & Anal, Gran Via Corts Catalanes 585, Barcelona 08007, Spain; [Palmero, Cristina; Clapes, Albert; Escalera, Sergio] Comp Vis Ctr, Campus UAB,Edifici O, Cerdanyola Del Valles 08193, Spain; [Bahnsen, Chris; Mogelmose, Andreas; Moeslund, Thomas B.] Aalborg Univ, Sofiendalsvej 11, DK-9200 Aalborg SV, Denmark	University of Barcelona; Autonomous University of Barcelona; Centre de Visio per Computador (CVC); Aalborg University	Palmero, C (corresponding author), UB, Dept Matemat Aplicada & Anal, Gran Via Corts Catalanes 585, Barcelona 08007, Spain.; Palmero, C (corresponding author), Comp Vis Ctr, Campus UAB,Edifici O, Cerdanyola Del Valles 08193, Spain.	c.palmero.cantarino@gmail.com; aclapes@cvc.uab.cat; cb@create.aau.dk; am@create.aau.dk; tbmg@create.aau.dk; sergio@maia.ub.es	Escalera, Sergio/L-2998-2015; Clapés, Albert/GMW-4956-2022; Bahnsen, Chris Holmberg/T-4491-2019; Clapés, Albert/AAY-8971-2020	Escalera, Sergio/0000-0003-0617-8873; Clapés, Albert/0000-0002-4089-9060; Moeslund, Thomas B./0000-0001-7584-5209; Mogelmose, Andreas/0000-0003-0328-382X; Holmberg Bahnsen, Chris/0000-0002-8665-2418	Spanish Project [TIN2013-43478-P]; SUR-DEC of the Generalitat de Catalunya; FSE	Spanish Project(Spanish Government); SUR-DEC of the Generalitat de Catalunya(Generalitat de Catalunya); FSE(European Social Fund (ESF))	This work was partly supported by the Spanish Project TIN2013-43478-P. The work of Albert Clapes was supported by SUR-DEC of the Generalitat de Catalunya and FSE. We would like to thank Anders Jorgensen for his valuable help in capturing the dataset.	Abidi B, IEEE OTCBVS WS SERIE; Alahari K., 2013, IEEE INT C COMP VIS; Alpert S, 2007, PROC CVPR IEEE, P359; Andriluka M, 2010, PROC CVPR IEEE, P623, DOI 10.1109/CVPR.2010.5540156; Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754; Barbosa IB, 2012, LECT NOTES COMPUT SC, V7583, P433, DOI 10.1007/978-3-642-33863-2_43; Bertozzi M, 2007, 2007 IEEE INTELLIGENT VEHICLES SYMPOSIUM, VOLS 1-3, P1013; Bouguet J.Y., 2015, CAMERA CALIBRATION T; Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303; Bouwmans Thierry, 2011, Recent Patents on Computer Science, V4, P147, DOI 10.2174/1874479611104030147; Bouwmans T., 2008, RECENT PATENTS COMPU, V1, P219; Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505; Bradski G., 2008, LEARNING OPENCV COMP; Bray M, 2006, LECT NOTES COMPUT SC, V3952, P642; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Brkic K., 2013, ARXIV13100308; Buys K, 2014, J VIS COMMUN IMAGE R, V25, P39, DOI 10.1016/j.jvcir.2013.03.011; Camplani M., 2014, MACH VISION APPL, V25, P122; Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800; Charles J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1202, DOI 10.1109/ICCVW.2011.6130387; Chun SY, 2013, IEEE COMPUT SOC CONF, P387, DOI 10.1109/CVPRW.2013.65; Clapes A, 2012, LECT NOTES COMPUT SC, V7378, P1, DOI 10.1007/978-3-642-31567-1_1; Cohen W.W, 2005, STACKED SEQUENTIAL L; Dai CX, 2007, COMPUT VIS IMAGE UND, V106, P288, DOI 10.1016/j.cviu.2006.08.009; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33; Davis J.W., 2004, IEEE WORKSH OBJ TRAC; Davis JW, 2007, COMPUT VIS IMAGE UND, V106, P162, DOI 10.1016/j.cviu.2006.06.010; Everingham M., 2012, PASCAL VISUAL OBJECT; Fanelli G, 2013, INT J COMPUT VISION, V101, P437, DOI 10.1007/s11263-012-0549-0; Farneback G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50; Fernandez-Caballero A, 2011, EXPERT SYST APPL, V38, P2577, DOI 10.1016/j.eswa.2010.08.047; Fernandez-Sanchez EJ, 2013, SENSORS-BASEL, V13, P8895, DOI 10.3390/s130708895; Fidler S, 2013, PROC CVPR IEEE, P3294, DOI 10.1109/CVPR.2013.423; Gade R, 2014, MACH VISION APPL, V25, P245, DOI 10.1007/s00138-013-0570-5; Gade R, 2013, PROC CVPR IEEE, P3698, DOI 10.1109/CVPR.2013.474; Giordano D, 2014, INT C PATT RECOG, P4388, DOI 10.1109/ICPR.2014.751; Girshick R., 2011, ADV NEURAL INFORM PR, V24, P442; Gordon G., 1999, IEEE COMP SOC C COMP, V2; Gulshan V., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1127, DOI 10.1109/ICCVW.2011.6130376; Hernandez-Vela A, 2012, INT C PATT RECOG, P449; Hernandez-Vela A, 2012, PROC CVPR IEEE, P726, DOI 10.1109/CVPR.2012.6247742; Hg RI, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P42, DOI 10.1109/SITIS.2012.17; Holt B., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1196, DOI 10.1109/ICCVW.2011.6130386; Huynh Tri, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P133, DOI 10.1007/978-3-642-37410-4_12; Irani R., 2015, IEEE C COMP VIS PATT; Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446; Kumar MP, 2005, PROC CVPR IEEE, P18; Ladicky L, 2010, LECT NOTES COMPUT SC, V6314, P424, DOI 10.1007/978-3-642-15561-1_31; Leibe B., 2004, EUROPEAN C COMPUTER, P17; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; Levin A, 2006, LECT NOTES COMPUT SC, V3954, P581; Leykin A., 2006, P C COMP VIS PATT RE, P136, DOI DOI 10.1109/CVPRW.2006.175; Leykin A, 2007, PROC CVPR IEEE, P3382; Lin Z, 2007, IEEE I CONF COMP VIS, P2301; Lopes O., 2014, SPHERICAL BLURRED SH; Martin D., 2001, P ICCV, P416, DOI DOI 10.1109/ICCV.2001.937655; Mittal A, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P263, DOI 10.1109/AVSS.2003.1217930; Moeslund TB, 2011, VISUAL ANAL HUMANS L, V1st; Mogelmose A, 2013, IEEE COMPUT SOC CONF, P301, DOI 10.1109/CVPRW.2013.52; MORI G, 2004, PROC CVPR IEEE, P326; Nghiem AT, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P476, DOI 10.1109/AVSS.2007.4425357; Nikisins O, 2014, INT C PATT RECOG, P1716, DOI 10.1109/ICPR.2014.302; Olmeda D, 2012, 2012 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV), P117, DOI 10.1109/IVS.2012.6232242; Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98; Otsu N., 1975, AUTOMATICA, V11, P23; Pirsiavash H, 2012, PROC CVPR IEEE, P3226, DOI 10.1109/CVPR.2012.6248058; Plagemann C, 2010, IEEE INT CONF ROBOT, P3108, DOI 10.1109/ROBOT.2010.5509559; Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014; Puertas E, 2015, PATTERN ANAL APPL, V18, P247, DOI 10.1007/s10044-013-0333-y; Pugeault N, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130290; Ramanan D., 2006, NIPS, P1129; Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720; Scharwachter T, 2013, LECT NOTES COMPUT SC, V8142, P435, DOI 10.1007/978-3-642-40602-7_46; Schwarz L. A., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P700, DOI 10.1109/FG.2011.5771333; Sheasby Glenn, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P94, DOI 10.1007/978-3-642-37444-9_8; Sheasby G., 2012, BRIT MACH VIS C STUD; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Spinello L, 2011, IEEE INT C INT ROBOT, P3838, DOI 10.1109/IROS.2011.6048835; Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637; Stefanczyk M, 2012, LECT NOTES COMPUT SC, V7594, P626, DOI 10.1007/978-3-642-33564-8_75; Suard F, 2006, 2006 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P207; Susperregi L, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/56123; Teichman A, 2013, IEEE T AUTOM SCI ENG, V10, P841, DOI 10.1109/TASE.2013.2264286; Vidas S, 2012, IEEE T INSTRUM MEAS, V61, P1625, DOI 10.1109/TIM.2012.2182851; Vineet Vibhav, 2013, Energy Minimization Methods in Computer Vision and Pattern Recognition. 9th International Conference, EMMCVPR 2013. Proceedings. LNCS 8081, P180, DOI 10.1007/978-3-642-40395-8_14; Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8; Wang LM, 2013, PROC CVPR IEEE, P2674, DOI 10.1109/CVPR.2013.345; Wang WH, 2010, IEEE IMAGE PROC, P2313, DOI 10.1109/ICIP.2010.5649946; Wang Y, 2011, PROC CVPR IEEE, P1705, DOI 10.1109/CVPR.2011.5995519; Windheuser T, 2011, IEEE I CONF COMP VIS, P2134, DOI 10.1109/ICCV.2011.6126489; Wolf C., 2012, 5205 LIRIS UMR CNRSI; Xia L., 2011, COMP VIS PATT REC WO, P15, DOI DOI 10.1109/CVPRW.2011.5981811; Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261; Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741; Yao Bangpeng, 2010, CVPR, DOI DOI 10.1109/CVPR.2010.5540234; Zhao J., 2012, MULTIMED TOOLS APPL, V1, P1; Zhu L., 2008, IEEE C COMP VIS PATT, P1; Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992	100	38	40	0	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2016	118	2			SI		217	239		10.1007/s11263-016-0901-x	http://dx.doi.org/10.1007/s11263-016-0901-x			23	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	DO0OE		Green Submitted			2022-12-18	WOS:000377477400007
J	Tian, YD; Narasimhan, SG				Tian, Yuandong; Narasimhan, Srinivasa G.			Globally Optimal Estimation of Nonrigid Image Distortion	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Computer vision; Motion and tracking; Image alignment; Image registration; Nonrigid deformation; Feature correspondence; Distortion estimation; Global optimum; Iterative approach; Combine generative and discriminative approaches; Physics-based vision; Water distortion	MODELS; REGISTRATION	Image alignment in the presence of non-rigid distortions is a challenging task. Typically, this involves estimating the parameters of a dense deformation field that warps a distorted image back to its undistorted template. Generative approaches based on parameter optimization such as Lucas-Kanade can get trapped within local minima. On the other hand, discriminative approaches like nearest-neighbor require a large number of training samples that grows exponentially with respect to the dimension of the parameter space, and polynomially with the desired accuracy 1/I mu. In this work, we develop a novel data-driven iterative algorithm that combines the best of both generative and discriminative approaches. For this, we introduce the notion of a "pull-back" operation that enables us to predict the parameters of the test image using training samples that are not in its neighborhood (not I mu-close) in the parameter space. We prove that our algorithm converges to the global optimum using a significantly lower number of training samples that grows only logarithmically with the desired accuracy. We analyze the behavior of our algorithm extensively using synthetic data and demonstrate successful results on experiments with complex deformations due to water and clothing.	[Tian, Yuandong; Narasimhan, Srinivasa G.] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Tian, YD (corresponding author), Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.	yuandong@cs.cmu.edu; srinivas@cs.cmu.edu			ONR [N00014-08-1-0330, DURIP N00014-06-1-0762]; Okawa Research grant; NSF [IIS-0643628]	ONR(Office of Naval Research); Okawa Research grant; NSF(National Science Foundation (NSF))	This work was supported in parts by ONR grants N00014-08-1-0330 and DURIP N00014-06-1-0762, an Okawa Research grant and an NSF CAREER Award IIS-0643628.	Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21; [Anonymous], 2008, CVPR; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Baker S., 2001, CVPR; Bissacco A., 2007, CVPR; Cootes T., 1998, ECCV; Efros A., 2004, NIPS, p[1153, 1154, 1156]; FATHI A, 2007, ICCV; FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909; Gleicher M, 1997, CVPR; Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606; Hess R., 2007, CVPR; Hou X., 2001, CVPR; Jurie F, 2002, IEEE T PATTERN ANAL, V24, P996, DOI 10.1109/TPAMI.2002.1017625; Learned-Miller EG, 2006, IEEE T PATTERN ANAL, V28, P236, DOI 10.1109/TPAMI.2006.34; LING H, 2005, ICCV; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lucas B.D., 1981, ITERATIVE IMAGE REGI, P674; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; NGUYEN M, 2008, CVPR; Pilet J, 2008, INT J COMPUT VISION, V76, P109, DOI 10.1007/s11263-006-0017-9; Rogez G., 2008, CVPR; Rosales R., 2002, NIPS; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284; Salzmann M., 2010, CVPR; Salzmann M., 2007, ICCV; Salzmann M., 2009, CVPR; Sclaroff S., 1998, ICCV; Shekhovtsov A, 2008, COMPUT VIS IMAGE UND, V112, P91, DOI 10.1016/j.cviu.2008.06.006; SHON A, 2006, NIPS; Shum HY, 2000, INT J COMPUT VISION, V36, P101, DOI 10.1023/A:1008195814169; Sigal L., 2007, NIPS; Sminchisescu C, 2007, IEEE T PATTERN ANAL, V29, P2030, DOI 10.1109/TPAMI.2007.1111; Taylor J., 2010, CVPR; Tian Y., 2009, ICCV; Tuzel O., 2008, CVPR; Zeng Yun, 2010, CVPR; ZHAO X, 2008, ICPR	38	38	48	1	12	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2012	98	3					279	302		10.1007/s11263-011-0509-0	http://dx.doi.org/10.1007/s11263-011-0509-0			24	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	934NI		Green Submitted			2022-12-18	WOS:000303450600003
J	Zhang, DS; Islam, MM; Lu, GJ; Sumana, IJ				Zhang, Dengsheng; Islam, M. Monirul; Lu, Guojun; Sumana, Ishrat Jahan			Rotation Invariant Curvelet Features for Region Based Image Retrieval	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Texture; Image retrieval; Curvelet transform; CBIR; Gabor filters	TEXTURE FEATURES; COLOR; CLASSIFICATION; SEGMENTATION; TRANSFORM	There have been much interest and a large amount of research on content based image retrieval (CBIR) in recent years due to the ever increasing number of digital images. Texture features play a key role in CBIR. Many texture features exist in literature, however, most of them are neither rotation invariant nor robust to scale and other variations. Texture features based on Gabor filters have been shown with significant advantages over other methods, and they are adopted by MPEG-7 as one of the texture descriptors for image retrieval. In this paper, we propose a rotation invariant curvelet features for texture representation. With systematic analysis and rigorous experiments, we show that the proposed curvelet texture features significantly outperforms the widely used Gabor texture features. A novel region padding method is also proposed to apply curvelet transform to region based image retrieval. Retrieval results from standard image databases show that curvelet features are promising for both texture and region representation.	[Zhang, Dengsheng; Islam, M. Monirul; Lu, Guojun; Sumana, Ishrat Jahan] Monash Univ, Gippsland Sch Informat Technol, Churchill, Vic 3842, Australia	Federation University Australia; Monash University	Zhang, DS (corresponding author), Monash Univ, Gippsland Sch Informat Technol, Churchill, Vic 3842, Australia.	Dengsheng.Zhang@monash.edu; Md.Monirul.Islam@monash.edu; Guojun.Lu@monash.edu; Ishrat.Sumana@monash.edu	Zhang, Dengsheng/W-8467-2019	Zhang, Dengsheng/0000-0001-8728-1746; Lu, Guojun/0000-0003-2523-7576				Arivazhagan S, 2006, INT C PATT RECOG, P938; Bhagavathy S, 2007, ECE278A U CAL VIS RE; Candes E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X; CHAUDHURI BB, 1995, IEEE T PATTERN ANAL, V17, P72, DOI 10.1109/34.368149; Chen LP, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P273; Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248; DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160; DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644; DAUGMAN JG, 1989, IEEE T BIO-MED ENG, V36, P107, DOI 10.1109/10.16456; DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676; Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985; Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822; Do MN, 2003, IEEE T IMAGE PROCESS, V12, P16, DOI 10.1109/TIP.2002.806252; DO MN, 2001, THESIS EPFL; Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97; Ferecatu M, 2007, IEEE T GEOSCI REMOTE, V45, P818, DOI 10.1109/TGRS.2007.892007; Herve N., 2007, P 6 ACM INT C IM VID, P70; Howarth P, 2004, LECT NOTES COMPUT SC, V3115, P326; Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412; INOUE M, 2004, P WORKSH INF RETR CO, P44; Islam M., 2009, P 9 AS C COMP VIS AC; Islam Md Monirul, 2008, 2008 Digital Image Computing: Techniques and Applications, P191, DOI 10.1109/DICTA.2008.17; Jeon J., 2003, P ACM SIGIR C RES DE, P119; Joutel G, 2007, PROC INT CONF DOC, P649; Joutel G., 2007, SPIE, V6500; Kokare M, 2006, IEEE T SYST MAN CY B, V36, P1273, DOI 10.1109/TSMCB.2006.874692; Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005; Li SZ, 2000, IEEE T PATTERN ANAL, V22, P1335, DOI 10.1109/34.888719; Liu F, 1996, IEEE T PATTERN ANAL, V18, P722, DOI 10.1109/34.506794; Liu Y, 2008, PATTERN RECOGN, V41, P2554, DOI 10.1016/j.patcog.2007.12.003; Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045; Long F., 2003, MULTIMEDIA INFORM RE; Lu Yijuan, 2008, P IEEE C COMP VIS PA, P1; Lu ZM, 2006, INT J INNOV COMPUT I, V2, P831; Ma Y., 1995, P IEEE INT C IM PROC, V2, P256, DOI DOI 10.1109/ICIP.1995.537463; Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803; Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424; MANJUNATH BS, 2002, INTRO MPEG 7; Ng C. R., 2005, P IEEE INT WORKSH MU; Ngo CW, 2001, PATTERN RECOGN, V34, P1841, DOI 10.1016/S0031-3203(00)00111-4; NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173; Semler L, 2006, IEEE IMAGE PROC, P2165, DOI 10.1109/ICIP.2006.312873; Shekhar R., 2005, LECT NOTES COMPUTER, V3776, P563; Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI 10.1117/12.408568; Suematsu N., 2002, P 15 INT C VIS INT M; Sumana IJ, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P11, DOI 10.1109/MMSP.2008.4665041; TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999; Vasconcelos N, 2007, COMPUTER, V40, P20, DOI 10.1109/MC.2007.239; Vertan C, 2000, LECT NOTES COMPUT SC, V1929, P178; Wang C., 2008, P 31 ANN INT ACM SIG, V24, P355, DOI DOI 10.1145/1390334.1390396; Wang C, 2008, P INT C CONT BAS IM, P113; Wang C. C., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383221; Wang Changhu, 2006, P 14 ANN ACM INT C M, P647, DOI DOI 10.1145/1180639.1180774; Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109; Zhang DS, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P928; Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008; Zhang DS, 2000, P 1 IEEE PAC RIM C M, P1139	57	38	41	0	23	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2012	98	2					187	201		10.1007/s11263-011-0503-6	http://dx.doi.org/10.1007/s11263-011-0503-6			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	934NH					2022-12-18	WOS:000303450500004
J	Tretyak, E; Barinova, O; Kohli, P; Lempitsky, V				Tretyak, Elena; Barinova, Olga; Kohli, Pushmeet; Lempitsky, Victor			Geometric Image Parsing in Man-Made Environments	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Geometry estimation; Scene understanding; Man-made environment; Vanishing points estimation	VANISHING POINT DETECTION	We present a new optimization based parsing framework for the geometric analysis of a single image coming from a man-made environment. This framework models the scene as a composition of geometric primitives spanning different layers from low level (edges) through mid-level (lines segments, lines and vanishing points) to high level (the zenith and the horizon). The inference in such a model thus jointly and simultaneously estimates (a) the grouping of edges into the line segments, (b) the grouping of line segments into the straight lines, (c) the grouping of lines into parallel families, and (d) the positioning of the horizon and the zenith in the image. Such a unified treatment means that the uncertainty information propagates between the layers of the model. This is in contrast to most previous approaches to the same problem, which either ignore the middle levels (line segments or lines) all together, or use the bottom-up step-by-step pipeline. For the evaluation, we consider a publicly available York Urban dataset of "Manhattan" scenes, and also introduce a new, harder dataset of 103 urban outdoor images containing many non-Manhattan scenes. The comparative evaluation for the horizon estimation task demonstrate higher accuracy and robustness attained by our method when compared to the current state-of-the-art approaches.	[Tretyak, Elena; Barinova, Olga] Moscow MV Lomonosov State Univ, Moscow, Russia; [Kohli, Pushmeet] Microsoft Res Cambridge, Cambridge, England; [Lempitsky, Victor] Univ Oxford, Oxford, England	Lomonosov Moscow State University; Microsoft; University of Oxford	Tretyak, E (corresponding author), Moscow MV Lomonosov State Univ, Moscow, Russia.	tretiak.elena@gmail.com; olga.barinova@gmail.com; pkohli@microsoft.com; victorlempitsky@gmail.com			EU under ERC [228180]; Microsoft, Russia	EU under ERC; Microsoft, Russia	Tretyak Elena, Barinova Olga and Victor Lempitsky are supported by Microsoft Research programs in Russia. Victor Lempitsky is also supported by EU under ERC grant VisRec no. 228180.	Aguilera D. G., 2005, P ISPRS COMM 5; Almansa A, 2003, IEEE T PATTERN ANAL, V25, P502, DOI 10.1109/TPAMI.2003.1190575; Antone ME, 2000, PROC CVPR IEEE, P282, DOI 10.1109/CVPR.2000.854809; Barinova O., 2010, CVPR; Barinova O., 2010, ECCV; BARNARD ST, 1983, ARTIF INTELL, V21, P435, DOI 10.1016/S0004-3702(83)80021-6; Beardsley P., 1992, BMVC92. Proceedings of the British Machine Vision Conference, P416; BOULANGER K, 2006, EG UK THEORY PRACTIC; Cipolla Roberto, 1999, BMVC; Collins R. T., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P400, DOI 10.1109/ICCV.1990.139560; Coughlan J.M., 1999, P ICCV, V2, P941, DOI DOI 10.1109/ICCV.1999.790349; Denis P, 2008, LECT NOTES COMPUT SC, V5303, P197, DOI 10.1007/978-3-540-88688-4_15; Deutscher J, 2002, LECT NOTES COMPUT SC, V2353, P175; Duric Z, 1996, REAL-TIME IMAGING, V2, P271, DOI 10.1006/rtim.1996.0029; Flint A, 2010, PROC CVPR IEEE, P467, DOI 10.1109/CVPR.2010.5540176; Hartley R., 2003, MULTIPLE VIEW GEOMET; Hedau V, 2010, LECT NOTES COMPUT SC, V6316, P224, DOI 10.1007/978-3-642-15567-3_17; Hedau V, 2009, IEEE I CONF COMP VIS, P1849, DOI 10.1109/ICCV.2009.5459411; Hoiem D, 2005, IEEE I CONF COMP VIS, P654; Hoiem D, 2005, ACM T GRAPHIC, V24, P577, DOI 10.1145/1073204.1073232; Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5; Kosecka J, 2002, LECT NOTES COMPUT SC, V2353, P476; Lee D.C., 2010, ADV NEURAL INFORM PR; Lee D. C., 2009, CVPR; MCLEAN GF, 1995, IEEE T PATTERN ANAL, V17, P1090, DOI 10.1109/34.473236; Rother C., 2000, BMVC; Schaffalitzky F, 2000, IMAGE VISION COMPUT, V18, P647, DOI 10.1016/S0262-8856(99)00069-4; Schindler G, 2004, PROC CVPR IEEE, P203; Tardif J.-P., 2009, ICCV; Tu ZW, 2005, INT J COMPUT VISION, V63, P113, DOI 10.1007/s11263-005-6642-x; Tuytelaars T, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P67, DOI 10.1109/ICCV.1998.710702; von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300; Wildenauer H, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P615, DOI 10.1109/ICIAP.2007.4362845; Yu SX, 2008, POCV	34	38	43	0	12	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2012	97	3					305	321		10.1007/s11263-011-0488-1	http://dx.doi.org/10.1007/s11263-011-0488-1			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	907VP					2022-12-18	WOS:000301447600004
J	Huynh, CP; Robles-Kelly, A				Huynh, Cong Phuoc; Robles-Kelly, Antonio			A Solution of the Dichromatic Model for Multispectral Photometric Invariance	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Photometric invariance; Multispectral imaging; Dichromatic reflection model; Reflectance	COLOR; SHAPE; CHROMATICITY; CONSISTENCY	In this paper, we address the problem of photometric invariance in multispectral imaging making use of an optimisation approach based upon the dichromatic model. In this manner, we cast the problem of recovering the spectra of the illuminant, the surface reflectance and the shading and specular factors in a structural optimisation setting. Making use of the additional information provided by multispectral imaging and the structure of image patches, we recover the dichromatic parameters of the scene. To do this, we formulate a target cost function combining the dichromatic error and the smoothness priors for the surfaces under study. The dichromatic parameters are recovered through minimising this cost function in a coordinate descent manner. The algorithm is quite general in nature, admitting the enforcement of smoothness constraints and extending in a straightforward manner to trichromatic settings. Moreover, the objective function is convex with respect to the subset of variables to be optimised in each alternating step of the minimisation strategy. This gives rise to an optimal closed-form solution for each of the iterations in our algorithm. We illustrate the effectiveness of our method for purposes of illuminant spectrum recovery, skin recognition, material clustering and specularity removal. We also compare our results to a number of alternatives.	[Huynh, Cong Phuoc; Robles-Kelly, Antonio] Australian Natl Univ, Sch Engn, Canberra, ACT 0200, Australia; [Robles-Kelly, Antonio] Natl ICT Australia NICTA, Canberra, ACT 2601, Australia	Australian National University; NICTA	Huynh, CP (corresponding author), Australian Natl Univ, Sch Engn, GPO Box 4, Canberra, ACT 0200, Australia.	huynh@rsise.anu.edu.au; Antonio.Robles-Kelly@nicta.com.au	Robles-Kelly, Antonio/A-2459-2009; Huynh, Cong/V-5712-2019	Robles-Kelly, Antonio/0000-0002-2465-5971; 	Australian Government	Australian Government(Australian GovernmentCGIAR)	NICTA is funded by the Australian Government as represented by the Department of Broadband, Communications and the Digital Economy and the Australian Research Council through the ICT Centre of Excellence program.	Angelopoulou E, 2000, LECT NOTES COMPUT SC, V1842, P359; Angelopoulou E, 2007, IEEE I CONF COMP VIS, P2104; Barnard K, 2002, IEEE T IMAGE PROCESS, V11, P985, DOI 10.1109/TIP.2002.802529; Barnard K, 2002, COLOR RES APPL, V27, P147, DOI 10.1002/col.10049; BARNARD K, 2000, P 6 EUR C COMP VIS D, P375; Boyd S., 2004, CONVEX OPTIMIZATION, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441.001, 10.1017/cbo97805118044 41]; Brainard DH, 2006, J VISION, V6, P1267, DOI 10.1167/6.11.10; BRAINARD DH, 1986, J OPT SOC AM A, V3, P1651, DOI 10.1364/JOSAA.3.001651; Brainard DH, 1997, J OPT SOC AM A, V14, P1393, DOI 10.1364/JOSAA.14.001393; BRELSTAFF G, 1988, INT C COMP VIS, P297; BROOKS M, 1985, MIT AI MEMO; BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7; Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199; CHANG JY, 2003, P INT C IM PROC; CIE, 1932, COMM INT ECL P 1931; DROR RO, 2001, P IEEE WORKSH ID OBJ; FERRIE FP, 1992, CVGIP-IMAG UNDERSTAN, V55, P95, DOI 10.1016/1049-9660(92)90009-R; Finayson GD, 2001, IEEE T PATTERN ANAL, V23, P1209, DOI 10.1109/34.969113; Finlayson G, 2000, IEEE T IMAGE PROCESS, V9, P1774, DOI 10.1109/83.869188; Finlayson GD, 2006, INT J COMPUT VISION, V67, P93, DOI 10.1007/s11263-006-4100-z; Finlayson GD, 2001, PROC CVPR IEEE, P598; Finlayson GD, 2001, INT J COMPUT VISION, V42, P127, DOI 10.1023/A:1011120214885; FORSYTH DA, 1990, INT J COMPUT VISION, V5, P5, DOI 10.1007/BF00056770; HEALEY G, 1991, IMAGE VISION COMPUT, V9, P333, DOI 10.1016/0262-8856(91)90038-Q; Healey G., 1999, IEEE C COMP VIS PATT, P1438; Hoaglin D. C, 2000, UNDERSTANDING ROBUST; Hofmann T, 1997, IEEE T PATTERN ANAL, V19, P1, DOI 10.1109/34.566806; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1986, COMPUT VISION GRAPH, V33, P174, DOI 10.1016/0734-189X(86)90114-3; Huber PJ, 1981, ROBUST STAT; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; KLINKER GJ, 1990, INT J COMPUT VISION, V4, P7, DOI 10.1007/BF00137441; KLINKER GJ, 1988, INT J COMPUT VISION, V2, P7, DOI 10.1007/BF00836279; KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F; LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001; LAND EH, 1986, VISION RES, V26, P7, DOI 10.1016/0042-6989(86)90067-2; LEE HC, 1986, J OPT SOC AM A, V3, P1694, DOI 10.1364/JOSAA.3.001694; LI SZ, 1995, IMAGE VISION COMPUT, V13, P227, DOI 10.1016/0262-8856(95)90842-V; Lin S, 2001, PROC CVPR IEEE, P341; Mallick SP, 2006, LECT NOTES COMPUT SC, V3951, P550; Narasimhan SG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1387; Nayar SK, 1996, INT J COMPUT VISION, V17, P219, DOI 10.1007/BF00128232; NAYAR SK, 1993, PATTERN RECOGN, V26, P1529, DOI 10.1016/0031-3203(93)90158-S; Phung SL, 2005, IEEE T PATTERN ANAL, V27, P148, DOI 10.1109/TPAMI.2005.17; Poggio T, 1984, ILL POSED PROBLEMS R; Ragheb H, 2002, LECT NOTES COMPUT SC, V2351, P626; RASKAR R, 2006, P EUR STAT ART REP S; SCHAEFER G, 2005, COMP VIS PATT REC 20, V1, P148; SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409; SLATER D, 1997, COMPUTER VISION PATT, P827; Stokman H., 1999, BMVC99. Proceedings of the 10th British Machine Vision Conference, P643; Suen PH, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P262, DOI 10.1109/ICCV.2001.937527; SUNSHINE JM, 1990, J GEOPHYS RES-SOLID, V95, P6955, DOI 10.1029/JB095iB05p06955; Tan RT, 2004, IEEE T PATTERN ANAL, V26, P1373, DOI 10.1109/TPAMI.2004.90; TOMINAGA S, 1989, J OPT SOC AM A, V6, P576, DOI 10.1364/JOSAA.6.000576; TOMINAGA S, 1990, J OPT SOC AM A, V7, P312, DOI 10.1364/JOSAA.7.000312; van de Weijer J, 2005, IEEE IMAGE PROC, P2069; Wang J, 2006, IEEE T PATTERN ANAL, V28, P446, DOI 10.1109/TPAMI.2006.63; Worthington PL, 1999, IEEE T PATTERN ANAL, V21, P1250, DOI 10.1109/34.817406; ZHENG QF, 1991, IEEE T PATTERN ANAL, V13, P680, DOI 10.1109/34.85658; Zickler T, 2008, INT J COMPUT VISION, V79, P13, DOI 10.1007/s11I263-007-0087-3	61	38	38	0	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	OCT	2010	90	1					1	27		10.1007/s11263-010-0333-y	http://dx.doi.org/10.1007/s11263-010-0333-y			27	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	616GA		Green Submitted			2022-12-18	WOS:000279195800001
J	Porway, J; Wang, QC; Zhu, SC				Porway, Jake; Wang, Qiongchen; Zhu, Song Chun			A Hierarchical and Contextual Model for Aerial Image Parsing	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Hierarchical models; Scene-level context; Statistical learning; Image understanding; Aerial images; Swendsen-Wang clustering; Bayesian inference		In this paper we present a hierarchical and contextual model for aerial image understanding. Our model organizes objects (cars, roofs, roads, trees, parking lots) in aerial scenes into hierarchical groups whose appearances and configurations are determined by statistical constraints (e.g. relative position, relative scale, etc.). Our hierarchy is a non-recursive grammar for objects in aerial images comprised of layers of nodes that can each decompose into a number of different configurations. This allows us to generate and recognize a vast number of scenes with relatively few rules. We present a minimax entropy framework for learning the statistical constraints between objects and show that this learned context allows us to rule out unlikely scene configurations and hallucinate undetected objects during inference. A similar algorithm was proposed for texture synthesis (Zhu et al. in Int. J. Comput. Vis. 2:107-126, 1998) but didn't incorporate hierarchical information. We use a range of different bottom-up detectors (AdaBoost, TextonBoost, Compositional Boosting (Freund and Schapire in J. Comput. Syst. Sci. 55, 1997; Shotton et al. in Proceedings of the European Conference on Computer Vision, pp. 1-15, 2006; Wu et al. in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-8, 2007)) to propose locations of objects in new aerial images and employ a cluster sampling algorithm (C4 (Porway and Zhu, 2009)) to choose the subset of detections that best explains the image according to our learned prior model. The C4 algorithm can quickly and efficiently switch between alternate competing sub-solutions, for example whether an image patch is better explained by a parking lot with cars or by a building with vents. We also show that our model can predict the locations of objects our detectors missed. We conclude by presenting parsed aerial images and experimental results showing that our cluster sampling and top-down prediction algorithms use the learned contextual cues from our model to improve detection results over traditional bottom-up detectors alone.	[Porway, Jake; Wang, Qiongchen; Zhu, Song Chun] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA; [Wang, Qiongchen; Zhu, Song Chun] Lotus Hill Inst Comp Vis & Informat Sci, Ezhou, Peoples R China	University of California System; University of California Los Angeles	Porway, J (corresponding author), Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA.	jakeporway@gmail.com			NSF [IIS-0713652]; ONR [N00014-05-01-0543]; 863 project [2008AA01Z126]; NSFC [60776793]	NSF(National Science Foundation (NSF)); ONR(Office of Naval Research); 863 project(National High Technology Research and Development Program of China); NSFC(National Natural Science Foundation of China (NSFC))	This work at UCLA is supported by an NSF grant IIS-0713652 and ONR grant N00014-05-01-0543. The work at Lotus Hill Research Institute is supported by 863 project 2008AA01Z126 and NSFC grant 60776793. We thank the Lotus Hill Dataset for groundtruth annotation (Yao et al. 2007) for the aerial images used in this paper and Benjamin Yao for his many helpful discussions and his assistance with preparing the dataset.	Barbu A, 2005, IEEE T PATTERN ANAL, V27, P1239, DOI 10.1109/TPAMI.2005.161; Berg A., 2007, IEEE 11 INT C COMP V; Chen H., 2006, PROC IEEE COMPUT SCI, V1, P943; CHI Z, 1998, COMPUTATIONAL LINGUI, V24; Fei-Fei L, 2005, PROC CVPR IEEE, P524; Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49; FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602; Freund Y., 1997, J COMPUTER SYSTEM SC, V55; HAN F, 2005, P INT C COMP VIS, V2; HINZ S, 2000, INT ARCH PHOTOGRAMME, V33; JIN Y, 2006, P IEEE C COMP VIS PA, V2, P2145; JOHNSON M, 1999, P ACL 99 MAR; KESELMAN Y, 2001, PATTERN ANAL MACHINE, V27, P1141; LI Y, 2005, SPIE INT SOC OPTICAL; MALOOF MA, 2003, MACHINE LEARNING; MATSUYAMA T, 1990, SIGMA FRAMEWORK IMAG; MOISSINAC H, 1994, P SPIE; NICOLAS B, 2000, INT ARCH PHOTOGRAMME; OHTA Y, 1985, KNOWLEDGE BASED INTE; Porway J., 2008, P IEEE C COMP VIS PA; PORWAY J, 2009, C4 STOCHASTIC INFERE; Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1; Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703; SINGHAL A, 2003, IEEE COMP SOC C COMP, V1; Sivic J., 2005, 10 IEEE INT C COMP V; Sudderth E., 2005, NEURAL INFORM PROCES; SWENDSEN R, 1987, PHYS REV LETT; TODOROVIC S, 2006, P IEEE INT C COMP VI, V1, P927; Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239; ULLMAN S, 2001, P 4 INT WORKSH VIS F; VESTRI C, 2001, P IEEE C COMP VIS PA, V1; Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517; Wainwright MJ, 2008, FOUND TRENDS MACH LE, V1, P1, DOI 10.1561/2200000001; Weber M, 2000, PROC CVPR IEEE, P101, DOI 10.1109/CVPR.2000.854754; WEI L, 2005, GEOSC REM SENS S IGA, P25; Wu J, 2007, PROCEEDINGS OF THE 2007 IEEE INTERNATIONAL CONFERENCE ON SERVICE OPERATIONS AND LOGISTICS, AND INFORMATICS, P7, DOI 10.1109/SOLI.2007.4383891; ZHAO T, 2001, IEEE INT C COMP VIS, V1; ZHU L, 2008, P 10 EUR C COMP VI 2; Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420; Zhu SC, 2006, FOUND TRENDS COMPUT, V2, P259, DOI 10.1561/0600000018; [No title captured]	42	38	41	0	22	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN 10	2010	88	2			SI		254	283		10.1007/s11263-009-0306-1	http://dx.doi.org/10.1007/s11263-009-0306-1			30	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	573YX		Green Published, Bronze			2022-12-18	WOS:000275955400007
J	Byrod, M; Josephson, K; Astrom, K				Byrod, Martin; Josephson, Klas; Astrom, Kalle			Fast and Stable Polynomial Equation Solving and Its Application to Computer Vision	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Polynomial equations; Grobner basis; Minimal problems; Structure from motion	ALGORITHM; SYSTEMS	This paper presents several new results on techniques for solving systems of polynomial equations in computer vision. Grobner basis techniques for equation solving have been applied successfully to several geometric computer vision problems. However, in many cases these methods are plagued by numerical problems. In this paper we derive a generalization of the Grobner basis method for polynomial equation solving, which improves overall numerical stability. We show how the action matrix can be computed in the general setting of an arbitrary linear basis for a",[x]/I. In particular, two improvements on the stability of the computations are made by studying how the linear basis for a",[x]/I should be selected. The first of these strategies utilizes QR factorization with column pivoting and the second is based on singular value decomposition (SVD). Moreover, it is shown how to improve stability further by an adaptive scheme for truncation of the Grobner basis. These new techniques are studied on some of the latest reported uses of Grobner basis methods in computer vision and we demonstrate dramatically improved numerical stability making it possible to solve a larger class of problems than previously possible.	[Byrod, Martin; Josephson, Klas; Astrom, Kalle] Lund Univ, Ctr Math Sci, S-22100 Lund, Sweden	Lund University	Byrod, M (corresponding author), Lund Univ, Ctr Math Sci, Solvegatan 18, S-22100 Lund, Sweden.	byrod@maths.lth.se; klasj@maths.lth.se; kalle@maths.lth.se	Åström, Kalle/C-2836-2009; Astrom, Kalle/AAT-9538-2020	Åström, Kalle/0000-0002-8689-7810; Astrom, Kalle/0000-0002-8689-7810				AGARWAL S, 2006, P 9 EUR C COMP VIS G, P592; Anderson E., 1999, LAPACK USERS GUIDE S; [Anonymous], 1996, REC; [Anonymous], 1998, USING ALGEBRAIC GEOM; [Anonymous], [No title captured]; BAYER D, 1994, MACAULAY; BROWN M, 2007, P INT C COMP VIS PAT; Bujnak M., 2008, P C COMP VIS PATT RE; BYROD M, 2007, P 11 INT C COMP VIS; Byrod M., 2007, AS C COMP VIS; BYROD M, 2008, 10 EUR C COMP VIS; Byrod M., 2008, P C COMP VIS PATT RE; CHASLES M, 1855, NOUV ANN MATH, V14; Cox D. A., 2007, IDEALS VARIETIES ALG; DEMAZURE M, 1988, 882 INRIA; Faugere JC, 1999, J PURE APPL ALGEBRA, V139, P61, DOI 10.1016/S0022-4049(99)00005-5; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; GEYER C, 2007, P C COMP VIS PATT RE; Golub Gene H., 2013, MATRIX COMPUTATION, V3; Grayson D., 1993, MACAULAY2; Hartley R, 2004, PROC CVPR IEEE, P504; Hartley RI, 1997, COMPUT VIS IMAGE UND, V68, P146, DOI 10.1006/cviu.1997.0547; Holt RJ, 1996, IEEE T IMAGE PROCESS, V5, P976, DOI 10.1109/83.503913; Hook D., 1990, GRAPHICS GEMS, P416; JOSEPHSON K, 2007, 2 INT ISPRS WORKSH B; Kahl F, 2005, IEEE I CONF COMP VIS, P1002; Kahl F, 2005, IEEE I CONF COMP VIS, P978; Karasalo I., 1974, BIT (Nordisk Tidskrift for Informationsbehandling), V14, P156, DOI 10.1007/BF01932945; Kruppa E., 1913, SITZ BER AKAD WIS MN, V122, P1939; Kukelova Z., 2007, P 7 WORKSH OMN VIS C; Kukelova Z., 2007, CVPR; LAZARD D, 1981, THEOR COMPUT SCI, V15, P77, DOI 10.1016/0304-3975(81)90064-5; LI H, 2006, P 9 EUR C COMP VIS G; Nister D, 2003, PROC CVPR IEEE, P195; Pless R., 2003, P C COMP VIS PATT RE; Stewenius H, 2005, IEEE I CONF COMP VIS, P686; Stewenius H., 2005, THESIS LUND U; STEWENIUS H, 2005, P C COMP VIS PATT RE; Stewenius H, 2006, ISPRS J PHOTOGRAMM, V60, P284, DOI 10.1016/j.isprsjprs.2006.03.005; Stewenius Henrik, 2005, WORKSH OMN VIS; THOMPSON EH, 1959, PHOTOGRAMM REC, V14, P152; Torr P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P727, DOI 10.1109/ICCV.1998.710798; Torr PHS, 1997, IMAGE VISION COMPUT, V15, P591, DOI 10.1016/S0262-8856(97)00010-3; Verschelde J, 1999, ACM T MATH SOFTWARE, V25, P251, DOI 10.1145/317275.317286	44	38	38	0	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2009	84	3					237	256		10.1007/s11263-009-0235-z	http://dx.doi.org/10.1007/s11263-009-0235-z			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	458MS		Green Submitted			2022-12-18	WOS:000267028600001
J	Deselaers, T; Muller, H; Clough, P; Ney, H; Lehmann, TM				Deselaers, Thomas; Muller, Henning; Clough, Paul; Ney, Hermann; Lehmann, Thomas M.			The CLEF 2005 automatic medical image annotation task	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	10th IEEE International Conference on Computer Vision (ICCV 2005)	OCT 17-20, 2005	Beijing, PEOPLES R CHINA	IEEE, IEEE Comp Soc, Microsoft, intel, OMRON, SIEMENS, Mitsubishi Elect, Sarnoff Corp, Point Grey Res		content-based image retrieval; medical image annotation; evaluation in computer vision	RETRIEVAL; CLASSIFICATION	In this paper, the automatic annotation task of the 2005 CLEF cross-language image retrieval campaign (ImageCLEF) is described. This paper focuses on the database used, the task setup, and the plans for further medical image annotation tasks in the context of ImageCLEF. Furthermore, a short summary of the results of 2005 is given. The automatic annotation task was added to ImageCLEF in 2005 and provides the first international evaluation of state-of-the-art methods for completely automatic annotation of medical images based on visual properties. The aim of this task is to explore and promote the use of automatic annotation techniques to allow for extracting semantic information from little-annotated medical images. A database of 10.000 images was established and annotated by experienced physicians resulting in 57 classes, each with at least 10 images. Detailed analysis is done regarding the (i) image representation, (ii) classification method, and (iii) learning method. Based on the strong participation of the 2005 campain, future benchmarks are planned.	Univ Aachen, Rhein Westfal TH Aachen, Dept Comp Sci, D-5100 Aachen, Germany; Univ Aachen, Rhein Westfal TH Aachen, Dept Med Informat, Fac Med, D-5100 Aachen, Germany; Geneva Univ & Hosp, Med Informat Serv, Geneva, Switzerland; Univ Sheffield, Dept Informat Studies, Sheffield S10 2TN, S Yorkshire, England	RWTH Aachen University; RWTH Aachen University; University of Geneva; University of Sheffield	Deselaers, T (corresponding author), Univ Aachen, Rhein Westfal TH Aachen, Dept Comp Sci, D-5100 Aachen, Germany.	deselaers@cs.rwth-aachen.de; henning.mueller@sim.hcuge.ch; p.d.clough@sheffield.ac.uk; ney@cs.rwth-aachen.de; lehmann@computer.org		Muller, Henning/0000-0001-6800-9878				BALLESTEROS L, 2005, LNCS, V4022, P662; BESANCON R, 2005, LNCS, V4022, P622; CHANG YC, 2005, LNCS, V4022, P592; Chen DR, 1999, RADIOLOGY, V213, P407, DOI 10.1148/radiology.213.2.r99nv13407; CHENG PC, 2005, LNCS, V4022, P712; Clough P, 2006, LECT NOTES COMPUT SC, V4022, P535; Deselaers T, 2005, PROC CVPR IEEE, P157; Eidenberger H, 2003, P SOC PHOTO-OPT INS, V5150, P476, DOI 10.1117/12.503064; Everingham M, 2006, LECT NOTES ARTIF INT, V3944, P117; Gabor D., 1946, J I ELECT ENG, V93, P429, DOI DOI 10.1049/JI-3-2.1946.0074; Guld MO, 2002, PROC SPIE, V4685, P280, DOI 10.1117/12.467017; Keysers D, 2003, J ELECTRON IMAGING, V12, P59, DOI 10.1117/1.1525790; KEYSERS D, 2004, P BVM 2004 BILDV MED, P366; Lehmann TM, 2003, PROC SPIE, V5033, P440, DOI 10.1117/12.480677; Lehmann TM, 2005, COMPUT MED IMAG GRAP, V29, P143, DOI 10.1016/j.compmedimag.2004.09.010; Maree R, 2005, LECT NOTES COMPUT SC, V3765, P220; MARTINEZFERNAND.JL, 2005, LNCS, V4022, P680; Muller H, 2004, INT J COMPUT VISION, V56, P65, DOI 10.1023/B:VISI.0000004832.02269.45; Muller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024; MULLER H, 2006, LNCS, V4022, P724; RAHMAN M, 2005, LNCS, V4022, P692; TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999; Tourassi GD, 1999, RADIOLOGY, V213, P317, DOI 10.1148/radiology.213.2.r99nv49317; XIONG W, 2005, LNCS, V4022, P632; Yamamoto S, 1996, THIRD IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV '96, PROCEEDINGS, P236, DOI 10.1109/ACV.1996.572061	25	38	38	0	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2007	74	1					51	58		10.1007/s11263-006-0007-y	http://dx.doi.org/10.1007/s11263-006-0007-y			8	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	165PX					2022-12-18	WOS:000246318800005
J	Antone, M; Teller, S				Antone, M; Teller, S			Scalable extrinsic calibration of omni-directional image networks	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						exterior orientation; egomotion; structure from motion; panoramas	STRUCTURE-FROM-MOTION; SPHERICAL REGRESSION; MAXIMUM-LIKELIHOOD; CAMERA; ERRORS; MODEL; UNCERTAINTY; ROTATIONS; RECOVERY; MATRIX	We describe a linear-time algorithm that recovers absolute camera orientations and positions, along with uncertainty estimates, for networks of terrestrial image nodes spanning hundreds of meters in outdoor urban scenes. The algorithm produces pose estimates globally consistent to roughly 0.1degrees (2 milliradians) and 5 centimeters on average, or about four pixels of epipolar alignment. We assume that adjacent nodes observe overlapping portions of the scene, and that at least two distinct vanishing points are observed by each node. The algorithm decouples registration into pure rotation and translation stages. The rotation stage aligns nodes to commonly observed scene line directions; the translation stage assigns node positions consistent with locally estimated motion directions, then registers the resulting network to absolute (Earth) coordinates. The paper's principal contributions include: extension of classic registration methods to large scale and dimensional extent; a consistent probabilistic framework for modeling projective uncertainty; and a new hybrid of Hough transform and expectation maximization algorithms. We assess the algorithm's performance on synthetic and real data, and draw several conclusions. First, by fusing thousands of observations the algorithm achieves accurate registration even in the face of significant lighting variations, low-level feature noise, and error in initial pose estimates. Second, the algorithm's robustness and accuracy increase with image field of view. Third, the algorithm surmounts the usual tradeoff between speed and accuracy; it is both faster and more accurate than manual bundle adjustment.	MIT, Comp Sci Lab, Comp Graph Grp, Cambridge, MA 02139 USA	Massachusetts Institute of Technology (MIT)	Antone, M (corresponding author), MIT, Comp Sci Lab, Comp Graph Grp, 545 Technol Sq, Cambridge, MA 02139 USA.	tone@graphics.lcs.mit.edu; teller@lcs.mit.edu						Adam A, 2000, PROC CVPR IEEE, P2, DOI 10.1109/CVPR.2000.855791; AMEMIYA Y, 1984, ANN STAT, V12, P497, DOI 10.1214/aos/1176346502; Antone M, 2001, PROC CVPR IEEE, P398; Antone ME, 2000, PROC CVPR IEEE, P282, DOI 10.1109/CVPR.2000.854809; AZARBAYEJANI A, 1995, IEEE T PATTERN ANAL, V17, P562, DOI 10.1109/34.387503; BARNARD ST, 1983, ARTIF INTELL, V21, P435, DOI 10.1016/S0004-3702(83)80021-6; BECKER S, 1995, P SOC PHOTO-OPT INS, V2410, P447, DOI 10.1117/12.205979; BERAN R, 1979, ANN STAT, V7, P1162, DOI 10.1214/aos/1176344838; BINGHAM C, 1974, ANN STAT, V2, P1201, DOI 10.1214/aos/1176342874; BOSSE M, 1999, GPS WORLD, P20; CANNY JF, 1986, PAMI, V8, P6, DOI DOI 10.1109/TPAMI.1986.4767851; CHANG T, 1989, ANN STAT, V17, P293, DOI 10.1214/aos/1176347017; CHAUDHURI S, 1991, P AS C SIGN SYST COM, P1195; Chui HL, 2000, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P190, DOI 10.1109/MMBIA.2000.852377; Chui HL, 2000, PROC CVPR IEEE, P44, DOI 10.1109/CVPR.2000.854733; Cipolla R, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P25, DOI 10.1109/MMCS.1999.779115; Collins R. T., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P400, DOI 10.1109/ICCV.1990.139560; Coorg S, 1998, PROC CVPR IEEE, P872, DOI 10.1109/CVPR.1998.698707; Csurka G, 1997, COMPUT VIS IMAGE UND, V68, P18, DOI 10.1006/cviu.1997.0531; Debevec P. E., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P11, DOI 10.1145/237170.237191; Dellaert F, 2000, PROC CVPR IEEE, P557, DOI 10.1109/CVPR.2000.854916; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Fermuller C, 1998, INT J COMPUT VISION, V28, P137, DOI 10.1023/A:1008063000586; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; FITZGIBBON AW, 1998, P EUR C COMP VIS, P311; FUA P, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P121, DOI 10.1109/CVPR.1994.323818; GLUCKMAN J, 1998, ICCV, P35; GOLUB GH, 1980, SIAM J NUMER ANAL, V17, P883, DOI 10.1137/0717073; Hartley Richard, 2000, MULTIPLE VIEW GEOMET, V7, P8; Horn B., 1986, ROBOT VISION, P1; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629; JUPP PE, 1979, ANN STAT, V7, P599, DOI 10.1214/aos/1176344681; KANATANI K, 1994, CVGIP-IMAG UNDERSTAN, V59, P286, DOI 10.1006/ciun.1994.1020; KANATANI K, 1993, INT J COMPUT VISION, V11, P267, DOI 10.1007/BF01469345; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; LEE MS, 1995, P IEEE INT S COMP VI, P73; LEUNG JCH, 1996, P ICIP, V2, P305; Luong QT, 1997, INT J COMPUT VISION, V22, P261, DOI 10.1023/A:1007982716991; LUTTON E, 1994, IEEE T PATTERN ANAL, V16, P430, DOI 10.1109/34.277598; Matei B, 2000, PROC CVPR IEEE, P18, DOI 10.1109/CVPR.2000.854727; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; Mundy J., 1992, GEOMETRIC INVARIANCE; NICEWARNER KE, 1994, IEEE INT CONF ROBOT, P1161, DOI 10.1109/ROBOT.1994.351204; POELMAN C, 1994, P 3 EUR C COMP VIS S, V2, P97; PRENTICE MJ, 1989, J ROY STAT SOC B MET, V51, P241; PRITCHETT P, 1998, P EUR WORKSH 3D STRU, P78; Rangarajan A., 1999, MED IMAGE ANAL, V3, P1; RIVEST LP, 1984, ANN STAT, V12, P1085, DOI 10.1214/aos/1176346724; Shigang L., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P499, DOI 10.1109/ICCV.1990.139581; Shufelt JA, 1999, IEEE T PATTERN ANAL, V21, P282, DOI 10.1109/34.754631; Shum HY, 1998, PROC CVPR IEEE, P427, DOI 10.1109/CVPR.1998.698641; SINKHORN R, 1964, ANN MATH STAT, V35, P876, DOI 10.1214/aoms/1177703591; STEFANSKI LA, 1985, BIOMETRIKA, V72, P583, DOI 10.1093/biomet/72.3.583; STEIN G, 1998, P DARPA IM UND WORKS, P521; Szeliski R., 1995, Proceedings International Symposium on Computer Vision (Cat. No.95TB100006), P241, DOI 10.1109/ISCV.1995.477008; Szeliski R., 1994, Journal of Visual Communication and Image Representation, V5, P10, DOI 10.1006/jvci.1994.1002; TAYLOR CJ, 1992, 1992 IEEE INTERNATIONAL CONF ON ROBOTICS AND AUTOMATION : PROCEEDINGS, VOLS 1-3, P1615, DOI 10.1109/ROBOT.1992.220021; TELLER S, 1997, P IM UND WORKSH; TELLER S, 2001, 825 MIT LCS; TELLER S, 2001, P CVPR; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; TUYTELAARS T, 1997, P INT C IM PROC ICIP, V2, P736; Watson G.S., 1983, STAT SPHERES; Zelnik-Manor L, 2000, IEEE T PATTERN ANAL, V22, P1105, DOI 10.1109/34.879791; Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561; [No title captured]	68	38	40	0	13	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP-OCT	2002	49	2-3					143	174		10.1023/A:1020141505696	http://dx.doi.org/10.1023/A:1020141505696			32	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	590TA					2022-12-18	WOS:000177837100004
J	Bouguet, JY; Perona, P				Bouguet, JY; Perona, P			3D photography using shadows in dual-space geometry	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						3D photography; 3D scanning; 3D modeling shape from shadows; dual-space geometry	CAMERA CALIBRATION; VANISHING POINTS; VISION	A simple and inexpensive approach for extracting the three-dimensional shape of objects is presented. It is based on 'weak structured lighting'. It requires very little hardware besides the camera: a light source (a desk-lamp or the sun), a stick and a checkerboard. The object, illuminated by the light source, is placed on a stage composed of a ground plane and a back plane; the camera faces the object. The user moves the stick in front of the light source, casting a moving shadow on the scene. The 3D shape of the object is extracted from the spatial and temporal location of the observed shadow. Experimental results are presented on five different scenes (indoor with a desk lamp and outdoor with the sun) demonstrating that the error in reconstructing the surface is less than 0.5% of the size of the object. A mathematical formalism is proposed that simplifies the notation and keep the algebra compact. A real-time implementation of the system is also presented.	CALTECH, Pasadena, CA 91125 USA; Univ Padua, I-35100 Padua, Italy	California Institute of Technology; University of Padua	Bouguet, JY (corresponding author), CALTECH, Pasadena, CA 91125 USA.	bouguetj@vision.caltech.edu; perona@vision.caltech.edu						[Anonymous], 1980, TENSOR ANAL MANIFOLD; BAJAJ C, 1995, SIGGRAPH 95, P109; Besl P.J., 1989, ADV MACHINE VISION, P1, DOI [10.1007/978-1-4612-4532-21, DOI 10.1007/978-1-4612-4532-21]; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Bougnoux S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P790, DOI 10.1109/ICCV.1998.710808; Bouguet J.-Y., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P514, DOI 10.1109/CVPR.1999.786986; Bouguet J.-Y., 1999, THESIS CALTECH; Bouguet JY, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P43, DOI 10.1109/ICCV.1998.710699; BOUGUET JY, 1997, 3D PHOTOGRAPHY DESK; BROWN DC, 1971, P S CLOS RANG PHOT M; BROWN DC, 1972, P 12 C INT SOC PHOT; BRUCE JW, 1992, LINES SURFACES DUALI; CANNY JF, 1986, PAMI, V8, P6, DOI DOI 10.1109/TPAMI.1986.4767851; CAPRILE B, 1990, INT J COMPUT VISION, V4, P127, DOI 10.1007/BF00127813; Cross G, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P25, DOI 10.1109/ICCV.1998.710697; CURLESS B, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P987, DOI 10.1109/ICCV.1995.466772; CURLESS B, 1996, SIGGRAPH96 COMP GRAP; Daniilidis K, 1996, PATTERN RECOGN LETT, V17, P1179, DOI 10.1016/0167-8655(96)00073-6; FAUGERAS O, 1994, P 5 INT C COMP VIS B, P851; Faugeras Olivier, 1993, 3 DIMENSIONAL VISION, P2; GAGNON H, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P581, DOI 10.1109/CVPR.1994.323796; Goshtasby AA, 1997, IEEE T MED IMAGING, V16, P664, DOI 10.1109/42.640757; GRUSS A, 1993, DARPA93, P977; HARTLEY RI, 1994, P 5 INT C COMP VIS B, P882; Heikkila J, 1997, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.1997.609468; JARVIS RA, 1983, IEEE T PATTERN ANAL, V5, P122, DOI 10.1109/TPAMI.1983.4767365; KANADE T, 1991, INT C ROB AUT, V39, P1322; KOCH R, 1998, P EUR C COMP VIS, P55; MEYERARENDT JR, 1968, APPL OPTICS, V7, P2081, DOI 10.1364/AO.7.002081; PAPOULIS A, 1991, PROBABILITY RANDOM V, P187; Pollefeys M, 1997, PROC CVPR IEEE, P407, DOI 10.1109/CVPR.1997.609357; POLLEFEYS M, 1908, P 6 INT C COMP VIS B, P90; Rioux M, 1997, P SOC PHOTO-OPT INS, V3023, P109, DOI 10.1117/12.269748; SAVARESE S, 1998, THESIS U STUDI NAPOL; SHASHUA A, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P920; STEIN GP, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P230, DOI 10.1109/ICCV.1995.466781; Sturm P., 1999, P IEEE C COMP VIS PA, P432, DOI DOI 10.1109/CVPR.1999.786974; Trobina M., 1995, BIWITR164 ETH ZENTR; TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109; Walsh J. W. T., 1965, PHOTOMETRY; Wang L L, 1990, MACH VISION APPL, V3, P129; WANG YF, 1991, IEEE T PATTERN ANAL, V13, P52, DOI 10.1109/34.67630; Ward GJ., 1994, SIGGRAPH 94 P 21 ANN, DOI DOI 10.1145/192161.192241	43	38	45	1	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	1999	35	2					129	149		10.1023/A:1008124523456	http://dx.doi.org/10.1023/A:1008124523456			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	265PF					2022-12-18	WOS:000084252000002
J	BRUCKSTEIN, AM; KATZIR, N; LINDENBAUM, M; PORAT, M				BRUCKSTEIN, AM; KATZIR, N; LINDENBAUM, M; PORAT, M			SIMILARITY-INVARIANT SIGNATURES FOR PARTIALLY OCCLUDED PLANAR SHAPES	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							OBJECTS	A methodology is described for associating local invariant signature functions to smooth planar curves in order to enable their translation, rotation, and scale-invariant recognition from arbitrarily clipped portions. The suggested framework incorporates previous approaches, based on locating inflections, curvature extrema, breakpoints, and other singular points on planar object boundaries, and provides a systematic way of deriving novel invariant signature functions based on curvature or cumulative turn angle of curves. These new signatures allow the specification of arbitrarily dense feature points on smooth curves, whose locations are invariant under similarity transformations. The results are useful for detecting and recognizing partially occluded planar objects, a key task in low-level robot vision.	TECHNION ISRAEL INST TECHNOL,DEPT COMP SCI,IL-32000 HAIFA,ISRAEL; TECHNION ISRAEL INST TECHNOL,DEPT ELECT ENGN,IL-32000 HAIFA,ISRAEL	Technion Israel Institute of Technology; Technion Israel Institute of Technology								ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; BARRETT EB, 1991, P DARPA ESPRIT WORKS; BRUCKSTEIN A, 1991, INVARIANT SIGNATURES; BRUCKSTEIN AM, 1991, MAY P WORKSH VIS FOR; BRUCKSTEIN AM, 1990, DIFFERENTIAL INVARIA; CYGANSKI D, 1987, 1ST P INT C COMP VIS, P496; FISCHLER MA, 1986, IEEE T PATTERN ANAL, V8, P100, DOI 10.1109/TPAMI.1986.4767756; GOTTSCHALK PG, 1989, INT J ROBOT RES, V8, P110, DOI 10.1177/027836498900800608; GOTTSCHALK PG, 1988, P SPIE INTELL ROBOTS, V7, P46; Guggenheimer H.W., 1963, DIFFERENTIAL GEOMETR; HONG J, 1988, NOV P ICPR ROM, P72; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; KALVIN A, 1986, INT J ROBOT RES, V5, P38, DOI 10.1177/027836498600500403; KATZIR N, 1990, 10TH P INT C PATT RE; Koenderink J., 1990, SOLID SHAPE; Lamdan Y., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P238, DOI 10.1109/CCV.1988.589995; RAY KS, 1989, PATTERN RECOGN LETT, V9, P351, DOI 10.1016/0167-8655(89)90064-0; TURNEY JL, 1985, IEEE T PATTERN ANAL, V7, P410, DOI 10.1109/TPAMI.1985.4767680; VANGOOL L, 1991, MAR DARPA ESPRIT WOR; VANGOOL L, 1991, JUN INT C PATT REC M; VAZ RF, 1990, PATTERN RECOGN LETT, V11, P479, DOI 10.1016/0167-8655(90)90082-D; WEISS I, 1991, MAR P DARPA ESPRIT W; WEISS I, 1988, CAR TR339 U MAR TECH; WEISS I, 1991, CAR TR537 TECH REPT; [No title captured]	26	38	38	0	1	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	APR	1992	7	3					271	285		10.1007/BF00126396	http://dx.doi.org/10.1007/BF00126396			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	HX401					2022-12-18	WOS:A1992HX40100005
J	Bergmann, P; Batzner, K; Fauser, M; Sattlegger, D; Steger, C				Bergmann, Paul; Batzner, Kilian; Fauser, Michael; Sattlegger, David; Steger, Carsten			The MVTec Anomaly Detection Dataset: A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Anomaly detection; Novelty detection; Datasets; Unsupervised learning; Defect segmentation		The detection of anomalous structures in natural image data is of utmost importance for numerous tasks in the field of computer vision. The development of methods for unsupervised anomaly detection requires data on which to train and evaluate new approaches and ideas. We introduce the MVTec anomaly detection dataset containing 5354 high-resolution color images of different object and texture categories. It contains normal, i.e., defect-free images intended for training and images with anomalies intended for testing. The anomalies manifest themselves in the form of over 70 different types of defects such as scratches, dents, contaminations, and various structural changes. In addition, we provide pixel-precise ground truth annotations for all anomalies. We conduct a thorough evaluation of current state-of-the-art unsupervised anomaly detection methods based on deep architectures such as convolutional autoencoders, generative adversarial networks, and feature descriptors using pretrained convolutional neural networks, as well as classical computer vision methods. We highlight the advantages and disadvantages of multiple performance metrics as well as threshold estimation techniques. This benchmark indicates that methods that leverage descriptors of pretrained networks outperform all other approaches and deep-learning-based generative models show considerable room for improvement.	[Bergmann, Paul; Batzner, Kilian; Fauser, Michael; Sattlegger, David; Steger, Carsten] MVTec Software GmbH, Arnulfstr 205, D-80634 Munich, Germany; [Bergmann, Paul] Tech Univ Munich, Dept Informat, Boltzmannstr 3, D-85748 Garching, Germany	Technical University of Munich	Bergmann, P (corresponding author), MVTec Software GmbH, Arnulfstr 205, D-80634 Munich, Germany.; Bergmann, P (corresponding author), Tech Univ Munich, Dept Informat, Boltzmannstr 3, D-85748 Garching, Germany.	paul.bergmann@mvtec.com; kilian.batzner@mvtec.com; fauser@mvtec.com; sattlegger@mvtec.com; steger@mvtec.com		Steger, Carsten/0000-0003-3426-1703; Batzner, Kilian/0000-0002-7312-7673; Bergmann, Paul/0000-0002-4458-3573; Sattlegger, David/0000-0002-8336-4672; Fauser, Michael/0000-0003-0162-3392				An J., 2015, SPEC LECT, V2, P1, DOI DOI 10.1007/BF00758335; Baur C, 2019, LECT NOTES COMPUT SC, V11383, P161, DOI 10.1007/978-3-030-11723-8_16; Bergmann P, 2020, PROC CVPR IEEE, P4182, DOI 10.1109/CVPR42600.2020.00424; Bergmann P, 2019, PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISAPP), VOL 5, P372, DOI 10.5220/0007364503720380; Bergmann P, 2019, PROC CVPR IEEE, P9584, DOI 10.1109/CVPR.2019.00982; Blum H, 2019, IEEE INT CONF COMP V, P2403, DOI 10.1109/ICCVW.2019.00294; Bottger T., 2016, Pattern Recognition and Image Analysis, V26, P88, DOI 10.1134/S1054661816010053; Bulatov Y., 2011, TECH REP; Burlina P, 2019, PROC CVPR IEEE, P11499, DOI 10.1109/CVPR.2019.01177; Carrera D, 2017, IEEE T IND INFORM, V13, P551, DOI 10.1109/TII.2016.2641472; Chalapathy R., 2018, ARXIV PREPRINT ARXIV; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Ehret T, 2019, J MATH IMAGING VIS, V61, P710, DOI 10.1007/s10851-019-00885-0; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; Hendrycks D., 2019, ICLR, P1; Hendrycks Dan, 2019, ARXIV191111132; Huang YB, 2018, IEEE INT CON AUTO SC, P612, DOI 10.1109/COASE.2018.8560423; Kingma D.P, P 3 INT C LEARNING R; Krizhevsky A, 2009, LEARNING MULTIPLE LA; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Lis K, 2019, IEEE I CONF COMP VIS, P2152, DOI 10.1109/ICCV.2019.00224; Marchal N, 2020, IEEE ROBOT AUTOM LET, V5, P1032, DOI 10.1109/LRA.2020.2967313; Nalisnick E., 2019, DO DEEP GENERATIVE M; Napoletano P, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18010209; Perera P, 2019, IEEE T IMAGE PROCESS, V28, P5450, DOI 10.1109/TIP.2019.2917862; Pimentel MAF, 2014, SIGNAL PROCESS, V99, P215, DOI 10.1016/j.sigpro.2013.12.026; Ruff L, 2018, PR MACH LEARN RES, V80; Sabokrou M, 2018, COMPUT VIS IMAGE UND, V172, P88, DOI 10.1016/j.cviu.2018.02.006; Saleh B, 2013, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2013.107; Schlegl T, 2019, MED IMAGE ANAL, V54, P30, DOI 10.1016/j.media.2019.01.010; Schlegl T, 2017, LECT NOTES COMPUT SC, V10265, P146, DOI 10.1007/978-3-319-59050-9_12; Song KC, 2013, APPL SURF SCI, V285, P858, DOI 10.1016/j.apsusc.2013.09.002; Steger C., 2001, Pattern Recognition. 23rd DAGM Symposium. Proceedings (Lecture Notes in Computer Science Vol.2191), P148; Steger C., 2002, INT ARCH PHOTOGR REM, V34, P345; Steger C., 2018, MACHINE VISION ALGOR; Tukey JW., 1977, EXPLORATORY DATA ANA; Wang H, 2019, 17TH IEEE INTERNATIONAL CONFERENCE ON IC DESIGN AND TECHNOLOGY (ICICDT 2019); Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wieler M., 2007, 29 ANN S GERMAN ASS; Yu F, 2020, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR42600.2020.00271	44	37	39	13	34	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	2021	129	4					1038	1059		10.1007/s11263-020-01400-4	http://dx.doi.org/10.1007/s11263-020-01400-4		JAN 2021	22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	RB3QK		hybrid			2022-12-18	WOS:000605541100006
J	Tokmakov, P; Schmid, C; Alahari, K				Tokmakov, Pavel; Schmid, Cordelia; Alahari, Karteek			Learning to Segment Moving Objects	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Motion segmentation; Video object segmentation; Visual memory		We study the problem of segmenting moving objects in unconstrained videos. Given a video, the task is to segment all the objects that exhibit independent motion in at least one frame. We formulate this as a learning problem and design our framework with three cues: (1)independent object motion between a pair of frames, which complements object recognition, (2)object appearance, which helps to correct errors in motion estimation, and (3)temporal consistency, which imposes additional constraints on the segmentation. The framework is a two-stream neural network with an explicit memory module. The two streams encode appearance and motion cues in a video sequence respectively, while the memory module captures the evolution of objects over time, exploiting the temporal consistency. The motion stream is a convolutional neural network trained on synthetic videos to segment independently moving objects in the optical flow field. The module to build a visual memory in video, i.e., a joint representation of all the video frames, is realized with a convolutional recurrent unit learned from a small number of training video sequences. For every pixel in a frame of a test video, our approach assigns an object or background label based on the learned spatio-temporal features as well as the visual memory specific to the video. We evaluate our method extensively on three benchmarks, DAVIS, Freiburg-Berkeley motion segmentation dataset and SegTrack. In addition, we provide an extensive ablation study to investigate both the choice of the training data and the influence of each component in the proposed framework.	[Tokmakov, Pavel] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA; [Schmid, Cordelia; Alahari, Karteek] Univ Grenoble Alpes, INRIA, CNRS, Grenoble INP,LJK, F-38000 Grenoble, France	Carnegie Mellon University; Centre National de la Recherche Scientifique (CNRS); Communaute Universite Grenoble Alpes; Institut National Polytechnique de Grenoble; UDICE-French Research Universities; Universite Grenoble Alpes (UGA); Inria	Tokmakov, P (corresponding author), Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.	ptokmako@andrew.cmu.edu; cordelia.schmid@inria.fr; karteek.alahari@inria.fr			ERC advanced Grant ALLEGRO; Google research award; Inria-CMU associate team GAYA; Facebook; NVIDIA	ERC advanced Grant ALLEGRO; Google research award(Google Incorporated); Inria-CMU associate team GAYA; Facebook(Facebook Inc); NVIDIA	This work was supported in part by the ERC advanced Grant ALLEGRO, a Google research award, the Inria-CMU associate team GAYA, a Facebook and an Intel gift. We gratefully acknowledge the support of NVIDIA with the donation of GPUs used for this work. We also thank Yeong Jun Koh for providing segmentation masks produced by their method (Koh et al. 2017) on the FBMS dataset, and the associate editor and the anonymous reviewers for their suggestions.	Adelson E. H, 2001, P SPIE; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Badrinarayanan V., 2010, CVPR; Ballas Nicolas, 2016, ICLR; Bideau Pia, 2016, ECCV; Brendel W., 2009, ICCV; Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143; Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21; Byeon W., 2015, CVPR; Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565; Chen J., 2016, NIPS; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Cho Kyunghyun, 2014, ARXIV, DOI 10.3115/v1/w14-4012; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Dosovitskiy A., 2015, ICCV; Everingham M., 2012, PASCAL VISUAL OBJECT; Faktor A., 2014, P BMVC, V2, P8; Fayyaz M., 2016, ARXIV160805971; Fragkiadaki K, 2012, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2012.6247883; Glorot X., 2010, PROC MACH LEARN RES, P249; Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042; Graves A., 2013, P 2013 IEEE INT C AC, P6645, DOI [10.1109/ICASSP.2013.6638947, DOI 10.1109/ICASSP.2013.6638947]; Graves A., 2013, WORKSH AUT SPEECH RE; Graves A, 2013, ARXIV13080850; Grundmann M, 2010, PROC CVPR IEEE, P2141, DOI 10.1109/CVPR.2010.5539893; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; Huguet F., 2007, ICCV; Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179; Jain SD, 2017, PROC CVPR IEEE, P2117, DOI 10.1109/CVPR.2017.228; Keuper Margret, 2015, ICCV; Khoreva A., 2015, CVPR; Khoreva A, 2017, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2017.181; Koh YJ, 2017, PROC CVPR IEEE, P7417, DOI 10.1109/CVPR.2017.784; Koltun V, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472; Lee YJ, 2011, IEEE I CONF COMP VIS, P1995, DOI 10.1109/ICCV.2011.6126471; Lezama J., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3369, DOI 10.1109/CVPR.2011.6044588; Li FX, 2013, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2013.273; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438; Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045; Narayana Manjunath, 2013, ICCV; Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242; Ochs Peter, 2012, CVPR; Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223; Pascanu R., 2013, P 30 INT C INT C MAC, P1310; Patraucean V., 2016, ICLR WORKSH TRACK; Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85; Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Revaud J, 2015, PROC CVPR IEEE, P1164, DOI 10.1109/CVPR.2015.7298720; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Srivastava N, 2015, PR MACH LEARN RES, V37, P843; Sundaram N, 2010, LECT NOTES COMPUT SC, V6311, P438, DOI 10.1007/978-3-642-15549-9_32; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Taylor B., 2015, CVPR; Tieleman T., 2012, RMSPROP COURSERA LEC; Tokmakov P, 2017, IEEE I CONF COMP VIS, P4491, DOI 10.1109/ICCV.2017.480; Tokmakov P, 2017, PROC CVPR IEEE, P531, DOI 10.1109/CVPR.2017.64; Torr PHS, 1998, PHILOS T R SOC A, V356, P1321, DOI 10.1098/rsta.1998.0224; Vedula S, 2005, IEEE T PATTERN ANAL, V27, P475, DOI 10.1109/TPAMI.2005.63; Vogel C, 2015, INT J COMPUT VISION, V115, P1, DOI 10.1007/s11263-015-0806-0; Wang W, 2015, PROC CVPR IEEE, P3395, DOI 10.1109/CVPR.2015.7298816; Wedel A, 2011, INT J COMPUT VISION, V95, P29, DOI 10.1007/s11263-010-0404-0; WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337; Xingjian S., 2015, ADV NEURAL INFORM PR, P802, DOI DOI 10.1007/978-3-319-21233-3_6; Xu CL, 2016, INT J COMPUT VISION, V119, P272, DOI 10.1007/s11263-016-0906-5; Zhang D, 2013, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2013.87	75	37	37	0	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAR	2019	127	3					282	301		10.1007/s11263-018-1122-2	http://dx.doi.org/10.1007/s11263-018-1122-2			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	HM5CT		Green Submitted			2022-12-18	WOS:000459493200004
J	Malinowski, M; Rohrbach, M; Fritz, M				Malinowski, Mateusz; Rohrbach, Marcus; Fritz, Mario			Ask Your Neurons: A Deep Learning Approach to Visual Question Answering	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	IEEE International Conference on Computer Vision (ICCV)	DEC 11-18, 2015	Santiago, CHILE	CPS, IEEE Comp Soc, Amazon, Microsoft, SENSETIME, Baidu, Intel, Facebook, Adobe, Panasonic, Google, OMRON, Blippar, iRobot, HISCENE, NVIDIA, Viscovery, AiCUre, M Tec, Inst Elect & Elect Engineers, Comp Vis Fdn		Computer vision; Scene understanding; Deep learning; Natural language processing; Visual turing test; Visual question answering	COEFFICIENT	We propose a Deep Learning approach to the visual question answering task, where machines answer to questions about real-world images. By combining latest advances in image representation and natural language processing, we propose Ask Your Neurons, a scalable, jointly trained, end-to-end formulation to this problem. In contrast to previous efforts, we are facing a multi-modal problem where the language output (answer) is conditioned on visual and natural language inputs (image and question). We evaluate our approaches on the DAQUAR as well as the VQA dataset where we also report various baselines, including an analysis how much information is contained in the language part only. To study human consensus, we propose two novel metrics and collect additional answers which extend the original DAQUAR dataset to DAQUAR-Consensus. Finally, we evaluate a rich set of design choices how to encode, combine and decode information in our proposed Deep Learning formulation.	[Malinowski, Mateusz; Fritz, Mario] Max Planck Inst Informat, Saarland Informat Campus, Saarbrucken, Germany; [Rohrbach, Marcus] UC Berkeley EECS, Berkeley, CA USA	Max Planck Society	Rohrbach, M (corresponding author), UC Berkeley EECS, Berkeley, CA USA.	mmalinow@mpi-inf.mpg.de; rohrbach@berkeley.edu; mfritz@mpi-inf.mpg.de	Malinowski, Mateusz/AAI-8855-2020	Malinowski, Mateusz/0000-0003-3909-0149	FITweltweit-Program of the German Academic Exchange Service (DAAD); Collaborative Research Center (CRC) from the German Research Foundation (DFG) [1223]	FITweltweit-Program of the German Academic Exchange Service (DAAD)(Deutscher Akademischer Austausch Dienst (DAAD)); Collaborative Research Center (CRC) from the German Research Foundation (DFG)	Marcus Rohrbach was supported by a fellowship within the FITweltweit-Program of the German Academic Exchange Service (DAAD). The project was in part supported by the Collaborative Research Center (CRC) 1223 from the German Research Foundation (DFG).	Akata Z, 2016, PROC CVPR IEEE, P59, DOI 10.1109/CVPR.2016.14; Andreas J, 2016, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2016.12; Andreas Jacob, 2016, ARXIV160101705, P1545, DOI [DOI 10.18653/V1/N16-1181, 10.18653/v1/N16-1181]; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Bastien F., 2012, DEEP LEARN UNS FEAT; Bengio Y., 2014, ARXIV14061078; Berant J., 2014, P ANN M ASS COMP LIN; Chen Kan, 2015, ARXIV151105960; Chollet F., 2015, KERAS; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; FLEISS JL, 1973, EDUC PSYCHOL MEAS, V33, P613, DOI 10.1177/001316447303300309; Gao H., 2015, ADV NEURAL INFORM PR, V28, P2296, DOI DOI 10.1145/2733373.2807418; Geman D, 2015, P NATL ACAD SCI USA, V112, P3618, DOI 10.1073/pnas.1422953112; He K., 2016, PROC IEEE C COMPUTER, P770, DOI DOI 10.1109/CVPR.2016.90; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Holmes B, 2016, NEURAL PLAST, V2016, DOI 10.1155/2016/5942980; Hu R., 2016, P EUR C COMP VIS ECC; Hu RH, 2016, PROC CVPR IEEE, P4555, DOI 10.1109/CVPR.2016.493; Ilievski I., 2016, ARXIV160401485; Iyyer M., 2014, P 2014 C EMPIRICAL M, P633, DOI DOI 10.3115/V1/D14-1070; Jia Y., 2014, P 22 ACM INT C MULT, P675; Jiang A, 2015, ARXIV151105676; Kafle K., 2016, P IEEE C COMP VIS PA; Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062; Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932; Kazemzadeh Sahar, 2014, P 2014 C EMP METH NA, P787, DOI DOI 10.3115/V1/D14-1086; Kim Jin-Hwa, 2016, ICLR; Kim Y., 2014, P 2014 C EMPIRICAL M, DOI [10.3115/v1/D14-1181, DOI 10.3115/V1/D14-1181]; Kingma D.P, P 3 INT C LEARNING R; Klein D, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P423, DOI 10.3115/1075096.1075150; Kong C., 2014, P IEEE C COMP VIS PA; Krishna Ranjay, 2016, ARXIV160207332; Krishnamurthy J, 2013, T ASSOC COMPUT LING, V1, P193, DOI DOI 10.1162/TACL_A_00220; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Kumar Ankit, 2015, ABS150607285 CORR; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Liang P, 2013, COMPUT LINGUIST, V39, P389, DOI 10.1162/COLI_a_00127; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu CZ, 2016, PROCEEDINGS OF THE ASME 5TH INTERNATIONAL CONFERENCE ON MICRO/NANOSCALE HEAT AND MASS TRANSFER, 2016, VOL 2; Malinowski M., 2014, ADV NEURAL INFORM PR, V27, P1682; Malinowski M., 2016, ARXIV161001076; Malinowski M., 2014, LEARNING SEMANTICS; Malinowski M., 2015, AAAIWORKSHOP TUR TES; Malinowski M, 2015, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2015.9; Malinowski Mateusz, 2014, ARXIV14115190; Manning CD, 1999, FDN STAT NATURAL LAN; Mao JH, 2016, PROC CVPR IEEE, P11, DOI 10.1109/CVPR.2016.9; Matuszek C., 2012, P ITN C MACH LEARN I; Nag Chowdhury S., 2016, ACM INT C MULT RETR; Nakashole N., 2013, P ANN M ASS COMP LIN; Noh H., 2015, ARXIV151105756; Pennington Jeffrey., 2014, P 2014 C EMP METH NA, P1532, DOI [10.3115/v1/D14-1162, DOI 10.3115/V1/D14-1162]; Plummer B., 2016, ARXIV150504870; Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303; Prakash A., 2016, HIGHWAY NETWORKS VIS; Regneri M., 2013, TACL, V1, P25, DOI DOI 10.1162/TACL_A_00207; Rohrbach A., 2015, P EUR C COMP VIS ECC; Rohrbach A., 2015, P IEEE C COMP VIS PA; Rohrbach M, 2016, P C EMP METH NAT LAN; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Saito K., 2016, ARXIV160606108; Shih KJ, 2016, PROC CVPR IEEE, P4613, DOI 10.1109/CVPR.2016.499; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Sutskever I., 2014, ARXIV14093215, DOI DOI 10.1007/S10107-014-0839-0; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Tapaswi M, 2016, PROC CVPR IEEE, P4631, DOI 10.1109/CVPR.2016.501; Toshev Alexander, 2014, ARXIV14114555; Trecvid, 2014, TRECV MED 14; Venugopalan S., 2015, P C N AM CHAPT ASS C; Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515; Wang LJ, 2016, PROC CVPR IEEE, P1373, DOI 10.1109/CVPR.2016.153; Weinberger KQ, 2014, ADV NEURAL INFORM PR, P1889; Weston J., 2014, ARXIV14103916; Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29; Wu Z., 1994, P ANN M ASS COMP LIN; Xiong CM, 2016, PR MACH LEARN RES, V48; Xu H., 2015, ARXIV151105234; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Yang Z., 2015, ARXIV151102274; Yu LC, 2016, LECT NOTES COMPUT SC, V9906, P69, DOI 10.1007/978-3-319-46475-6_5; Yu LC, 2015, IEEE I CONF COMP VIS, P2461, DOI 10.1109/ICCV.2015.283; Zaremba W, 2014, CORR; Zemel, 2015, ADV NEURAL INFORM PR, V1, P5; Zhou Bolei, 2015, ARXIV151202167; Zhu L., 2015, ARXIV151104670; Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540; Zitnick C. L., 2013, P IEEE INT C COMP VI	89	37	40	0	29	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	2017	125	1-3			SI		110	135		10.1007/s11263-017-1038-2	http://dx.doi.org/10.1007/s11263-017-1038-2			26	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	FL2TO		Green Submitted			2022-12-18	WOS:000414072800009
J	Pons-Moll, G; Taylor, J; Shotton, J; Hertzmann, A; Fitzgibbon, A				Pons-Moll, Gerard; Taylor, Jonathan; Shotton, Jamie; Hertzmann, Aaron; Fitzgibbon, Andrew			Metric Regression Forests for Correspondence Estimation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Human pose estimation; Model based pose estimation; Correspondence estimation; Depth images; Metric regression forests	TRACKING	We present a new method for inferring dense data to model correspondences, focusing on the application of human pose estimation from depth images. Recent work proposed the use of regression forests to quickly predict correspondences between depth pixels and points on a 3D human mesh model. That work, however, used a proxy forest training objective based on the classification of depth pixels to body parts. In contrast, we introduce Metric Space Information Gain (MSIG), a new decision forest training objective designed to directly minimize the entropy of distributions in a metric space. When applied to a model surface, viewed as a metric space defined by geodesic distances, MSIG aims to minimize image-to-model correspondence uncertainty. A na < ve implementation of MSIG would scale quadratically with the number of training examples. As this is intractable for large datasets, we propose a method to compute MSIG in linear time. Our method is a principled generalization of the proxy classification objective, and does not require an extrinsic isometric embedding of the model surface in Euclidean space. Our experiments demonstrate that this leads to correspondences that are considerably more accurate than state of the art, using far fewer training images.	[Pons-Moll, Gerard] Max Planck Intelligent Syst, Tubingen, Germany; [Taylor, Jonathan; Shotton, Jamie; Fitzgibbon, Andrew] Microsoft Res, Cambridge, England; [Hertzmann, Aaron] Adobe Res, San Francisco, CA USA	Microsoft; Adobe Systems Inc.	Pons-Moll, G (corresponding author), Max Planck Intelligent Syst, Tubingen, Germany.	gerard.pons.moll@tue.mpg.de; jota@microsoft.com; jamiesho@microsoft.com; hertzman@adobe.com; awf@microsoft.com	Pons-Moll, Gerard/AAF-8845-2019	Pons-Moll, Gerard/0000-0001-5115-7794; Hertzmann, Aaron/0000-0001-9667-0292				Baak A, 2011, IEEE I CONF COMP VIS, P1092, DOI 10.1109/ICCV.2011.6126356; Balan Alexandru O., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383340; BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148; Bo LF, 2010, INT J COMPUT VISION, V87, P28, DOI 10.1007/s11263-008-0204-y; Bregler C, 2004, INT J COMPUT VISION, V56, P179, DOI 10.1023/B:VISI.0000011203.00237.9b; Breiman L., 1999, TR567 UC BERK; Brubaker MA, 2010, INT J COMPUT VISION, V87, P140, DOI 10.1007/s11263-009-0274-5; BUNTINE W, 1992, MACH LEARN, V8, P75, DOI 10.1023/A:1022686419106; Criminisi A., 2013, DECISION FORESTS COM; Deutscher J, 2005, INT J COMPUT VISION, V61, P185, DOI 10.1023/B:VISI.0000043757.18370.9c; Dijkstra EW, 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]; Gall J, 2011, IEEE T PATTERN ANAL, V33, P2188, DOI 10.1109/TPAMI.2011.70; Gall J, 2010, INT J COMPUT VISION, V87, P75, DOI 10.1007/s11263-008-0173-1; Ganapathi V., 2010, CVPR; Ganapathi V, 2012, LECT NOTES COMPUT SC, V7577, P738, DOI 10.1007/978-3-642-33783-3_53; Girshick R, 2011, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2011.6126270; KABSCH W, 1976, ACTA CRYSTALLOGR A, V32, P922, DOI 10.1107/S0567739476001873; Lee CS, 2010, INT J COMPUT VISION, V87, P118, DOI 10.1007/s11263-009-0266-5; LIU WZ, 1994, MACH LEARN, V15, P25, DOI 10.1007/BF01000407; Memisevic R, 2012, IEEE T PATTERN ANAL, V34, P778, DOI 10.1109/TPAMI.2011.154; Nowozin S., 2012, ICML, P297; PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472; Pons-Moll G., 2011, VISUAL ANAL HUMANS, P139, DOI [10.1007/978-0-85729-997-0_9, DOI 10.1007/978-0-85729-997-0_9]; Pons-Moll G., 2011, EFFICIENT ROBUST SHA; Pons-Moll G, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.4; Pons-Moll G, 2011, IEEE I CONF COMP VIS, P1243, DOI 10.1109/ICCV.2011.6126375; Shotton J, 2013, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2013.377; Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316; Silverman B. W., 1986, DENSITY ESTIMATION S, V26; Sminchisescu C., 2011, VISUAL ANAL HUMANS, P225; Stoll C, 2011, IEEE I CONF COMP VIS, P951, DOI 10.1109/ICCV.2011.6126338; Taylor J, 2012, PROC CVPR IEEE, P103, DOI 10.1109/CVPR.2012.6247664; Urtasun R, 2008, PROC CVPR IEEE, P149	35	37	37	0	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2015	113	3			SI		163	175		10.1007/s11263-015-0818-9	http://dx.doi.org/10.1007/s11263-015-0818-9			13	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	CK3BZ					2022-12-18	WOS:000356091900002
J	Zheng, B; Zhao, YB; Yu, J; Ikeuchi, K; Zhu, SC				Zheng, Bo; Zhao, Yibiao; Yu, Joey; Ikeuchi, Katsushi; Zhu, Song-Chun			Scene Understanding by Reasoning Stability and Safety	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							SEGMENTATION	This paper presents a new perspective for 3D scene understanding by reasoning object stability and safety using intuitive mechanics. Our approach utilizes a simple observation that, by human design, objects in static scenes should be stable in the gravity field and be safe with respect to various physical disturbances such as human activities. This assumption is applicable to all scene categories and poses useful constraints for the plausible interpretations (parses) in scene understanding. Given a 3D point cloud captured for a static scene by depth cameras, our method consists of three steps: (i) recovering solid 3D volumetric primitives from voxels; (ii) reasoning stability by grouping the unstable primitives to physically stable objects by optimizing the stability and the scene prior; and (iii) reasoning safety by evaluating the physical risks for objects under physical disturbances, such as human activity, wind or earthquakes. We adopt a novel intuitive physics model and represent the energy landscape of each primitive and object in the scene by a disconnectivity graph (DG). We construct a contact graph with nodes being 3D volumetric primitives and edges representing the supporting relations. Then we adopt a Swendson-Wang Cuts algorithm to partition the contact graph into groups, each of which is a stable object. In order to detect unsafe objects in a static scene, our method further infers hidden and situated causes (disturbances) in the scene, and then introduces intuitive physical mechanics to predict possible effects (e.g., falls) as consequences of the disturbances. In experiments, we demonstrate that the algorithm achieves a substantially better performance for (i) object segmentation, (ii) 3D volumetric recovery, and (iii) scene understanding with respect to other state-of-the-art methods. We also compare the safety prediction from the intuitive mechanics model with human judgement.	[Zheng, Bo; Ikeuchi, Katsushi] Univ Tokyo, Tokyo, Japan; [Zhao, Yibiao; Yu, Joey; Zhu, Song-Chun] Univ Calif Los Angeles, Los Angeles, CA USA	University of Tokyo; University of California System; University of California Los Angeles	Zheng, B (corresponding author), Univ Tokyo, Tokyo, Japan.	zheng@cvl.iis.u-tokyo.ac.jp; ybzhao@ucla.edu; chengchengyu@ucla.edu; ki@cvl.iis.u-tokyo.ac.jp; sczhu@stat.ucla.edu			MURI ONR [N00014-10-1-0933]; DARPA MSEE, USA [FA 8650-11-1-7149]; Next-generation Energies for Tohoku Recovery (NET); SCOPE Program of Ministry of Internal Affairs and Communications, Japan; Microsoft Japan	MURI ONR(MURIOffice of Naval Research); DARPA MSEE, USA; Next-generation Energies for Tohoku Recovery (NET); SCOPE Program of Ministry of Internal Affairs and Communications, Japan; Microsoft Japan(Microsoft)	This work is supported by (1) MURI ONR N00014-10-1-0933 and DARPA MSEE grant FA 8650-11-1-7149, USA, (2) Next-generation Energies for Tohoku Recovery (NET) and SCOPE Program of Ministry of Internal Affairs and Communications, Japan, (3) and the 10-th core Project Grant of Microsoft Japan.	Anand A., 2012, IJRR; [Anonymous], 2012, ACM T GRAPHIC, DOI DOI 10.1145/2366145.2366155; Attene M, 2006, VISUAL COMPUT, V22, P181, DOI 10.1007/s00371-006-0375-x; Barbu A, 2005, IEEE T PATTERN ANAL, V27, P1239, DOI 10.1109/TPAMI.2005.161; BIEDERMAN I, 1982, COGNITIVE PSYCHOL, V14, P143, DOI 10.1016/0010-0285(82)90007-X; Blane MM, 2000, IEEE T PATTERN ANAL, V22, P298, DOI 10.1109/34.841760; Chen XB, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531379; DARPA, 2014, ROB RESC PEOPL; Delaitre V, 2012, LECT NOTES COMPUT SC, V7577, P284, DOI 10.1007/978-3-642-33783-3_21; Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77; Fleming RW, 2010, PERCEPTION, V39, P109; Fouhey DF, 2012, LECT NOTES COMPUT SC, V7576, P732, DOI 10.1007/978-3-642-33715-4_53; Furukawa Y, 2009, PROC CVPR IEEE, P1422, DOI 10.1109/CVPRW.2009.5206867; Grabner H, 2011, PROC CVPR IEEE, P1529, DOI 10.1109/CVPR.2011.5995327; Guo R., 2013, ICCV; Gupta A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1961, DOI 10.1109/CVPR.2011.5995448; Gupta A, 2010, LECT NOTES COMPUT SC, V6311, P171, DOI 10.1007/978-3-642-15549-9_13; Hamrick J., 2011, C COG SC, P1545; Hedau V, 2010, ECCV; Janoch A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1168, DOI 10.1109/ICCVW.2011.6130382; Jia ZY, 2013, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2013.8; Jiang Y., 2013, ROBOTICS SCI SYSTEMS; Jiang Y, 2013, PROC CVPR IEEE, P2993, DOI 10.1109/CVPR.2013.385; Karpathy A, 2013, IEEE INT CONF ROBOT, P2088, DOI 10.1109/ICRA.2013.6630857; Koppula H. S., 2011, ADV NEURAL INFORM PR, P244; Kriegman DJ, 1997, INT J ROBOT RES, V16, P448, DOI 10.1177/027836499701600402; Lee DC, 2009, PROC CVPR IEEE, P2136, DOI 10.1109/CVPRW.2009.5206872; Lee David C, 2010, ESTIMATING SPATIAL L, P3; MCCLOSKEY M, 1983, SCI AM, V248, P122, DOI 10.1038/scientificamerican0483-122; Nan LL, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366156; Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378; Petti S, 2005, 2005 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P3726, DOI 10.1109/IROS.2005.1545549; Phillips M., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P5628, DOI 10.1109/ICRA.2011.5980306; Poppinga J, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3378, DOI 10.1109/IROS.2008.4650729; Sagawa R, 2005, IEEE T PATTERN ANAL, V27, P392, DOI 10.1109/TPAMI.2005.46; Savva M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661230; Shao TJ, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661288; SHI QY, 1983, IEEE T PATTERN ANAL, V5, P472, DOI 10.1109/TPAMI.1983.4767426; Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54; Tu ZW, 2005, INT J COMPUT VISION, V63, P113, DOI 10.1007/s11263-005-6642-x; WALES DJ, 2004, ENERGY LANDSCAPES AP; Wu C, 2014, ROBOTICS SCI SYSTEMS; Zhao Y., 2011, NIPS; Zheng B., 2013, CVPR; Zheng B, 2014, IEEE INT CONF ROBOT, P3417, DOI 10.1109/ICRA.2014.6907351; Zheng B, 2010, IEEE T PATTERN ANAL, V32, P561, DOI 10.1109/TPAMI.2009.189	46	37	38	1	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	2015	112	2			SI		221	238		10.1007/s11263-014-0795-4	http://dx.doi.org/10.1007/s11263-014-0795-4			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	CE0TD					2022-12-18	WOS:000351518500007
J	Tian, HD; Li, WQ; Wang, L; Ogunbona, P				Tian, Hongda; Li, Wanqing; Wang, Lei; Ogunbona, Philip			Smoke Detection in Video: An Image Separation Approach	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Smoke detection; Smoke texture; Image separation; Sparse representation	TRANSPARENT LAYERS; COMPUTER VISION; REFLECTIONS; REPRESENTATION; DECOMPOSITION; SEGMENTATION; MINIMIZATION; ALGORITHM; MOTION; MODEL	Existing video-based smoke detection methods often rely on the visual features extracted directly from the original frames. In the case of light smoke, the background is still visible and it deteriorates the quality of the features. This paper presents an approach to separating the smoke component from the background such that visual features can be extracted from the smoke component for reliable smoke detection. Specifically, an image is assumed to be a linear blending of a smoke component and a background image. Given a video frame and its background, the estimation of the blending parameter and the actual smoke component can be formulated as an optimization problem. Three methods based on different models for the smoke component are proposed to solve the optimization problem. Experimental results on synthesized and real video data have shown that the proposed approach can effectively separate the smoke component and the smoke detection performance is significantly improved by using the visual features extracted from the smoke component.	[Tian, Hongda; Li, Wanqing; Wang, Lei; Ogunbona, Philip] Univ Wollongong, Sch Comp Sci & Software Engn, Wollongong, NSW 2522, Australia	University of Wollongong	Li, WQ (corresponding author), Univ Wollongong, Sch Comp Sci & Software Engn, Northfield Ave, Wollongong, NSW 2522, Australia.	ht615@uow.edu.au; wanqing@uow.edu.au; leiw@uow.edu.au; philipo@uow.edu.au	Wang, Lei/D-9079-2013; Wang, Lei/AAL-9684-2020; Li, Wanqing/ABG-2620-2020; Tian, Hongda/AAD-4744-2020	Wang, Lei/0000-0002-0961-0441; Tian, Hongda/0000-0002-2889-6158; Li, Wanqing/0000-0002-4427-2687; Ogunbona, Philip O./0000-0003-4119-2873	Beijing Polymer Sensing Technology Co. Ltd.	Beijing Polymer Sensing Technology Co. Ltd.	This work was partly supported by Beijing Polymer Sensing Technology Co. Ltd.	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Almeida LB, 2005, J MACH LEARN RES, V6, P1199; Bai X, 2009, INT J COMPUT VISION, V82, P113, DOI 10.1007/s11263-008-0191-z; BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129; Calderara S, 2011, MACH VISION APPL, V22, P705, DOI 10.1007/s00138-010-0272-1; Chen TH, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P427; Fadili MJ, 2010, P IEEE, V98, P983, DOI 10.1109/JPROC.2009.2024776; Farid H., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P262, DOI 10.1109/CVPR.1999.786949; Funaro M, 2003, NEURAL NETWORKS, V16, P469, DOI 10.1016/S0893-6080(03)00017-0; Gai K, 2008, PROC CVPR IEEE, P15; Gonzalez Rafael C., 2007, DIGITAL IMAGE PROCES; Guidara R, 2009, IEEE T IMAGE PROCESS, V18, P2435, DOI 10.1109/TIP.2009.2027367; Guo LF, 2006, PATTERN RECOGN, V39, P1066, DOI 10.1016/j.patcog.2005.09.006; He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168; Kolesov I, 2010, IEEE IMAGE PROC, P761, DOI 10.1109/ICIP.2010.5652119; Kong N, 2011, IEEE T IMAGE PROCESS, V20, P3393, DOI 10.1109/TIP.2011.2155080; Lee H., 2007, P ADV NEUR INF PROC, V19; Levin A, 2004, PROC CVPR IEEE, P306; Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177; Levin A, 2007, IEEE T PATTERN ANAL, V29, P1647, DOI 10.1109/TPAMI.2007.1106; Long CJ, 2010, LECT NOTES ARTIF INT, V6319, P389, DOI 10.1007/978-3-642-16530-6_46; Maruta H, 2010, IEEE IMAGE PROC, P4653, DOI 10.1109/ICIP.2010.5650254; Meyer FG, 2002, IEEE T IMAGE PROCESS, V11, P1072, DOI 10.1109/TIP.2002.802527; Minh HQ, 2011, IEEE I CONF COMP VIS, P866, DOI 10.1109/ICCV.2011.6126327; Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723; Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623; Osher S, 2003, MULTISCALE MODEL SIM, V1, P349, DOI 10.1137/S1540345902416247; Sarel B, 2005, IEEE I CONF COMP VIS, P26; Schechner YY, 2000, INT J COMPUT VISION, V39, P25, DOI 10.1023/A:1008166017466; Starck JL, 2005, IEEE T IMAGE PROCESS, V14, P1570, DOI 10.1109/TIP.2005.852206; Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677; Szeliski R, 2000, PROC CVPR IEEE, P246, DOI 10.1109/CVPR.2000.855826; Tian H., 2011, P IEEE INT WORKSH MU, P1, DOI DOI 10.1109/MMSP.2011.6093844; Tonazzini A, 2006, IEEE T IMAGE PROCESS, V15, P473, DOI 10.1109/TIP.2005.860323; TOREYIN BU, 2005, P EUR SIGN PROC C; Tung TX, 2011, FIRE SAFETY J, V46, P276, DOI 10.1016/j.firesaf.2011.03.003; TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71; Wang J, 2005, IEEE I CONF COMP VIS, P936; Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470; Yu CY, 2010, FIRE TECHNOL, V46, P651, DOI 10.1007/s10694-009-0110-z; Yuan F, 2008, PATTERN RECOGN LETT, V29, P925, DOI 10.1016/j.patrec.2008.01.013; Zhang C, 2011, PROC CVPR IEEE, P185, DOI 10.1109/CVPR.2011.5995704	42	37	43	0	46	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2014	106	2					192	209		10.1007/s11263-013-0656-6	http://dx.doi.org/10.1007/s11263-013-0656-6			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	290UR		Green Submitted			2022-12-18	WOS:000329784300005
J	Dickscheid, T; Schindler, F; Forstner, W				Dickscheid, Timo; Schindler, Falko; Foerstner, Wolfgang			Coding Images with Local Features	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Local features; Complementarity; Information theory; Coding; Keypoint detectors; Local entropy	SCALE; DETECTORS	We develop a qualitative measure for the completeness and complementarity of sets of local features in terms of covering relevant image information. The idea is to interpret feature detection and description as image coding, and relate it to classical coding schemes like JPEG. Given an image, we derive a feature density from a set of local features, and measure its distance to an entropy density computed from the power spectrum of local image patches over scale. Our measure is meant to be complementary to existing ones: After task usefulness of a set of detectors has been determined regarding robustness and sparseness of the features, the scheme can be used for comparing their completeness and assessing effects of combining multiple detectors. The approach has several advantages over a simple comparison of image coverage: It favors response on structured image parts, penalizes features in purely homogeneous areas, and accounts for features appearing at the same location on different scales. Combinations of complementary features tend to converge towards the entropy, while an increased amount of random features does not. We analyse the complementarity of popular feature detectors over different image categories and investigate the completeness of combinations. The derived entropy distribution leads to a new scale and rotation invariant window detector, which uses a fractal image model to take pixel correlations into account. The results of our empirical investigations reflect the theoretical concepts of the detectors.	[Dickscheid, Timo; Schindler, Falko; Foerstner, Wolfgang] Univ Bonn, Dept Photogrammetry, Inst Geodesy & Geoinformat, D-5300 Bonn, Germany	University of Bonn	Dickscheid, T (corresponding author), Univ Bonn, Dept Photogrammetry, Inst Geodesy & Geoinformat, D-5300 Bonn, Germany.	dickscheid@uni-bonn.de; falko.schindler@uni-bonn.de; wf@ipb.uni-bonn.de	Dickscheid, Timo/AAF-9819-2022; Dickscheid, Timo/AFK-2544-2022	Dickscheid, Timo/0000-0002-9051-3701; Dickscheid, Timo/0000-0002-9051-3701				Bay H, 2005, PROC CVPR IEEE, P329; Bercher JF, 2000, IEEE T SIGNAL PROCES, V48, P1687, DOI 10.1109/78.845926; Berger T., 1971, RATE DISTORTION THEO; BIGUN J, 1990, COMPUT VISION GRAPH, V51, P166, DOI 10.1016/0734-189X(90)90029-U; Bishop C. M., 2006, INFORM SCI STAT PATT; Cayton L., 2006, P 23 INT C MACH LEAR, P169; Corso JJ, 2009, COMPUT VIS IMAGE UND, V113, P446, DOI 10.1016/j.cviu.2008.11.009; DAVIS GM, 1998, APPL COMPUTATIONAL C, V1, P205; DAVISSON LD, 1972, PR INST ELECTR ELECT, V60, P800, DOI 10.1109/PROC.1972.8779; Dickscheid T, 2009, LECT NOTES COMPUT SC, V5815, P305, DOI 10.1007/978-3-642-04667-4_31; Fei-Fei L, 2005, PROC CVPR IEEE, P524; Forstner<spacing Wolfgang, 1987, ISPRS INT C FAST PRO, P2; Forstner W., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P383, DOI 10.1007/BFb0028370; FORSTNER W., 2009, P IEEE INT C COMP VI; FORSTNER W, 1998, LECT NOTES EARTH SCI, P165; Haja A., 2008, P IEEE C COMP VIS PA; Harris C, 1988, P ALVEY VISION C AVC, P1, DOI DOI 10.5244/C.2.23; Heath M, 1996, PROC CVPR IEEE, P143, DOI 10.1109/CVPR.1996.517066; Kadir T, 2004, LECT NOTES COMPUT SC, V3021, P228; Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855; KOVESI PD, 2009, MATLAB OCTAVE FUNCTI; Lazebnik S., 2006, 2006 IEEE COMPUTER S, V2, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/cvpr.2006.68]; LIANG P, 2010, OXFORD HDB APPL BAYE; Lillholm M, 2003, INT J COMPUT VISION, V52, P73, DOI 10.1023/A:1022995822531; Lindeberg T, 1998, INT J COMPUT VISION, V30, P117, DOI 10.1023/A:1008097225773; Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935; Liu C, 2008, IEEE T PATTERN ANAL, V30, P299, DOI [10.1109/TPAMI.2007.1176, 10.1109/TPAMI.20071176]; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Marr D., 1982, VISION COMPUTATIONAL; Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006; MCCLURE DE, 1980, COMPUT VISION GRAPH, V12, P309, DOI 10.1016/0146-664X(80)90017-9; MCGILLEM CD, 1976, IEEE T GEOSCI REMOTE, V14, P44, DOI 10.1109/TGE.1976.294464; MELTZER J, 2008, P IEEE C COMP VIS PA; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; Mikolajczyk K., 2003, BRIT MACH VIS C BMVC, V2, P779; Moreels P, 2007, INT J COMPUT VISION, V73, P263, DOI 10.1007/s11263-006-9967-1; MUMFORD D, 2005, NEW DIRECTIONS STAT; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; PERDOCH M, 2007, P IEEE INT C COMP VI, P8; Puzicha J., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P602, DOI 10.1109/CVPR.1999.784981; Rosenfeld A., 1982, DIGITAL PICTURE PROC; Shannon C. E., 1948, BELL SYSTEM TECHNICA; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Smith J.O., 2007, MATH DISCRETE FOURIE; Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8; Tuytelaars T., 2008, LOCAL INVARIANT FEAT; Zeisl B., 2009, P BRIT MACH VIS C LO	48	37	39	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2011	94	2					154	174		10.1007/s11263-010-0340-z	http://dx.doi.org/10.1007/s11263-010-0340-z			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	775VB					2022-12-18	WOS:000291490400001
J	Drareni, J; Roy, S; Sturm, P				Drareni, Jamil; Roy, Sebastien; Sturm, Peter			Plane-Based Calibration for Linear Cameras	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Pushbroom camera; Planar calibration; Linear sensor		Linear or ID cameras are used in several areas such as industrial inspection and satellite imagery. Since ID cameras consist of a linear sensor, a motion (usually perpendicular to the sensor orientation) is performed in order to acquire a full image. In this paper, we present a novel linear method to estimate the intrinsic and extrinsic parameters of a ID camera using a planar object. As opposed to traditional calibration scheme based on 3D-2D correspondences of landmarks, our method uses homographies induced by the images of a planar object. The proposed algorithm is linear, simple and produces good results as shown by our experiments.	[Drareni, Jamil; Roy, Sebastien] Univ Montreal, Dept Informat & Rech Operat, Montreal, PQ H3C 3J7, Canada; [Sturm, Peter] INRIA Rhone Alpes, F-38330 Montbonnot St Martin, France	Universite de Montreal	Drareni, J (corresponding author), Univ Montreal, Dept Informat & Rech Operat, CP 6128 Succ Ctr Ville, Montreal, PQ H3C 3J7, Canada.	drarenij@iro.umontreal.ca; roys@iro.umontreal.ca; Peter.Sturm@inrialpes.fr						*BASL, 2009, BASL VIS TECHN; Faugeras O. D., 1987, Proceedings of the International Workshop on Industrial Applications of Machine Vision and Machine Intelligence. Seiken Symposium (Cat. no. 87TH0166-9), P240; Gupta R, 1997, IEEE T PATTERN ANAL, V19, P963, DOI 10.1109/34.615446; GUPTA R, 1995, P 2 AS C COMP VIS, V3; GURDJOS P, 2001, BRIT MACH VIS C SESS; Hartley R., 2000, MULTIPLE VIEW GEOMET, V2, DOI [10.2277/0511188951, DOI 10.2277/0511188951]; Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246; Hirschmuller H, 2005, LECT NOTES COMPUT SC, V3663, P58; ISHIGURO H, 1992, IEEE T PATTERN ANAL, V14, P257, DOI 10.1109/34.121792; Seitz SM, 2002, INT J COMPUT VISION, V48, P21, DOI 10.1023/A:1014851111084; SHUM HY, 1999, ICCV 99, P14; Sturm P., 1999, P IEEE C COMP VIS PA, P432, DOI DOI 10.1109/CVPR.1999.786974; Triggs B., 2000, BUNDLE ADJUSTMENT MO, V1883; Tsai R.Y., 1986, P IEEE C COMP VIS PA, P364; VIALA CR, 2005, INT C IM PROC, V2, P1142; Wang JH, 2006, LECT NOTES COMPUT SC, V4179, P576; Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718	17	37	44	3	28	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2011	91	2					146	156		10.1007/s11263-010-0349-3	http://dx.doi.org/10.1007/s11263-010-0349-3			11	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	708KJ		Green Submitted			2022-12-18	WOS:000286360400002
J	Juan, O; Keriven, R; Postelnicu, G				Juan, Olivier; Keriven, Renaud; Postelnicu, Gheorghe			Stochastic motion and the level set method in computer vision: Stochastic active contours	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	2nd IEEE Workshop on Variational, Geometric and Level Set Methods held in Conjunction with the IEEE International Conference on Computer Vision	OCT, 2003	Nice, FRANCE	IEEE, French Natl Inst Res Comp Sci & Control, Siemens Corp Res, Imaging & Visualizat Dept		level sets; stochastic partial differential equations; shape optimization; stochastic optimization; segmentation; active contours	PARTIAL-DIFFERENTIAL-EQUATIONS	Based on recent work on Stochastic Partial Differential Equations (SPDEs), this paper presents a simple and well-founded method to implement the stochastic evolution of a curve. First. we explain why great care should be taken when considering such an evolution in a Level Set framework. To guarantee the well-posedness of the evolution and to make it independent of the implicit representation of the initial curve, a Stratonovich differential has to be introduced. To implement this differential. a standard Ito plus drift approximation is proposed to turn an implicit scheme into an explicit one. Subsequently, we consider shape optimization techniques, which are a common framework to address various applications in Computer Vision, like segmentation, tracking, stereo vision etc. The objective of our approach is to improve these methods through the introduction of stochastic motion principles. The extension we propose can deal with local minima and with complex cases where the gradient of the objective function with respect to the shape is impossible to derive exactly. Finally. as an application. we focus on image segmentation methods, leading to what we call Stochastic Active Contours.	ENPC, CERTIS, ENS, Odyssee Lab,INRIA Sophia, F-77455 Marne La Vallee, France	Ecole des Ponts ParisTech	Keriven, R (corresponding author), ENPC, CERTIS, ENS, Odyssee Lab,INRIA Sophia, F-77455 Marne La Vallee, France.	keriven@certis.enpc.fr						BALLERINI L, 1999, LECT NOTES COMPUTER, V1596, P59; BENAROUS G, 2002, STOCHASTIC APPROXIMA; Bezdek J.C., 2013, PATTERN RECOGN, DOI 10.1007/978-1-4757-0450-1; Buckdahn R, 2001, STOCH PROC APPL, V93, P181, DOI 10.1016/S0304-4149(00)00093-4; CANCES E, 2004, THEORET CHEM ACC; Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043; de Gruijter J. J., 1988, Classification and Related Methods of Data Analysis. Proceedings of the First Conference of the International Federation of Classification Societies (IFCS), P97; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; Faugeras O, 1998, IEEE T IMAGE PROCESS, V7, P336, DOI 10.1109/83.661183; GART T, 1988, INTRO STOCHASTIC DIF; Jiang GS, 2000, SIAM J SCI COMPUT, V21, P2126, DOI 10.1137/S106482759732455X; JUAN O, 2004, 0401 CERTIS; Karatzas I., 1987, BROWNIAN MOTION STOC; KATSOULAKIS M, 2001, J INTERFACES FREE BO, V3, P265; KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671; Kunita H., 1990, STOCHASTIC FLOWS STO; LIONS P, 1999, UNPUB SEM X EDP; Lions PL, 1998, CR ACAD SCI I-MATH, V327, P735, DOI 10.1016/S0764-4442(98)80161-4; Lions PL, 1998, CR ACAD SCI I-MATH, V326, P1085, DOI 10.1016/S0764-4442(98)80067-0; Lions PL, 2000, CR ACAD SCI I-MATH, V331, P617, DOI 10.1016/S0764-4442(00)00583-8; Lions PL, 2000, CR ACAD SCI I-MATH, V331, P783, DOI 10.1016/S0764-4442(00)01597-4; MacQueen J., 1967, 5 BERK S MATH STAT P, V1, P281; MCLACHALN G, 1997, EM ALGORITHM EXTENSI; Mclachlan G., 2000, WILEY SER PROB STAT; METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068; Rissanen Jorma, 1989, STOCHASTIC COMPLEXIT; Rousson M, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P56, DOI 10.1109/MOTION.2002.1182214; Souganidis PE, 2004, ANN I H POINCARE-AN, V21, P1, DOI 10.1016/j.anihpc.2002.11.001; STORVIK G, 1994, IEEE T PATTERN ANAL, V16, P976, DOI 10.1109/34.329011; Ueda N, 2000, NEURAL COMPUT, V12, P2109, DOI 10.1162/089976600300015088; Unal G, 2002, IEEE T IMAGE PROCESS, V11, P1405, DOI 10.1109/TIP.2002.804568; UNAL G, 2003, IEEE INT C IM PROC; Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076; WALLACE CS, 1968, COMPUT J, V11, P185, DOI 10.1093/comjnl/11.2.185; WALSH J, 1994, LECT NOTES MATH, V14; Yip NK, 2002, LECT NOTES PURE APPL, V227, P443; Yip NK, 1998, ARCH RATION MECH AN, V144, P313, DOI 10.1007/s002050050120; Zhang B, 1999, HEWLETT PACKARD LABS	40	37	37	0	4	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2006	69	1					7	25		10.1007/s11263-006-6849-5	http://dx.doi.org/10.1007/s11263-006-6849-5			19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	063QH					2022-12-18	WOS:000239034100002
J	Teller, S; Antone, M; Bodnar, Z; Bosse, M; Coorg, S; Jethwa, M; Master, N				Teller, S; Antone, M; Bodnar, Z; Bosse, M; Coorg, S; Jethwa, M; Master, N			Calibrated, registered images of an extended urban area	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						structure from motion; extrinsic calibration; close-range photogrammetry	RECOVERY	We describe a dataset of several thousand calibrated, time-stamped, geo-referenced, high dynamic range color images, acquired under uncontrolled, variable illumination conditions in an outdoor region spanning several hundred meters. The image data is clustered into several groups which have little mutual inter-visibility. For each group, the calibration data is globally consistent on average to roughly five centimeters and 0.1., or about four pixels of epipolar registration. All image, feature and calibration data is available for interactive inspection and downloading at http:// city. lcs. mit. edu/ data. Calibrated imagery is of fundamental interest in a variety of applications. We have made this data available in the belief that researchers in computer graphics, computer vision, photogrammetry and digital cartography will find it of value as a test set for their own image registration algorithms, as a calibrated image set for applications such as image-based rendering, metric 3D reconstruction, and appearance recovery, and as input for existing GIS applications.	MIT, Comp Sci Lab, Comp Graph Grp, Cambridge, MA 02139 USA	Massachusetts Institute of Technology (MIT)	Teller, S (corresponding author), MIT, Comp Sci Lab, Comp Graph Grp, 200 Technol Sq,NE 43-252, Cambridge, MA 02139 USA.	teller@graphics.lcs.mit.edu; antone@graphics.lcs.mit.edu; zbodnar@graphics.lcs.mit.edu; ifni@graphics.lcs.mit.edu; satyan@graphics.lcs.mit.edu; manish@graphics.lcs.mit.edu; neel@graphics.lcs.mit.edu	Bosse, Michael/B-7719-2011					Antone M, 2001, PROC CVPR IEEE, P398; Antone M, 2002, INT J COMPUT VISION, V49, P143, DOI 10.1023/A:1020141505696; Antone ME, 2000, PROC CVPR IEEE, P282, DOI 10.1109/CVPR.2000.854809; BECKER S, 1995, P SOC PHOTO-OPT INS, V2410, P447, DOI 10.1117/12.205979; BINGHAM C, 1974, ANN STAT, V2, P1201, DOI 10.1214/aos/1176342874; BOSSE M, 1999, GPS WORLD, P20; Coorg S, 2000, INT J COMPUT VISION, V37, P259, DOI 10.1023/A:1008184124789; Coorg S., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P625, DOI 10.1109/CVPR.1999.787004; Coorg S, 1998, PROC CVPR IEEE, P872, DOI 10.1109/CVPR.1998.698707; Debevec P. E., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P11, DOI 10.1145/237170.237191; DEBEVEC PE, 1997, SIGGRAPH 97 C P; DECOUTO D, 1998, THESIS MIT; GREEVE C, 1997, DIGITAL PHOTOGRAMMET; HOFMANNWELLENHO.B, 1997, GPS THEORY PRACTICE; Larson G. W., 1998, Journal of Graphics Tools, V3, P15, DOI 10.1080/10867651.1998.10487485; Preparata F.P., 1985, COMPUTATIONAL GEOMET, V1; ROSENFELD A, 1984, MULTIRESOLUTION IMAG; SANDERS C, 1998, P 37 IEEE C DEC CONT; Shoemaker K., 1985, Computer Graphics, V19, P245, DOI 10.1145/325165.325242; Shum HY, 1998, PROC CVPR IEEE, P427, DOI 10.1109/CVPR.1998.698641; Slama CC., 1980, MANUAL PHOTOGRAMMETR, V4th edn; Teller S, 2001, PROC CVPR IEEE, P813; TELLER S, 1997, P IM UND WORKSH, P767; TELLER S, 1998, P IM UND WORKSH, P455; Wang XY, 2002, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON CSCW IN DESIGN, P145, DOI 10.1109/CSCWD.2002.1047670; Wolf P.R., 1974, ELEMENTS PHOTOGRAMME; ZHANG Z, 1998, MSRTR9871 MICR RES	27	37	39	0	13	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2003	53	1					93	107		10.1023/A:1023035826052	http://dx.doi.org/10.1023/A:1023035826052			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	668CV					2022-12-18	WOS:000182273500005
J	Ye, JC				Ye, JC			A self-referencing level-set method for image reconstruction from sparse Fourier samples	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article; Proceedings Paper	1st IEEE Workshop on Variational and Level Set Methods in Computer Vision	JUL 07-13, 2001	VANCOUVER, CANADA	Siemens Corp Res, Inst Natl Rech Informat & Automat, IEEE Comp Soc Tech Council Pattern Analysis & Machine Intelligence		inverse problems; Fourier imaging; medical imaging; partial-data; level-set; geometry-driven diffusion		We address an ill-posed inverse problem of image estimation from sparse samples of its Fourier transform. The problem is formulated as joint estimation of the supports of unknown sparse objects in the image, and pixel values on these supports. The domain and the pixel values are alternately estimated using the level-set method and the conjugate gradient method, respectively. Our level-set evolution shows a unique switching behavior, which stabilizes the level-set evolution. Furthermore, the trade-off between the stability and the speed of evolution can be easily controlled by the number of the conjugate gradient steps, thus avoiding the re-initialization steps in conventional level set approaches.	Philips Res USA, Briarcliff Manor, NY 10510 USA; Univ Illinois, Coordinated Sci Lab, Urbana, IL 61801 USA	Philips; Philips Research; University of Illinois System; University of Illinois Urbana-Champaign	Ye, JC (corresponding author), Philips Res USA, 345 Scarborough Rd, Briarcliff Manor, NY 10510 USA.	jong.ye@philips.com	Ye, Jong Chul/C-1623-2011	Bresler, Yoram/0000-0002-9738-1094				Adalsteinsson D, 1999, J COMPUT PHYS, V148, P2, DOI 10.1006/jcph.1998.6090; AMBROSIO L, 1990, COMMUN PUR APPL MATH, P707; BLAHUT RE, 2001, THEORY REMOTE IMAGE; Bresler Y, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL I, P701, DOI 10.1109/ICIP.1996.559595; Bresler Y., 1999, P 1999 IEEE INF THEO, P48; CHAN T, 1999, SCALE SPACE THEORIES; Chan T.F., 2000, LEVEL SET ALGORITHM, P00; Charbonnier P, 1997, IEEE T IMAGE PROCESS, V6, P298, DOI 10.1109/83.551699; Delaney AH, 1998, IEEE T IMAGE PROCESS, V7, P204, DOI 10.1109/83.660997; Dorn O, 2000, INVERSE PROBL, V16, P1119, DOI 10.1088/0266-5611/16/5/303; GASTPAR M, 2000, P ISIT INT S INF THE; GASTPAR M, 2000, P IEEE INT C AC SPEE; GEMAN D, 1995, IEEE T IMAGE PROCESS, V4, P932, DOI 10.1109/83.392335; JCHANBESSON S, 2001, INT C COMP VIS VANC; Lanterman AD, 1999, PROC SPIE, V3692, P189, DOI 10.1117/12.352861; LECLERC YG, 1989, INT J COMPUT VISION, V3, P73, DOI 10.1007/BF00054839; LUENBERGER D.G., 1989, INTRO LINEAR NONLINE; MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; PARAGIOS N, 1999, INT C COMP VIS CORF; RICHARDSON TJ, 1989, THESIS MIT; Romeny B.M., 1994, GEOMETRY DRIVEN DIFF; Santosa F., 1995, ESAIM. Control, Optimisation and Calculus of Variations, V1, P17, DOI 10.1051/cocv:1996101; Sethian JA, 1996, LEVEL SET METHODS FA; Sokolowski J., 1991, INTRO SHAPE OPTIMIZA; Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033; Venkataramani R, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P752, DOI 10.1109/ICIP.1998.723641; Ye JC, 2001, IEEE T ANTENN PROPAG, V49, P771, DOI 10.1109/8.929632; Ye JC, 2000, IEEE T INFORM THEORY, V46, P1881, DOI 10.1109/18.857798; YE JC, 2001, IN PRESS IEEE T IMAG; YU DF, 2001, UNPUB IEEE T IMAGE P; Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343	34	37	41	0	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	DEC	2002	50	3					253	270		10.1023/A:1020822324006	http://dx.doi.org/10.1023/A:1020822324006			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	607XU					2022-12-18	WOS:000178816700003
J	Lorette, A; Descombes, X; Zerubia, J				Lorette, A; Descombes, X; Zerubia, J			Texture analysis through a Markovian modelling and fuzzy classification: Application to urban area extraction from satellite images	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Markov Random Fields; Fuzzy C-means; urban areas; remote sensed images	STATISTICAL-ANALYSIS; GABOR FILTERS; RANDOM-FIELDS; SEGMENTATION; RELAXATION	Herein we propose a complete procedure to analyze and classify the texture of an image. We apply this scheme to solve a specific image processing problem: urban areas detection in satellite images. First we propose to analyze the texture through the modelling of the luminance field with eight different chain-based models. We then derived a texture parameter from these models. The effect of the lattice anisotropy is corrected by a renormalization group technique coming from statistical physics. This parameter, which takes into account local conditional variances of the image, is compared to classical methods of texture analysis. Afterwards we develop a modified fuzzy Cmeans algorithm that includes an entropy term. The advantage of such an algorithm is that the number of classes does not need to be known a priori. Besides this algorithm provides us with further information, i.e. the probability that a given pixel belongs to a given cluster. Finally we introduce this information in a Markovian model of segmentation. Some results on SPOT5 simulated images, SPOT3 images and ERS1 radar images are presented. These images are provided by the French National Space Agency (CNES) and the European Space Agency (ESA).	Ariana, Joint Grp CNRS INRIA UNSA INRIA, F-06902 Sophia Antipolis, France		Lorette, A (corresponding author), Ariana, Joint Grp CNRS INRIA UNSA INRIA, 2004 Route Des Luciozes,BP 93, F-06902 Sophia Antipolis, France.							AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705; [Anonymous], 1988, EYE BRAIN VISION; BARALDI A, 1990, IEEE T GEOSCI REMOTE, V28, P674, DOI 10.1109/TGRS.1990.572979; BESAG J, 1974, J ROY STAT SOC B MET, V36, P192; BESAG J, 1986, J R STAT SOC B, V48, P259; BOUMAN C, 1991, IEEE T PATTERN ANAL, V13, P99, DOI 10.1109/34.67641; CHATTERJEE S, 1993, MARKOV RANDOM FIELDS, P159; Chen C, 1993, HDB PATTERN RECOGNIT; COHEN FS, 1987, IEEE T PATTERN ANAL, V9, P195, DOI 10.1109/TPAMI.1987.4767895; CONNERS RW, 1984, COMPUT VISION GRAPH, V25, P273, DOI 10.1016/0734-189X(84)90197-X; Descombes X, 1999, IEEE T IMAGE PROCESS, V8, P490, DOI 10.1109/83.753737; DESCOMBES X, 1993, SPIE, V2032, P156; Dubes R.C., 1989, J APPL STAT, V16, P131, DOI DOI 10.1080/02664768900000014; FOGEL I, 1989, BIOL CYBERN, V61, P103, DOI 10.1007/BF00204594; Forbes F, 1999, J AM STAT ASSOC, V94, P555; FRANCOS JM, 1993, IEEE T SIGNAL PROCES, V41, P2665, DOI 10.1109/78.229897; Frigui H, 1996, PROC CVPR IEEE, P550, DOI 10.1109/CVPR.1996.517126; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; GIDAS B, 1989, IEEE T PATTERN ANAL, V11, P164, DOI 10.1109/34.16712; GOUINAUD C, 1996, THESIS ECOLE NATL SU; GULL SF, 1984, IEE PROC-F, V131, P646, DOI 10.1049/ip-f-1.1984.0099; HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328; HOFFMAN R, 1987, IEEE T PATTERN ANAL, V9, P608, DOI 10.1109/TPAMI.1987.4767955; HOUZELLE S, 1991, IGARSS, V3, P1455; Huang K., 1998, QUANTUM FIELD THEORY; JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S; JULESZ B, 1987, READINGS COMPUTER VI, P243; KHINCHIN AI, 1957, MATH FDN INFORMATION; KRISHNAPURAM R, 1994, SPIE I SER, V12, P133; LEMEN H, 1994, CFC FRANCE, V142, P182; Li S., 1995, MARKOV RANDOM FIELD, P1; LORETTE A, 1999, ICIP KOBE; LORETTE A, 1998, RR3423 INRIA; MALIK J, 1990, J OPT SOC AM A, V7, P923, DOI 10.1364/JOSAA.7.000923; Matsuba I., 1988, ICASSP 88: 1988 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.88CH2561-9), P1044, DOI 10.1109/ICASSP.1988.196772; MOOD A, 1974, MCGRAWHILL INT EDITI; NGUYEN HH, 1993, CVGIP-GRAPH MODEL IM, V55, P1, DOI 10.1006/cgip.1993.1001; Palubinskas G, 1998, INT C PATT RECOG, P1816, DOI 10.1109/ICPR.1998.712082; RICHARD F, 1998, EUSIPCO RHOD, V4, P2493; RUSPINI EH, 1969, INFORM CONTROL, V15, P22, DOI 10.1016/S0019-9958(69)90591-9; SCHROEDER M, 1990, FRACTALS CHAOS POWER; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x; SIGELLE M, 1992, TRAIT SIGNAL, V6, P449; UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936; Wilson K. G., 1974, PHYS REP, V12, P75, DOI DOI 10.1016/0370-1573(74)90023-4; WINKLER G., 1995, IMAGE ANAL RANDOM FI; WINTER A, 1997, ICIP SANT, V2, P234; ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X	49	37	45	0	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	FEB	2000	36	3					221	236		10.1023/A:1008129103384	http://dx.doi.org/10.1023/A:1008129103384			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	315LD					2022-12-18	WOS:000087114500003
J	KIMMEL, R; SIDDIQI, K; KIMIA, BB; BRUCKSTEIN, AM				KIMMEL, R; SIDDIQI, K; KIMIA, BB; BRUCKSTEIN, AM			SHAPE FROM SHADING - LEVEL SET PROPAGATION AND VISCOSITY SOLUTIONS	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							ALGORITHMS; CURVATURE; FRONTS	We present a new implementation of an algorithm aimed at recovering a 3D shape from its 2D gray-level picture. In order to reconstruct the shape of the object, an almost arbitrarily initialized 3D function is propagated on a rectangular grid, so that a level set of this function tracks the height contours of the shape. The method imports techniques from differential geometry, fluid dynamics, and numerical analysis and provides an accurate shape from shading algorithm. The method solves some topological problems and gracefully handles cases of non-smooth surfaces that give rise to shocks in the propagating contours. Real and synthetic images of 3D profiles were submitted to the algorithm and the reconstructed surfaces are presented, demonstrating the effectiveness of the proposed method.	BROWN UNIV,MAN MACHINE SYST LAB,PROVIDENCE,RI 02912; TECHNION ISRAEL INST TECHNOL,DEPT COMP SCI,IL-32000 HAIFA,ISRAEL	Brown University; Technion Israel Institute of Technology	KIMMEL, R (corresponding author), TECHNION ISRAEL INST TECHNOL,DEPT ELECT ENGN,IL-32000 HAIFA,ISRAEL.		Elhamod, Mohannad/A-1904-2012	Siddiqi, Kaleem/0000-0002-7347-9716				ASCHER UM, 1993, SIAM J NUMER ANAL, V30, P102, DOI 10.1137/0730005; BROOKS MJ, 1989, 1985 P INT JOINT C A, P932; BRUCKSTEIN AM, 1988, COMPUT VISION GRAPH, V44, P139, DOI 10.1016/S0734-189X(88)80002-1; CAYLEY A, 1859, PHILOS MAG, P264; CHOPP DL, 1991, THESIS U CA BERKELEY; CHOPP DL, 1991, PAM541 U CA CTR PUR; CHORIN AJ, 1980, J COMPUT PHYS, V35, P1, DOI 10.1016/0021-9991(80)90030-3; CHROIN AJ, 1985, J COMPUT PHYS, V58, P472; COURANT R, 1953, METHODS MATH PHYSICS, V1; COURANT R, 1902, METHODS MATH PHYSICS, V2; FRAKOT RT, 1988, IEEE T PATTERN ANAL, V4, P439; Horn B., 1986, ROBOT VISION, P1; Horn B.K.P., 1989, SHAPE SHADING; Horn Berthold K. P., 1975, PSYCHOL COMPUTER VIS, P115; HORN BKP, 1990, INT J COMPUT VISION, V5, P37, DOI 10.1007/BF00056771; HORN BKP, 1986, COMPUT VISION GRAPH, V2, P174; IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0; JOHN F, 1982, APPLIED MATH SCI; KIMIA BB, 1990, THESIS MCGILL U MONT; KIMIA BB, 1994, P CVPR; KIMIA BB, IN PRESS INT J COMPU; KIMIA BB, 1990, 1ST P EUR C COMP VIS; KIMIA BB, 1992, J MAHT ANAL APPLICAT, V163; KIMM, 1995, CVIU, V62, P47; KIMMEL R, 1992, THESIS TECHNION ISRA; KIMMEL R, 1993, IN PRESS CVIU; KIMMEL R, 1992, CIS9209 TECHN CS DEP; KIMMEL R, 1994, IN PRESS J MATH IMAG; KIMMEL R, 1993, P SPIE GEOMETRIC MET, V2, P259; Maxwell J. C., 1870, PHILOS MAG, P233; MITCHELL A, 1985, FINITE DIFFERENCE ME; OLIENSIS J, 1991, CVGIP-IMAG UNDERSTAN, V54, P163, DOI 10.1016/1049-9660(91)90061-S; OLIENSIS J, 1990, INT J COMPUT VISION, V6, P75; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; OSHER S, 1991, SIAM J NUMER ANAL, V28, P907, DOI 10.1137/0728049; OSHER S, 1993, UNPUB RAPID CONVERGE; PENTLAND AP, 1990, INT J COMPUT VISION, V4, P153, DOI 10.1007/BF00127815; PENTLAND AP, 1989, IEEE T PAMI, V6, P170; ROUY E, 1992, SIAM J NUMER ANAL, V29, P867, DOI 10.1137/0729053; Sethian J.A., 1987, VARIATIONAL METHODS; SETHIAN JA, 1992, J COMPUT PHYS, V98, P231, DOI 10.1016/0021-9991(92)90140-T; SETHIAN JA, 1985, COMMUN MATH PHYS, V101, P487, DOI 10.1007/BF01210742; SETHIAN JA, 1989, J DIFFER GEOM, V33, P131; Sod G. A., 1985, NUMERICAL METHODS FL; ZHU J, 1991, LBL30183 U CA BERK D	45	37	38	0	1	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	OCT	1995	16	2					107	133		10.1007/BF01539551	http://dx.doi.org/10.1007/BF01539551			27	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	TC767					2022-12-18	WOS:A1995TC76700001
J	ZHENG, QF; CHELLAPPA, R				ZHENG, QF; CHELLAPPA, R			AUTOMATIC FEATURE POINT EXTRACTION AND TRACKING IN IMAGE SEQUENCES FOR ARBITRARY CAMERA MOTION	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article								An automatic egomotion compensation based point correspondence algorithm is presented. A basic problem in autonomous navigation and motion estimation is automatically detecting and tracking features in consecutive frames, a challenging problem when camera motion is significant. In general, feature displacements between consecutive frames can be approximately decomposed into two components: (i) displacements due to camera motion which can be approximately compensated by image rotation, scaling, and translation; (ii) displacements due to object motion and/or perspective projection. In this paper, we introduce a two-step approach: First, the motion of the camera is compensated using a computational vision based image registration algorithm. Then consecutive frames are transformed to the same coordinate system and the feature correspondence problem is solved as though tracking moving objects for a stationary camera. Methods of subpixel accuracy feature matching, tracking and error analysis are introduced. The approach results in a robust and efficient algorithm. Results on several real image sequences are presented.	UNIV MARYLAND, DEPT ELECT ENGN, COLLEGE PK, MD 20742 USA	University System of Maryland; University of Maryland College Park	ZHENG, QF (corresponding author), UNIV MARYLAND, CTR AUTOMAT RES, COLLEGE PK, MD 20742 USA.		Chellappa, Rama/AAJ-1504-2020; Chellappa, Rama/AAV-8690-2020; Chellappa, Rama/B-6573-2012; ZHENG, Qin/T-2925-2019					BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032; Crowley J. L., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P658, DOI 10.1109/CCV.1988.590047; DERICHE R, 1990, 1ST P EUR C COMP VIS, P259; FANG JQ, 1984, IEEE T PATTERN ANAL, V6, P545, DOI 10.1109/TPAMI.1984.4767569; Horn B., 1986, ROBOT VISION, P1; HUANG TS, 1981, IMAGE SEQUENCE ANAL; LIM HS, 1988, P DARPA IMAGE UNDERS, P7944; MANJUNATH BS, 1992, CARTR604 U MAR CTR A; MATTHEIS L, 1988, P DARPA IMAGE UNDERS, P199; MEDIONI G, 1984, IEEE T PATTERN ANAL, V6, P675, DOI 10.1109/TPAMI.1984.4767592; RANADE S, 1980, PATTERN RECOGN, V12, P269, DOI 10.1016/0031-3203(80)90067-9; SETHI IK, 1987, IEEE T PATTERN ANAL, V9, P56, DOI 10.1109/TPAMI.1987.4767872; SHEKHAR C, 1922, CARTR607CSTR2862 U M; SMITH P, 1991, VISION BASED RANGE E; TIAN Q, 1986, COMPUT VISION GRAPH, V35, P220, DOI 10.1016/0734-189X(86)90028-9; Venkateswar V., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P280, DOI 10.1109/WVM.1991.212774; WU T, 1992, CARTR646 U MAR CTR A; WU T, 1993, P DARPA IMAGE UNDERS, P641; ZHENG Q, 1991, CARTR583 U MAR CTR A; ZHENG QF, 1991, IEEE T PATTERN ANAL, V13, P680, DOI 10.1109/34.85658; ZHENG QF, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL I, P193, DOI 10.1109/ICPR.1992.201539	21	37	43	0	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	1995	15	1-2					31	76		10.1007/BF01450849	http://dx.doi.org/10.1007/BF01450849			46	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	QY042					2022-12-18	WOS:A1995QY04200003
J	Yuan, YH; Huang, L; Guo, JY; Zhang, C; Chen, XL; Wang, JD				Yuan, Yuhui; Huang, Lang; Guo, Jianyuan; Zhang, Chao; Chen, Xilin; Wang, Jingdong			OCNet: Object Context for Semantic Segmentation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Semantic segmentation; Context; Self-attention		In this paper, we address the semantic segmentation task with a new context aggregation scheme named object context, which focuses on enhancing the role of object information. Motivated by the fact that the category of each pixel is inherited from the object it belongs to, we define the object context for each pixel as the set of pixels that belong to the same category as the given pixel in the image. We use a binary relation matrix to represent the relationship between all pixels, where the value one indicates the two selected pixels belong to the same category and zero otherwise. We propose to use a dense relation matrix to serve as a surrogate for the binary relation matrix. The dense relation matrix is capable to emphasize the contribution of object information as the relation scores tend to be larger on the object pixels than the other pixels. Considering that the dense relation matrix estimation requires quadratic computation overhead and memory consumption w.r.t. the input size, we propose an efficient interlaced sparse self-attention scheme to model the dense relations between any two of all pixels via the combination of two sparse relation matrices. To capture richer context information, we further combine our interlaced sparse self-attention scheme with the conventional multi-scale context schemes including pyramid pooling (Zhao et al. 2017) and atrous spatial pyramid pooling (Chen et al. 2018). We empirically show the advantages of our approach with competitive performances on five challenging benchmarks including: Cityscapes, ADE20K, LIP, PASCAL-Context and COCO-Stuff.	[Yuan, Yuhui; Wang, Jingdong] Microsoft Res Asia, Beijing, Peoples R China; [Huang, Lang; Guo, Jianyuan; Zhang, Chao] Peking Univ, Beijing, Peoples R China; [Yuan, Yuhui; Chen, Xilin] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China; [Yuan, Yuhui; Chen, Xilin] Univ Chinese Acad Sci, Beijing, Peoples R China	Microsoft; Microsoft Research Asia; Peking University; Chinese Academy of Sciences; Institute of Computing Technology, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS	Yuan, YH (corresponding author), Microsoft Res Asia, Beijing, Peoples R China.; Yuan, YH (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.; Yuan, YH (corresponding author), Univ Chinese Acad Sci, Beijing, Peoples R China.	yuyua@microsoft.com; jingdw@microsoft.com	Wang, Jingdong/E-9920-2017	Wang, Jingdong/0000-0002-4888-4445	National Nature Science Foundation of China [62071013, 61671027]; National Key R&D Program of China [2018AAA0100300]	National Nature Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Key R&D Program of China	This work is supported in part by the National Nature Science Foundation of China under Grant 62071013 and 61671027, and in part by National Key R&D Program of China under Grant 2018AAA0100300.	Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615; Berg A. C., 2015, ARXIV150604579 CORR; Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184; Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Ding HH, 2019, PROC CVPR IEEE, P8877, DOI 10.1109/CVPR.2019.00909; Ding HH, 2018, PROC CVPR IEEE, P2393, DOI 10.1109/CVPR.2018.00254; Divvala SK, 2009, PROC CVPR IEEE, P1271, DOI 10.1109/CVPRW.2009.5206532; Fu J, 2019, IEEE I CONF COMP VIS, P6747, DOI 10.1109/ICCV.2019.00685; Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326; Gong K, 2017, PROC CVPR IEEE, P6757, DOI 10.1109/CVPR.2017.715; Gonzalez-Garcia A, 2018, PROC CVPR IEEE, P6907, DOI 10.1109/CVPR.2018.00722; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069; Kong S, 2018, PROC CVPR IEEE, P956, DOI 10.1109/CVPR.2018.00106; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Kuo WC, 2019, IEEE I CONF COMP VIS, P9206, DOI 10.1109/ICCV.2019.00930; Li X, 2019, IEEE I CONF COMP VIS, P9166, DOI 10.1109/ICCV.2019.00926; Li Y, 2018, ADV NEUR IN, V31; Liang X., 2018, NEURIPS, P1858; Liang XD, 2019, IEEE T PATTERN ANAL, V41, P871, DOI 10.1109/TPAMI.2018.2820063; Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106; Luo YW, 2018, LECT NOTES COMPUT SC, V11213, P424, DOI 10.1007/978-3-030-01240-3_26; Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8; Munoz M., 2019, ADV NEURAL INFORM PR, P8; Nie XC, 2018, LECT NOTES COMPUT SC, V11209, P519, DOI 10.1007/978-3-030-01228-1_31; Pang YW, 2019, IEEE I CONF COMP VIS, P4229, DOI 10.1109/ICCV.2019.00433; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Ruan T, 2019, AAAI CONF ARTIF INTE, P4814; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Shen Z., 2018, ARXIV181201243; Shuai B, 2018, IEEE T PATTERN ANAL, V40, P1480, DOI 10.1109/TPAMI.2017.2712691; Sun K., 2019, ARXIV190404514 CORR; Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584; Sutskever I., 2019, ARXIV190410509 CORR; Tian Z, 2019, PROC CVPR IEEE, P3121, DOI 10.1109/CVPR.2019.00324; Vaswani A., 2017, P 31 INT C NEUR INF, P5998, DOI DOI 10.5555/3295222.3295349; Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163; Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274; Wang WG, 2019, IEEE I CONF COMP VIS, P5702, DOI 10.1109/ICCV.2019.00580; Weiss Y., 2018, LECT NOTES COMPUTER, V11205; Wu TY, 2019, IEEE INT CON MULTI, P940, DOI 10.1109/ICME.2019.00166; Xiao TT, 2018, LECT NOTES COMPUT SC, V11209, P432, DOI 10.1007/978-3-030-01228-1_26; Xie GT, 2018, PROC CVPR IEEE, P8847, DOI 10.1109/CVPR.2018.00922; Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388; Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20; Yu CQ, 2018, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR.2018.00199; Yu F., 2016, ICLR; Yue KY, 2018, ADV NEUR IN, V31; Yuhui Yuan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P173, DOI 10.1007/978-3-030-58539-6_11; Zhang F, 2019, IEEE I CONF COMP VIS, P6797, DOI 10.1109/ICCV.2019.00690; Zhang H, 2019, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2019.00064; Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747; Zhang R, 2017, IEEE I CONF COMP VIS, P2050, DOI 10.1109/ICCV.2017.224; Zhang T, 2017, IEEE I CONF COMP VIS, P4383, DOI 10.1109/ICCV.2017.469; Zhao HS, 2018, LECT NOTES COMPUT SC, V11213, P270, DOI 10.1007/978-3-030-01240-3_17; Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660; Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544; Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1; Zhu Z, 2019, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2019.00068	74	36	37	10	26	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2021	129	8					2375	2398		10.1007/s11263-021-01465-9	http://dx.doi.org/10.1007/s11263-021-01465-9		MAY 2021	24	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	TR3NV					2022-12-18	WOS:000653602100003
J	Stoll, S; Camgoz, NC; Hadfield, S; Bowden, R				Stoll, Stephanie; Camgoz, Necati Cihan; Hadfield, Simon; Bowden, Richard			Text2Sign: Towards Sign Language Production Using Neural Machine Translation and Generative Adversarial Networks	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Generative adversarial networks; Neural machine translation; Sign language production		We present a novel approach to automatic Sign Language Production using recent developments in Neural Machine Translation (NMT), Generative Adversarial Networks, and motion generation. Our system is capable of producing sign videos from spoken language sentences. Contrary to current approaches that are dependent on heavily annotated data, our approach requires minimal gloss and skeletal level annotations for training. We achieve this by breaking down the task into dedicated sub-processes. We first translate spoken language sentences into sign pose sequences by combining an NMT network with a Motion Graph. The resulting pose information is then used to condition a generative model that produces photo realistic sign language video sequences. This is the first approach to continuous sign video generation that does not use a classical graphical avatar. We evaluate the translation abilities of our approach on the PHOENIX14T Sign Language Translation dataset. We set a baseline for text-to-gloss translation, reporting a BLEU-4 score of 16.34/15.26 on dev/test sets. We further demonstrate the video generation capabilities of our approach for both multi-signer and high-definition settings qualitatively and quantitatively using broadcast quality assessment metrics.	[Stoll, Stephanie; Camgoz, Necati Cihan; Hadfield, Simon; Bowden, Richard] Ctr Vis Speech & Signal Proc, Guildford, Surrey, England	University of Surrey	Stoll, S (corresponding author), Ctr Vis Speech & Signal Proc, Guildford, Surrey, England.	s.m.stoll@surrey.ac.uk; n.camgoz@surrey.ac.uk; s.hadfield@surrey.ac.uk; r.bowden@surrey.ac.uk	Bowden, Richard/AAF-8283-2019	Bowden, Richard/0000-0003-3285-8020; Hadfield, Simon/0000-0001-8637-5054; Stoll, Stephanie/0000-0002-3582-3969	SNSF Sinergia project "Scalable Multimodal Sign Language Technology for Sign Language Learning and Assessment" (SMILE) grant [CRSII2 160811]; European Union's Horizon 2020 research and innovation programme [762021]; EPSRC Project ExTOL [EP/R03298X/1]; NVIDIA Corporation; EPSRC [EP/R03298X/1] Funding Source: UKRI	SNSF Sinergia project "Scalable Multimodal Sign Language Technology for Sign Language Learning and Assessment" (SMILE) grant; European Union's Horizon 2020 research and innovation programme; EPSRC Project ExTOL(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); NVIDIA Corporation; EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was funded by the SNSF Sinergia project "Scalable Multimodal Sign Language Technology for Sign Language Learning and Assessment" (SMILE) grant Agreement No. CRSII2 160811, the European Union's Horizon 2020 research and innovation programme under grant Agreement No. 762021 (Content4All) and the EPSRC Project ExTOL (EP/R03298X/1). We would also like to thank NVIDIA Corporation for their GPU grant, and Oscar Koller at Microsoft.	AHN H, 2018, IEEE INT C ROB AUT I; Arikan O, 2002, ACM T GRAPHIC, V21, P483, DOI 10.1145/566570.566606; BANGHAM JA, 2000, IEE SEM SPEECH LANG; *BDA, 2019, BSL STAT; BOWDEN R, 2016, LEARNING RECOGNISE D; CAMGOZ NC, 2018, IEEE C COMP VIS PATT; Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143; CHAN C, 2018, ARXIV180807371 CORR; Chen QF, 2017, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2017.168; Cho Kyunghyun, 2014, ARXIV, DOI 10.3115/v1/w14-4012; Chung J., 2014, ARXIV14123555; COX S, 2002, P 5 INT ACM C ASS TE, P205; Dzmitry Bahdanau, 2016, Arxiv, DOI arXiv:1409.0473; EBLING S, 2018, 11 ED LANG RES EV C; EBLING S, 2015, SLPAT INTERSPEECH; EBLING S, 2013, 3 INT S SIGN LANG TR; EFTHIMIOU E, 2012, LECT NOTES COMPUTER, V7383; *EU, 2018, SIGN LANG EU; Forster J, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1911; Gibet S, 2016, UNIVERSAL ACCESS INF, V15, P525, DOI 10.1007/s10209-015-0411-6; Glauert J. R. W., 2006, TECHNOLOGY DISABILIT, V18, P207, DOI DOI 10.3233/TAD-2006-18408; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gregor K, 2015, PR MACH LEARN RES, V37, P1462; Guo D, 2018, AAAI CONF ARTIF INTE, P6845; Guo D, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3152121; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hu ZW, 2018, IEEE ICC; Isola P., 2017, IMAGE TO IMAGE TRANS, P1125; Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43; KALCHBRENNER N, 2016, ARXIV161010099 CORR; KENNAWAY R, 2013, ARXIV150202961 CORR; Kingma D. P., 2013, AUTO ENCODING VARIAT; KIPP M, 2011, IVA; Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605; Larsen ABL, 2016, PR MACH LEARN RES, V48; Lee J, 1999, COMP GRAPH, P39; LEE J, 2002, P ACM SIGGRAPH 2002, P491, DOI DOI 10.1145/566570.566607; Lundberg SM, 2017, ADV NEUR IN, V30; Luong M., 2015, ARXIV150804025; Makhzani Alireza, 2016, ICLR WORKSH; McDonald J, 2016, UNIVERSAL ACCESS INF, V15, P551, DOI 10.1007/s10209-015-0407-2; Min JY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366172; Mirza M., 2014, ARXIV; Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811; Perarnau G, 2016, ARXIV161106355; Prillwitz S., 1989, HAMBURG NOTATION SYS; Radford A., 2015, P COMP C; Reed S. E., 2016, ADV NEURAL INFORM PR, P217; SAVITZKY A, 1964, ANAL CHEM, V36, P1627, DOI 10.1021/ac60214a047; Siarohin A, 2018, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2018.00359; STOLL S, 2018, BRIT MACH VIS C BMVC; Sutskever I., 2014, ARXIV14093215, DOI DOI 10.1007/S10107-014-0839-0; van den Oord A, 2016, ADV NEUR IN, V29; van den Oord A, 2016, PR MACH LEARN RES, V48; Vaswani A., 2017, ARXIV170603762 CORR; *VIRT HUM GROUP, 2017, VIRT HUM RES SIGN LA; Wang S, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1483, DOI 10.1145/3240508.3240671; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; World Health Organization, 2018, DEAFN HEAR LOSS; Yan XC, 2016, LECT NOTES COMPUT SC, V9908, P776, DOI 10.1007/978-3-319-46493-0_47; Zwitserlood I, 2005, SYNTHETIC SIGNING DE	61	36	38	9	26	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	2020	128	4			SI		891	908		10.1007/s11263-019-01281-2	http://dx.doi.org/10.1007/s11263-019-01281-2		JAN 2020	18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	LC5TN		Green Submitted, hybrid			2022-12-18	WOS:000505388600003
J	Fu, Y; Lam, A; Sato, I; Sato, Y				Fu, Ying; Lam, Antony; Sato, Imari; Sato, Yoichi			Adaptive Spatial-Spectral Dictionary Learning for Hyperspectral Image Restoration	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Adaptive spatial-spectral dictionary learning; Hyperspectral image restoration; Self-similarity; High correlation across spectra; Non-local sparse representation	NOISE-REDUCTION; SPARSE; SUPERRESOLUTION; CLASSIFICATION; REPRESENTATIONS; RECONSTRUCTION; ALGORITHM; FILTER; SIGNAL	Hyperspectral imaging is beneficial in a diverse range of applications from diagnostic medicine, to agriculture, to surveillance to name a few. However, hyperspectral images often suffer from degradation such as noise and low resolution. In this paper, we propose an effective model for hyperspectral image (HSI) restoration, specifically image denoising and super-resolution. Our model considers three underlying characteristics of HSIs: sparsity across the spatial-spectral domain, high correlation across spectra, and non-local self-similarity over space. We first exploit high correlation across spectra and non-local self-similarity over space in the degraded HSI to learn an adaptive spatial-spectral dictionary. Then, we employ the local and non-local sparsity of the HSI under the learned spatial-spectral dictionary to design an HSI restoration model, which can be effectively solved by an iterative numerical algorithm with parameters that are adaptively adjusted for different clusters and different noise levels. In experiments on HSI denoising, we show that the proposed method outperforms many state-of-the-art methods under several comprehensive quantitative assessments. We also show that our method performs well on HSI super-resolution.	[Fu, Ying; Sato, Yoichi] Univ Tokyo, Inst Ind Sci, Meguro Ku, 4-6-1 Komaba, Tokyo 1538505, Japan; [Lam, Antony] Saitama Univ, Grad Sch Sci & Engn, Sakura Ku, 255 Shimo Okubo, Saitama 3388570, Japan; [Sato, Imari] Natl Inst Informat, 2-1-2 Hitotsubashi, Tokyo 1018430, Japan	University of Tokyo; Saitama University; Research Organization of Information & Systems (ROIS); National Institute of Informatics (NII) - Japan	Fu, Y (corresponding author), Univ Tokyo, Inst Ind Sci, Meguro Ku, 4-6-1 Komaba, Tokyo 1538505, Japan.	fuying@ut-vision.org						Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Akgun T, 2005, IEEE T IMAGE PROCESS, V14, P1860, DOI 10.1109/TIP.2005.854479; Alsberg B. K., 2006, Chemometrics and Intelligent Laboratory Systems, V84, P62, DOI 10.1016/j.chemolab.2006.04.014; [Anonymous], P IEEE C COMP VIS PA; Atkinson I, 2003, INT GEOSCI REMOTE SE, P743; Banerjee A., 2009, PROC 1 WORKSHOP HYPE, P1; Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319; Borengasser M., 2007, HYPERSPECTRAL REMOTE; Bourennane S, 2010, IEEE GEOSCI REMOTE S, V7, P801, DOI 10.1109/LGRS.2010.2048696; Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38; Buades A, 2009, IEEE T IMAGE PROCESS, V18, P1192, DOI 10.1109/TIP.2009.2017171; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507; Castrodad A, 2011, IEEE T GEOSCI REMOTE, V49, P4263, DOI 10.1109/TGRS.2011.2163822; Chakrabarti A, 2011, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.2011.5995660; Chan JCW, 2010, IEEE T GEOSCI REMOTE, V48, P2569, DOI 10.1109/TGRS.2009.2039797; Chen GY, 2011, IEEE T GEOSCI REMOTE, V49, P973, DOI 10.1109/TGRS.2010.2075937; Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010; Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238; Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042; Dicker DT, 2006, CANCER BIOL THER, V5, P1033, DOI 10.4161/cbt.5.8.3261; Dong WS, 2016, IEEE T IMAGE PROCESS, V25, P2337, DOI 10.1109/TIP.2016.2542360; Dong WS, 2015, INT J COMPUT VISION, V114, P217, DOI 10.1007/s11263-015-0808-y; Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847; Dong WS, 2011, PROC CVPR IEEE, P457, DOI 10.1109/CVPR.2011.5995478; Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132; Eismann MT, 2005, IEEE T GEOSCI REMOTE, V43, P455, DOI 10.1109/TGRS.2004.837324; Eismann MT, 2004, IEEE T GEOSCI REMOTE, V42, P1924, DOI 10.1109/TGRS.2004.830644; Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969; Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271; Guo X, 2013, ISPRS J PHOTOGRAMM, V83, P50, DOI 10.1016/j.isprsjprs.2013.06.001; Gupta N., 2008, P SPIE; Hou B, 2013, IEEE J-STARS, V6, P1602, DOI 10.1109/JSTARS.2013.2259470; Kang XD, 2014, IEEE T GEOSCI REMOTE, V52, P3742, DOI 10.1109/TGRS.2013.2275613; Karami A, 2011, IEEE J-STSP, V5, P487, DOI 10.1109/JSTSP.2011.2132692; Lam A, 2012, INT C PATT RECOG, P477; Letexier D, 2008, IEEE T GEOSCI REMOTE, V46, P2061, DOI 10.1109/TGRS.2008.916641; Lu GL, 2014, J BIOMED OPT, V19, DOI 10.1117/1.JBO.19.1.010901; Ma CG, 2014, INT J COMPUT VISION, V110, P141, DOI 10.1007/s11263-013-0690-4; Maggioni M, 2013, IEEE T IMAGE PROCESS, V22, P119, DOI 10.1109/TIP.2012.2210725; MAIRAL J., 2009, P 26 ANN INT C MACH, P689, DOI [10.1145/1553374.1553463, DOI 10.1145/1553374.1553463]; Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452; Manjon JV, 2010, J MAGN RESON IMAGING, V31, P192, DOI 10.1002/jmri.22003; Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865; Monno Y., 2013, P SOC PHOTO-OPT INS, V8660, P866; Murakami Y, 2008, OPT EXPRESS, V16, P4106, DOI 10.1364/OE.16.004106; Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7; Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0; Othman H, 2006, IEEE T GEOSCI REMOTE, V44, P397, DOI 10.1109/TGRS.2005.860982; Parmar M, 2008, IEEE IMAGE PROC, P473, DOI 10.1109/ICIP.2008.4711794; Peng Y, 2014, PROC CVPR IEEE, P2949, DOI 10.1109/CVPR.2014.377; Qian YT, 2013, IEEE J-STARS, V6, P499, DOI 10.1109/JSTARS.2012.2232904; Qian YT, 2012, INT GEOSCI REMOTE SE, P1345, DOI 10.1109/IGARSS.2012.6351287; Renard N, 2008, IEEE T GEOSCI REMOTE, V46, P2407, DOI 10.1109/TGRS.2008.918419; Renard N, 2008, IEEE GEOSCI REMOTE S, V5, P138, DOI 10.1109/LGRS.2008.915736; Rowe RK, 2005, Proceedings from the Sixth Annual IEEE Systems, Man and Cybernetics Information Assurance Workshop, P14, DOI 10.1109/IAW.2005.1495928; Shimano M, 2011, LECT NOTES COMPUT SC, V6492, P93, DOI 10.1007/978-3-642-19315-6_8; Stamatas GN, 2003, P SOC PHOTO-OPT INS, V4959, P77, DOI 10.1117/12.479491; Teke M, 2013, PROCEEDINGS OF 6TH INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN SPACE TECHNOLOGIES (RAST 2013), P171, DOI 10.1109/RAST.2013.6581194; VRHEL MJ, 1994, COLOR RES APPL, V19, P4, DOI 10.1111/j.1520-6378.1994.tb00053.x; Wang Y., 2009, J SENSORS, P1; Wang Y, 2010, IEEE SENS J, V10, P469, DOI 10.1109/JSEN.2009.2037800; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Yang CY, 2011, LECT NOTES COMPUT SC, V6494, P497, DOI 10.1007/978-3-642-19318-7_39; Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625; Yasuma F., 2008, TECH REP; Yuan QQ, 2012, IEEE T GEOSCI REMOTE, V50, P3660, DOI 10.1109/TGRS.2012.2185054; Zhang HY, 2014, IEEE T GEOSCI REMOTE, V52, P4729, DOI 10.1109/TGRS.2013.2284280; Zhang HY, 2012, SIGNAL PROCESS, V92, P2082, DOI 10.1016/j.sigpro.2012.01.020; Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730; Zhao Q, 2015, IEEE I CONF COMP VIS, P271, DOI 10.1109/ICCV.2015.39; Zhao YH, 2011, EXP DIABETES RES, DOI 10.1155/2011/192564; Zhong P, 2013, IEEE T GEOSCI REMOTE, V51, P2260, DOI 10.1109/TGRS.2012.2209656; Zibulevsky M, 2010, IEEE SIGNAL PROC MAG, V27, P76, DOI 10.1109/MSP.2010.936023	73	36	37	1	47	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	2017	122	2			SI		228	245		10.1007/s11263-016-0921-6	http://dx.doi.org/10.1007/s11263-016-0921-6			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	EQ5ZS					2022-12-18	WOS:000398162200004
J	Gan, C; Yang, Y; Zhu, LC; Zhao, DL; Zhuang, YT				Gan, Chuang; Yang, Yi; Zhu, Linchao; Zhao, Deli; Zhuang, Yueting			Recognizing an Action Using Its Name: A Knowledge-Based Approach	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Action recognition; Semantic correlation; Adaptive multi-model rank-preserving mapping (AMRM)	ACTION RECOGNITION; EVENT RECOGNITION	Existing action recognition algorithms require a set of positive exemplars to train a classifier for each action. However, the amount of action classes is very large and the users' queries vary dramatically. It is impractical to pre-define all possible action classes beforehand. To address this issue, we propose to perform action recognition with no positive exemplars, which is often known as the zero-shot learning. Current zero-shot learning paradigms usually train a series of attribute classifiers and then recognize the target actions based on the attribute representation. To ensure the maximum coverage of ad-hoc action classes, the attribute-based approaches require large numbers of reliable and accurate attribute classifiers, which are often unavailable in the real world. In this paper, we propose an approach that merely takes an action name as the input to recognize the action of interest without any pre-trained attribute classifiers and positive exemplars. Given an action name, we first build an analogy pool according to an external ontology, and each action in the analogy pool is related to the target action at different levels. The correlation information inferred from the external ontology may be noisy. We then propose an algorithm, namely adaptive multi-model rank-preserving mapping (AMRM), to train a classifier for action recognition, which is able to evaluate the relatedness of each video in the analogy pool adaptively. As multiple mapping models are employed, our algorithm has better capability to bridge the gap between visual features and the semantic information inferred from the ontology. Extensive experiments demonstrate that our method achieves the promising performance for action recognition only using action names, while no attributes and positive exemplars are available.	[Gan, Chuang] Tsinghua Univ, IIIS, Beijing, Peoples R China; [Yang, Yi; Zhu, Linchao] Univ Technol, QCIS, Sydney, NSW, Australia; [Zhao, Deli] HTC Res, Beijing, Peoples R China; [Zhuang, Yueting] Zhejiang Univ, Hangzhou, Zhejiang, Peoples R China	Tsinghua University; University of Technology Sydney; Zhejiang University	Yang, Y (corresponding author), Univ Technol, QCIS, Sydney, NSW, Australia.	ganchuang1990@gmail.com; yee.i.yang@gmail.com; zhulinchao7@gmail.com; zhaodeli@gmail.com; yzhuang@zju.edu.cn	yang, yang/GVT-5210-2022; Yang, Yi/B-9273-2017; Zhu, Linchao/AAE-6700-2020; yang, yang/GWB-9426-2022; yang, yang/HGT-7999-2022	Yang, Yi/0000-0002-0512-880X; Zhu, Linchao/0000-0002-4093-7557; 	973 Program [2012CB316400]; National Natural Science Foundation of China [61033001, 61361136003]; ARC DECRA [DE130101311]; ACR DP [DP150103008]	973 Program(National Basic Research Program of China); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); ARC DECRA(Australian Research Council); ACR DP	This work was partially supported by the 973 Program (No. 2012CB316400), partially supported by the National Natural Science Foundation of China Grant 61033001, 61361136003, and partially supported by the ARC DECRA (DE130101311), the ACR DP (DP150103008). This work was done when Chuang Gan was a visiting student at Zhejiang University.	Akata Z, 2013, PROC CVPR IEEE, P819, DOI 10.1109/CVPR.2013.111; Blank M, 2005, IEEE I CONF COMP VIS, P1395; Cai Junjie, 2012, P 20 ACM INT C MULT, P873; Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32; Chen M, 2009, MOSIFT RECOGNIZING H; Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114; Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772; Frome Andrea, 2013, NEURIPS; Fu YW, 2015, IEEE T PATTERN ANAL, V37, P2332, DOI 10.1109/TPAMI.2015.2408354; Fu YW, 2014, LECT NOTES COMPUT SC, V8690, P584, DOI 10.1007/978-3-319-10605-2_38; Gabrilovich E, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1606; Guadarrama S, 2013, IEEE I CONF COMP VIS, P2712, DOI 10.1109/ICCV.2013.337; Hauptmann A, 2007, IEEE T MULTIMEDIA, V9, P958, DOI 10.1109/TMM.2007.900150; Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407; Jiang YG, 2013, INT J MULTIMED INF R, V2, P73, DOI 10.1007/s13735-012-0024-2; Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353; Kankuekul P, 2012, PROC CVPR IEEE, P3657, DOI 10.1109/CVPR.2012.6248112; Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594; Lan Z.-Z., 2012, DOUBLE FUSION MULTIM; Lan Z. Z., 2013, TRECVID 2013 WORKSH, V1, P5; Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7; Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756; Liu JE, 2013, IEEE WORK APP COMP, P339, DOI 10.1109/WACV.2013.6475038; Ma Z., 2013, P 21 ACM INT C MULT, P293; Ma ZG, 2014, INT J COMPUT VISION, V109, P60, DOI 10.1007/s11263-014-0717-5; Ma Z, 2013, IEEE T MULTIMEDIA, V15, P1628, DOI 10.1109/TMM.2013.2264928; Oneata D., 2013, ICCV; Reddy KK, 2013, MACH VISION APPL, V24, P971, DOI 10.1007/s00138-012-0450-4; Rohrbach M, 2012, LECT NOTES COMPUT SC, V7572, P144, DOI 10.1007/978-3-642-33718-5_11; Rohrbach M, 2011, PROC CVPR IEEE, P1641, DOI 10.1109/CVPR.2011.5995627; Rohrbach M, 2010, PROC CVPR IEEE, P910, DOI 10.1109/CVPR.2010.5540121; Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806; Sanchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x; Socher Richard, 2013, NEURIPS; Soomro K., 2012, CRCVTR1201; Sun C., 2015, ICCV; Tang KV, 2013, IEEE I CONF COMP VIS, P2696, DOI 10.1109/ICCV.2013.335; Torresani L, 2010, LECT NOTES COMPUT SC, V6311, P776, DOI 10.1007/978-3-642-15549-9_56; Tran D., 2014, ARXIV; Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441; Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8; Wang S, 2012, PROC CVPR IEEE, P1370, DOI 10.1109/CVPR.2012.6247823; Yang Y, 2015, INT J COMPUT VISION, V113, P113, DOI 10.1007/s11263-014-0781-x; Yu FLX, 2013, PROC CVPR IEEE, P771, DOI 10.1109/CVPR.2013.105	46	36	39	1	18	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	OCT	2016	120	1					61	77		10.1007/s11263-016-0893-6	http://dx.doi.org/10.1007/s11263-016-0893-6			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	DU3DX					2022-12-18	WOS:000382092100005
J	Aflalo, Y; Dubrovina, A; Kimmel, R				Aflalo, Yonathan; Dubrovina, Anastasia; Kimmel, Ron			Spectral Generalized Multi-dimensional Scaling	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Spectral domain; GMDS; Shape matching	SHAPE; FRAMEWORK	Multidimensional scaling (MDS) is a family of methods that embed a given set of points into a simple, usually flat, domain. The points are assumed to be sampled from some metric space, and the mapping attempts to preserve the distances between each pair of points in the set. Distances in the target space can be computed analytically in this setting. Generalized MDS is an extension that allows mapping one metric space into another, that is, MDS into target spaces in which distances are evaluated numerically rather than analytically. Here, we propose an efficient approach for computing such mappings between surfaces based on their natural spectral decomposition, where the surfaces are treated as sampled metric-spaces. The resulting spectral-GMDS procedure enables efficient embedding by incorporating smoothness of the metric structure into the problem, thereby substantially reducing the complexity involved in its solution while practically overcoming its non-convex nature. The method is compared to existing techniques that compute dense correspondence between shapes. Numerical experiments of the proposed method demonstrate its efficiency and accuracy compared to state-of-the-art approaches especially when isometry invariance is a dominant property.	[Aflalo, Yonathan; Dubrovina, Anastasia; Kimmel, Ron] Technion Israel Inst Technol, Haifa, Israel	Technion Israel Institute of Technology	Aflalo, Y (corresponding author), Technion Israel Inst Technol, Haifa, Israel.	yaflalo@cs.technion.ac.il; nastyad@cs.technion.ac.il; ron@cs.technion.ac.il			European Communitys FP7-ERC program [267414]	European Communitys FP7-ERC program	The authors would like to thank Alon Shtern and Matan Sela for stimulating discussions throughout this research. This work has been supported by Grant agreement No. 267414 of the European Communitys FP7-ERC program.	Aflalo Y, 2015, SIAM J IMAGING SCI, V8, P1141, DOI 10.1137/140977680; Aflalo Y, 2015, P NATL ACAD SCI USA, V112, P2942, DOI 10.1073/pnas.1401651112; Aflalo Y, 2013, P NATL ACAD SCI USA, V110, P18052, DOI 10.1073/pnas.1308708110; Aflalo Y, 2013, SIAM J IMAGING SCI, V6, P1579, DOI 10.1137/120888107; Anguelov D., 2004, ADV NEURAL INFORM PR, P33; Aubry M, 2011, IEEE I CONF COMP VIS, P1411, DOI 10.1109/ICCV.2011.6126396; Baloch S., 2005, ICIP 2005, V3; BenTal A, 1997, SIAM J OPTIMIZ, V7, P347, DOI 10.1137/S1052623493259215; BERARD P, 1994, GEOM FUNCT ANAL, V4, P373, DOI 10.1007/BF01896401; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Borg I., 1997, MODERN MULTIDIMENSIO; Bronstein AM, 2008, MONOGR COMPUT SCI, P1, DOI 10.1007/978-0-387-73301-2_1; Bronstein AM, 2010, INT J COMPUT VISION, V89, P266, DOI 10.1007/s11263-009-0301-6; Bronstein AM, 2006, P NATL ACAD SCI USA, V103, P1168, DOI 10.1073/pnas.0508601103; Bronstein Michael M, 2011, IEEE Trans Pattern Anal Mach Intell, V33, P1065, DOI 10.1109/TPAMI.2010.210; Burago D., 2001, GRADUATE STUDIEMAT; CHEN Y, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P2724, DOI 10.1109/ROBOT.1991.132043; Coifman RR, 2006, APPL COMPUT HARMON A, V21, P5, DOI 10.1016/j.acha.2006.04.006; Dubrovina A., 2010, P S 3D DAT PROC VIS; Gebal K, 2009, COMPUT GRAPH FORUM, V28, P1405, DOI 10.1111/j.1467-8659.2009.01517.x; GONZALEZ TF, 1985, THEOR COMPUT SCI, V38, P293, DOI 10.1016/0304-3975(85)90224-5; GROMOV M., 1981, TEXTES MATH, V1; Gu XF, 2004, IEEE T MED IMAGING, V23, P949, DOI 10.1109/TMI.2004.831226; HOCHBAUM DS, 1985, MATH OPER RES, V10, P180, DOI 10.1287/moor.10.2.180; Jin M, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P267, DOI 10.1109/VISUAL.2004.75; Kim VG, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964974; Levy B, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P66; Lipman Y, 2011, ADV MATH, V227, P1047, DOI 10.1016/j.aim.2011.01.020; Lipman Y, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531378; Mateus D., 2008, PROC CVPR IEEE, P1, DOI DOI 10.1109/CVPR.2008.4587538; Memoli F, 2005, FOUND COMPUT MATH, V5, P313, DOI 10.1007/s10208-004-0145-y; MEMOLI F., 2007, S POINT BAS GRAPH, P81, DOI DOI 10.2312/SPBG/SPBG07/081-090; Ovsjanikov M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185526; Pinkall U., 1993, EXPT MATH, V2, P15, DOI DOI 10.1080/10586458.1993.10504266; Pokrass J, 2013, COMPUT GRAPH FORUM, V32, P459, DOI 10.1111/cgf.12066; Raviv D, 2012, LECT NOTES COMPUT SC, V6667, P604, DOI 10.1007/978-3-642-24785-9_51; Rustamov R., 2013, SIGGRAPH; Sahillioglu Y, 2011, COMPUT GRAPH FORUM, V30, P1461, DOI 10.1111/j.1467-8659.2011.02020.x; SCHWARTZ EL, 1989, IEEE T PATTERN ANAL, V11, P1005, DOI 10.1109/34.35506; Shtern Alon, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P499, DOI 10.1109/3DV.2014.24; Shtern A, 2015, COMPUT VIS IMAGE UND, V140, P21, DOI 10.1016/j.cviu.2015.02.004; Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x; Zaharescu A, 2009, PROC CVPR IEEE, P373, DOI 10.1109/CVPRW.2009.5206748; Zeng W, 2012, NUMER MATH, V121, P671, DOI 10.1007/s00211-012-0446-z; Zeng Y, 2010, PROC CVPR IEEE, P382, DOI 10.1109/CVPR.2010.5540189	45	36	37	0	3	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2016	118	3					380	392		10.1007/s11263-016-0883-8	http://dx.doi.org/10.1007/s11263-016-0883-8			13	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	DP9AM		Green Submitted			2022-12-18	WOS:000378789100006
J	Zhuang, LS; Chan, TH; Yang, AY; Sastry, SS; Ma, Y				Zhuang, Liansheng; Chan, Tsung-Han; Yang, Allen Y.; Sastry, S. Shankar; Ma, Yi			Sparse Illumination Learning and Transfer for Single-Sample Face Recognition with Image Corruption and Misalignment	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Single-sample face recognition; Illumination dictionary learning; Sparse illumination transfer; Face alignment; Robust face recognition	ALGORITHM; MODELS	Single-sample face recognition is one of the most challenging problems in face recognition. We propose a novel algorithm to address this problem based on a sparse representation based classification (SRC) framework. The new algorithm is robust to image misalignment and pixel corruption, and is able to reduce required gallery images to one sample per class. To compensate for the missing illumination information traditionally provided by multiple gallery images, a sparse illumination learning and transfer (SILT) technique is introduced. The illumination in SILT is learned by fitting illumination examples of auxiliary face images from one or more additional subjects with a sparsely-used illumination dictionary. By enforcing a sparse representation of the query image in the illumination dictionary, the SILT can effectively recover and transfer the illumination and pose information from the alignment stage to the recognition stage. Our extensive experiments have demonstrated that the new algorithms significantly outperform the state of the art in the single-sample regime and with less restrictions. In particular, the single-sample face alignment accuracy is comparable to that of the well-known Deformable SRC algorithm using multiple gallery images per class. Furthermore, the face recognition accuracy exceeds those of the SRC and Extended SRC algorithms using hand labeled alignment initialization.	[Zhuang, Liansheng] Univ Sci & Technol China, CAS Key Lab Electromagnet Space Informat, Hefei, Peoples R China; [Chan, Tsung-Han] Adv Digital Sci Ctr, Singapore, Singapore; [Yang, Allen Y.; Sastry, S. Shankar] Univ Calif Berkeley, Dept EECS, Berkeley, CA 94720 USA; [Ma, Yi] ShanghaiTech Univ, Shanghai, Peoples R China	Chinese Academy of Sciences; University of Science & Technology of China, CAS; University of California System; University of California Berkeley; ShanghaiTech University	Yang, AY (corresponding author), Univ Calif Berkeley, Dept EECS, Berkeley, CA 94720 USA.	lszhuang@ustc.edu.cn; thchan@ieee.org; yang@eecs.berkeley.edu; sastry@eecs.berkeley.edu; mayi@shanghaitech.edu.cn			ARO [63092-MA-II]; DARPA [FA8650-11-1-7153]; ONR [N00014-09-1-0230]; NSF [CCF09-64215]; NSFC [61103134, 61371192]; Science Foundation for Outstanding Young Talent of Anhui Province [BJ2101020001]	ARO; DARPA(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); ONR(Office of Naval Research); NSF(National Science Foundation (NSF)); NSFC(National Natural Science Foundation of China (NSFC)); Science Foundation for Outstanding Young Talent of Anhui Province	The work was supported in part by ARO 63092-MA-II, DARPA FA8650-11-1-7153, ONR N00014-09-1-0230, NSF CCF09-64215, NSFC No. 61103134 and 61371192, and the Science Foundation for Outstanding Young Talent of Anhui Province (BJ2101020001).	Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228; Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016; CHEN X., 2011, P IEEE INT C COMP VI; Cootes Timothy F, 1998, P EUR C COMP VIS; Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30; Do C., 2005, P NIPS; Elhamifar E, 2012, IEEE T SIGNAL PROCES, V60, P4094, DOI 10.1109/TSP.2012.2196694; Gabay D., 1976, Computers & Mathematics with Applications, V2, P17, DOI 10.1016/0898-1221(76)90003-1; Ganesh A., 2011, COMPRESSED SENSING T; Gross R., 2008, P 8 IEEE INT C AUT F; Gu L., 2008, P EUR C COMP VIS; Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606; Ho J., 2003, P IEEE INT C COMP VI; Horn R. A., 1986, MATRIX ANAL; Huang J., 2008, P IEEE INT C COMP VI; Lampert Christoph H., 2009, P IEEE INT C COMP VI; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Li Xiao-Wen, 2013, P IEEE INT C COMP VI; Liang L., 2008, P EUR C COMP VIS; Lucas B. D., 1981, ITERATIVE IMAGE REGI; Peers P., 2007, P ACM SIGGRAPH; Quattoni A., 2008, P IEEE INT C COMP VI; Saragih J., 2009, P IEEE INT C COMP VI; Shashua A, 2001, IEEE T PATTERN ANAL, V23, P129, DOI 10.1109/34.908964; SPIELMAN D. A., 2012, JMLR WORKSHOP C P; TSENG P, 1991, SIAM J CONTROL OPTIM, V29, P119, DOI 10.1137/0329006; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112; Wright J, 2010, IEEE T INFORM THEORY, V56, P3540, DOI 10.1109/TIT.2010.2048473; Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79; Yan SC, 2003, IMAGE VISION COMPUT, V21, P69, DOI 10.1016/S0262-8856(02)00136-1; Yan SC, 2010, IEEE T IMAGE PROCESS, V19, P1087, DOI 10.1109/TIP.2009.2038765; Yang AY, 2013, IEEE T IMAGE PROCESS, V22, P3234, DOI 10.1109/TIP.2013.2262292; Yang M., 2012, P EUR C COMP VIS; Zhang L, 2012, ARXIV12042358; Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342; Zhuang L., 2013, P IEEE INT C COMP VI	40	36	40	0	20	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2015	114	2-3			SI		272	287		10.1007/s11263-014-0749-x	http://dx.doi.org/10.1007/s11263-014-0749-x			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	CP7MJ		Green Submitted			2022-12-18	WOS:000360071900010
J	Goldlucke, B; Aubry, M; Kolev, K; Cremers, D				Goldluecke, Bastian; Aubry, Mathieu; Kolev, Kalin; Cremers, Daniel			A Super-Resolution Framework for High-Accuracy Multiview Reconstruction	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Multi-view 3D reconstruction; Texture reconstruction; Super-resolution; Camera calibration; Variational methods	CONTINUOUS GLOBAL OPTIMIZATION; MULTIPLE; CALIBRATION	We present a variational framework to estimate super-resolved texture maps on a 3D geometry model of a surface from multiple images. Given the calibrated images and the reconstructed geometry, the proposed functional is convex in the super-resolution texture. Using a conformal atlas of the surface, we transform the model from the curved geometry to the flat charts and solve it using state-of-the-art and provably convergent primal-dual algorithms. In order to improve image alignment and quality of the texture, we extend the functional to also optimize for a normal displacement map on the surface as well as the camera calibration parameters. Since the sub-problems for displacement and camera parameters are non-convex, we revert to relaxation schemes in order to robustly estimate a minimizer via sequential convex programming. Experimental results confirm that the proposed super-resolution framework allows to recover textured models with significantly higher level-of-detail than the individual input images.	[Goldluecke, Bastian] Heidelberg Univ, Heidelberg Collaboratory Image Proc, Heidelberg, Germany; [Aubry, Mathieu; Cremers, Daniel] Tech Univ Munich, Dept Comp Sci, D-80290 Munich, Germany; [Kolev, Kalin] ETH, Dept Comp Sci, Zurich, Switzerland	Ruprecht Karls University Heidelberg; Technical University of Munich; Swiss Federal Institutes of Technology Domain; ETH Zurich	Goldlucke, B (corresponding author), Heidelberg Univ, Heidelberg Collaboratory Image Proc, Heidelberg, Germany.	bastian.goldluecke@iwr.uni-heidelberg.de; mathieu.aubry@in.tum.de; kalin.kolev@inf.ethz.ch; cremers@tum.de		Aubry, Mathieu/0000-0002-3804-0193	ERC	ERC(European Research Council (ERC)European Commission)	We thank Martin R. Oswald for providing the visualization in Fig. 1. This work was supported by the ERC Starting Grant "Convex Vision".	Allne C., 2008, 19 INT C PATT REC; [Anonymous], 2006, MPS SIAM SERIES OPTI; Aubry M., 2011, P ICCV; Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210; Bernardini F, 2001, IEEE T VIS COMPUT GR, V7, P318, DOI 10.1109/2945.965346; Bertalmio M, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P186, DOI 10.1109/VLSM.2001.938899; Bhat P., 2007, EUR S REND; Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0; Capel D, 2001, PROC CVPR IEEE, P627; Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1; Donnelly W., 2005, GPU GEMS 2 CHAPTER P; Eisemann M, 2008, COMPUT GRAPH FORUM, V27, P409, DOI 10.1111/j.1467-8659.2008.01138.x; Floater MS, 2005, MATH VIS, P157, DOI 10.1007/3-540-26808-1_9; Fransens R, 2007, COMPUT VIS IMAGE UND, V106, P106, DOI 10.1016/j.cviu.2005.09.011; Furukawa Y, 2009, INT J COMPUT VISION, V84, P257, DOI 10.1007/s11263-009-0232-2; Goldluecke B., 2009, PATT REC P DAGM; Goldluecke B., 2012, SIAM J IMAGING SCI; Goldluecke B., 2009, P ICCV; Hartley R., 2004, ROBOTICA; Jin HL, 2008, INT J COMPUT VISION, V76, P245, DOI 10.1007/s11263-007-0055-y; Klein George, 2007, P1; Kolev K, 2010, EUR C COMP VIS ECCV; Kolev K, 2007, LECT NOTES COMPUT SC, V4679, P441; Kolev K, 2009, INT J COMPUT VISION, V84, P80, DOI 10.1007/s11263-009-0233-1; Lempitsky V., 2007, IEEE C COMP VIS PATT, P1, DOI [DOI 10.1109/CVPR.2007.383078, DOI 10.1109/ICCV.2007.4408907]; Lensch HPA, 2001, GRAPH MODELS, V63, P245, DOI 10.1006/gmod.2001.0554; Levy B., 2003, ACM T GRAPHIC, V21, P362; Lui L. M., 2005, VARIATIONAL GEOMETRI, P309; Mitzel D., 2009, PATT REC P DAGM JEN; Pock T., 2008, P ECCV; Pock T., 2009, P ICCV KYOT JAP; Rav-Acha A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360616; RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F; Schoenemann T, 2008, P IEEE C COMP VIS PA, P1; Seitz S.M., 2006, P IEEE COMPUTER SOC, P519; Snavely N., 2006, P ACM SIGGRAPH; Sroubek F, 2007, IEEE T IMAGE PROCESS, V16, P2322, DOI 10.1109/TIP.2007.903256; Stam J, 2003, ACM T GRAPHIC, V22, P724, DOI 10.1145/882262.882338; Strecha C., 2008, P CVPR; Theoloalt C, 2007, IEEE T VIS COMPUT GR, V13, P663, DOI 10.1109/TVCG.2007.1006; Triggs B., 2000, LECT NOTES COMPUTER, V1883, P298, DOI [DOI 10.1007/3-540-44480-7, DOI 10.1007/3-540-44480-7_21]; Unal G, 2007, IEEE T PATTERN ANAL, V29, P1322, DOI 10.1109/TPAMI.2007.1035; Wang YL, 2005, IEEE I CONF COMP VIS, P1061; Wanner S., 2012, P ECCV; Xianfeng Gu, 2003, Symposium on Geometry Processing, P127; Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22	46	36	37	4	34	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2014	106	2					172	191		10.1007/s11263-013-0654-8	http://dx.doi.org/10.1007/s11263-013-0654-8			20	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	290UR		Green Submitted, Green Accepted			2022-12-18	WOS:000329784300004
J	Lorenzi, M; Pennec, X				Lorenzi, Marco; Pennec, Xavier			Geodesics, Parallel Transport & One-Parameter Subgroups for Diffeomorphic Image Registration	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							ATLAS ESTIMATION; CONSTRUCTION; GEOMETRY; FIELDS	Computational anatomy aims at developing models to understand the anatomical variability of organs and tissues. A widely used and validated instrument for comparing the anatomy in medical images is non-linear diffeomorphic registration which is based on a rich mathematical background. For instance, the "large deformation diffeomorphic metric mapping" (LDDMM) framework defines a Riemannian setting by providing a right invariant metric on the tangent spaces, and solves the registration problem by computing geodesics parametrized by time-varying velocity fields. A simpler alternative based on stationary velocity fields (SVF) has been proposed, using the one-parameter subgroups from Lie groups theory. In spite of its better computational efficiency, the geometrical setting of the SVF is more vague, especially regarding the relationship between one-parameter subgroups and geodesics. In this work, we detail the properties of finite dimensional Lie groups that highlight the geometric foundations of one-parameter subgroups. We show that one can define a proper underlying geometric structure (an affine manifold) based on the canonical Cartan connections, for which one-parameter subgroups and their translations are geodesics. This geometric structure is perfectly compatible with all the group operations (left, right composition and inversion), contrarily to left- (or right-) invariant Riemannian metrics. Moreover, we derive closed-form expressions for the parallel transport. Then, we investigate the generalization of such properties to infinite dimensional Lie groups. We suggest that some of the theoretical objections might actually be ruled out by the practical implementation of both the LDDMM and the SVF frameworks for image registration. This leads us to a more practical study comparing the parameterization (initial velocity field) of metric and Cartan geodesics in the specific optimization context of longitudinal and inter-subject image registration.Our experimental results suggests that stationarity is a good approximation for longitudinal deformations, while metric geodesics notably differ from stationary ones for inter-subject registration, which involves much larger and non-physical deformations. Then, we turn to the practical comparison of five parallel transport techniques along one-parameter subgroups. Our results point out the fundamental role played by the numerical implementation, which may hide the theoretical differences between the different schemes. Interestingly, even if the parallel transport generally depends on the path used, an experiment comparing the Cartan parallel transport along the one-parameter subgroup and the LDDMM (metric) geodesics from inter-subject registration suggests that our parallel transport methods are not so sensitive to the path.	[Lorenzi, Marco; Pennec, Xavier] INRIA, Asclepios Res Grp, Sophia Antipolis, France; [Lorenzi, Marco] IRCCS San Giovanni di Dio, LENITEM, Brescia, Italy	Inria; IRCCS Fatebenefratelli	Lorenzi, M (corresponding author), INRIA, Asclepios Res Grp, Sophia Antipolis, France.	marco.lorenzi@inria.fr; xavier.pennec@inria.fr	Pennec, Xavier/L-2537-2013; Lorenzi, Marco/R-3149-2017	Pennec, Xavier/0000-0002-6617-7664; Lorenzi, Marco/0000-0003-0521-2881	European Research Council (ERC advanced Grant MedYMA); ANR blanc Karametria; EU project Care4Me	European Research Council (ERC advanced Grant MedYMA)(European Research Council (ERC)); ANR blanc Karametria(French National Research Agency (ANR)); EU project Care4Me	This work was partially funded by the European Research Council (ERC advanced Grant MedYMA), ANR blanc Karametria and the EU project Care4Me.	Arsigny V, 2006, LECT NOTES COMPUT SC, V4190, P924; Ashburner J, 2007, NEUROIMAGE, V38, P95, DOI 10.1016/j.neuroimage.2007.07.007; AtlasWerks, 2012, SET HIGH PERF TOOLS; Bossa M., 2010, P SPAT TEMP IM AN WO; Bossa M, 2007, LECT NOTES COMPUT SC, V4791, P667; Cachier P, 2004, J MATH IMAGING VIS, V20, P251, DOI 10.1023/B:JMIV.0000024042.88755.4f; Cartan E, 1926, P K AKAD WET-AMSTERD, V29, P803; do Carmo M. P., 1992, RIEMANNIAN GEOMETRY; Durrleman S, 2011, NEUROIMAGE, V55, P1073, DOI 10.1016/j.neuroimage.2010.11.056; Durrleman S, 2009, LECT NOTES COMPUT SC, V5761, P297, DOI 10.1007/978-3-642-04268-3_37; Gallot S., 1993, RIEMANNIAN GEOMETRY; Galluzzi S, 2009, AGING CLIN EXP RES, V21, P266; Helgason S., 1978, DIFFERENTIAL GEOMETR, V80; Hernandez M, 2009, INT J COMPUT VISION, V85, P291, DOI 10.1007/s11263-009-0219-z; Joshi S, 2004, NEUROIMAGE, V23, pS151, DOI 10.1016/j.neuroimage.2004.07.068; Joshi SC, 2000, IEEE T IMAGE PROCESS, V9, P1357, DOI 10.1109/83.855431; Khesin B, 2009, GEOMETRY INFINITE DI; Kheyfets A, 2000, INT J THEOR PHYS, V39, P2891, DOI 10.1023/A:1026473418439; Kolev B., 2007, GROUPES LIE MECANIQU; Lorenzi M, 2011, LECT NOTES COMPUT SC, V6892, P663, DOI 10.1007/978-3-642-23629-7_81; Lorenzi M, 2011, LECT NOTES COMPUT SC, V6801, P463, DOI 10.1007/978-3-642-22092-0_38; Mansi T, 2011, IEEE T MED IMAGING, V30, P1605, DOI 10.1109/TMI.2011.2135375; Mansi T, 2011, INT J COMPUT VISION, V92, P92, DOI 10.1007/s11263-010-0405-z; Miller MI, 2002, ANNU REV BIOMED ENG, V4, P375, DOI 10.1146/annurev.bioeng.4.092101.125733; Milnor J., 1984, RELATIVITY GROUPS TO; Misner C. W., 1973, GRAVITATION; Modat M., 2011, P SPIE MED IMAGING 2; Pennec X., 2012, MATRIX INFORM GEOMET; Postnikov M. M., 2001, GEOMETRY; Rao A, 2004, IEEE T MED IMAGING, V23, P1065, DOI 10.1109/TMI.2004.828681; Schild A., 1970, COMMUNICATION   0119; Schmid R., 2004, J GEOMETRY SYMMETRY, V1, P167; Schmid R, 2010, ADV MATH PHYS, V2010, DOI 10.1155/2010/280362; Seiler C, 2011, LECT NOTES COMPUT SC, V6892, P631, DOI 10.1007/978-3-642-23629-7_77; Shattuck DW, 2008, NEUROIMAGE, V39, P1064, DOI 10.1016/j.neuroimage.2007.09.031; Thompson PM, 2003, J NEUROSCI, V23, P994; Vercauteren T, 2008, LECT NOTES COMPUT SC, V5241, P754, DOI 10.1007/978-3-540-85988-8_90; Younes L., 2010, APPL MATH SCI, V171; Younes L, 2008, J MATH IMAGING VIS, V32, P41, DOI 10.1007/s10851-008-0074-5; Younes L, 2007, Q APPL MATH, V65, P113, DOI 10.1090/S0033-569X-07-01027-5	40	36	36	0	24	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	2013	105	2			SI		111	127		10.1007/s11263-012-0598-4	http://dx.doi.org/10.1007/s11263-012-0598-4			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	207YP		Green Submitted			2022-12-18	WOS:000323641100002
J	Schoenemann, T; Kahl, F; Masnou, S; Cremers, D				Schoenemann, Thomas; Kahl, Fredrik; Masnou, Simon; Cremers, Daniel			A Linear Framework for Region-Based Image Segmentation and Inpainting Involving Curvature Penalization	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Curvature regularity; Image segmentation; Inpainting; Linear programming; Cell complexes		We present the first method to handle curvature regularity in region-based image segmentation and inpainting that is independent of initialization. To this end we start from a new formulation of length-based optimization schemes, based on surface continuation constraints, and discuss the connections to existing schemes. The formulation is based on a cell complex and considers basic regions and boundary elements. The corresponding optimization problem is cast as an integer linear program. We then show how the method can be extended to include curvature regularity, again cast as an integer linear program. Here, we are considering pairs of boundary elements to reflect curvature. Moreover, a constraint set is derived to ensure that the boundary variables indeed reflect the boundary of the regions described by the region variables. We show that by solving the linear programming relaxation one gets reasonably close to the global optimum, and that curvature regularity is indeed much better suited in the presence of long and thin objects compared to standard length regularity.	[Schoenemann, Thomas; Kahl, Fredrik] Lund Univ, Ctr Math Sci, Lund, Sweden; [Masnou, Simon] Univ Lyon 1, CNRS, Inst Camille Jordan, F-69622 Villeurbanne, France; [Cremers, Daniel] Tech Univ Munich, Dept Comp Sci, Munich, Germany	Lund University; UDICE-French Research Universities; Universite Claude Bernard Lyon 1; Centre National de la Recherche Scientifique (CNRS); Ecole Centrale de Lyon; Institut National des Sciences Appliquees de Lyon - INSA Lyon; Universite Jean Monnet; Technical University of Munich	Schoenemann, T (corresponding author), Lund Univ, Ctr Math Sci, Lund, Sweden.	thomas_schoenemann@yahoo.de			Swedish Foundation for Strategic Research (SSF); European Research Council (GlobalVision) [209480]; French ANR; ERC	Swedish Foundation for Strategic Research (SSF)(Swedish Foundation for Strategic Research); European Research Council (GlobalVision); French ANR(French National Research Agency (ANR)); ERC(European Research Council (ERC)European Commission)	Thomas Schoenemann and Fredrik Kahl were funded by the Swedish Foundation for Strategic Research (SSF) through the programmes Future Research Leaders and Wearable Visual Information Systems, and by the European Research Council (GlobalVision grant no. 209480). Simon Masnou would like to acknowledge funding by the French ANR Freedom project. Daniel Cremers' work was financed through the ERC starting grant "ConvexVision".	AMINI AA, 1990, IEEE T PATTERN ANAL, V12, P855, DOI 10.1109/34.57681; Bertalmio M., 2001, ACM SIGGRAPH JUL; Bornemann F, 2007, J MATH IMAGING VIS, V28, P259, DOI 10.1007/s10851-007-0017-6; Boykov Y., 2001, IEEE INT C COMP VIS; Boykov Y., 2003, IEEE INT C COMP VIS; Bruckstein A., 2001, APPL ANAL, V79, P137; Cao F., 2012, SIAM J IMAGING UNPUB; Chan TF, 2003, SIAM J APPL MATH, V63, P564; Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291; Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286; Dantzig GB, 1997, LINEAR PROGRAMMING; El-Zehiry N. Y., 2010, IEEE COMP SOC C COMP; Esedoglu S, 2003, J MATH IMAGING VIS, V18, P7, DOI 10.1023/A:1021837026373; Goldlucke B., 2011, IEEE INT C COMP VIS; Grady L, 2010, IEEE T PATTERN ANAL, V32, P321, DOI 10.1109/TPAMI.2008.289; GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x; Kanizsa G., 1974, GIORNALE ITALIANO PS, V9, P93; Klodt M., 2008, EUR C COMP VIS ECCV; Masnou S, 2002, IEEE T IMAGE PROCESS, V11, P68, DOI 10.1109/83.982815; Masnou S., 1998, INT C IM PROC ICIP C; MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503; NITZBERG M, 1993, LNCS, V662; PARENT P, 1989, IEEE T PATTERN ANAL, V11, P823, DOI 10.1109/34.31445; Rudin W, 1987, REAL COMPLEX ANAL; Schoenemann T., 2011, INT WORKSH EN MIN ME; SCHOENEMANN T, 2009, IEEE INT C COMP VIS; Schoenemann T., 2007, IEEE INT C COMP VIS; Strandmark P., 2011, INT WORKSH EN MIN ME; Sullivan J. M., 1992, THESIS PRINCETON U P; SULLIVAN JM, 1994, MOTION BY MEAN CURVATURE AND RELATED TOPICS, P186; Toshev A., 2010, IEEE COMP SOC C COMP; Tschumperle D, 2006, INT J COMPUT VISION, V68, P65, DOI 10.1007/s11263-006-5631-z; Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1; Weickert J., 2003, PATT REC P DAGM MAGD; Ye Y, 1997, INTERIOR POINT ALGOR	37	36	36	0	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2012	99	1					53	68		10.1007/s11263-012-0518-7	http://dx.doi.org/10.1007/s11263-012-0518-7			16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	935NG		Green Submitted			2022-12-18	WOS:000303525200003
J	Li, J; Gong, SG; Xiang, T				Li, Jian; Gong, Shaogang; Xiang, Tao			Learning Behavioural Context	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Visual context; Behavioural context; Video-based behaviour recognition; Activity-based scene segmentation; Cascaded topic models; Anomaly detection	OBJECTS	We propose a novel framework for automatic discovering and learning of behavioural context for video-based complex behaviour recognition and anomaly detection. Our work differs from most previous efforts on learning visual context in that our model learns multi-scale spatio-temporal rather than static context. Specifically three types of behavioural context are investigated: behaviour spatial context, behaviour correlation context, and behaviour temporal context. To that end, the proposed framework consists of an activity-based semantic scene segmentation model for learning behaviour spatial context, and a cascaded probabilistic topic model for learning both behaviour correlation context and behaviour temporal context at multiple scales. These behaviour context models are deployed for recognising non-exaggerated multi-object interactive and co-existence behaviours in public spaces. In particular, we develop a method for detecting subtle behavioural anomalies against the learned context. The effectiveness of the proposed approach is validated by extensive experiments carried out using data captured from complex and crowded outdoor scenes.	[Li, Jian; Gong, Shaogang; Xiang, Tao] Queen Mary Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England	University of London; Queen Mary University London	Li, J (corresponding author), Queen Mary Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England.	jianli@eecs.qmul.ac.uk; sgg@eecs.qmul.ac.uk; txiang@eecs.qmul.ac.uk			UK Engineering and Physical Sciences Research Council [EP/E028594/1]; Engineering and Physical Sciences Research Council [EP/E028594/1] Funding Source: researchfish; EPSRC [EP/E028594/1] Funding Source: UKRI	UK Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	We shall thank Xiaogang Wang for providing us with the MIT Traffic Dataset for our comparative experiments and evaluation. This work was partially supported by the UK Engineering and Physical Sciences Research Council (grant number EP/E028594/1).	Ali S., 2008, EUR C COMP VIS MARS, VII; Bar M, 2003, NEURON, V38, P347, DOI 10.1016/S0896-6273(03)00167-3; Bar M, 1996, PERCEPTION, V25, P343, DOI 10.1068/p250343; Bar M, 2004, NAT REV NEUROSCI, V5, P617, DOI 10.1038/nrn1476; Belongie S, 2007, INT C COMP VIS RIO D; BIEDERMAN I, 1982, COGNITIVE PSYCHOL, V14, P143, DOI 10.1016/0010-0285(82)90007-X; Blei D., 2007, ADV NEURAL INFORM PR; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; BREITENSTEIN MD, 2008, BRIT MACH VIS C LEED; Canini K. R., 2009, INT C ART INT STAT; Cao L., 2007, INT C COMP VIS; Carbonetto P., 2004, EUR C COMP VIS PRAG; Chi Y., 2007, ACM SIGKDD INT C KNO; Duan LX, 2009, PROC CVPR IEEE, P1375, DOI [10.1109/CVPR.2009.5206747, 10.1109/CVPRW.2009.5206747]; GALLEGUILLOS C, 2008, IEEE C COMP VIS PATT; Greenhill D, 2008, IMAGE VISION COMPUT, V26, P430, DOI 10.1016/j.imavis.2006.12.007; Griffiths T., 2005, INFINITE LATENT FEAT; Griffiths T., 2007, NEURAL INFORM PROCES; Gupta A., 2008, EUR C COMP VIS MARS; Haines T., 2009, IACM WORKSH MULT PER; Heitz G, 2008, EUR C COMP VIS MARS; Hofmann T, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P289; Hofmann Thomas, 1999, SIGIR; Hospedales T. M., 2009, INT C COMP VIS; Kuettel D, 2010, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2010.5539869; Kumar S., 2005, INT C COMP VIS BEIJ; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Li J, 2008, BRIT MACH VIS C LEED, P193; Li J, 2008, LECT NOTES COMPUT SC, V5305, P383; Loy CC, 2009, PROC CVPR IEEE, P1988, DOI 10.1109/CVPRW.2009.5206827; Lucas B. D., 1981, IJCAI, P121, DOI DOI 10.5555/1623264.1623280; Makris D, 2005, IEEE T SYST MAN CY B, V35, P397, DOI 10.1109/TSMCB.2005.846652; Makris D, 2004, PROC CVPR IEEE, P205; Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800; Marszalek M., 2009, IEEE C COMP VIS PATT; Murphy K., 2003, NEURAL INFORM PROCES; Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4; PALMER SE, 1975, MEM COGNITION, V3, P519, DOI 10.3758/BF03197524; Russell D., 2006, BRIT MACH VIS C ED U; SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136; Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688; Singhal A., 2003, IEEE INT C COMP VIS; Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302; Wallach H., 2009, INT C MACH LEARN MON; Wallach H, 2006, INT C MACH LEARN PIT; Wang X., 2008, IEEE C COMP VIS PATT; Wang XG, 2006, LECT NOTES COMPUT SC, V3953, P110, DOI 10.1007/11744078_9; Wang XG, 2010, IEEE T PATTERN ANAL, V32, P56, DOI 10.1109/TPAMI.2008.241; Wang XG, 2009, IEEE T PATTERN ANAL, V31, P539, DOI 10.1109/TPAMI.2008.87; Wolf L, 2006, INT J COMPUT VISION, V69, P251, DOI 10.1007/s11263-006-7538-0; Xiang T, 2006, INT J COMPUT VISION, V67, P21, DOI 10.1007/s11263-006-4329-6; Xiang T, 2008, IEEE T PATTERN ANAL, V30, P893, DOI 10.1109/TPAMI.2007.70731; Xiang T, 2006, INT J COMPUT VISION, V69, P181, DOI 10.1007/s11263-005-5024-8; Yang M, 2009, IEEE T PATTERN ANAL, V31, P1195, DOI 10.1109/TPAMI.2008.146; Zelnik-Manor L., 2004, NEURAL INFORM PROCES; Zheng W., 2009, INT C COMP VIS KYOT	56	36	36	0	15	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2012	97	3					276	304		10.1007/s11263-011-0487-2	http://dx.doi.org/10.1007/s11263-011-0487-2			29	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science	907VP		Green Submitted			2022-12-18	WOS:000301447600003
J	Paladini, M; Del Bue, A; Xavier, J; Agapito, L; Stosic, M; Dodig, M				Paladini, Marco; Del Bue, Alessio; Xavier, Joao; Agapito, Lourdes; Stosic, Marko; Dodig, Marija			Optimal Metric Projections for Deformable and Articulated Structure-from-Motion	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Non-rigid structure from motion; Articulated structure from motion; Convex optimization	NONRIGID SHAPE	This paper describes novel algorithms for recovering the 3D shape and motion of deformable and articulated objects purely from uncalibrated 2D image measurements using a factorisation approach. Most approaches to deformable and articulated structure from motion require to upgrade an initial affine solution to Euclidean space by imposing metric constraints on the motion matrix. While in the case of rigid structure the metric upgrade step is simple since the constraints can be formulated as linear, deformability in the shape introduces non-linearities. In this paper we propose an alternating bilinear approach to solve for non-rigid 3D shape and motion, associated with a globally optimal projection step of the motion matrices onto the manifold of metric constraints. Our novel optimal projection step combines into a single optimisation the computation of the orthographic projection matrix and the configuration weights that give the closest motion matrix that satisfies the correct block structure with the additional constraint that the projection matrix is guaranteed to have orthonormal rows (i.e. its transpose lies on the Stiefel manifold). This constraint turns out to be non-convex. The key contribution of this work is to introduce an efficient convex relaxation for the non-convex projection step. Efficient in the sense that, for both the cases of deformable and articulated motion, the proposed relaxations turned out to be exact (i.e. tight) in all our numerical experiments. The convex relaxations are semi-definite (SDP) or second-order cone (SOCP) programs which can be readily tackled by popular solvers. An important advantage of these new algorithms is their ability to handle missing data which becomes crucial when dealing with real video sequences with self-occlusions. We show successful results of our algorithms on synthetic and real sequences of both deformable and articulated data. We also show comparative results with state of the art algorithms which reveal that our new methods outperform existing ones.	[Paladini, Marco; Agapito, Lourdes] Queen Mary Univ London, Sch Elect Engn & Comp Sci, London, England; [Del Bue, Alessio] IIT, Genoa, Italy; [Xavier, Joao; Stosic, Marko] Univ Tecn Lisboa, IST, ISR, Lisbon, Portugal; [Dodig, Marija] Univ Lisbon, CELC, Lisbon, Portugal	University of London; Queen Mary University London; Istituto Italiano di Tecnologia - IIT; Universidade de Lisboa; Instituto Superior Tecnico; Universidade de Lisboa	Agapito, L (corresponding author), Queen Mary Univ London, Sch Elect Engn & Comp Sci, London, England.	paladini@dcs.qmul.ac.uk; alessio.delbue@iit.it; jxavier@isr.ist.utl.pt; lourdes@dcs.qmul.ac.uk; mstosic@isr.ist.utl.pt; dodig@cii.fc.ul.pt	Xavier, João/R-4294-2016	Xavier, João/0000-0002-9669-8532; Del Bue, Alessio/0000-0002-2262-4872; Dodig, Marija/0000-0001-8209-6920; Stosic, Marko/0000-0002-4464-396X	European Research Council under ERC [204871-HUMANIS]; FCT [SIPM-PTDC/EEA-ACR/73749/2006, MODI-PTDC/EEA-ACR/72201/2006, ISFL-1-1431, SFRH/BPD/26607/2006]	European Research Council under ERC(European Research Council (ERC)); FCT(Portuguese Foundation for Science and TechnologyEuropean Commission)	This research has received funding from the European Research Council under ERC Starting Grant agreement 204871-HUMANIS. The Portuguese research team was partially supported by FCT, under ISR/IST pluriannual funding (POSC program, FEDER), grant SIPM-PTDC/EEA-ACR/73749/2006, grant MODI-PTDC/EEA-ACR/72201/2006, the project ISFL-1-1431 and scholarship SFRH/BPD/26607/2006. We gratefully acknowledge Manuel Marques and Joao Paulo Costeira for insightful discussions and for providing the code of their approach. Phil Tresadern provided the data for the articulated sequence.	Akhter I., 2009, P IEEE C COMP VIS PA; Akhter Ijaz, 2008, NEURAL INFORM PROCES; BARTOLI A, 2008, P IEEE C COMP VIS PA; Brand M., 2005, P IEEE C COMP VIS PA; BREGLER C, 2000, P IEEE C COMP VIS PA; Buchanan A. M., 2005, P IEEE C COMP VIS PA, V2; Del Bue A, 2007, IMAGE VISION COMPUT, V25, P297, DOI 10.1016/j.imavis.2005.10.004; DELBUE A, 2008, P IEEE C COMP VIS PA; DELBUE A, 2006, P IEEE C COMP VIS PA; DODIG M, 2009, MINIMIZING QUADRATIC; Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954; Fayad J., 2009, BRIT MACH VIS C LOND, P2; HARTLEY R, 2008, P EUR C COMP VIS; Kahl F, 2002, WORKSH VIS MOD DYN S; Marques M., 2008, WMVC 08, P1; Marques M, 2009, COMPUT VIS IMAGE UND, V113, P261, DOI 10.1016/j.cviu.2008.09.004; PALADINI M, 2009, P IEEE C COMP VIS PA; Rabaud V., 2008, P IEEE C COMP VIS PA; Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; TORRESANI L, 2001, P IEEE C COMP VIS PA; Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752; Tresadern P., 2005, P IEEE C COMP VIS PA, V2; Wang G, 2008, PATTERN RECOGN LETT, V29, P72, DOI 10.1016/j.patrec.2007.09.004; Wang GH, 2010, INT J COMPUT VISION, V87, P213, DOI 10.1007/s11263-009-0267-4; XIAO J, 2005, P 10 INT C COMP VIS; Xiao J, 2006, INT J COMPUT VISION, V67, P233, DOI 10.1007/s11263-005-3962-9; Yan JY, 2008, IEEE T PATTERN ANAL, V30, P865, DOI 10.1109/TPAMI.2007.70739	28	36	38	0	13	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2012	96	2					252	276		10.1007/s11263-011-0468-5	http://dx.doi.org/10.1007/s11263-011-0468-5			25	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	876AW					2022-12-18	WOS:000299080200007
J	Lehmann, A; Leibe, B; Van Gool, L				Lehmann, Alain; Leibe, Bastian; Van Gool, Luc			Fast PRISM: Branch and Bound Hough Transform for Object Class Detection	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Object detection; Hough transform; Sliding-window; Branch and bound; Soft-matching; Spatial pyramid histograms	SCALE	This paper addresses the task of efficient object class detection by means of the Hough transform. This approach has been made popular by the Implicit Shape Model (ISM) and has been adopted many times. Although ISM exhibits robust detection performance, its probabilistic formulation is unsatisfactory. The PRincipled Implicit Shape Model (PRISM) overcomes these problems by interpreting Hough voting as a dual implementation of linear sliding-window detection. It thereby gives a sound justification to the voting procedure and imposes minimal constraints. We demonstrate PRISM's flexibility by two complementary implementations: a generatively trained Gaussian Mixture Model as well as a discriminatively trained histogram approach. Both systems achieve state-of-the-art performance. Detections are found by gradient-based or branch and bound search, respectively. The latter greatly benefits from PRISM's feature-centric view. It thereby avoids the unfavourable memory trade-off and any on-line pre-processing of the original Efficient Subwindow Search (ESS). Moreover, our approach takes account of the features' scale value while ESS does not. Finally, we show how to avoid soft-matching and spatial pyramid descriptors during detection without losing their positive effect. This makes algorithms simpler and faster. Both are possible if the object model is properly regularised and we discuss a modification of SVMs which allows for doing so.	[Lehmann, Alain; Van Gool, Luc] Swiss Fed Inst Technol, Comp Vis Lab, Zurich, Switzerland; [Leibe, Bastian] Rhein Westfal TH Aachen, UMIC Res Ctr, Aachen, Germany; [Van Gool, Luc] Katholieke Univ Leuven, ESAT PSI IBBT, Louvain, Belgium	Swiss Federal Institutes of Technology Domain; ETH Zurich; RWTH Aachen University; KU Leuven	Lehmann, A (corresponding author), Swiss Fed Inst Technol, Comp Vis Lab, Zurich, Switzerland.	lehmann@vision.ee.ethz.ch; leibe@umic.rwth-aachen.de; vangool@vision.ee.ethz.ch	Leibe, Bastian/E-5499-2017	Leibe, Bastian/0000-0003-4225-0051	Swiss National Fund (SNF) [200021-118106]	Swiss National Fund (SNF)(Swiss National Science Foundation (SNSF))	The authors wish to thank the Swiss National Fund (SNF) for support through the CASTOR project (200021-118106).	Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108; BAGGENSTOOS PM, 2002, STAT MODELING USING; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014; Bentley J., 1984, Communications of the ACM, V27, P865, DOI 10.1145/358234.381162; Blaschko M.B., 2008, P EUR C COMP VIS; BREUEL TM, 1992, P IEEE C COMP VIS PA; BREUEL TM, 2002, P EUR C COMP VIS; Carreira-Perpinan MA, 2000, IEEE T PATTERN ANAL, V22, P1318, DOI 10.1109/34.888716; Chapelle O, 2007, NEURAL COMPUT, V19, P1155, DOI 10.1162/neco.2007.19.5.1155; Chum 0., 2007, P IEEE C COMP VIS PA; Comaniciu D., 2001, P IEEE INT C COMP VI; CORNELIS N, 2008, P COMP VIS PATT REC; Dalal N., 2005, HISTOGRAMS ORIENTED; DARRELL T., 2009, P IEEE C COMP VIS PA; Felzenszwalb P., 2008, P IEEE C COMP VIS PA; Ferrari V., 2007, P IEEE C COMP VIS PA; Fritz M., 2005, P IEEE INT C COMP VI; Gall J., 2009, P IEEE C COMP VIS PA; Grauman K, 2005, P IEEE INT C COMP VI; HEITZ G, 2008, P EUR C COMP VIS; Keysers D., 2007, ELECT LETT COMPUTER, V6, P44; Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881; LAMPERT C. H., 2008, P IEEE C COMP VIS PA; LAMPERT CH, 2009, IEEE T PATTERN ANAL, V99; LAZEBNIK S, 2006, IEEE C COMP VIS PATT, V2, P2169, DOI DOI 10.1109/CVPR.2006.68; LEHMANN A, 2009, P BRIT MACH VIS C; Lehmann A., 2009, P IEEE INT C COMP VI; LEIBE B, 2004, P DAGM S; LEIBE B., 2005, P IEEE C COMP VIS PA; Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3; Liebelt J., 2008, P IEEE C COMP VIS PA; Lindeberg T., 1994, SCALE SPACE THEORY C; Maji S., 2009, P IEEE C COMP VIS PA; Maji S., 2008, P IEEE C COMP VIS PA; MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2; OMMER B, 2007, P IEEE C COMP VIS PA; Opelt A., 2006, P EUR C COMP VIS; PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205; Philbin J., 2008, P IEEE C COMP VIS PA; SANDLER T, 2008, P ADV NEUR INF PROC; Schneiderman H, 2004, INT J COMPUT VISION, V56, P151, DOI 10.1023/B:VISI.0000011202.85607.00; Schneiderman H, 2004, PROC CVPR IEEE, P29; Shawe-Taylor J., 2004, KERNEL METHODS PATTE; Sudderth E.B., 2005, P IEEE INT C COMP VI; VENKATESH S., 2009, P IEEE C COMP VIS PA; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; WILLIAMS CKI, 2006, 0719 U ED	50	36	38	0	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2011	94	2					175	197		10.1007/s11263-010-0342-x	http://dx.doi.org/10.1007/s11263-010-0342-x			23	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	775VB		Green Accepted, Green Submitted, Green Published			2022-12-18	WOS:000291490400002
J	Winkelbach, S; Wahl, FM				Winkelbach, Simon; Wahl, Friedrich M.			Pairwise matching of 3D fragments using cluster trees	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						fracture matching; surface registration; 3D puzzle; fragment alignment; cluster tree; broken objects	REGISTRATION; OBJECTS	We propose a novel and efficient surface matching approach for reassembling broken solids as well as for matching assembly components using cluster trees of oriented points. The method rapidly scans through the space of all possible contact poses of the fragments to be ( re) assembled using a tree search strategy, which neither relies on any surface features nor requires an initial solution. The new method first decomposes each point set into a binary tree structure using a hierarchical clustering algorithm. Subsequently the fragments are matched pairwise by descending the cluster trees simultaneously in a depth-first fashion. In contrast to the reassemblage of pottery and thin walled artifacts, this paper addresses the problem of matching broken 3D solids on the basis of their 2.5D fracture surfaces, which are assumed to be reasonable large. Our proposed contact area maximization is a powerful common basis for most surface matching tasks, which can be adapted to numerous special applications. The suggested approach is very robust and offers an outstanding efficiency.	[Winkelbach, Simon; Wahl, Friedrich M.] Tech Univ Carolo Wilhelmina Braunschweig, Inst Robot & Proc Control, Braunschweig, Germany	Braunschweig University of Technology	Winkelbach, S (corresponding author), Tech Univ Carolo Wilhelmina Braunschweig, Inst Robot & Proc Control, Braunschweig, Germany.	s.winkelbach@tu-bs.de	Wahl, Friedrich M/Q-4009-2017					BAREQUET G, 1996, P 12 ANN S COMP GEOM, P490; BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791; Chua CS, 1997, INT J COMPUT VISION, V25, P63, DOI 10.1023/A:1007981719186; COOPER D, 2002, INT C PATTERN RECOGN, V16, P297; Dalley G, 2002, COMPUT VIS IMAGE UND, V87, P104, DOI 10.1006/cviu.2002.0986; Ericson C., 2005, REAL TIME COLLISION; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Goldberg D, 2004, COMP GEOM-THEOR APPL, V28, P165, DOI 10.1016/j.comgeo.2004.03.007; Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830; HUANG QX, 2006, SIGGRAPH 06 ACM SIGG, P569; Johnson AE, 1997, PROC CVPR IEEE, P684, DOI 10.1109/CVPR.1997.609400; Kampel M, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P318, DOI 10.1109/IM.2003.1240265; Kampel M., 2003, COMP VIS PATT REC WO, P4; Krsek P, 2002, COMPUT VIS IMAGE UND, V87, P27, DOI 10.1006/cviu.2002.0980; Leitao HCD, 2002, IEEE T PATTERN ANAL, V24, P1239, DOI 10.1109/TPAMI.2002.1033215; LINNAINMAA S, 1988, IEEE T PATTERN ANAL, V10, P634, DOI 10.1109/34.6772; Mitra N. J., 2003, SCG 03, P322; Papaioannou G, 2002, IEEE T PATTERN ANAL, V24, P114, DOI 10.1109/34.982888; PAPAIOANNOU G, 1999, IEEE CVPR WORKSH APP; Papaioannou G, 2000, P INT C COMP GRAPH A, P117; Pottmann H, 2006, INT J COMPUT VISION, V67, P277, DOI 10.1007/s11263-006-5167-2; Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423; SAPPA A, 2001, INT S INT ROB SYST S, P167; SCHON N, 2005, VISION MODELILNG VIS, P71; Seeger S., 2000, PRINCIPLES 3D IMAGE, V556, P153; STOCKMAN G, 1987, COMPUT VISION GRAPH, V40, P361, DOI 10.1016/S0734-189X(87)80147-0; *VIENN U TECHN, 3D PUZZL REASS FRACT; Wahl E, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P474, DOI 10.1109/IM.2003.1240284; WILLIS A, 2004, IEEE C COMPUTER VISI, V1, P82; Winkelbach S, 2004, LECT NOTES COMPUT SC, V3175, P129; Winkelbach S, 2003, LECT NOTES COMPUT SC, V2781, P566; Winkelbach S, 2006, LECT NOTES COMPUT SC, V4174, P718; Wyngaerd JV, 2002, COMPUT VIS IMAGE UND, V87, P8, DOI 10.1006/cviu.2002.0979	33	36	51	1	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2008	78	1					1	13		10.1007/s11263-007-0121-5	http://dx.doi.org/10.1007/s11263-007-0121-5			13	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	270YE					2022-12-18	WOS:000253755300001
J	Evgeniou, T; Pontil, M; Poggio, T				Evgeniou, T; Pontil, M; Poggio, T			Statistical learning theory: A primer	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						VC-dimension; structural risk minimization; regularization networks; support vector machines		In this paper we first overview the main concepts of Statistical Learning Theory, a framework in which learning from examples can be studied in a principled way. We then briefly discuss well known as well as emerging learning techniques such as Regularization Networks and Support Vector Machines which can be justified in term of the same induction principle.	MIT, Artificial Intelligence Lab, Ctr Biol & Computat Learning, Cambridge, MA 02139 USA	Massachusetts Institute of Technology (MIT)	Evgeniou, T (corresponding author), MIT, Artificial Intelligence Lab, Ctr Biol & Computat Learning, Cambridge, MA 02139 USA.							ALON N, 1993, S FDN COMP SCI; Cortes C., 1995, MACH LEARN, P273, DOI [10.1023/A:1022627411411, DOI 10.1007/BF00994018]; Devroye L., 1996, APPL MATH, V31; EVGENIOU T, 2000, IN PRESS P ACCV TAIW; EVGENIOU T, 1999, 1654 MIT AI LAB; EZZAT T, 1996, FACE GESTURE RECOGNI, P116; JAAKKOLA T, 1998, P NEUR INF PROC C; KEARNS MJ, 1994, J COMPUT SYST SCI, V48, P464, DOI 10.1016/S0022-0000(05)80062-5; MOHAN A, 1999, THESIS MIT; OSUNA E, 1997, IEEE WORKSH NEUR NET; PAPAGEORGIOU C, 1998, P INT C COMP VIS BOM; Platt J. C., 1998, MSTTR9814; TIKHNOV AN, 1977, SOLUTIONS ILL POSED; Vapnik V.N, 1998, STAT LEARNING THEORY; VAPNIK VN, 1971, THEOR PROBAB APPL+, V16, P264, DOI 10.1137/1116025; Wahba G., 1990, SERIES APPL MATH, V59	17	36	40	1	11	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2000	38	1					9	13		10.1023/A:1008110632619	http://dx.doi.org/10.1023/A:1008110632619			5	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	342GH					2022-12-18	WOS:000088636500002
J	LUO, A; BURKHARDT, H				LUO, A; BURKHARDT, H			AN INTENSITY-BASED COOPERATIVE BIDIRECTIONAL STEREO MATCHING WITH SIMULTANEOUS DETECTION OF DISCONTINUITIES AND OCCLUSIONS	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							VISION	This paper presents a new intensity-based stereo algorithm using cooperative bidirectional matching with a hierarchical multilevel structure. Based on a new model of piecewise smooth depth fields and the consistency constraint, the algorithm is able to estimate the 3-D structure and detect its discontinuities and the occlusion reliably with low computational costs. In order to find the global optimal estimates, we utilize a multiresolution two-stage algorithm minimizing nonconvex cost functions, which is equivalent to the MAP estimation. This basic framework computing the 3-D structure from binocular stereo images has been extended to the trinocular stereo vision for a further improvement of the performance. A few examples for the binocular and trinocular stereo problems are given to illustrate the performance of the new algorithms.			LUO, A (corresponding author), TECH UNIV HAMBURG,POSTFACH 901052,D-21071 HAMBURG,GERMANY.		Burkhardt, Hans/M-5895-2019; Luo, Albert/N-8042-2019					BARNARD ST, 1989, INT J COMPUTER VISIO, V2, P17; Burt P.J., 1984, MULTIRESOLUTION IMAG, P6; Chang C., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P722, DOI 10.1109/CVPR.1991.139799; CHANG C, 1990, 10TH P INT C PATT RE, P908; Chung R. C., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P50, DOI 10.1109/CVPR.1991.139660; ENKELMANN W, 1988, COMPUT VISION GRAPH, V43, P150, DOI 10.1016/0734-189X(88)90059-X; GEIGER D, 1992, 2 EUR C COMP VIS ECC, P425; GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596; Gennert M. A., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P139, DOI 10.1109/CCV.1988.589984; GLAZER F, 1984, MULTIRESOLUTION IMAG, P312; GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615; Hansen C., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P129, DOI 10.1109/CCV.1988.589982; HOFF W, 1989, IEEE T PATTERN ANAL, V11, P121, DOI 10.1109/34.16709; Horn B., 1986, ROBOT VISION, P1; JONES DG, 1992, 2ND P EUR C COMP VIS, P395; LUO A, 1993, THESIS TU HAMBURG HA; LUO A, 1993, 15 DAGM S MUST LUB, P59; LUO A, 1993, 15 DAGM S MUSTERERKE, P584; MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029; MORAVEC H, 1981, ROBOT ROVER VISUAL N; ROSENFELD A, 1984, MULTIRESOLUTION IMAG; Stewart C. V., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P134, DOI 10.1109/CCV.1988.589983; SZELISKI R, 1990, INT J COMPUT VISION, V5, P271, DOI 10.1007/BF00126502; TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807; Terzopoulos Demetri, 1984, MULTIRESOLUTION IMAG, P237; WENG J, 1988, DEC P INT C COMP VIS, P64	27	36	38	0	4	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	1995	15	3					171	188		10.1007/BF01451740	http://dx.doi.org/10.1007/BF01451740			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	RM520					2022-12-18	WOS:A1995RM52000001
J	RIMEY, RD; BROWN, CM				RIMEY, RD; BROWN, CM			CONTROLLING EYE-MOVEMENTS WITH HIDDEN MARKOV-MODELS	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							SPEECH RECOGNITION; SHAPE	Advances in technology and in active vision research allow and encourage sequential visual information acquisition. Hidden Markov models (HMMs) can represent probabilistic sequences and probabilistic graph structures: here we explore their use in controlling the acquisition of visual information. We include a brief tutorial with two examples: (1) use input sequences to derive an aspect graph and (2) similarly derive a finite state machine for control of visual processing. The first main topic is the use of HMMs in both their learning and generative modes, and their augmentation to allow inputs sensed during generation to modify the generated outputs temporarily or permanently. We propose these augmented HMMs as a theory of adaptive skill acquisition and generation. The second main topic builds on the first: the augmented HMMs can be used for knowledge fusion. We give an example, the what-where-AHMM, which creates a hybrid skill from separate skills based on object location and object identity. Insofar as low-level skills can be learned from the output of high-level cognitive processes, AHMMs can provide a link between high-level and low-level vision.	UNIV ROCHESTER,DEPT COMP SCI,ROCHESTER,NY 14627	University of Rochester								BAJCSY R, 1988, IEEE P, V76, P996; BAKER JK, 1979, 97 M AC SOC AM; Ballard D.H., 1982, COMPUTER VISION; BALLARD DH, 1991, ARTIF INTELL, V48, P57, DOI 10.1016/0004-3702(91)90080-4; Barto A.G., 1989, 8995 U MASS DEP COMP; Bobick A. F., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P492, DOI 10.1109/CVPR.1989.37892; BOLLE RM, 1990, P IEEE INTERN C PATT, P1; BOURLARD H, 1988, P NEURAL INFOR PROCE, P502; BROWN CM, 1988, 257 U ROCH DEP COMP; BROWSE RA, 1988, 2ND P INT C COMP VIS, P405; BURT PJ, 1988, IEEE P, V76, P1006; CASACUBERTA F, 1990, IEEE T PATTERN ANAL, V12, P691, DOI 10.1109/34.56212; Clark J. J., 1988, Second International Conference on Computer Vision (IEEE Cat. No.88CH2664-1), P514, DOI 10.1109/CCV.1988.590032; Dean T., 1989, Computational Intelligence, V5, P142, DOI 10.1111/j.1467-8640.1989.tb00324.x; Gong X., 1988, ICASSP 88: 1988 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.88CH2561-9), P1128, DOI 10.1109/ICASSP.1988.196795; HE Y, 1991, P IEEE C COMPUT VISI; KEHAGIAS A, 1991, THESIS BROWN U; KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644; KUNG SY, 1989, P IEEE INT C ACOUST; Mao W. D., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P832, DOI 10.1109/ICPR.1990.118225; Mozer MC, 1990, NEURAL COMPUT, V2, P447, DOI 10.1162/neco.1990.2.4.447; NOTON D, 1971, SCI AM, V224, P34; OLSON TJ, 1991, INT J COMPUT VISION, V7, P67, DOI 10.1007/BF00130490; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; RABINER LR, 1986, IEEE ASSP MAGAZI JAN, P37114; Rimey R, 1990, SELECTIVE ATTENTION; ROSENSCHEIN SJ, 1985, NEW GENERAT COMPUT, V3, P345, DOI 10.1007/BF03037076; Rueckl J G, 1989, J Cogn Neurosci, V1, P171, DOI 10.1162/jocn.1989.1.2.171; SEIBERT M, 1990, P NEURAL INFOR PROCE, P258; STARK L, EYE MOVEMENTS COGNIT; ULLMAN S, 1984, COGNITION, V18, P97, DOI 10.1016/0010-0277(84)90023-4; WATTS NA, 1988, NOV P IEEE INT C PAT; WHITEHEAD SD, 1990, P 7 INT C MACH LEARN, P179; WRIGHT CE, 1990, INVITATION COGNITIVE, V2, P285; YESHURUN Y, 1989, IEEE T PATTERN ANAL, V11, P1217, DOI 10.1109/34.42860	35	36	36	0	9	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	1991	7	1					47	65		10.1007/BF00130489	http://dx.doi.org/10.1007/BF00130489			19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	GY893					2022-12-18	WOS:A1991GY89300004
J	Yang, B; Wang, S; Markham, A; Trigoni, N				Yang, Bo; Wang, Sen; Markham, Andrew; Trigoni, Niki			Robust Attentional Aggregation of Deep Feature Sets for Multi-view 3D Reconstruction	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Robust attention model; Deep learning on sets; Multi-view 3D reconstruction		We study the problem of recovering an underlying 3D shape from a set of images. Existing learning based approaches usually resort to recurrent neural nets, e.g., GRU, or intuitive pooling operations, e.g., max/mean poolings, to fuse multiple deep features encoded from input images. However, GRU based approaches are unable to consistently estimate 3D shapes given different permutations of the same set of input images as the recurrent unit is permutation variant. It is also unlikely to refine the 3D shape given more images due to the long-term memory loss of GRU. Commonly used pooling approaches are limited to capturing partial information, e.g., max/mean values, ignoring other valuable features. In this paper, we present a new feed-forward neural module, named AttSets, together with a dedicated training algorithm, named FASet, to attentively aggregate an arbitrarily sized deep feature set for multi-view 3D reconstruction. The AttSets module is permutation invariant, computationally efficient and flexible to implement, while the FASet algorithm enables the AttSets based network to be remarkably robust and generalize to an arbitrary number of input images. We thoroughly evaluate FASet and the properties of AttSets on multiple large public datasets. Extensive experiments show that AttSets together with FASet algorithm significantly outperforms existing aggregation approaches.	[Yang, Bo; Markham, Andrew; Trigoni, Niki] Univ Oxford, Dept Comp Sci, Oxford, England; [Wang, Sen] Heriot Watt Univ, Sch Engn & Phys Sci, Edinburgh, Midlothian, Scotland	University of Oxford; Heriot Watt University	Yang, B (corresponding author), Univ Oxford, Dept Comp Sci, Oxford, England.	Bo.Yang@cs.ox.ac.uk; s.wang@hw.ac.uk; Andrew.Markham@cs.ox.ac.uk; Niki.Trigoni@cs.ox.ac.uk		YANG, Bo/0000-0002-2419-4140; Trigoni, Niki/0000-0001-6236-9645; Wang, Sen/0000-0003-1537-8834	EPSRC Robotics and Artificial Intelligence ORCA Hub [EP/R026173/1]; EU [731103]; EPSRC [EP/R026173/1] Funding Source: UKRI	EPSRC Robotics and Artificial Intelligence ORCA Hub(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); EU(European Commission); EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	Sen Wang was supported by EPSRC Robotics and Artificial Intelligence ORCA Hub (grant No. EP/R026173/1) and EU H2020 Programme under EU Marine Robots project (grant ID 731103).	Rodriguez AMB, 2018, ESTUDIOS CRITICOS DE JURISPRUDENCIA TRIBUTARIA Y ADUANERA, TOMO VII, OBSERVATORIO DE JURISPRUDENCIA TRIBUTARIA Y ADUANERA, P349; BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754; Cao YP, 2018, LECT NOTES COMPUT SC, V11213, P626, DOI 10.1007/978-3-030-01240-3_38; Chang Angel X., 2015, ARXIV151203012CSGR P; Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38; Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269; Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693; Dong W, 2018, LECT NOTES COMPUT SC, V11213, P714, DOI 10.1007/978-3-030-01240-3_43; Dzmitry Bahdanau, 2016, Arxiv, DOI arXiv:1409.0473; Eslami SMA, 2018, SCIENCE, V360, P1204, DOI 10.1126/science.aar6170; Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264; Gardner A., 2017, ARXIV170903019; Girdhar R, 2017, ADV NEUR IN, V30; Hartley R., 2004, ROBOTICA; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang PH, 2018, PROC CVPR IEEE, P2821, DOI 10.1109/CVPR.2018.00298; Ilse M, 2018, PR MACH LEARN RES, V80; Ionescu C, 2015, IEEE I CONF COMP VIS, P2965, DOI 10.1109/ICCV.2015.339; Ji MQ, 2017, IEEE I CONF COMP VIS, P2326, DOI 10.1109/ICCV.2017.253; Ji P, 2017, IEEE I CONF COMP VIS, P929, DOI 10.1109/ICCV.2017.106; Kar A., 2017, ADV NEURAL INFORM PR; Kolen J.F., 2001, GRADIENT FLOW RECURR, P237, DOI [10.1109/9780470544037.ch14, DOI 10.1109/9780470544037.CH14]; Kumar S, 2017, IEEE I CONF COMP VIS, P4659, DOI 10.1109/ICCV.2017.498; Li Hanchao, 2018, ARXIV180510180; Lin T. Y., 2017, BRIT MACH VIS C; Lin SY, 2018, LECT NOTES COMPUT SC, V11207, P639, DOI 10.1007/978-3-030-01219-9_38; Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170; Liu XF, 2018, LECT NOTES COMPUT SC, V11215, P573, DOI 10.1007/978-3-030-01252-6_34; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Martin E., 2018, INT C LEARN REPR; Nakka K. K., 2018, BRIT MACH VIS C; Ozyesil O, 2017, ACTA NUMER, V26, P305, DOI 10.1017/S096249291700006X; Paschalidou D, 2018, PROC CVPR IEEE, P3897, DOI 10.1109/CVPR.2018.00410; Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609; Raffel C., 2016, INT C LEARN REPR WOR; Riegler G, 2017, INT CONF 3D VISION, P57, DOI 10.1109/3DV.2017.00017; Sarafianos N, 2018, LECT NOTES COMPUT SC, V11215, P708, DOI 10.1007/978-3-030-01252-6_42; Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114; Tatarchenko M, 2017, IEEE I CONF COMP VIS, P2107, DOI 10.1109/ICCV.2017.230; Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298; Vaswani A., 2017, ADV NEURAL INFORM PR, V30; Vinyals O., 2015, INT C LEARN REPR; Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070; Wiles O, 2019, INT J COMPUT VISION, V127, P1780, DOI 10.1007/s11263-018-1124-0; Wiles Olivia, 2017, P BMVC; WU ZR, 2015, PROC CVPR IEEE, P1912, DOI DOI 10.1109/CVPR.2015.7298801; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Yang X, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4965; Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10; Yao Y, 2018, LECT NOTES COMPUT SC, V11212, P785, DOI 10.1007/978-3-030-01237-3_47; Yu T, 2018, LECT NOTES COMPUT SC, V11205, P191, DOI 10.1007/978-3-030-01246-5_12; Zaheer M., 2017, INT C NEUR INF PROC; Zhang Han, 2018, ARXIV180508318; Zhu Y., 2018, ACM INT C MULT	56	35	37	2	7	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2020	128	1					53	73		10.1007/s11263-019-01217-w	http://dx.doi.org/10.1007/s11263-019-01217-w			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	KI6WA		Green Published, hybrid, Green Submitted			2022-12-18	WOS:000511490100003
J	He, XT; Peng, YX; Zhao, JJ				He, Xiangteng; Peng, Yuxin; Zhao, Junjie			Which and How Many Regions to Gaze: Focus Discriminative Regions for Fine-Grained Visual Categorization	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Fine-grained visual categorization; Deep reinforcement learning; Multi-granularity discriminative localization; Multi-scale representation learning; Unsupervised discriminative localization; Semantic reward	ATTENTION; MODEL	Fine-grained visual categorization (FGVC) aims to discriminate similar subcategories that belong to the same superclass. Since the distinctions among similar subcategories are quite subtle and local, it is highly challenging to distinguish them from each other even for humans. So the localization of distinctions is essential for fine-grained visual categorization, and there are two pivotal problems: (1) Which regions are discriminative and representative to distinguish from other subcategories? (2) How many discriminative regions are necessary to achieve the best categorization performance? It is still difficult to address these two problems adaptively and intelligently. Artificial prior and experimental validation are widely used in existing mainstream methods to discover which and how many regions to gaze. However, their applications extremely restrict the usability and scalability of the methods. To address the above two problems, this paper proposes a multi-scale and multi-granularity deep reinforcement learning approach (M2DRL), which learns multi-granularity discriminative region attention and multi-scale region-based feature representation. Its main contributions are as follows: (1) Multi-granularity discriminative localization is proposed to localize the distinctions via a two-stage deep reinforcement learning approach, which discovers the discriminative regions with multiple granularities in a hierarchical manner (which problem), and determines the number of discriminative regions in an automatic and adaptive manner (how many problem). (2) Multi-scale representation learning helps to localize regions in different scales as well as encode images in different scales, boosting the fine-grained visual categorization performance. (3) Semantic reward function is proposed to drive M2DRL to fully capture the salient and conceptual visual information, via jointly considering attention and category information in the reward function. It allows the deep reinforcement learning to localize the distinctions in a weakly supervised manner or even an unsupervised manner. (4) Unsupervised discriminative localization is further explored to avoid the heavy labor consumption of annotating, and extremely strengthen the usability and scalability of our M2DRL approach. Compared with state-of-the-art methods on two widely-used fine-grained visual categorization datasets, our M2DRL approach achieves the best categorization accuracy.	[He, Xiangteng; Peng, Yuxin; Zhao, Junjie] Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China	Peking University	Peng, YX (corresponding author), Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China.	pengyuxin@pku.edu.cn			National Natural Science Foundation of China [61771025, 61532005]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported by National Natural Science Foundation of China under the Grant 61771025 and Grant 61532005.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Ba J., 2014, ARXIV; Berg T, 2013, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2013.128; Branson S., 2014, PROC BRIT MACH VIS C; Branson S, 2014, INT J COMPUT VISION, V108, P3, DOI 10.1007/s11263-014-0698-4; Cai SJ, 2017, IEEE I CONF COMP VIS, P511, DOI 10.1109/ICCV.2017.63; Caicedo JC, 2015, IEEE I CONF COMP VIS, P2488, DOI 10.1109/ICCV.2015.286; Chai Y, 2013, IEEE I CONF COMP VIS, P321, DOI 10.1109/ICCV.2013.47; Cui Y, 2016, PROC CVPR IEEE, P1153, DOI 10.1109/CVPR.2016.130; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5; Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Gonzalez-Garcia A, 2018, INT J COMPUT VISION, V126, P476, DOI 10.1007/s11263-017-1048-0; He X., 2017, IEEE C COMP VIS PATT; He XT, 2017, AAAI CONF ARTIF INTE, P4075; Huang SL, 2016, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2016.132; Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500; Jaderberg M., 2015, ADV NEURAL INFORM PR, P2017, DOI DOI 10.1038/NBT.3343; Jie ZQ, 2016, ADV NEUR IN, V29; Jin S, 2014, IEEE GLOB COMM CONF, P834, DOI 10.1109/GLOCOM.2014.7036912; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237, DOI 10.1613/jair.301; Kong S, 2017, PROC CVPR IEEE, P7025, DOI 10.1109/CVPR.2017.743; Krause J, 2015, PROC CVPR IEEE, P5546, DOI 10.1109/CVPR.2015.7299194; Krause J, 2014, INT C PATT RECOG, P26, DOI 10.1109/ICPR.2014.15; Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77; Li YL, 2016, 2016 9TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2016), P1995; Lin D, 2015, PROC CVPR IEEE, P1666, DOI 10.1109/CVPR.2015.7298775; Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170; Maji Subhransu, 2013, ARXIV13065151; Mathe S, 2016, PROC CVPR IEEE, P2894, DOI 10.1109/CVPR.2016.316; Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236; Neider MB, 2006, VISION RES, V46, P2217, DOI 10.1016/j.visres.2006.01.006; Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Parkhurst D, 2002, VISION RES, V42, P107, DOI 10.1016/S0042-6989(01)00250-4; Peng YX, 2018, IEEE T IMAGE PROCESS, V27, P1487, DOI 10.1109/TIP.2017.2774041; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707; Schaul T, 2015, P INT C LEARN REPR; Sfar AR, 2015, INT J COMPUT VISION, V111, P255, DOI 10.1007/s11263-014-0743-3; Simon M, 2015, IEEE I CONF COMP VIS, P1143, DOI 10.1109/ICCV.2015.136; Sutton RS, 2018, ADAPT COMPUT MACH LE, P1; Szegedy C., 2015, ARXIV 1502 03167, P448, DOI DOI 10.1007/S13398-014-0173-7.2; Tatler BW, 2006, VISION RES, V46, P1857, DOI 10.1016/j.visres.2005.12.005; Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5; Van Hasselt Hado, 2016, P AAAI C ART INT, V30; Wah C., 2011, TECH REP; Wang DQ, 2015, IEEE I CONF COMP VIS, P2399, DOI 10.1109/ICCV.2015.276; WANG JJ, 2010, PROC CVPR IEEE, P3360, DOI DOI 10.1109/CVPR.2010.5540018; Wang Y., 2016, ARXIV161109932; Wang YM, 2016, PROC CVPR IEEE, P1163, DOI 10.1109/CVPR.2016.131; Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685; Xie LX, 2016, PROC CVPR IEEE, P270, DOI 10.1109/CVPR.2016.36; Xie LX, 2013, IEEE I CONF COMP VIS, P1641, DOI 10.1109/ICCV.2013.206; Xie SN, 2015, PROC CVPR IEEE, P2645, DOI 10.1109/CVPR.2015.7298880; Xu Z, 2018, IEEE T PATTERN ANAL, V40, P1100, DOI 10.1109/TPAMI.2016.2637331; Xu Z, 2017, IEEE T IMAGE PROCESS, V26, P135, DOI 10.1109/TIP.2016.2621661; Yang S., 2012, ADV NEURAL INFORM PR, P3122; Yao HT, 2016, IEEE T IMAGE PROCESS, V25, P4858, DOI 10.1109/TIP.2016.2599102; Zhang H, 2016, PROC CVPR IEEE, P1143, DOI 10.1109/CVPR.2016.129; Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4; Zhang LM, 2016, IEEE T IMAGE PROCESS, V25, P553, DOI 10.1109/TIP.2015.2502147; Zhang N, 2013, IEEE I CONF COMP VIS, P729, DOI 10.1109/ICCV.2013.96; Zhang XP, 2017, IEEE T MULTIMEDIA, V19, P2736, DOI 10.1109/TMM.2017.2710803; Zhang XP, 2016, PROC CVPR IEEE, P1134, DOI 10.1109/CVPR.2016.128; Zhang XP, 2016, IEEE T IMAGE PROCESS, V25, P878, DOI 10.1109/TIP.2015.2509425; Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, P1713, DOI 10.1109/TIP.2016.2531289; Zhao B, 2017, IEEE T MULTIMEDIA, V19, P1245, DOI 10.1109/TMM.2017.2648498; Zhao DB, 2017, IEEE T COGN DEV SYST, V9, P356, DOI 10.1109/TCDS.2016.2614675; ZHOU B, 2016, PROC CVPR IEEE, P2921, DOI DOI 10.1109/CVPR.2016.319; Zhou Bolei, 2015, OBJECT DETECTORS EME, P2; Zhou F, 2016, PROC CVPR IEEE, P1124, DOI 10.1109/CVPR.2016.127	74	35	36	2	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	SEP	2019	127	9					1235	1255		10.1007/s11263-019-01176-2	http://dx.doi.org/10.1007/s11263-019-01176-2			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	IL9YV					2022-12-18	WOS:000477642300004
J	Wu, BY; Jia, F; Liu, W; Ghanem, B; Lyu, S				Wu, Baoyuan; Jia, Fan; Liu, Wei; Ghanem, Bernard; Lyu, Siwei			Multi-label Learning with Missing Labels Using Mixed Dependency Graphs	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Multi-label learning; Missing labels; Mixed dependency graphs; Image annotation; Image retrieval	TAG COMPLETION; IMAGE; CLASSIFICATION; ADMM	This work focuses on the problem of multi-label learning with missing labels (MLML), which aims to label each test instance with multiple class labels given training instances that have an incomplete/partial set of these labels (i.e., some of their labels are missing). The key point to handle missing labels is propagating the label information from the provided labels to missing labels, through a dependency graph that each label of each instance is treated as a node. We build this graph by utilizing different types of label dependencies. Specifically, the instance-level similarity is served as undirected edges to connect the label nodes across different instances and the semantic label hierarchy is used as directed edges to connect different classes. This base graph is referred to as the mixed dependency graph, as it includes both undirected and directed edges. Furthermore, we present another two types of label dependencies to connect the label nodes across different classes. One is the class co-occurrence, which is also encoded as undirected edges. Combining with the above base graph, we obtain a new mixed graph, called mixed graph with co-occurrence (MG-CO). The other is the sparse and low rank decomposition of the whole label matrix, to embed high-order dependencies over all labels. Combining with the base graph, the new mixed graph is called as MG-SL (mixed graph with sparse and low rank decomposition). Based on MG-CO and MG-SL, we further propose two convex transductive formulations of the MLML problem, denoted as MLMG-CO and MLMG-SL respectively. In both formulations, the instance-level similarity is embedded through a quadratic smoothness term, while the semantic label hierarchy is used as a linear constraint. In MLMG-CO, the class co-occurrence is also formulated as a quadratic smoothness term, while the sparse and low rank decomposition is incorporated into MLMG-SL, through two additional matrices (one is assumed as sparse, and the other is assumed as low rank) and an equivalence constraint between the summation of this two matrices and the original label matrix. Interestingly, two important applications, including image annotation and tag based image retrieval, can be jointly handled using our proposed methods. Experimental results on several benchmark datasets show that our methods lead to significant improvements in performance and robustness to missing labels over the state-of-the-art methods.	[Wu, Baoyuan; Jia, Fan; Liu, Wei] Tencent AI Lab, Shenzhen 518000, Peoples R China; [Ghanem, Bernard] King Abdullah Univ Sci & Technol, Visual Comp Ctr, Thuwal 23955, Saudi Arabia; [Lyu, Siwei] SUNY Albany, Comp Sci Dept, 1400 Washington Ave, Albany, NY 12222 USA	Tencent; King Abdullah University of Science & Technology; State University of New York (SUNY) System; State University of New York (SUNY) Albany	Wu, BY (corresponding author), Tencent AI Lab, Shenzhen 518000, Peoples R China.	wubaoyuan1987@gmail.com; jiafan@tju.edu.cn; wliu@ee.columbia.edu; bernard.ghanem@kaust.edu.sa; slyu@albany.edu	; Ghanem, Bernard/J-7605-2017	Liu, Wei/0000-0002-3865-8145; Lyu, Siwei/0000-0002-0992-685X; Wu, Baoyuan/0000-0003-2183-5990; Ghanem, Bernard/0000-0002-5534-587X	Tencent AI Lab; King Abdullah University of Science and Technology (KAUST) Office of Sponsored Research; National Science Foundation National Robotics Initiative (NRI) [IIS-1537257]	Tencent AI Lab; King Abdullah University of Science and Technology (KAUST) Office of Sponsored Research(King Abdullah University of Science & Technology); National Science Foundation National Robotics Initiative (NRI)	This work is supported by Tencent AI Lab. The participation of Bernard Ghanem is supported by the King Abdullah University of Science and Technology (KAUST) Office of Sponsored Research. The participation of Siwei Lyu is partially supported by National Science Foundation National Robotics Initiative (NRI) Grant (IIS-1537257).	Agrawal Rahul, 2013, WWW 13, P13; [Anonymous], 1998, WORDNET; Bi W., 2011, P 28 INT C MACH LEAR, P17; Boyd S, 2011, TRENDS MACH LEARN, V3, P1, DOI DOI 10.1561/2200000016; Bucak S. S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2801, DOI 10.1109/CVPR.2011.5995734; Cabral R. S., 2011, ADV NEURAL INFORM PR, P190; Chang X., 2016, BMVC; Chatfield K., 2014, BMVC; Chen CH, 2016, MATH PROGRAM, V155, P57, DOI 10.1007/s10107-014-0826-5; Chen G., 2018, P 2008 SIAM INT C DA, P410; Chen Minmin, 2013, P 30 INT C MACH LEAR, P1274; Chen Z., 2015, AAAI; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deng J, 2014, LECT NOTES COMPUT SC, V8689, P48, DOI 10.1007/978-3-319-10590-1_4; Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97; Fazel M., 2002, MATRIX RANK MINIMIZA; Furnkranz J, 2008, MACH LEARN, V73, P133, DOI 10.1007/s10994-008-5064-8; Geng B., 2008, P 1 ACM INT C MULT I, P443; Ghadimi E, 2015, IEEE T AUTOMAT CONTR, V60, P644, DOI 10.1109/TAC.2014.2354892; Gibaja E, 2014, WIRES DATA MIN KNOWL, V4, P411, DOI 10.1002/widm.1139; Goldberg A., 2010, P NIPS, V23, P757; Grubinger M., 2006, INT WORKSHOP ONTOIMA, V2; Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266; Kapoor Ashish, 2012, NIPS, V25, P2645; Li X, 2015, JMLR WORKSH CONF PRO, V38, P635; Li YQ, 2016, PATTERN RECOGN, V60, P890, DOI 10.1016/j.patcog.2016.07.009; Lin ZJ, 2013, PROC CVPR IEEE, P1618, DOI 10.1109/CVPR.2013.212; Manning C. D., 2008, INTRO INFORM RETRIEV, V1; Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282; Raghunathan A. U., 2014, PROC S MATH THEORY N, P807; Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835; Rousu J, 2006, J MACH LEARN RES, V7, P1601; Rousu Juho, 2005, ICML, P744; Snoek C.G., 2006, P 14 ANN ACM INT C M, P421, DOI DOI 10.1145/1180639.1180727; Sun HJ, 2016, J INEQUAL APPL, DOI 10.1186/s13660-016-1173-2; Sun YY, 2010, AAAI CONF ARTIF INTE, P593; Tousch AM, 2012, PATTERN RECOGN, V45, P333, DOI 10.1016/j.patcog.2011.05.017; Vasisht D, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P472, DOI 10.1145/2623330.2623759; Von Ahn Luis, 2004, P SIGCHI C HUM FACT, P319, DOI DOI 10.1145/985692.985733; von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z; Wang QF, 2014, LECT NOTES COMPUT SC, V8691, P378, DOI 10.1007/978-3-319-10578-9_25; Wang QF, 2014, LECT NOTES COMPUT SC, V8690, P425, DOI 10.1007/978-3-319-10605-2_28; Weston J., 2002, NIPS, P873; Wu B., 2017, P IEEE C COMPUTER VI, P2559; Wu B., 2018, CVPR; Wu B, 2016, AAAI CONF ARTIF INTE, P2229; Wu BY, 2015, IEEE I CONF COMP VIS, P4157, DOI 10.1109/ICCV.2015.473; Wu BY, 2015, PATTERN RECOGN, V48, P2279, DOI 10.1016/j.patcog.2015.01.022; Wu L, 2013, IEEE T PATTERN ANAL, V35, P716, DOI 10.1109/TPAMI.2012.124; Xu C, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1275, DOI 10.1145/2939672.2939798; Xu Miao, 2013, ADV NEURAL INFORM PR, P2301, DOI DOI 10.5555/2999792.2999869; Yu GX, 2015, BMC BIOINFORMATICS, V16, DOI 10.1186/s12859-014-0430-y; Yu H.-F., 2014, INT C MACH LEARN, P593; Zehfuss G., 1858, Z MATH PHYS, V3, P298; Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019; Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39; Zhang TZ, 2012, LECT NOTES COMPUT SC, V7577, P470, DOI 10.1007/978-3-642-33783-3_34; Zhang Y, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1839490.1839495	58	35	42	1	22	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2018	126	8					875	896		10.1007/s11263-018-1085-3	http://dx.doi.org/10.1007/s11263-018-1085-3			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	GL5ZB		Green Submitted			2022-12-18	WOS:000437253500005
J	Ordonez, V; Han, XF; Kuznetsova, P; Kulkarni, G; Mitchell, M; Yamaguchi, K; Stratos, K; Goyal, A; Dodge, J; Mensch, A; Daume, H; Berg, AC; Choi, Y; Berg, TL				Ordonez, Vicente; Han, Xufeng; Kuznetsova, Polina; Kulkarni, Girish; Mitchell, Margaret; Yamaguchi, Kota; Stratos, Karl; Goyal, Amit; Dodge, Jesse; Mensch, Alyssa; Daume, Hal, III; Berg, Alexander C.; Choi, Yejin; Berg, Tamara L.			Large Scale Retrieval and Generation of Image Descriptions	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Retrieval; Image description; Data driven; Big data; Natural language processing	SCENE	What is the story of an image? What is the relationship between pictures, language, and information we can extract using state of the art computational recognition systems? In an attempt to address both of these questions, we explore methods for retrieving and generating natural language descriptions for images. Ideally, we would like our generated textual descriptions (captions) to both sound like a person wrote them, and also remain true to the image content. To do this we develop data-driven approaches for image description generation, using retrieval-based techniques to gather either: (a) whole captions associated with a visually similar image, or (b) relevant bits of text (phrases) from a large collection of image + description pairs. In the case of (b), we develop optimization algorithms to merge the retrieved phrases into valid natural language sentences. The end result is two simple, but effective, methods for harnessing the power of big data to produce image captions that are altogether more general, relevant, and human-like than previous attempts.	[Ordonez, Vicente; Han, Xufeng; Berg, Alexander C.; Berg, Tamara L.] Univ N Carolina, Chapel Hill, NC 27599 USA; [Kuznetsova, Polina; Kulkarni, Girish] SUNY Stony Brook, Stony Brook, NY 11794 USA; [Mitchell, Margaret] Microsoft Res, Redmond, WA USA; [Yamaguchi, Kota] Tohoku Univ, Sendai, Miyagi, Japan; [Stratos, Karl] Columbia Univ, New York, NY USA; [Goyal, Amit] Yahoo Labs, Sunnyvale, CA USA; [Dodge, Jesse] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA; [Mensch, Alyssa] Univ Penn, Philadelphia, PA 19104 USA; [Daume, Hal, III] Univ Maryland, College Pk, MD 20742 USA; [Choi, Yejin] Univ Washington, Seattle, WA 98195 USA	University of North Carolina; University of North Carolina Chapel Hill; State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook; Microsoft; Tohoku University; Columbia University; Carnegie Mellon University; University of Pennsylvania; University System of Maryland; University of Maryland College Park; University of Washington; University of Washington Seattle	Berg, AC (corresponding author), Univ N Carolina, Chapel Hill, NC 27599 USA.	vicente@cs.unc.edu; aberg@cs.unc.edu; tlberg@cs.unc.edu			JHU-CLSP Summer Workshop Program; NSF CAREER [IIS-1054133]; NSF [IIS-1139909]	JHU-CLSP Summer Workshop Program; NSF CAREER(National Science Foundation (NSF)NSF - Office of the Director (OD)); NSF(National Science Foundation (NSF))	Support of the 2011 JHU-CLSP Summer Workshop Program. Tamara L. Berg and Kota Yamaguchi were supported in part by NSF CAREER IIS-1054133; Hal Daume III and Amit Goyal were partially supported by NSF Award IIS-1139909.	Aker A., 2010, ACL; Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214; Berg T., 2004, CVPR; Berg T. L., 2004, NIPS; Berg Tamara L, 2010, ECCV; Brants T., 2006, LDC; Brin S., 1998, WWW; Chum O., 2008, BMVC; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Deng J., 2011, ADV NEURAL INFORM PR; Deng J., 2012, CVPR; Deng J., 2011, CVPR; Deng J., 2010, ECCV; Duygulu P., 2002, ECCV; Farhadi A., 2009, CVPR; Farhadi A., 2010, ECCV; Felzenszwalb P. F., 2011, DISCRIMINATIVELY TRA; Feng Y., 2010, ACL; FERRARI V, 2007, P ADV NEUR INF PROC; Guadarrama S., 2013, INT C COMP VIS; Hays J., 2008, CVPR; Hoiem Derek, 2005, CVPR; Jing Y., 2008, WWW; Klein D., 2006, COLING ACL; Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162; Kumar N., 2009, ICCV; Kuznetsova P., 2012, ACL; Kuznetsova P, 2013, ACL; Lampert C. H., 2009, CVPR; LEUNG T, 1999, ICCV; Li L-J., 2010, ADV NEURAL INF PROCE, V23, P106; Li Siming, 2011, CONLL; Li W., 2006, INT C COMP LING; Lin C.Y., 2004, ACL; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Mason R., 2014, ACL; Mihalcea R., 2005, AAAI; Mitchell Margaret, 2012, EACL; Nenkova A., 2006, SIGIR; Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724; Ordonez V., 2011, NIPS; Ordonez V, 2013, ICCV; Papineni K., 2002, P ANN M ASS COMP LIN; Petrov S., 2007, HLT NAACL; Radev D. R., 2004, LREC; Rashtchian C., 2010, NAACL WORKSH CREAT S; Roelleke T., 2008, SIGIR; Sivic J., 2003, ICCV; Stratos K., 2012, CVPR; Tighe J., 2010, ECCV; Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128; Wong K.-F., 2008, COLING; Xiao J., 2010, CVPR; Yang Y., 2011, EMNLP; Yao B, 2010, P IEEE; Young Peter, 2014, T ASSOC COMPUT LING, V2, P67	57	35	35	0	24	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	2016	119	1					46	59		10.1007/s11263-015-0840-y	http://dx.doi.org/10.1007/s11263-015-0840-y			14	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	DP9AP		Green Submitted			2022-12-18	WOS:000378789400004
J	Han, S; Sato, I; Okabe, T; Sato, Y				Han, Shuai; Sato, Imari; Okabe, Takahiro; Sato, Yoichi			Fast Spectral Reflectance Recovery Using DLP Projector	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Spectral reflectance; Color switch; High temporal resolution; Spectral relighting; DLP projector; High-speed camera; Color wheel	COLOR CONSTANCY; SURFACE	Spectral reflectance is an intrinsic characteristic of objects that is independent of illumination and the used imaging sensors. This direct representation of objects is useful for various computer vision tasks, such as color constancy and material discrimination. In this work, we present a novel system for spectral reflectance recovery with high temporal resolution by exploiting the unique color-forming mechanism of digital light processing (DLP) projectors. DLP projectors use color wheels, which are composed of a number of color segments and rotate quickly to produce the desired colors. Making effective use of this mechanism, we show that a DLP projector can be used as a light source with spectrally distinct illuminations when the appearance of a scene under the projector's irradiation is captured with a high-speed camera. Based on the measurements, the spectral reflectance of scene points can be recovered using a linear approximation of the surface reflectance. Our imaging system is built from off-the-shelf devices, and is capable of taking multi-spectral measurements as fast as 100 Hz. We carefully evaluated the accuracy of our system and demonstrated its effectiveness by spectral relighting of static as well as dynamic scenes containing different objects.	[Han, Shuai; Okabe, Takahiro; Sato, Yoichi] Univ Tokyo, Inst Ind Sci, Meguro, Tokyo 1538505, Japan; [Sato, Imari] Natl Inst Informat, Tokyo, Tokyo 1018430, Japan	University of Tokyo; Research Organization of Information & Systems (ROIS); National Institute of Informatics (NII) - Japan	Han, S (corresponding author), Univ Tokyo, Inst Ind Sci, 4-6-1 Komaba, Meguro, Tokyo 1538505, Japan.	hanshuai@iis.u-tokyo.ac.jp			Ministry of Education, Culture, Sports, Science and Technology; Grants-in-Aid for Scientific Research [22135001, 22135002] Funding Source: KAKEN	Ministry of Education, Culture, Sports, Science and Technology(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)); Grants-in-Aid for Scientific Research(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI))	This research was supported in part by Grant-in-Aid for Scientific Research on Innovative Areas from the Ministry of Education, Culture, Sports, Science and Technology.	Abrardo A., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P570, DOI 10.1109/ICIP.1999.817179; Chi C, 2010, INT J COMPUT VISION, V86, P140, DOI 10.1007/s11263-008-0176-y; Chiao CC, 2000, J OPT SOC AM A, V17, P218, DOI 10.1364/JOSAA.17.000218; COHEN J, 1964, PSYCHON SCI, V1, P369, DOI 10.3758/BF03342963; DANNEMILLER JL, 1992, J OPT SOC AM A, V9, P507, DOI 10.1364/JOSAA.9.000507; DiCarlo J. M., 2000, COL IMAG C SCOTTSD, P27; DiCarlo JM, 2003, J OPT SOC AM A, V20, P1261, DOI 10.1364/JOSAA.20.001261; Du H, 2009, IEEE I CONF COMP VIS, P175, DOI 10.1109/ICCV.2009.5459162; DZMURA M, 1992, J OPT SOC AM A, V9, P490, DOI 10.1364/JOSAA.9.000490; Finlayson GD, 2005, PROC CVPR IEEE, P1079; Gat N, 2000, P SOC PHOTO-OPT INS, V4056, P50, DOI 10.1117/12.381686; Han S., 2010, AS C COMP VIS ACCV; Jasinski MF, 1996, IEEE T GEOSCI REMOTE, V34, P804, DOI 10.1109/36.499785; Jiang J, 2013, IEEE WORK APP COMP, P168, DOI 10.1109/WACV.2013.6475015; Kohonen O, 2006, COLOR RES APPL, V31, P381, DOI 10.1002/col.20244; Liu JJ, 2012, IEEE INFOCOM SER, P1, DOI 10.1109/INFCOM.2012.6195580; MALONEY LT, 1986, J OPT SOC AM A, V3, P1673, DOI 10.1364/JOSAA.3.001673; MALONEY LT, 1986, J OPT SOC AM A, V3, P29, DOI 10.1364/JOSAA.3.000029; Narasimhan SG, 2008, LECT NOTES COMPUT SC, V5305, P830, DOI 10.1007/978-3-540-88693-8_61; Nayar SK, 2006, INT J COMPUT VISION, V70, P7, DOI 10.1007/s11263-005-3102-6; Park JI, 2007, IEEE I CONF COMP VIS, P2049; PARKKINEN JPS, 1989, J OPT SOC AM A, V6, P318, DOI 10.1364/JOSAA.6.000318; Schechner YY, 2002, IEEE T PATTERN ANAL, V24, P1334, DOI 10.1109/TPAMI.2002.1039205; Tominaga S, 1996, J OPT SOC AM A, V13, P2163, DOI 10.1364/JOSAA.13.002163; Tominaga S, 2000, INT C PATT RECOG, P708, DOI 10.1109/ICPR.2000.905485; Wenger A., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P249; Xing XX, 2010, LECT NOTES COMPUT SC, V6249, P509, DOI 10.1007/978-3-642-14533-9_52; Yamaguchi M, 2006, PROC SPIE, V6062, DOI 10.1117/12.649454; Zhang S., 2004, IEEE COMP VIS PATT R, P28, DOI DOI 10.1109/CVPR.2004.86	29	35	36	0	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	2014	110	2			SI		172	184		10.1007/s11263-013-0687-z	http://dx.doi.org/10.1007/s11263-013-0687-z			13	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	AY5UE		Green Submitted			2022-12-18	WOS:000347636400007
J	Rao, SR; Yang, AY; Sastry, SS; Ma, Y				Rao, Shankar R.; Yang, Allen Y.; Sastry, S. Shankar; Ma, Yi			Robust Algebraic Segmentation of Mixed Rigid-Body and Planar Motions from Two Views	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Motion segmentation; Epipolar geometry; Homography; Outlier rejection; Influence function; Algebraic segmentation	ESTIMATOR	This paper studies segmentation of multiple rigid-body motions in a 3-D dynamic scene under perspective camera projection. We consider dynamic scenes that contain both 3-D rigid-body structures and 2-D planar structures. Based on the well-known epipolar and homography constraints between two views, we propose a hybrid perspective constraint (HPC) to unify the representation of rigid-body and planar motions. Given a mixture of K hybrid perspective constraints, we propose an algebraic process to partition image correspondences to the individual 3-D motions, called Robust Algebraic Segmentation (RAS). Particularly, we prove that the joint distribution of image correspondences is uniquely determined by a set of (2K)-th degree polynomials, a global signature for the union of K motions of possibly mixed type. The first and second derivatives of these polynomials provide a means to recover the association of the individual image samples to their respective motions. Finally, using robust statistics, we show that the polynomials can be robustly estimated in the presence of moderate image noise and outliers. We conduct extensive simulations and real experiments to validate the performance of the new algorithm. The results demonstrate that RAS achieves notably higher accuracy than most existing robust motion-segmentation methods, including random sample consensus (RANSAC) and its variations. The implementation of the algorithm is also two to three times faster than the existing methods. The implementation of the algorithm and the benchmark scripts are available at http://perception.csl.illinois.edu/ras/ .	[Rao, Shankar R.; Ma, Yi] Univ Illinois, Dept ECE, Coordinate Sci Lab, Urbana, IL 61801 USA; [Yang, Allen Y.; Sastry, S. Shankar] Univ Calif Berkeley, Dept EECS, Berkeley, CA 94720 USA; [Rao, Shankar R.] HRL Labs LLC, Malibu, CA 90265 USA; [Ma, Yi] Microsoft Res Asia, Visual Comp Grp, Beijing, Peoples R China	University of Illinois System; University of Illinois Urbana-Champaign; University of California System; University of California Berkeley; HRL Laboratories; Microsoft; Microsoft Research Asia	Rao, SR (corresponding author), Univ Illinois, Dept ECE, Coordinate Sci Lab, Urbana, IL 61801 USA.	srrao@illinois.edu; yang@eecs.berkeley.edu; sastry@eecs.berkeley.edu; yima@illinois.edu			NSF [CAREER IIS-0347456]; ONR [YIP N00014-05-1-0633]; ARO [MURI W911NF-06-1-0076]	NSF(National Science Foundation (NSF)); ONR(Office of Naval Research); ARO	The authors would like to thank Roberto Tron and Prof. Rene Vidal of Johns Hopkins University, Dr. Konrad Schindler of ETH Zurich, Dr. Raghav Subbarao and Prof. Peter Meer of Rutgers University, Prof. Kenichi Kanatani of Okayama University, and Prof. Philip H. S. Torr of Oxford Brooks University for providing us with code and test sequences. This work is partially supported by NSF CAREER IIS-0347456, ONR YIP N00014-05-1-0633, and ARO MURI W911NF-06-1-0076.	AGRAWAL R, 1998, P ACM SPEC INT GROUP; ANANDAN P, 2000, P EUR C COMP VIS; BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1; BARTOLI A, 2001, P IEEE C COMP VIS PA; Campbell N. A., 1980, Applied Statistics, V29, P231, DOI 10.2307/2346896; Campbell NA., 1978, APPLIED STATISTICS, V27, P251; Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Frahm J.-M., 2006, P C COMP VIS PATT RE, P453; GNANADESIKAN R, 1972, BIOMETRICS, V28, P81, DOI 10.2307/2528963; Goh A, 2007, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2007.383235; Goshen L, 2005, INT J COMPUT VISION, V65, P131, DOI 10.1007/s11263-005-3673-2; Hampel FR., 2011, WILEY SERIES PROBABI; Han M, 2000, PROC CVPR IEEE, P542, DOI 10.1109/CVPR.2000.854908; HARRIS J., 1992, ALGEBRAIC GEOMETRY 1; Huber P., 1981, ROBUST STAT; Jollife I.T., 2002, PRINCIPAL COMPONENT; Kanatani, 2012, INT J IMAGE GRAPHICS, V2, P179, DOI DOI 10.1142/S0219467802000585; Kanatani K., 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P7; KANATANI K, 2003, P AUSTR JAP ADV WORK; Lang S, 2002, ALGEBRA, VThird; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Leonardis A, 2002, PATTERN RECOGN, V35, P2613, DOI 10.1016/S0031-3203(01)00198-4; Ma Y, 2008, SIAM REV, V50, P413, DOI 10.1137/060655523; Ma Y, 2007, IEEE T PATTERN ANAL, V29, P1546, DOI 10.1109/TP'AMI.2007.1085; Ng A.Y., 2001, P NEUR INF PROC SYST; OZDEN K, 2007, P IEEE INT C COMP VI; RAO S, 2008, P IEEE C COMP VIS PA; RAO S, 2005, P IEEE INT C COMP VI; ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718; SCHINDLER K, 2005, P IEEE C COMP VIS PA; Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467; SHAPIRO LS, 1995, AFFINE ANAL IMAGE SE; Shashua A, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P592, DOI 10.1109/ICCV.2001.937680; SOUVENIR R, 2007, INT C COMP VIS; STEWART CV, 1995, IEEE T PATTERN ANAL, V17, P925, DOI 10.1109/34.464558; Stewart CV, 1999, SIAM REV, V41, P513, DOI 10.1137/S0036144598345802; SUBBARAO R, 2006, CVPR WORKSH 25 YEARS; Sugaya Y, 2003, IEICE T INF SYST, VE86D, P1095; TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273; Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728; Tong WS, 2004, IEEE T PATTERN ANAL, V26, P1167, DOI 10.1109/TPAMI.2004.72; Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832; Torr PHS, 2003, IEEE T PATTERN ANAL, V25, P354, DOI 10.1109/TPAMI.2003.1182098; Torr PHS, 1998, PHILOS T R SOC A, V356, P1321, DOI 10.1098/rsta.1998.0224; TRIGGS B, 1995, P IEEE INT C COMP VI; Tron R, 2007, PROC CVPR IEEE, P41, DOI 10.1109/cvpr.2007.382974; Vidal R., 2005, IEEE T PATTERN ANAL, V27, P1; Vidal R, 2008, IEEE T PATTERN ANAL, V30, P214, DOI [10.1109/TPAMI.2007.1179, 10.1109/TPAMl.2007.1179]; Vidal R, 2006, J MATH IMAGING VIS, V25, P403, DOI 10.1007/s10851-006-8286-z; Vidal R, 2006, INT J COMPUT VISION, V68, P7, DOI 10.1007/s11263-005-4839-7; Wang HZ, 2004, INT J COMPUT VISION, V59, P139, DOI 10.1023/B:VISI.0000022287.61260.b0; Weiss Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P975, DOI 10.1109/ICCV.1999.790354; Yan JY, 2006, LECT NOTES COMPUT SC, V3954, P94; Yang A., 2006, CVPR WORKSH 25 YEARS; YANG A, 2005, P IEEE C COMP VIS PA; YANG A, 2006, THESIS U ILLINOIS UR	57	35	40	0	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUL	2010	88	3					425	446		10.1007/s11263-009-0314-1	http://dx.doi.org/10.1007/s11263-009-0314-1			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	580EL		Green Published, Bronze			2022-12-18	WOS:000276429900005
J	Jaeggli, T; Koller-Meier, E; Van Gool, L				Jaeggli, Tobias; Koller-Meier, Esther; Van Gool, Luc			Learning Generative Models for Multi-Activity Body Pose Estimation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Monocular pose estimation; Machine learning; Dimensionality reduction; Activity recognition; Human locomotion		We present a method to simultaneously estimate 3D body pose and action categories from monocular video sequences. Our approach learns a generative model of the relationship of body pose and image appearance using a sparse kernel regressor. Body poses are modelled on a low-dimensional manifold obtained by Locally Linear Embedding dimensionality reduction. In addition, we learn a prior model of likely body poses and a dynamical model in this pose manifold. Sparse kernel regressors capture the nonlinearities of this mapping efficiently. Within a Recursive Bayesian Sampling framework, the potentially multimodal posterior probability distributions can then be inferred. An activity-switching mechanism based on learned transfer functions allows for inference of the performed activity class, along with the estimation of body pose and 2D image location of the subject. Using a rough foreground segmentation, we compare Binary PCA and distance transforms to encode the appearance. As a postprocessing step, the globally optimal trajectory through the entire sequence is estimated, yielding a single pose estimate per frame that is consistent throughout the sequence. We evaluate the algorithm on challenging sequences with subjects that are alternating between running and walking movements. Our experiments show how the dynamical model helps to track through poorly segmented low-resolution image sequences where tracking otherwise fails, while at the same time reliably classifying the activity type.	[Jaeggli, Tobias; Koller-Meier, Esther; Van Gool, Luc] Swiss Fed Inst Technol, Zurich, Switzerland	Swiss Federal Institutes of Technology Domain; ETH Zurich	Jaeggli, T (corresponding author), Swiss Fed Inst Technol, Zurich, Switzerland.	jaeggli@vision.ee.ethz.ch; ebmeier@vision.ee.ethz.ch; vangool@vision.ee.ethz.ch			FP6 EU [IST-027787]; SNF [NCCR IM2]	FP6 EU(European Commission); SNF	This work is supported, in parts, by the FP6 EU Integrated Project DIRAC (IST-027787), the SNF project PICSEL and the SNF NCCR IM2.	Agarwal A., 2004, IEEE C COMP VIS PATT; AGARWAL A, 2005, IEEE CVPR WORKSH VIS; AGARWAL A, 2004, EUR C COMP VIS ECCV; BAILEY DG, 2004, INT WORKSH COMB IM A; Bhattacharyya A., 1943, B CALCUTTA MATH SOC; DOUCET A, 2000, P IEEE INT C AC SPEE, V2, P701; Doucet Arnaud, 2000, STAT COMPUTING; ELGAMMAL A, 2004, IEEE C COMP VIS PATT; FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030; FORSYTH DA, 2006, COMPUTER GRAPHICS VI, V1; Grauman K., 2003, INT C COMP VIS ICCV; Isard M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P107, DOI 10.1109/ICCV.1998.710707; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; Isard M., 2003, IEEE C COMP VIS PATT; JAEGGLI T, 2006, 4 C ART MOT DEF OBJ; Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572; Lawrence N, 2005, J MACH LEARN RES, V6, P1783; LEE CS, 2007, INT C COMP VIS ICCV; LI R, 2007, INT C COMP VIS ICCV; Li R, 2006, LECT NOTES COMPUT SC, V3952, P137; Lim H., 2006, IEEE C COMP VIS PATT, P751; Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002; NAVARATNAM R, 2007, INT C COMP VIS ICCV; PAVLOVIC V, 2001, NEURAL INFORM PROCES; ROSALES R, 2001, NEURAL INFORM PROCES; Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323; Sidenbladh H., 2000, LNCS, V2, P702; SIGAL L, 2004, IEEE C COMPUTER VISI; SMINCHISESCU C, 2004, INT C MACH LEARN ICM; Sminchisescu C., 2005, IEEE C COMP VIS PATT; SUDDERTH EB, 2003, IEEE C COMP VIS PATT; SUN Y, 2006, BRIT MACH VIS C; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; THAYANANTHAN A, 2006, EUR C COMP VIS ECCV; TIPPING M, 2000, NEURAL INFORM PROCES; Urtasun R., 2006, 2006 IEEE COMP VIS P, P238, DOI DOI 10.1109/CVPR.2006.15; Wang J., 2006, ADV NEURAL INFORM PR, P1441; Wiberg N., 1996, THESIS LINKOPING U S; Yedidia J. S., 2002, TR200122 MERL; ZIVKOVIC Z, 2006, IEEE C COMP VIS PATT, P254	40	35	36	0	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JUN	2009	83	2					121	134		10.1007/s11263-008-0158-0	http://dx.doi.org/10.1007/s11263-008-0158-0			14	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	423UE		Green Published, Green Submitted			2022-12-18	WOS:000264520400001
J	Smith, WAP; Hancock, ER				Smith, William A. P.; Hancock, Edwin R.			Facial shape-from-shading and recognition using principal geodesic analysis and robust statistics	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						shape-from-shading; face recognition; principal geodesic analysis	FACE RECOGNITION; SINGLE IMAGE; CONSTRAINTS; PERCEPTION; MODELS	The aim in this paper is to use principal geodesic analysis to model the statistical variations for sets of facial needle maps. We commence by showing how to represent the distribution of surface normals using the exponential map. Shape deformations are described using principal geodesic analysis on the exponential map. Using ideas from robust statistics we show how this deformable model may be fitted to facial images in which there is significant self-shadowing. Moreover, we demonstrate that the resulting shape-from-shading algorithm can be used to recover accurate facial shape and albedo from real world images. In particular, the algorithm can effectively fill-in the facial surface when more than 30% of its area is subject to self-shadowing. To investigate the utility of the shape parameters delivered by the method, we conduct experiments with illumination insensitive face recognition. We present a novel recognition strategy in which similarity is measured in the space of the principal geodesic parameters. We also use the recovered shape information to generate illumination normalized prototype images on which recognition can be performed. Finally we show that, from a single input image, we are able to generate the basis images employed by a number of well known illumination-insensitive recognition algorithms. We also demonstrate that the principal geodesics provide an efficient parameterization of the space of harmonic basis images.	[Smith, William A. P.; Hancock, Edwin R.] Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England	University of York - UK	Smith, WAP (corresponding author), Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England.	wsmith@cs.york.ac.uk	Smith, William/AAK-9101-2020; Hancock, Edwin/N-7548-2019; Hancock, Edwin R/C-6071-2008	Smith, William/0000-0002-6047-0413; Hancock, Edwin/0000-0003-4496-2028; Hancock, Edwin R/0000-0003-4496-2028				Atick JJ, 1996, NEURAL COMPUT, V8, P1321, DOI 10.1162/neco.1996.8.6.1321; Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153; Belhumeur PN, 1999, INT J COMPUT VISION, V35, P33, DOI 10.1023/A:1008154927611; Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556; Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983; Blanz V, 2003, COMPUT GRAPH FORUM, V22, P641, DOI 10.1111/1467-8659.t01-1-00712; Bronstein AM, 2005, INT J COMPUT VISION, V64, P5, DOI 10.1007/s11263-005-1085-y; Castelan M, 2006, COMPUT VIS IMAGE UND, V103, P64, DOI 10.1016/j.cviu.2006.03.001; DOVGARD R, 2004, P ECCV, V2, P99; Dupuis P, 1994, ANN APPL PROBAB, V4, P287, DOI 10.1214/aoap/1177005063; Finlayson GD, 2004, LECT NOTES COMPUT SC, V3023, P582; FISHER NI, 1985, J ROY STAT SOC B MET, V47, P342; Fletcher PT, 2004, IEEE T MED IMAGING, V23, P995, DOI 10.1109/TMI.2004.831793; FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909; FUA P, 1994, P ECCV, P281; Georghiades A. S., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P230; Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464; Giles PT, 2001, PHOTOGRAMM ENG REM S, V67, P833; Gregory RL, 1997, PHILOS T ROY SOC B, V352, P1121, DOI 10.1098/rstb.1997.0095; Hill H, 1996, J EXP PSYCHOL HUMAN, V22, P986, DOI 10.1037/0096-1523.22.4.986; Huber P., 1981, ROBUST STAT; Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92; Lenglet C, 2005, LECT NOTES COMPUT SC, V3565, P591; Levine MD, 2005, PATTERN RECOGN LETT, V26, P251, DOI 10.1016/j.patrec.2004.10.021; Mardia K.V., 2000, DIRECTIONAL STAT; Marr D., 1982, VISION; NISHINO K, 2005, P ICCV, V1, P519; Pennec X., 1999, P IEEE WORKSH NONL S; PENNEC X, 2004, RR5093 INRIA; PRADOS E, 2004, P ECCV, P141, DOI DOI 10.1007/978-3-540-24673-2_12; PRADOS E, 2004, RR5133 INRIA; Samaras D, 2003, IEEE T PATTERN ANAL, V25, P247, DOI 10.1109/TPAMI.2003.1177155; Smith WAP, 2006, IEEE T PATTERN ANAL, V28, P1914, DOI 10.1109/TPAMI.2006.251; TURK M, 1991, P IEEE C COMP VIS PA, P586, DOI DOI 10.1109/CVPR.1991.139758; *U S FLOR, USF HUMANID 3D DAT C; Worthington PL, 1999, IEEE T PATTERN ANAL, V21, P1250, DOI 10.1109/34.817406; Zhang L, 2005, PROC CVPR IEEE, P209; Zhao WY, 2001, INT J COMPUT VISION, V45, P55, DOI 10.1023/A:1012369907247; Zhao WY, 2000, PROC CVPR IEEE, P286, DOI 10.1109/CVPR.2000.855831; Zhou SH, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P11	40	35	36	0	6	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2008	76	1					71	91		10.1007/s11263-007-0074-8	http://dx.doi.org/10.1007/s11263-007-0074-8			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	248VS					2022-12-18	WOS:000252185800005
J	Rosales, R; Sclaroff, S				Rosales, Romer; Sclaroff, Stan			Combining generative and discriminative models in a framework for articulated pose estimation	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						human body pose; hand pose; nonrigid and articulated pose estimation; statistical inference; generative and discriminative models; mixture models; expectation maximization algorithm	TRACKING; EM; RECONSTRUCTION	We develop a method for the estimation of articulated pose, such as that of the human body or the human hand, from a single (monocular) image. Pose estimation is formulated as a statistical inference problem, where the goal is to find a posterior probability distribution over poses as well as a maximum a posteriori (MAP) estimate. The method combines two modeling approaches, one discriminative and the other generative. The discriminative model consists of a set of mapping functions that are constructed automatically from a labeled training set of body poses and their respective image features. The discriminative formulation allows for modeling ambiguous, one-to-many mappings (through the use of multi-modal distributions) that may yield multiple valid articulated pose hypotheses from a single image. The generative model is defined in terms of a computer graphics rendering of poses. While the generative model offers an accurate way to relate observed (image features) and hidden (body pose) random variables, it is difficult to use it directly in pose estimation, since inference is computationally intractable. In contrast, inference with the discriminative model is tractable, but considerably less accurate for the problem of interest. A combined discriminative/generative formulation is derived that leverages the complimentary strengths of both models in a principled framework for articulated pose inference. Two efficient MAP pose estimation algorithms are derived from this formulation; the first is deterministic and the second non-deterministic. Performance of the framework is quantitatively evaluated in estimating articulated pose of both the human hand and human body.	MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA; Boston Univ, Dept Comp Sci, Image & Video Comp Grp, Boston, MA 02215 USA	Massachusetts Institute of Technology (MIT); Boston University	Rosales, R (corresponding author), MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	romer@csail.mit.edu; sclaroff@cs.bu.edu						ALT FL, 1962, J ACM, V9, P240, DOI 10.1145/321119.321122; Amari SI, 1995, NEURAL NETWORKS, V8, P1379, DOI 10.1016/0893-6080(95)00003-8; Barron C, 2000, PROC CVPR IEEE, P669, DOI 10.1109/CVPR.2000.855884; Black MJ, 1997, PROC CVPR IEEE, P561, DOI 10.1109/CVPR.1997.609381; Brand M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1237, DOI 10.1109/ICCV.1999.790422; Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581; Cheng J, 2000, J ARTIF INTELL RES, V13, P155, DOI 10.1613/jair.764; Cover TM., 1999, ELEMENTS INFORM THEO; Csiszar I., 1984, STAT DECISIONS, V1, P205; DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x; DEUTSCHER J, 2000, P COMP VIS PATT REC; Felzenszwalb P., 2000, P COMP VIS PATT REC; FRIEDMAN JH, 1991, ANN STAT, V19, P1, DOI 10.1214/aos/1176347963; Gavrila D, 1995, INT WORKSH AUT FAC G, P272; Haritaoglu I, 1998, INT C PATT RECOG, P77, DOI 10.1109/ICPR.1998.711084; Heap T, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P140, DOI 10.1109/AFGR.1996.557255; Hinton GE, 1998, NATO ADV SCI I D-BEH, V89, P479; HOGG D, 1983, IMAGE VISION COMPUT, V1, P5, DOI DOI 10.1016/0262-8856(83)90003-3; Howe NR, 2000, ADV NEUR IN, V12, P820; HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692; IIJIMA T, 1973, P 1 INT JOINT C PATT, P50; Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650; JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378; Jordan M. I., 1999, LEARNING GRAPHICAL M; JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181; MacKay D.J.C., 1998, LEARNING GRAPHICAL M; MCLACHLAN GJ, 1992, DICRIMINANT ANAL STA; Ormoneit D, 2001, ADV NEUR IN, V13, P894; Pavlovic V, 2001, ADV NEUR IN, V13, P981; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; REHG JM, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P612, DOI 10.1109/ICCV.1995.466882; RISSANEN J, 1986, ANN STAT, V14, P1080, DOI 10.1214/aos/1176350051; Rosales R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P378, DOI 10.1109/ICCV.2001.937543; ROSALES R, 2002, THESIS BOSTON U; RUBINSTEIN R, 1998, 3 INT C KNOWL DISC D, P49; Rubinstein R. Y., 2017, SIMULATION MONTE CAR, V3rd, DOI 10.1002/9781118631980; Shimada N, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P268, DOI 10.1109/AFGR.1998.670960; Sigal L, 2000, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2000.854764; Sminchisescu C, 2001, PROC CVPR IEEE, P447; Song Y, 2000, PROC CVPR IEEE, P810, DOI 10.1109/CVPR.2000.855904; Taylor CJ, 2000, COMPUT VIS IMAGE UND, V80, P349, DOI 10.1006/cviu.2000.0878; *VIRT TECHN INC, 1998, VIRT HAND SOFTW LIB; Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236	46	35	35	0	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2006	67	3					251	276		10.1007/s11263-006-5165-4	http://dx.doi.org/10.1007/s11263-006-5165-4			26	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	052JA					2022-12-18	WOS:000238228800001
J	Liu, YX; Tsin, YH; Lin, WC				Liu, YX; Tsin, YH; Lin, WC			The promise and perils of near-regular texture	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						near-regular texture; texture synthesis; lattice; texture analysis; symmetry groups	MODEL; IMAGE	Motivated by the low structural fidelity for near-regular textures in current texture synthesis algorithms, we propose and implement an alternative texture synthesis method for near-regular texture. We view such textures as statistical departures from regular patterns and argue that a thorough understanding of their structures in terms of their translation symmetries can enhance existing methods of texture synthesis. We demonstrate the perils of texture synthesis for near-regular texture and the promise of faithfully preserving the regularity as well as the randomness in a near-regular texture sample.	Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Liu, YX (corresponding author), Carnegie Mellon Univ, Inst Robot, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	yanxi@cs.cinu.edu; ytsin@cs.cmu.edu; wclin@cs.cmu.edu						ASHIKHMIN M, 2001, ACM S INT 3D GRAPH, P217, DOI DOI 10.1145/364338.364405; CHAMBERS DA, 1995, DNA DOUBLE HELIX PER; Chetverikov D, 2000, IMAGE VISION COMPUT, V18, P975, DOI 10.1016/S0262-8856(00)00041-X; CHETVERIKOV D, 2002, THESIS MTA SZTAKI BU; Cohen MF, 2003, ACM T GRAPHIC, V22, P287, DOI 10.1145/882262.882265; CONNERS RW, 1980, COMPUT VISION GRAPH, V12, P224, DOI 10.1016/0146-664X(80)90013-1; Coxeter H.S.M., 1980, INTRO GEOMETRY, VSecond; Coxeter H. S. M., 1980, GENERATORS RELATIONS; CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341; De Bonet J. S., 1997, SIGGRAPH 97, P361, DOI [10.1145/258734.258882, DOI 10.1145/258734.258882]; Efros A., 1999, INT C COMP VIS; Efros A., 2001, SIGGRAPH, P35; ENRICH R, 1978, COMPUTER GRAPHICS IM, V8, P174; Fedorov E. S., 1885, ZAPISKI IMPERATORSKO, P1; Feynman RP, 1998, 6 NOT SO EASY PIECES; Gr?nbaum B., 1987, TILINGS PATTERNS; Hargittai I., 2000, OUR OWN IMAGE PERSON; Henry N. F., 1969, INT TABLES XRAY CRYS, VI; HERTZMANN A., 2001, SIGGRAPH; Hsu TI, 1998, IEEE T IMAGE PROCESS, V7, P1466, DOI 10.1109/83.718486; KAPLAN CS, 2000, 27 INT C COMP GRAPH; Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264; Leyton M., 1992, SYMMETRY CAUSALITY M; Liang L, 2001, ACM T GRAPHIC, V20, P127, DOI 10.1145/501786.501787; LIN WC, 2004, UNPUB SIGGRAPH 2004, P1; LIU Y, 2001, WENNERGREN INT SERIE, V80, P231; Liu YX, 2004, ACM T GRAPHIC, V23, P368, DOI 10.1145/1015706.1015731; Liu YX, 2004, IEEE T PATTERN ANAL, V26, P354, DOI 10.1109/TPAMI.2004.1262332; Liu YX, 2001, PROC CVPR IEEE, P872; Liu YX, 2000, PROC CVPR IEEE, P537, DOI 10.1109/CVPR.2000.855866; LU SY, 1978, COMPUT VISION GRAPH, V7, P303, DOI 10.1016/S0146-664X(78)80001-X; Miller W., 1972, SYMMETRY GROUPS THEI; Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983; RAO AR, 1993, CVGIP-GRAPH MODEL IM, V55, P218, DOI 10.1006/cgip.1993.1016; SCHATTSCHNEIDER D, 1978, AM MATH MON, V85, P439, DOI 10.2307/2320063; Senechal M., 1995, QUASICRYSTALS GEOMET; Tsin YH, 2001, PROC CVPR IEEE, P539; Washburn D.K., 1991, SYMMETRIES CULTURE T; Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009; XU YQ, 2001, INT WORKSH STAT COMP; ZEE A, 1999, FEARFUL SYMMETRY; Zhu SC, 1997, NEURAL COMPUT, V9, P1627, DOI 10.1162/neco.1997.9.8.1627; ZHU SC, 2002, P EUR C COMP VIS COP; ZHU SC, 2000, IEEE T PAMI, V22; Zucker SW., 1976, COMPUTER GRAPHICS IM, V5, P190, DOI [10.1016/0146-664X(76)90027-7, DOI 10.1016/0146-664X(76)90027-7]; [No title captured]	46	35	38	0	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR-MAY	2005	62	1-2					145	159						15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	866XV		Green Submitted			2022-12-18	WOS:000224807600009
J	Oliensis, J				Oliensis, J			A multi-frame structure-from-motion algorithm under perspective projection	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						structure from motion; multi-frame structure from motion; two-frame algorithms; perspective; partial calibration; bas-relief ambiguity; rigorous results; optimal estimation; orthographic projection; shape from X; reconstruction; experiments	RECOVERING 3-D MOTION; NOISY FLOW FIELD; IMAGE SEQUENCES; INHERENT AMBIGUITIES; STATISTICAL-ANALYSIS; 2 VIEWS; SHAPE	We present a fast, robust algorithm for multi-frame structure from motion from point features which works for general motion and large perspective effects. The algorithm is for point features but easily extends to a direct method based on image intensities. Experiments on synthetic and real sequences show that the algorithm gives results nearly as accurate as the maximum likelihood estimate in a couple of seconds on an IRIS 10000. The results are significantly better than those of an optimal two-image estimate. When the camera projection is close to scaled orthographic, the accuracy is comparable to that of the Tomasi/Kanade algorithm, and the algorithms are comparably fast. The algorithm incorporates a quantitative theoretical analysis of the bas-relief ambiguity and exemplifies how such an analysis can be exploited to improve reconstruction. Also, we demonstrate a structure-from-motion algorithm for partially calibrated cameras, with unknown focal length varying from image to image. Unlike the projective approach, this algorithm fully exploits the partial knowledge of the calibration. It is given by a simple modification of our algorithm for calibrated sequences and is insensitive to errors in calibrating the camera center. Theoretically, we show that unknown focal-length variations strengthen the effects of the bas-relief ambiguity. This paper includes extensive experimental studies of two-frame reconstruction and the Tomasi/Kanade approach in comparison to our algorithm. We find that two-frame algorithms are surprisingly robust and accurate, despite some problems with local minima. We demonstrate experimentally that a nearly optimal two-frame reconstruction can be computed quickly, by a minimization in the motion parameters alone. Lastly, we show that a well known problem with the Tomasi/Kanade algorithm is often not a significant one.	NEC Res Inst, Princeton, NJ 08540 USA	NEC Corporation	Oliensis, J (corresponding author), NEC Res Inst, 4 Independence Way, Princeton, NJ 08540 USA.	oliensis@research.nj.nec.com						ADIV G, 1989, IEEE T PATTERN ANAL, V11, P477, DOI 10.1109/34.24780; AZARBAYEJANI A, 1995, PAMI, P562; BELHUMEUR PN, 1997, CVPR, P1060; BROIDA TJ, 1991, IEEE T PATTERN ANAL, V13, P497, DOI 10.1109/34.87338; *CMU, 1994, CIL0001 CMU; CUI N, 1994, CVGIP-IMAG UNDERSTAN, V59, P154, DOI 10.1006/ciun.1994.1010; DANIILIDIS K, 1990, IMAGE VISION COMPUT, V8, P297, DOI 10.1016/0262-8856(90)80006-F; DANIILIDIS K, 1997, VISUAL NAVIGATION, P60; Frahm J.-M., 1996, EUR C COMP VIS CAMBR, P2; Golub G.H., 2013, MATRIX COMPUTATIONS, P357; HARRIS CG, 1988, IMAGE VISION COMPUT, V6, P87, DOI 10.1016/0262-8856(88)90003-0; Hartley R., 1994, Image Understanding Workshop. Proceedings, P1009; HARTLEY R, 1993, 2 WORKSH INV AZ, P187; Hartley R. I., 1994, Image Understanding Workshop. Proceedings, P957; HARTLEY RI, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P882, DOI 10.1109/ICCV.1995.466843; Hartley RI, 1997, COMPUT VIS IMAGE UND, V68, P146, DOI 10.1006/cviu.1997.0547; Hartley RI, 1997, INT J COMPUT VISION, V22, P125, DOI 10.1023/A:1007936012022; HARTLEY RI, 1995, PAMI, V19, P580; Heyden A, 1997, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.1997.609362; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; HORN BKP, 1990, INT J COMPUT VISION, V4, P59, DOI 10.1007/BF00137443; JACOBS D, 1997, CVPR, P206; JEPSON AD, 1993, SPATIAL VISION IN HUMANS AND ROBOTS, P39; JEPSON AD, 1991, MOT WORKSH PRINC, P124; JEPSON AD, 1990, RBCVTR9036; KANATANI K, 1993, IEEE T PATTERN ANAL, V15, P37, DOI 10.1109/34.184773; Kanatani K., 1996, STAT OPTIMIZATION GE; KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377; KUMAR R, 1994, INT C PATT RECOG, P685, DOI 10.1109/ICPR.1994.576402; LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0; MATTHIES L, 1989, INT J COMPUT VISION, V3, P209, DOI 10.1007/BF00133032; MAYBANK S, 1993, THEORY RECONSTRUCTIO; MAYBANK SJ, 1987, THESIS U LONDON; Oliensis J., 1994, Image Understanding Workshop. Proceedings, P1225; OLIENSIS J, 1997, NEW STRUCTURE MOTION; OLIENSIS J, 1995, EXPT STUDY PROJECTIV; OLIENSIS J, 1991, WORKSH VIS MOT PRINC, P8; OLIENSIS J, 1997, RECOVERING HEADING S; OLIENSIS J, 1997, CRITIQUE STRUCTURE M; OLIENSIS J, 1995, WORKSH REPR VIS SCEN, P77; OLIENSIS J, 1996, CVPR, P335; OLIENSIS J, UNPUB; OLIESIS J, 1997, MULTIFRAME STRUCTURE; Pollefeys M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P90, DOI 10.1109/ICCV.1998.710705; POLLEFEYS M, 1996, ECCV, V1, P31; SHASHUA A, 1995, IEEE T PATTERN ANAL, V17, P779, DOI 10.1109/34.400567; SHASHUA A, 1994, ECCV, V1, P479; SHASHUA A, 1996, ECCV, P196; Soatto S, 1997, INT J COMPUT VISION, V22, P235, DOI 10.1023/A:1007930700152; Soatto S., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P428, DOI 10.1109/CVPR.1993.341095; SPETSAKIS ME, 1992, IEEE T PATTERN ANAL, V14, P959, DOI 10.1109/34.161355; SRINIVASAN S, 1998, CARTR893 U MAR; Szeliski R, 1997, IEEE T PATTERN ANAL, V19, P506, DOI 10.1109/34.589211; Szeliski R., 1994, Journal of Visual Communication and Image Representation, V5, P10, DOI 10.1006/jvci.1994.1002; THOMAS JI, 1994, CVGIP-IMAG UNDERSTAN, V60, P359, DOI 10.1006/ciun.1994.1062; TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684; WENG JY, 1993, IEEE T PATTERN ANAL, V15, P864, DOI 10.1109/34.232074; YOUNG GSJ, 1992, IEEE T PATTERN ANAL, V14, P995, DOI 10.1109/34.159903; ZHANG Z, 1998, PAMI, V20, P717; ZHANG ZY, 1998, ICCV, P772	60	35	38	0	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	AUG	1999	34	2-3					163	192		10.1023/A:1008139920864	http://dx.doi.org/10.1023/A:1008139920864			30	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	265NF					2022-12-18	WOS:000084249700006
J	FERMULLER, C; ALOIMONOS, Y				FERMULLER, C; ALOIMONOS, Y			THE ROLE OF FIXATION IN VISUAL-MOTION ANALYSIS	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article							OPTICAL-FLOW; 3-DIMENSIONAL MOTION; ANIMATE VISION; OBJECTS	How does the ability of humans and primates to fixate at environmental points in the presence of relative motion help their visual systems in solving various tasks? To state the question in a more formal setting, we investigate in this article the following problem: Suppose that we have an active vision system, that is, a camera resting on a platform and being controlled through motors by a computer that has access to the images sensed by the camera in real time. The platform can move freely in the environment. If this machine can fixate on targets being in relative motion with it, can it solve visual tasks in an efficient and robust manner? By restricting our attention to a set of navigational tasks, we find that such an active observer can solve the problems of 3-D motion estimation, egomotion recovery, and estimation of time-to-contact in a very efficient manner, using as input the spatiotemporal derivatives of the image-intensity function (or normal flow). Fixation over time changes the input (motion field) in a controlled way and from this change additional information is derived making the previously mentioned tasks easier to solve.	UNIV MARYLAND,INST ADV COMP STUDIES,COLL PK,MD 20742; VIENNA TECH UNIV,INST AUTOMAT,DEPT PATTERN RECOGNIT & IMAGE PROC,A-1040 VIENNA,AUSTRIA	University System of Maryland; University of Maryland College Park; Technische Universitat Wien	FERMULLER, C (corresponding author), CTR AUTOMAT RES,DEPT COMP SCI,COMP VIS LAB,COLL PK,MD 20742, USA.		Aloimonos, Yiannis/AAI-2969-2020	Aloimonos, Yiannis/0000-0002-8152-4281				ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678; ALOIMONOS J, 1989, BIOL CYBERN, V60, P445, DOI 10.1007/BF00204700; ALOIMONOS J, 1988, INT J COMPUT VISION, V2, P333; ALOIMONOS Y, 1984, P WORKSHOP COMPUT VI, P72; Aloimonos Y., 1990, P DARPA IMAGE UNDERS, P816; Bajcsy R., 1985, P IEEE WORKSHOP COMP, P55; BALLARD DH, 1991, ARTIF INTELL, V48, P57, DOI 10.1016/0004-3702(91)90080-4; BALLARD DH, 1992, CVGIP-IMAG UNDERSTAN, V56, P3, DOI 10.1016/1049-9660(92)90081-D; BANDOPADHAY A, 1992, COMPUTATIONAL INTELL, V7, P39; CIPOLLA R, 1992, ACTIVE VISION, P39; Fermuller C., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P271, DOI 10.1109/CVPR.1992.223264; FERMULLER C, 1992, BIOL CYBERN, V67, P259, DOI 10.1007/BF00204399; FERMULLER C, 1993, P IMAGE UNDERSTANDIN; FERMULLER C, 1993, ACTIVE COMPUTER VISI, P51; FERMULLER C, 1991, CARTR564 U MAR CTR A; FERMULLER C, 1993, THESIS U MARYLAND TU; FLEET DJ, 1990, INT J COMPUT VISION, V5, P77, DOI 10.1007/BF00056772; Horn B. K. P., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P2; HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2; LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057; Marr D., 1982, VISION; NEGADHARIPOUR S, 1989, COMPUT VIS GRAPH IMA, P46; NEGADHARIPOUR S, 1986, THESIS MIT ARTIFICIA; NEGADHARIPOUR S, 1992, P IEEE C COMPUT VIS; PAHLAVAN K, 1992, CVGIP-IMAG UNDERSTAN, V56, P41, DOI 10.1016/1049-9660(92)90084-G; PAHLAVAN K, 1993, THESIS DEP NUMERICAL; SCHON FW, 1941, STEREOGRAPHIC PROJEC; SINGH A, 1990, THESIS COLUMBIA U; SPETSAKIS M, 1991, INT J COMPUT VISION, V6, P245, DOI 10.1007/BF00115698; SPETSAKIS ME, 1992, IEEE T PATTERN ANAL, V14, P959, DOI 10.1109/34.161355; SPETSAKIS ME, 1990, INT J COMPUT VISION, V4, P171, DOI 10.1007/BF00054994; SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487; SWAIN MJ, PROMISING DIRECTIONS, P91; TAALEBINEZHAAD MA, 1990, P IMAGE UNDERSTANDIN, P284; TISTARELLI M, 1992, CVGIP-IMAG UNDERSTAN, V56, P108, DOI 10.1016/1049-9660(92)90089-L; TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471; Ullman S., 1979, PROC R SOC SER B-BIO, DOI 10.7551/mitpress/3877.003.0009; VERRI A, 1989, IEEE T PATTERN ANAL, V11, P490, DOI 10.1109/34.24781; WAXMAN AM, 1987, INT J COMPUT VISION, V1, P239, DOI 10.1007/BF00127823	39	35	35	0	7	KLUWER ACADEMIC PUBL	DORDRECHT	SPUIBOULEVARD 50, PO BOX 17, 3300 AA DORDRECHT, NETHERLANDS	0920-5691			INT J COMPUT VISION	Int. J. Comput. Vis.	OCT	1993	11	2					165	186		10.1007/BF01469227	http://dx.doi.org/10.1007/BF01469227			22	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	MB329					2022-12-18	WOS:A1993MB32900005
J	Song, X; Zhao, X; Fang, LJ; Hu, HW; Yu, YH				Song, Xiao; Zhao, Xu; Fang, Liangji; Hu, Hanwen; Yu, Yizhou			EdgeStereo: An Effective Multi-task Learning Network for Stereo Matching and Edge Detection	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Stereo matching; Edge detection; Multi-task learning; Edge-aware smoothness loss; Residual pyramid	EFFICIENT; ACCURATE	Recently, leveraging on the development of end-to-end convolutional neural networks, deep stereo matching networks have achieved remarkable performance far exceeding traditional approaches. However, state-of-the-art stereo frameworks still have difficulties at finding correct correspondences in texture-less regions, detailed structures, small objects and near boundaries, which could be alleviated by geometric clues such as edge contours and corresponding constraints. To improve the quality of disparity estimates in these challenging areas, we propose an effective multi-task learning network, EdgeStereo, composed of a disparity estimation branch and an edge detection branch, which enables end-to-end predictions of both disparity map and edge map. To effectively incorporate edge cues, we propose the edge-aware smoothness loss and edge feature embedding for inter-task interactions. It is demonstrated that based on our unified model, edge detection task and stereo matching task can promote each other. In addition, we design a compact module called residual pyramid to replace the commonly-used multi-stage cascaded structures or 3-D convolution based regularization modules in current stereo matching networks. By the time of the paper submission, EdgeStereo achieves state-of-art performance on the FlyingThings3D dataset, KITTI 2012 and KITTI 2015 stereo benchmarks, outperforming other published stereo matching methods by a noteworthy margin. EdgeStereo also achieves comparable generalization performance for disparity estimation because of the incorporation of edge cues.	[Song, Xiao; Zhao, Xu; Fang, Liangji; Hu, Hanwen] Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200240, Peoples R China; [Zhao, Xu] Shanghai Jiao Tong Univ, Inst Med Robot, Shanghai 200240, Peoples R China; [Yu, Yizhou] Deepwise AI Lab, Beijing, Peoples R China	Shanghai Jiao Tong University; Shanghai Jiao Tong University	Zhao, X (corresponding author), Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200240, Peoples R China.; Zhao, X (corresponding author), Shanghai Jiao Tong Univ, Inst Med Robot, Shanghai 200240, Peoples R China.	zhaoxu@sjtu.edu.cn			Institute ofMedical Robotics, Shanghai Jiao Tong University [61673269, U1764264, 61273285]	Institute ofMedical Robotics, Shanghai Jiao Tong University	This research has been supported in part by the funding fromNSFCprograms (61673269, U1764264, 61273285) and in part by the project funding from Institute ofMedical Robotics, Shanghai Jiao Tong University	Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161; Barron J.T, 2017, ARXIV170103077; Barron JT, 2015, PROC CVPR IEEE, P4466, DOI 10.1109/CVPR.2015.7299076; CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851; Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567; Chen ZY, 2015, IEEE I CONF COMP VIS, P972, DOI 10.1109/ICCV.2015.117; Cheng JC, 2017, IEEE I CONF COMP VIS, P686, DOI 10.1109/ICCV.2017.81; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dollar P., 2006, P IEEE COMP SOC C CO, V2, P1964, DOI DOI 10.1109/CVPR.2006.298; Dollar P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715; Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316; Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45; Geiger A., 2012, P IEEE COMP SOC C CO; Geiger A, 2011, LECT NOTES COMPUT SC, V6492, P25, DOI 10.1007/978-3-642-19315-6_3; Gidaris Spyros, 2017, P IEEE C COMP VIS PA, P2; Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699; Guney F, 2015, PROC CVPR IEEE, P4165, DOI 10.1109/CVPR.2015.7299044; He K, 2016, P 2016 IEEE C COMPUT, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]; Heise P, 2015, IEEE INT CONF ROBOT, P105, DOI 10.1109/ICRA.2015.7138987; Hirschmuller H, 2005, PROC CVPR IEEE, P807, DOI 10.1109/cvpr.2005.56; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Jie ZQ, 2018, PROC CVPR IEEE, P3838, DOI 10.1109/CVPR.2018.00404; Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781; Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17; Klaus A, 2006, INT C PATT RECOG, P15; Knobelreiter P., 2017, P IEEE C COMP VIS PA, P2339; Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668; Kuznietsov Y, 2017, PROC CVPR IEEE, P2215, DOI 10.1109/CVPR.2017.238; Liang ZF, 2018, PROC CVPR IEEE, P2811, DOI 10.1109/CVPR.2018.00297; Liu Y, 2016, PROC CVPR IEEE, P231, DOI 10.1109/CVPR.2016.32; Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Lu CH, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111844; LUO WJ, 2016, PROC CVPR IEEE, P5695, DOI DOI 10.1109/CVPR.2016.614; Mao JY, 2017, PROC CVPR IEEE, P6034, DOI 10.1109/CVPR.2017.639; Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438; Mei X, 2011, PROC CVPR IEEE, P1257; Mely DA, 2016, VISION RES, V120, P93, DOI 10.1016/j.visres.2015.11.007; Menze Moritz, 2015, CVPR; Nam KW, 2012, HEALTHC INFORM RES, V18, P158, DOI 10.4258/hir.2012.18.3.158; Pang J., 2017, ICCV WORKSH, V3, P1057; Ramirez P.Z., 2018, ASIAN C COMPUT VIS, P298; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977; Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3; Schmid K, 2013, IEEE INT C INT ROBOT, P3955, DOI 10.1109/IROS.2013.6696922; Seki A, 2017, PROC CVPR IEEE, P6640, DOI 10.1109/CVPR.2017.703; Shaked A, 2017, PROC CVPR IEEE, P6901, DOI 10.1109/CVPR.2017.730; Shean DE, 2016, ISPRS J PHOTOGRAMM, V116, P101, DOI 10.1016/j.isprsjprs.2016.03.012; Song X, 2019, LECT NOTES COMPUT SC, V11365, P20, DOI 10.1007/978-3-030-20873-8_2; Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931; Tao Y, 2017, CHIN CONTR CONF, P4288, DOI 10.23919/ChiCC.2017.8028032; Tonioni A, 2019, PROC CVPR IEEE, P195, DOI 10.1109/CVPR.2019.00028; Tonioni A, 2017, IEEE I CONF COMP VIS, P1614, DOI 10.1109/ICCV.2017.178; Tulyakov S., 2018, NIPS; Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164; Yang G., 2018, ACCV; Yang GR, 2018, LECT NOTES COMPUT SC, V11211, P660, DOI 10.1007/978-3-030-01234-2_39; Yu L., 2018, AAAI; ZAGORUYKO S, 2015, 2015 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2015.7299064; Zbontar J, 2016, J MACH LEARN RES, V17; Zbontar J, 2015, PROC CVPR IEEE, P1592, DOI 10.1109/CVPR.2015.7298767; Zhang L, 2007, IEEE T PATTERN ANAL, V29, P331, DOI 10.1109/TPAMI.2007.36; Zhong Y., 2017, CVPR; Zhou C., 2017, ICCV, V2	67	34	37	9	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	2020	128	4			SI		910	930		10.1007/s11263-019-01287-w	http://dx.doi.org/10.1007/s11263-019-01287-w		JAN 2020	21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	LC5TN		Green Submitted			2022-12-18	WOS:000515719200001
J	Dapogny, A; Bailly, K; Dubuisson, S				Dapogny, Arnaud; Bailly, Kevin; Dubuisson, Severine			Confidence-Weighted Local Expression Predictions for Occlusion Handling in Expression Recognition and Action Unit Detection	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Facial expressions; Action unit; Random forest; Occlusions; Autoencoder; Real-time	FACE; ALIGNMENT	Fully-automatic facial expression recognition (FER) is a key component of human behavior analysis. Performing FER from still images is a challenging task as it involves handling large interpersonal morphological differences, and as partial occlusions can occasionally happen. Furthermore, labelling expressions is a time-consuming process that is prone to subjectivity, thus the variability may not be fully covered by the training data. In this work, we propose to train random forests upon spatially-constrained random local subspaces of the face. The output local predictions form a categorical expression-driven high-level representation that we call local expression predictions (LEPs). LEPs can be combined to describe categorical facial expressions as well as action units (AUs). Furthermore, LEPs can be weighted by confidence scores provided by an autoencoder network. Such network is trained to locally capture the manifold of the non-occluded training data in a hierarchical way. Extensive experiments show that the proposed LEP representation yields high descriptive power for categorical expressions and AU occurrence prediction, and leads to interesting perspectives towards the design of occlusion-robust and confidence-aware FER systems.	[Dapogny, Arnaud; Bailly, Kevin; Dubuisson, Severine] Sorbonne Univ, UPMC Univ Paris 06, CNRS, UMR 7222, F-75005 Paris, France	Centre National de la Recherche Scientifique (CNRS); UDICE-French Research Universities; Sorbonne Universite; Universite Paris Cite	Dapogny, A (corresponding author), Sorbonne Univ, UPMC Univ Paris 06, CNRS, UMR 7222, F-75005 Paris, France.	arnaud.dapogny@isir.upmc.fr; kevin.bailly@isir.upmc.fr; severine.dubuisson@isir.upmc.fr		Bailly, Kevin/0000-0001-7802-3673	French National Agency (ANR) [ANR-13-CORD-0004]	French National Agency (ANR)(French National Research Agency (ANR))	This work has been supported by the French National Agency (ANR) in the frame of its Technological Research CONTINT program (JEMImE, project number ANR-13-CORD-0004).	Bihan Jiang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P314, DOI 10.1109/FG.2011.5771416; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Bylander T, 2002, MACH LEARN, V48, P287, DOI 10.1023/A:1013964023376; Chen C., 2004, TECHNICAL REPORT, V110; Chu Wen-Sheng, 2013, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, V2013, P3515; Cotter SF, 2010, INT CONF ACOUST SPEE, P838, DOI 10.1109/ICASSP.2010.5494903; Dapogny A., 2015, ICCV; Dhall A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS); Dollar P, 2009, BRIT MACHINE VISION, DOI [10.5244/C.23.91, DOI 10.5244/C.23.91]; Du S., 2014, P NATL ACAD SCI USA, P111; EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377; Ekman P., 1978, FACIAL ACTION CODING, DOI [10.1037/t27734-000, DOI 10.1037/T27734-000]; Eleftheriadis S., 2015, ICCV; Eleftheriadis S, 2015, IEEE T IMAGE PROCESS, V24, P189, DOI 10.1109/TIP.2014.2375634; Ghiasi G, 2014, PROC CVPR IEEE, P1899, DOI 10.1109/CVPR.2014.306; Ghosh Sayan, 2015, ACII; Greenwald M. K., 1989, J PSYCHOPHYSIOL, V3, P51; Hayat M, 2012, C HUM SYST INTERACT, P43, DOI 10.1109/HSI.2012.16; Huang XH, 2012, PATTERN RECOGN LETT, V33, P2181, DOI 10.1016/j.patrec.2012.07.015; Jeni L., 2015, FG; Jolliffe I.T., 1986, PRINCIPAL COMPONENT; Kotsia I, 2008, IMAGE VISION COMPUT, V26, P1052, DOI 10.1016/j.imavis.2007.11.004; Linusson H, 2013, MULTIOUTPUT RANDOM F; Liu MY, 2015, NEUROCOMPUTING, V159, P126, DOI 10.1016/j.neucom.2015.02.011; Lucey P., 2010, P IEEE COMP SOC C CO, P94, DOI [10.1109/CVPRW.2010.5543262, DOI 10.1109/CVPRW.2010.5543262]; Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4; Mengyi Liu, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P577, DOI 10.1007/978-3-642-37444-9_45; Nicolle J., 2015, FG; Pei YR, 2013, IEEE I CONF COMP VIS, P129, DOI 10.1109/ICCV.2013.23; Ranzato M., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2857, DOI 10.1109/CVPR.2011.5995710; Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218; Rifai S., 2011, PROC INT C MACH LEAR; Rifai S, 2012, LECT NOTES COMPUT SC, V7577, P808, DOI 10.1007/978-3-642-33783-3_58; Sandbach G., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P406, DOI 10.1109/FG.2011.5771434; Savran A., 2008, BIOID, P47, DOI [DOI 10.1007/978-3-540-89991-4_6, DOI 10.1007/978-3-540-89991-4_]; Senechal T., 2012, TSMC B, P42; Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005; Sun Y, 2008, LECT NOTES COMPUT SC, V5303, P58, DOI 10.1007/978-3-540-88688-4_5; Van de Weijer J., 2015, ICCV; Vincent P, 2010, J MACH LEARN RES, V11, P3371; Wallhoff F., 2006, DATABASEWITH FACIAL; Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75; Xu L., 2010, P BRIT MACH VIS C, p13.1; Yin L., 2008, FG, P1; Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52; Zhang LG, 2014, NEUROCOMPUTING, V145, P451, DOI 10.1016/j.neucom.2014.05.008; Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002; Zhao KL, 2016, PROC CVPR IEEE, P3391, DOI 10.1109/CVPR.2016.369; Zhao KL, 2015, PROC CVPR IEEE, P2207, DOI 10.1109/CVPR.2015.7298833; Zhao XW, 2014, PROC CVPR IEEE, P1765, DOI 10.1109/CVPR.2014.228; Zhong L, 2012, PROC CVPR IEEE, P2562, DOI 10.1109/CVPR.2012.6247974	51	34	36	2	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	APR	2018	126	2-4			SI		255	271		10.1007/s11263-017-1010-1	http://dx.doi.org/10.1007/s11263-017-1010-1			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	FW8XA		Green Submitted			2022-12-18	WOS:000425619100007
J	Korman, S; Reichman, D; Tsur, G; Avidan, S				Korman, Simon; Reichman, Daniel; Tsur, Gilad; Avidan, Shai			Fast-Match: Fast Affine Template Matching	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Pattern matching; Template matching; Image matching; Sublinear algorithms	PERFORMANCE EVALUATION; IMAGE; SEARCH; MODEL	Fast-Match is a fast algorithm for approximate template matching under 2D affine transformations that minimizes the Sum-of-Absolute-Differences (SAD) error measure. There is a huge number of transformations to consider but we prove that they can be sampled using a density that depends on the smoothness of the image. For each potential transformation, we approximate the SAD error using a sublinear algorithm that randomly examines only a small number of pixels. We further accelerate the algorithm using a branch-and-bound-like scheme. As images are known to be piecewise smooth, the result is a practical affine template matching algorithm with approximation guarantees, that takes a few seconds to run on a standard machine. We perform several experiments on three different datasets, and report very good results.	[Korman, Simon] Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90024 USA; [Korman, Simon] Tel Aviv Univ, Tel Aviv, Israel; [Reichman, Daniel] Univ Calif Berkeley, Inst Cognit & Brain Sci, Berkeley, CA 94720 USA; [Reichman, Daniel; Tsur, Gilad] Weizmann Inst Sci, Rehovot, Israel; [Tsur, Gilad] Yahoo Res Labs, IL-31905 Haifa, Israel; [Avidan, Shai] Tel Aviv Univ, Sch Elect Engn, Tel Aviv, Israel	University of California System; University of California Los Angeles; Tel Aviv University; University of California System; University of California Berkeley; Weizmann Institute of Science; Tel Aviv University	Korman, S (corresponding author), Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90024 USA.; Korman, S (corresponding author), Tel Aviv Univ, Tel Aviv, Israel.	simon.korman@gmail.com; daniel.reichman@gmail.com; gilad.tsur@gmail.com; avidan@eng.tau.ac.il			Israel Science Foundation [873/08]; Ministry of Science and Technology	Israel Science Foundation(Israel Science Foundation); Ministry of Science and Technology(Ministry of Science, ICT & Future Planning, Republic of Korea)	This work was supported by the Israel Science Foundation (Grant No. 873/08, in part) and the Ministry of Science and Technology.	Alexe B., 2011, P ADV NEUR INF PROC, P2735; Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348; Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692; Fredriksson K., 2001, THESIS; FUH CS, 1991, OPT ENG, V30, P881, DOI 10.1117/12.55885; Hartley R., 2003, MULTIPLE VIEW GEOMET; Kim HY, 2007, LECT NOTES COMPUT SC, V4872, P100; Kleiner I, 2011, IEEE T PATTERN ANAL, V33, P256, DOI 10.1109/TPAMI.2010.165; Korman S., FAST MATCH WEBPAGE; Korman S., 2011, ARXIV11111713; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Lucas B. D., 1981, INT JOINT C ART INT, P674, DOI DOI 10.5555/1623264.1623280; Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x; Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188; Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730; Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376; Ouyang WL, 2012, IEEE T PATTERN ANAL, V34, P127, DOI 10.1109/TPAMI.2011.106; Pele O, 2007, LECT NOTES COMPUT SC, V4844, P435; Raskhodnikova S, 2003, LECT NOTES COMPUT SC, V2764, P370; Rucklidge W, 1997, PROC CVPR IEEE, P717, DOI 10.1109/CVPR.1997.609405; Seitz SM, 2009, IEEE I CONF COMP VIS, P143, DOI 10.1109/ICCV.2009.5459155; Shao H., 2003, TECHNICAL REPORT, V260; Tian YD, 2012, INT J COMPUT VISION, V98, P279, DOI 10.1007/s11263-011-0509-0; Tsai DM, 2002, PATTERN RECOGN LETT, V23, P191, DOI 10.1016/S0167-8655(01)00099-X; Tsur G, 2010, ANN IEEE SYMP FOUND, P468, DOI 10.1109/FOCS.2010.52; Wang QF, 2007, IEEE DECIS CONTR P, P1; Yao CH, 2003, PATTERN RECOGN, V36, P913, DOI 10.1016/S0031-3203(02)00124-3	30	34	40	3	13	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	JAN	2017	121	1					111	125		10.1007/s11263-016-0926-1	http://dx.doi.org/10.1007/s11263-016-0926-1			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	EI3HN		Green Submitted			2022-12-18	WOS:000392380900005
J	Ouyang, WL; Zeng, XY; Wang, XG				Ouyang, Wanli; Zeng, Xingyu; Wang, Xiaogang			Learning Mutual Visibility Relationship for Pedestrian Detection with a Deep Model	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Deep model; Deep learning; Pedestrian detection; Object detection		Detecting pedestrians in cluttered scenes is a challenging problem in computer vision. The difficulty is added when several pedestrians overlap in images and occlude each other. We observe, however, that the occlusion/visibility statuses of overlapping pedestrians provide useful mutual relationship for visibility estimation-the visibility estimation of one pedestrian facilitates the visibility estimation of another. In this paper, we propose a mutual visibility deep model that jointly estimates the visibility statuses of overlapping pedestrians. The visibility relationship among pedestrians is learned from the deep model for recognizing co-existing pedestrians. Then the evidence of co-existing pedestrians is used for improving the single pedestrian detection results. Compared with existing image-based pedestrian detection approaches, our approach has the lowest average miss rate on the Caltech-Train dataset and the ETH dataset. Experimental results show that the mutual visibility deep model effectively improves the pedestrian detection results. The mutual visibility deep model leads to 6-15 % improvements on multiple benchmark datasets.	[Ouyang, Wanli; Zeng, Xingyu; Wang, Xiaogang] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China	Chinese University of Hong Kong	Ouyang, WL (corresponding author), Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.	wlouyang@ee.cuhk.edu.hk; xyzeng@ee.cuhk.edu.hk; xgwang@ee.cuhk.edu.hk	Ouyang, Wanli/I-7135-2018	Ouyang, Wanli/0000-0002-9163-2761	General Research Fund - Research Grants Council of Hong Kong [CUHK 417110, CUHK 417011]; National Natural Science Foundation of China [61005057]; Guangdong Innovative Research Team Program [201001D0104648280]	General Research Fund - Research Grants Council of Hong Kong(Hong Kong Research Grants Council); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Guangdong Innovative Research Team Program	This work is supported by the General Research Fund sponsored by the Research Grants Council of Hong Kong (Project No. CUHK 417110 and CUHK 417011), National Natural Science Foundation of China (Project No. 61005057), and Guangdong Innovative Research Team Program (No. 201001D0104648280).	[Anonymous], 2012, ICML; [Anonymous], 2011, CVPR; Bar-Hillel A., 2010, P ECCV; Belongie P. Dollar, 2010, BMVC; Benenson R., 2012, CVPR; Benenson R., 2013, P CVPR; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Chen G., 2013, P CVPR; Dai S., 2007, IEEE C CVPR; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Dalal N., 2005, IEEE C CVPR; Dean T., 2013, P IEEE C CVPR NEW YO; Deng J., 2009, IEEE C CVPR; Desai C., 2009, ICCV; Desai C., 2012, IEEE INT C ECCV; Ding Y., 2012, CVPR; Dollar P., 2009, BMVC; Dollar P., 2014, CALTECH PEDESTRIAN D; Dollar P., 2012, ECCV; Dollar P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479; Dollar P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155; Duan G., 2010, ECCV; Enzweiler M., 2010, CVPR; Erhan D, 2010, J MACH LEARN RES, V11, P625; Ess A., 2007, ICCV; Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Hu J, 2014, CVPR; Jarrett K., 2009, CVPR; Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59; Krizhevsky A., 2012, ADV NEURAL INF PROCE; Lee H., 2009, ICML; Leibe B., 2005, CVPR; Li C., 2011, ICCV; Lin Z., 2007, ICCV; Liu P., 2014, CVPR; Luo Ping, 2012, CVPR; Mann J., 2013, CVPR; Mathias M., 2013, CVPR; NOROUZI M, 2009, CVPR; Ouyang W., 2013, CVPR; Ouyang W., 2013, ICCV; Ouyang W., 2012, CVPR; Ouyang WL, 2016, IEEE T CIRC SYST VID, V26, P2123, DOI 10.1109/TCSVT.2015.2501940; Ouyang WL, 2015, IEEE T PATTERN ANAL, V37, P1875, DOI 10.1109/TPAMI.2014.2377734; Paisitkriangkrai S., 2013, ICCV; Park D., 2013, CVPR; Park D., 2010, ECCV; Pepik B, 2013, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2013.422; Ranzato Marc'Aurelio, 2011, CVPR; Sadeghi MA, 2011, PROC CVPR IEEE, P1745, DOI 10.1109/CVPR.2011.5995711; SCHWARTZ WR, 2009, ICCV; Sermanet P., 2013, CVPR; Sermanet P., 2013, COMPUT VIS PATTERN R; Shen CH, 2013, INT J COMPUT VISION, V103, P326, DOI 10.1007/s11263-013-0608-1; Shet V.D., 2007, CVPR; Sun L., 2014, CVPR; Sun Y., 2014, CVPR; Tang S., 2013, P ICCV; Tang S., 2012, BMVC; Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8; Walk S., 2010, CVPR; Wang X., 2009, CVPR; Wojek C., 2008, DAGM; Woonhyun Nam, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1801, DOI 10.1109/ICCVW.2011.6130467; Wu B., 2005, ICCV; Wu B, 2009, INT J COMPUT VISION, V82, P185, DOI 10.1007/s11263-008-0194-9; Wu TF, 2011, INT J COMPUT VISION, V93, P226, DOI 10.1007/s11263-010-0346-6; Yan J., 2012, CVPR; Yan J., 2013, CVPR; Yang Y., 2012, CVPR; Yao B., 2010, CVPR; Zeng X., 2013, ICCV; Zhu L., 2010, CVPR	77	34	35	1	40	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	OCT	2016	120	1					14	27		10.1007/s11263-016-0890-9	http://dx.doi.org/10.1007/s11263-016-0890-9			14	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	DU3DX					2022-12-18	WOS:000382092100002
J	Saurer, O; Baatz, G; Koser, K; Ladicky, L; Pollefeys, M				Saurer, Olivier; Baatz, Georges; Koeser, Kevin; Ladicky, L'ubor; Pollefeys, Marc			Image Based Geo-localization in the Alps	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Geo-localization; Localization; Camera calibration; Computer vision		Given a picture taken somewhere in the world, automatic geo-localization of such an image is an extremely useful task especially for historical and forensic sciences, documentation purposes, organization of the world's photographs and intelligence applications. While tremendous progress has been made over the last years in visual location recognition within a single city, localization in natural environments is much more difficult, since vegetation, illumination, seasonal changes make appearance-only approaches impractical. In this work, we target mountainous terrain and use digital elevation models to extract representations for fast visual database lookup. We propose an automated approach for very large scale visual localization that can efficiently exploit visual information (contours) and geometric constraints (consistent orientation) at the same time. We validate the system at the scale of Switzerland (40,000 ) using over 1000 landscape query images with ground truth GPS position.	[Saurer, Olivier; Ladicky, L'ubor; Pollefeys, Marc] ETH, Comp Vis & Geometry Grp, Zurich, Switzerland; [Baatz, Georges] Google Inc, Zurich, Switzerland; [Koeser, Kevin] GEOMAR Helmholtz Ctr Ocean Res Kiel, Kiel, Germany	Swiss Federal Institutes of Technology Domain; ETH Zurich; Google Incorporated; Helmholtz Association; GEOMAR Helmholtz Center for Ocean Research Kiel	Saurer, O (corresponding author), ETH, Comp Vis & Geometry Grp, Zurich, Switzerland.	saurero@inf.ethz.ch; gbaatz@google.com; kkoeser@geomar.de; lubor.ladicky@inf.ethz.ch; marc.pollefeys@inf.ethz.ch	Pollefeys, Marc/I-7607-2013		SNF by the Swiss National Science Foundation [127224]	SNF by the Swiss National Science Foundation(Swiss National Science Foundation (SNSF))	This work has been supported through SNF Grant 127224 by the Swiss National Science Foundation. We also thank Simon Wenner for his help to render the DEMs and Hiroto Nagayoshi for providing the CH2 dataset. We also thank the anonymous reviewers for useful discussions and constructive feedback.	Baatz G, 2012, LECT NOTES COMPUT SC, V7573, P517, DOI 10.1007/978-3-642-33709-3_37; Baatz G, 2012, INT J COMPUT VISION, V96, P315, DOI 10.1007/s11263-011-0458-7; Baboud L, 2011, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2011.5995727; Bansal M, 2014, PROC CVPR IEEE, P3978, DOI 10.1109/CVPR.2014.508; Bazin JC, 2009, IEEE INT CONF ROBOT, P532; Blake A, 2004, LECT NOTES COMPUT SC, V3021, P428; Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3; Chen D., 2011, P COMP VIS PATT REC; Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236; Cozman F, 1996, THIRD IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV '96, PROCEEDINGS, P156, DOI 10.1109/ACV.1996.572046; Cozman F., 1997, THESIS C MELLON U PI; Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223; Hays J., 2008, P COMP VIS PATT REC; Hussain S. ul., 2012, P EUR C COMP VIS ECC; Kolmogorov V, 2005, IEEE I CONF COMP VIS, P564; Ladicky L, 2014, IEEE T PATTERN ANAL, V36, P1056, DOI 10.1109/TPAMI.2013.165; Ladicky Lubor, 2014, P EUR C COMP VIS ECC; Lalonde JF, 2010, INT J COMPUT VISION, V88, P24, DOI 10.1007/s11263-009-0291-4; Li YP, 2010, LECT NOTES COMPUT SC, V6312, P791; Lie WN, 2005, PATTERN RECOGN LETT, V26, P221, DOI 10.1016/j.patrec.2004.08.021; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800; Manay S, 2006, IEEE T PATTERN ANAL, V28, P1602, DOI 10.1109/TPAMI.2006.208; NAVAL PC, 1997, 38 RES M PATT SENS G, P9; Nister D, 2006, IEEE COMP SOC C COMP, V2, P2161, DOI DOI 10.1109/CVPR.2006.264; Ramalingam Srikumar, 2011, 2011 IEEE International Conference on Robotics and Automation, P4716; Ramalingam S, 2010, IEEE INT C INT ROBOT, P3816, DOI 10.1109/IROS.2010.5649105; Schindler Grant, 2007, IEEE C COMP VIS PATT, DOI DOI 10.1109/CVPR.2007.383150; Shechtman E., 2007, P C COMP VIS PATT RE; Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1; Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663; STEIN F, 1995, IEEE T ROBOTIC AUTOM, V11, P892, DOI 10.1109/70.478436; TALLURI R, 1992, IEEE T ROBOTIC AUTOM, V8, P573, DOI 10.1109/70.163782; Taneja A, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P479, DOI 10.1109/3DIMPVT.2012.45; Thompson W. B., 1993, IM UND WORKSH, P491; Vasilevskiy A, 2002, IEEE T PATTERN ANAL, V24, P1565, DOI 10.1109/TPAMI.2002.1114849; Woo J., 2007, P IAPR C MACH VIS AP, P236; Yang M., 2008, PATTERN RECOGNIT, V15, P43, DOI DOI 10.5772/6237	38	34	37	2	25	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	FEB	2016	116	3			SI		213	225		10.1007/s11263-015-0830-0	http://dx.doi.org/10.1007/s11263-015-0830-0			13	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	DC7SY					2022-12-18	WOS:000369421900002
J	Wu, Y; Ji, Q				Wu, Yue; Ji, Qiang			Discriminative Deep Face Shape Model for Facial Point Detection	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Facial point detection; Restricted Boltzmann Machine; Deep learning		Facial point detection is an active area in computer vision due to its relevance to many applications. It is a nontrivial task, since facial shapes vary significantly with facial expressions, poses or occlusion. In this paper, we address this problem by proposing a discriminative deep face shape model that is constructed based on an augmented factorized three-way Restricted Boltzmann Machines model. Specifically, the discriminative deep model combines the top-down information from the embedded face shape patterns and the bottom up measurements from local point detectors in a unified framework. In addition, along with the model, effective algorithms are proposed to perform model learning and to infer the true facial point locations from their measurements. Based on the discriminative deep face shape model, 68 facial points are detected on facial images in both controlled and "in-the-wild" conditions. Experiments on benchmark data sets show the effectiveness of the proposed facial point detection algorithm against state-of-the-art methods.	[Wu, Yue; Ji, Qiang] Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA	Rensselaer Polytechnic Institute	Ji, Q (corresponding author), Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, 110 8th St, Troy, NY 12180 USA.	wuy9@rpi.edu; jiq@rpi.edu			US Army Research office [W911NF-12-C-0017]	US Army Research office	This work is supported in part by a Grant from US Army Research office (W911NF-12-C-0017).	Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd; Belhumeur P. N., 2011, IEEE INT C COMP VIS; Belhumeur PN, 2013, IEEE T PATTERN ANAL, V35, P2930, DOI 10.1109/TPAMI.2013.23; Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467; Cristinacce D, 2008, PATTERN RECOGN, V41, P3054, DOI 10.1016/j.patcog.2008.01.024; Dalal N., 2005, INT J INFORM SYSTEM, P886, DOI [10.1109/icnc.2013.6818189, DOI 10.1109/ICNC.2013.6818189]; Eslami SMA, 2012, PROC CVPR IEEE, P406, DOI 10.1109/CVPR.2012.6247702; Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Kae A, 2013, PROC CVPR IEEE, P2019, DOI 10.1109/CVPR.2013.263; Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49; Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94; Martinez B, 2013, IEEE T PATTERN ANAL, V35, P1149, DOI 10.1109/TPAMI.2012.205; Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3; Memisevic R, 2010, NEURAL COMPUT, V22, P1473, DOI 10.1162/neco.2010.01-09-953; Mohamed AD, 2012, INT J NEUROPSYCHOPH, V15, P559, DOI 10.1017/S146114571100037X; Ranzato M., 2010, P 13 INT C ART INT S, P621; Sagonas C., 2013, P IEEE INT C COMP VI; Sagonas C, 2013, IEEE COMPUT SOC CONF, P896, DOI 10.1109/CVPRW.2013.132; Salakhutdinov R., 2009, P 12 INT C ART INT S, P448; Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4; Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88; Sun Y, 2013, IEEE I CONF COMP VIS, P1489, DOI 10.1109/ICCV.2013.188; Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446; Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220; Taylor GW, 2010, PROC CVPR IEEE, P631, DOI 10.1109/CVPR.2010.5540157; Tieleman T., 2008, P 25 INT C MACHINE L, P1064, DOI DOI 10.1145/1390156.1390290; Tzimiropoulos G, 2013, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2013.79; Valstar M., 2010, IEEE INT C COMP VIS, P13; Welling M, 2002, LECT NOTES COMPUT SC, V2415, P351; Wu Y, 2013, PROC CVPR IEEE, P3452, DOI 10.1109/CVPR.2013.443; Xiong XD, 2013, IEEE C ELEC DEVICES; Zhou EJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P386, DOI 10.1109/ICCVW.2013.58; Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014	37	34	36	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2015	113	1			SI		37	53		10.1007/s11263-014-0775-8	http://dx.doi.org/10.1007/s11263-014-0775-8			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	CH6GX					2022-12-18	WOS:000354135700004
J	Delaunoy, A; Prados, E				Delaunoy, Amael; Prados, Emmanuel			Gradient Flows for Optimizing Triangular Mesh-based Surfaces: Applications to 3D Reconstruction Problems Dealing with Visibility	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Triangle mesh-based surface; Gradient descent flow; Surface evolution; Variational methods; Shape gradient; Visibility; 3D reconstruction; Multi-view stereovision	MULTIVIEW STEREO RECONSTRUCTION; SHAPE	This article tackles the problem of using variational methods for evolving 3D deformable surfaces. We give an overview of gradient descent flows when the shape is represented by a triangular mesh-based surface, and we detail the gradients of two generic energy functionals which embody a number of energies used in mesh processing and computer vision. In particular, we show how to rigorously account for visibility in the surface optimization process. We present different applications including 3D reconstruction from multiple views for which the visibility is fundamental. The gradient correctly takes into account the visibility changes that occur when a surface moves; this forces the contours generated by the reconstructed surface to match with the apparent contours in the input images.	[Delaunoy, Amael; Prados, Emmanuel] INRIA Rhone Alpes, Perception Team, LJK, Grenoble, France		Delaunoy, A (corresponding author), INRIA Rhone Alpes, Perception Team, LJK, Grenoble, France.	Amael.Delaunoy@inrialpes.fr; Emmanuel.Prados@inrialpes.fr			Agence Nationale pour la Recherche [ANR-06-MDCA-007]	Agence Nationale pour la Recherche(French National Research Agency (ANR))	Research was supported by the Agence Nationale pour la Recherche within the Flamenco project (Grant ANR-06-MDCA-007).	Bertalmio M., 2001, VARIATIONAL LEVEL SE; BIRKBECK N, 2006, P 9 EUR C COMP VIS M, V1, P536; CHANG JY, 2007, IEEE C COMP VIS PATT; Charpiat G, 2007, INT J COMPUT VISION, V73, P325, DOI 10.1007/s11263-006-9966-2; Debreuve E., 2007, J MATH IMAGING VISIO; Delaunoy A., 2008, BRIT MACH VIS C LEED; Desbrun M, 1999, COMP GRAPH, P317, DOI 10.1145/311535.311576; DUAN Y, 2004, EUR C COMP VIS, V3, P238; Dziuk G, 2007, IMA J NUMER ANAL, V27, P262, DOI [10.1093/imanum/dr1023, 10.1093/imanum/drl023]; ECKSTEIN I, 2007, EUR S GEOM PROC; Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016; Faugeras O, 1998, IEEE T IMAGE PROCESS, V7, P336, DOI 10.1109/83.661183; GARGALLO P, 2008, THESIS I NATL POLYTE; Gargallo P., 2007, P INT C COMP VIS RIO; Goldlucke B, 2004, LECT NOTES COMPUT SC, V3022, P366; Goldlucke B, 2007, IEEE T PATTERN ANAL, V29, P1194, DOI 10.1109/TPAMI.2007.1146.; Gupta R, 1997, IEEE T PATTERN ANAL, V19, P963, DOI 10.1109/34.615446; Hernandez C, 2008, IEEE T PATTERN ANAL, V30, P548, DOI 10.1109/TPAMI.2007.70820; JIN H, 2008, INT J COMPUTER VISIO, V76; Jin HL, 2005, INT J COMPUT VISION, V63, P175, DOI 10.1007/s11263-005-6876-7; Jin HL, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P626, DOI 10.1109/TDPVT.2002.1024128; KOLEV K, 2008, EUR C COMP VIS OCT 2; KOLEV K, 2010, EUR C COMP VIS 2010; Kolev K., 2009, INT J COMPUTER VISIO; Kolev K., 2009, IEEE C COMP VIS PATT; Kolmogorov, 2004, IEEETPAMI IEEE T PAT, V26; Labatut P, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P774; Meyer Mark, 2002, DISCRETE DIFFERENTIA; NEHAB D, 2005, SIGGRAPH 05, P536; OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2; Pons JP, 2007, COMPUT GRAPH FORUM, V26, P227, DOI 10.1111/j.1467-8659.2007.01029.x; Pons JP, 2007, INT J COMPUT VISION, V72, P179, DOI 10.1007/s11263-006-8671-5; Pons JP, 2005, PROC CVPR IEEE, P822; SEITZ SM, 2006, IEEE C COMP VIS PATT, P519; Sinha SN, 2005, IEEE I CONF COMP VIS, P349; Slabaugh G, 2005, PROC CVPR IEEE, P84; Soatto S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P974; Solem JE, 2006, INT J COMPUT VISION, V69, P267, DOI 10.1007/s11263-006-7068-9; Solem JE, 2005, LECT NOTES COMPUT SC, V3459, P419; SOLEM JE, 2004, 3DPVT, P26; Vlasic D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618520; Vogiatzis G, 2007, IEEE T PATTERN ANAL, V29, P2241, DOI 10.1109/TPAMI.2007.70712; Vu H., 2009, IEEE C COMP VIS PATT; Whitaker RT, 1998, INT J COMPUT VISION, V29, P203, DOI 10.1023/A:1008036829907; Yezzi A, 2003, INT J COMPUT VISION, V53, P31, DOI 10.1023/A:1023079624234; Yezzi A., 2001, IEEE INT C COMP VIS; YOON KJ, 2009, INT J COMPUTER VISIO; Yu TL, 2007, INT J COMPUT VISION, V73, P123, DOI 10.1007/s11263-006-9373-8; Zaharescu A., 2007, P AS C COMP VIS TOK	49	34	38	1	13	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	NOV	2011	95	2					100	123		10.1007/s11263-010-0408-9	http://dx.doi.org/10.1007/s11263-010-0408-9			24	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	815YN		Green Submitted			2022-12-18	WOS:000294566000001
J	Sinha, SN; Pollefeys, M				Sinha, Sudipta N.; Pollefeys, Marc			Camera Network Calibration and Synchronization from Silhouettes in Archived Video	INTERNATIONAL JOURNAL OF COMPUTER VISION			English	Article						Camera calibration; Epipolar geometry; Silhouettes; Frontier points; Epipolar tangents; Visual hulls; Camera networks; Camera network synchronization	EPIPOLAR GEOMETRY	In this paper we present an automatic method for calibrating a network of cameras that works by analyzing only the motion of silhouettes in the multiple video streams. This is particularly useful for automatic reconstruction of a dynamic event using a camera network in a situation where pre-calibration of the cameras is impractical or even impossible. The key contribution of this work is a RANSAC-based algorithm that simultaneously computes the epipolar geometry and synchronization of a pair of cameras only from the motion of silhouettes in video. Our approach involves first independently computing the fundamental matrix and synchronization for multiple pairs of cameras in the network. In the next stage the calibration and synchronization for the complete network is recovered from the pairwise information. Finally, a visual-hull algorithm is used to reconstruct the shape of the dynamic object from its silhouettes in video. For unsynchronized video streams with sub-frame temporal offsets, we interpolate silhouettes between successive frames to get more accurate visual hulls. We show the effectiveness of our method by remotely calibrating several different indoor camera networks from archived video streams.	[Sinha, Sudipta N.; Pollefeys, Marc] Univ N Carolina, Dept Comp Sci, Chapel Hill, NC USA	University of North Carolina; University of North Carolina Chapel Hill	Sinha, SN (corresponding author), Microsoft Res, Redmond, WA USA.	ssinha@cs.unc.edu; marc@cs.unc.edu	Pollefeys, Marc/I-7607-2013; Sinha, Sudipta/AAA-2447-2019		David and Lucille Packard Foundation; NSF [IIS-0237533]; European Research Council	David and Lucille Packard Foundation(The David & Lucile Packard Foundation); NSF(National Science Foundation (NSF)); European Research Council(European Research Council (ERC)European Commission)	We gratefully acknowledge the support of David and Lucille Packard Foundation Fellowship, NSF Career award IIS-0237533 and the European Research Council Grant-for their financial support on this project. We would also like to thank many researchers who have shared valuable datasets with us-Peter Sand, Seth Teller, Christian Theobalt, Marcus Magnor, Gabriel Brostow, German Cheung, Luca Ballan, Jonathan Stark, Adrian Hilton and the PERCEPTION research group at INRIA Rhone-Alpes. We are also grateful to Jean-Sebastien Franco and Edmund Boyer for the EPVH software ( Franco and Boyer 2003) for computing visual hulls.	BALLAN L, 2006, 3DPVT 06 P 3 INT S 3, P924; Bolles R.C., 1981, P 7 INT JOINT C ART, V1981, P637; Bouguet J.-Y., 2000, MATLAB CAMERA CALIBR; Boyer E, 2006, LECT NOTES COMPUT SC, V3851, P1; BROSTOW GJ, 2004, ECCV04, V3, P66; Carranza J, 2003, ACM T GRAPHIC, V22, P569, DOI 10.1145/882262.882309; Cheung GKM, 2003, PROC CVPR IEEE, P77; Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269; Franco J.-S., 2003, BRIT MACH VIS C BMVC, V1, P329, DOI [DOI 10.5244/C.17.32, 10.5244/C.17.32]; FRANCO JS, 2006, P 3 INT S 3D DAT PRO; Furukawa Y, 2006, IEEE T PATTERN ANAL, V28, P302, DOI 10.1109/TPAMI.2006.41; Hartley R., 2005, MULTIPLE VIEW GEOMET, V23; Hernandez C, 2007, IEEE T PATTERN ANAL, V29, P343, DOI 10.1109/TPAMI.2007.42; JOSHI T, 1995, INT C COMP VIS, P290; Kanade T, 1997, IEEE MULTIMEDIA, V4, P34, DOI 10.1109/93.580394; LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735; Lazebnik S, 2002, LECT NOTES COMPUT SC, V2352, P651; LAZEBNIK S, 2001, COMPUTER VISION PATT, V1, P156; LEVI N, 2003, COMPUTER VISION PATT, V1, P518; Matusik W, 2001, SPRING EUROGRAP, P115; Matusik W, 2000, COMP GRAPH, P369, DOI 10.1145/344779.344951; Mendonca PRS, 2001, IEEE T PATTERN ANAL, V23, P604, DOI 10.1109/34.927461; Pollefeys M, 2004, INT J COMPUT VISION, V59, P207, DOI 10.1023/B:VISI.0000025798.50602.3a; PORRILL J, 1991, IMAGE VISION COMPUT, V9, P45, DOI 10.1016/0262-8856(91)90048-T; Sand P, 2003, ACM T GRAPHIC, V22, P578, DOI 10.1145/882262.882310; Sinha SN, 2004, INT C PATT RECOG, P116, DOI 10.1109/ICPR.2004.1334021; SINHA SN, 2004, CVPR, V1, P195; SINHA SN, 2004, 3DPVT, P349; Starck J, 2007, IEEE COMPUT GRAPH, V27, P21, DOI 10.1109/MCG.2007.68; Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298; VIJAYAKUMAR B, 1996, CVPR             JUN, P327; Wong KYK, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P217, DOI 10.1109/ICCV.2001.937627; YEZZI AJ, 2003, CVPR, P525; Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561	34	34	36	0	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0920-5691	1573-1405		INT J COMPUT VISION	Int. J. Comput. Vis.	MAY	2010	87	3					266	283		10.1007/s11263-009-0269-2	http://dx.doi.org/10.1007/s11263-009-0269-2			18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	551KA		Green Submitted			2022-12-18	WOS:000274205700004
