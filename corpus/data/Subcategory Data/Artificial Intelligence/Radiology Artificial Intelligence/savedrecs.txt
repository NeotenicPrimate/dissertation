PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	C3	RP	EM	RI	OI	FU	FP	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	DL	D2	EA	PG	WC	WE	SC	GA	PM	OA	HC	HP	DA	UT
J	Mongan, J; Moy, L; Kahn, CE				Mongan, John; Moy, Linda; Kahn, Charles E., Jr.			Checklist for Artificial Intelligence in Medical Imaging (CLAIM): A Guide for Authors and Reviewers	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material							RADIOLOGY		[Mongan, John] Univ Calif San Francisco, Dept Radiol & Biomed Imaging, San Francisco, CA 94143 USA; [Moy, Linda] NYU, Sch Med, Dept Radiol, New York, NY USA; [Moy, Linda] NYU, Sch Med, Ctr Adv Imaging Innovat & Res, New York, NY USA; [Kahn, Charles E., Jr.] Univ Penn, Dept Radiol, 3400 Spruce St,1 Silverstein, Philadelphia, PA 19104 USA	University of California System; University of California San Francisco; New York University; New York University; University of Pennsylvania	Kahn, CE (corresponding author), Univ Penn, Dept Radiol, 3400 Spruce St,1 Silverstein, Philadelphia, PA 19104 USA.	ckahn@rsna.org	Kahn, Charles/U-5055-2019	Kahn, Charles/0000-0002-6654-7434; Mongan, John/0000-0003-2765-7451; Moy, Linda/0000-0001-9564-9360	Siemens	Siemens(Siemens AG)	J.M. Activities related to the present article: disclosed no relevant relationships. Activities not related to the present article: author is consultant for Siemens; institution receives grants from GE, Nuance, and Enlitic. Other relationships: disclosed no relevant relationships. L.M. Activities related to the present article: disclosed no relevant relationships. Activities not related to the present article: author is consultant for Lunit Insight and iCAD; institution receives grant from Siemens; travel accommodations from the Chinese Congress of Radiology and the Society of Breast Imaging. Other relationships: disclosed no relevant relationships. C.E.K. Activities related to the present article: institution receives salary support as Editor of Radiology: Artificial Intelligence. Activities not related to the present article: disclosed no relevant relationships. Other relationships: disclosed no relevant relationships.	Altman DG, 2008, LANCET, V371, P1149, DOI 10.1016/S0140-6736(08)60505-X; [Anonymous], CLIN TRIALS; Begg C, 1996, JAMA-J AM MED ASSOC, V276, P637, DOI 10.1001/jama.276.8.637; Bluemke DA, 2020, RADIOLOGY, V294, P487, DOI 10.1148/radiol.2019192515; Bossuyt PM, 2015, BMJ-BRIT MED J, V351, DOI [10.1148/radiol.2015151516, 10.1136/bmj.h5527, 10.1373/clinchem.2015.246280]; Bossuyt PM, 2003, LANCET, V361, P71, DOI 10.1016/S0140-6736(03)12122-8; Bossuyt PM, 2003, RADIOLOGY, V226, P24, DOI 10.1148/radiol.2261021292; Budovec JJ, 2010, AM J ROENTGENOL, V195, pW1, DOI 10.2214/AJR.10.4696; Cohen JF, 2016, BMJ OPEN, V6, DOI 10.1136/bmjopen-2016-012799; Eng J, 2003, RADIOLOGY, V227, P309, DOI 10.1148/radiol.2272012051; Geis JR, 2019, RADIOLOGY, V293, P436, DOI 10.1148/radiol.2019191586; Handelman GS, 2019, AM J ROENTGENOL, V212, P38, DOI 10.2214/AJR.18.20224; Harvey H, 2019, ARTIF INTELL; Kahn CE, 2019, RADIOL-ARTIF INTELL, V1, DOI [10.1148/ryai.2019184001, 10.1148/ryai2019184001]; Kohli M, 2019, J AM COLL RADIOL, V16, P1464, DOI 10.1016/j.jacr.2019.06.009; Lakhani P, 2012, RADIOLOGY, V265, P809, DOI 10.1148/radiol.12112438; Lambin P, 2017, NAT REV CLIN ONCOL, V14, P749, DOI 10.1038/nrclinonc.2017.141; Lipton ZC, 2015, ARXIV; Luo W, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.5870; National Institutes of Health, NIH COMM DAT EL CDE; Park SH, 2018, J KOREAN MED SCI, V33, DOI 10.3346/jkms.2018.33.e152; Park SH, 2018, RADIOLOGY, V286, P800, DOI 10.1148/radiol.2017171920; Provenzale JM, 2005, AM J ROENTGENOL, V185, P848, DOI 10.2214/AJR.05.0782; Radiological Society of North America American College of Radiology, RAD COMM DAT EL; Rubin DL, 2017, RADIOLOGY, V283, P836, DOI 10.1148/radiol.2016161553; Schulz KF, 2010, J CLIN EPIDEMIOL, V63, P834, DOI [10.1016/j.jclinepi.2010.02.005, 10.1016/j.ijsu.2011.09.004, 10.1186/1741-7015-8-18, 10.4103/0976-500X.72352]; Sheehan J, 2016, CLIN TRIALS, V13, P671, DOI 10.1177/1740774516653238; Simera I, 2013, INT J CLIN PRACT, V67, P710, DOI 10.1111/ijcp.12168; Vandenbroucke J.P., 2007, EPIDEMIOLOGY, V4; Willemink MJ, 2020, RADIOLOGY, V295, P4, DOI 10.1148/radiol.2020192224	30	129	129	7	10	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2020	2	2							e200029	10.1148/ryai.2020200029	http://dx.doi.org/10.1148/ryai.2020200029			6	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CS	33937821	Bronze, Green Published			2022-12-18	WOS:000826298800009
J	Reyes, M; Meier, R; Pereira, S; Silva, CA; Dahlweid, FM; Von Tengg-Kobligk, H; Summers, RM; Wiest, R				Reyes, Mauricio; Meier, Raphael; Pereira, Sergio; Silva, Carlos A.; Dahlweid, Fried-Michael; Von Tengg-Kobligk, Hendrik; Summers, Ronald M.; Wiest, Roland			On the Interpretability of Artificial Intelligence in Radiology: Challenges and Opportunities	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							FEATURES	As artificial intelligence (AI) systems begin to make their way into clinical radiology practice, it is crucial to assure that they function correctly and that they gain the trust of experts. Toward this goal, approaches to make AI "interpretable" have gained attention to enhance the understanding of a machine learning algorithm, despite its complexity. This article aims to provide insights into the current state of the art of interpretability methods for radiology AI. This review discusses radiologists' opinions on the topic and suggests trends and challenges that need to be addressed to effectively streamline interpretability methods in clinical practice. Supplemental material is available for this article. (C) RSNA, 2020.	[Reyes, Mauricio] Univ Bern, Artorg Ctr Biomed Res, Murtenstr 50, CH-3008 Bern, Switzerland; [Dahlweid, Fried-Michael] Univ Bern, Insel Data Sci Ctr, Bern, Switzerland; [Meier, Raphael; Wiest, Roland] Inselspital Univ Hosp Bern, Inst Diagnost & Intervent Neuroradiol, Bern, Switzerland; [Von Tengg-Kobligk, Hendrik] Inselspital Univ Hosp Bern, Dept Diagnost Intervent & Paediat Radiol, Bern, Switzerland; [Pereira, Sergio; Silva, Carlos A.] Univ Minho, Ctr Microelectromech Syst Univ Minho Res Unit, Guimaraes, Portugal; [Summers, Ronald M.] NIH, Ctr Clin, Dept Radiol & Imaging Sci, Bethesda, MD 20892 USA	University of Bern; University of Bern; University of Bern; University Hospital of Bern; University of Bern; University Hospital of Bern; Universidade do Minho; National Institutes of Health (NIH) - USA; NIH Clinical Center (CC)	Reyes, M (corresponding author), Univ Bern, Artorg Ctr Biomed Res, Murtenstr 50, CH-3008 Bern, Switzerland.	mauricio.reyes@med.unibe.ch	Silva, Carlos/J-1190-2014; Pereira, Sergio/N-9642-2015; Dahlweid, Fried-Michael/M-9363-2018; von Tengg-Kobligk, Hendrik/A-1420-2017	Silva, Carlos/0000-0002-1015-5095; Pereira, Sergio/0000-0002-4298-0903; Dahlweid, Fried-Michael/0000-0002-5416-9915; von Tengg-Kobligk, Hendrik/0000-0003-3207-3223; Reyes, Mauricio/0000-0002-2434-9990; Meier, Raphael/0000-0003-4632-0360				Adebayo J, ARXIV 181003292; Ancona Marco, 2018, 6 INT C LEARNING REP; Nguyen A, 2015, PROC CVPR IEEE, P427, DOI 10.1109/CVPR.2015.7298640; [Anonymous], UNDERSTANDING INTERP, DOI DOI 10.1007/978-3-030-02628-8_12; Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140; Balsiger F., 2019, P MACHINE LEARNING R, V102, P27; Caruana R, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1721, DOI 10.1145/2783258.2788613; Doshi-Velez F, ARXIV 170208608; Eaton-Rosen Z, 2018, LECT NOTES COMPUT SC, V11070, P691, DOI 10.1007/978-3-030-00928-1_78; Gale W, ARXIV 180600340 PREP; Gallego-Ortiz C, ARXIV 160608288 PREP; Geirhos R, IMAGENET TRAINED CNN; Geis JR, 2019, CAN ASSOC RADIOL J, V70, P329, DOI 10.1016/j.carj.2019.08.010; Goldstein A, 2015, J COMPUT GRAPH STAT, V24, P44, DOI 10.1080/10618600.2014.907095; Goodman B, 2017, AI MAG, V38, P50, DOI 10.1609/aimag.v38i3.2741; Graziani M, 2019, PROC SPIE, V10950, DOI 10.1117/12.2512584; Grossmann P, 2017, ELIFE, V6, DOI 10.7554/eLife.23421; Gunning D., EXPLAINABLE ARTIFICI; Guo CA, 2017, PR MACH LEARN RES, V70; He JX, 2019, NAT MED, V25, P30, DOI 10.1038/s41591-018-0307-0; Jungo A, 1907, ARXIV; Jungo A, 2018, 1 C MEDICAL IMAGING; Kim B, ARXIV 171111279 PREP; Koh PW, ARXIV 170304730 PREP; Leibig C, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-17876-z; Lipton ZC, ARXIV 160603490V3 PR; Lundberg SM, 2017, ADV NEUR IN, V30; Mahapatra D, 2018, LECT NOTES COMPUT SC, V11071, P580, DOI 10.1007/978-3-030-00934-2_65; Maier-Hein L., 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P616, DOI 10.1007/978-3-319-46723-8_71; Maier-Hein L, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-07619-7; MillerT, ARXIV 170607269 PREP; Nair T, 2018, LECT NOTES COMPUT SC, V11070, P655, DOI 10.1007/978-3-030-00928-1_74; Pereira S, 2018, MED IMAGE ANAL, V44, P228, DOI 10.1016/j.media.2017.12.009; Poursabzi-Sangdeh F, ARXIV 180207810 PREP; Ribeiro MT, KDD16 P 22 ACM; Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74; Shrikumar A, 2017, PR MACH LEARN RES, V70; Simonyan K, ARXIV 13126034 PREPR; Springenberg JT, ARXIV 14126806; Szegedy C, ARXIV 13126199; Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7; van Lent M, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P900; Zech J, 2018, RADIOLOGY, V287, P570, DOI 10.1148/radiol.2018171093; Zech JR, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002683; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319; Zhu B, 2018, NATURE, V555, P487, DOI 10.1038/nature25988	48	100	101	2	11	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2020	2	3							e190043	10.1148/ryai.2020190043	http://dx.doi.org/10.1148/ryai.2020190043			12	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CW	32510054	Green Published			2022-12-18	WOS:000826470300003
J	Shih, G; Wu, CC; Halabi, SS; Kohli, MD; Prevedello, LM; Cook, TS; Sharma, A; Amorosa, JK; Arteaga, V; Galperin-Aizenberg, M; Gill, RR; Godoy, MCB; Hobbs, S; Jeudy, J; Laroia, A; Shah, PN; Vummidi, D; Yaddanapudi, K; Stein, A				Shih, George; Wu, Carol C.; Halabi, Safwan S.; Kohli, Marc D.; Prevedello, Luciano M.; Cook, Tessa S.; Sharma, Arjun; Amorosa, Judith K.; Arteaga, Veronica; Galperin-Aizenberg, Maya; Gill, Ritu R.; Godoy, Myrna C. B.; Hobbs, Stephen; Jeudy, Jean; Laroia, Archana; Shah, Palmi N.; Vummidi, Dharshan; Yaddanapudi, Kavitha; Stein, Anouk			Augmenting the National Institutes of Health Chest Radiograph Dataset with Expert Annotations of Possible Pneumonia	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article									[Shih, George] Weill Cornell Med Coll, Dept Radiol, 525 E 68th St,Box 141, New York, NY 10065 USA; [Wu, Carol C.; Godoy, Myrna C. B.] Univ Texas MD Anderson Canc Ctr, Dept Diagnost Radiol, Houston, TX 77030 USA; [Halabi, Safwan S.] Stanford Univ, Sch Med, Dept Radiol, Stanford, CA 94305 USA; [Kohli, Marc D.] Univ Calif San Francisco, Dept Radiol & Biomed Imaging, San Francisco, CA 94143 USA; [Prevedello, Luciano M.] Ohio State Univ, Dept Radiol, Wexner Med Ctr, Columbus, OH 43210 USA; [Cook, Tessa S.; Galperin-Aizenberg, Maya] Hosp Univ Penn, Dept Radiol, 3400 Spruce St, Philadelphia, PA 19104 USA; [Sharma, Arjun] Amita Hlth, Dept Radiol, Chicago, IL USA; [Amorosa, Judith K.] Rutgers Robert Wood Johnson Med Sch, Dept Radiol, New Brunswick, NJ USA; [Arteaga, Veronica] Univ Arizona, Coll Med, Dept Radiol, Tucson, AZ 85724 USA; [Gill, Ritu R.] Beth Israel Deaconess Med Ctr, Dept Radiol, 330 Brookline Ave, Boston, MA 02215 USA; [Hobbs, Stephen] Univ Kentucky, Coll Med, Dept Radiol, Lexington, KY USA; [Jeudy, Jean] Univ Maryland, Sch Med, Dept Diagnost Radiol & Nucl Med, Baltimore, MD 21201 USA; [Laroia, Archana] Univ Iowa, Dept Radiol, Carver Coll Med, Iowa City, IA 52242 USA; [Shah, Palmi N.] Rush Univ, Dept Diagnost Radiol, Med Ctr, Chicago, IL USA; [Vummidi, Dharshan] Univ Michigan Hlth Syst, Dept Radiol, Ann Arbor, MI USA; [Yaddanapudi, Kavitha] Stony Brook Sch Med, Dept Radiol, Stony Brook, NY USA; [Stein, Anouk] MDai, New York, NY USA; [Yaddanapudi, Kavitha] Univ Arizona, Dept Radiol, Tucson, AZ 85724 USA		Shih, G (corresponding author), Weill Cornell Med Coll, Dept Radiol, 525 E 68th St,Box 141, New York, NY 10065 USA.	george@cornellradiology.org	; Halabi, Safwan/H-2279-2018	Prevedello, Luciano/0000-0002-6768-6452; Jeudy, Jean/0000-0002-6028-459X; Halabi, Safwan/0000-0003-1317-984X; Stein, Anouk/0000-0002-3066-7901; Shih, George/0000-0002-8356-2011	ACR Innovation grant; Beryl Institute; ACRIN	ACR Innovation grant; Beryl Institute; ACRIN	lated to the present article: travel reimbursement for board meetings from SIIM; income and travel support from Medical Sciences Corporation for work on xray truck in Kenya and work on datasets for machine learning in Kenya; ACR Innovation grant for LI-RADS, CAR/DS, and CDE work; Gilead, Fuji Medical Systems (UCSF CME) paid for lecture on machine learning at Gilead headquarters to Gilead employees, nothing related to Gilead products; gave lecture on machine learning to SIIM 2017 attendees at Fiji reception; presenter at UCSF Palm Springs CME course. Other relationships: disclosed no relevant relationships. L.M. P. disclosed no relevant relationships. T.S.C. Activities related to the present article: disclosed no relevant relationships. Activities not related to the present article: travel expenses to board meetings and retreats covered by RSNA and SIIM; grant from Beryl Institute and ACRIN; receives royalties from Osler Institute for lectures originally give in 2012-2013. Other relationships: serves on committees and boards for multiple radiology and medical societies, including AUR, RSNA, SIIM, ACR, PRS, PRRS, SPIE, and AMIA and is not paid for this work. A. Sharma Activities related to the present article: disclosed no relevant relationships. Activities not related to the present article: consultant for IBM developing their Watson Health Service. Other relationships: disclosed no relevant relationships. J.K.A. disclosed no relevant relationships. V.A. disclosed no relevant relationships. M. G. disclosed no relevant relationships. R.R. G. disclosed no relevant relationships. M. C.B.G. disclosed no relevant relationships. S.H. Activities related to the present article: disclosed no relevant relationships. Activities not related to the present article: received payment from Potomac Center for Medical Education and Academy for Continued Healthcare Learning for preparation and delivery of CME lectures; book royalties from Wolters Kluwer Health and Elsevier. Other relationships: disclosed no relevant relationships. J.J. disclosed no relevant relationships. A.L. disclosed no relevant relationships. P.N.S. disclosed no relevant relationships. D.V. Activities related to the present article: disclosed no relevant relationships. Activities not related to the present article: consultant for Boehringer Ingelheim; travel paid by Boehringer Ingelheim for Open Source Imaging Consortium in interstitial lung disease meetings. Other relationships: disclosed no relevant relationships. K.Y. Activities related to the present article: disclosed no relevant relationships. Activities not related to the present article: received payment for lecture (speakers bureau) from Boerhinger Ingelheim. Other relationships: disclosed no relevant relationships. A. Stein Activities related to the present article: employed by MD.ai, which provided the annotation tool for the project; patent issued for MD.ai. Activities not related to the present article: disclosed no relevant relationships. Other relationships: disclosed no relevant relationships. Activities related to the present article: MD.ai board member, consultant, and shareholder. Activities not related to the present article: MD.ai board member, consultant, and shareholder. Other relationships: disclosed no relevant relationships. C.C. W. disclosed no relevant relationships. S.S.H. disclosed no relevant relationships. M.D.K. Activities related to the present article: disclosed no relevant relationships. Activities not re-	[Anonymous], DEATHS FINAL DATA 20; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Hansell DM, 2008, RADIOLOGY, V246, P697, DOI 10.1148/radiol.2462070712; Rajpurkar P, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002686; Rui P., NATL AMBULATORY MED; Wang X, 2017, PROC CVPR IEEE, P7178, DOI 10.1109/CVPR.2017.759	6	72	72	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2019	1	1							e180041	10.1148/ryai.2019180041	http://dx.doi.org/10.1148/ryai.2019180041			5	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CL	33937785	Green Published			2022-12-18	WOS:000826287700006
J	Thian, YL; Li, YT; Jagmohan, P; Sia, D; Chan, VEY; Tan, RT				Thian, Yee Liang; Li, Yiting; Jagmohan, Pooja; Sia, David; Chan, Vincent Ern Yao; Tan, Robby T.			Convolutional Neural Networks for Automated Fracture Detection and Localization on Wrist Radiographs	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To demonstrate the feasibility and performance of an object detection convolutional neural network (CNN) for fracture detection and localization on wrist radiographs. Materials and Methods: Institutional review board approval was obtained with waiver of consent for this retrospective study. A total of 7356 wrist radiographic studies were extracted from a hospital picture archiving and communication system. Radiologists annotated all radius and ulna fractures with bounding boxes. The dataset was split into training (90%) and validation (10%) sets and used to train fracture localization models for frontal and lateral images. Inception-ResNet Faster R-CNN architecture was implemented as a deep learning model. The models were tested on an unseen test set of 524 consecutive emergency department wrist radiographic studies with two radiologists in consensus as the reference standard. Per-fracture, per-image (ie, per-view), and per-study sensitivity and specificity were determined. Area under the receiver operating characteristic curve (AUC) analysis was performed. Results: The model detected and correctly localized 310 (91.2%) of 340 and 236 (96.3%) of 245 of all radius and ulna fractures on the frontal and lateral views, respectively. The per-image sensitivity, specificity, and AUC were 95.7% (95% confidence interval [CI]: 92.4%, 97.8%), 82.5% (95% CI: 77.4%, 86.8%), and 0.918 (95% CI: 0.894, 0.941), respectively, for the frontal view and 96.7% (95% CI: 93.6%, 98.6%), 86.4% (95% CI: 81.9%, 90.2%), and 0.933 (95% CI: 0.912, 0.954), respectively, for the lateral view. The per-study sensitivity, specificity, and AUC were 98.1% (95% CI: 95.6%, 99.4%), 72.9% (95% CI: 67.1%, 78.2%), and 0.895 (95% CI: 0.870, 0.920), respectively. Conclusion: The ability of an object detection CNN to detect and localize radius and ulna fractures on wrist radiographs with high sensitivity and specificity was demonstrated. (C) RSNA, 2019	[Thian, Yee Liang; Jagmohan, Pooja; Sia, David; Chan, Vincent Ern Yao] Natl Univ Singapore, Dept Diagnost Imaging, 5 Lower Kent Ridge Rd, Singapore 1190741, Singapore; [Li, Yiting; Tan, Robby T.] Natl Univ Singapore, Dept Elect & Comp Engn, 5 Lower Kent Ridge Rd, Singapore 1190741, Singapore; [Tan, Robby T.] Yale NUS Coll, Sci Div, Singapore, Singapore		Thian, YL (corresponding author), Natl Univ Singapore, Dept Diagnost Imaging, 5 Lower Kent Ridge Rd, Singapore 1190741, Singapore.	yee_liang_thian@nuhs.edu.sg		Thian, Yee Liang/0000-0001-9899-205X				Batchelor O., 2016, 2016 INT C IMAGE VIS, P1; Bentohami A, 2014, BMC MUSCULOSKEL DIS, V15, DOI 10.1186/1471-2474-15-24; Cho J, ARXIV; Chung SW, 2018, ACTA ORTHOP, V89, P468, DOI 10.1080/17453674.2018.1453714; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Goodfellow I.J., ARXIV; Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Kim DH, 2018, CLIN RADIOL, V73, P439, DOI 10.1016/j.crad.2017.11.015; Kohli M, 2017, AM J ROENTGENOL, V208, P754, DOI 10.2214/AJR.16.17224; Lakhani P, 2017, RADIOLOGY, V284, P574, DOI 10.1148/radiol.2017162326; Larson DB, 2018, RADIOLOGY, V287, P313, DOI 10.1148/radiol.2017170236; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Long L, ARXIV; Olczak J, 2017, ACTA ORTHOP, V88, P581, DOI 10.1080/17453674.2017.1344459; Petinaux B, 2011, AM J EMERG MED, V29, P18, DOI 10.1016/j.ajem.2009.07.011; Pinto A, 2016, BRIT J RADIOL, V89, DOI 10.1259/bjr.20150914; Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Teare P, 2017, J DIGIT IMAGING, V30, P499, DOI 10.1007/s10278-017-9993-2; Thrall JH, 2018, J AM COLL RADIOL, V15, P504, DOI 10.1016/j.jacr.2017.12.026; Xiao T, 2015, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2015.7298885	24	68	69	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2019	1	1							e180001	10.1148/ryai.2019180001	http://dx.doi.org/10.1148/ryai.2019180001			8	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CL	33937780	Green Published			2022-12-18	WOS:000826287700001
J	Sabottke, CF; Spieler, BM				Sabottke, Carl F.; Spieler, Bradley M.			The Effect of Image Resolution on Deep Learning in Radiography	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							AREAS	Purpose: To examine variations of convolutional neural network (CNN) performance for multiple chest radiograph diagnoses and image resolutions. Materials and Methods: This retrospective study examined CNN performance using the publicly available National Institutes of Health chest radiograph dataset comprising 112 120 chest radiographic images from 30 805 patients. The network architectures examined included ResNet34 and DenseNet121. Image resolutions ranging from 32 x 32 to 600 x 600 pixels were investigated. Network training paradigms used 80% of samples for training and 20% for validation. CNN performance was evaluated based on area under the receiver operating characteristic curve (AUC) and label accuracy. Binary output networks were trained separately for each label or diagnosis under consideration. Results: Maximum AUCs were achieved at image resolutions between 256 x 256 and 448 x 448 pixels for binary decision networks targeting emphysema, cardiomegaly, hernias, edema, effusions, atelectasis, masses, and nodules. When comparing performance between networks that utilize lower resolution (64 x 64 pixels) versus higher (320 x 320 pixels) resolution inputs, emphysema, cardiomegaly, hernia, and pulmonary nodule detection had the highest fractional improvements in AUC at higher image resolutions. Specifically, pulmonary nodule detection had an AUC performance ratio of 80.7% +/- 1.5 (standard deviation) (0.689 of 0.854) whereas thoracic mass detection had an AUC ratio of 86.7% +/- 1.2 (0.767 of 0.886) for these image resolutions. Conclusion: Increasing image resolution for CNN training often has a trade-off with the maximum possible batch size, yet optimal selection of image resolution has the potential for further increasing neural network performance for various radiology-based machine learning tasks. Furthermore, identifying diagnosis-specific tasks that require relatively higher image resolution can potentially provide insight into the relative difficulty of identifying different radiology findings. (c) RSNA, 2020	[Sabottke, Carl F.; Spieler, Bradley M.] LSU Hlth Sci Ctr New Orleans, Dept Radiol, 433 Bolivar St, New Orleans, LA 70112 USA	Louisiana State University System; Louisiana State University Health Sciences Center New Orleans	Sabottke, CF (corresponding author), LSU Hlth Sci Ctr New Orleans, Dept Radiol, 433 Bolivar St, New Orleans, LA 70112 USA.	cfs121090@gmail.com						Aarti Bagul, 2017, Arxiv, DOI arXiv:1711.05225; Annarumma M, 2019, RADIOLOGY, V291, P195, DOI 10.1148/radiol.2018180921; [Anonymous], 1999, 10153 BS EN; Atwi NE, 2019, ABDOM RADIOL, V44, P783, DOI 10.1007/s00261-018-1774-y; BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; Deng J., IMAGENET LARGE SCALE; Huang G., DENSELY CONNECTED CO; Irvin J, CHEXPERT LARGE CHEST; Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90; Krizhevsky A., 2009, LEARNING MULTIPLE L; Marinelli B, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180019; Rayan JC, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180015; Rodriguez-Ruiz A, 2019, RADIOLOGY, V290, P305, DOI 10.1148/radiol.2018181371; Rosenkrantz AB, 2012, AM J ROENTGENOL, V199, P830, DOI 10.2214/AJR.11.8446; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Smith LN, ARXIV 180309820 PREP; Snoeckx A, 2018, INSIGHTS IMAGING, V9, P73, DOI 10.1007/s13244-017-0581-2; Sun X, 2014, IEEE SIGNAL PROC LET, V21, P1389, DOI 10.1109/LSP.2014.2337313; Wang X, CHESTX RAY8 HOSP SCA; Yao L, ARXIV 171010501 PREP	21	67	67	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2020	2	1							e190015	10.1148/ryai.2019190015	http://dx.doi.org/10.1148/ryai.2019190015			7	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CR	33937810	Bronze, Green Published			2022-12-18	WOS:000826298000003
J	Knoll, F; Zbontar, J; Sriram, A; Muckley, MJ; Bruno, M; Defazio, A; Parente, M; Geras, KJ; Katsnelson, J; Chandarana, H; Zhang, ZH; Drozdzalv, M; Romero, A; Rabbat, M; Vincent, P; Pinkerton, J; Wang, D; Yakubova, N; Owens, E; Zitnick, CL; Recht, MP; Sodickson, DK; Lui, YW				Knoll, Florian; Zbontar, Jure; Sriram, Anuroop; Muckley, Matthew J.; Bruno, Mary; Defazio, Aaron; Parente, Marc; Geras, Krzysztof J.; Katsnelson, Joe; Chandarana, Hersh; Zhang, Zizhao; Drozdzalv, Michal; Romero, Adriana; Rabbat, Michael; Vincent, Pascal; Pinkerton, James; Wang, Duo; Yakubova, Nafissa; Owens, Erich; Zitnick, C. Lawrence; Recht, Michael P.; Sodickson, Daniel K.; Lui, Yvonne W.			fastMRI: A Publicly Available Raw k-Space and DICOM Dataset of Knee Images for Accelerated MR Image Reconstruction Using Machine Learning	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Knoll, Florian; Muckley, Matthew J.; Bruno, Mary; Parente, Marc; Geras, Krzysztof J.; Katsnelson, Joe; Chandarana, Hersh; Wang, Duo; Yakubova, Nafissa; Recht, Michael P.; Sodickson, Daniel K.; Lui, Yvonne W.] NYU Sch Med, Dept Radiol, 650 First Ave, New York, NY 10016 USA; [Zbontar, Jure; Sriram, Anuroop; Pinkerton, James; Owens, Erich; Zitnick, C. Lawrence] Facebook, Dept Artificial Intelligence Res, Menlo Pk, CA USA; [Defazio, Aaron] Facebook, Dept Artificial Intelligence Res, New York, NY USA; [Geras, Krzysztof J.] NYU, Ctr Data Sci, 550 1St Ave, New York, NY 10003 USA; [Drozdzalv, Michal; Romero, Adriana; Rabbat, Michael; Vincent, Pascal] Facebook, Dept Artificial Intelligence Res, Montreal, PQ, Canada; [Zhang, Zizhao] Univ Florida, Dept Comp Sci, Gainesville, FL USA	New York University; Facebook Inc; Facebook Inc; New York University; Facebook Inc; State University System of Florida; University of Florida	Lui, YW (corresponding author), NYU Sch Med, Dept Radiol, 650 First Ave, New York, NY 10016 USA.	Yvonne.Lui@nyulangone.org	Sriram, Anuroop/AAF-1926-2021; Sodickson, Daniel/AAV-4715-2021	Sriram, Anuroop/0000-0001-6295-7535; Sodickson, Daniel/0000-0002-2436-4664; Knoll, Florian/0000-0001-5357-8656; Parente, Marc/0000-0002-7611-0324; , michael/0000-0002-8546-6314; Muckley, Matthew/0000-0002-6525-8817; Chandarana, Hersh/0000-0002-6807-4589; bruno, mary/0000-0003-1625-0293	National Institutes of Health [R01EB024532, P41EB017183]	National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	We would like to thank Tobias Block for assistance with the Yarra database framework. We would also like to thank the National Institutes of Health for grants R01EB024532 and P41EB017183 for research support.	Block TK, 2016, ISMRM WORKSHOP DATA; Chen F, 2018, RADIOLOGY, V289, P366, DOI 10.1148/radiol.2018180445; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Eckstein F, 2012, NAT REV RHEUMATOL, V8, P622, DOI 10.1038/nrrheum.2012.113; Griswold MA, 2005, MAGN RESON MED, V54, P1553, DOI 10.1002/mrm.20722; Hammernik K, 2018, MAGN RESON MED, V79, P3055, DOI 10.1002/mrm.26977; Inati SJ, 2017, MAGN RESON MED, V77, P411, DOI 10.1002/mrm.26089; Knoll F, 2019, MAGN RESON MED, V81, P116, DOI 10.1002/mrm.27355; Mardani M, 2019, IEEE T MED IMAGING, V38, P167, DOI 10.1109/TMI.2018.2858752; Petersen RC, 2010, NEUROLOGY, V74, P201, DOI 10.1212/WNL.0b013e3181cb3e25; Pruessmann KP, 1999, MAGNET RESON MED, V42, P952, DOI 10.1002/(SICI)1522-2594(199911)42:5<952::AID-MRM16>3.0.CO;2-S; Pruessmann KP, 2001, MAGNET RESON MED, V46, P638, DOI 10.1002/mrm.1241; Schlemper J, 2018, IEEE T MED IMAGING, V37, P491, DOI 10.1109/TMI.2017.2760978; Sodickson DK, 1997, MAGNET RESON MED, V38, P591, DOI 10.1002/mrm.1910380414; Tygert M, ARXIV181108839; Van Essen DC, 2013, NEUROIMAGE, V80, P62, DOI 10.1016/j.neuroimage.2013.05.041; Wang SS, 2016, I S BIOMED IMAGING, P514, DOI 10.1109/ISBI.2016.7493320; Zbontar J, ARXIV 181108839; Zhu B, 2018, NATURE, V555, P487, DOI 10.1038/nature25988	19	61	63	1	11	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2020	2	1							e190007	10.1148/ryai.2020190007	http://dx.doi.org/10.1148/ryai.2020190007			5	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CR	32076662	Green Published			2022-12-18	WOS:000826298000008
J	Conant, EF; Toledano, AY; Periaswamy, S; Fotin, SV; Go, J; Boatsman, JE; Hoffmeister, JW				Conant, Emily F.; Toledano, Alicia Y.; Periaswamy, Senthil; Fotin, Sergei, V; Go, Jonathan; Boatsman, Justin E.; Hoffmeister, Jeffrey W.			Improving Accuracy and Efficiency with Concurrent Use of Artificial Intelligence for Digital Breast Tomosynthesis	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							COMPUTER-AIDED DETECTION; SYNTHESIZED 2-DIMENSIONAL MAMMOGRAPHY; DIAGNOSTIC-ACCURACY; INTERPRETATION TIME; READING TIME; PERFORMANCE; IMPLEMENTATION; READERS; CURVES	Purpose: To evaluate the use of artificial intelligence (AI) to shorten digital breast tomosynthesis (DBT) reading time while maintaining or improving accuracy. Materials and Methods: A deep learning AI system was developed to identify suspicious soft-tissue and calcified lesions in DBT images. A reader study compared the performance of 24 radiologists (13 of whom were breast subspecialists) reading 260 DBT examinations (including 65 cancer cases) both with and without AI. Readings occurred in two sessions separated by at least 4 weeks. Area under the receiver operating characteristic curve (AUC), reading time, sensitivity, specificity, and recall rate were evaluated with statistical methods for multireader, multicase studies. Results: Radiologist performance for the detection of malignant lesions, measured by mean AUC, increased 0.057 with the use of AI (95% confidence interval [CI]: 0.028, 0.087; P<.01), from 0.795 without AI to 0.852 with AI. Reading time decreased 52.7% (95% CI: 41.8%, 61.5%; P<.01), from 64.1 seconds without to 30.4 seconds with AI. Sensitivity increased from 77.0% without AI to 85.0% with AI (8.0%; 95% CI: 2.6%, 13.4%; P<.01), specificity increased from 62.7% without to 69.6% with AI (6.9%; 95% CI: 3.0%, 10.8%; noninferiority P<.01), and recall rate for noncancers decreased from 38.0% without to 30.9% with AI (7.2%; 95% CI: 3.1%, 11.2%; noninferiority P<.01). Conclusion: The concurrent use of an accurate DBT AI system was found to improve cancer detection efficacy in a reader study that demonstrated increases in AUC, sensitivity, and specificity and a reduction in recall rate and reading time. (C) RSNA, 2019	[Conant, Emily F.] Univ Penn, Perelman Sch Med, Dept Radiol, 3400 Spruce St, Philadelphia, PA 19104 USA; [Toledano, Alicia Y.] Biostat Consulting, Kensington, MD USA; [Periaswamy, Senthil; Fotin, Sergei, V; Go, Jonathan; Hoffmeister, Jeffrey W.] iCAD, Nashua, NH USA; [Boatsman, Justin E.] Intrins Imaging, Bolton, MA USA	University of Pennsylvania; Pennsylvania Medicine	Conant, EF (corresponding author), Univ Penn, Perelman Sch Med, Dept Radiol, 3400 Spruce St, Philadelphia, PA 19104 USA.	emily.conant@pennmedicine.upenn.edu		Hoffmeister, Jeffrey/0000-0002-8203-6589; Conant, Emily/0000-0001-9331-644X	National Cancer Institute [U54CA163313]; iCAD; Hologic	National Cancer Institute(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Cancer Institute (NCI)); iCAD; Hologic	E.F.C. supported by grants from the National Cancer Institute (U54CA163313), iCAD, and Hologic.	[Anonymous], ACR STAT BREAST TOM; Aujero MP, 2017, RADIOLOGY, V283, P70, DOI 10.1148/radiol.2017162674; Balleyguier C, 2017, EUR J RADIOL, V97, P83, DOI 10.1016/j.ejrad.2017.10.014; BARTLETT MS, 1947, BIOMETRICS, V3, P39, DOI 10.2307/3001536; Benedikt RA, 2018, AM J ROENTGENOL, V210, P685, DOI 10.2214/AJR.17.18185; Bernardi D, 2012, BRIT J RADIOL, V85, pE1174, DOI 10.1259/bjr/19385909; Chae EY, 2019, EUR RADIOL, V29, P2518, DOI 10.1007/s00330-018-5886-0; Clinical Performance Assessment, CONS COMP ASS DET DE; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; Fenton JJ, 2007, NEW ENGL J MED, V356, P1399, DOI 10.1056/NEJMoa066099; Friedewald SM, 2014, JAMA-J AM MED ASSOC, V311, P2499, DOI 10.1001/jama.2014.6095; Gilbert FJ, 2008, NEW ENGL J MED, V359, P1675, DOI 10.1056/NEJMoa0803545; Gilbert FJ, 2015, RADIOLOGY, V277, P697, DOI 10.1148/radiol.2015142566; Gromet M, 2008, AM J ROENTGENOL, V190, P854, DOI 10.2214/AJR.07.2812; Gur D, 2008, RADIOLOGY, V249, P47, DOI 10.1148/radiol.2491072025; Hillis SL, 2007, STAT MED, V26, P596, DOI 10.1002/sim.2532; Hooley RJ, 2017, AM J ROENTGENOL, V208, P256, DOI 10.2214/AJR.16.17127; James JJ, 2010, RADIOLOGY, V256, P379, DOI 10.1148/radiol.10091899; Lehman CD, 2015, JAMA INTERN MED, V175, P1828, DOI 10.1001/jamainternmed.2015.5231; McDonald ES, 2016, JAMA ONCOL, V2, P737, DOI 10.1001/jamaoncol.2015.5536; Obuchowski N A, 1995, Acad Radiol, V2 Suppl 1, pS22; OBUCHOWSKI NA, 1995, COMMUN STAT SIMULAT, V24, P285, DOI 10.1080/03610919508813243; Obuchowski NA, 2000, AM J ROENTGENOL, V175, P603, DOI 10.2214/ajr.175.3.1750603; Obuchowski NA, 1998, STAT MED, V17, P1495, DOI 10.1002/(SICI)1097-0258(19980715)17:13<1495::AID-SIM863>3.0.CO;2-I; RAO JNK, 1992, BIOMETRICS, V48, P577, DOI 10.2307/2532311; Sharpe RE, 2016, RADIOLOGY, V278, P698, DOI 10.1148/radiol.2015142036; Sickles EA, 2013, ACR BI RADS ATLAS BR, V5th, P46; Skaane P, 2013, RADIOLOGY, V267, P47, DOI 10.1148/radiol.12121373; Tchou PM, 2010, RADIOLOGY, V257, P40, DOI 10.1148/radiol.10092170; Tucker L, 2017, RADIOLOGY, V283, P371, DOI 10.1148/radiol.2017151936; Wilson EB, 1927, J AM STAT ASSOC, V22, P209, DOI 10.2307/2276774; Zhou XH, 1996, STAT MED, V15, P1687, DOI 10.1002/(SICI)1097-0258(19960815)15:15<1687::AID-SIM324>3.0.CO;2-S; Zuckerman SP, 2016, RADIOLOGY, V281, P730, DOI 10.1148/radiol.2016160366	33	61	62	0	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2019	1	4							e180096	10.1148/ryai.2019180096	http://dx.doi.org/10.1148/ryai.2019180096			12	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CO	32076660	Green Published			2022-12-18	WOS:000826292900004
J	Flanders, AE; Prevedello, LM; Shih, G; Halabi, SS; Kalpathy-Cramer, J; Ball, R; Mongan, JT; Stein, A; Kitamura, FC; Lungren, MP; Choudhary, G; Cala, L; Coelho, L; Mogensen, M; Moron, F; Miller, E; Ikuta, I; Zohrabian, V; McDonnell, O; Lincoln, C; Shah, L; Joyner, D; Agarwal, A; Lee, RK; Nath, J				Flanders, Adam E.; Prevedello, Luciano M.; Shih, George; Halabi, Safwan S.; Kalpathy-Cramer, Jayashree; Ball, Robyn; Mongan, John T.; Stein, Anouk; Kitamura, Felipe C.; Lungren, Matthew P.; Choudhary, Gagandeep; Cala, Lesley; Coelho, Luiz; Mogensen, Monique; Moron, Fanny; Miller, Elka; Ikuta, Ichiro; Zohrabian, Vahe; McDonnell, Olivia; Lincoln, Christie; Shah, Lubdha; Joyner, David; Agarwal, Amit; Lee, Ryan K.; Nath, Jaya		RSNA-ASNR 2019 Brain Hemorrhage CT	Construction of a Machine Learning Dataset through Collaboration: The RSNA 2019 Brain CT Hemorrhage Challenge	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article									[Flanders, Adam E.] Thomas Jefferson Univ Hosp, Dept Radiol, Div Neuroradiol, 132 S Tenth St,Suite 1080B Main Bldg, Philadelphia, PA 19107 USA; [Prevedello, Luciano M.] Ohio State Univ, Dept Radiol, Columbus, OH 43210 USA; [Shih, George] Weill Cornell Med Coll, Dept Radiol, New York, NY USA; [Halabi, Safwan S.; Lungren, Matthew P.] Stanford Univ, Dept Radiol, Stanford, CA 94305 USA; [Kalpathy-Cramer, Jayashree] Massachusetts Gen Hosp, Dept Radiol, Charlestown, MA USA; [Kalpathy-Cramer, Jayashree] Massachusetts Gen Hosp, Athinoula A Martins Ctr Biomed Imaging, Charlestown, MA USA; [Ball, Robyn] Stanford Univ, Quantitat Sci Unit, Stanford, CA 94305 USA; [Mongan, John T.] Univ Calif San Francisco, Dept Radiol & Biomed Imaging, San Francisco, CA 94143 USA; [Stein, Anouk] M Dai, New York, NY USA; [Kitamura, Felipe C.] Univ Fed Sao Paulo, Dept Diagnost Imaging, Sao Paulo, Brazil; [Choudhary, Gagandeep] Univ Alabama Birmingham, Dept Radiol, Birmingham, AL USA; [Cala, Lesley] Univ Western Australia, Fac Hlth & Med Sci, Perth, WA, Australia; [Coelho, Luiz] Clin DAPI, Adv Diagnost Imaging, Curitiba, Parana, Brazil; [Mogensen, Monique] Univ Washington, Dept Radiol, Seattle, WA 98195 USA; [Moron, Fanny; Lincoln, Christie] Baylor Coll Med, Dept Radiol, Houston, TX 77030 USA; [Miller, Elka] Univ Ottawa, Dept Radiol, Ottawa, ON, Canada; [Ikuta, Ichiro; Zohrabian, Vahe] Yale Univ, Dept Radiol & Biomed Imaging, New Haven, CT USA; [McDonnell, Olivia] Gold Coast Univ Hosp, Dept Med Imaging, Southport, Qld, Australia; [Shah, Lubdha] Univ Utah, Hlth Sci Ctr, Dept Neuroradiol, Salt Lake City, UT USA; [Joyner, David] Univ Virginia Hlth, Dept Radiol & Med Imaging, Charlottesville, VA USA; [Agarwal, Amit] Univ Texas Southwestern Med Ctr Dallas, Div Neuroradiol, Dallas, TX 75390 USA; [Lee, Ryan K.] Albert Einstein Healthcare Network, Dept Radiol, Philadelphia, PA USA; [Nath, Jaya] Suny Downstate Med Ctr, Dept Radiol, Albany, NY USA		Flanders, AE (corresponding author), Thomas Jefferson Univ Hosp, Dept Radiol, Div Neuroradiol, 132 S Tenth St,Suite 1080B Main Bldg, Philadelphia, PA 19107 USA.	adam.flanders@jefferson.edu	Halabi, Safwan S/H-2279-2018; Miller, Elka/AAR-2991-2020; Ikuta, Ichiro/AAJ-7951-2020; Kitamura, Felipe Campos/AAC-4368-2021; Kitamura, Felipe Campos/AAC-7075-2021; Lee, Ryan/HCI-5836-2022	Halabi, Safwan S/0000-0003-1317-984X; Miller, Elka/0000-0003-1075-5952; Ikuta, Ichiro/0000-0002-7145-833X; Kitamura, Felipe Campos/0000-0002-9992-5630; Stein, Anouk/0000-0002-3066-7901; Oswood, Mark/0000-0002-9942-4094; Mongan, John/0000-0003-2765-7451; Prevedello, Luciano/0000-0002-6768-6452; Flanders, Adam/0000-0002-4679-0787; Kalpathy-Cramer, Jayashree/0000-0001-8906-9618; Lungren, Matthew/0000-0002-8591-5861; Shih, George/0000-0002-8356-2011				Chilamkurthy S, 2018, LANCET, V392, P2388, DOI 10.1016/S0140-6736(18)31645-3; Cordonnier C, 2018, LANCET, V392, P1257, DOI 10.1016/S0140-6736(18)31878-6; Dawud AM, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/4629859; Ginat DT, 2020, NEURORADIOLOGY, V62, P335, DOI 10.1007/s00234-019-02330-w; Kuo WC, 2019, P NATL ACAD SCI USA, V116, P22737, DOI 10.1073/pnas.1908021116; Majumdar Arjun, 2018, Annu Int Conf IEEE Eng Med Biol Soc, V2018, P583, DOI 10.1109/EMBC.2018.8512336; Prevedello LM, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180031; Shih G, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180041	8	57	57	0	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2020	2	3							e190211	10.1148/ryai.2020190211	http://dx.doi.org/10.1148/ryai.2020190211			7	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CW	33937827	Green Published, Bronze			2022-12-18	WOS:000826470300007
J	Chaganti, S; Grenier, P; Balachandran, A; Chabin, G; Cohen, S; Flohr, T; Georgescu, B; Grbic, S; Liu, SQ; Mellot, F; Murray, N; Nicolaou, S; Parker, W; Re, T; Sanelli, P; Sauter, AW; Xu, ZB; Yoo, YJ; Ziebandt, V; Comaniciu, D				Chaganti, Shikha; Grenier, Philippe; Balachandran, Abishek; Chabin, Guillaume; Cohen, Stuart; Flohr, Thomas; Georgescu, Bogdan; Grbic, Sasa; Liu, Siqi; Mellot, Francois; Murray, Nicolas; Nicolaou, Savvas; Parker, William; Re, Thomas; Sanelli, Pina; Sauter, Alexander W.; Xu, Zhoubing; Yoo, Youngjin; Ziebandt, Valentin; Comaniciu, Dorin			Automated Quantification of CT Patterns Associated with COVID-19 from Chest CT	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						66CT; Lung; Segmentation/Vision/Application Domain; Quantification/Vision/Application Domain; Supervised Learning; Reinforcement Learning		Purpose: To present a method that automatically segments and quantifies abnormal CT patterns commonly present in COVID-19, namely ground-glass opacities and consolidations. Materials and Methods: In this retrospective study, the proposed method takes as input a noncontrast chest CT and segments the lesions, lungs, and lobes in three dimensions, based on a dataset of 9749 chest CT volumes. The method outputs two combined measures of the severity of lung and lobe involvement, quantifying both the extent of COVID-19 abnormalities and presence of high opacities, based on deep learning and deep reinforcement learning. The first measure of (percentage of opacity, percentage of high opacity [PO, PHO]) is global, while the second of (lung severity score, lung high opacity score [LSS, LHOS]) is lobe-wise. Evaluation of the algorithm is reported on CT studies of 200 participants (100 COVID-19 confirmed patients and 100 healthy controls) from institutions from Canada, Europe, and the United States collected between 2002 and April 2020. Ground truth is established by manual annotations of lesions, lungs, and lobes. Correlation and regression analyses were performed to compare the prediction to the ground truth. Results: Pearson correlation coefficient between method prediction and ground truth for COVID-19 cases was calculated as 0.92 for PO (P<.001), 0.97 for PHO (P<.001), 0.91 for LSS (P<.001), and 0.90 for LHOS (P<.001). Ninety-eight of 100 healthy controls had a predicted PO of less than 1%; two had between 1% and 2%. Automated processing time to compute the severity scores was 10 seconds per case compared with 30 minutes required for manual annotations. Conclusion: A new method segments regions of CT abnormalities associated with COVID-19 and computes (PO, PHO), as well as (LSS, LHOS) severity scores. (C) RSNA, 2020	[Grenier, Philippe; Mellot, Francois] Hop Foch, Dept Clin Res & Innovat, Suresnes, France; [Cohen, Stuart; Sanelli, Pina] Northwell Hlth, Feinstein Inst Med Res, Donald & Barbara Zucker Sch Med, Manhasset, NY USA; [Balachandran, Abishek] Siemens Healthineers, Bangalore, Karnataka, India; [Flohr, Thomas; Ziebandt, Valentin] Siemens Healthineers, Forchheim, Germany; [Chaganti, Shikha; Georgescu, Bogdan; Grbic, Sasa; Liu, Siqi; Re, Thomas; Xu, Zhoubing; Yoo, Youngjin; Comaniciu, Dorin] Siemens Healthineers, 755 Coll Rd E, Princeton, NJ 08540 USA; [Chabin, Guillaume] Siemens Healthineers, Paris, France; [Sauter, Alexander W.] Univ Hosp Basel, Clin Radiol & Nucl Med, Basel, Switzerland; [Murray, Nicolas; Nicolaou, Savvas; Parker, William] Vancouver Gen Hosp, Dept Radiol, Vancouver, BC, Canada	Hospital Foch; Northwell Health; Siemens AG; Siemens AG; University of Basel; University of British Columbia	Chaganti, S (corresponding author), Siemens Healthineers, 755 Coll Rd E, Princeton, NJ 08540 USA.	shikha.chaganti@siemens-healthineers.com		grenier, philippe/0000-0003-3745-0032; cohen, stuart/0000-0003-1294-8002; Georgescu, Bogdan/0000-0001-5388-5699; Liu, Siqi/0000-0002-4169-7567; , Francois/0000-0002-5634-4764; Balachandran, Dr.Abishek/0000-0002-3726-7839	NHLBI [U01 HL089897, U01 HL089856]; COPD Foundation	NHLBI(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Heart Lung & Blood Institute (NHLBI)); COPD Foundation	We gratefully acknowledge the contributions of Clinica Universidad de Navarra, Health Time, Houston Methodist, and multiple other frontline hospitals to this collaboration. The authors also thank the COPDGene for providing the data. The COPDGene study (NCT00608764) was funded by NHLBI U01 HL089897 and U01 HL089856 and also supported by the COPD Foundation through contributions made to an Industry Advisory Committee composed of AstraZeneca, BoehringerIngelheim, GlaxoSmithKline, Novartis, and Sunovion. We thank many colleagues who made this work possible in a short amount of time. Special recognition to Christian Eusemann and Ahmed Halaweish for the great effort to ensure proper data de-identification and compliance with local regulations, to Dr. Vishwanath RS and Dr. Eileen Krieg for their valuable input on CT data and their annotations, to Brian Teixeira and Sebastien Piat, who were instrumental for implementing and managing the data infrastructure, and to Marlene Roblot, for her support with the manuscript editing.	Arroz SDE, 2009, COPDGENE, V1, P2; Bai HX, 2020, RADIOLOGY, V296, pE46, DOI 10.1148/radiol.2020200823; Centers for Disease Control and Prevention, 2020, CDC CLIN CRIT; Chung MS, 2020, EUR RADIOL, V30, P2182, DOI [10.1007/s00330-019-06574-1, 10.1148/radiol.2020200230]; CRESSIE N, 1984, J ROY STAT SOC B MET, V46, P440; Fang YC, 2020, RADIOLOGY, V296, pE115, DOI 10.1148/radiol.2020200432; Gatsonis CA, 2011, RADIOLOGY, V258, P243, DOI 10.1148/radiol.10091808; Ghesu FC, 2019, IEEE T PATTERN ANAL, V41, P176, DOI 10.1109/TPAMI.2017.2782687; Guan W, 2020, NEW ENGL J MED, V382, P1708, DOI 10.1056/NEJMoa2002032; Hosseiny M, 2020, AM J ROENTGENOL, V214, P1078, DOI 10.2214/AJR.20.22969; Inui Shohei, 2020, Radiol Cardiothorac Imaging, V2, pe204002, DOI [10.1148/ryct.2020200110, 10.1148/ryct.2020204002]; Johns Hopkins University, COR COVID 19 GLOB CA; Kanne Jeffrey P, 2020, Radiology, V296, pE113, DOI 10.1148/radiol.2020200527; Kim H, 2020, EUR RADIOL, V30, P3266, DOI 10.1007/s00330-020-06748-2; KNIGHT WR, 1966, J AM STAT ASSOC, V61, P436, DOI 10.2307/2282833; Pan F, 2020, RADIOLOGY, V295, P715, DOI 10.1148/radiol.2020200370; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Rubin GD, 2020, RADIOLOGY, V296, P172, DOI [10.1016/j.chest.2020.04.003, 10.1148/radiol.2020201365]; Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2; Wilson N, 2020, EMERG INFECT DIS, V26, P1339, DOI 10.3201/eid2606.200320; Xie XZ, 2020, RADIOLOGY, V296, pE41, DOI 10.1148/radiol.2020200343; Yang D, 2017, P INT C MED IM COMP, P507, DOI [10.1007/978-3-319-66179-7_58, DOI 10.1007/978-3-319-66179-758]; Yang Ran, 2020, Radiol Cardiothorac Imaging, V2, pe200047, DOI 10.1148/ryct.2020200047; Zhao W, 2020, AM J ROENTGENOL, V214, P1072, DOI 10.2214/AJR.20.22976; Zou LR, 2020, NEW ENGL J MED, V382, P1177, DOI 10.1056/NEJMc2001737	25	53	53	1	3	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2020	2	4							e200048	10.1148/ryai.2020200048	http://dx.doi.org/10.1148/ryai.2020200048			11	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CX	33928255	Green Submitted, Green Published			2022-12-18	WOS:000826472900010
J	Commandeur, F; Goeller, M; Razipour, A; Cadet, S; Hell, MM; Kwiecinski, J; Chen, X; Chang, HJ; Marwan, M; Achenbach, S; Berman, DS; Slomka, PJ; Tamarappoo, BK; Dey, D				Commandeur, Frederic; Goeller, Markus; Razipour, Aryabod; Cadet, Sebastien; Hell, Michaela M.; Kwiecinski, Jacek; Chen, Xi; Chang, Hyuk-Jae; Marwan, Mohamed; Achenbach, Stephan; Berman, Daniel S.; Slomka, Piotr J.; Tamarappoo, Balaji K.; Dey, Damini			Fully Automated CT Quantification of Epicardial Adipose Tissue by Deep Learning: A Multicenter Study	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To evaluate the performance of deep learning for robust and fully automated quantification of epicardial adipose tissue (EAT) from multicenter cardiac CT data. Materials and Methods: In this multicenter study, a convolutional neural network approach was trained to quantify EAT on non-contrast material-enhanced calcium-scoring CT scans from multiple cohorts, scanners, and protocols (n = 850). Deep learning performance was compared with the performance of three expert readers and with interobserver variability in a subset of 141 scans. The deep learning algorithm was incorporated into research software. Automated EAT progression was compared with expert measurements for 70 patients with baseline and follow-up scans. Results: Automated quantification was performed in a mean (6 standard deviation) time of 1.57 seconds 6 0.49, compared with 15 minutes for experts. Deep learning provided high agreement with expert manual quantification for all scans (R = 0.974; P < .001), with no significant bias (0.53 cm(3); P =.13). Manual EAT volumes measured by two experienced readers were highly correlated (R = 0.984; P < .001) but with a bias of 4.35 cm(3) (P < .001). Deep learning quantifications were highly correlated with the measurements of both experts (R = 0.973 and R = 0.979; P < .001), with significant bias for reader 1 (5.11 cm(3); P < .001) but not for reader 2 (0.88 cm(3); P = .26). EAT progression by deep learning correlated strongly with manual EAT progression (R = 0.905; P < .001) in 70 patients, with no significant bias (0.64 cm(3); P = .43), and was related to an increased noncalcified plaque burden quantified from coronary CT angiography (5.7% vs 1.8%; P = .026). Conclusion: Deep learning allows rapid, robust, and fully automated quantification of EAT from calcium scoring CT. It performs as well as an expert reader and can be implemented for routine cardiovascular risk assessment. (c) RSNA, 2019	[Commandeur, Frederic; Razipour, Aryabod; Dey, Damini] Cedars Sinai Med Ctr, Biomed Imajing Res Inst, 8700 Beverly Blvd,Taper A238, Los Angeles, CA 90048 USA; [Cadet, Sebastien; Kwiecinski, Jacek; Chen, Xi; Berman, Daniel S.; Slomka, Piotr J.; Tamarappoo, Balaji K.] Cedars Sinai Med Ctr, Dept Imajing & Med, 8700 Beverly Blvd,Taper A238, Los Angeles, CA 90048 USA; [Goeller, Markus; Hell, Michaela M.; Marwan, Mohamed; Achenbach, Stephan] Friedrich Alexander Univ Erlangen Nurnberg, Dept Cardiol, Erlangen, Germany; [Chang, Hyuk-Jae] Yonsei Univ, Severance Cardiovasc Hosp, Coll Med, Seoul, South Korea		Dey, D (corresponding author), Cedars Sinai Med Ctr, Biomed Imajing Res Inst, 8700 Beverly Blvd,Taper A238, Los Angeles, CA 90048 USA.	Damini.Dey@cshs.org		Chen, Xi/0000-0003-3855-2591; Chang, Hyuk-Jae/0000-0002-6139-7545				Abazid RM, 2017, J THORAC IMAG, V32, P378, DOI 10.1097/RTI.0000000000000296; Barbosa JG, 2011, COMPUT METHOD BIOMEC, V14, P905, DOI 10.1080/10255842.2010.499871; Cheng VY, 2010, JACC-CARDIOVASC IMAG, V3, P352, DOI 10.1016/j.jcmg.2009.12.013; Commandeur F, 2018, IEEE T MED IMAGING, V37, P1835, DOI 10.1109/TMI.2018.2804799; Dey D, 2010, ATHEROSCLEROSIS, V209, P136, DOI 10.1016/j.atherosclerosis.2009.08.032; DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409; Ding XW, 2015, MED PHYS, V42, P5015, DOI 10.1118/1.4927375; Glorot X., 2010, PROC MACH LEARN RES, P249; Goeller M, 2019, EUR HEART J-CARD IMG, V20, P636, DOI 10.1093/ehjci/jez013; Goeller M, 2018, J CARDIOVASC COMPUT, V12, P67, DOI 10.1016/j.jcct.2017.11.007; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hwang IC, 2017, J ATHEROSCLER THROMB, V24, P262, DOI 10.5551/jat.36467; Jones E., 2001, SCIPY OPEN SOURCE SC; Kingma DP, ARXIV 14126980 PREPR; Mahabadi AA, 2014, EUR HEART J-CARD IMG, V15, P863, DOI 10.1093/ehjci/jeu006; Mazurek T, 2003, CIRCULATION, V108, P2460, DOI 10.1161/01.CIR.0000099542.57313.C5; Mortazi A, 2018, LECT NOTES COMPUT SC, V10663, P199, DOI 10.1007/978-3-319-75541-0_21; Nakagawa S, 2017, J R SOC INTERFACE, V14, DOI 10.1098/rsif.2017.0213; Nakazato R, 2011, J CARDIOVASC COMPUT, V5, P172, DOI 10.1016/j.jcct.2011.03.009; Norlen A, 2016, J MED IMAGING, V3, DOI 10.1117/1.JMI.3.3.034003; Rajani R, 2013, J CARDIOVASC COMPUT, V7, P125, DOI 10.1016/j.jcct.2013.02.003; Rozanski A, 2011, J AM COLL CARDIOL, V57, P1622, DOI 10.1016/j.jacc.2011.01.019; Sacks HS, 2007, AM HEART J, V153, P907, DOI 10.1016/j.ahj.2007.03.019; Shahzad R, 2013, MED PHYS, V40, DOI 10.1118/1.4817577; Tamarappoo B, 2018, J CARDIOVASC COMPUT, V12, P385, DOI 10.1016/j.jcct.2018.05.004; Tamarappoo B, 2010, JACC-CARDIOVASC IMAG, V3, P1104, DOI 10.1016/j.jcmg.2010.07.014	26	52	55	0	2	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2019	1	6							e190045	10.1148/ryai.2019190045	http://dx.doi.org/10.1148/ryai.2019190045			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CQ	32090206	Bronze, Green Published, Green Accepted			2022-12-18	WOS:000826296100005
J	Langlotz, CP				Langlotz, Curtis P.			Will Artificial Intelligence Replace Radiologists?	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material							MAMMOGRAPHY; DIAGNOSIS		[Langlotz, Curtis P.] Stanford Univ, Dept Radiol, 300 Pasteur Dr,Room H1330D, Stanford, CA 94305 USA	Stanford University	Langlotz, CP (corresponding author), Stanford Univ, Dept Radiol, 300 Pasteur Dr,Room H1330D, Stanford, CA 94305 USA.	langlotz@stanford.edu		Langlotz, Curtis/0000-0002-8972-8051				AIWinter, US; [Anonymous], ECONOMIST; BANKOWITZ RA, 1989, ANN INTERN MED, V110, P824, DOI 10.7326/0003-4819-110-10-824; Beam CA, 1996, ARCH INTERN MED, V156, P209, DOI 10.1001/archinte.156.2.209; Bessen J., 2015, LEARNING DOING REAL; Bien N, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002699; Budovec JJ, 2014, RADIOGRAPHICS, V34, P254, DOI 10.1148/rg.341135036; Chokshi FH, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019190021; Choy G, 2018, RADIOLOGY, V288, P318, DOI 10.1148/radiol.2018171820; Fenton JJ, 2010, ARCH INTERN MED, V170, P987, DOI 10.1001/archinternmed.2010.104; Hinton G., RADIOLOGY; Hinton G, 2018, JAMA-J AM MED ASSOC, V320, P1101, DOI 10.1001/jama.2018.11100; Krupinski E, 2019, ACAD RADIOL, V26, P579, DOI 10.1016/j.acra.2018.11.017; Lakhani P, 2017, RADIOLOGY, V284, P574, DOI 10.1148/radiol.2017162326; Langlotz CP., 2015, RADIOLOGY REPORT GUI; Langlotz Curtis P, 2009, J Am Coll Radiol, V6, P861, DOI 10.1016/j.jacr.2009.09.015; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Lehman CD, 2015, JAMA INTERN MED, V175, P1828, DOI 10.1001/jamainternmed.2015.5231; Meeker M., INTERNET TRENDS REPO; Morelli JN, 2011, RADIOGRAPHICS, V31, P849, DOI 10.1148/rg.313105115; Nishikawa RM, 2018, J AM COLL RADIOL, V15, P49, DOI 10.1016/j.jacr.2017.08.027; Obermeyer Z, 2016, NEW ENGL J MED, V375, P1216, DOI 10.1056/NEJMp1606181; Rajpurkar P, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002686; Russell S, 2015, AI MAG, V36, P105, DOI 10.1609/aimag.v36i4.2577; Susskind Richard E., 2016, HARVARD BUS REV	25	51	52	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2019	1	3							e190058	10.1148/ryai.2019190058	http://dx.doi.org/10.1148/ryai.2019190058			3	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CN	33937794	Green Published			2022-12-18	WOS:000826290100005
J	Vorontsov, E; Cerny, M; Regnier, P; Di Jorio, L; Pal, CJ; Lapointe, R; Vandenbroucke-Menu, F; Turcotte, S; Kadoury, S; Tang, A				Vorontsov, Eugene; Cerny, Milena; Regnier, Philippe; Di Jorio, Lisa; Pal, Christopher J.; Lapointe, Real; Vandenbroucke-Menu, Franck; Turcotte, Simon; Kadoury, Samuel; Tang, An			Deep Learning for Automated Segmentation of Liver Lesions at CT in Patients with Colorectal Cancer Liver Metastases	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To evaluate the performance, agreement, and efficiency of a fully convolutional network (FCN) for liver lesion detection and segmentation at CT examinations in patients with colorectal liver metastases (CLMs). Materials and Methods: This retrospective study evaluated an automated method using an FCN that was trained, validated, and tested with 115, 15, and 26 contrast material-enhanced CT examinations containing 261, 22, and 105 lesions, respectively. Manual detection and segmentation by a radiologist was the reference standard. Performance of fully automated and user-corrected segmentations was compared with that of manual segmentations. The interuser agreement and interaction time of manual and user-corrected segmentations were assessed. Analyses included sensitivity and positive predictive value of detection, segmentation accuracy, Cohen kappa, Bland-Altman analyses, and analysis of variance. Results: In the test cohort, for lesion size smaller than 10 mm (n = 30), 10-20 mm (n = 35), and larger than 20 mm (n = 40), the detection sensitivity of the automated method was 10%, 71%, and 85%; positive predictive value was 25%, 83%, and 94%; Dice similarity coefficient was 0.14, 0.53, and 0.68; maximum symmetric surface distance was 5.2, 6.0, and 10.4 mm; and average symmetric surface distance was 2.7, 1.7, and 2.8 mm, respectively. For manual and user-corrected segmentation, k values were 0.42 (95% confidence interval: 0.24, 0.63) and 0.52 (95% confidence interval: 0.36, 0.72); normalized interreader agreement for lesion volume was -0.10 +/- 0.07 (95% confidence interval) and -0.10 +/- 0.08; and mean interaction time was 7.7 minutes +/- 2.4 (standard deviation) and 4.8 minutes +/- 2.1 (P <.001), respectively. Conclusion: Automated detection and segmentation of CLM by using deep learning with convolutional neural networks, when manually corrected, improved efficiency but did not substantially change agreement on volumetric measurements. (C) RSNA, 2019	[Cerny, Milena; Tang, An] Ctr Hosp Univ Montreal CHUM, Dept Radiol, 1000 Rue St Denis, Montreal, PQ H2X 0C2, Canada; [Lapointe, Real; Vandenbroucke-Menu, Franck; Turcotte, Simon] Ctr Hosp Univ Montreal CHUM, Dept Surg, Hepatopancreatobiliary & Liver Transplantat Div, 1000 Rue St Denis, Montreal, PQ H2X 0C2, Canada; [Vorontsov, Eugene; Pal, Christopher J.] Montreal Inst Learning Algorithms MILA, Montreal, PQ, Canada; [Vorontsov, Eugene; Pal, Christopher J.; Kadoury, Samuel] Ecole Polytech, Montreal, PQ, Canada; [Cerny, Milena; Regnier, Philippe; Turcotte, Simon; Kadoury, Samuel; Tang, An] Ctr Rech Ctr Hosp Univ Montreal CRCHUM, Montreal, PQ, Canada; [Di Jorio, Lisa] Imagia Cybernet, Montreal, PQ, Canada		Tang, A (corresponding author), Ctr Hosp Univ Montreal CHUM, Dept Radiol, 1000 Rue St Denis, Montreal, PQ H2X 0C2, Canada.; Tang, A (corresponding author), Ctr Rech Ctr Hosp Univ Montreal CRCHUM, Montreal, PQ, Canada.	an.tang@umontreal.ca	; Tang, An/E-5333-2016	Cerny, Milena/0000-0001-5033-7507; Tang, An/0000-0001-8967-5503	Canada Research Chair in Medical Imaging and Assisted Interventions [950-228359]; Fondation de l'Association des Radiologistes du Quebec; Fonds de Recherche du Quebec-Sante [34939]; Roger Des Groseillers Hepato-Pancreatico-Biliary Surgical Oncology Research Chair; Natural Sciences and Engineering Research Council of Canada; PREMIER Internship Award - Institut du Cancer de Montreal; MEDTEQ; Polytechnique Montreal; MITACS-Cluster Accelerate [IT05356]; Imagia	Canada Research Chair in Medical Imaging and Assisted Interventions; Fondation de l'Association des Radiologistes du Quebec; Fonds de Recherche du Quebec-Sante(Fonds de la Recherche en Sante du Quebec); Roger Des Groseillers Hepato-Pancreatico-Biliary Surgical Oncology Research Chair; Natural Sciences and Engineering Research Council of Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)CGIAR); PREMIER Internship Award - Institut du Cancer de Montreal; MEDTEQ; Polytechnique Montreal; MITACS-Cluster Accelerate; Imagia	S.K. supported by The Canada Research Chair in Medical Imaging and Assisted Interventions (950-228359). A.T. supported by Fondation de l'Association des Radiologistes du Quebec and Fonds de Recherche du Quebec-Sante (34939). S.T. supported by Roger Des Groseillers Hepato-Pancreatico-Biliary Surgical Oncology Research Chair. E.V. supported by Natural Sciences and Engineering Research Council of Canada. P.R. supported by PREMIER (previously COPSE) Internship Award sponsored by the Institut du Cancer de Montreal. Study supported by Imagia (co-funding to MEDTEQ operating grant), MEDTEQ, Polytechnique Montreal, and MITACS-Cluster Accelerate (IT05356).	Adam R, 2015, CANCER TREAT REV, V41, P729, DOI 10.1016/j.ctrv.2015.06.006; Albrecht MH, 2014, EUR J RADIOL, V83, P1752, DOI 10.1016/j.ejrad.2014.07.005; Ben-Cohen A, 2016, LECT NOTES COMPUT SC, V10008, P77, DOI 10.1007/978-3-319-46976-8_9; Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505; Chartrand G, 2017, RADIOGRAPHICS, V37, P2113, DOI 10.1148/rg.2017170077; Chartrand G, 2017, IEEE T BIO-MED ENG, V64, P2110, DOI 10.1109/TBME.2016.2631139; Christ PF, ARXIV 170205970; ctrnet, CANADIAN TISSUE REPO; De Vries H, 2008, FIELD METHOD, V20, P272, DOI 10.1177/1525822X08317166; Donadon Matteo, 2007, Gastrointest Cancer Res, V1, P20; Eisenhauer EA, 2009, EUR J CANCER, V45, P228, DOI 10.1016/j.ejca.2008.10.026; Ferlay J, 2015, INT J CANCER, V136, pE359, DOI 10.1002/ijc.29210; Gallagher DJ, 2010, ONCOLOGY-BASEL, V78, P237, DOI 10.1159/000315730; Gotra A, 2017, INSIGHTS IMAGING, V8, P377, DOI 10.1007/s13244-017-0558-1; Gotra A, 2015, ACAD RADIOL, V22, P1088, DOI 10.1016/j.acra.2015.03.010; He K, ARXIV 170306870; Hwang M, 2014, EUR J CANCER, V50, P1747, DOI 10.1016/j.ejca.2014.03.277; Imai K, 2016, ONCOLOGIST, V21, P887, DOI 10.1634/theoncologist.2015-0468; insight, MIDAS LIVER TUMOR DA; IRCAD France, 3DIRCADB DAT RES I D; Ko Y, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0189797; Li W, 2015, J COMPUT COMMUN, V3, P146, DOI [DOI 10.4236/JCC.2015.311023, 10.4236/jcc.2015.311023,03]; Linguraru MG, 2012, IEEE T MED IMAGING, V31, P1965, DOI 10.1109/TMI.2012.2211887; Litjens G., ARXIV170205747; LiTS, LIV TUM SEGM CHALL; Mantatzis M, 2009, EUR RADIOL, V19, P1809, DOI 10.1007/s00330-009-1327-4; mitk, MED IMAGING INTERACT; Moghbel M, 2018, ARTIF INTELL REV, V50, P497, DOI 10.1007/s10462-017-9550-x; Moghbel M, 2016, EXCLI J, V15, P406, DOI 10.17179/excli2016-402; Niekel MC, 2010, RADIOLOGY, V257, P674, DOI 10.1148/radiol.10100729; Norman B, 2018, RADIOLOGY, V288, P177, DOI 10.1148/radiol.2018172322; Odland A, 2015, ACTA RADIOL, V56, P1396, DOI 10.1177/0284185114554822; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Rothe JH, 2013, EUR J RADIOL, V82, P1831, DOI 10.1016/j.ejrad.2012.05.018; Schwarz RE, 2013, HPB, V15, P89, DOI 10.1111/j.1477-2574.2012.00569.x; Siegel R, 2012, CA-CANCER J CLIN, V62, P220, DOI 10.3322/caac.21149; Siegel RL, 2017, CA-CANCER J CLIN, V67, P177, DOI 10.3322/caac.21395; Silverman Paul M, 2006, Cancer Imaging, V6, P175, DOI 10.1102/1470-7330.2006.0024; Sliver'07, DAT MED IM COMP COMP; TCIA, 2016, CANC IM ARCH FRED NA; Tirumani SH, 2014, RADIOGRAPHICS, V34, P1908, DOI 10.1148/rg.347130090; Tomlinson JS, 2007, J CLIN ONCOL, V25, P4575, DOI 10.1200/JCO.2007.11.0833; Udupa JK, 2006, COMPUT MED IMAG GRAP, V30, P75, DOI 10.1016/j.compmedimag.2005.12.001; van Erkel AR, 2002, RADIOLOGY, V224, P404, DOI 10.1148/radiol.2242011322; Vorontsov E, 2018, I S BIOMED IMAGING, P1332; Yasaka K, 2018, RADIOLOGY, V286, P899, DOI 10.1148/radiol.2017170706; Zou GY, 2013, STAT METHODS MED RES, V22, P630, DOI 10.1177/0962280211402548	48	47	47	0	2	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2019	1	2							e180014	10.1148/ryai.2019180014	http://dx.doi.org/10.1148/ryai.2019180014			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CM	33937787	Green Published			2022-12-18	WOS:000826288900002
J	Prevedello, LM; Halabi, SS; Shih, G; Wu, CC; Kohli, MD; Chokshi, FH; Erickson, BJ; Kalpathy-Cramer, J; Andriole, KP; Flanders, AE				Prevedello, Luciano M.; Halabi, Safwan S.; Shih, George; Wu, Carol C.; Kohli, Marc D.; Chokshi, Falgun H.; Erickson, Bradley J.; Kalpathy-Cramer, Jayashree; Andriole, Katherine P.; Flanders, Adam E.			Challenges Related of Artificial Intelligence Research in Medical Imaging and the Importance of Image Analysis Competitions	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								In recent years, there has been enormous interest in applying artificial intelligence (AI) to radiology. Although some of this interest may have been driven by exaggerated expectations that the technology can outperform radiologists in some tasks, there is a growing body of evidence that illustrates its limitations in medical imaging. The true potential of the technique probably lies somewhere in the middle, and AI will ultimately play a key role in medical imaging in the future. The limitless power of computers makes AI an ideal candidate to provide the standardization, consistency, and dependability needed to support radiologists in their mission to provide excellent patient care. However, important roadblocks currently limit the expansion of this field in medical imaging. This article reviews some of the challenges and potential solutions to advance the field forward, with focus on the experience gained by hosting image-based competitions.	[Prevedello, Luciano M.] Ohio State Univ, Wexner Med Ctr, Dept Radiol, 395 West 12th Ave,4th Floor,Room 422, Columbus, OH 43210 USA; [Halabi, Safwan S.] Stanford Univ, Dept Radiol, Sch Med, Stanford, CA 94305 USA; [Shih, George] Weill Cornell Med Coll, Dept Radiol, New York, NY USA; [Wu, Carol C.] Univ Texas MD Anderson Canc Ctr, Dept Diagnost Lab, Houston, TX 77030 USA; [Kohli, Marc D.] Univ Calif San Francisco, Dept Radiol & Biomed Imaging, San Francisco, CA 94143 USA; [Chokshi, Falgun H.] Emory Univ, Sch Med, Dept Radiol & Imaging Sci, Atlanta, GA USA; [Erickson, Bradley J.] Mayo Clin, Dept Radiol, Rochester, MN USA; [Kalpathy-Cramer, Jayashree] Massachusetts Gen Hosp, Dept Radiol, Charlestown, MA USA; [Kalpathy-Cramer, Jayashree] Massachusetts Gen Hosp, Athinoula A Martinos Ctr Biomed Imaging, Charlestown, MA USA; [Kalpathy-Cramer, Jayashree] Harvard Med Sch, Charlestown, MA USA; [Andriole, Katherine P.] Massachusetts Gen Hosp, Brigham & Womens Hosp, Dept Radiol, Boston, MA 02114 USA; [Andriole, Katherine P.] BWH Ctr Clin Data Sci, Boston, MA 02114 USA; [Flanders, Adam E.] Thomas Jefferson Univ Hosp, Dept Radiol, Philadelphia, PA 19107 USA		Prevedello, LM (corresponding author), Ohio State Univ, Wexner Med Ctr, Dept Radiol, 395 West 12th Ave,4th Floor,Room 422, Columbus, OH 43210 USA.	Luciano.Prevedello@osumc.edu	; Halabi, Safwan/H-2279-2018	Shih, George/0000-0002-8356-2011; Halabi, Safwan/0000-0003-1317-984X; Prevedello, Luciano/0000-0002-6768-6452; Flanders, Adam/0000-0002-4679-0787; Kalpathy-Cramer, Jayashree/0000-0001-8906-9618	NIH [U01CA154601, U24CA180927, U24CA180918]; Leidos	NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Leidos	disclosed no relevant relationships. S.S.H. disclosed no relevant relationships. G.S. Activities related to the present article: disclosed no relevant relationships. Activities not related to the present article: board member and shareholder of MD.ai. Other relationships: disclosed no relevant relationships. C.C.W. disclosed no relevant relationships. M.D.K. Activities related to the present article: disclosed no relevant relationships. Activities not related to the present article: received travel reimbursement for board meetings from SIIM; consultant for Medical Sciences Corporation, consultant for National Library of Medicine; received ACR Innovation grant for development of LI-RADS integration with dictation products; gave one paid lecture at Gilead campus to staff regarding big data, machine learning, and imaging; received funds for travel for committee meetings from RSNA and SIIM. Other relationships: disclosed no relevant relationships. F.H.C. disclosed no relevant relationships. B.J.E. disclosed no relevant relationships. J.K. Activities related to the present article: supported by the following NIH grants U01CA154601 (NIH/NCI), U24CA180927 (NIH/NCI), U24CA180918 (NIH/NCI); supported by contract from Leidos. Activities not related to the present article: consultant for INFOTECH, Soft. Other relationships: disclosed no relevant relationships. K.P.A. Activities related to the present article: disclosed no relevant relationships. Activities not related to the present article: consultant for McKinsey & Company; on RSNA Radiology Informatics Committee and Machine Learning and Standards Subcommittees; Senior Scientist for education at ACR Data Science Institute; Director of Research Strategy and Operations at the MGH and BWH Center for Clinical Data Science, which is funded in part by monies and resources from NVIDIA, GE, and Nuance; associate editor for Radiology: Artificial Intelligence and Journal of Medical Imaging. Other relationships: disclosed no relevant relationships. A.E.F. disclosed no relevant relationships.	Brownson RC, 2006, PUBLIC HEALTH REP, V121, P97, DOI 10.1177/003335490612100118; Caffe, CAFFE DEEP LEARNING; chainer, CHAINER FLEXIBLE FRA; Chang K, 2018, J AM MED INFORM ASSN, V25, P945, DOI 10.1093/jamia/ocy017; Cheng PM, 2018, ABDOM RADIOL, V43, P1120, DOI 10.1007/s00261-017-1294-1; Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dhara AK, 2017, J DIGIT IMAGING, V30, P63, DOI 10.1007/s10278-016-9904-y; Freymann JB, 2012, J DIGIT IMAGING, V25, P14, DOI 10.1007/s10278-011-9422-x; Gershgorn D, DATA TRANSFORMED RES; Halabi SS, 2019, RADIOLOGY, V290, P498, DOI 10.1148/radiol.2018180736; Hoang JK, 2018, AM J ROENTGENOL, V211, P162, DOI 10.2214/AJR.17.19192; Huda W, 2015, AM J ROENTGENOL, V204, pW393, DOI 10.2214/AJR.14.13126; Huh M, 2016, ARXIV160808614 CS; image-net, IMAGENET LARGE SCALE; kaggle, 2017, DATASCIENCE BOWL; kaggle, RSNA PNEUMONIA DETEC; keras, HOME KERAS DOCUMENTA; Kim DH, 2018, CLIN RADIOL, V73, P439, DOI 10.1016/j.crad.2017.11.015; Larson DB, 2018, RADIOLOGY, V287, P313, DOI 10.1148/radiol.2017170236; Lim HK, 2013, AM J NEURORADIOL, V34, P747, DOI 10.3174/ajnr.A3293; Maier-Hein L, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-07619-7; Mazura JC, 2012, J DIGIT IMAGING, V25, P347, DOI 10.1007/s10278-011-9429-3; Monteiro E, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0736-1; mxnet.apache, US; PyTorch, US; Rajpurkar P, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002686; Reinke A, 2018, LECT NOTES COMPUT SC, V11073, P388, DOI 10.1007/978-3-030-00937-3_45; Ren XH, 2019, IEEE J BIOMED HEALTH, V23, P2030, DOI 10.1109/JBHI.2018.2876916; Ribeiro E, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/6584725; Rolnick D., 2017, ARXIV170510694; rsnachallenges, RSNA PEDIAT BONE AGE; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Shen QJ, 2018, EUR RADIOL, V28, P4389, DOI 10.1007/s00330-018-5364-8; Shih G, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180041; Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302; TensorFlow, TENSORFLOW; toolbox.google, DATASET SEARCH; Wang X., 2017, PROC CVPR IEEE, P2097; WIDROW B, 1994, COMMUN ACM, V37, P93, DOI 10.1145/175247.175257; Winklhofer S, 2017, EUR SPINE J, V26, P353, DOI 10.1007/s00586-016-4667-1; Yan K, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.3.036501	42	47	47	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2019	1	1							e180031	10.1148/ryai.2019180031	http://dx.doi.org/10.1148/ryai.2019180031			7	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CL	33937783	Green Published			2022-12-18	WOS:000826287700004
J	Liu, F; Guan, BC; Zhou, ZY; Samsonov, A; Rosas, H; Lian, K; Sharma, R; Kanarek, A; Kim, J; Guermazi, A; Kijowski, R				Liu, Fang; Guan, Bochen; Zhou, Zhaoye; Samsonov, Alexey; Rosas, Humberto; Lian, Kevin; Sharma, Ruchi; Kanarek, Andrew; Kim, John; Guermazi, Ali; Kijowski, Richard			Fully Automated Diagnosis of Anterior Cruciate Ligament Tears on Knee MR Images by Using Deep Learning	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							CLASSIFICATION	Purpose: To investigate the feasibility of using a deep learning-based approach to detect an anterior cruciate ligament (ACL) tear within the knee joint at MRI by using arthroscopy as the reference standard. Materials and Methods: A fully automated deep learning-based diagnosis system was developed by using two deep convolutional neural networks (CNNs) to isolate the ACL on MR images followed by a classification CNN to detect structural abnormalities within the isolated ligament. With institutional review board approval, sagittal proton density-weighted and fat-suppressed T2-weighted fast spinecho MR images of the knee in 175 subjects with a full-thickness ACL tear (98 male subjects and 77 female subjects; average age, 27.5 years) and 175 subjects with an intact ACL (100 male subjects and 75 female subjects; average age, 39.4 years) were retrospectively analyzed by using the deep learning approach. Sensitivity and specificity of the ACL tear detection system and five clinical radiologists for detecting an ACL tear were determined by using arthroscopic results as the reference standard. Receiver operating characteristic (ROC) analysis and two-sided exact binomial tests were used to further assess diagnostic performance. Results: The sensitivity and specificity of the ACL tear detection system at the optimal threshold were 0.96 and 0.96, respectively. In comparison, the sensitivity of the clinical radiologists ranged between 0.96 and 0.98, while the specificity ranged between 0.90 and 0.98. There was no statistically significant difference in diagnostic performance between the ACL tear detection system and clinical radiologists at P <.05. The area under the ROC curve for the ACL tear detection system was 0.98, indicating high overall diagnostic accuracy. Conclusion: There was no significant difference between the diagnostic performance of the ACL tear detection system and clinical radiologists for determining the presence or absence of an ACL tear at MRI. (C) RSNA, 2019	[Liu, Fang; Guan, Bochen; Samsonov, Alexey; Rosas, Humberto; Lian, Kevin; Sharma, Ruchi; Kanarek, Andrew; Kim, John; Kijowski, Richard] Univ Wisconsin, Sch Med & Publ Hlth, Dept Radiolou, 600 Highland Ave, Madison, WI 53705 USA; [Guan, Bochen] Univ Wisconsin, Sch Engn, Dept Elect & Comp Engn, Madison, WI 53705 USA; [Zhou, Zhaoye] Univ Minnesota, Dept Biomed Engn, Minneapolis, MN USA; [Guermazi, Ali] Boston Univ, Sch Med, Dept Radiol, Boston, MA 02118 USA	University of Wisconsin System; University of Wisconsin Madison; University of Wisconsin System; University of Wisconsin Madison; University of Minnesota System; University of Minnesota Twin Cities; Boston University	Liu, F (corresponding author), Univ Wisconsin, Sch Med & Publ Hlth, Dept Radiolou, 600 Highland Ave, Madison, WI 53705 USA.	fliu37@wisc.edu	Guan, Bochen/AAD-6431-2020; Liu, Fang/Q-5681-2018	Liu, Fang/0000-0001-8032-6681; Guermazi, Ali/0000-0002-9374-8266	National Institute of Arthritis and Musculoskeletal and Skin Diseases [R01-AR068373]; National Institutes of Health [R01EB027087]	National Institute of Arthritis and Musculoskeletal and Skin Diseases(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Arthritis & Musculoskeletal & Skin Diseases (NIAMS)); National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	Funding support for the research project was provided by the National Institute of Arthritis and Musculoskeletal and Skin Diseases (R01-AR068373) and by the National Institutes of Health (R01EB027087).	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865; Arevalo J, 2016, COMPUT METH PROG BIO, V127, P248, DOI 10.1016/j.cmpb.2015.12.014; Bien N, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002699; Chen F, 2018, RADIOLOGY, V289, P366, DOI 10.1148/radiol.2018180445; Cicero M, 2017, INVEST RADIOL, V52, P281, DOI 10.1097/RLI.0000000000000341; Ciompi F, 2015, MED IMAGE ANAL, V26, P195, DOI 10.1016/j.media.2015.08.001; De Fauw J.S, NATMED2018, V24, P1342; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; Fluss R, 2005, BIOMETRICAL J, V47, P458, DOI 10.1002/bimj.200410135; G.Tofighi, 2016, bioRxiv, DOI 10.1101/070441; Gianotti SM, 2009, J SCI MED SPORT, V12, P622, DOI 10.1016/j.jsams.2008.07.005; Huang G, ARXIV 160806993 PREP; Kooi T, 2017, MED IMAGE ANAL, V35, P303, DOI 10.1016/j.media.2016.07.007; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Lakhani P, 2017, RADIOLOGY, V284, P574, DOI 10.1148/radiol.2017162326; LeCun Y., 1995, Neural Networks: The Statistical Mechanics Perspective. Proceedings of the CTP-PBSRI. Joint Workshop on Theoretical Physics, P261; LEE JK, 1988, RADIOLOGY, V166, P861, DOI 10.1148/radiology.166.3.3340785; Liu F, 2019, MAGN RESON MED, V81, P3330, DOI 10.1002/mrm.27627; Liu F, 2018, RADIOLOGY, V289, P160, DOI 10.1148/radiol.2018172986; Liu F, 2018, MAGN RESON MED, V79, P2379, DOI 10.1002/mrm.26841; Liu F, 2018, RADIOLOGY, V286, P676, DOI 10.1148/radiol.2017170700; Malon Christopher D, 2013, J Pathol Inform, V4, P9, DOI 10.4103/2153-3539.112694; MCCAULEY TR, 1994, AM J ROENTGENOL, V162, P115, DOI 10.2214/ajr.162.1.8273648; Norman B, 2018, RADIOLOGY, V288, P177, DOI 10.1148/radiol.2018172322; Pedoia V, 2019, J MAGN RESON IMAGING, V49, P400, DOI 10.1002/jmri.26246; Redmon J., ARXIV 150602640 PREP; Richardson ML, 2011, ACAD RADIOL, V18, P1376, DOI 10.1016/j.acra.2011.06.014; ROBERTSON PL, 1994, RADIOLOGY, V193, P829, DOI 10.1148/radiology.193.3.7972833; Russakovsky O., ARXIV 14090575 PREPR; Setio AAA, 2016, IEEE T MED IMAGING, V35, P1160, DOI 10.1109/TMI.2016.2536809; Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI 10.1146/annurev-bioeng-071516-044442; VAHEY TN, 1991, RADIOLOGY, V181, P251, DOI 10.1148/radiology.181.1.1887042; Van Dyck P, 2011, SKELETAL RADIOL, V40, P701, DOI 10.1007/s00256-010-1044-8; Zhou B., ARXIV 151204150 PREP; Zhou ZY, 2018, MAGN RESON MED, V80, P2759, DOI 10.1002/mrm.27229; Zhu B, 2018, NATURE, V555, P487, DOI 10.1038/nature25988	37	43	47	1	6	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2019	1	3							e180091	10.1148/ryai.2019180091	http://dx.doi.org/10.1148/ryai.2019180091			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CN	32076658	Green Published			2022-12-18	WOS:000826290100004
J	Liu, K; Li, Q; Ma, JC; Zhou, ZJ; Sun, MM; Deng, YF; Tu, WT; Wang, Y; Fan, L; Xia, C; Xiao, Y; Zhang, RG; Liu, SY				Liu, Kai; Li, Qiong; Ma, Jiechao; Zhou, Zijian; Sun, Mengmeng; Deng, Yufeng; Tu, Wenting; Wang, Yun; Fan, Li; Xia, Chen; Xiao, Yi; Zhang, Rongguo; Liu, Shiyuan			Evaluating a Fully Automated Pulmonary Nodule Detection Approach and Its Impact on Radiologist Performance	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							COMPUTED-TOMOGRAPHY IMAGES; LUNG-CANCER; AIDED DETECTION; CT; MANAGEMENT	Purpose: To compare sensitivity in the detection of lung nodules between the deep learning (DL) model and radiologists using various patient population and scanning parameters and to assess whether the radiologists' detection performance could be enhanced when using the DL model for assistance. Materials and Methods: A total of 12 754 thin-section chest CT scans from January 2012 to June 2017 were retrospectively collected for DL model training, validation, and testing. Pulmonary nodules from these scans were categorized into four types: solid, subsolid, calcified, and pleural. The testing dataset was divided into three cohorts based on radiation dose, patient age, and CT manufacturer. Detection performance of the DL model was analyzed by using a free-response receiver operating characteristic curve. Sensitivities of the DL model and radiologists were compared by using exploratory data analysis. False-positive detection rates of the DL model were compared within each cohort. Detection performance of the same radiologist with and without the DL model were compared by using nodule-level sensitivity and patient-level localization receiver operating characteristic curves. Results: The DL model showed elevated overall sensitivity compared with manual review of pulmonary nodules. No significant dependence regarding radiation dose, patient age range, or CT manufacturer was observed. The sensitivity of the junior radiologist was significantly dependent on patient age. When radiologists used the DL model for assistance, their performance improved and reading time was reduced. Conclusion: DL shows promise to enhance the identification of pulmonary nodules and benefit nodule management. (C) RSNA, 2019	[Liu, Kai; Li, Qiong; Tu, Wenting; Wang, Yun; Fan, Li; Xiao, Yi; Liu, Shiyuan] Second Mil Med Univ, Changzheng Hosp, Dept Radiol, 415 Fengyang Rd, Shanghai 20003, Peoples R China; [Ma, Jiechao; Zhou, Zijian; Sun, Mengmeng; Deng, Yufeng; Xia, Chen; Zhang, Rongguo] Infervis Adv Inst, Beijing, Peoples R China	Naval Medical University	Liu, SY (corresponding author), Second Mil Med Univ, Changzheng Hosp, Dept Radiol, 415 Fengyang Rd, Shanghai 20003, Peoples R China.	cjr.liushiyuan@vip.163.com		Tu, Wenting/0000-0003-1010-7189; Ma, Jiechao/0000-0001-6502-4140; Deng, Yufeng/0000-0003-2153-8494; Zhou, Zijian/0000-0001-8917-7387				Aberle DR, 2011, NEW ENGL J MED, V365, P395, DOI 10.1056/NEJMoa1102873; Arimura H, 2004, ACAD RADIOL, V11, P617, DOI 10.1016/j.acra.2004.02.009; Armato SG, 2002, RADIOLOGY, V225, P685, DOI 10.1148/radiol.2253011376; Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492; Calkins H, 2017, J ARRYTHM, V33, P369, DOI 10.1016/j.joa.2017.08.001; Causey JL, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-27569-w; Church TR, 2013, NEW ENGL J MED, V368, P1980, DOI 10.1056/NEJMoa1209120; Ciompi F, 2017, SCI REP-UK, V7, DOI 10.1038/srep46479; Diederich S, 2002, RADIOLOGY, V222, P773, DOI 10.1148/radiol.2223010490; Gifford HC, 2000, IEEE T MED IMAGING, V19, P463, DOI 10.1109/42.870256; GILLOOLY M, 1993, THORAX, V48, P39, DOI 10.1136/thx.48.1.39; Gruden JF, 2002, AM J ROENTGENOL, V179, P149, DOI 10.2214/ajr.179.1.1790149; Hossain R, 2018, RADIOL CLIN N AM, V56, P365, DOI 10.1016/j.rcl.2018.01.004; Hua KL, 2015, ONCOTARGETS THER, V8, P2015, DOI 10.2147/OTT.S80733; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Li F, 2005, RADIOLOGY, V237, P684, DOI 10.1148/radiol.2372041555; Liang MZ, 2016, RADIOLOGY, V281, P279, DOI 10.1148/radiol.2016150063; Manning DJ, 2004, BRIT J RADIOL, V77, P231, DOI 10.1259/bjr/28883951; Ohno Y, 2017, RADIOLOGY, V284, P562, DOI 10.1148/radiol.2017161037; Park SH, 2004, KOREAN J RADIOL, V5, P11, DOI 10.3348/kjr.2004.5.1.11; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Roth HR, 2014, LECT NOTES COMPUT SC, V8673, P520, DOI 10.1007/978-3-319-10404-1_65; Shen Wei, 2015, Inf Process Med Imaging, V24, P588, DOI 10.1007/978-3-319-19992-4_46; Siegel RL, 2018, CA-CANCER J CLIN, V68, P7, DOI 10.3322/caac.21442; Sone S, 1998, LANCET, V351, P1242, DOI 10.1016/S0140-6736(97)08229-9; TURNER JM, 1968, J APPL PHYSIOL, V25, P664, DOI 10.1152/jappl.1968.25.6.664; van Klaveren RJ, 2009, NEW ENGL J MED, V361, P2221, DOI 10.1056/NEJMoa0906085; Zhou Qinghua, 2018, Zhongguo Fei Ai Za Zhi, V21, P67, DOI 10.3779/j.issn.1009-3419.2018.02.01	28	42	47	3	7	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2019	1	3							e180084	10.1148/ryai.2019180084	http://dx.doi.org/10.1148/ryai.2019180084			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CN	33937792	Green Published			2022-12-18	WOS:000826290100002
J	Khorrami, M; Khunger, M; Zagouras, A; Patil, P; Thawani, R; Bera, K; Rajiah, P; Fu, PF; Velcheti, V; Madabhushi, A				Khorrami, Mohammadhadi; Khunger, Monica; Zagouras, Alexia; Patil, Pradnya; Thawani, Rajat; Bera, Kaustav; Rajiah, Prabhakar; Fu, Pingfu; Velcheti, Vamsidhar; Madabhushi, Anant			Combination of Peri- and Intratumoral Radiomic Features on Baseline CT Scans Predicts Response to Chemotherapy in Lung Adenocarcinoma	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							RANDOMIZED PHASE-III; PATHOLOGICAL RESPONSE; TUMOR HETEROGENEITY; TEXTURE ANALYSIS; CANCER; EXPRESSION; INVASION; CARBOPLATIN; PERFORMANCE; PROGNOSIS	Purpose: To identify the role of radiomics texture features both within and outside the nodule in predicting (a) time to progression (TTP) and overall survival (OS) as well as (b) response to chemotherapy in patients with non-small cell lung cancer (NSCLC). Materials and Methods: Data in a total of 125 patients who had been treated with pemetrexed-based platinum doublet chemotherapy at Cleveland Clinic were retrospectively analyzed. The patients were divided randomly into two sets with the constraint that there were an equal number of responders and nonresponders in the training set. The training set comprised 53 patients with NSCLC, and the validation set comprised 72 patients. A machine learning classifier trained with radiomic texture features extracted from intra-and peritumoral regions of non-contrast-enhanced CT images was used to predict response to chemotherapy. The radiomic risk-score signature was generated by using least absolute shrinkage and selection operator with the Cox regression model; association of the radiomic signature with TTP and OS was also evaluated. Results: A combination of radiomic features in conjunction with a quadratic discriminant analysis classifier yielded a mean maximum area under the receiver operating characteristic curve (AUC) of 0.82 +/- 0.09 (standard deviation) in the training set and a corresponding AUC of 0.77 in the independent testing set. The radiomics signature was also significantly associated with TTP (hazard ratio [HR], 2.8; 95% confidence interval [CI]: 1.95, 4.00; P <.0001) and OS (HR, 2.35; 95% CI: 1.41, 3.94; P =.0011). Additionally, decision curve analysis demonstrated that in terms of clinical usefulness, the radiomics signature had a higher overall net benefit in prediction of high-risk patients to receive treatment than the clinicopathologic measurements. Conclusion: This study suggests that radiomic texture features extracted from within and around the nodule on baseline CT scans are (a) predictive of response to chemotherapy and (b) associated with TTP and OS for patients with NSCLC. (C) RSNA, 2019	[Khorrami, Mohammadhadi; Bera, Kaustav; Madabhushi, Anant] Case Western Reserve Univ, Sch Engn, Dept Biomed Engn, 2071 Martin Luther King Dr, Cleveland, OH 44106 USA; [Khunger, Monica] Cleveland Clin, Dept Internal Med, Cleveland, OH 44106 USA; [Zagouras, Alexia; Patil, Pradnya] Cleveland Clin, Dept Solid Tumor Oncol, Cleveland, OH 44106 USA; [Thawani, Rajat] Maimonides Hosp, Dept Internal Med, Brooklyn, NY 11219 USA; [Rajiah, Prabhakar] UT Southwestern Med Ctr, Dept Radiol, Dallas, TX USA; [Fu, Pingfu] Case Western Reserve Univ, Dept Populat & Quantitat Hlth Sci, Cleveland, OH 44106 USA; [Velcheti, Vamsidhar] NYU, Dept Hematol & Oncol, New York, NY USA; [Madabhushi, Anant] Louis Stokes Cleveland Vet Adm Med Ctr, Cleveland, OH USA	Case Western Reserve University; Cleveland Clinic Foundation; Cleveland Clinic Foundation; Maimonides Medical Center; University of Texas System; University of Texas Southwestern Medical Center Dallas; Case Western Reserve University; New York University; US Department of Veterans Affairs; Veterans Health Administration (VHA); Case Western Reserve University; Louis Stokes Cleveland Veterans Affairs Medical Center	Khorrami, M (corresponding author), Case Western Reserve Univ, Sch Engn, Dept Biomed Engn, 2071 Martin Luther King Dr, Cleveland, OH 44106 USA.	mxk760@case.edu	Fu, Pingfu/O-5415-2019; Thawani, Rajat/M-1190-2019	Fu, Pingfu/0000-0002-2334-5218; Thawani, Rajat/0000-0002-5378-9434; Rajiah, Prabhakar/0000-0001-7538-385X; Khorrami, Mohammadhadi/0000-0002-4141-8548; Malhotra, Monica Khunger/0000-0002-2625-1049	U.S. Department of Defense; National Cancer Institute; National Institute of Diabetes and Digestive and Kidney Diseases; National Center for Research Resources; Ohio Third Frontier Technology Validation Fund; Wallace H. Coulter Foundation Program in the Department of Biomedical Engineering; Clinical and Translational Science Award Program at Case Western Reserve University	U.S. Department of Defense(United States Department of Defense); National Cancer Institute(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Cancer Institute (NCI)); National Institute of Diabetes and Digestive and Kidney Diseases(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Diabetes & Digestive & Kidney Diseases (NIDDK)); National Center for Research Resources(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Research Resources (NCRR)); Ohio Third Frontier Technology Validation Fund; Wallace H. Coulter Foundation Program in the Department of Biomedical Engineering; Clinical and Translational Science Award Program at Case Western Reserve University	Supported by the U.S. Department of Defense, the National Cancer Institute, the National Institute of Diabetes and Digestive and Kidney Diseases, the National Center for Research Resources, the Ohio Third Frontier Technology Validation Fund, the Wallace H. Coulter Foundation Program in the Department of Biomedical Engineering, and the Clinical and Translational Science Award Program at Case Western Reserve University.	Ahmed A, 2013, J MAGN RESON IMAGING, V38, P89, DOI 10.1002/jmri.23971; Armato SG, 2008, CLIN PHARMACOL THER, V84, P448, DOI 10.1038/clpt.2008.161; Braman NM, 2017, BREAST CANCER RES, V19, DOI 10.1186/s13058-017-0846-1; Bukhari Ali A, 2013, Lung Cancer Int, V2013, P436409, DOI 10.1155/2013/436409; Burrell RA, 2014, MOL ONCOL, V8, P1095, DOI 10.1016/j.molonc.2014.06.005; Camp RL, 2004, CLIN CANCER RES, V10, P7252, DOI 10.1158/1078-0432.CCR-04-0713; Coroller TP, 2017, J THORAC ONCOL, V12, P467, DOI 10.1016/j.jtho.2016.11.2226; Coroller TP, 2016, RADIOTHER ONCOL, V119, P480, DOI 10.1016/j.radonc.2016.04.004; Dela Cruz CS, 2011, CLIN CHEST MED, V32, P605, DOI 10.1016/j.ccm.2011.09.001; Ding C, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P523, DOI 10.1109/CSB.2003.1227396; Fave X, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-00665-z; Friboulet L, 2013, NEW ENGL J MED, V368, P1101, DOI 10.1056/NEJMoa1214271; Gabor S, 2004, EUR J CARDIO-THORAC, V25, P439, DOI 10.1016/j.ejcts.2003.11.033; Ganeshan B, 2013, RADIOLOGY, V266, P326, DOI 10.1148/radiol.12112428; GengY, CELL PHYSIOLBIOCHEM2, V37, P1560; Gerlinger M, 2012, NEW ENGL J MED, V366, P883, DOI 10.1056/NEJMoa1113205; Harrell FE, 2015, SPRINGER SER STAT, DOI 10.1007/978-3-319-19425-7; He L, 2016, SCI REP-UK, V6, DOI 10.1038/srep34921; Hilbe W, 2004, J CLIN PATHOL, V57, P965, DOI 10.1136/jcp.2004.016444; Leighl NB, 2012, CURR ONCOL, V19, pS52, DOI 10.3747/co.19.1114; Liu-Jarin XL, 2003, MODERN PATHOL, V16, P1102, DOI 10.1097/01.MP.0000096041.13859.AB; Maeda R, 2010, THORAX, V65, P1092, DOI 10.1136/thx.2010.141861; Massarelli E, 2003, LUNG CANCER-J IASLC, V39, P55, DOI 10.1016/S0169-5002(02)00308-2; Mohiuddin K, 2014, J THORAC CARDIOV SUR, V147, P1169, DOI 10.1016/j.jtcvs.2013.11.056; Morita R, 2011, J CANCER RES CLIN, V137, P1849, DOI 10.1007/s00432-011-1043-8; OGAWA J, 1994, CANCER, V73, P1177, DOI 10.1002/1097-0142(19940215)73:4<1177::AID-CNCR2820730409>3.0.CO;2-0; Oikonomou A, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22357-y; Onn A, 2004, BRIT J CANCER, V91, pS11, DOI 10.1038/sj.bjc.6602062; Orooji M, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.2.024501; Parra ER, 2016, CLIN CANCER RES, V22, P6278, DOI 10.1158/1078-0432.CCR-15-2443; Patel JD, 2013, J CLIN ONCOL, V31, P4349, DOI 10.1200/JCO.2012.47.9626; Ravanelli M, 2013, EUR RADIOL, V23, P3450, DOI 10.1007/s00330-013-2965-0; Saijo T, 2007, LUNG CANCER, V55, P61, DOI 10.1016/j.lungcan.2006.09.027; Semenza GL, 2002, TRENDS MOL MED, V8, pS62, DOI 10.1016/S1471-4914(02)02317-1; Shimada Y, 2010, J THORAC ONCOL, V5, P970, DOI 10.1097/JTO.0b013e3181dd1803; Siegel RL, 2016, CA-CANCER J CLIN, V66, P7, DOI [10.3322/caac.21332, 10.3322/caac.21590, 10.3322/caac.21708]; Song XR, 2006, CANCER CHEMOTH PHARM, V58, P776, DOI 10.1007/s00280-006-0224-7; Sulpher JA, 2013, CLIN LUNG CANCER, V14, P238, DOI 10.1016/j.cllc.2012.11.004; Tibshirani R, 1997, STAT MED, V16, P385, DOI 10.1002/(SICI)1097-0258(19970228)16:4<385::AID-SIM380>3.0.CO;2-3; Tixier F, 2011, J NUCL MED, V52, P369, DOI 10.2967/jnumed.110.082404; Vickers AJ, 2006, MED DECIS MAKING, V26, P565, DOI 10.1177/0272989X06295361; Win T, 2013, CLIN CANCER RES, V19, P3591, DOI 10.1158/1078-0432.CCR-12-1307; Wu J, 2018, RADIOLOGY, V288, P26, DOI 10.1148/radiol.2018172462; Zhang BC, 2012, EXP THER MED, V3, P636, DOI 10.3892/etm.2012.470; Zukin M, 2013, J CLIN ONCOL, V31, P2849, DOI 10.1200/JCO.2012.48.1911	45	42	42	6	13	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2019	1	2							e180012	10.1148/ryai.2019180012	http://dx.doi.org/10.1148/ryai.2019180012			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CM	32076657	Green Published			2022-12-18	WOS:000826288900001
J	Loffler, MT; Sekuboyina, A; Jacob, A; Grau, AL; Scharr, A; El Husseini, M; Kallweit, M; Zimmer, C; Baum, T; Kirschke, JS				Loeffler, Maximilian T.; Sekuboyina, Anjany; Jacob, Alina; Grau, Anna-Lena; Scharr, Andreas; El Husseini, Malek; Kallweit, Mareike; Zimmer, Claus; Baum, Thomas; Kirschke, Jan S.			A Vertebral Segmentation Dataset with Fracture Grading	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article									[Loeffler, Maximilian T.; Sekuboyina, Anjany; Jacob, Alina; Grau, Anna-Lena; Scharr, Andreas; El Husseini, Malek; Kallweit, Mareike; Zimmer, Claus; Baum, Thomas; Kirschke, Jan S.] Tech Univ Munich, Klinikum Rechts Isar, Sch Med, Dept Diagnost & Intervent Neuroradiol, Ismaninger Str 22, D-81675 Munich, Germany; [Sekuboyina, Anjany] Tech Univ Munich, Dept Informat, Munich, Germany		Loffler, MT (corresponding author), Tech Univ Munich, Klinikum Rechts Isar, Sch Med, Dept Diagnost & Intervent Neuroradiol, Ismaninger Str 22, D-81675 Munich, Germany.	m_loeffler@web.de	Löffler, Maximilian/AAW-4937-2020; Kirschke, Jan/E-2550-2012	Kirschke, Jan/0000-0002-7557-0003; Loffler, Maximilian/0000-0002-6022-3682; Sekuboyina, Anjany/0000-0002-5601-284X				Ashburner J, 2005, NEUROIMAGE, V26, P839, DOI 10.1016/j.neuroimage.2005.02.018; Baum T, 2014, EUR RADIOL, V24, P872, DOI 10.1007/s00330-013-3089-2; Burns JE, 2017, RADIOLOGY, V284, P788, DOI 10.1148/radiol.2017162100; Burns JE, 2016, RADIOLOGY, V278, P64, DOI 10.1148/radiol.2015142346; GENANT HK, 1993, J BONE MINER RES, V8, P1137, DOI 10.1002/jbmr.5650080915; Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5; Ibragimov B, 2014, IEEE T MED IMAGING, V33, P861, DOI 10.1109/TMI.2013.2296976; Janssens R, 2018, I S BIOMED IMAGING, P893; Kickingereder P, 2019, LANCET ONCOL, V20, P728, DOI 10.1016/S1470-2045(19)30098-1; Klinder T, 2009, MED IMAGE ANAL, V13, P471, DOI 10.1016/j.media.2009.02.004; Korez R, 2015, IEEE T MED IMAGING, V34, P1649, DOI 10.1109/TMI.2015.2389334; Lessmann N, 2019, MED IMAGE ANAL, V53, P142, DOI 10.1016/j.media.2019.02.005; Loffler MT, 2020, OSTEOPOROSIS INT, V31, P233, DOI 10.1007/s00198-019-05212-2; Loffler MT, 2019, EUR RADIOL, V29, P4980, DOI 10.1007/s00330-019-06018-w; McDonald RJ, 2015, ACAD RADIOL, V22, P1191, DOI 10.1016/j.acra.2015.05.007; Payer C, 2020, PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 5: VISAPP, P124, DOI 10.5220/0008975201240133; Pickhardt PJ, 2019, BRIT J RADIOL, V92, DOI 10.1259/bjr.20180726; Rajapakse CS, 2014, OSTEOPOROSIS INT, V25, P973, DOI 10.1007/s00198-013-2569-1; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Sekuboyina A, ARXIV180401307 CS; Sekuboyina A, ARXIV200109193 CS EE; Sekuboyina A, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190074; Sekuboyina A, 2018, LECT NOTES COMPUT SC, V10734, P108, DOI 10.1007/978-3-319-74113-0_10; Sim Y, 2020, RADIOLOGY, V294, P199, DOI 10.1148/radiol.2019182465; Valentinitsch A, 2017, BONE, V103, P233, DOI 10.1016/j.bone.2017.06.013; Williams AL, 2009, EUR J RADIOL, V69, P179, DOI 10.1016/j.ejrad.2007.08.028; Yao JH, 2016, COMPUT MED IMAG GRAP, V49, P16, DOI 10.1016/j.compmedimag.2015.12.006; Yao JH, 2012, LECT NOTES COMPUT SC, V7512, P509, DOI 10.1007/978-3-642-33454-2_63; Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015	29	40	40	2	4	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2020	2	4							e190138	10.1148/ryai.2020190138	http://dx.doi.org/10.1148/ryai.2020190138			6	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CX	33937831	hybrid, Green Published			2022-12-18	WOS:000826472900004
J	Krogue, JD; Cheng, KV; Hwang, KM; Toogood, P; Meinberg, EG; Geiger, EJ; Zaid, M; McGill, KC; Patel, R; Sohn, JH; Wright, A; Darger, BF; Padrez, KA; Ozhinsky, E; Majumdar, S; Pedoia, V				Krogue, Justin D.; Cheng, Kaiyang, V; Hwang, Kevin M.; Toogood, Paul; Meinberg, Eric G.; Geiger, Erik J.; Zaid, Musa; McGill, Kevin C.; Patel, Rina; Sohn, Jae Ho; Wright, Alexandra; Darger, Bryan F.; Padrez, Kevin A.; Ozhinsky, Eugene; Majumdar, Sharmila; Pedoia, Valentina			Automatic Hip Fracture Identification and Functional Subclassification with Deep Learning	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							SURGICAL-MANAGEMENT; MORTALITY; RADIOGRAPHS; SURGERY	Purpose: To investigate the feasibility of automatic identification and classification of hip fractures using deep learning, which may improve outcomes by reducing diagnostic errors and decreasing time to operation. Materials and Methods: Hip and pelvic radiographs from 1118 studies were reviewed, and 3026 hips were labeled via bounding boxes and classified as normal, displaced femoral neck fracture, nondisplaced femoral neck fracture, intertrochanteric fracture, previous open reduction and internal fixation, or previous arthroplasty. A deep learning-based object detection model was trained to automate the placement of the bounding boxes. A Densely Connected Convolutional Neural Network (or DenseNet) was trained on a subset of the bounding box images, and its performance was evaluated on a held-out test set and by comparison on a 100-image subset with two groups of human observers: fellowship-trained radiologists and orthopedists; senior residents in emergency medicine, radiology, and orthopedics. Results: The binary accuracy for detecting a fracture of this model was 93.7% (95% confidence interval [CI]: 90.8%, 96.5%), with a sensitivity of 93.2% (95% CI: 88.9%, 97.1%) and a specificity of 94.2% (95% CI: 89.7%, 98.4%). Multiclass classification accuracy was 90.8% (95% CI: 87.5%, 94.2%). When compared with the accuracy of human observers, the accuracy of the model achieved an expert-level classification, at the very least, under all conditions. Additionally, when the model was used as an aid, human performance improved, with aided resident performance approximating unaided fellowship-trained expert performance in the multiclass classification. Conclusion: A deep learning model identified and classified hip fractures with expert-level performance, at the very least, and when used as an aid, improved human performance, with aided resident performance approximating that of unaided fellowship-trained attending physicians. Supplemental material is available for this article. (c) RSNA, 2020	[Krogue, Justin D.; Hwang, Kevin M.; Toogood, Paul; Meinberg, Eric G.; Geiger, Erik J.; Zaid, Musa] Univ Calif San Francisco, Dept Orthopaed Surg, 6945 Geary Blvd, San Francisco, CA 94121 USA; [Darger, Bryan F.; Padrez, Kevin A.] Univ Calif San Francisco, Dept Emergency Med, 6945 Geary Blvd, San Francisco, CA 94121 USA; [McGill, Kevin C.; Patel, Rina; Sohn, Jae Ho; Wright, Alexandra; Ozhinsky, Eugene; Majumdar, Sharmila; Pedoia, Valentina] Univ Calif San Francisco, Dept Radiol & Biomed Imaging, 6945 Geary Blvd, San Francisco, CA 94121 USA; [Cheng, Kaiyang, V] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA	University of California System; University of California San Francisco; University of California System; University of California San Francisco; University of California System; University of California San Francisco; University of California System; University of California Berkeley	Krogue, JD (corresponding author), Univ Calif San Francisco, Dept Orthopaed Surg, 6945 Geary Blvd, San Francisco, CA 94121 USA.	justin.d.krogue@gmail.com		Ozhinsky, Eugene/0000-0001-8993-7905; Krogue, Justin/0000-0002-6756-4877; Patel, Rina/0000-0002-2750-2751				Anthony CA, 2017, J ARTHROPLASTY, V32, P3314, DOI 10.1016/j.arth.2017.07.023; Bien N, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002699; Brauer CA, 2009, JAMA-J AM MED ASSOC, V302, P1573, DOI 10.1001/jama.2009.1462; Cannon J, 2009, J EMERG MED, V37, P144, DOI 10.1016/j.jemermed.2007.12.039; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; DeVries T, ARXIV170804552 CS PR; Dominguez S, 2005, ACAD EMERG MED, V12, P366, DOI 10.1197/j.aem.2004.10.024; Donahue J, 2014, PR MACH LEARN RES, V32; Fu MC, 2017, BONE JOINT J, V99B, P1216, DOI 10.1302/0301-620X.99B9.BJJ-2017-0101.R1; Gale W, ARXIV171106504CS STA; hcup, HEALTHCARE COST UTIL; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Huang G, ARXIV160806993 CS PR; ImageNet, IMAGENET; Kaplan K, 2008, J AM ACAD ORTHOP SUR, V16, P665, DOI 10.5435/00124635-200811000-00007; Kingma DP, ARXIV14126980 CS PRE; Lin T.-Y., 2017, PROC CVPR IEEE, P936, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Lindsey R, 2018, P NATL ACAD SCI USA, V115, P11591, DOI 10.1073/pnas.1806905115; Liu F, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180091; Liu F, 2018, RADIOLOGY, V289, P160, DOI 10.1148/radiol.2018172986; Macskassy S., 2004, P 1 WORKSH ROC AN AI; Maheshwari K, 2018, J ORTHOP TRAUMA, V32, P105, DOI 10.1097/BOT.0000000000001043; Miyamoto RG, 2008, J AM ACAD ORTHOP SUR, V16, P596, DOI 10.5435/00124635-200810000-00005; Norman BD, 2018, OSTEOARTHR CARTILAGE, V26, pS436, DOI 10.1016/j.joca.2018.02.840; Norman B, 2018, RADIOLOGY, V288, P177, DOI 10.1148/radiol.2018172322; Rayan JC, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180015; Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131; robots, VGG IMAGE ANNOTATOR; Roche JJW, 2005, BMJ-BRIT MED J, V331, P1374, DOI 10.1136/bmj.38643.663843.55; Stevens JA, 2013, OSTEOPOROSIS INT, V24, P2725, DOI 10.1007/s00198-013-2375-9; Tiulpin A, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-20132-7; Urakawa T, 2019, SKELETAL RADIOL, V48, P239, DOI 10.1007/s00256-018-3016-3; Zhou ZY, 2018, MAGN RESON MED, V80, P2759, DOI 10.1002/mrm.27229	34	40	41	10	11	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2020	2	2							e190023	10.1148/ryai.2020190023	http://dx.doi.org/10.1148/ryai.2020190023			12	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CS	33937815	Green Published, Green Submitted, Bronze			2022-12-18	WOS:000826298800002
J	Morshid, A; Elsayes, KM; Khalaf, AM; Elmohr, MM; Yu, J; Kaseb, AO; Hassan, M; Mahvash, A; Wang, ZH; Hazle, JD; Fuentes, D				Morshid, Ali; Elsayes, Khaled M.; Khalaf, Ahmed M.; Elmohr, Mohab M.; Yu, Justin; Kaseb, Ahmed O.; Hassan, Manal; Mahvash, Armeen; Wang, Zhihui; Hazle, John D.; Fuentes, David			A Machine Learning Model to Predict Hepatocellular Carcinoma Response to Transcatheter Arterial Chemoembolization	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							DOXORUBICIN-ELUTING BEADS; TRANSARTERIAL CHEMOEMBOLIZATION; BETA-CATENIN; CONVENTIONAL CHEMOEMBOLIZATION; LIVER; EMBOLIZATION; VALIDATION; EXPRESSION; SORAFENIB; SURVIVAL	Purpose: To evaluate a fully automated machine learning algorithm that uses pretherapeutic quantitative CT image features and clinical factors to predict hepatocellular carcinoma (HCC) response to transcatheter arterial chemoembolization (TACE). Materials and Methods: Outcome information from 105 patients receiving first-line treatment with TACE was evaluated retrospectively. The primary clinical endpoint was time to progression (TTP) based on follow-up CT radiologic criteria (modified Response Evaluation Criteria in Solid Tumors). A 14-week cutoff was used to classify patients as TACE-susceptible (TTP >= 14 weeks) or TACE-refractory (TTP < 14 weeks). Response to TACE was predicted using a random forest classifier with the Barcelona Clinic Liver Cancer (BCLC) stage and quantitative image features as input, as well as the BCLC stage alone as a control. Results: The model's response prediction accuracy rate was 74.2% (95% confidence interval [CI]: 64%, 82%) using a combination of the BCLC stage plus quantitative image features versus 62.9% (95% CI: 52%, 72%) using the BCLC stage alone. Shape image features of the tumor and background liver were the dominant features correlated to the TTP as selected by the Boruta method and were used to predict the outcome. Conclusion: This preliminary study demonstrated that quantitative image features obtained prior to therapy can improve the accuracy of predicting response of HCC to TACE. This approach is likely to provide useful information for aiding in selection of patients with HCC for TACE. (C) RSNA, 2019	[Morshid, Ali; Khalaf, Ahmed M.; Elmohr, Mohab M.; Yu, Justin; Hazle, John D.; Fuentes, David] Univ Texas MD Anderson Canc Ctr, Dept Imaging Phys, 1515 Holcombe Blvd, Houston, TX 77030 USA; [Elsayes, Khaled M.] Univ Texas MD Anderson Canc Ctr, Dept Diagnost Radiol, 1515 Holcombe Blvd, Houston, TX 77030 USA; [Kaseb, Ahmed O.; Hassan, Manal] Univ Texas MD Anderson Canc Ctr, Dept Gastrointestinal Oncol, 1515 Holcombe Blvd, Houston, TX 77030 USA; [Mahvash, Armeen] Univ Texas MD Anderson Canc Ctr, Dept Intervent Radiol, 1515 Holcombe Blvd, Houston, TX 77030 USA; [Wang, Zhihui] Univ Texas Hlth Sci Ctr Houston, Brown Fdn Inst Mol Med, McGovern Med Sch, Houston, TX 77030 USA	University of Texas System; UTMD Anderson Cancer Center; University of Texas System; UTMD Anderson Cancer Center; University of Texas System; UTMD Anderson Cancer Center; University of Texas System; UTMD Anderson Cancer Center; University of Texas System; University of Texas Health Science Center Houston	Elsayes, KM (corresponding author), Univ Texas MD Anderson Canc Ctr, Dept Diagnost Radiol, 1515 Holcombe Blvd, Houston, TX 77030 USA.	Kmelsayes@mdanderson.org	Wang, Zhihui/B-2464-2009	Wang, Zhihui/0000-0001-6262-700X; Yu, Justin/0000-0003-2778-3175; Morshid, Ali/0000-0003-3678-4751; khalaf, Ahmed/0000-0002-0355-1516; Elmohr, Mohab/0000-0001-9695-2644	MD Anderson	MD Anderson	This work was supported in part by the institutional research grant at MD Anderson. The authors thank the open source communities ITK (https://www.igb.illinois.edu/sites/default/files/upload/core/PDF/ItkSoftwareGuide-2.4.0.pdf) and ANTs (https://www.sciencedirect.com/science/article/abs/pii/S1053811910012061?via%3Dihub) for providing enabling software for image processing and visualization.	Aagaard K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036466; Abajian A, 2018, J VASC INTERV RADIOL, V29, P850, DOI 10.1016/j.jvir.2018.01.769; Bilic P, ARXIV 190104056; BREEDIS C, 1954, AM J PATHOL, V30, P969; Chlebus G, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-33860-7; Cho YK, 2008, CANCER-AM CANCER SOC, V112, P352, DOI 10.1002/cncr.23185; European Assoc Study Liver, 2018, J HEPATOL, V69, P182, DOI 10.1016/j.jhep.2018.03.019; Facciorusso Antonio, 2016, World J Gastrointest Pharmacol Ther, V7, P477; Facciorusso A, 2016, DIGEST LIVER DIS, V48, P571, DOI 10.1016/j.dld.2016.02.005; Facciorusso A, 2016, J GASTROEN HEPATOL, V31, P645, DOI 10.1111/jgh.13147; Garwood ER, 2013, LIVER TRANSPLANT, V19, P164, DOI 10.1002/lt.23552; Gomes AS, 2017, AM J ROENTGENOL, V209, P722, DOI 10.2214/AJR.17.18219; Heimbach JK, 2018, HEPATOLOGY, V67, P358, DOI 10.1002/hep.29086; Huang GW, 2005, WORLD J GASTROENTERO, V11, P1705; Huang KJ, 2014, J GASTROEN HEPATOL, V29, P920, DOI 10.1111/jgh.12439; Izumoto H, 2017, ONCOLOGY-BASEL, V93, P120, DOI 10.1159/000481242; Jeong SO, 2017, GUT LIVER, V11, P409, DOI 10.5009/gnl16001; Keating GM, 2017, TARGET ONCOL, V12, P243, DOI 10.1007/s11523-017-0484-7; Kursa MB, 2010, J STAT SOFTW, V36, P1, DOI 10.18637/jss.v036.i11; Lanza E, 2017, LIVER CANCER, V6, P27, DOI 10.1159/000449347; Lee JM, 2014, CANCER LETT, V343, P90, DOI 10.1016/j.canlet.2013.09.020; Lencioni R, 2012, J CLIN ONCOL, V30, DOI 10.1200/jco.2012.30.4_suppl.lba154; Li PF, 2014, INT J CLIN EXP PATHO, V7, P3190; Llovet JM, 2002, LANCET, V359, P1734, DOI 10.1016/S0140-6736(02)08649-X; Mason MC, 2015, HPB, V17, P1137, DOI 10.1111/hpb.12487; Park HJ, 2017, AM J ROENTGENOL, V209, pW211, DOI 10.2214/AJR.16.17398; Pesapane F, 2017, MED ONCOL, V34, DOI 10.1007/s12032-017-0917-2; Pomerantz SM, 2000, AM J ROENTGENOL, V174, P311, DOI 10.2214/ajr.174.2.1740311; Salem R, 2011, GASTROENTEROLOGY, V140, P497, DOI 10.1053/j.gastro.2010.10.049; Saulnier DM, 2011, GASTROENTEROLOGY, V141, P1782, DOI 10.1053/j.gastro.2011.06.072; Sciarra A, 2015, LIVER INT, V35, P2466, DOI 10.1111/liv.12844; Shanbhogue AK, 2011, RADIOLOGY, V258, P673, DOI 10.1148/radiol.10100376; Sohn JH, 2017, CLIN GASTROENTEROL H, V15, P746, DOI 10.1016/j.cgh.2016.10.036; van Griethuysen JJM, 2017, CANCER RES, V77, pE104, DOI 10.1158/0008-5472.CAN-17-0339; Vorontsov E, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180014; Waisberg J, 2015, WORLD J HEPATOL, V7, P2631, DOI 10.4254/wjh.v7.i26.2631; Wang GL, 2016, HEPATOL INT, V10, P501, DOI 10.1007/s12072-015-9700-7; Wang Z, 2015, MOL CLIN ONCOL, V3, P936, DOI 10.3892/mco.2015.569; Xiang X, 2017, CLIN TRANSL ONCOL, V19, P891, DOI 10.1007/s12094-017-1621-6; Xie ZB, 2015, HEPATOL RES, V45, P190, DOI 10.1111/hepr.12450; Yan XP, 2015, EUR J GASTROEN HEPAT, V27, P1180, DOI 10.1097/MEG.0000000000000418; Yang JD, 2010, INFECT DIS CLIN N AM, V24, P899, DOI 10.1016/j.idc.2010.07.004; Yau T, 2014, GASTROENTEROLOGY, V146, P1691, DOI 10.1053/j.gastro.2014.02.032; Yu SJ, 2017, J PROTEOME RES, V16, P1239, DOI 10.1021/acs.jproteome.6b00833; Zachow S, 3D RECONSTRUCTION IN; Zou JH, 2016, J DIGEST DIS, V17, P510, DOI 10.1111/1751-2980.12380	46	39	40	0	2	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2019	1	5							e180021	10.1148/ryai.2019180021	http://dx.doi.org/10.1148/ryai.2019180021			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CP	31858078	Green Published, Green Accepted			2022-12-18	WOS:000826294400001
J	Rayan, JC; Reddy, N; Kan, JH; Zhang, W; Annapragada, A				Rayan, Jesse C.; Reddy, Nakul; Kan, J. Herman; Zhang, Wei; Annapragada, Ananth			Binomial Classification of Pediatric Elbow Fractures Using a Deep Learning Multiview Approach Emulating Radiologist Decision Making	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To determine the feasibility of using deep learning with a multiview approach, similar to how a human radiologist reviews multiple images, for binomial classification of acute pediatric elbow radiographic abnormalities. Materials and Methods: A total of 21 456 radiographic studies containing 58 817 images of the elbow and associated radiology reports over the course of a 4-year period from January 2014 through December 2017 at a dedicated children's hospital were retrospectively retrieved. Mean age was 7.2 years, and 43% were female patients. The studies were binomially classified, based on the reports, as either positive or negative for acute or subacute traumatic abnormality. The studies were randomly divided into a training set containing 20 350 studies and a validation set containing the remaining 1106 studies. A multiview approach was used for the model by combining both a convolutional neural network and recurrent neural network to interpret an entire series of three radiographs together. Sensitivity, specificity, positive predictive value, negative predictive value, area under the receiver operating characteristic curve (AUC), and their 95% confidence intervals were calculated. Results: AUC was 0.95, and accuracy was 88% for the model on the studied dataset. Sensitivity for the model was 91% (536 of 590), while the specificity for the model was 84% (434 of 516). Of 241 supracondylar fractures, one was missed. Of 88 lateral condylar fractures, one was missed. Of 77 elbow effusions without fracture, 15 were missed. Of 184 other abnormalities, 37 were missed. Conclusion: Deep learning can effectively classify acute and nonacute pediatric elbow abnormalities on radiographs in the setting of trauma. A recurrent neural network was used to classify an entire radiographic series, arrive at a decision based on all views, and identify fractures in pediatric patients with variable skeletal immaturity. (C) RSNA, 2019	[Rayan, Jesse C.; Reddy, Nakul; Kan, J. Herman; Annapragada, Ananth] Texas Childrens Hosp, Baylor Coll Med, EB Singleton Dept Pediat Radiol, 6701 Fannin St,Suite 470, Houston, TX 77030 USA; [Zhang, Wei] Texas Childrens Hosp, Baylor Coll Med, Outcomes & Impact Serv, 6701 Fannin St,Suite 470, Houston, TX 77030 USA; [Rayan, Jesse C.] Massachusetts Gen Hosp, Dept Radiol, Div Abdominal Imaging, 32 Fruit St, Boston, MA 02114 USA; [Reddy, Nakul] Univ Texas MD Anderson Canc Ctr, Dept Intervent Radiol, Houston, TX 77030 USA		Rayan, JC (corresponding author), Texas Childrens Hosp, Baylor Coll Med, EB Singleton Dept Pediat Radiol, 6701 Fannin St,Suite 470, Houston, TX 77030 USA.; Rayan, JC (corresponding author), Massachusetts Gen Hosp, Dept Radiol, Div Abdominal Imaging, 32 Fruit St, Boston, MA 02114 USA.	jcrayan@gmail.com		Rayan, Jesse/0000-0002-7309-6803				[Anonymous], 1999, 10153 BS EN; Bojanowski P., ARXIV CSCL; Chalian M, 2016, AM J ROENTGENOL, V206, P1217, DOI 10.2214/AJR.15.14540; Cheng PM, 2018, ABDOM RADIOL, V43, P1120, DOI 10.1007/s00261-017-1294-1; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Choy G, 2018, RADIOLOGY, V288, P318, DOI 10.1148/radiol.2018171820; Chung SW, 2018, ACTA ORTHOP, V89, P468, DOI 10.1080/17453674.2018.1453714; Girshick  R., 2014, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2014.81; Guan X, ARXIV CS 105; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Iyer RS, 2012, AM J ROENTGENOL, V198, P1053, DOI 10.2214/AJR.10.7314; Johnson Roberta, ROLES DEGENERO CAMBI; Karpathy A., 2016, ARXIV CSLG; Karpathy A., 2017, SOFTWARE 2 0; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Kim DH, 2018, CLIN RADIOL, V73, P439, DOI 10.1016/j.crad.2017.11.015; Kingma D.P, P 3 INT C LEARNING R; Klambauer G, 2017, ADV NEUR IN, V30; Klein EJ, 1999, PEDIATR EMERG CARE, V15, P245; Kyeong Ho Cho, 2013, 2013 IEEE International Conference on Automation Science and Engineering (CASE), P1059, DOI 10.1109/CoASE.2013.6653913; Lin Tsung-Yi, 2017, ARXIV170802002, P2980, DOI [DOI 10.1109/ICCV.2017.324, DOI 10.1109/TPAMI.2018.2858826]; Little KJ, 2014, ORTHOP CLIN N AM, V45, P327, DOI 10.1016/j.ocl.2014.03.004; Nowak J, 2017, LECT NOTES ARTIF INT, V10246, P553, DOI 10.1007/978-3-319-59060-8_50; Paryavi E, 2016, J PEDIATR ORTHOPED, V36, P483, DOI 10.1097/BPO.0000000000000477; Philipsen RHHM, 2015, SCI REP-UK, V5, DOI 10.1038/srep12215; Reddi S., 2018, P INT C LEARN REPR; Shan M, ARXIV CSCV; Springenberg JT, ARXIV 14126806; Sun J., 2017, STRUCTURAL HLTH MONI; Swanson JO, 2012, AM J ROENTGENOL, V198, P1121, DOI 10.2214/AJR.11.6724; Taves J, 2018, CAN J EMERG MED, V20, P420, DOI 10.1017/cem.2017.34; Venugopalan S., ARXIV CSCL; Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515; Yao L, ARXIV1502 08029; Zanfir M, 2017, LECT NOTES COMPUT SC, V10114, P104, DOI 10.1007/978-3-319-54190-7_7	35	39	39	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2019	1	1							e180015	10.1148/ryai.2019180015	http://dx.doi.org/10.1148/ryai.2019180015			8	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CL	33937781	Green Published			2022-12-18	WOS:000826287700002
J	Li, MD; Arun, NT; Gidwani, M; Chang, K; Deng, F; Little, BP; Mendoza, DP; Lang, M; Lee, SI; O'Shea, A; Parakh, A; Singh, P; Kalpathy-Cramer, J				Li, Matthew D.; Arun, Nishanth T.; Gidwani, Mishka; Chang, Ken; Deng, Francis; Little, Brent P.; Mendoza, Dexter P.; Lang, Min; Lee, Susanna, I; O'Shea, Aileen; Parakh, Anushri; Singh, Praveer; Kalpathy-Cramer, Jayashree			Automated Assessment and Tracking of COVID-19 Pulmonary Disease Severity on Chest Radiographs Using Convolutional Siamese Neural Networks	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Conventional Radiography; Thorax; Lung; Infection; Computer Applications-General (Informatics)	INTEROBSERVER RELIABILITY; PNEUMONIA	Purpose: To develop an automated measure of COVID-19 pulmonary disease severity on chest radiographs for longitudinal disease tracking and outcome prediction. Materials and Methods: A convolutional Siamese neural network-based algorithm was trained to output a measure of pulmonary disease severity on chest radiographs (pulmonary x-ray severity [PXS] score), using weakly supervised pretraining on approximately 160 000 anterior-posterior images from CheXpert and transfer learning on 314 frontal chest radiographs from patients with COVID-19. The algorithm was evaluated on internal and external test sets from different hospitals (154 and 113 chest radiographs, respectively). PXS scores were correlated with radiographic severity scores independently assigned by two thoracic radiologists and one in-training radiologist (Pearson r). For 92 internal test set patients with follow-up chest radiographs, PXS score change was compared with radiologist assessments of change (Spearman r). The association between PXS score and subsequent intubation or death was assessed. Bootstrap 95% CIs were calculated. Results: PXS scores correlated with radiographic pulmonary disease severity scores assigned to chest radiographs in the internal and external test sets (r = 0.86 [95% CI: 0.80, 0.90] and r = 0.86 [95% CI: 0.79, 0.90], respectively). The direction of change in PXS score in follow-up chest radiographs agreed with radiologist assessment (r = 0.74 [95% CI: 0.63, 0.81]). In patients not intubated on the admission chest radiography, the PXS score predicted subsequent intubation or death within 3 days of hospital admission (area under the receiver operating characteristic curve = 0.80 [95% CI: 0.75, 0.85]). Conclusion: A Siamese neural network-based severity score automatically measures radiographic COVID-19 pulmonary disease severity, which can be used to track disease change and predict subsequent intubation or death. (C) RSNA, 2020	[Li, Matthew D.; Arun, Nishanth T.; Gidwani, Mishka; Chang, Ken; Singh, Praveer; Kalpathy-Cramer, Jayashree] Athinoula A Maninos Ctr Biomed Imaging, 149 13th St, Charlestown, MA 02129 USA; [Deng, Francis; Lang, Min] Harvard Med Sch, Massachusetts Gen Hosp, Dept Radiol, Boston, MA 02115 USA; [Little, Brent P.; Mendoza, Dexter P.] Harvard Med Sch, Massachusetts Gen Hosp, Div Thorac Imaging & Intervent, Boston, MA 02115 USA; [Lee, Susanna, I; O'Shea, Aileen; Parakh, Anushri] Harvard Med Sch, Massachusetts Gen Hosp, Div Abdominal Imaging, Boston, MA 02115 USA; [Kalpathy-Cramer, Jayashree] Harvard Med Sch, Massachusetts Gen Hosp, MGH & BWH Ctr Clin Data Sci, Boston, MA 02115 USA	Harvard University; Harvard Medical School; Massachusetts General Hospital; Harvard University; Harvard Medical School; Massachusetts General Hospital; Harvard University; Harvard Medical School; Massachusetts General Hospital; Harvard University; Harvard Medical School; Massachusetts General Hospital	Kalpathy-Cramer, J (corresponding author), Athinoula A Maninos Ctr Biomed Imaging, 149 13th St, Charlestown, MA 02129 USA.; Kalpathy-Cramer, J (corresponding author), Harvard Med Sch, Massachusetts Gen Hosp, MGH & BWH Ctr Clin Data Sci, Boston, MA 02115 USA.	kalpathy@nmr.mgh.harvard.edu		Deng, Francis/0000-0003-3117-5076; Chang, Ken/0000-0001-6956-5059; Little, Brent/0000-0001-6657-8241; Lee, Susanna I/0000-0003-2195-2943	NIH (National Institute of Biomedical Imaging and Bioengineering of the National Institutes of Health) [5T32EB1680]; National Cancer Institute of the National Institutes of Health [F30CA239407]	NIH (National Institute of Biomedical Imaging and Bioengineering of the National Institutes of Health); National Cancer Institute of the National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Cancer Institute (NCI))	M.D.L. Activities related to the present article: member of the Radiology: Artificial Intelligence trainee editorial board. Activities not related to the present article: disclosed no relevant relationships. Otherrelationships: disclosed no relevant relationships. N.T.A. disclosed no relevant relationships. M.G. disclosed no relevant relationships. K.C. Activities related to the present article: institution receives funding from NIH (research reported in this publication was supported by a training grant from National Institute of Biomedical Imaging and Bioengineering of the National Institutes of Health under award number 5T32EB1680 and by the National Cancer Institute of the National Institutes of Health under award number F30CA239407 to K.C.; the content is solely the responsibility of the authors and does not necessarily represent the official views of the NIH. Activities not related to the present article: disclosed no relevant relationships. Other relationships: disclosed no relevant relationships. F.D. disclosed no relevant relationships. B.P.L. Activities related to the present article: disclosed no relevant relationships. Activities not related to the present article: author receives royalties from Elsevier as textbook author/associate editor. Other relationships: disclosed no relevant relationships. D.P.M. disclosed no relevant relationships. M.L. disclosed no relevant relationships. S.I.L. Activities related to the present article: disclosed no relevant relationships. Activities not related to the present article: institution receives grant from ECOG-ACRIN; author receives royalties from Wolters Kluwer and Springer; author received travel accommodations from RSNA CTMW. Other relationships: disclosed no relevant relationships. A.O. disclosed no relevant relationships. A.P. disclosed no relevant relationships. P.S. disclosed no relevant relationships. J.K.C. Activities related to the present article: deputy editor of Radiology: Artificial Intelligence. Activities not related to the present article: institution receives grants from GE and Genentech; author received travel accommodations from IBM. Other relationships: disclosed no relevant relationships.	ACR, RECOMMENDATIONS USE; Albaum MN, 1996, CHEST, V110, P343, DOI 10.1378/chest.110.2.343; Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339; Hadsell R., 2006, 2006 IEEE COMPUTER S, P1735, DOI DOI 10.1109/CVPR.2006.100; Hammon M, 2014, BMC ANESTHESIOL, V14, DOI 10.1186/1471-2253-14-94; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Hurt B, 2020, J THORAC IMAG, V35, pW87, DOI 10.1097/RTI.0000000000000512; Irvin J, ARXIV PREPRINT; Kennedy S, 2011, J EMERG MED, V40, P47, DOI 10.1016/j.jemermed.2009.10.018; King DB, 2015, ACS SYM SER, V1214, P1; Lakhani P, 2017, RADIOLOGY, V284, P574, DOI 10.1148/radiol.2017162326; Li MD, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0255-1; Liao R, ARXIV PREPRINT; Loeb MB, 2006, J AM MED DIR ASSOC, V7, P416, DOI 10.1016/j.jamda.2006.02.004; Mason D, 2011, MED PHYS, V38, DOI 10.1118/1.3611983; McClain L, 2014, J HOSP MED, V9, P559, DOI 10.1002/jhm.2227; Neuman MI, 2012, J HOSP MED, V7, P294, DOI 10.1002/jhm.955; Phua Jason, 2020, Lancet Respir Med, V8, P506, DOI 10.1016/S2213-2600(20)30161-2; Rajpurkar P, ARXIV PREPRINT; Rubin GD, 2020, RADIOLOGY, V296, P172, DOI [10.1016/j.chest.2020.04.003, 10.1148/radiol.2020201365]; Sabottke CF, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2019190015; Sheshadri A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0197418; Taylor E, 2015, BMC MED IMAGING, V15, DOI 10.1186/s12880-015-0103-y; The OpenCV Library, DR DOBBS J; Toussie D, 2020, RADIOLOGY, V297, pE197, DOI 10.1148/radiol.2020201754; Warren MA, 2018, THORAX, V73, P840, DOI 10.1136/thoraxjnl-2017-211280; Wong HYF, 2020, RADIOLOGY, V296, pE72, DOI 10.1148/radiol.2020201160; Wynants L, 2020, BMJ-BRIT MED J, V369, DOI 10.1136/bmj.m1328; Zeiler MD, ARXIV PREPRINT; Zhou F, 2020, LANCET, V395, P1054, DOI 10.1016/S0140-6736(20)30566-3	30	33	33	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2020	2	4							e200079	10.1148/ryai.2020200079	http://dx.doi.org/10.1148/ryai.2020200079			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CX	33928256	Green Published			2022-12-18	WOS:000826472900012
J	Yao, AD; Cheng, DL; Pan, I; Kitamura, F				Yao, Anthony D.; Cheng, Derrick L.; Pan, Ian; Kitamura, Felipe			Deep Learning in Neuroradiology: A Systematic Review of Current Algorithms and Approaches for the New Wave of Imaging Technology	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Review								Purpose: To systematically review and synthesize the current literature and to develop a compendium of technical characteristics of existing deep learning applications in neuroradiology. Materials and Methods: A Preferred Reporting Items for Systematic Reviews and Meta-Analyses systematic review was conducted through September 1, 2019, using PubMed, Cochrane, and Web of Science databases. A total of 155 articles discussing deep learning applications in neuroimaging were identified, divided by imaging modality, and characterized by imaging task, data source, algorithm type, and outcome metrics. Results: A total of 155 studies were identified and divided into: MRI (n = 115), functional MRI (n = 19), CT (n = 9), PET (n = 18), and US (n = 1). Seven were multimodal. MRI applications were described in 74%, and 76 (49%) were tasked with image segmentation. Of the 155 articles identified in this study, 65 (42%) were tested on institutional data; only 16 were validated against publicly available data. In addition, 53 studies (34%) used a combined dataset of less than 100, and 124 (80%) used a combined dataset of less than 1000. Conclusion: Although deep learning has demonstrated potential for each of these modalities, this review highlights several needs in the field of deep learning research including use of internal datasets without external validation, unavailability of implementation methods, inconsistent assessment metrics, and lack of clinical validation. However, the rapid growth of deep learning in neuroradiology holds promise and, as strides are made to improve standardization, generalizability, and reproducibility, it may soon play a role in clinical diagnosis and treatment of neurologic disorders. Supplemental material is available for this article. (c) RSNA, 2020	[Yao, Anthony D.; Cheng, Derrick L.; Pan, Ian] Brown Univ, Warren Alpert Med Sch, Box G-9280,222 Richmond St, Providence, RI 02912 USA; [Kitamura, Felipe] Univ Fed Sao Paulo, Dept Diagnost Imaging, Sao Paulo, Brazil		Yao, AD (corresponding author), Brown Univ, Warren Alpert Med Sch, Box G-9280,222 Richmond St, Providence, RI 02912 USA.	anthony_yao@brown.edu	Pan, Ian/ABD-3474-2021; Kitamura, Felipe Campos/AAC-7075-2021; Kitamura, Felipe Campos/AAC-4368-2021	Pan, Ian/0000-0002-0650-6614; Kitamura, Felipe Campos/0000-0002-9992-5630; Yao, Anthony/0000-0001-8846-2258; Cheng, Derrick/0000-0002-7605-3323				Akkus Z, 2017, J DIGIT IMAGING, V30, P449, DOI 10.1007/s10278-017-9983-4; Chartrand G, 2017, RADIOGRAPHICS, V37, P2113, DOI 10.1148/rg.2017170077; Feng R, 2018, J NEUROINTERV SURG, V10, P358, DOI 10.1136/neurintsurg-2017-013355; Jiang F, 2017, STROKE VASC NEUROL, V2, P230, DOI 10.1136/svn-2017-000101; Lee EJ, 2017, J STROKE, V19, P277, DOI 10.5853/jos.2017.02054; Moravec H., 1998, J EVOLUTION TECHNOLO, V1, P1; Nielsen A, 2018, STROKE, V49, P1394, DOI 10.1161/STROKEAHA.117.019740; Plis SM, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00229; Titano JJ, 2018, NAT MED, V24, P1337, DOI 10.1038/s41591-018-0147-y; Zaharchuk G, 2018, AM J NEURORADIOL, V39, P1776, DOI 10.3174/ajnr.A5543	10	30	30	1	2	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2020	2	2							e190026	10.1148/ryai.2020190026	http://dx.doi.org/10.1148/ryai.2020190026			6	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CS	33937816	Green Published			2022-12-18	WOS:000826298800003
J	Nakamura, Y; Higaki, T; Tatsugami, F; Zhou, J; Yu, Z; Akino, N; Ito, Y; Iida, M; Awai, K				Nakamura, Yuko; Higaki, Toru; Tatsugami, Fuminari; Zhou, Jian; Yu, Zhou; Akino, Naruomi; Ito, Yuya; Iida, Makoto; Awai, Kazuo			Deep Learning-based CT Image Reconstruction: Initial Evaluation Targeting Hypovascular Hepatic Metastases	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							STATISTICAL ITERATIVE RECONSTRUCTION; FILTERED BACK-PROJECTION; ABDOMINAL CT; COMPUTED-TOMOGRAPHY; DOSE REDUCTION; QUALITY; MODULATION; DIAGNOSIS; STANDARD	Purpose: To evaluate the effect of a deep learning-based reconstruction (DLR) method on the conspicuity of hypovascular hepatic metastases on abdominal CT images. Materials and Methods: This retrospective study with institutional review board approval included 58 patients with hypovascular hepatic metastases. A radiologist recorded the standard deviation of attenuation in the paraspinal muscle as the image noise and the contrast-to-noise ratio (CNR). CNR was calculated as region of interest ([ROI](L) - ROIT)/N, where ROIL is the mean liver parenchyma attenuation, ROIT, the mean tumor attenuation, and N, the noise. Two other radiologists graded the conspicuity of the liver lesion on a five-point scale where 1 is unidentifiable and 5 is detected without diagnostic compromise. Only the smallest liver lesion in each patient, classified as smaller or larger than 10 mm, was evaluated. The difference between hybrid iterative reconstruction (IR) and DLR images was determined by using a two-sided Wilcoxon signed-rank test. Results: The image noise was significantly lower, and the CNR was significantly higher on DLR images than hybrid IR images (median image noise: 19.2 vs 12.8 HU, P < .001; median CNR: tumors, 10 mm: 1.9 vs 2.5; tumors. 10 mm: 1.7 vs 2.2, both P < .001). The scores for liver lesions were significantly higher for DLR images than hybrid IR images (P < .01 for both in tumors smaller or larger than 10 mm). Conclusion: DLR improved the quality of abdominal CT images for the evaluation of hypovascular hepatic metastases. (c) RSNA, 2019 Supplemental material is available for this article.	[Nakamura, Yuko; Higaki, Toru; Tatsugami, Fuminari; Iida, Makoto; Awai, Kazuo] Hiroshima Univ, Dept Diagnost Radiol, Minami Ku, 1-2-3 Kasumi, Hiroshima 7348551, Japan; [Zhou, Jian; Yu, Zhou] Canon Med Res USA, Vernon Hills, IL USA; [Akino, Naruomi; Ito, Yuya] Canon Med Syst, Otawara, Tochigi, Japan	Hiroshima University	Nakamura, Y (corresponding author), Hiroshima Univ, Dept Diagnost Radiol, Minami Ku, 1-2-3 Kasumi, Hiroshima 7348551, Japan.	yukon@hiroshima-u.ac.jp		Zhou, Jian/0000-0001-9712-6301; Tatsugami, Fuminari/0000-0002-2350-6819; Yu, Zhou/0000-0001-7729-4893; Ito, Yuya/0000-0002-1292-3166; Akino, Naruomi/0000-0002-7413-2095; Higaki, Toru/0000-0003-0631-7271				AAPM Task Group 204, 2011, 204 AAPM TASK GROUP; Ananthakrishnan Ashwin, 2006, Semin Intervent Radiol, V23, P47, DOI 10.1055/s-2006-939841; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bosch FX, 2004, GASTROENTEROLOGY, V127, pS5, DOI 10.1053/j.gastro.2004.09.011; Brady SL, 2012, RADIOLOGY, V265, P832, DOI 10.1148/radiol.12120131; Chang W, 2013, INVEST RADIOL, V48, P598, DOI 10.1097/RLI.0b013e3182899104; Christner JA, 2012, RADIOLOGY, V265, P841, DOI 10.1148/radiol.12112365; de Ridder J, 2016, ONCOTARGET, V7, P55368, DOI 10.18632/oncotarget.10552; Deak Z, 2013, RADIOLOGY, V266, P197, DOI 10.1148/radiol.12112707; Dou Q, 2016, IEEE T MED IMAGING, V35, P1182, DOI 10.1109/TMI.2016.2528129; Euler A, 2017, EUR RADIOL, V27, P5252, DOI 10.1007/s00330-017-4825-9; Fontarensky M, 2015, RADIOLOGY, V276, P156, DOI 10.1148/radiol.2015141287; Higaki T, 2017, DATA BRIEF, V13, P437, DOI 10.1016/j.dib.2017.06.024; Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90; Kakinuma R, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0137165; Kalra MK, 2004, RADIOLOGY, V233, P241, DOI 10.1148/radiol.2331031505; Kanal KM, 2011, AM J ROENTGENOL, V197, P437, DOI 10.2214/AJR.10.5726; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Lee KH, 2012, RADIOLOGY, V265, P437, DOI 10.1148/radiol.12112434; Likert R., 1932, ARCH PSYCHOL, V140, P1, DOI DOI 10.4135/9781412961288.N454; Maher B, 2017, CLIN RADIOL, V72, P617, DOI 10.1016/j.crad.2017.05.016; Mainenti PP, 2010, ABDOM IMAGING, V35, P511, DOI 10.1007/s00261-009-9555-2; Muhi A, 2011, J MAGN RESON IMAGING, V34, P326, DOI 10.1002/jmri.22613; Nagayama Y, 2019, EUR RADIOL, V29, P2837, DOI 10.1007/s00330-018-5789-0; Nakamoto A, 2015, EUR J RADIOL, V84, P1715, DOI 10.1016/j.ejrad.2015.05.027; Niekel MC, 2010, RADIOLOGY, V257, P674, DOI 10.1148/radiol.10100729; Nishizawa M, 2015, JPN J RADIOL, V33, P26, DOI 10.1007/s11604-014-0376-z; Phelps AS, 2015, AM J ROENTGENOL, V204, P8, DOI 10.2214/AJR.14.13022; Powell S, 2008, NEUROIMAGE, V39, P238, DOI 10.1016/j.neuroimage.2007.05.063; Qurashi AA, 2018, RAD PROT DOSIMETRY; Racine D, 2016, PHYS MEDICA, V32, P76, DOI 10.1016/j.ejmp.2015.09.011; Roth HR, 2014, LECT NOTES COMPUT SC, V8673, P520, DOI 10.1007/978-3-319-10404-1_65; Sagara Y, 2010, AM J ROENTGENOL, V195, P713, DOI 10.2214/AJR.09.2989; Shuman WP, 2014, RADIOLOGY, V273, P793, DOI 10.1148/radiol.14140676; SVANHOLM H, 1989, APMIS, V97, P689, DOI 10.1111/j.1699-0463.1989.tb00464.x; Tsurusaki M, 2016, HEPATOL RES, V46, P853, DOI 10.1111/hepr.12646; Volders D, 2013, RADIOLOGY, V269, P468, DOI 10.1148/radiol.13130002; Yasaka K, 2017, ACTA RADIOL, V58, P1085, DOI 10.1177/0284185116684675; Zhu B, 2018, NATURE, V555, P487, DOI 10.1038/nature25988	40	30	31	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2019	1	6							e180011	10.1148/ryai.2019180011	http://dx.doi.org/10.1148/ryai.2019180011			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CQ	33937803	Green Published, Bronze			2022-12-18	WOS:000826296100001
J	Pacile, S; Lopez, J; Chone, P; Bertinotti, T; Grouin, JM; Fillard, P				Pacile, Serena; Lopez, January; Chone, Pauline; Bertinotti, Thomas; Grouin, Jean Marie; Fillard, Pierre			Improving Breast Cancer Detection Accuracy of Mammography with the Concurrent Use of an Artificial Intelligence Tool	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							COMPUTER-AIDED DETECTION; SCREENING MAMMOGRAPHY; PERFORMANCE	Purpose: To evaluate the benefits of an artificial intelligence (AI)-based tool for two-dimensional mammography in the breast cancer detection process. Materials and Methods: In this multireader, multicase retrospective study, 14 radiologists assessed a dataset of 240 digital mammography images, acquired between 2013 and 2016, using a counterbalance design in which half of the dataset was read without AI and the other half with the help of AI during a first session and vice versa during a second session, which was separated from the first by a washout period. Area under the receiver operating characteristic curve (AUC), sensitivity, specificity, and reading time were assessed as endpoints. Results: The average AUC across readers was 0.769 (95% CI: 0.724, 0.814) without AI and 0.797 (95% CI: 0.754, 0.840) with AI. The average difference in AUC was 0.028 (95% CI: 0.002, 0.055, P=.035). Average sensitivity was increased by 0.033 when using AI support (P=.021). Reading time changed dependently to the AI-tool score. For low likelihood of malignancy (<2.5%), the time was about the same in the first reading session and slightly decreased in the second reading session. For higher likelihood of malignancy, the reading time was on average increased with the use of AI. Conclusion: This clinical investigation demonstrated that the concurrent use of this AI tool improved the diagnostic performance of radiologists in the detection of breast cancer without prolonging their workflow. (C) RSNA, 2020	[Pacile, Serena; Chone, Pauline; Bertinotti, Thomas; Fillard, Pierre] Therapixel SA, 39 Rue Claude Daunesse, F-06560 Valbonne, France; [Lopez, January] Hoag Mem Hosp, Radiol & Imaging Serv, Newport Beach, CA USA; [Grouin, Jean Marie] Univ Rouen, Dept Stat, Rouen, France	Universite de Rouen Normandie	Pacile, S (corresponding author), Therapixel SA, 39 Rue Claude Daunesse, F-06560 Valbonne, France.			PACILE, SERENA/0000-0003-3354-4293; Lopez, January/0000-0001-5207-1458				[Anonymous], 2018, GLOB AN POP SCREEN T; [Anonymous], MATTH ICC R PACK ASS; Benedikt R, ECR 2017 POS TERNG; Conant EF, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180096; Evans KK, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0064366; Fenton JJ, 2007, NEW ENGL J MED, V356, P1399, DOI 10.1056/NEJMoa066099; Gilbert FJ, 2008, NEW ENGL J MED, V359, P1675, DOI 10.1056/NEJMoa0803545; Gromet M, 2008, AM J ROENTGENOL, V190, P854, DOI 10.2214/AJR.07.2812; Gur D, 2011, RADIOLOGICAL SOC N A; Gur D, 2008, RADIOLOGY, V249, P47, DOI 10.1148/radiol.2491072025; Hillis SL, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.4.045503; Hillis SL, 2011, ACAD RADIOL, V18, P129, DOI 10.1016/j.acra.2010.09.007; Hupse R, 2013, RADIOLOGY, V266, P123, DOI 10.1148/radiol.12120218; James JJ, 2010, RADIOLOGY, V256, P379, DOI 10.1148/radiol.10091899; Kim HE, 2020, LANCET DIGIT HEALTH, V2, pE138, DOI 10.1016/S2589-7500(20)30003-0; Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012; Kooi T, 2017, MED IMAGE ANAL, V35, P303, DOI 10.1016/j.media.2016.07.007; Lehman CD, 2015, JAMA INTERN MED, V175, P1828, DOI 10.1001/jamainternmed.2015.5231; Liljequist D, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0219854; Marmot MG, 2013, BRIT J CANCER, V108, P2205, DOI 10.1038/bjc.2013.177; McDonald ES, 2015, AM J ROENTGENOL, V205, P1143, DOI 10.2214/AJR.15.14406; McKinney SM, 2020, NATURE, V577, P89, DOI 10.1038/s41586-019-1799-6; Pannucci CJ, 2010, PLAST RECONSTR SURG, V126, P619, DOI 10.1097/PRS.0b013e3181de24bc; Park SH, 2018, RADIOLOGY, V286, P800, DOI 10.1148/radiol.2017171920; Rawashdeh MA, 2013, RADIOLOGY, V269, P61, DOI 10.1148/radiol.13122581; Rodriguez-Ruiz A, 2019, RADIOLOGY, V290, P305, DOI 10.1148/radiol.2018181371; Rodriguez-Ruiz A, 2018, PROC SPIE, V10718, DOI 10.1117/12.2317937; Sahran S, 2018, BREAST CANC SURG; Sant M, 2004, CANCER-AM CANCER SOC, V100, P715, DOI 10.1002/cncr.20038; Shen L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48995-4; Sumkin JH, 2015, ACAD RADIOL, V22, P1477, DOI 10.1016/j.acra.2015.08.015; Watanabe AT, 2019, J DIGIT IMAGING, V32, P625, DOI 10.1007/s10278-019-00192-5; Wu N, ARXIV190308297	33	26	26	2	2	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2020	2	6							e190208	10.1148/ryai.2020190208	http://dx.doi.org/10.1148/ryai.2020190208			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CZ	33937844	Green Published			2022-12-18	WOS:000826480100003
J	Kundu, S; Elhalawani, H; Gichoya, JW; Kahn, CE				Kundu, Shinjini; Elhalawani, Hesham; Gichoya, Judy W.; Kahn, Charles E., Jr.			How Might AI and Chest Imaging Help Unravel COVID-19's Mysteries?	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material						CT; Informatics; Computer Aided Diagnosis (CAD); Thorax; Computer Applications-General (Informatics); Radiomics-Integration-Application Domain; Feature Detection; Vision-Application Domain; Diagnosis-Classification-Application Domain; Prognosis-Classification-Application; Domain	DIAGNOSIS	Artificial intelligence (AI) has the potential to expand the role of chest imaging in COVID-19 beyond diagnosis to enable risk stratification, treatment monitoring, and discovery of novel therapeutic targets. AI's power to generate models from large volumes of information-fusing molecular, clinical, epidemiologic, and imaging data-may accelerate solutions to detect, contain, and treat COVID-19.	[Kundu, Shinjini] Johns Hopkins Univ Hosp, Dept Radiol, 601 N Caroline St,Room 4223, Baltimore, MD 21287 USA; [Elhalawani, Hesham] Cleveland Clin, Dept Radiat Oncol, Cleveland, OH 44106 USA; [Gichoya, Judy W.] Emory Univ, Sch Med, Dept Radiol, Atlanta, GA 30322 USA; [Kahn, Charles E., Jr.] Univ Penn, Dept Radiol, Philadelphia, PA 19104 USA	Johns Hopkins University; Johns Hopkins Medicine; Cleveland Clinic Foundation; Emory University; University of Pennsylvania	Kundu, S (corresponding author), Johns Hopkins Univ Hosp, Dept Radiol, 601 N Caroline St,Room 4223, Baltimore, MD 21287 USA.	skundu2@jhmi.edu		Kahn, Charles/0000-0002-6654-7434				Ai T, 2020, RADIOLOGY, V296, pE32, DOI 10.1148/radiol.2020200642; [Anonymous], THER OPT COVID 19 PA; [Anonymous], COVID 19 UPDATES; B.Kang, 2020, medRxiv, DOI 10.1101/2020.02.14.20023028; B.Ma, 2020, medRxiv, DOI 10.1101/2020.02.29.20029603; B.Zheng, 2020, medRxiv, DOI 10.1101/2020.02.25.20021568; Bai X., 2020, PREDICTING COVID 19, DOI 10.2139/ssrn.3557984; Bernheim Adam, 2020, Radiology, V295, P200463, DOI 10.1148/radiol.2020200463; Bohmwald K, 2019, FRONT IMMUNOL, V10, DOI 10.3389/fimmu.2019.00452; Bullock J, ARXIV 200311336 PREP; Buonsenso D, 2020, EUR REV MED PHARMACO, V24, P2776, DOI 10.26355/eurrev_202003_20549; Chua F, 2020, LANCET RESP MED, V8, P438, DOI 10.1016/S2213-2600(20)30132-6; Collins GS, 2015, ANN INTERN MED, V162, P55, DOI [10.7326/M14-0697, 10.1038/bjc.2014.639, 10.1161/CIRCULATIONAHA.114.014508, 10.1186/s12916-014-0241-z, 10.1002/bjs.9736, 10.7326/M14-0698, 10.1016/j.jclinepi.2014.11.010, 10.1136/bmj.g7594, 10.1016/j.eururo.2014.11.025]; Division of Viral Diseases, CTR DIS CONTR PREV C; Fang YC, 2020, RADIOLOGY, V296, pE115, DOI 10.1148/radiol.2020200432; Ghoshal B, 2003, ARXIV; Gozes O, 2003, ARXIV 2020; H.Zhao, 2020, medRxiv, DOI 10.1101/2020.02.23.20026930; Hu X, 2020, SSRN, DOI [10.2139/ssrn.3550043, DOI 10.2139/SSRN.3550043]; Ji YP, 2020, LANCET GLOB HEALTH, V8, pE480, DOI 10.1016/S2214-109X(20)30068-1; Jin S., 2020, MEDRXIV; Kucirka L, MEDRXIV, DOI [10.1101/2020.04.07.20051474, DOI 10.1101/2020.04.07.20051474]; Kwong MT, 2019, BIO-DES MANUF, V2, P31, DOI 10.1007/s42242-018-0030-1; Li L., 2020, RADIOLOGY, V19, DOI DOI 10.1148/RADIOL.2020200905; Liu ZY, 2019, THERANOSTICS, V9, P1303, DOI 10.7150/thno.30309; Mehta P, 2020, LANCET, V395, P1033, DOI 10.1016/S0140-6736(20)30628-0; Mongan J, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020200029; National Health Commission of the People's Republic of China, NOT LAUNCH GUID DIAG; Pan C.T., 2020, SCI REP-UK, V10, P1, DOI 10.1038/srep46402; Pan F, 2020, RADIOLOGY, V295, P715, DOI 10.1148/radiol.2020200370; Rodrigues JCL, 2020, CLIN RADIOL, V75, P323, DOI 10.1016/j.crad.2020.03.003; Ruan QR, 2020, INTENS CARE MED, V46, P846, DOI 10.1007/s00134-020-05991-x; Rubin GD, 2020, RADIOLOGY, V296, P172, DOI [10.1016/j.chest.2020.04.003, 10.1148/radiol.2020201365]; Shan F., ARXIV PREPRINT ARXIV; Shi YF, 2020, CELL DEATH DIFFER, V27, P1451, DOI 10.1038/s41418-020-0530-3; Simpson Scott, 2020, Radiol Cardiothorac Imaging, V2, pe200152, DOI [10.1097/RTI.0000000000000524, 10.1148/ryct.2020200152]; Voiriot G, 2017, RESP RES, V18, DOI 10.1186/s12931-017-0553-6; Wilkinson MD, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.18; Wu ZY, 2020, JAMA-J AM MED ASSOC, V323, P1239, DOI 10.1001/jama.2020.2648; Xu Z, 2020, LANCET RESP MED, V8, P420, DOI 10.1016/S2213-2600(20)30076-X; Yang WJ, 2020, RADIOLOGY, V295, pE3, DOI 10.1148/radiol.2020200702	42	25	25	2	3	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2020	2	3							e200053	10.1148/ryai.2020200053	http://dx.doi.org/10.1148/ryai.2020200053			5	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CW	33928254	Green Published			2022-12-18	WOS:000826470300011
J	Thomas, KA; Kidzinski, L; Halilaj, E; Fleming, SL; Venkataraman, GR; Oei, EHG; Gold, GE; Delp, SL				Thomas, Kevin A.; Kidzinski, Lukasz; Halilaj, Eni; Fleming, Scott L.; Venkataraman, Guhan R.; Oei, Edwin H. G.; Gold, Garry E.; Delp, Scott L.			Automated Classification of Radiographic Knee Osteoarthritis Severity Using Deep Neural Networks	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To develop an automated model for staging knee osteoarthritis severity from radiographs and to compare its performance to that of musculoskeletal radiologists. Materials and Methods: Radiographs from the Osteoarthritis Initiative staged by a radiologist committee using the Kellgren-Lawrence (KL) system were used. Before using the images as input to a convolutional neural network model, they were standardized and augmented automatically. The model was trained with 32 116 images, tuned with 4074 images, evaluated with a 4090-image test set, and compared to two individual radiologists using a 50-image test subset. Saliency maps were generated to reveal features used by the model to determine KL grades. Results: With committee scores used as ground truth, the model had an average F1 score of 0.70 and an accuracy of 0.71 for the full test set. For the 50-image subset, the best individual radiologist had an average F1 score of 0.60 and an accuracy of 0.60; the model had an average F1 score of 0.64 and an accuracy of 0.66. Cohen weighted k between the committee and model was 0.86, comparable to intraexpert repeatability. Saliency maps identified sites of osteophyte formation as influential to predictions. Conclusion: An end-to-end interpretable model that takes full radiographs as input and predicts KL scores with state-of-the-art accuracy, performs as well as musculoskeletal radiologists, and does not require manual image preprocessing was developed. Saliency maps suggest the model's predictions were based on clinically relevant information. Supplemental material is available for this article. (c) RSNA, 2020++	[Thomas, Kevin A.; Fleming, Scott L.; Venkataraman, Guhan R.] Stanford Univ, Clark Ctr, Dept Biomed Data Sci, 318 Campus Dr,Room S321, Stanford, CA 94305 USA; [Kidzinski, Lukasz; Delp, Scott L.] Stanford Univ, Clark Ctr, Dept Bioengn, 318 Campus Dr,Room S321, Stanford, CA 94305 USA; [Gold, Garry E.] Stanford Univ, Clark Ctr, Dept Radiol, 318 Campus Dr,Room S321, Stanford, CA 94305 USA; [Oei, Edwin H. G.] Erasmus Univ, Dept Radiol, Rotterdam, Netherlands; [Halilaj, Eni] Carnegie Mellon Univ, Dept Mech Engn, Pittsburgh, PA 15213 USA	Stanford University; Stanford University; Stanford University; Erasmus University Rotterdam; Carnegie Mellon University	Thomas, KA (corresponding author), Stanford Univ, Clark Ctr, Dept Biomed Data Sci, 318 Campus Dr,Room S321, Stanford, CA 94305 USA.	kevin.a.thomas@stanford.edu	Oei, Edwin HG/E-8174-2013	Halilaj, Eni/0000-0001-6304-8552; Gold, Garry/0000-0002-3207-822X; Fleming, Scott/0000-0002-6047-7877; Delp, Scott/0000-0002-9643-7551	NIH Big Data to Knowledge (BD2K) Research Grant [U54EB020405]	NIH Big Data to Knowledge (BD2K) Research Grant	Work supported by NIH Big Data to Knowledge (BD2K) Research Grant U54EB020405	Antony J, ARXIV 160902469; Bishop C.M, 2006, PATTERN RECOGN; Bourne RB, 2010, CLIN ORTHOP RELAT R, V468, P57, DOI 10.1007/s11999-009-1119-9; COHEN J, 1968, PSYCHOL BULL, V70, P213, DOI 10.1037/h0026256; epi-ucsf, 2013, OSTEOARTHRITIS INITI; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; KELLGREN JH, 1957, ANN RHEUM DIS, V16, P485, DOI 10.1136/ard.16.4.485; Kessler S, 1998, CLIN RHEUMATOL, V17, P205, DOI 10.1007/BF01451048; Mazzuca SA, 2005, J RHEUMATOL, V32, P1540; Merkel D, 2014, LINUX J, V2014; Norman B, 2019, J DIGIT IMAGING, V32, P471, DOI 10.1007/s10278-018-0098-3; Rajpurkar P, ARXIV 171206957; Riddle DL, 2013, ORTHOPEDICS, V36, pE25, DOI 10.3928/01477447-20121217-14; Shamir L, 2009, OSTEOARTHR CARTILAGE, V17, P1307, DOI 10.1016/j.joca.2009.04.010; Shamir L, 2010, EURASIP J BIOINFORM, DOI 10.1155/2010/107036; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Tiulpin A, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-20132-7	17	25	25	1	3	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2020	2	2							e190065	10.1148/ryai.2020190065	http://dx.doi.org/10.1148/ryai.2020190065			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CS	32280948	Green Published, Bronze			2022-12-18	WOS:000826298800005
J	Arun, N; Gaw, N; Singh, P; Chang, K; Aggarwal, M; Chen, B; Hoebel, K; Gupta, S; Patel, J; Gidwani, M; Adebayo, J; Li, MD; Kalpathy-Cramer, J				Arun, Nishanth; Gaw, Nathan; Singh, Praveer; Chang, Ken; Aggarwal, Mehak; Chen, Bryan; Hoebel, Katharina; Gupta, Sharut; Patel, Jay; Gidwani, Mishka; Adebayo, Julius; Li, Matthew D.; Kalpathy-Cramer, Jayashree			Assessing the Trustworthiness of Saliency Maps for Localizing Abnormalities in Medical Imaging	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Technology Assessment; Technical Aspects; Feature Detection; Convolutional Neural Network (CNN)		Purpose: To evaluate the trustworthiness of saliency maps for abnormality localization in medical imaging. Materials and Methods: Using two large publicly available radiology datasets (Society for Imaging Informatics in Medicine-American College of Radiology Pneumothorax Segmentation dataset and Radiological Society of North America Pneumonia Detection Challenge dataset), the performance of eight commonly used saliency map techniques were quantified in regard to (a) localization utility (segmentation and detection), (b) sensitivity to model weight randomization, (c) repeatability, and (d) reproducibility. Their performances versus baseline methods and localization network architectures were compared, using area under the precision-recall curve (AUPRC) and structural similarity index measure (SSIM) as metrics. Results: All eight saliency map techniques failed at least one of the criteria and were inferior in performance compared with localization networks. For pneumothorax segmentation, the AUPRC ranged from 0.024 to 0.224, while a U-Net achieved a significantly superior AUPRC of 0.404 (P < .005). For pneumonia detection, the AUPRC ranged from 0.160 to 0.519, while a RetinaNet achieved a significantly superior AUPRC of 0.596 (P < .005). Five and two saliency methods (of eight) failed the model randomization test on the segmentation and detection datasets, respectively, suggesting that these methods are not sensitive to changes in model parameters. The repeatability and reproducibility of the majority of the saliency methods were worse than localization networks for both the segmentation and detection datasets. Conclusion: The use of saliency maps in the high-risk domain of medical imaging warrants additional scrutiny and recommend that detection or segmentation models be used if localization is the desired output of the network. Supplemental material is available for this article. (C) RSNA, 2021.	[Arun, Nishanth; Singh, Praveer; Chang, Ken; Aggarwal, Mehak; Chen, Bryan; Hoebel, Katharina; Gupta, Sharut; Patel, Jay; Gidwani, Mishka; Li, Matthew D.; Kalpathy-Cramer, Jayashree] Harvard Med Sch, Massachusetts Gen Hosp, Athinoula A Martinos Ctr Biomed Imaging, Dept Radiol, 149 13th St, Boston, MA 02129 USA; [Arun, Nishanth] Shiv Nadar Univ, Dept Comp Sci, Greater Noida, India; [Gaw, Nathan] Air Force Inst Technol, Grad Sch Engn & Management, Dept Operat Sci, Dayton, OH USA; [Chang, Ken; Chen, Bryan; Hoebel, Katharina; Patel, Jay; Adebayo, Julius] MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA	Harvard University; Harvard Medical School; Massachusetts General Hospital; Shiv Nadar University; Air Force Institute of Technology; Air Force Institute of Technology Graduate School of Engineering & Management; Air Force Institute of Technology (AFIT); Massachusetts Institute of Technology (MIT)	Kalpathy-Cramer, J (corresponding author), Harvard Med Sch, Massachusetts Gen Hosp, Athinoula A Martinos Ctr Biomed Imaging, Dept Radiol, 149 13th St, Boston, MA 02129 USA.	cramer@mgh.harvard.edu		Patel, Jay/0000-0002-8507-795X; Gidwani, Mishka/0000-0002-8477-2539; Arun, Nishanth/0000-0003-1424-4703; Gupta, Sharut/0000-0003-1848-9935; SINGH, Praveer/0000-0001-6641-2030; Chang, Ken/0000-0001-6956-5059; Hoebel, Katharina/0000-0002-1881-7065	National Institute of Biomedical Imaging and Bioengineering of the National Institutes of Health (NIH) [5T32EB1680]	National Institute of Biomedical Imaging and Bioengineering of the National Institutes of Health (NIH)	K.C. supported in part by a training grant from the National Institute of Biomedical Imaging and Bioengineering of the National Institutes of Health (NIH) (award no. 5T32EB1680). Content is solely the responsibility of the authors and does not necessarily represent the official views of the NIH.	Adebayo J, 2018, ADV NEUR IN, V31; Alzantot M, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON SMART COMPUTING (SMARTCOMP 2019), P81, DOI 10.1109/SMARTCOMP.2019.00033; [Anonymous], SIIM ACRPNEUMOTHORAX; [Anonymous], INCEPTIONV3; [Anonymous], DENSENET121; [Anonymous], RSNA PNEUMONIA DETEC; Bien N, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002699; Boyd Kendrick, 2013, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2013. Proceedings: LNCS 8190, P451, DOI 10.1007/978-3-642-40994-3_29; Chang K, 2020, J AM COLL RADIOL, V17, P1653, DOI 10.1016/j.jacr.2020.05.015; Eitel F, 2020, LECT NOTES COMPUT SC, V11797, P3, DOI 10.1007/978-3-030-33850-3_1; Jeyaraj PR, 2019, J CANCER RES CLIN, V145, P829, DOI 10.1007/s00432-018-02834-7; Li MD, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020200079; Li MD, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0255-1; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Lou B, 2019, LANCET DIGIT HEALTH, V1, pE136, DOI 10.1016/S2589-7500(19)30058-5; Mitani A, 2020, NAT BIOMED ENG, V4, P18, DOI 10.1038/s41551-019-0487-z; Narin A, 2021, PATTERN ANAL APPL, V24, P1207, DOI 10.1007/s10044-021-00984-y; Oakden-Rayner Luke, 2020, Proc ACM Conf Health Inference Learn (2020), V2020, P151, DOI 10.1145/3368555.3384468; Ozenne B, 2015, J CLIN EPIDEMIOL, V68, P855, DOI 10.1016/j.jclinepi.2015.02.010; Renieblas GP, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.3.035501; Rajpurkar P, ARXIV171105225 PREPR; Rajpurkar P, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002686; Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x; Saba T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1413-3; Sayres R, 2019, OPHTHALMOLOGY, V126, P552, DOI 10.1016/j.ophtha.2018.11.016; Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI 10.1007/s11263-019-01228-7; Shih G, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180041; Simonyan K., 2014, WORKSH INT C LEARN R, P1; Singh A, ARXIV200912648; Smilkov D, ARXIV170603825; Springenberg JT., 2014, INT C LEARN REPR ICL; Sundararajan M, 2017, PR MACH LEARN RES, V70; Tolkachev A, 2021, IEEE J BIOMED HEALTH, V25, P1660, DOI 10.1109/JBHI.2020.3023476; Young Kyle, 2019, Interpretability of Machine Intelligence in Medical Image Computing and Multimodal Learning for Clinical Decision Support. Second International Workshop, iMIMIC 2019 and 9th International Workshop, ML-CDS 2019. Held in Conjunction with MICCAI 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11797), P48, DOI 10.1007/978-3-030-33850-3_6; Zar J. H, 2005, ENCY BIOSTATISTICS	35	24	24	4	6	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2021	3	6							e200267	10.1148/ryai.2021200267	http://dx.doi.org/10.1148/ryai.2021200267			12	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9UW	34870212	Green Submitted, Green Published			2022-12-18	WOS:000826914400002
J	Astuto, B; Flament, I; Namiri, NK; Shah, R; Bharadwaj, U; Link, TM; Bucknor, MD; Pedoia, V; Majumdar, S				Astuto, Bruno; Flament, Io; Namiri, Nikan K.; Shah, Rutwik; Bharadwaj, Upasana; Link, Thomas M.; Bucknor, Matthew D.; Pedoia, Valentina; Majumdar, Sharmila			Automatic Deep Learning-assisted Detection and Grading of Abnormalities in Knee MRI Studies	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							CARTILAGE; SCORE; OA	Purpose: To test the hypothesis that artificial intelligence (AI) techniques can aid in identifying and assessing lesion severity in the cartilage, bone marrow, meniscus, and anterior cruciate ligament (ACL) in the knee, improving overall MRI interreader agreement. Materials and Methods: This retrospective study was conducted on 1435 knee MRI studies (n = 294 patients; mean age, 43 years 6 15 [standard deviation]; 153 women) collected within three previous studies (from 2011 to 2014). All MRI studies were acquired using high-spatial-resolution three-dimensional fast-spin-echo CUBE sequence. Three-dimensional convolutional neural networks were developed to detect the regions of interest within MRI studies and grade abnormalities of the cartilage, bone marrow, menisci, and ACL. Evaluation included sensitivity, specificity, and Cohen linear-weighted k. The impact of AI-aided grading in intergrader agreement was assessed on an external dataset. Results: Binary lesion sensitivity reported for all tissues was between 70% and 88%. Specificity ranged from 85% to 89%. The area under the receiver operating characteristic curve for all tissues ranged from 0.83 to 0.93. Deep learning-assisted intergrader Cohen k agreement significantly improved in 10 of 16 comparisons among two attending physicians and two trainees for all tissues. Conclusion: The three-dimensional convolutional neural network had high sensitivity, specificity, and accuracy for knee-lesion-severity scoring and also increased intergrader agreement when used on an external dataset. Supplemental material is available for this article. (C) RSNA, 2021	[Astuto, Bruno; Flament, Io; Namiri, Nikan K.; Shah, Rutwik; Bharadwaj, Upasana; Link, Thomas M.; Bucknor, Matthew D.; Pedoia, Valentina; Majumdar, Sharmila] Univ Calif San Francisco, Ctr Intelligent Imaging, 1700 Fourth St,Suite 201,QB3 Bldg, San Francisco, CA 94107 USA; [Astuto, Bruno; Flament, Io; Namiri, Nikan K.; Shah, Rutwik; Bharadwaj, Upasana; Link, Thomas M.; Bucknor, Matthew D.; Pedoia, Valentina; Majumdar, Sharmila] Univ Calif San Francisco, Musculoskeletal & Quantitat Imaging Res Grp, Dept Radiol & Biomed Imaging, 1700 Fourth St,Suite 201,QB3 Bldg, San Francisco, CA 94107 USA; [Pedoia, Valentina; Majumdar, Sharmila] Univ Calif San Francisco, Ctr Digital Hlth Innovat, 1700 Fourth St,Suite 201,QB3 Bldg, San Francisco, CA 94107 USA	University of California System; University of California San Francisco; University of California System; University of California San Francisco; University of California System; University of California San Francisco	Astuto, B (corresponding author), Univ Calif San Francisco, Ctr Intelligent Imaging, 1700 Fourth St,Suite 201,QB3 Bldg, San Francisco, CA 94107 USA.; Astuto, B (corresponding author), Univ Calif San Francisco, Musculoskeletal & Quantitat Imaging Res Grp, Dept Radiol & Biomed Imaging, 1700 Fourth St,Suite 201,QB3 Bldg, San Francisco, CA 94107 USA.	bruno.astutoarouchenunes@ucsf.edu	Astuto Arouche Nunes, Bruno/C-2367-2014	Astuto Arouche Nunes, Bruno/0000-0002-8890-7963; Namiri, Nikan/0000-0003-2943-9546; Bharadwaj, Upasana/0000-0002-4710-809X; Majumdar, Sharmila/0000-0002-0201-871X; Link, Thomas M./0000-0002-2850-8143	National Institutes of Health (NIH); National Institute of Arthritis and Musculoskeletal and Skin Diseases [R61AR073552, R00AR070902, P50AR060752]; Anterior Cruciate Ligament Arthritis Foundation Study Trial grant [6157]; GE Healthcare; NIH [P50AR060752, R01AR046905]	National Institutes of Health (NIH)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); National Institute of Arthritis and Musculoskeletal and Skin Diseases(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Arthritis & Musculoskeletal & Skin Diseases (NIAMS)); Anterior Cruciate Ligament Arthritis Foundation Study Trial grant; GE Healthcare(General ElectricGE Healthcare); NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	This work was supported by GE Healthcare, National Institutes of Health (NIH), and National Institute of Arthritis and Musculoskeletal and Skin Diseases; Contract grant numbers: R61AR073552 (to S.M., V.P.), R00AR070902 (to V.P.), and P50AR060752 (to S.M.). Medical images considered in this study were collected as part of the NIH-funded grants P50AR060752 and R01AR046905 and the Anterior Cruciate Ligament Arthritis Foundation Study Trial grant 6157.	Aarti Bagul, 2017, Arxiv, DOI arXiv:1711.05225; Alizai H, 2014, RADIOLOGY, V271, P479, DOI 10.1148/radiol.13122056; Bien N, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002699; Choy G, 2018, RADIOLOGY, V288, P318, DOI 10.1148/radiol.2018171820; Eberhardt SC, 2018, RADIOGRAPHICS, V38, P1888, DOI 10.1148/rg.2018180133; Farr Ii Jack, 2013, Open Orthop J, V7, P619, DOI 10.2174/1874325001307010619; Gersing AS, 2017, RADIOLOGY, V284, P508, DOI 10.1148/radiol.2017161005; Gupta S, 2005, RHEUMATOLOGY, V44, P1531, DOI 10.1093/rheumatology/kei049; Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5; Hunter DJ, 2011, OSTEOARTHR CARTILAGE, V19, P990, DOI 10.1016/j.joca.2011.05.004; Jha S, 2020, ACAD RADIOL, V27, P147, DOI 10.1016/j.acra.2019.10.026; Kawano MM, 2015, ACTA ORTOP BRAS, V23, P307, DOI 10.1590/1413-785220152306150596; Liew C, 2018, EUR J RADIOL, V102, P152, DOI 10.1016/j.ejrad.2018.03.019; Liu F, 2019, RADIOL ARTIF INTELL, V1; Liu F, 2018, RADIOLOGY, V289, P160, DOI 10.1148/radiol.2018172986; Lundervold AS, 2019, Z MED PHYS, V29, P102, DOI 10.1016/j.zemedi.2018.11.002; McDonald RJ, 2015, ACAD RADIOL, V22, P1191, DOI 10.1016/j.acra.2015.05.007; McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031; Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79; N. Arun, 2021, medRxiv, DOI 10.1101/2020.07.28.20163899; Namiri NK, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190207; O'Neill TW, 2018, BEST PRACT RES CL RH, V32, P312, DOI 10.1016/j.berh.2018.10.007; Pedoia V, 2019, J MAGN RESON IMAGING, V49, P400, DOI 10.1002/jmri.26246; Peterfy CG, 2004, OSTEOARTHR CARTILAGE, V12, P177, DOI 10.1016/j.joca.2003.11.003; Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI 10.1007/s11263-019-01228-7; Simon AF, 2020, CLIN IMAG, V59, P167, DOI 10.1016/j.clinimag.2019.10.014; Vos T, 2016, LANCET, V388, P1545, DOI [10.1016/S0140-6736(16)31678-6, 10.1016/S0140-6736(16)31012-1]; Wallis A, 2011, CLIN RADIOL, V66, P1015, DOI 10.1016/j.crad.2011.05.013; Wang HY, 2020, IEEE J BIOMED HEALTH, V24, P475, DOI 10.1109/JBHI.2019.2928369; Wang SH, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0932-7; Zhang J, 2018, CIRCULATION, V138, P1623, DOI 10.1161/CIRCULATIONAHA.118.034338	31	20	23	2	6	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2021	3	3							e200165	10.1148/ryai.2021200165	http://dx.doi.org/10.1148/ryai.2021200165			12	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SA	34142088	Green Published			2022-12-18	WOS:000826907000006
J	Tanioka, S; Ishida, F; Yamamoto, A; Shimizu, S; Sakaida, H; Toyoda, M; Kashiwagi, N; Suzuki, H				Tanioka, Satoru; Ishida, Fujimaro; Yamamoto, Atsushi; Shimizu, Shigetoshi; Sakaida, Hiroshi; Toyoda, Mitsuru; Kashiwagi, Nobuhisa; Suzuki, Hidenori			Machine Learning Classification of Cerebral Aneurysm Rupture Status with Morphologic Variables and Hemodynamic Parameters	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							WALL SHEAR-STRESS; INTRACRANIAL ANEURYSMS; RISK STRATIFICATION; IRREGULAR SHAPE; SIZE; RATIO	Purpose: To construct a classification model of rupture status and to clarify the importance of morphologic variables and hemodynamic parameters on rupture status by applying a machine learning (ML) algorithm to morphologic and hemodynamic data of cerebral aneurysms. Materials and Methods: Between 2011 and 2019, 226 (112 ruptured and 114 unruptured) cerebral aneurysms in 188 consecutive patients were retrospectively analyzed with computational fluid dynamics (CFD). A random forest ML algorithm was applied to the results to create three classification models consisting of only morphologic variables (model 1), only hemodynamic parameters (model 2), and both morphologic variables and hemodynamic parameters (model 3). The accuracy of rupture status classification and the importance of each variable or parameter in the models were computed. Results: The accuracy was 77.0% in model 1, 71.2% in model 2, and 78.3% in model 3. The three most important features were projection ratio, size ratio, and aspect ratio in model 1; low shear area ratio, oscillatory shear index, and oscillatory velocity index in model 2; and projection ratio, irregular shape, and size ratio in model 3. Conclusion: Classification models of rupture status of cerebral aneurysms were constructed by applying an ML algorithm to morphologic variables and hemodynamic parameters. The model worked with relatively high accuracy, in which projection ratio, irregular shape, and size ratio were important for the discrimination of ruptured aneurysms. (c) RSNA, 2020	[Tanioka, Satoru; Ishida, Fujimaro] Mie Chuo Med Ctr, Dept Neurosurg, 2158-5 Myojin Cho, Tsu, Mie 5141101, Japan; [Yamamoto, Atsushi; Sakaida, Hiroshi] Kuwana City Med Ctr, Dept Neurosurg, Kuwana, Japan; [Shimizu, Shigetoshi] Suzuka Cent Gen Hosp, Dept Neurosurg, Suzuka, Japan; [Toyoda, Mitsuru; Kashiwagi, Nobuhisa] Inst Stat Math, Sch Stat Thinking, Tachikawa, Tokyo, Japan; [Suzuki, Hidenori] Mie Univ, Dept Neurosurg, Grad Sch Med, Tsu, Mie, Japan	Research Organization of Information & Systems (ROIS); Institute of Statistical Mathematics (ISM) - Japan; Mie University	Tanioka, S (corresponding author), Mie Chuo Med Ctr, Dept Neurosurg, 2158-5 Myojin Cho, Tsu, Mie 5141101, Japan.	satoru.tanioka@umin.net		Ishida, Fujimaro/0000-0001-6324-027X; Suzuki, Hidenori/0000-0002-8555-5448; Toyoda, Mitsuru/0000-0002-2443-4642; Tanioka, Satoru/0000-0002-4678-6163	Scientific Research from Japan Society for the Promotion of Science [17K10825, 18K16556]	Scientific Research from Japan Society for the Promotion of Science(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI))	Supported by Scientific Research from Japan Society for the Promotion of Science (17K10825, 18K16556).	Abboud T, 2017, WORLD NEUROSURG, V99, P610, DOI 10.1016/j.wneu.2016.12.053; [Anonymous], ENS METH; [Anonymous], RANDOM FOREST CLASSI; Berg P, 2013, INT J BIOSCI BIOCH B, V3, P177, DOI DOI 10.7763/IJBBB; Bjorkman J, 2017, STROKE, V48, P1986, DOI 10.1161/STROKEAHA.117.017147; Brinjikji W, 2017, J NEUROINTERV SURG, V9, P376, DOI 10.1136/neurintsurg-2016-012327; Cebral JR, 2011, AM J NEURORADIOL, V32, P264, DOI 10.3174/ajnr.A2274; Cebral JR, 2005, AM J NEURORADIOL, V26, P2550; Chang PD, 2018, AM J NEURORADIOL, V39, P1609, DOI 10.3174/ajnr.A5742; Cornelissen BMW, 2015, AM J NEURORADIOL, V36, P1927, DOI 10.3174/ajnr.A4385; Cui ZX, 2018, NEUROIMAGE, V178, P622, DOI 10.1016/j.neuroimage.2018.06.001; Jiang PJ, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00596; Jing LK, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0132494; Lauric A, 2014, J NEUROINTERV SURG, V6, P466, DOI 10.1136/neurintsurg-2013-010871; Lindgren AE, 2016, STROKE, V47, P1219, DOI 10.1161/STROKEAHA.115.012404; Liu J, 2014, J NEUROINTERV SURG, V6, P658, DOI 10.1136/neurintsurg-2013-010946; Louppe G.., ARXIV 14077502; Miura Y, 2013, STROKE, V44, P519, DOI 10.1161/STROKEAHA.112.675306; Morita A, 2012, NEW ENGL J MED, V366, P2474, DOI 10.1056/NEJMoa1113260; Muhlestein WE, 2019, NEUROSURGERY, V85, P384, DOI 10.1093/neuros/nyy343; Muller AC., 2017, INTRO MACHINE LEARNI; Qian Y, 2011, AM J NEURORADIOL, V32, P1948, DOI 10.3174/ajnr.A2655; Raghavan ML, 2005, J NEUROSURG, V102, P355, DOI 10.3171/jns.2005.102.2.0355; Rahman M, 2010, STROKE, V41, P916, DOI 10.1161/STROKEAHA.109.574244; Sano T, 2017, WORLD NEUROSURG, V98, DOI 10.1016/j.wneu.2016.12.047; Skodvin TO, 2018, J NEUROSURG, V129, P854, DOI 10.3171/2017.5.JNS17195; Takao H, 2012, STROKE, V43, P1436, DOI 10.1161/STROKEAHA.111.640995; Tanioka S, 2019, J NEUROINTERV SURG, V11, P614, DOI 10.1136/neurintsurg-2018-014489; Tsuji M, 2017, J NEUROSURG, V126, P1566, DOI 10.3171/2016.3.JNS152264; Ujiie H, 2001, NEUROSURGERY, V48, P495, DOI 10.1097/00006123-200103000-00007; Urbizu A, 2018, J NEUROSURG, V129, P779, DOI 10.3171/2017.3.JNS162479; Xiang JP, 2015, J NEUROINTERV SURG, V7, P490, DOI 10.1136/neurintsurg-2014-011218; Xiang JP, 2011, STROKE, V42, P144, DOI 10.1161/STROKEAHA.110.592923; Yasuda R, 2011, NEUROSURGERY, V68, P310, DOI 10.1227/NEU.0b013e3182010ed0; Zhang YS, 2016, FRONT NEUROL, V7, DOI 10.3389/fneur.2016.00169	35	20	20	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2020	2	1							e190077	10.1148/ryai.2019190077	http://dx.doi.org/10.1148/ryai.2019190077			7	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CR	33937812	Green Published			2022-12-18	WOS:000826298000006
J	Halling-Brown, MD; Warren, LM; Ward, D; Lewis, E; Mackenzie, A; Wallis, MG; Wilkinson, LS; Given-Wilson, RM; McAvinchey, R; Young, KC				Halling-Brown, Mark D.; Warren, Lucy M.; Ward, Dominic; Lewis, Emma; Mackenzie, Alistair; Wallis, Matthew G.; Wilkinson, Louise S.; Given-Wilson, Rosalind M.; McAvinchey, Rita; Young, Kenneth C.			OPTIMAM Mammography Image Database: A Large-Scale Resource of Mammography Images and Clinical Data	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article									[Halling-Brown, Mark D.; Ward, Dominic; Lewis, Emma] Royal Surrey NHS Fdn Trust, Dept Sci Comp, Egerton Rd, Guildford GU2 7XX, Surrey, England; [Warren, Lucy M.; Mackenzie, Alistair; Young, Kenneth C.] Royal Surrey NHS Fdn Trust, Natl Coordinating Ctr Phys Mammog, Egerton Rd, Guildford GU2 7XX, Surrey, England; [Halling-Brown, Mark D.; Lewis, Emma] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford, Surrey, England; [Young, Kenneth C.] Univ Surrey, Dept Phys, Guildford, Surrey, England; [Wallis, Matthew G.] Cambridge Univ Hosp NHS Fdn Trust, Cambridge Breast Unit, Cambridge, England; [Wallis, Matthew G.] NIHR Cambridge Biomed Res Ctr, Cambridge, England; [Wilkinson, Louise S.] Oxford Univ Hosp NHS Fdn Trust, Oxford Breast Imaging Ctr, Oxford, England; [Given-Wilson, Rosalind M.] St Georges Healthcare NHS Trust, Dept Radiol, London, England; [McAvinchey, Rita] Jarvis Breast Screening Ctr, Guildford, Surrey, England	University of Surrey; University of Surrey; University of Cambridge; University of Cambridge; Oxford University Hospitals NHS Foundation Trust; St Georges University London	Halling-Brown, MD (corresponding author), Royal Surrey NHS Fdn Trust, Dept Sci Comp, Egerton Rd, Guildford GU2 7XX, Surrey, England.; Halling-Brown, MD (corresponding author), Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford, Surrey, England.	mhalling-brown@nhs.net		Halling-Brown, Mark/0000-0002-6247-4768; Mackenzie, Alistair/0000-0003-4545-8018	Google Health UK; Cancer Research UK	Google Health UK(Google Incorporated); Cancer Research UK(Cancer Research UK)	Activities not related to the present article: Royal Surrey NHS Foundation Trust received funding from Google Health UK to support research collaboration in the development and evaluation of Google's AI system for breast cancer screening (McKinney et al. International evaluation of an AI system for breast cancer screening. Nature. Nature Publishing Group; 2020;577(7788): 89-94. doi:10.1038/s41586-019-1799-6); Royal Surrey NHS Foundation Trust receives additional income from Cancer Research UK as a share of payments for commercial licensed access to the OPTIMAM Mammography Image Database. Other relationships: disclosed no relevant relationships. E.L. Activities related to the present article: The development of the database and its ongoing management was and is funded by grants from Cancer Research UK to The Royal Surrey NHS Foundation Trust. Activities not related to the present article: Royal Surrey NHS Foundation Trust received funding from Google Health UK to support research collaboration in the development and evaluation of Google's AI system for breast cancer screening (McKinney et al. International evaluation of an AI system for breast cancer screening. Nature. Nature Publishing Group; 2020; 577(7788):89-94. doi: 10.1038/s41586-019-1799-6); Royal Surrey NHS Foundation Trust receives additional income from Cancer Research UK as a share of payments for commercial licensed access to the OPTIMAM Mammography Image Database. Other relationships: disclosed no relevant relationships. A.M. disclosed no relevant relationships. M. G.W. Activities related to the present article: Cancer Research UK program grant partly funded setup of database. Activities not related to the present article: disclosed no relevant relationships. Other relationships: disclosed no relevant relationships. L.S.W. disclosed no relevant relationships. R.G. W. Activities related to the present article: Cancer Research UK charity grant funding the OPTIMAM project staff undertaking data collection from 2009 to 2019. Activities not related to the present article: disclosed no relevant relationships. Other relationships: disclosed no relevant relationships. R. M. disclosed no relevant relationships. K.C.Y. Activities related to the present article: The development of the database and its ongoing management was and is funded by grants from Cancer Research UK to The Royal Surrey NHS Foundation Trust. Activities not related to the present article: Royal Surrey NHS Foundation Trust received funding from Google Health UK to support research collaboration in the development and evaluation of Google's AI system for breast cancer screening (McKinney et al. International evaluation of an AI system for breast cancer screening. Nature. Nature Publishing Group; 2020; 577(7788):89-94. doi: 10.1038/s41586-019-1799-6); Royal Surrey NHS Foundation Trust receives additional income from Cancer Research UK as a share of payments for commercial licensed access to the OPTIMAM Mammography Image Database. Other relationships: disclosed no relevant relationships. M.D.H.B. Activities related to the present article: The development of the database and its ongoing management was and is funded by grants from Cancer Research UK to The Royal Surrey NHS Foundation Trust. C30682/A28396. Activities not related to the present article: Royal Surrey NHS Foundation Trust received funding from Google Health UK to support research collaboration in the development and evaluation of Google's AI system for breast cancer screening (McKinney et al.; International evaluation of an AI system for breast cancer screening. Nature. Nature Publishing Group; 2020; 577(7788):89-94. doi: 10.1038/s41586-019-1799-6); Royal Surrey NHS Foundation Trust receives additional income from Cancer Research UK as a share of payments for commercial licensed access to the OPTIMAM Mammography Image Database. Other relationships: disclosed no relevant relationships. L. M.W. Activities related to the present article: The development of the database and its ongoing management was and is funded by grants from Cancer Research UK to The Royal Surrey NHS Foundation Trust. Activities not related to the present article: Royal Surrey NHS Foundation Trust received funding from Google Health UK to support research collaboration in the development and evaluation of Google's AI system for breast cancer screening (McKinney et al. International evaluation of an AI system for breast cancer screening. Nature. Nature Publishing Group; 2020;577(7788):89-94. doi:10.1038/s41586-0191799-6); author teaches two lectures a year on a MSc course at the University of Surrey; Royal Surrey NHS Foundation Trust receives additional income from Cancer Research UK as a share of payments for commercial licensed access to the OPTIMAM Mammography Image Database. Other relationships: disclosed no relevant relationships. D.W. Activities related to the present article: The development of the database and its ongoing management was and is funded by grants from Cancer Research UK to The Royal Surrey NHS Foundation Trust.	Agarwal R, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103774; Alam N, 2019, J IMAGING, V5, DOI 10.3390/jimaging5090076; [Anonymous], OMI DB OPTIMAM MAMMO; Burnside ES, USING QUANTITATIVE B; Debelee TG, 2020, EVOL SYST-GER, V11, P143, DOI 10.1007/s12530-019-09297-2; Halling-Brown M, 2019, ARTIF INTELL; Halling-Brown MD, 2014, PROC SPIE, V9039, DOI 10.1117/12.2041674; Kim HE, 2020, LANCET DIGIT HEALTH, V2, pE138, DOI 10.1016/S2589-7500(20)30003-0; Looney PT, 2016, RADIAT PROT DOSIM, V169, P32, DOI 10.1093/rpd/ncv482; Mackenzie A, 2016, EUR RADIOL, V26, P874, DOI 10.1007/s00330-015-3885-y; McKinney SM, 2020, NATURE, V577, P89, DOI 10.1038/s41586-019-1799-6; NHS Breast Screening Programme, AGEX TRIAL; Patel MN, 2015, PROC SPIE, V9418, DOI 10.1117/12.2082114; Patel MN, 2014, PROC SPIE, V9039, DOI 10.1117/12.2043656; Patnick J, NATIONWIDE CLUSTER R, DOI [10.1186/IS-RCTN33292440, DOI 10.1186/IS-RCTN33292440]; Warren LM, 2019, PROC SPIE, V10952, DOI 10.1117/12.2512252; Warren LM, 2017, CLIN RADIOL, V72, DOI 10.1016/j.crad.2017.03.024	17	18	18	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2021	3	1							e200103	10.1148/ryai.2020200103	http://dx.doi.org/10.1148/ryai.2020200103			6	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z3HE	33937853	Green Published, Green Submitted			2022-12-18	WOS:000826472300006
J	Weisman, AJ; Kieler, MW; Perlman, SB; Hutchings, M; Jeraj, R; Kostakoglu, L; Bradshaw, TJ				Weisman, Amy J.; Kieler, Minnie W.; Perlman, Scott B.; Hutchings, Martin; Jeraj, Robert; Kostakoglu, Lale; Bradshaw, Tyler J.			Convolutional Neural Networks for Automated PET/CT Detection of Diseased Lymph Node Burden in Patients with Lymphoma	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To automatically detect lymph nodes involved in lymphoma on fluorine 18 (F-18) fluorodeoxyglucose (FDG) PET/CT images using convolutional neural networks (CNNs). Materials and Methods: In this retrospective study, baseline disease of 90 patients with lymphoma was segmented on F-18-FDG PET/CT images (acquired between 2005 and 2011) by a nuclear medicine physician. An ensemble of three-dimensional patch-based, multiresolution pathway CNNs was trained using fivefold cross-validation. Performance was assessed using the true-positive rate (TPR) and number of false-positive (FP) findings. CNN performance was compared with agreement between physicians by comparing the annotations of a second nuclear medicine physician to the first reader in 20 of the patients. Patient TPR was compared using Wilcoxon signed rank tests. Results: Across all 90 patients, a range of 0-61 nodes per patient was detected. At an average of four FP findings per patient, the method achieved a TPR of 85% (923 of 1087 nodes). Performance varied widely across patients (TPR range, 33%-100%; FP range, 0-21 findings). In the 20 patients labeled by both physicians, a range of 1-49 nodes per patient was detected and labeled. The second reader identified 96% (210 of 219) of nodes with an additional 3.7 per patient compared with the first reader. In the same 20 patients, the CNN achieved a 90% (197 of 219) TPR at 3.7 FP findings per patient. Conclusion: An ensemble of three-dimensional CNNs detected lymph nodes at a performance nearly comparable to differences between two physicians' annotations. This preliminary study is a first step toward automated PET/CT assessment for lymphoma. (C) RSNA, 2020	[Weisman, Amy J.; Jeraj, Robert] Univ Wisconsin, Dept Med Phys, Madison, WI 53705 USA; [Kieler, Minnie W.; Perlman, Scott B.; Bradshaw, Tyler J.] Univ Wisconsin, Wisconsin Inst Med Res, Dept Radiol, 1111 Highland Ave,Room 1005, Madison, WI 53705 USA; [Hutchings, Martin] Rigshosp, Dept Hematol, Copenhagen, Denmark; [Jeraj, Robert] Univ Ljubljana, Fac Math & Phys, Ljubljana, Slovenia; [Kostakoglu, Lale] Univ Virginia, Dept Radiol & Med Imaging, Charlottesville, VA USA		Bradshaw, TJ (corresponding author), Univ Wisconsin, Wisconsin Inst Med Res, Dept Radiol, 1111 Highland Ave,Room 1005, Madison, WI 53705 USA.	tbradshaw@wisc.edu	Hutchings, Martin/B-6959-2012	Hutchings, Martin/0000-0003-3873-1741; Weisman, Amy/0000-0001-5230-7782; Bradshaw, Tyler/0000-0001-9549-7002	GE Healthcare; UW Carbone Cancer Center	GE Healthcare(General ElectricGE Healthcare); UW Carbone Cancer Center	A.J.W. Activities related to the present article: disclosed money paid to institution for research support by GE Healthcare. Activities not related to the present article: disclosed no relevant relationships. Other relationships: disclosed no relevant relationships. M.W.K. disclosed no relevant relationships. S.B.P. disclosed no relevant relationships. M.H. disclosed no relevant relationships. R.J. Activities related to the present article: disclosed grant money paid to institution by the National Cancer Institute, in part supported by the UW Carbone Cancer Center. Activities not related to the present article: disclosed no relevant relationships. Other relationships: disclosed patent issued by WARF and patent pending with AIQ Solutions. L.K. Activities related to the present article: disclosed no relevant relationships. Activities not related to the present article: disclosed money paid for consultancy by Roche, Genentech. Other relationships: disclosed no relevant relationships. T.J.B. Activities related to the present article: disclosed no relevant relationships. Activities not related to the present article: disclosed no relevant relationships. Other relationships: institution receives research support from GE Healthcare.	Barrington SE, 2019, J NUCL MED, V60, P1096, DOI 10.2967/jnumed.119.227249; Barrington SF, 2014, BRIT J HAEMATOL, V164, P315, DOI 10.1111/bjh.12601; Ben Bouallegue F, 2017, MED PHYS, V44, P4608, DOI 10.1002/mp.12349; Bi L, 2017, COMPUT MED IMAG GRAP, V60, P3, DOI 10.1016/j.compmedimag.2016.11.008; Ceriani L, 2018, BLOOD, V132, P179, DOI 10.1182/blood-2018-01-826958; Cottereau AS, 2018, J NUCL MED, V59, P589, DOI 10.2967/jnumed.117.193946; Cottereau AS, 2017, J NUCL MED, V58, P276, DOI 10.2967/jnumed.116.180406; Decazes P, 2018, EUR J NUCL MED MOL I, V45, P1672, DOI 10.1007/s00259-018-4041-0; Dou Q, 2017, MED IMAGE ANAL, V41, P40, DOI 10.1016/j.media.2017.05.001; Grossiord E, 2017, I S BIOMED IMAGING, P174, DOI 10.1109/ISBI.2017.7950495; Hinton G., NEURAL NETWORKS MACH; Hu HG, 2019, INT J COMPUT ASS RAD, V14, P1715, DOI 10.1007/s11548-019-02049-2; Hutchings M, 2014, J CLIN ONCOL, V32, P2705, DOI 10.1200/JCO.2013.53.2838; Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004; Kline TL, 2017, J DIGIT IMAGING, V30, P442, DOI 10.1007/s10278-017-9978-1; Kostakoglu L, 2019, PET CLIN, V14, P317, DOI 10.1016/j.cpet.2019.03.002; Meignan M, 2009, LEUKEMIA LYMPHOMA, V50, P1257, DOI 10.1080/10428190903040048; Mettler J, 2018, J NUCL MED; Milgrom SA, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-37197-z; Mylam KJ, 2015, LEUKEMIA LYMPHOMA, V56, P2005, DOI 10.3109/10428194.2014.975800; Roth HR, 2014, LECT NOTES COMPUT SC, V8673, P520, DOI 10.1007/978-3-319-10404-1_65; Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162; Yu YT, 2018, COMPUT MED IMAG GRAP, V70, P1, DOI 10.1016/j.compmedimag.2018.09.001	23	18	18	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2020	2	5							e200016	10.1148/ryai.2020200016	http://dx.doi.org/10.1148/ryai.2020200016			8	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CY	33937842	Green Published, Bronze			2022-12-18	WOS:000826477600008
J	Erickson, BJ				Erickson, Bradley J.			Magician's Corner: 3. Image Wrangling	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Erickson, Bradley J.] Mayo Clin, Dept Radiol, 200 First St SW, Rochester, MN 55905 USA		Erickson, BJ (corresponding author), Mayo Clin, Dept Radiol, 200 First St SW, Rochester, MN 55905 USA.	bje@mayo.edu		Erickson, Bradley/0000-0001-7926-6095				Erickson Bradley J, 2019, Radiol Artif Intell, V1, pe190113, DOI 10.1148/ryai.2019190113; Erickson BJ, 2019, RADIOL-ARTIF INTELL, V1, DOI [10.1148/ryai.2019190072, 10.1148/ryai.2019190113, 10.1148/ryai.2019190126]; Tustison NJ, 2010, IEEE T MED IMAGING, V29, P1310, DOI 10.1109/TMI.2010.2046908	3	18	17	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2019	1	6							e190126	10.1148/ryai.2019190126	http://dx.doi.org/10.1148/ryai.2019190126			3	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CQ	33937797	Bronze, Green Published			2022-12-18	WOS:000826296100007
J	Erickson, BJ				Erickson, Bradley J.			Magician's Corner: 2. Optimizing a Simple Image Classifier	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Erickson, Bradley J.] Mayo Clin, Dept Radiol, 200 First St SW, Rochester, MN 55905 USA		Erickson, BJ (corresponding author), Mayo Clin, Dept Radiol, 200 First St SW, Rochester, MN 55905 USA.	bje@mayo.edu		Erickson, Bradley/0000-0001-7926-6095				Erickson BJ, 2019, RADIOL-ARTIF INTELL, V1, DOI [10.1148/ryai.2019190072, 10.1148/ryai.2019190113, 10.1148/ryai.2019190126]; Gadermayr M, 2019, J MAGN RESON IMAGING, V49, P1676, DOI 10.1002/jmri.26544; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Li FF, 2010, J VISUAL-JAPAN, V9, P1037, DOI DOI 10.1167/9.8.1037; Tustison NJ, 2019, ACAD RADIOL, V26, P412, DOI 10.1016/j.acra.2018.08.003	6	18	17	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2019	1	5							e190113	10.1148/ryai.2019190113	http://dx.doi.org/10.1148/ryai.2019190113			4	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CP	33937797	Green Published			2022-12-18	WOS:000826294400004
J	Erickson, BJ				Erickson, Bradley J.			Magician's Corner: How to Start Learning about Deep Learning	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Erickson, Bradley J.] Mayo Clin, Dept Radiol, Mayo Bldg E2,200 First St SW, Rochester, MN 55905 USA		Erickson, BJ (corresponding author), Mayo Clin, Dept Radiol, Mayo Bldg E2,200 First St SW, Rochester, MN 55905 USA.	bje@mayo.edu		Erickson, Bradley/0000-0001-7926-6095					0	18	17	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2019	1	4							e190072	10.1148/ryai.2019190072	http://dx.doi.org/10.1148/ryai.2019190072			4	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CO	33937797	Green Published			2022-12-18	WOS:000826292900005
J	Chen, M; Li, HL; Wang, JH; Dillman, JR; Parikh, NA; He, LL				Chen, Ming; Li, Hailong; Wang, Jinghua; Dillman, Jonathan R.; Parikh, Nehal A.; He, Lili			A Multichannel Deep Neural Network Model Analyzing Multiscale Functional Brain Connectome Data for Attention Deficit Hyperactivity Disorder Detection	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							MILD COGNITIVE IMPAIRMENT; LEARNING APPROACH; FMRI; PARCELLATION; DIAGNOSIS	Purpose: To develop a multichannel deep neural network (mcDNN) classification model based on multiscale brain functional connectome data and demonstrate the value of this model by using attention deficit hyperactivity disorder (ADHD) detection as an example. Materials and Methods: In this retrospective case-control study, existing data from the Neuro Bureau ADHD-200 dataset consisting of 973 participants were used. Multiscale functional brain connectomes based on both anatomic and functional criteria were constructed. The mcDNN model used the multiscale brain connectome data and personal characteristic data (PCD) as joint features to detect ADHD and identify the most predictive brain connectome features for ADHD diagnosis. The mcDNN model was compared with single-channel deep neural network (scDNN) models and the classification performance was evaluated through cross-validation and hold-out validation with the metrics of accuracy, sensitivity, specificity, and area under the receiver operating characteristic curve (AUC). Results: In the cross-validation, the mcDNN model using combined features (fusion of the multiscale brain connectome data and PCD) achieved the best performance in ADHD detection with an AUC of 0.82 (95% confidence interval [CI]: 0.80, 0.83) compared with scDNN models using the features of the brain connectome at each individual scale and PCD, independently. In the hold-out validation, the mcDNN model achieved an AUC of 0.74 (95% CI: 0.73, 0.76). Conclusion: An mcDNN model was developed for multiscale brain functional connectome data, and its utility for ADHD detection was demonstrated. By fusing the multiscale brain connectome data, the mcDNN model improved ADHD detection performance considerably over the use of a single scale. (c) RSNA, 2019	[Chen, Ming; Li, Hailong; Parikh, Nehal A.; He, Lili] Univ Cincinnati, Perinatal Inst, Dept Pediat, Cincinnati, OH 45221 USA; [Chen, Ming] Univ Cincinnati, Dept Elect Engn & Comp Sci, Cincinnati, OH USA; [Dillman, Jonathan R.] Cincinnati Childrens Hosp Med Ctr, Dept Radiol, 3333 Burnet Ave,MLC 7009, Cincinnati, OH 45229 USA; [Wang, Jinghua; Dillman, Jonathan R.] Univ Cincinnati, Coll Med, Dept Radiol, Cincinnati, OH USA; [Parikh, Nehal A.; He, Lili] Univ Cincinnati, Coll Med, Dept Pediat, Cincinnati, OH 45221 USA	University System of Ohio; University of Cincinnati; University System of Ohio; University of Cincinnati; Cincinnati Children's Hospital Medical Center; University System of Ohio; University of Cincinnati; University System of Ohio; University of Cincinnati	He, LL (corresponding author), Univ Cincinnati, Perinatal Inst, Dept Pediat, Cincinnati, OH 45221 USA.; He, LL (corresponding author), Univ Cincinnati, Coll Med, Dept Pediat, Cincinnati, OH 45221 USA.	lili.hei@cchmc.org		Parikh, Nehal/0000-0002-1375-1247; Dillman, Jonathan/0000-0003-0124-0164	National Institutes of Health [R21-HD094085, R01-NS094200, R01-NS096037]; Cincinnati Children's Hospital Medical Center	National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Cincinnati Children's Hospital Medical Center	Work supported by National Institutes of Health grants (R21-HD094085, R01-NS094200, and R01-NS096037) and a Trustee grant from Cincinnati Children's Hospital Medical Center. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.	Acuna C, 2012, FRONT SYST NEUROSCI, V6, DOI 10.3389/fnsys.2012.00062; Ambastha AK, 2017, STUD HEALTH TECHNOL, V245, P1249, DOI 10.3233/978-1-61499-830-3-1249; American Psychiatric Association, 2013, DSM V DIAGN STAT MAN, DOI [10.1176/appi.books.9780890425596, DOI 10.1176/APPI.BOOKS.9780890425596]; Bellec P, 2017, NEUROIMAGE, V144, P275, DOI 10.1016/j.neuroimage.2016.06.034; Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006; Betzel RF, 2017, NEUROIMAGE, V160, P73, DOI 10.1016/j.neuroimage.2016.11.006; Biederman J, 2005, BIOL PSYCHIAT, V57, P1215, DOI 10.1016/j.biopsych.2004.10.020; Brown MRG, 2012, FRONT SYST NEUROSCI, V6, DOI 10.3389/fnsys.2012.00069; Craddock RC, 2012, HUM BRAIN MAPP, V33, P1914, DOI 10.1002/hbm.21333; Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021; Dey S, 2014, FRONT NEURAL CIRCUIT, V8, DOI 10.3389/fncir.2014.00064; Diez I, 2015, SCI REP-UK, V5, DOI 10.1038/srep10532; Fair DA, 2013, FRONT SYST NEUROSCI, V6, DOI 10.3389/fnsys.2012.00080; Fei F, 2014, BRAIN CONNECT, V4, P347, DOI 10.1089/brain.2013.0214; Glasser MF, 2016, NAT NEUROSCI, V19, P1175, DOI 10.1038/nn.4361; Glasser MF, 2016, NATURE, V536, P171, DOI 10.1038/nature18933; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; He LL, 2018, NEUROIMAGE-CLIN, V18, P290, DOI 10.1016/j.nicl.2018.01.032; Kaczkurkin AN, 2019, NEUROPSYCHOPHARMACOL, V44, P71, DOI 10.1038/s41386-018-0111-z; Khazaee A, 2016, BRAIN IMAGING BEHAV, V10, P799, DOI 10.1007/s11682-015-9448-7; Kingma D.P, P 3 INT C LEARNING R; Li HL, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00491; Riaz A, 2018, COMPUT MED IMAG GRAP, V65, P115, DOI 10.1016/j.compmedimag.2017.10.002; Sen B, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194856; Sidhu GS, 2012, FRONT SYST NEUROSCI, V6, DOI 10.3389/fnsys.2012.00074; Simonyan K., 2014, WORKSH INT C LEARN R, P1; Siqueira AD, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/380531; Sporns O, 2013, NEUROIMAGE, V80, P53, DOI 10.1016/j.neuroimage.2013.03.023; Tafazoli S, 2013, J PSYCHIATR RES, V47, P505, DOI 10.1016/j.jpsychires.2012.11.011; Tian LX, 2008, BRAIN DEV-JPN, V30, P342, DOI 10.1016/j.braindev.2007.10.005; Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978; Valera EM, 2010, BIOL PSYCHIAT, V68, P359, DOI 10.1016/j.biopsych.2010.05.012; van den Heuvel OA, 2016, EUR NEUROPSYCHOPHARM, V26, P810, DOI 10.1016/j.euroneuro.2015.12.005; Wee CY, 2016, CNS NEUROSCI THER, V22, P212, DOI 10.1111/cns.12499; Zalesky A, 2010, NEUROIMAGE, V50, P970, DOI 10.1016/j.neuroimage.2009.12.027; Zhu CZ, 2008, NEUROIMAGE, V40, P110, DOI 10.1016/j.neuroimage.2007.11.029	36	17	17	2	5	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2020	2	1							e190012	10.1148/ryai.2019190012	http://dx.doi.org/10.1148/ryai.2019190012			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CR	32076663	Bronze, Green Published			2022-12-18	WOS:000826298000002
J	Pan, I; Thodberg, HH; Halabi, SS; Kalpathy-Cramer, J; Larson, DB				Pan, Ian; Thodberg, Hans Henrik; Halabi, Safwan S.; Kalpathy-Cramer, Jayashree; Larson, David B.			Improving Automated Pediatric Bone Age Estimation Using Ensembles of Models from the 2017 RSNA Machine Learning Challenge	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To investigate improvements in performance for automatic bone age estimation that can be gained through model ensembling. Materials and Methods: A total of 48 submissions from the 2017 RSNA Pediatric Bone Age Machine Learning Challenge were used. Participants were provided with 12611 pediatric hand radiographs with bone ages determined by a pediatric radiologist to develop models for bone age determination. The final results were determined using a test set of 200 radiographs labeled with the weighted average of six ratings. The mean pairwise model correlation and performance of all possible model combinations for ensembles of up to 10 models using the mean absolute deviation (MAD) were evaluated. A bootstrap analysis using the 200 test radiographs was conducted to estimate the true generalization MAD. Results: The estimated generalization MAD of a single model was 4.55 months. The best-performing ensemble consisted of four models with an MAD of 3.79 months. The mean pairwise correlation of models within this ensemble was 0.47. In comparison, the lowest achievable MAD by combining the highest-ranking models based on individual scores was 3.93 months using eight models with a mean pairwise model correlation of 0.67. Conclusion: Combining less-correlated, high-performing models resulted in better performance than naively combining the top-performing models. Machine learning competitions within radiology should be encouraged to spur development of heterogeneous models whose predictions can be combined to achieve optimal performance. Supplemental material is available for this article. (c) RSNA, 2019	[Pan, Ian] Brown Univ, Warren Alpert Med Sch, Dept Radiol, 593 Eddy St, Providence, RI 02903 USA; [Pan, Ian] Rhode Isl Hosp, Dept Diagnost Imaging, Providence, RI 02903 USA; [Thodberg, Hans Henrik] Visiana, Horsholm, Denmark; [Halabi, Safwan S.; Larson, David B.] Stanford Univ, Dept Radiol, Palo Alto, CA 94304 USA; [Kalpathy-Cramer, Jayashree] Harvard Med Sch, Massachusetts Gen Hosp, Athinoula A Martinos Ctr Biomed Imaging, Dept Radiol, Boston, MA 02115 USA		Pan, I (corresponding author), Brown Univ, Warren Alpert Med Sch, Dept Radiol, 593 Eddy St, Providence, RI 02903 USA.; Pan, I (corresponding author), Rhode Isl Hosp, Dept Diagnost Imaging, Providence, RI 02903 USA.	ianpan358@gmail.com	Halabi, Safwan S/H-2279-2018; Pan, Ian/ABD-3474-2021	Halabi, Safwan S/0000-0003-1317-984X; Pan, Ian/0000-0002-0650-6614; Kalpathy-Cramer, Jayashree/0000-0001-8906-9618				Bien N, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002699; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1; Dunnmon JA, 2019, RADIOLOGY, V290, P537, DOI 10.1148/radiol.2018181422; Gelbrich B, 2015, ANN HUM BIOL, V42, P389, DOI 10.3109/03014460.2015.1046487; Greulich W.W., 1971, RADIOGRAPHIC ATLAS S; Halabi SS, 2019, RADIOLOGY, V290, P498, DOI 10.1148/radiol.2018180736; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Ju C, 2018, J APPL STAT, V45, P2800, DOI 10.1080/02664763.2018.1441383; Kahn CE, 2012, J DIGIT IMAGING, V25, P37, DOI 10.1007/s10278-011-9399-5; Lakhani P, 2017, RADIOLOGY, V284, P574, DOI 10.1148/radiol.2017162326; Larson DB, 2018, RADIOLOGY, V287, P313, DOI 10.1148/radiol.2017170236; Nanni L., 2020, APPL COMPUT INFORM, DOI [10.1016/j.aci.2018.06.002, DOI 10.1016/J.ACI.2018.06.002]; Norman B, 2019, J DIGIT IMAGING, V32, P471, DOI 10.1007/s10278-018-0098-3; Prevedello LM, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180031; Rodriguez-Ruiz A, 2019, RADIOLOGY, V290, P305, DOI 10.1148/radiol.2018181371; Tajmir SH, 2019, SKELETAL RADIOL, V48, P275, DOI 10.1007/s00256-018-3033-2	16	17	17	0	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2019	1	6							e190053	10.1148/ryai.2019190053	http://dx.doi.org/10.1148/ryai.2019190053			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CQ	32090207	Green Published			2022-12-18	WOS:000826296100006
J	Du, R; Lee, VH; Yuan, H; Lam, KO; Pang, HH; Chen, Y; Lam, EY; Khong, PL; Lee, AW; Kwong, DL; Vardhanabhuti, V				Du, Richard; Lee, Victor H.; Yuan, Hui; Lam, Ka-On; Pang, Herbert H.; Chen, Yu; Lam, Edmund Y.; Khong, Pek-Lan; Lee, Anne W.; Kwong, Dora L.; Vardhanabhuti, Varut			Radiomics Model to Predict Early Progression of Nonmetastatic Nasopharyngeal Carcinoma after Intensity Modulation Radiation Therapy: A Multicenter Study	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							CONVENTIONAL 2-DIMENSIONAL RADIOTHERAPY; PROGNOSTIC VALUE; PHASE-II; CHEMOTHERAPY; RECURRENT; OUTCOMES; IMAGES; VOLUME; MRI; DNA	Purpose: To examine the prognostic value of a machine learning model trained with pretreatment MRI radiomic features in the assessment of patients with nonmetastatic nasopharyngeal carcinoma (NPC) who are at risk for 3-year disease progression after intensity-modulated radiation therapy and to explain the radiomics features in the model. Materials and Methods: A total of 277 patients with nonmetastatic NPC admitted between March 2008 and December 2014 at two imaging centers were retrospectively reviewed. Patients were allocated to a discovery or validation cohort based on where they underwent MRI (discovery cohort, n = 217; validation cohort, n = 60). A total of 525 radiomics features extracted from contrast material-enhanced T1- or T2-weighted MRI studies and five clinical features were subjected to radiomic machine learning modeling to predict 3-year disease progression. Feature selection was performed by analyzing robustness to resampling, reproducibility between observers, and redundancy. Features for the final model were selected with Kaplan-Meier analysis and the log-rank test. A support vector machine was used as the classifier for the model. To interpret the pattern learned from the model, Shapley additive explanations (SHAP) was applied. Results: The final model yielded an area under the receiver operating characteristic curve of 0.80 in both the discovery (95% bootstrap confidence interval: 0.80, 0.81) and independent validation (95% bootstrap confidence interval: 0.73, 0.89) cohorts. Analysis with SHAP revealed that tumor shape sphericity, first-order mean absolute deviation, T stage, and overall stage were important factors in 3-year disease progression. Conclusion: These results add to the growing evidence of the role of radiomics in the assessment of NPC. By using explanatory techniques, such as SHAP, the complex interaction of features learned by the model may be understood. (C) RSNA, 2019	[Du, Richard; Yuan, Hui; Khong, Pek-Lan; Vardhanabhuti, Varut] Univ Hong Kong, Queen Mary Hosp, Li Ka Shing Fac Med, Sch Publ Hlth,Dept Diagnost Radiol, Room 406,Block K,Pok Fu Lam Rd, Hong Kong, Peoples R China; [Lee, Victor H.; Lam, Ka-On; Lee, Anne W.; Kwong, Dora L.] Univ Hong Kong, Queen Mary Hosp, Li Ka Shing Fac Med, Sch Publ Hlth,Dept Clin Oncol, Room 406,Block K,Pok Fu Lam Rd, Hong Kong, Peoples R China; [Pang, Herbert H.] Univ Hong Kong, Queen Mary Hosp, Li Ka Shing Fac Med, Sch Publ Hlth, Room 406,Block K,Pok Fu Lam Rd, Hong Kong, Peoples R China; [Chen, Yu] Chinese Acad Med Sci, Peking Union Med Coll Hosp, Dept Radiol, Beijing, Peoples R China; [Lam, Edmund Y.] Univ Hong Kong, Fac Engn, Dept Elect & Elect Engn, Hong Kong, Peoples R China	University of Hong Kong; University of Hong Kong; University of Hong Kong; Chinese Academy of Medical Sciences - Peking Union Medical College; Peking Union Medical College Hospital; University of Hong Kong	Vardhanabhuti, V (corresponding author), Univ Hong Kong, Queen Mary Hosp, Li Ka Shing Fac Med, Sch Publ Hlth,Dept Diagnost Radiol, Room 406,Block K,Pok Fu Lam Rd, Hong Kong, Peoples R China.	varv@hku.hk	Du, Richard/AAV-6150-2020; Du, Richard/AAV-6147-2020; Lam, Edmund/C-1853-2009; /D-7948-2011	Du, Richard/0000-0002-2062-1109; Du, Richard/0000-0002-2062-1109; Lam, Edmund/0000-0001-6268-950X; /0000-0002-7523-5088; Pang, Herbert/0000-0002-7896-6716; Yuan, Hui/0000-0002-9122-3407	Research Grants Council, University Grants Committee [AoE M-06/08]; University Research Committee, University of Hong Kong [201611159216]; Lee Shau Kee Foundation	Research Grants Council, University Grants Committee; University Research Committee, University of Hong Kong(University of Hong Kong); Lee Shau Kee Foundation	Supported by the Research Grants Council, University Grants Committee (AoE M-06/08), University Research Committee, University of Hong Kong (201611159216), and the Lee Shau Kee Foundation.	Aerts HJWL, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5006; Aktan M, 2017, RADIOL MED; Au KH, 2018, ORAL ONCOL, V77, P16, DOI 10.1016/j.oraloncology.2017.12.004; Brier G. W., 1950, MON WEATHER REV, V78, P1, DOI [10.1175/1520-0493(1950)0782.0.co;2, DOI 10.1175/1520-0493(1950)078<0001:VOFEIT>2.0.CO;2]; Chua DTT, 2008, HEAD NECK-J SCI SPEC, V30, P863, DOI 10.1002/hed.20792; Chua DTT, 1997, INT J RADIAT ONCOL, V39, P711, DOI 10.1016/S0360-3016(97)00374-X; Chua MLK, 2016, LANCET, V387, P1012, DOI 10.1016/S0140-6736(15)00055-0; Gillies RJ, 2016, RADIOLOGY, V278, P563, DOI 10.1148/radiol.2015151169; Hsieh JCH, 2015, JPN J CLIN ONCOL, V45, P819, DOI 10.1093/jjco/hyv083; Hsieh TC, 2015, ONCOLOGIST, V20, P539, DOI 10.1634/theoncologist.2014-0291; Jones E., 2001, SCIPY OPEN SOURCE SC; Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012; Lai SZ, 2011, INT J RADIAT ONCOL, V80, P661, DOI 10.1016/j.ijrobp.2010.03.024; Lambin P, 2012, EUR J CANCER, V48, P441, DOI 10.1016/j.ejca.2011.11.036; Lee AWM, 2015, J CLIN ONCOL, V33, P3356, DOI 10.1200/JCO.2015.60.9347; Lee VHF, 2017, ONCOTARGET, V8, P5292, DOI 10.18632/oncotarget.14137; Li WF, 2017, CHIN J CANCER, V36, DOI 10.1186/s40880-017-0256-x; Lin J, 2017, ONCOTARGET, V8, P33884, DOI 10.18632/oncotarget.13934; Liu J, 2016, J MAGN RESON IMAGING, V44, P445, DOI 10.1002/jmri.25156; Liu LT, 2017, RADIOLOGY, V282, P171, DOI 10.1148/radiol.2016152540; Lundberg SM, 2017, ADV NEUR IN, V30; Lundberg SM, 2018, NAT BIOMED ENG, V2, P749, DOI 10.1038/s41551-018-0304-0; Neri E, 2018, INSIGHTS IMAGING, V9, P915, DOI 10.1007/s13244-018-0657-7; Ouyang FS, 2017, ONCOTARGET, V8, P74869, DOI 10.18632/oncotarget.20423; Pedregosa F., 2011, J MACH LEARN RES, V12, P2825; Peng G, 2012, RADIOTHER ONCOL, V104, P286, DOI 10.1016/j.radonc.2012.08.013; Ribeiro MT, KDD16 P 22 ACM; Shen CY, 2008, LARYNGOSCOPE, V118, P1206, DOI 10.1097/MLG.0b013e31816ed587; Tang LL, 2016, CANCER LETT, V374, P22, DOI 10.1016/j.canlet.2016.01.040; van Griethuysen JJM, 2017, CANCER RES, V77, pE104, DOI 10.1158/0008-5472.CAN-17-0339; Yuan H, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-10423-w; Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015; Zhang B, 2017, ONCOTARGET, V8, P72457, DOI 10.18632/oncotarget.19799; Zhang B, 2017, CLIN CANCER RES, V23, P4259, DOI 10.1158/1078-0432.CCR-16-2910; Zhang MX, 2015, EUR J CANCER, V51, P2587, DOI 10.1016/j.ejca.2015.08.006	35	17	17	2	6	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2019	1	4							e180075	10.1148/ryai.2019180075	http://dx.doi.org/10.1148/ryai.2019180075			11	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CO	33937796	Green Published			2022-12-18	WOS:000826292900002
J	Hoebel, KV; Patel, JB; Beers, AL; Chang, K; Singh, P; Brown, JM; Pinho, MC; Batchelor, TT; Gerstner, ER; Rosen, BR; Kalpathy-Cramer, J				Hoebel, Katharina, V; Patel, Jay B.; Beers, Andrew L.; Chang, Ken; Singh, Praveer; Brown, James M.; Pinho, Marco C.; Batchelor, Tracy T.; Gerstner, Elizabeth R.; Rosen, Bruce R.; Kalpathy-Cramer, Jayashree			Radiomics Repeatability Pitfalls in a Scan-Rescan MRI Study of Glioblastoma	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							PERFORMANCE; IMAGES	Purpose: To determine the influence of preprocessing on the repeatability and redundancy of radiomics features extracted using a popular open-source radiomics software package in a scan-rescan glioblastoma MRI study. Materials and Methods: In this study, a secondary analysis of T2-weighted fluid-attenuated inversion recovery (FLAIR) and T1-weighted postcontrast images from 48 patients (mean age, 56 years [range, 22-77 years]) diagnosed with glioblastoma were included from two prospective studies (ClinicalTrials.gov NCT00662506 [2009-2011] and NCT00756106 [2008-2011]). All patients underwent two baseline scans 2-6 days apart using identical imaging protocols on 3-T MRI systems. No treatment occurred between scan and rescan, and tumors were essentially unchanged visually. Radiomic features were extracted by using PyRadiomics (https://pyradiomics.readthedocs.io/) under varying conditions, including normalization strategies and intensity quantization. Subsequently, intraclass correlation coefficients were determined between feature values of the scan and rescan. Results: Shape features showed a higher repeatability than intensity (adjusted P<.001) and texture features (adjusted P<.001) for both T2-weighted FLAIR and T1-weighted postcontrast images. Normalization improved the overlap between the region of interest intensity histograms of scan and rescan (adjusted P<.001 for both T2-weighted FLAIR and T1-weighted postcontrast images), except in scans where brain extraction fails. As such, normalization significantly improves the repeatability of intensity features from T2-weighted FLAIR scans (adjusted P=.003 [z score normalization] and adjusted P=.002 [histogram matching]). The use of a relative intensity binning strategy as opposed to default absolute intensity binning reduces correlation between gray-level co-occurrence matrix features after normalization. Conclusion: Both normalization and intensity quantization have an effect on the level of repeatability and redundancy of features, emphasizing the importance of both accurate reporting of methodology in radiomics articles and understanding the limitations of choices made in pipeline design. (C) RSNA, 2020	[Hoebel, Katharina, V; Patel, Jay B.; Beers, Andrew L.; Chang, Ken; Singh, Praveer; Brown, James M.; Pinho, Marco C.; Rosen, Bruce R.; Kalpathy-Cramer, Jayashree] Massachusetts Gen Hosp, Dept Radiol, Athinoula A Martins Ctr Biomed Imaging, 149 13th St, Charlestown, MA 02129 USA; [Batchelor, Tracy T.; Gerstner, Elizabeth R.] Massachusetts Gen Hosp, Stephen E & Catherine Pappas Ctr Neurooncol, 149 13th St, Charlestown, MA 02129 USA; [Hoebel, Katharina, V; Patel, Jay B.; Chang, Ken] Harvard MIT Div Hlth Sci & Technol, Cambridge, MA USA	Harvard University; Massachusetts General Hospital; Harvard University; Massachusetts General Hospital; Harvard University	Kalpathy-Cramer, J (corresponding author), Massachusetts Gen Hosp, Dept Radiol, Athinoula A Martins Ctr Biomed Imaging, 149 13th St, Charlestown, MA 02129 USA.	JKALPATHY-CRAMER@mgh.harvard.edu		Hoebel, Katharina/0000-0002-1881-7065; Chang, Ken/0000-0001-6956-5059; Brown, James/0000-0001-7636-4554; SINGH, Praveer/0000-0001-6641-2030				Aerts HJWL, 2016, SCI REP-UK, V6, DOI 10.1038/srep33860; Aparicio S, 2013, NEW ENGL J MED, V368, P842, DOI 10.1056/NEJMra1204892; Batchelor TT, 2013, P NATL ACAD SCI USA, V110, P19059, DOI 10.1073/pnas.1318022110; Chang K, 2019, NEURO-ONCOLOGY, V21, P1412, DOI 10.1093/neuonc/noz106; Chen W, 2018, INT J BIOMED IMAGING, V2018, DOI 10.1155/2018/2512037; Duron L, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0213459; Fedorov A, 2012, MAGN RESON IMAGING, V30, P1323, DOI 10.1016/j.mri.2012.05.001; Garapati SS, 2017, MED PHYS, V44, P5814, DOI 10.1002/mp.12510; Gorgolewski Krzysztof, 2011, Front Neuroinform, V5, P13, DOI 10.3389/fninf.2011.00013; He L, 2016, SCI REP-UK, V6, DOI 10.1038/srep34921; Iglesias JE, 2011, IEEE T MED IMAGING, V30, P1617, DOI 10.1109/TMI.2011.2138152; JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S; Johnson H. J, 2007, INSIGHT J; Kalpathy-Cramer J, 2016, TOMOGRAPHY, V2, P430, DOI 10.18383/j.tom.2016.00235; Lambin P, 2012, EUR J CANCER, V48, P441, DOI 10.1016/j.ejca.2011.11.036; Laws KI, 1980, TEXTURED IMAGE SEGME; LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115; Madabhushi A, 2006, MED PHYS, V33, P3426, DOI 10.1118/1.2335487; Molina D, 2016, COMPUT BIOL MED, V78, P49, DOI 10.1016/j.compbiomed.2016.09.011; Nyul LG, 1999, MAGNET RESON MED, V42, P1072, DOI 10.1002/(SICI)1522-2594(199912)42:6<1072::AID-MRM11>3.0.CO;2-M; Pavic M, 2018, ACTA ONCOL, V57, P1070, DOI 10.1080/0284186X.2018.1445283; Raunig DL, 2015, STAT METHODS MED RES, V24, P27, DOI 10.1177/0962280214537344; Rizzo Stefania, 2018, Eur Radiol Exp, V2, P36, DOI 10.1186/s41747-018-0068-z; Rudie JD, 2019, RADIOLOGY, V290, P607, DOI 10.1148/radiol.2018181928; Schwier M, ARXIV 180706089; Shinohara RT, 2014, NEUROIMAGE-CLIN, V6, P9, DOI 10.1016/j.nicl.2014.08.008; Sun XF, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/s12938-015-0064-y; Traverso A, 2018, INT J RADIAT ONCOL, V102, P1143, DOI 10.1016/j.ijrobp.2018.05.053; van Griethuysen JJM, 2017, CANCER RES, V77, pE104, DOI 10.1158/0008-5472.CAN-17-0339; Zwanenburg A, ARXIV 161207003	30	16	16	3	3	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2021	3	1							e190199	10.1148/ryai.2020190199	http://dx.doi.org/10.1148/ryai.2020190199			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z3HE	33842889	Green Published			2022-12-18	WOS:000826472300001
J	Kearney, V; Ziemer, BP; Perry, A; Wang, TQ; Chan, JW; Ma, LJ; Morin, O; Yom, SS; Solberg, TD				Kearney, Vasant; Ziemer, Benjamin P.; Perry, Alan; Wang, Tianqi; Chan, Jason W.; Ma, Lijun; Morin, Olivier; Yom, Sue S.; Solberg, Timothy D.			Attention-Aware Discrimination for MR-to-CT Image Translation Using Cycle-Consistent Generative Adversarial Networks	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							OPTIMIZATION; ALGORITHM	Purpose: To suggest an attention-aware, cycle-consistent generative adversarial network (A-CycleGAN) enhanced with variational auto-encoding (VAE) as a superior alternative to current state-of-the-art MR-to-CT image translation methods. Materials and Methods: An attention-gating mechanism is incorporated into a discriminator network to encourage a more parsimonious use of network parameters, whereas VAE enhancement enables deeper discrimination architectures without inhibiting model convergence. Findings from 60 patients with head, neck, and brain cancer were used to train and validate A-CycleGAN, and findings from 30 patients were used for the holdout test set and were used to report final evaluation metric results using mean absolute error (MAE) and peak signal-to-noise ratio (PSNR). Results: A-CycleGAN achieved superior results compared with U-Net, a generative adversarial network (GAN), and a cycle-consistent GAN. The A-CycleGAN averages, 95% confidence intervals (CIs), and Wilcoxon signed-rank two-sided test statistics are shown for MAE (19.61 [95% CI: 18.83, 20.39], P = .0104), structure similarity index metric (0.778 [95% CI: 0.758, 0.798], P = .0495), and PSNR (62.35 [95% CI: 61.80, 62.90], P = .0571). Conclusion: A-CycleGANs were a superior alternative to state-of-the-art MR-to-CT image translation methods. (c) RSNA, 2020	[Kearney, Vasant; Ziemer, Benjamin P.; Perry, Alan; Wang, Tianqi; Chan, Jason W.; Ma, Lijun; Morin, Olivier; Yom, Sue S.; Solberg, Timothy D.] Univ Calif San Francisco, Dept Radiat Oncol, 1600 Divisidero St, San Francisco, CA 94115 USA	University of California System; University of California San Francisco	Kearney, V (corresponding author), Univ Calif San Francisco, Dept Radiat Oncol, 1600 Divisidero St, San Francisco, CA 94115 USA.	vasantkearney@gmail.com		Ziemer, Benjamin/0000-0003-0489-5238; Yom, Sue/0000-0002-0779-7476				[Anonymous], 2001, MED SCI SER; [Anonymous], 1999, 10153 BS EN; Chan JW, 2019, MED PHYS, V46, P2204, DOI 10.1002/mp.13495; De Meerleer G, 2005, RADIOTHER ONCOL, V75, P325, DOI 10.1016/j.radonc.2005.04.014; Doersch C., ARXIV 160605908 PREP; GOODFELLOW IJ, 2014, GENERATIVE ADVERSARI, V27; Han X, 2017, MED PHYS, V44, P1408, DOI 10.1002/mp.12155; Interian Y, 2018, MED PHYS, V45, P2672, DOI 10.1002/mp.12890; Isola P, ARXIV 161107004; Januszewski M, 2019, BIORXIV, DOI [10.1101/548081v1, DOI 10.1101/548081, 10.1101/548081]; Jelen U, 2007, PHYS MED BIOL, V52, P617, DOI 10.1088/0031-9155/52/3/006; Jetley S, ARXIV 180402391 PREP; Jin CB, ARXIV 180510790 PREP; Kastaniotis D, 2018, PROCEEDINGS 2018 IEEE 13TH IMAGE, VIDEO, AND MULTIDIMENSIONAL SIGNAL PROCESSING WORKSHOP (IVMSP); Kearney V, 2019, RADIOTHER ONCOL, V133, pS549, DOI 10.1016/S0167-8140(19)31417-3; Kearney V, 2018, INT J RADIAT ONCOL, V102, pS214, DOI 10.1016/j.ijrobp.2018.07.130; Kearney V, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab2818; Kearney V, 2018, ORAL ONCOL, V87, P111, DOI 10.1016/j.oraloncology.2018.10.026; Kearney V, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aaef74; Kearney V, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aada66; Kearney V, 2018, MED PHYS, V45, P3861, DOI 10.1002/mp.13022; Kearney V, 2018, MED PHYS, V45, P1001, DOI 10.1002/mp.12759; Kearney V, 2017, PHYS MED BIOL, V62, P5777, DOI 10.1088/1361-6560/aa6f92; Kearney V, 2017, PHYS MED BIOL, V62, P966, DOI 10.1088/1361-6560/aa5342; Kearney V, 2015, PHYS MED BIOL, V60, P101, DOI 10.1088/0031-9155/60/1/101; Kida S, ARXIV190105773V1 PRE; Luong MT, ARXIV150804025 PREPR; Mejjati YA, ARXIV 180602311 PREP; Nash C, 2017, COMPUT GRAPH FORUM, V36, P1, DOI 10.1111/cgf.13240; Nie Dong, 2017, Med Image Comput Comput Assist Interv, V10435, P417, DOI 10.1007/978-3-319-66179-7_48; Nie D, 2016, LECT NOTES COMPUT SC, V10008, P170, DOI 10.1007/978-3-319-46976-8_18; Oktay O, ARXIV180403999 PREPR; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Schlemper J, ARXIV180808114 PREPR; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Welander P, ARXIV 180607777 PREP; Wu Y, ARXIV 180308494 PREP; Ypsilantis PP, ARXIV 170106452 PREP	38	16	16	3	4	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2020	2	2							e190027	10.1148/ryai.2020190027	http://dx.doi.org/10.1148/ryai.2020190027			7	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CS	33937817	Green Published, Bronze			2022-12-18	WOS:000826298800004
J	Desai, AD; Caliva, F; Iriondo, C; Mortazi, A; Jambawalikar, S; Bagci, U; Perslev, M; Igel, C; Dam, EB; Gaj, S; Yang, MR; Li, XJ; Deniz, CM; Juras, V; Regatte, R; Gold, GE; Hargreaves, BA; Pedoia, V; Chaudhari, AS				Desai, Arjun D.; Caliva, Francesco; Iriondo, Claudia; Mortazi, Aliasghar; Jambawalikar, Sachin; Bagci, Ulas; Perslev, Mathias; Igel, Christian; Dam, Erik B.; Gaj, Sibaji; Yang, Mingrui; Li, Xiaojuan; Deniz, Cem M.; Juras, Vladimir; Regatte, Ravinder; Gold, Garry E.; Hargreaves, Brian A.; Pedoia, Valentina; Chaudhari, Akshay S.		IWOAI Segmentation Challenge Writi	The International Workshop on Osteoarthritis Imaging Knee MRI Segmentation Challenge: A Multi-Institute Evaluation and Analysis Framework on a Standardized Dataset	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							NEURAL-NETWORKS; CARTILAGE; EXTRUSION; IMAGES	Purpose: To organize a multi-institute knee MRI segmentation challenge for characterizing the semantic and clinical efficacy of automatic segmentation methods relevant for monitoring osteoarthritis progression. Materials and Methods: A dataset partition consisting of three-dimensional knee MRI from 88 retrospective patients at two time points (baseline and 1-year follow-up) with ground truth articular (femoral, tibial, and patellar) cartilage and meniscus segmentations was standardized. Challenge submissions and a majority-vote ensemble were evaluated against ground truth segmentations using Dice score, average symmetric surface distance, volumetric overlap error, and coefficient of variation on a holdout test set. Similarities in automated segmentations were measured using pairwise Dice coefficient correlations. Articular cartilage thickness was computed longitudinally and with scans. Correlation between thickness error and segmentation metrics was measured using the Pearson correlation coefficient. Two empirical upper bounds for ensemble performance were computed using combinations of model outputs that consolidated true positives and true negatives. Results: Six teams (T-1-T-6) submitted entries for the challenge. No differences were observed across any segmentation metrics for any tissues (P = .99) among the four top-performing networks (T-2, T-3, T-4, T-6). Dice coefficient correlations between network pairs were high (> 0.85). Per-scan thickness errors were negligible among networks T-1-T-4 (P =.99), and longitudinal changes showed minimal bias (< 0.03 mm). Low correlations (rho < 0.41) were observed between segmentation metrics and thickness error. The majority-vote ensemble was comparable to top-performing networks (P = .99). Empirical upper-bound performances were similar for both combinations (P = .99). Conclusion: Diverse networks learned to segment the knee similarly, where high segmentation accuracy did not correlate with cartilage thickness accuracy and voting ensembles did not exceed individual network performance. (C) RSNA, 2021	[Desai, Arjun D.; Gold, Garry E.; Hargreaves, Brian A.; Chaudhari, Akshay S.] Stanford Univ, Lucas Ctr Imaging, Dept Radiol, 1201 Welch Rd,PS 055B, Stanford, CA 94305 USA; [Desai, Arjun D.; Hargreaves, Brian A.] Stanford Univ, Lucas Ctr Imaging, Dept Elect Engn, 1201 Welch Rd,PS 055B, Stanford, CA 94305 USA; [Caliva, Francesco; Iriondo, Claudia; Pedoia, Valentina] Univ Calif San Francisco, Dept Radiol, San Francisco, CA 94143 USA; [Iriondo, Claudia] Univ Calif Berkeley, Berkeley Joint Grad Grp Bioengn, Berkeley, CA 94720 USA; [Mortazi, Aliasghar; Bagci, Ulas] Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA; [Bagci, Ulas] Northwestern Univ, Dept Radiol, Chicago, IL 60611 USA; [Jambawalikar, Sachin] Columbia Univ, Dept Radiol, New York, NY USA; [Perslev, Mathias; Igel, Christian; Dam, Erik B.] Univ Copenhagen, Dept Comp Sci, Copenhagen, Denmark; [Gaj, Sibaji; Yang, Mingrui; Li, Xiaojuan] Cleveland Clin, Dept Biomed Engn, Cleveland, OH 44106 USA; [Deniz, Cem M.; Regatte, Ravinder] New York Univ Langone Hlth, Dept Radiol, New York, NY USA; [Juras, Vladimir] Med Univ Vienna, High Field MR Ctr, Dept Biomed Imaging & Image Guided Therapy, Vienna, Austria	Stanford University; Stanford University; University of California System; University of California San Francisco; University of California System; University of California Berkeley; State University System of Florida; University of Central Florida; Northwestern University; Columbia University; University of Copenhagen; Cleveland Clinic Foundation; New York University; Medical University of Vienna	Desai, AD (corresponding author), Stanford Univ, Lucas Ctr Imaging, Dept Radiol, 1201 Welch Rd,PS 055B, Stanford, CA 94305 USA.; Desai, AD (corresponding author), Stanford Univ, Lucas Ctr Imaging, Dept Elect Engn, 1201 Welch Rd,PS 055B, Stanford, CA 94305 USA.	arjundd@stanford.edu	; Regatte, Ravinder/K-2364-2014	Bagci, Ulas/0000-0001-7379-6829; Gold, Garry/0000-0002-3207-822X; Dam, Erik Bjornager/0000-0002-8888-2524; Jambawalikar, Sachin/0000-0003-1839-6798; Mortazi, Aliasghar/0000-0001-5909-3166; Perslev, Mathias/0000-0002-0358-4692; Deniz, Cem/0000-0001-8809-5945; Regatte, Ravinder/0000-0002-4607-7682; Gaj, Sibaji/0000-0002-6997-5717; Chaudhari, Akshay/0000-0002-3667-6796	National Institutes of Health [R01 AR063643, R01 EB002524, K24 AR062068, P41 EB015891, R00AR070902, R61AR073552, R01 AR074453]; National Science Foundation [DGE 1656518]; GE Healthcare; Philips; Stanford University Department of Radiology Precision Health and Integrated Diagnostics Seed Grant; Independent Research Fund Denmark, project U-Sleep [9131-00099B]; Danish Council for Independent Research; National Institutes of Health, a branch of the Department of Health and Human Services [N01-AR-2-2258, N01-AR-2-2259, N01-AR-2-2260, N01-AR-2-2261, N01-AR-2-2262]; Merck Research Laboratories; Novartis Pharmaceuticals; GlaxoSmithKline; Pfizer	National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); National Science Foundation(National Science Foundation (NSF)); GE Healthcare(General ElectricGE Healthcare); Philips; Stanford University Department of Radiology Precision Health and Integrated Diagnostics Seed Grant; Independent Research Fund Denmark, project U-Sleep; Danish Council for Independent Research(Det Frie Forskningsrad (DFF)); National Institutes of Health, a branch of the Department of Health and Human Services(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Merck Research Laboratories(Merck & Company); Novartis Pharmaceuticals(Novartis); GlaxoSmithKline(GlaxoSmithKline); Pfizer(Pfizer)	Supported by National Institutes of Health grants (R01 AR063643, R01 EB002524, K24 AR062068, and P41 EB015891, R00AR070902, R61AR073552, R01 AR074453); a National Science Foundation grant (DGE 1656518); grants from GE Healthcare and Philips (research support); and a Stanford University Department of Radiology Precision Health and Integrated Diagnostics Seed Grant. M.P. supported by a grant from the Independent Research Fund Denmark, project U-Sleep, project number 9131-00099B. C. Igel supported by a grant from the Danish Council for Independent Research for the project U-Sleep. Image data were acquired from the Osteoarthritis Initiative (OAI). The OAI is a public-private partnership composed of five contracts (N01-AR-2-2258, N01-AR-2-2259, N01-AR-2-2260, N01-AR-2-2261, N01-AR-2-2262) funded by the National Institutes of Health, a branch of the Department of Health and Human Services, and conducted by the OAI Study Investigators. Private funding partners include Merck Research Laboratories, Novartis Pharmaceuticals, GlaxoSmithKline, and Pfizer. Private sector funding for the OAI is managed by the Foundation for the National Institutes of Health.	Ambellan F, 2019, MED IMAGE ANAL, V52, P109, DOI 10.1016/j.media.2018.11.009; Balamoody S, 2010, ARTHRITIS RES THER, V12, DOI 10.1186/ar3174; Chaudhari AS, 2021, J MAGN RESON IMAGING, V54, P357, DOI 10.1002/jmri.27331; Chaudhari AS, 2020, J MAGN RESON IMAGING, V51, P768, DOI [10.1002/jmri.26872, 10.1002/jmri.26991]; Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49; Cross M, 2014, ANN RHEUM DIS, V73, P1323, DOI 10.1136/annrheumdis-2013-204763; de Brebisson A, ARXIV 160408859 PREP; Deniz CM, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-34817-6; Desai A, 2020, OSTEOARTHR CARTILAGE, V28, pS304; Desai AD, ARXIV 190201977; Dieppe P, 1998, RHEUMATOLOGY, V2nd; Draper CE, 2006, OSTEOARTHR CARTILAGE, V14, P931, DOI 10.1016/j.joca.2006.03.006; Eckstein F, 2015, ARTHRITIS RHEUMATOL, V67, P3184, DOI 10.1002/art.39324; Emmanuel K, 2016, OSTEOARTHR CARTILAGE, V24, P262, DOI 10.1016/j.joca.2015.08.003; Gaj S, 2020, MAGN RESON MED, V84, P437, DOI 10.1002/mrm.28111; Heimann T., 2010, P MICCAI WORKSH MED, P207; Iriondo C, 2021, J ORTHOP RES, V39, P1305, DOI 10.1002/jor.24849; KELLGREN JH, 1957, ANN RHEUM DIS, V16, P494, DOI 10.1136/ard.16.4.494; Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79; Mongan J, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020200029; Mortazi Aliasghar, 2017, Medical Image Computing and Computer-Assisted Intervention, MICCAI 2017. 20th International Conference. Proceedings: LNCS 10434, P377, DOI 10.1007/978-3-319-66185-8_43; Norman B, 2018, RADIOLOGY, V288, P177, DOI 10.1148/radiol.2018172322; Pan I, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019190053; Panfilov E, ARXIV 190804126 PREP; Perslev M, 2019, LECT NOTES COMPUT SC, V11765, P30, DOI 10.1007/978-3-030-32245-8_4; Peterfy CG, 2008, OSTEOARTHR CARTILAGE, V16, P1433, DOI 10.1016/j.joca.2008.06.016; Sharma L, 2008, ARTHRITIS RHEUM-US, V58, P1716, DOI 10.1002/art.23462; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037/h0026750; Vincent G, 2010, MED IMAGE ANAL CLIN, P224; Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2; Wenger A, 2013, ARTHRITIS RHEUM-US, V65, P1804, DOI 10.1002/art.37947; Wirth W, 2011, OSTEOARTHR CARTILAGE, V19, P74, DOI 10.1016/j.joca.2010.10.022; Wirth W, 2021, MAGN RESON MATER PHY, V34, P337, DOI 10.1007/s10334-020-00889-7	34	15	15	2	2	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2021	3	3							e200078	10.1148/ryai.2021200078	http://dx.doi.org/10.1148/ryai.2021200078			13	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SA	34235438	Green Submitted, Green Published			2022-12-18	WOS:000826907000002
J	Cob, E; Kitamura, FC; Hobbs, SB; Wu, CC; Lungren, MP; Prevedello, LM; Kalpathy-Cramer, J; Ball, RL; Shih, G; Stein, A; Halabi, SS; Akinmakas, E; Law, M; Kumar, P; Manzalawi, KA; Rubio, DCN; Sechrist, JW; Germaine, P; Lopez, EC; Amerio, T; Gupta, P; Jain, M; Kay, FU; Lin, CT; Sen, S; Revels, JW; Brussaarel, CC; Mongan, J				Cob, Errol; Kitamura, Felipe C.; Hobbs, Stephen B.; Wu, Carol C.; Lungren, Matthew P.; Prevedello, Luciano M.; Kalpathy-Cramer, Jayashree; Ball, Robyn L.; Shih, George; Stein, Anouk; Halabi, Safwan S.; Akinmakas, Emre; Law, Meng; Kumar, Parveen; Manzalawi, Karam A.; Rubio, Dennis Charles Nelson; Sechrist, Jacob W.; Germaine, Pauline; Lopez, Eva Castro; Amerio, Tomas; Gupta, Puslpender; Jain, Manoj; Kay, Fernando U.; Lin, Cheng Ting; Sen, Saugata; Revels, Jonathan Wesley; Brussaarel, Carok C.; Mongan, John		RSNA-STR Annotators Dataset Curati	The RSNA Pulmonary Embolism CT Dataset	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article									[Cob, Errol] Univ Toronto, Unity Hlth Toronto, Dept Med Imaging, 30 Bond St, Toronto, ON M5B 1W8, Canada; [Kitamura, Felipe C.] Univ Fed Sao Paulo, Dept Diagnost Imaging, Sao Paulo, Brazil; [Kitamura, Felipe C.] Diagnost Amer SA Dasa, Barueri, Brazil; [Hobbs, Stephen B.] Univ Kentucky, Dept Radiol, Lexington, KY USA; [Wu, Carol C.] Univ Texas MD Anderson Canc Ctr, Dept Diagnost Radiol, Houston, TX 77030 USA; [Lungren, Matthew P.; Halabi, Safwan S.] Stanford Univ, Dept Radiol, Stanford, CA 94305 USA; [Prevedello, Luciano M.] Ohio State Univ, Dept Radiol, Columbus, OH 43210 USA; [Kalpathy-Cramer, Jayashree] Massachusetts Gen Hosp, Dept Radiol, Charlestown, MA USA; [Kalpathy-Cramer, Jayashree] Massachusetts Gen Hosp, Athinoula A Martinos Ctr Biomed Imaging, Charlestown, MA USA; [Ball, Robyn L.] Jackson Lab, 600 Main St, Bar Harbor, ME 04609 USA; [Shih, George] Weill Cornell Med Coll, Dept Radiol, New York, NY USA; [Stein, Anouk] MD Ai, New York, NY USA; [Akinmakas, Emre] Koc Univ, Sch Med, Dept Radiol, Istanbul, Turkey; [Law, Meng] Monash Univ, Alfred Hlth, Dept Radiol & Nucl Med, Melbourne, Vic, Australia; [Kumar, Parveen] Fortis Escorts Heart Inst, Dept Radiodiag, New Delhi, India; [Manzalawi, Karam A.] Univ Jordan, Fac Med, Dept Diagnost Radiol & Nucl Med, Amman, Jordan; [Rubio, Dennis Charles Nelson] Hosp Reg Alta Especialidad Peninsula Yucatan, Dept Dept Imagenol, Merida, Mexico; [Sechrist, Jacob W.] Univ Pittsburgh, Med Ctr, Dept Radiol, Pittsburgh, PA USA; [Germaine, Pauline] Cooper Univ Hosp, Dept Radiol, Camden, NJ USA; [Lopez, Eva Castro] A Coruna Univ Hosp, La Coruna, Spain; [Amerio, Tomas] Swiss Med Grp, Buenos Aires, DF, Argentina; [Gupta, Puslpender] Inland Imaging, Spokane, WA USA; [Jain, Manoj] AMRI Hosp, Kolkata, India; [Kay, Fernando U.] Univ Texas Southwestern Med Ctr Dallas, Dept Radiol, Dallas, TX 75390 USA; [Lin, Cheng Ting] Johns Hopkins Univ, Sch Med, Dept Radiol, Baltimore, MD 21205 USA; [Sen, Saugata] Tata Med Ctr, Dept Radiol & Imaging Sci, Kolkata, India; [Revels, Jonathan Wesley] Univ New Mexico, Sch Med, Dept Radiol, Albuquerque, NM 87131 USA; [Brussaarel, Carok C.] Univ Ziekenhuis Brussel, Dept Radiol, Jette, Belgium; [Mongan, John] Univ Calif San Francisco, Dept Radiol & Biomed Imaging, San Francisco, CA 94143 USA	University of Toronto; Universidade Federal de Sao Paulo (UNIFESP); University of Kentucky; University of Texas System; UTMD Anderson Cancer Center; Stanford University; University System of Ohio; Ohio State University; Harvard University; Massachusetts General Hospital; Harvard University; Massachusetts General Hospital; Jackson Laboratory; Cornell University; Koc University; Monash University; University of Jordan; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Cooper University Hospital; Complejo Hospitalario Universitario A Coruna; University of Texas System; University of Texas Southwestern Medical Center Dallas; Johns Hopkins University; University of New Mexico; University Hospital Brussels; University of California System; University of California San Francisco	Cob, E (corresponding author), Univ Toronto, Unity Hlth Toronto, Dept Med Imaging, 30 Bond St, Toronto, ON M5B 1W8, Canada.	Errol.Colak@unityhealth.to	Kitamura, Felipe Campos/AAC-7075-2021; Kitamura, Felipe Campos/AAC-4368-2021; Manzalawi, Karam/R-3101-2017; Manzalawi, Karam/AAD-7813-2021	Kitamura, Felipe Campos/0000-0002-9992-5630; Manzalawi, Karam/0000-0003-4367-5385; Manzalawi, Karam/0000-0003-4367-5385; Wu, Carol/0000-0003-1005-0995; Brussaard, Carola/0000-0002-5424-6300; Lungren, Matthew/0000-0002-8591-5861; Kalpathy-Cramer, Jayashree/0000-0001-8906-9618; Prevedello, Luciano/0000-0002-6768-6452; Colak, Errol/0000-0002-3771-7975; Castro Lopez, Eva/0000-0002-8746-9826; Shih, George/0000-0002-8356-2011; Zia, Adil/0000-0003-3213-6220; Stein, Anouk/0000-0002-3066-7901				Becattini C, 2016, HEMATOL-AM SOC HEMAT, P404, DOI 10.1182/asheducation-2016.1.404; Donohoo JH, 2008, J COMPUT ASSIST TOMO, V32, P421, DOI 10.1097/RCT.0b013e31812e6af3; Flanders AE, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190211; Goldhaber SZ, 2012, LANCET, V379, P1835, DOI 10.1016/S0140-6736(11)61904-1; Halabi SS, 2019, RADIOLOGY, V290, P498, DOI 10.1148/radiol.2018180736; Jha S, 2020, ACAD RADIOL, V27, P153, DOI 10.1016/j.acra.2019.11.002; Kaggle, RSNA STR PULM EMB DE; Lee J, 2010, ANN EMERG MED, V56, P591, DOI 10.1016/j.annemergmed.2010.05.027; Remy-Jardin M, 2020, J THORAC IMAG, V35, pS40, DOI 10.1097/RTI.0000000000000492; Shih G, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180041; Weiss CR, 2006, ACAD RADIOL, V13, P434, DOI 10.1016/j.acra.2006.01.002; Zhou C, J DIGIT IMAGING2019, V32, P1089	12	15	15	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2021	3	2							e200254	10.1148/ryai.2021200254	http://dx.doi.org/10.1148/ryai.2021200254			7	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z3LD	33937862	Green Published			2022-12-18	WOS:000826483100008
J	Schock, J; Truhn, D; Abrar, DB; Merhof, D; Conrad, S; Post, M; Mittelstrass, F; Kuhl, C; Nebelung, S				Schock, Justus; Truhn, Daniel; Abrar, Daniel B.; Merhof, Dorit; Conrad, Stefan; Post, Manuel; Mittelstrass, Felix; Kuhl, Christiane; Nebelung, Sven			Automated Analysis of Alignment in Long-Leg Radiographs by Using a Fully Automated Support System Based on Artificial Intelligence	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							TOTAL KNEE ARTHROPLASTY; LOWER-LIMB; INTRAOBSERVER RELIABILITY; OSTEOARTHRITIS; INTEROBSERVER	Purpose: To develop and validate a deep learning-based method for automatic quantitative analysis of lower-extremity alignment. Materials and Methods: In this retrospective study, bilateral long-leg radiographs (LLRs) from 255 patients that were obtained between January and September of 2018 were included. For training data (n = 109), a U-Net convolutional neural network was trained to segment the femur and tibia versus manual segmentation. For validation data (n = 40), model parameters were optimized. Following identification of anatomic landmarks, anatomic and mechanical axes were identified and used to quantify alignment through the hipknee-ankle angle (HKAA) and femoral anatomic-mechanical angle (AMA). For testing data (n = 106), algorithm-based angle measurements were compared with reference measurements by two radiologists. Angles and time for 30 random radiographs were compared by using repeated-measures analysis of variance and one-way analysis of variance, whereas correlations were quantified by using Pearson r and intraclass correlation coefficients. Results: Bilateral LLRs of 255 patients (mean age, 26 years 6 23 [standard deviation]; range, 0-88 years; 157 male patients) were included. Mean Sorensen-Dice coefficients for segmentation were 0.97 6 0.09 for the femur and 0.96 6 0.11 for the tibia. Mean HKAAs and AMAs as measured by the readers and the algorithm ranged from 0.05 degrees to 0.11 degrees (P = .5) and from 4.82 degrees to 5.43 degrees (P < .001). Interreader correlation coefficients ranged from 0.918 to 0.995 (r range, P < .001), and agreement was almost perfect (intraclass correlation coefficient range, 0.87-0.99). Automatic analysis was faster than the two radiologists' manual measurements (3 vs 36 vs 35 seconds, P,.001). Conclusion: Fully automated analysis of LLRs yielded accurate results across a wide range of clinical and pathologic indications and is fast enough to enhance and accelerate clinical workflows. Supplemental material is available for this article. (C) RSNA, 2020.	[Schock, Justus; Abrar, Daniel B.; Nebelung, Sven] Univ Hosp Dusseldorf, Dept Diagnost & Intervent Radiol, Dusseldorf, Germany; [Schock, Justus; Merhof, Dorit] Rhein Westfal TH Aachen, Inst Comp Vis & Imaging, Pauwelsstr 30, D-52072 Aachen, Germany; [Truhn, Daniel; Post, Manuel; Mittelstrass, Felix; Kuhl, Christiane; Nebelung, Sven] Univ Hosp Aachen, Dept Diagnost & Intervent Radiol, Aachen, Germany; [Conrad, Stefan] Heinrich Heine Univ Dusseldorf, Inst Informat, Fac Math & Nat Sci, Dusseldorf, Germany	Heinrich Heine University Dusseldorf; Heinrich Heine University Dusseldorf Hospital; RWTH Aachen University; RWTH Aachen University; RWTH Aachen University Hospital; Heinrich Heine University Dusseldorf	Nebelung, S (corresponding author), Univ Hosp Dusseldorf, Dept Diagnost & Intervent Radiol, Dusseldorf, Germany.; Nebelung, S (corresponding author), Univ Hosp Aachen, Dept Diagnost & Intervent Radiol, Aachen, Germany.	snebelung@ukaachen.de		Kuhl, Christiane/0000-0001-8696-2363; Truhn, Daniel/0000-0002-9605-0728; Post, Manuel/0000-0003-2810-6432; Conrad, Stefan/0000-0003-2788-3854; Nebelung, Sven/0000-0002-5267-9962				Bishop C.M., 2014, ANTIMICROB AGENTS CH, V58, P7250; Bowman A, 2016, KNEE, V23, P203, DOI 10.1016/j.knee.2015.11.013; Cooke D, 1997, OSTEOARTHR CARTILAGE, V5, P39, DOI 10.1016/S1063-4584(97)80030-1; Deakin AH, 2012, KNEE, V19, P120, DOI 10.1016/j.knee.2011.02.001; Feldman DS, 2007, J PEDIATR ORTHOPED, V27, P204, DOI 10.1097/01.bpb.0000242441.96434.6f; Felson DT, 2013, ARTHRITIS RHEUM-US, V65, P355, DOI 10.1002/art.37726; Gyftopoulos S, 2019, AM J ROENTGENOL, V213, P506, DOI 10.2214/AJR.19.21117; Hankemeier S, 2006, Comput Aided Surg, V11, P81, DOI 10.3109/10929080600628985; Ilahi O A, 2001, Am J Knee Surg, V14, P238; Kannan A, 2012, J KNEE SURG, V25, P407, DOI 10.1055/s-0032-1313756; Kijowski R, 2020, J MAGN RESON IMAGING, V52, P1607, DOI 10.1002/jmri.27001; Kingma D.P, P 3 INT C LEARNING R; Lampart M, 2019, KNEE SURG SPORT TR A, V27, P1434, DOI 10.1007/s00167-018-5041-0; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Maderbacher G, 2017, INT ORTHOP, V41, P1553, DOI 10.1007/s00264-017-3408-3; Mikolajczyk A., 2018, 2018 INT INTERDISCIP, P117, DOI [DOI 10.1109/IIPHDW.2018.8388338, 10.1109/IIPHDW.2018.8388338]; MORELAND JR, 1987, J BONE JOINT SURG AM, V69A, P745, DOI 10.2106/00004623-198769050-00016; Nolte D, 2016, J BIOMECH, V49, P3576, DOI 10.1016/j.jbiomech.2016.09.005; PALEY D, 1994, ORTHOP CLIN N AM, V25, P425; Rauh MA, 2007, ORTHOPEDICS, V30, P299, DOI 10.3928/01477447-20070401-14; Rerucha CM, 2017, AM FAM PHYSICIAN, V96, P226; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Sabharwal S, 2009, J BONE JOINT SURG AM, V91A, P2461, DOI [10.2106/JBJS.1.00015, 10.2106/JBJS.I.00015]; Schmidt Gary L, 2004, J Knee Surg, V17, P141; Schroter S, 2013, KNEE SURG SPORT TR A, V21, P189, DOI 10.1007/s00167-012-2114-3; Sharma L, 2013, ANN RHEUM DIS, V72, P235, DOI 10.1136/annrheumdis-2011-201070; Sheehy L, 2011, OSTEOARTHR CARTILAGE, V19, P58, DOI 10.1016/j.joca.2010.09.011; Sled EA, 2011, RHEUMATOL INT, V31, P71, DOI 10.1007/s00296-009-1236-5; Smith-Bindman R, 2008, HEALTH AFFAIR, V27, P1491, DOI 10.1377/hlthaff.27.6.1491; Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015; Zahn RK, 2019, KNEE SURG SPORT TR A, V27, P1470, DOI 10.1007/s00167-018-5056-6; Zheng Q, 2020, RADIOLOGY, V296, P152, DOI 10.1148/radiol.2020192003	33	15	15	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2021	3	2							e200198	10.1148/ryai.2020200198	http://dx.doi.org/10.1148/ryai.2020200198			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z3LD	33937861	Green Published			2022-12-18	WOS:000826483100005
J	Chassagnon, G; Vakalopoulou, M; Regent, A; Zacharaki, EI; Aviram, G; Martin, C; Marini, R; Bus, N; Jerjir, N; Mekinian, A; Hua-Huy, T; Monnier-Cholley, L; Benmostefa, N; Mouthon, L; Dinh-Xuan, AT; Paragios, N; Revel, MP				Chassagnon, Guillaume; Vakalopoulou, Maria; Regent, Alexis; Zacharaki, Evangelia, I; Aviram, Galit; Martin, Charlotte; Marini, Rafael; Bus, Norbert; Jerjir, Naim; Mekinian, Arsene; Hua-Huy, Thong; Monnier-Cholley, Laurence; Benmostefa, Nouria; Mouthon, Luc; Dinh-Xuan, Anh-Tuan; Paragios, Nikos; Revel, Marie-Pierre			Deep Learning-based Approach for Automated Assessment of Interstitial Lung Disease in Systemic Sclerosis on CT Images	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To develop a deep learning algorithm for the automatic assessment of the extent of systemic sclerosis (SSc)-related interstitial lung disease (ILD) on chest CT images. Materials and Methods: This retrospective study included 208 patients with SSc (median age, 57 years; 167 women) evaluated between January 2009 and October 2017. A multicomponent deep neural network (AtlasNet) was trained on 6888 fully annotated CT images (80% for training and 20% for validation) from 17 patients with no, mild, or severe lung disease. The model was tested on a dataset of 400 images from another 20 patients, independently partially annotated by three radiologist readers. The ILD contours from the three readers and the deep learning neural network were compared by using the Dice similarity coefficient (DSC). The correlation between disease extent obtained from the deep learning algorithm and that obtained by using pulmonary function tests (PFTs) was then evaluated in the remaining 171 patients and in an external validation dataset of 31 patients based on the analysis of all slices of the chest CT scan. The Spearman rank correlation coefficient (rho) was calculated to evaluate the correlation between disease extent and PFT results. Results: The median DSCs between the readers and the deep learning ILD contours ranged from 0.74 to 0.75, whereas the median DSCs between contours from radiologists ranged from 0.68 to 0.71. The disease extent obtained from the algorithm, by analyzing the whole CT scan, correlated with the diffusion lung capacity for carbon monoxide, total lung capacity, and forced vital capacity (rho = -0.76, -0.70, and -0.62, respectively; P<.001 for all) in the dataset for the correlation with PFT results. The disease extents correlated with diffusion lung capacity for carbon monoxide, total lung capacity, and forced vital capacity were rho = -0.65, -0.70, and -0.57, respectively, in the external validation dataset (P<.001 for all). Conclusion: The developed algorithm performed similarly to radiologists for disease-extent contouring, which correlated with pulmonary function to assess CT images from patients with SSc-related ILD. (C) RSNA, 2020	[Chassagnon, Guillaume; Jerjir, Naim; Revel, Marie-Pierre] Univ Paris, Hop Cochin, AP HP, Dept Radiol, 27 Rue Faubourg St Jacques, F-75014 Paris, France; [Regent, Alexis; Hua-Huy, Thong; Dinh-Xuan, Anh-Tuan] Univ Paris, Hop Cochin, AP HP, Dept Physiol, 27 Rue Faubourg St Jacques, F-75014 Paris, France; [Benmostefa, Nouria; Mouthon, Luc] Univ Paris, Hop Cochin, AP HP, Reference Ctr Rare Syst Autoinunune Dis Ile Franc, 27 Rue Faubourg St Jacques, F-75014 Paris, France; [Chassagnon, Guillaume; Vakalopoulou, Maria; Zacharaki, Evangelia, I; Martin, Charlotte; Paragios, Nikos] Ecole Cent Supelec, Ctr Visual Comp, Gif Sur Yvette, France; [Aviram, Galit] Tel Aviv Univ, Sackler Fac Med, Tel Aviv Sourasky Med Ctr, Dept Radiol, Tel Aviv, Israel; [Marini, Rafael; Bus, Norbert; Paragios, Nikos] TheraPanacea, Paris, France; [Mekinian, Arsene] Sorbonne Univ, Hop St Antoine, AP HP, Dept Internal Med, Paris, France; [Mekinian, Arsene] Sorbonne Univ, Hop St Antoine, AP HP, Dept Inflammatory Disorders, Paris, France; [Monnier-Cholley, Laurence] Sorbonne Univ, Hop St Antoine, AP HP, Radiol, Paris, France		Revel, MP (corresponding author), Univ Paris, Hop Cochin, AP HP, Dept Radiol, 27 Rue Faubourg St Jacques, F-75014 Paris, France.	marie-pierre.revel@aphp.fr	DINH-XUAN, Anh Tuan/A-9691-2008; Hua-Huy, Thong/F-9662-2013	DINH-XUAN, Anh Tuan/0000-0001-8651-5176; Hua-Huy, Thong/0000-0003-3212-0560; Zacharaki, Evangelia/0000-0001-8228-0437				Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615; Camiciottoli G, 2007, CHEST, V131, P672, DOI 10.1378/chest.06-1401; Chifflot H, 2008, SEMIN ARTHRITIS RHEU, V37, P223, DOI 10.1016/j.semarthrit.2007.05.003; COLLINS CD, 1994, CLIN RADIOL, V49, P236, DOI 10.1016/S0009-9260(05)81847-1; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411; Depeursinge A, 2012, IEEE T INF TECHNOL B, V16, P665, DOI 10.1109/TITB.2012.2198829; Depeursinge A, 2012, COMPUT MED IMAG GRAP, V36, P227, DOI 10.1016/j.compmedimag.2011.07.003; DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409; Diot E, 1998, CHEST, V114, P1623, DOI 10.1378/chest.114.6.1623; Gierada DS, 2010, ACAD RADIOL, V17, P146, DOI 10.1016/j.acra.2009.08.007; Goh NSL, 2008, AM J RESP CRIT CARE, V177, P1248, DOI 10.1164/rccm.200706-877OC; Goldin JG, 2008, CHEST, V134, P358, DOI 10.1378/chest.07-2444; Humphries SM, 2018, EUR RESPIR J, V52, DOI 10.1183/13993003.01384-2018; Humphries SM, 2017, RADIOLOGY, V285, P270, DOI 10.1148/radiol.2017161177; Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044; Kim HJ, 2010, CLIN EXP RHEUMATOL, V28, pS26; LEROY EC, 1988, J RHEUMATOL, V15, P202; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Lu L, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0166550; Lynch DA, 2018, LANCET RESP MED, V6, P138, DOI 10.1016/S2213-2600(17)30433-2; McBee MP, 2018, ACAD RADIOL, V25, P1472, DOI 10.1016/j.acra.2018.02.018; Meier FMP, 2012, ANN RHEUM DIS, V71, P1355, DOI 10.1136/annrheumdis-2011-200742; Moore OA, 2013, RHEUMATOLOGY, V52, P155, DOI 10.1093/rheumatology/kes289; O'Neil AQ, 2017, LECT NOTES COMPUT SC, V10552, P96, DOI 10.1007/978-3-319-67534-3_11; Ooi GC, 2003, ACTA RADIOL, V44, P258, DOI 10.1034/j.1600-0455.2003.00058.x; Raghu G, 2011, AM J RESP CRIT CARE, V183, P788, DOI 10.1164/rccm.2009-040GL; Ronneberger O, ARXIV 150504597 CS P; Rubio-Rivas M, 2014, SEMIN ARTHRITIS RHEU, V44, P208, DOI 10.1016/j.semarthrit.2014.05.010; Salaffi F, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0149240; Song Y, 2013, IEEE T MED IMAGING, V32, P797, DOI 10.1109/TMI.2013.2241448; Sverzellati N, 2011, J COMPUT ASSIST TOMO, V35, P596, DOI 10.1097/RCT.0b013e3182277d05; Taha AA, 2015, BMC MED IMAGING, V15, DOI 10.1186/s12880-015-0068-x; Tashkin DP, 2016, ANN RHEUM DIS, V75, P374, DOI 10.1136/annrheumdis-2014-206076; Tyndall AJ, 2010, ANN RHEUM DIS, V69, P1809, DOI 10.1136/ard.2009.114264; Vakalopoulou M, 2018, LECT NOTES COMPUT SC, V11073, P658, DOI 10.1007/978-3-030-00937-3_75; van den Hoogen F, 2013, ANN RHEUM DIS, V72, P1747, DOI [10.1136/annrheumdis-2013-204424, 10.1002/art.38098]; Watadani T, 2013, RADIOLOGY, V266, P936, DOI 10.1148/radiol.12112516; Wells AU, 2014, PRESSE MED, V43, pE329, DOI 10.1016/j.lpm.2014.08.002	38	15	15	0	2	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2020	2	4							e190006	10.1148/ryai.2020190006	http://dx.doi.org/10.1148/ryai.2020190006			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CX	33937829	Green Published			2022-12-18	WOS:000826472900001
J	O'Neill, TJ; Xi, Y; Stehel, E; Browning, T; Ng, YS; Baker, C; Peshock, RM				O'Neill, Thomas J.; Xi, Yin; Stehel, Edward; Browning, Travis; Ng, Yee Seng; Baker, Chris; Peshock, Ronald M.			Active Reprioritization of the Reading Worklist Using Artificial Intelligence Has a Beneficial Effect on the Turnaround Time for Interpretation of Head CT with Intracranial Hemorrhage	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							IMPACT	Purpose: To determine how to optimize the delivery of machine learning techniques in a clinical setting to detect intracranial hemorrhage (ICH) on non-contrast-enhanced CT images to radiologists to improve workflow. Materials and Methods: In this study, a commercially available machine learning algorithm that flags abnormal noncontrast CT examinations for ICH was implemented in a busy academic neuroradiology practice between September 2017 and March 2019. The algorithm was introduced in three phases: (a) as a "pop-up" widget on ancillary monitors, (b) as a marked examination in reading worklists, and (c) as a marked examination for reprioritization based on the presence of the flag. A statistical approach, which was based on a queuing theory, was implemented to assess the impact of each intervention on queue-adjusted wait and turnaround time compared with historical controls. Results: Notification with a widget or flagging the examination had no effect on queue-adjusted image wait (P..99) or turnaround time (P =.6). However, a reduction in queue-adjusted wait time was observed between negative (15.45 minutes; 95% CI: 15.07, 15.38) and positive (12.02 minutes; 95% CI: 11.06, 12.97; P < .0001) artificial intelligence-detected ICH examinations with reprioritization. Reduced wait time was present for all order classes but was greatest for examinations ordered as routine for both inpatients and outpatients because of their low priority. Conclusion: The approach used to present flags from artificial intelligence and machine learning algorithms to the radiologist can reduce image wait time and turnaround times. (C) RSNA, 2021.	[O'Neill, Thomas J.; Xi, Yin; Stehel, Edward; Browning, Travis; Ng, Yee Seng; Peshock, Ronald M.] Univ Texas Southwestern Med Ctr Dallas, Dept Radiol, 5323 Harry Hines Blvd, Dallas, TX 75235 USA; [Baker, Chris] Univ Texas Southwestern Med Ctr Dallas, Dept Syst Informat Resources, 5323 Harry Hines Blvd, Dallas, TX 75235 USA	University of Texas System; University of Texas Southwestern Medical Center Dallas; University of Texas System; University of Texas Southwestern Medical Center Dallas	O'Neill, TJ (corresponding author), Univ Texas Southwestern Med Ctr Dallas, Dept Radiol, 5323 Harry Hines Blvd, Dallas, TX 75235 USA.	thomas.oneill@utsouthwestern.edu	Xi, Yin/M-2268-2016	Xi, Yin/0000-0001-9743-3010; Baker, Chris/0000-0003-3765-0253; Browning, Travis/0000-0002-2675-413X; O'Neill, Thomas/0000-0002-2975-7459	University of Texas (UT) Southwestern Division of Neuroradiology	University of Texas (UT) Southwestern Division of Neuroradiology	We would like to acknowledge the University of Texas (UT) Southwestern Division of Neuroradiology and its faculty, fellows, and residents who participated in this research on workflow. We would also like to acknowledge the UT Southwestern PACS administrators and other IT professionals who assisted in the implementation and integration of the software used in this study.	Arbabshirani MR, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-017-0015-z; Cho J, 2019, J DIGIT IMAGING, V32, P450, DOI 10.1007/s10278-018-00172-1; Gaskin CM, 2016, AM J ROENTGENOL, V206, P1031, DOI 10.2214/AJR.15.14837; Halsted MJ, 2008, AM J ROENTGENOL, V191, P321, DOI 10.2214/AJR.07.3122; Ibanez M, HARVARD BUSINESS SCH; Kuo WC, 2019, P NATL ACAD SCI USA, V116, P22737, DOI 10.1073/pnas.1908021116; Majumdar Arjun, 2018, Annu Int Conf IEEE Eng Med Biol Soc, V2018, P583, DOI 10.1109/EMBC.2018.8512336; McDonald RJ, 2015, ACAD RADIOL, V22, P1191, DOI 10.1016/j.acra.2015.05.007; Morgan MB, 2008, J DIGIT IMAGING, V21, P50, DOI 10.1007/s10278-007-9008-9; Ojeda P, 2019, PROC SPIE, V10949, DOI 10.1117/12.2513167; Osborne TF, 2018, J STROKE CEREBROVASC, V27, P1190, DOI 10.1016/j.jstrokecerebrovasdis.2017.11.038; Panagos PD, 2002, EMERG MED CLIN N AM, V20, P631, DOI 10.1016/S0733-8627(02)00015-9; Ranschaert ER, 2016, J BELG SOC RADIOL, V100, DOI 10.5334/jbr-btr.1184; Remedios SW, 2020, MED PHYS, V47, P89, DOI 10.1002/mp.13880; Sauser K, 2014, JAMA NEUROL, V71, P1155, DOI 10.1001/jamaneurol.2014.1528	15	14	14	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2021	3	2							e200024	10.1148/ryai.2020200024	http://dx.doi.org/10.1148/ryai.2020200024			8	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z3LD	33937858	Green Published			2022-12-18	WOS:000826483100002
J	Mu, W; Tunali, I; Qi, J; Schabath, MB; Gillies, RJ				Mu, Wei; Tunali, Ilke; Qi, Jin; Schabath, Matthew B.; Gillies, Robert James			Radiomics of F-18 Fluorodeoxyglucose PET/CT Images Predicts Severe Immune-related Adverse Events in Patients with NSCLC	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							CHECKPOINT-BLOCKADE; NIVOLUMAB; PEMBROLIZUMAB; CHEMOTHERAPY; IPILIMUMAB; MELANOMA; TUMORS	Purpose: To investigate the performance of pretreatment fluorine 18 (F-18) fluorodeoxyglucose PET/CT radiomics in predicting severe immune-related adverse events (irSAEs) among patients with advanced non-small cell lung cancer (NSCLC) treated with immunotherapy, which is important in optimizing treatment plans and alleviating future complications with early interventions. Materials and Methods: The retrospective arm of this study included 146 patients with histologically confirmed stage IIIB-IV NSCLC who were treated with immune checkpoint blockade between June 2011 and December 2017 and who were split into training (n = 97) and test (n = 49) cohorts. A prospective validation arm enrolled 48 patients before initiation of immunotherapy between January 2018 and June 2019 as an independent test cohort. Radiomics features extracted from baseline (preimmunotherapy treatment) PET, CT, and PET/CT fusion images were used to generate a radiomics score (RS) to quantify patient risk for developing irSAEs by an improved least absolute shrinkage and selection operator method. Weighted multivariable logistic regression analysis was then used to develop a nomogram model to predict irSAEs, which was assessed by its calibration, discrimination, and clinical usefulness. Results: The radiomics nomogram, incorporating the RS, type of immune checkpoint blockade, and dosing schedule, was able to predict patients with and without irSAEs with area under the receiver operating characteristic curve of 0.92 (95% confidence interval [CI]: 0.86, 0.98), 0.92 (95% CI: 0.86, 0.99), and 0.88 (95% CI: 0.78, 0.97) in the training, test, and prospective validation cohorts, respectively. Decision curve analysis showed that the radiomics nomogram model had the highest overall net benefit. Conclusion: A high RS is a significant risk factor for development of irSAEs, demonstrating the value of PET/CT images in predicting irSAEs. By the identification, at baseline, of patients with NSCLC most likely to have irSAEs, treatment plans can be optimized before initiation of immunotherapy. (c) RSNA, 2020	[Mu, Wei; Tunali, Ilke; Qi, Jin; Gillies, Robert James] H Lee Moffitt Canc Ctr & Res Inst, Dept Canc Physiol, 12902 Magnolia Dr, Tampa, FL 33612 USA; [Schabath, Matthew B.] H Lee Moffitt Canc Ctr & Res Inst, Dept Canc Epidemiol, 12902 Magnolia Dr, Tampa, FL 33612 USA	H Lee Moffitt Cancer Center & Research Institute; H Lee Moffitt Cancer Center & Research Institute	Gillies, RJ (corresponding author), H Lee Moffitt Canc Ctr & Res Inst, Dept Canc Physiol, 12902 Magnolia Dr, Tampa, FL 33612 USA.	Robert.Giffies@moffitt.org	Mu, Wei/N-7207-2017	Mu, Wei/0000-0001-7970-8666; Tunali, Ilke/0000-0002-2565-4030; Gillies, Robert/0000-0002-8888-7747	U.S. Public Health Service [U01 CA143062, R01 CA190105]	U.S. Public Health Service(United States Department of Health & Human ServicesUnited States Public Health Service)	Supported by U.S. Public Health Service research grant U01 CA143062 (principal investigator R.J.G.) and R01 CA190105 (principal investigator R.J.G.)	Aerts HJWL, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5006; Beukinga RJ, 2018, RADIOLOGY, V287, P983, DOI 10.1148/radiol.2018172229; BOZDOGAN H, 1987, PSYCHOMETRIKA, V52, P345, DOI 10.1007/BF02294361; Brahmer J, 2015, NEW ENGL J MED, V373, P123, DOI 10.1056/NEJMoa1504627; Callahan MK, 2011, J CLIN ONCOL, V29, DOI 10.1200/jco.2011.29.15_suppl.2505; Coroller TP, 2017, J THORAC ONCOL, V12, P467, DOI 10.1016/j.jtho.2016.11.2226; Crivellaro C, 2012, GYNECOL ONCOL, V127, P131, DOI 10.1016/j.ygyno.2012.06.041; Dovedi SJ, 2014, CANCER RES, V74, P5458, DOI 10.1158/0008-5472.CAN-14-1258; Dubin K, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms10391; Fitzgerald M, 2015, JAMA-J AM MED ASSOC, V313, P409, DOI 10.1001/jama.2015.37; Fujimura Taku, 2018, Oncotarget, V9, P15542, DOI 10.18632/oncotarget.24509; Gandhi L, 2018, NEW ENGL J MED, V378, P2078, DOI 10.1056/NEJMoa1801005; Garon EB, 2015, NEW ENGL J MED, V372, P2018, DOI 10.1056/NEJMoa1501824; HOSMER DW, 1980, COMMUN STAT A-THEOR, V9, P1043, DOI 10.1080/03610928008827941; Kaira K, 2018, EUR J NUCL MED MOL I, V45, P56, DOI 10.1007/s00259-017-3806-1; Kirienko M, 2018, EUR J NUCL MED MOL I, V45, P207, DOI 10.1007/s00259-017-3837-7; Kumar V, 2017, FRONT PHARMACOL, V8, DOI 10.3389/fphar.2017.00049; Larkin J, 2015, NEW ENGL J MED, V373, P23, DOI [10.1056/NEJMoa1504030, 10.1056/NEJMc1509660]; Lucia F, 2018, EUR J NUCL MED MOL I, V45, P768, DOI 10.1007/s00259-017-3898-7; Michot JM, 2016, EUR J CANCER, V54, P139, DOI 10.1016/j.ejca.2015.11.016; Mu W, 2015, IEEE T BIO-MED ENG, V62, P2465, DOI 10.1109/TBME.2015.2433397; National Cancer Institute (NCI), 2010, COMM TERM CRIT ADV E; Patnaik A, 2015, PHASE 1 STUDY PEMBRO; Postow MA, 2018, NEW ENGL J MED, V378, P158, DOI [10.1056/NEJMra1703481, 10.1056/NEJMc1801663]; Reck M, 2016, NEW ENGL J MED, V375, P1823, DOI 10.1056/NEJMoa1606774; Renton AE, 2015, JAMA NEUROL, V72, P396, DOI 10.1001/jamaneurol.2014.4103; Rizvi N., 2015, J IMMUNOTHER CANCER, V3, pP193, DOI [10.1186/2051-1426-3-S2-P193, DOI 10.1186/2051-1426-3-S2-P193]; Rizvi NA, 2016, J CLIN ONCOL, V34, P2969, DOI 10.1200/JCO.2016.66.9861; Rizvi NA, 2015, J CLIN ONCOL, V33; Saeed-Vafa D., BIORXIV; Samstein RM, 2019, NAT GENET, V51, P202, DOI 10.1038/s41588-018-0312-8; Schindler K, 2014, CORRELATION ABSOLUTE; Schwarzenberg J, 2014, CLIN CANCER RES, V20, P3550, DOI 10.1158/1078-0432.CCR-13-1440; Shahabi V, 2013, J TRANSL MED, V11, DOI 10.1186/1479-5876-11-75; Siegel RL, 2018, CA-CANCER J CLIN, V68, P7, DOI 10.3322/caac.21442; Simeone E, 2012, J IMMUNOTOXICOL, V9, P241, DOI 10.3109/1547691X.2012.678021; Tunali I, 2019, LUNG CANCER, V129, P75, DOI 10.1016/j.lungcan.2019.01.010; van Timmeren JE, 2017, RADIOTHER ONCOL, V123, P363, DOI 10.1016/j.radonc.2017.04.016; Wu J, 2016, RADIOLOGY, V281, P270, DOI 10.1148/radiol.2016151829	39	14	14	2	5	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2020	2	1							e190063	10.1148/ryai.2019190063	http://dx.doi.org/10.1148/ryai.2019190063			12	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CR	33937811	Green Published			2022-12-18	WOS:000826298000005
J	Blansit, K; Retson, T; Masutani, E; Bahrami, N; Hsiao, A				Blansit, Kevin; Retson, Tara; Masutani, Evan; Bahrami, Naeim; Hsiao, Albert			Deep Learning-based Prescription of Cardiac MRI Planes	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							QUANTIFICATION; ACQUISITION	Purpose: To develop and evaluate a system to prescribe imaging planes for cardiac MRI based on deep learning (DL)-based localization of key anatomic landmarks. Materials and Methods: Annotated landmarks on 892 long-axis (LAX) and 493 short-axis (SAX) cine steady-state free precession series from cardiac MR images were retrospectively collected between February 2012 and June 2017. U-Net-based heatmap regression was used for localization of cardiac landmarks, which were used to compute cardiac MRI planes. Performance was evaluated by comparing localization distances and plane angle differences between DL predictions and ground truth. The plane angulations from DL were compared with those prescribed by the technologist at the original time of acquisition. Data were split into 80% for training and 20% for testing, and results confirmed with fivefold cross-validation. Results: On LAX images, DL localized the apex within mean 12.56 mm +/- 19.11 (standard deviation) and the mitral valve (MV) within 7.68 mm +/- 6.91. On SAX images, DL localized the aortic valve within 5.78 mm +/- 5.68, MV within 5.90 mm +/- 5.24, pulmonary valve within 6.55 mm +/- 6.39, and tricuspid valve within 6.39 mm +/- 5.89. On the basis of these localizations, average angle bias and mean error of DL-predicted imaging planes relative to ground truth annotations were as follows: SAX, -1.27 degrees +/- 6.81 and 4.93 degrees +/- 4.86; four chambers, 0.38 degrees +/- 6.45 and 5.16 degrees +/- 3.80; three chambers, 0.13 degrees +/- 12.70 and 9.02 degrees +/- 8.83; and two chamber, 0.25 degrees +/- 9.08 and 6.53 degrees +/- 6.28, respectively. Conclusion: DL-based anatomic localization is a feasible strategy for planning cardiac MRI planes. This approach can produce imaging planes comparable to those defined by ground truth landmarks. Supplemental material is available for this article. (c) RSNA, 2019	[Blansit, Kevin; Hsiao, Albert] Univ Calif San Diego, Dept Biomed Informat, 9500 Gilman Dr, La Jolla, CA 92093 USA; [Retson, Tara; Bahrami, Naeim; Hsiao, Albert] Univ Calif San Diego, Dept Radiol, 9500 Gilman Dr, La Jolla, CA 92093 USA; [Masutani, Evan] Univ Calif San Diego, Dept Bioengn, 9500 Gilman Dr, La Jolla, CA 92093 USA; [Masutani, Evan] Univ Calif San Diego, Sch Med, 9500 Gilman Dr, La Jolla, CA 92093 USA	University of California System; University of California San Diego; University of California System; University of California San Diego; University of California System; University of California San Diego; University of California System; University of California San Diego	Blansit, K (corresponding author), Univ Calif San Diego, Dept Biomed Informat, 9500 Gilman Dr, La Jolla, CA 92093 USA.	kblansit@eng.ucsd.edu		Hsiao, Albert/0000-0002-9412-1369; Retson, Tara/0000-0002-0009-7733	National Institute of Biomedical Imaging and Bioengineering; National Institute of General Medical Sciences; U.S. National Library of Medicine; GE Healthcare	National Institute of Biomedical Imaging and Bioengineering(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB)); National Institute of General Medical Sciences(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of General Medical Sciences (NIGMS)); U.S. National Library of Medicine(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Library of Medicine (NLM)); GE Healthcare(General ElectricGE Healthcare)	We acknowledge the support of NVIDIA Corporation for their generous donation of a Titan Xp GPU for training the deep learning networks in this research. We thank the San Diego Supercomputer Center for their donation of GPU-accelerated compute time that supported training deep learning network in this research; and the National Institute of Biomedical Imaging and Bioengineering, National Institute of General Medical Sciences, U.S. National Library of Medicine, and GE Healthcare for their generous grant support for this work.	Addy O, 2018, INT SOC MAGNETIC RES; [Anonymous], 1999, 10153 BS EN; Bahrami N, 2019, MAGN RESON MED, V81, P3283, DOI 10.1002/mrm.27680; Bloomer TN, 2001, J MAGN RESON IMAGING, V14, P685, DOI 10.1002/jmri.10019; Cao Z, ARXIV 161108050; Chartrand G, 2017, RADIOGRAPHICS, V37, P2113, DOI 10.1148/rg.2017170077; Choi KJ, 2018, RADIOLOGY, V289, P688, DOI 10.1148/radiol.2018180763; Crean A, 2007, HEART, V93, P1637, DOI 10.1136/hrt.2006.104729; Ferguson M, 2014, MEDEDPORTAL, V10, P9906; Frick M, 2011, J MAGN RESON IMAGING, V34, P457, DOI 10.1002/jmri.22626; Goldfarb JW, 2015, CIRCULATION, V132; He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239; Hochreiter S., 1997, STUD COMPUT INTELL, V9, P1735, DOI DOI 10.1007/978-3-642-24797-2; Jackson CE, 2004, COMPUT MED IMAG GRAP, V28, P411, DOI 10.1016/j.compmedimag.2004.03.006; La Gerche A, 2013, CIRC-CARDIOVASC IMAG, V6, P329, DOI 10.1161/CIRCIMAGING.112.980037; Le M, 2017, LECT NOTES COMPUT SC, V10553, P109, DOI 10.1007/978-3-319-67558-9_13; Lelieveldt BPF, 2001, RADIOLOGY, V221, P537, DOI 10.1148/radiol.2212010177; Lieman-Sifry J, 2017, LECT NOTES COMPUT SC, V10263, P127, DOI 10.1007/978-3-319-59448-4_13; Lopez-Mattei Juan C, 2013, Methodist Debakey Cardiovasc J, V9, P142; Lu XG, 2011, LECT NOTES COMPUT SC, V6893, P479, DOI 10.1007/978-3-642-23626-6_59; Nam JG, 2019, RADIOLOGY, V290, P218, DOI 10.1148/radiol.2018180237; Payer Christian, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P230, DOI 10.1007/978-3-319-46723-8_27; Pfister T, FLOWING CONVNETS HUM; Ronneberger O., ARXIV; Simonyan K, ARXIV PREPRINT; Stokes MB, 2017, AUST PRESCR, V40, P151, DOI 10.18773/austprescr.2017.045; Suinesiaputra A, 2015, J CARDIOVASC MAGN R, V17, DOI 10.1186/s12968-015-0170-9; Wang K, 2018, INT SOC MAGNETIC RES	28	14	15	0	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2019	1	6							e180069	10.1148/ryai.2019180069	http://dx.doi.org/10.1148/ryai.2019180069			8	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CQ	32090204	Green Submitted, Green Published, Bronze			2022-12-18	WOS:000826296100002
J	Morales, MA; Izquierdo-Garcia, D; Aganj, I; Kalpathy-Cramer, J; Rosen, BR; Catana, C				Morales, Manuel A.; Izquierdo-Garcia, David; Aganj, Iman; Kalpathy-Cramer, Jayashree; Rosen, Bruce R.; Catana, Ciprian			Implementation and Validation of a Three-dimensional Cardiac Motion Estimation Network	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							FEATURE TRACKING	Purpose: To describe an unsupervised three-dimensional cardiac motion estimation network (CarMEN) for deformable motion estimation from two-dimensional cine MR images. Materials and Methods: A function was implemented using CarMEN, a convolutional neural network that takes two three-dimensional input volumes and outputs a motion field. A smoothness constraint was imposed on the field by regularizing the Frobenius norm of its Jacobian matrix. CarMEN was trained and tested with data from 150 cardiac patients who underwent MRI examinations and was validated on synthetic (n = 100) and pediatric (n = 33) datasets. CarMEN was compared to five state-of-the-art nonrigid body registration methods by using several performance metrics, including Dice similarity coefficient (DSC) and end-point error. Results: On the synthetic dataset, CarMEN achieved a median DSC of 0.85, which was higher than all five methods (minimum-maximum median [or MMM], 0.67-0.84; P < .001), and a median end-point error of 1.7, which was lower than (MMM, 2.1-2.7; P < .001) or similar to (MMM, 1.6-1.7; P > .05) all other techniques. On the real datasets, CarMEN achieved a median DSC of 0.73 for Automated Cardiac Diagnosis Challenge data, which was higher than (MMM, 0.33; P < .0001) or similar to (MMM, 0.72-0.75;P > .05) all other methods, and a median DSC of 0.77 for pediatric data, which was higher than (MMM, 0.71-0.76; P < .0001) or similar to (MMM, 0.77-0.78; P > .05) all other methods. All P values were derived from pairwise testing. For all other metrics, CarMEN achieved better accuracy on all datasets than all other techniques except for one, which had the worst motion estimation accuracy. Conclusion: The proposed deep learning-based approach for three-dimensional cardiac motion estimation allowed the derivation of a motion model that balances motion characterization and image registration accuracy and achieved motion estimation accuracy comparable to or better than that of several state-of-the-art image registration algorithms. (C) RSNA, 2019	[Morales, Manuel A.; Izquierdo-Garcia, David; Aganj, Iman; Kalpathy-Cramer, Jayashree; Rosen, Bruce R.; Catana, Ciprian] Massachusetts Gen Hosp, Athinoula A Martinos Ctr Biomed Imaging, Dept Radiol, 149 13th St, Charlestown, MA 02129 USA; [Morales, Manuel A.; Izquierdo-Garcia, David; Aganj, Iman; Kalpathy-Cramer, Jayashree; Rosen, Bruce R.; Catana, Ciprian] Harvard Med Sch, 149 13th St, Charlestown, MA 02129 USA; [Morales, Manuel A.] MIT, Harvard MIT Div Hlth Sci & Technol, Cambridge, MA 02139 USA; [Aganj, Iman] MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA	Harvard University; Massachusetts General Hospital; Harvard University; Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT)	Catana, C (corresponding author), Massachusetts Gen Hosp, Athinoula A Martinos Ctr Biomed Imaging, Dept Radiol, 149 13th St, Charlestown, MA 02129 USA.; Catana, C (corresponding author), Harvard Med Sch, 149 13th St, Charlestown, MA 02129 USA.	ccatana@mgh.harvard.edu		Kalpathy-Cramer, Jayashree/0000-0001-8906-9618; Catana, Ciprian/0000-0002-3249-5971; Aganj, Iman/0000-0002-4673-1293	National Institute of Biomedical Imaging and Bioengineering of the National Institutes of Health (NIH) [T32 EB001680]; National Institute of Diabetes and Digestive and Kidney Diseases [K01DK101631]; BrightFocus Foundation [A2016172S]; National Cancer Institute [1R01CA218187-01A1]	National Institute of Biomedical Imaging and Bioengineering of the National Institutes of Health (NIH); National Institute of Diabetes and Digestive and Kidney Diseases(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Diabetes & Digestive & Kidney Diseases (NIDDK)); BrightFocus Foundation(BrightFocus Foundation); National Cancer Institute(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Cancer Institute (NCI))	Supported by the National Institute of Biomedical Imaging and Bioengineering of the National Institutes of Health (NIH) (T32 EB001680). I.A. supported by the National Institute of Diabetes and Digestive and Kidney Diseases (K01DK101631) and the BrightFocus Foundation (A2016172S). C.C. and D.I.G. supported by the National Cancer Institute (1R01CA218187-01A1).	Andreopoulos A, 2008, MED IMAGE ANAL, V12, P335, DOI 10.1016/j.media.2007.12.003; Balakrishnan G, ARXIV 180202604; Benovoy M, 2015, I S BIOMED IMAGING, P1588, DOI 10.1109/ISBI.2015.7164183; Bernard O, 2018, IEEE T MED IMAGING, V37, P2514, DOI 10.1109/TMI.2018.2837502; Catana C, 2015, SEMIN NUCL MED, V45, P212, DOI 10.1053/j.semnuclmed.2015.01.001; Dalca AV, ARXIV 180504605 CS; de Vos BD, ARXIV 170406065 CS; Eppenhof KAJ, 2018, PROC SPIE, V10574, DOI 10.1117/12.2292443; Gao B, 2016, PHYS MED BIOL, V61, P8640, DOI 10.1088/1361-6560/61/24/8640; Gigengack F, 2012, IEEE T MED IMAGING, V31, P698, DOI 10.1109/TMI.2011.2175402; Hor KN, 2010, JACC-CARDIOVASC IMAG, V3, P144, DOI 10.1016/j.jcmg.2009.11.006; Kolbitsch C, 2017, J NUCL MED, V58, P846, DOI 10.2967/jnumed.115.171728; Kwitt R, ARXIV 170310908 CS; Lamacie MM, 2017, EUR RADIOL, V27, P1404, DOI 10.1007/s00330-016-4514-0; Lester H, 1999, PATTERN RECOGN, V32, P129, DOI 10.1016/S0031-3203(98)00095-8; Li H, ARXIV 180104012 CS; Liao R, ARXIV 161110336 CS; Lowekamp BC, 2013, FRONT NEUROINFORM, V7, DOI 10.3389/fninf.2013.00045; LowekampB Gabehart, 2015, SIMPLEELASTIX SIMPLE; Pang JN, 2014, MAGN RESON MED, V72, P1208, DOI 10.1002/mrm.25450; Qin C, ARXIV 180604066 CS; Roh M.-M., 2017, INT C MEDICAL IMAGE, P266, DOI DOI 10.1007/978-3-319-66182-7_31; Savioli N, ARXIV 180901015 CS S; Segars WP, 2010, MED PHYS, V37, P4902, DOI 10.1118/1.3480985; Sheikhjafari A, UNSUPERVISED DEFORMA; Sloan J. M., 2018, P 11 INT JOINT C BIO, P89; Sokooti H, 2017, LECT NOTES COMPUTER, V10433, P232, DOI 10.1007/978-3-319-66182-7_27; Tarroni G, ARXIV 180309354 CS; Toth D, 2018, INT J COMPUT ASS RAD, V13, P1141, DOI 10.1007/s11548-018-1774-y; Vercauteren T, 2009, NEUROIMAGE, V45, pS61, DOI 10.1016/j.neuroimage.2008.10.040; Wissmann L, 2014, J CARDIOVASC MAGN R, V16, DOI 10.1186/s12968-014-0063-3; Yaniv Z, 2018, J DIGIT IMAGING, V31, P290, DOI 10.1007/s10278-017-0037-8; Zhang L, 2012, IEEE IMAGE PROC, P1477, DOI 10.1109/ICIP.2012.6467150; Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865; Zhu XX, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051477	35	14	14	0	3	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2019	1	4							e180080	10.1148/ryai.2019180080	http://dx.doi.org/10.1148/ryai.2019180080			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CO	32076659	Green Published			2022-12-18	WOS:000826292900003
J	Parakh, A; Lee, H; Lee, JH; Eisner, BH; Sahani, DV; Do, S				Parakh, Anushri; Lee, Hyunkwang; Lee, Jeong Hyun; Eisner, Brian H.; Sahani, Dushyant, V; Do, Synho			Urinary Stone Detection on CT Images Using Deep Convolutional Neural Networks: Evaluation of Model Performance and Generalization	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To investigate the diagnostic accuracy of cascading convolutional neural network (CNN) for urinary stone detection on un-enhanced CT images and to evaluate the performance of pretrained models enriched with labeled CT images across different scanners. Materials and Methods: This HIPAA-compliant, institutional review board-approved, retrospective clinical study used unenhanced abdominopelvic CT scans from 535 adults suspected of having urolithiasis. The scans were obtained on two scanners (scanner 1 [hereafter S1] and scanner 2 [hereafter S2]). A radiologist reviewed clinical reports and labeled cases for determination of reference standard. Stones were present on 279 (S1, 131; S2, 148) and absent on 256 (S1, 158; S2, 98) scans. One hundred scans (50 from each scanner) were randomly reserved as the test dataset, and the rest were used for developing a cascade of two CNNs: The first CNN identified the extent of the urinary tract, and the second CNN detected presence of stone. Nine variations of models were developed through the combination of different training data sources (S1, S2, or both [hereafter SB]) with (ImageNet, GrayNet) and without (Random) pretrained CNNs. First, models were compared for generalizability at the section level. Second, models were assessed by using area under the receiver operating characteristic curve (AUC) and accuracy at the patient level with test data-set from both scanners (n = 100). Results: The GrayNet-pretrained model showed higher classifier exactness than did ImageNet-pretrained or Random-initialized models when tested by using data from the same or different scanners at section level. At the patient level, the AUC for stone detection was 0.92-0.95, depending on the model. Accuracy of GrayNet-SB (95%) was higher than that of ImageNet-SB (91%) and Random-SB (88%). For stones larger than 4 mm, all models showed similar performance (false-negative results: two of 34). For stones smaller than 4 mm, the number of false-negative results for GrayNet-SB, ImageNet-SB, and Random-SB were one of 16, three of 16, and five of 16, respectively. GrayNet-SB identified stones in all 22 test cases that had obstructive uropathy. Conclusion: A cascading model of CNNs can detect urinary tract stones on unenhanced CT scans with a high accuracy (AUC, 0.954). Performance and generalization of CNNs across scanners can be enhanced by using transfer learning with datasets enriched with labeled medical images. (C) RSNA, 2019	[Parakh, Anushri; Lee, Hyunkwang; Sahani, Dushyant, V; Do, Synho] Massachusetts Gen Hosp, Dept Radiol, 55 Fruit St,White 270, Boston, MA 02114 USA; [Eisner, Brian H.] Massachusetts Gen Hosp, Dept Urol, 55 Fruit St,White 270, Boston, MA 02114 USA; [Lee, Hyunkwang] Harvard Univ, John A Paulson Sch Engn & Appl Sci, Cambridge, MA 02138 USA; [Lee, Jeong Hyun] Sungkyunkwan Univ, Sch Med, Samsung Med Ctr, Dept Radiol, Seoul, South Korea; [Lee, Jeong Hyun] Sungkyunkwan Univ, Sch Med, Ctr Imaging Sci, Seoul, South Korea; [Sahani, Dushyant, V] Univ Washington, Dept Radiol, Seattle, WA 98195 USA	Harvard University; Massachusetts General Hospital; Harvard University; Massachusetts General Hospital; Harvard University; Sungkyunkwan University (SKKU); Samsung Medical Center; Sungkyunkwan University (SKKU); University of Washington; University of Washington Seattle	Sahani, DV (corresponding author), Massachusetts Gen Hosp, Dept Radiol, 55 Fruit St,White 270, Boston, MA 02114 USA.; Sahani, DV (corresponding author), Univ Washington, Dept Radiol, Seattle, WA 98195 USA.	dsahani908@icloud.com		Lee, Jeong Hyun/0000-0002-7125-8899; Parakh, Anushri/0000-0002-4778-2383; Sahani, Dushyant/0000-0002-8522-1018; Do, Synho/0000-0001-6211-7050; Lee, Hyunkwang/0000-0002-4806-6709				Al Kadhi O, 2017, OPEN ACCESS EMERG M, V9, P53, DOI 10.2147/OAEM.S138470; AlBadawy EA, 2018, MED PHYS, V45, P1150, DOI 10.1002/mp.12752; American College of Radiology, ACR APPROPRIATENESS; Amit G, 2017, PROC SPIE, V10134, DOI 10.1117/12.2249981; [Anonymous], 1999, 10153 BS EN; Berlyand Y, 2018, AM J EMERG MED, V36, P1515, DOI 10.1016/j.ajem.2018.01.017; Chen ZY, 2019, J CLIN UROL, V12, P296, DOI 10.1177/2051415818813820; Cole JH, 2017, NEUROIMAGE, V163, P115, DOI 10.1016/j.neuroimage.2017.07.059; Davis J., 2006, 23 INT C MACH LEARN, P233, DOI [10.1145/1143844.1143874, DOI 10.1145/1143844.1143874]; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dobbins JM, 1997, EMERG RADIOL, V4, P303; Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056; Foster G, 2012, EMERGENCY DEP VISITS; Fwu CW, 2013, KIDNEY INT, V83, P479, DOI 10.1038/ki.2012.419; Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401; Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216; Hadad O, 2017, I S BIOMED IMAGING, P109, DOI 10.1109/ISBI.2017.7950480; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; IBM Corp, 2021, IBM SPSS STAT MAC VE; Kanzaria HK, 2014, AM J EMERG MED, V32, P1253, DOI 10.1016/j.ajem.2014.07.038; Kim HG, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI); Kohli MD, 2017, J DIGIT IMAGING, V30, P392, DOI 10.1007/s10278-017-9976-3; Lakhani P, 2017, RADIOLOGY, V284, P574, DOI 10.1148/radiol.2017162326; Lee H, 2017, J DIGIT IMAGING, V30, P427, DOI 10.1007/s10278-017-9955-8; Levin S, 2018, ANN EMERG MED, V71, P565, DOI 10.1016/j.annemergmed.2017.08.005; Lin WC, 2007, J UROLOGY, V178, P907, DOI 10.1016/j.juro.2007.05.042; Metser U, 2009, AM J ROENTGENOL, V192, P1509, DOI 10.2214/AJR.08.1545; Mordang JJ, 2016, LECT NOTES COMPUT SC, V9699, P35, DOI 10.1007/978-3-319-41546-8_5; NESTEROV IE, 1983, DOKL AKAD NAUK SSSR+, V269, P543; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Prevedello LM, 2017, RADIOLOGY, V285, P923, DOI 10.1148/radiol.2017162664; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Schoenfeld EM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169160; Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162; Szegedy C, CVPR2016; Turk C, 2016, EUR UROL, V69, P475, DOI 10.1016/j.eururo.2015.07.041; Wang DC, 2015, AM J ROENTGENOL, V205, P1222, DOI 10.2214/AJR.14.14057; Wang JH, 2009, MED PHYS, V36, P4592, DOI 10.1118/1.3222872; Westphalen AC, 2011, ACAD EMERG MED, V18, P700, DOI 10.1111/j.1553-2712.2011.01103.x; Yosinski J, 2014, ADV NEUR IN, V27	40	14	14	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2019	1	4							e180066	10.1148/ryai.2019180066	http://dx.doi.org/10.1148/ryai.2019180066			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CO	33937795	Green Published			2022-12-18	WOS:000826292900001
J	Hu, QY; Whitney, HM; Li, H; Ji, Y; Liu, PF; Giger, ML				Hu, Qiyuan; Whitney, Heather M.; Li, Hui; Ji, Yu; Liu, Peifang; Giger, Maryellen L.			Improved Classification of Benign and Malignant Breast Lesions Using Deep Feature Maximum Intensity Projection MRI in Breast Cancer Diagnosis Using Dynamic Contrast-enhanced MRI	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							CONVOLUTIONAL NEURAL-NETWORKS; OPERATING CHARACTERISTIC CURVES; IMAGE-ANALYSIS; ROC CURVES; RISK	Purpose: To develop a deep transfer learning method that incorporates four-dimensional (4D) information in dynamic contrast-enhanced (DCE) MRI to classify benign and malignant breast lesions. Materials and Methods: The retrospective dataset is composed of 1990 distinct lesions (1494 malignant and 496 benign) from 1979 women (mean age, 47 years 6 10). Lesions were split into a training and validation set of 1455 lesions (acquired in 2015-2016) and an independent test set of 535 lesions (acquired in 2017). Features were extracted from a convolutional neural network (CNN), and lesions were classified as benign or malignant using support vector machines. Volumetric information was collapsed into two dimensions by taking the maximum intensity projection (MIP) at the image level or feature level within the CNN architecture. Performances were evaluated using the area under the receiver operating characteristic curve (AUC) as the figure of merit and were compared using the DeLong test. Results: The image MIP and feature MIP methods yielded AUCs of 0.91 (95% CI: 0.87, 0.94) and 0.93 (95% CI: 0.91, 0.96), respectively, for the independent test set. The feature MIP method achieved higher performance than the image MIP method (Delta AUC 95% CI: 0.003, 0.051; P = .03). Conclusion: Incorporating 4D information in DCE MRI by MIP of features in deep transfer learning demonstrated superior classification performance compared with using MIP images as input in the task of distinguishing between benign and malignant breast lesions. (C) RSNA, 2021	[Hu, Qiyuan; Whitney, Heather M.; Li, Hui; Giger, Maryellen L.] Univ Chicago, Dept Radiol, 5841 S Maryland Ave,MC2026, Chicago, IL 60637 USA; [Whitney, Heather M.] Wheaton Coll, Dept Phys, Wheaton, IL 60187 USA; [Ji, Yu; Liu, Peifang] Tianjin Med Univ, Tianjin Med Univ Canc Inst & Hosp, Natl Clin Res Ctr Canc, Dept Breast Imaging, Tianjin, Peoples R China	University of Chicago; Wheaton College; Tianjin Medical University	Hu, QY (corresponding author), Univ Chicago, Dept Radiol, 5841 S Maryland Ave,MC2026, Chicago, IL 60637 USA.	qhu@uchicago.edu	Hu, Qiyuan/ABR-5306-2022; Hu, Qiyuan/HDM-5763-2022	Hu, Qiyuan/0000-0002-3326-6441; Li, Hui/0000-0003-3139-2898; Whitney, Heather/0000-0002-7258-1102; Giger, Maryellen/0000-0001-5482-9728	National Institutes of Health Quantitative Imaging Network [U01CA195564]; National Institutes of Health National Cancer Institute [R15 CA227948]; National Institutes of Health [S10 OD025081]; Radiological Society of North America/American Association of Physicists in Medicine Graduate Fellowship	National Institutes of Health Quantitative Imaging Network(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); National Institutes of Health National Cancer Institute(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Cancer Institute (NCI)); National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Radiological Society of North America/American Association of Physicists in Medicine Graduate Fellowship	Supported by the National Institutes of Health Quantitative Imaging Network grant U01CA195564, National Institutes of Health National Cancer Institute grant R15 CA227948, and National Institutes of Health grant S10 OD025081 (Shared Instrument Grant), and Radiological Society of North America/American Association of Physicists in Medicine Graduate Fellowship.	Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Antropova N, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.1.014503; Antropova N, 2017, MED PHYS, V44, P5162, DOI 10.1002/mp.12453; Bi WL, 2019, CA-CANCER J CLIN, V69, P127, DOI 10.3322/caac.21552; Chen L, 2013, PHYS MED BIOL, V58, P1663, DOI 10.1088/0031-9155/58/6/1663; Chen L, 2012, MED PHYS, V39, P1435, DOI 10.1118/1.3685462; Dalmis MU, 2019, INVEST RADIOL, V54, P325, DOI 10.1097/RLI.0000000000000544; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Donahue J, 2014, PR MACH LEARN RES, V32; EFRON B, 1987, J AM STAT ASSOC, V82, P171, DOI 10.2307/2289144; Garrett JW, 2018, MED PHYS, V45, P2009, DOI 10.1002/mp.12864; Giger ML, 2013, ANNU REV BIOMED ENG, V15, P327, DOI 10.1146/annurev-bioeng-071812-152416; Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401; Hawass NED, 1997, BRIT J RADIOL, V70, P360, DOI 10.1259/bjr.70.832.9166071; Herent P, 2019, DIAGN INTERV IMAG, V100, P219, DOI 10.1016/j.diii.2019.02.008; Horsch K, 2008, ACAD RADIOL, V15, P1446, DOI 10.1016/j.acra.2008.04.022; Hu Q, ARXIV 191103022; Hu QY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-67441-4; Huynh BQ, 2016, J MED IMAGING, V3, DOI 10.1117/1.JMI.3.3.034501; Ji Y, 2019, CANCER IMAGING, V19, DOI 10.1186/s40644-019-0252-2; Jolliffe IT, 2002, ENCY STATIST BEHAV S, DOI [10.1007/0-387-22440-8_13, 10.1007/b98835]; Kuhl CK, 2005, J CLIN ONCOL, V23, P8469, DOI 10.1200/JCO.2004.00.4960; Li J, 2017, PROC SPIE, V10138, DOI 10.1117/12.2254716; McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996; METZ CE, 1978, SEMIN NUCL MED, V8, P283, DOI 10.1016/S0001-2998(78)80014-2; Metz CE, 1999, J MATH PSYCHOL, V43, P1, DOI 10.1006/jmps.1998.1218; Metz CE, 1998, STAT MED, V17, P1033, DOI 10.1002/(SICI)1097-0258(19980515)17:9<1033::AID-SIM784>3.0.CO;2-Z; Morrow M, 2011, LANCET, V378, P1804, DOI 10.1016/S0140-6736(11)61350-0; Obuchowski NA, 2003, RADIOLOGY, V229, P3, DOI 10.1148/radiol.2291010898; Pickles MD, 2015, EUR RADIOL, V25, P1097, DOI 10.1007/s00330-014-3502-5; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Shawe-Taylor J, 2011, NEUROCOMPUTING, V74, P3609, DOI 10.1016/j.neucom.2011.06.026; Sheth D, 2020, J MAGN RESON IMAGING, V51, P1310, DOI 10.1002/jmri.26878; Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162; Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302; Turnbull LW, 2009, NMR BIOMED, V22, P28, DOI 10.1002/nbm.1273; Whitney HM, 2020, P IEEE, V108, P163, DOI [10.1109/jproc.2019.2950187, 10.1109/JPROC.2019.2950187]; Yosinski J, 2014, ADV NEUR IN, V27	39	13	13	4	5	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2021	3	3							e200159	10.1148/ryai.2021200159	http://dx.doi.org/10.1148/ryai.2021200159			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SA	34235439	Green Published			2022-12-18	WOS:000826907000005
J	Xue, H; Davies, RH; Brown, LAE; Knott, KD; Kotecha, T; Fontana, M; Plein, S; Moon, JC; Kellman, P				Xue, Hui; Davies, Rhodri H.; Brown, Louise A. E.; Knott, Kristopher D.; Kotecha, Tushar; Fontana, Marianna; Plein, Sven; Moon, James C.; Kellman, Peter			Automated Inline Analysis of Myocardial Perfusion MRI with Deep Learning	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To develop a deep neural network-based computational workflow for inline myocardial perfusion analysis that automatically delineates the myocardium, which improves the clinical workflow and offers a "one-click" solution. Materials and Methods: In this retrospective study, consecutive adenosine stress and rest perfusion scans were acquired from three hospitals between October 1, 2018 and February 27, 2019. The training and validation set included 1825 perfusion series from 1034 patients (mean age, 60.6 years +/- 14.2 [standard deviation]). The independent test set included 200 scans from 105 patients (mean age, 59.1 years +/- 12.5). A convolutional neural network (CNN) model was trained to segment the left ventricular cavity, myocardium, and right ventricle by processing an incoming time series of perfusion images. Model outputs were compared with manual ground truth for accuracy of segmentation and flow measures derived on a global and per-sector basis with t test performed for statistical significance. The trained models were integrated onto MR scanners for effective inference. Results: The mean Dice ratio of automatic and manual segmentation was 0.93 +/- 0.04. The CNN performed similarly to manual segmentation and flow measures for mean stress myocardial blood flow (MBF; 2.25 mL/min/g +/- 0.59 vs 2.24 mL/min/g +/- 0.59, P=.94) and mean rest MBF (1.08 mL/min/g +/- 0.23 vs 1.07 mL/min/g +/- 0.23, P=.83). The per-sector MBF values showed no difference between the CNN and manual assessment (P=.92). A central processing unit-based model inference on the MR scanner took less than 1 second for a typical perfusion scan of three slices. Conclusion: The described CNN was capable of cardiac perfusion mapping and integrated an automated inline implementation on the MR scanner, enabling one-click analysis and reporting in a manner comparable to manual assessment. Published under a CC BY 4.0 license.	[Xue, Hui; Kellman, Peter] NHLBI, NIH, 10 Ctr Dr, Bethesda, MD 20892 USA; [Davies, Rhodri H.; Knott, Kristopher D.; Moon, James C.] Barts Hlth NHS Trust, Barts Heart Ctr, London, England; [Brown, Louise A. E.; Plein, Sven] Univ Leeds, Leeds Inst Cardiovasc & Metab Med, Dept Biomed Imaging Sci, Leeds, W Yorkshire, England; [Kotecha, Tushar; Fontana, Marianna] Royal Free Hosp, Natl Amyloidosis Ctr, London, England		Xue, H (corresponding author), NHLBI, NIH, 10 Ctr Dr, Bethesda, MD 20892 USA.	hui.xue@nih.gov	Moon, James/AAA-9905-2020	Moon, James/0000-0001-8071-1491; Xue, Hui/0000-0002-4561-5530; Davies, Rhodri/0000-0001-7630-7517; Knott, Kristopher/0000-0003-1611-817X; Brown, Louise Anne Elizabeth/0000-0002-1327-6482; Plein, Sven/0000-0002-0997-4384				Acampa W, 2012, EUR J NUCL MED MOL I, V39, P387, DOI 10.1007/s00259-011-1983-x; Bai WJ, 2018, J CARDIOVASC MAGN R, V20, DOI 10.1186/s12968-018-0471-x; Bernard O, 2018, IEEE T MED IMAGING, V37, P2514, DOI 10.1109/TMI.2018.2837502; Bluemke DA, 2020, RADIOLOGY, V294, P487, DOI 10.1148/radiol.2019192515; Camaioni C, 2020, HEART, V106, P824, DOI 10.1136/heartjnl-2019-315848; Huttenlocher D. P., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P654, DOI 10.1109/CVPR.1992.223209; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Kellman P, 2017, J CARDIOVASC MAGN R, V19, DOI 10.1186/s12968-017-0355-5; Knott KD, 2020, CIRCULATION, V141, P1282, DOI 10.1161/CIRCULATIONAHA.119.044666; Kotecha T, 2019, JACC-CARDIOVASC IMAG, V12, P1958, DOI 10.1016/j.jcmg.2018.12.022; Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826; Maas A. L., 2013, P ICML; Moccia S, 2019, MAGN RESON MATER PHY, V32, P187, DOI 10.1007/s10334-018-0718-4; Nagel E, 2019, NEW ENGL J MED, V380, P2418, DOI 10.1056/NEJMoa1716734; Paszke A., 2017, 31 C NEURAL INFORM P, P1, DOI DOI 10.1017/CB09781107707221.009; Peng P, 2016, MAGN RESON MATER PHY, V29, P155, DOI 10.1007/s10334-015-0521-4; Ronneberger O., 2015, P INT C MED IMAG COM, P234, DOI [DOI 10.1007/978-3-319-24574-4_28, DOI 10.48550/ARXIV.1505.04597]; Scannell CM, 2020, J MAGN RESON IMAGING, V51, P1689, DOI 10.1002/jmri.26983; Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634; Xue H., 2019, P 27 ANN ISMRM M EXH, V27, P4837; Xue H, 2020, MAGN RESON MED, V83, P712, DOI 10.1002/mrm.27954; Xue H, 2020, MAGN RESON MED, V84, P2788, DOI 10.1002/mrm.28291; Xue H, 2012, MAGN RESON MED, V67, P1644, DOI 10.1002/mrm.23153; Zhang ZP, 2019, IEEE ACM T COMPUT BI, V16, P407, DOI 10.1109/TCBB.2017.2704587; Zorach B, 2018, J CARDIOVASC MAGN R, V20, DOI 10.1186/s12968-018-0435-1	25	13	13	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2020	2	6							e200009	10.1148/ryai.2020200009	http://dx.doi.org/10.1148/ryai.2020200009			8	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CZ	33330849	Green Submitted, Green Published			2022-12-18	WOS:000826480100007
J	Namiri, NK; Flament, I; Astuto, B; Shah, R; Tibrewala, R; Caliva, F; Link, TM; Pedoia, V; Majumdar, S				Namiri, Nikan K.; Flament, Io; Astuto, Bruno; Shah, Rutwik; Tibrewala, Radhika; Caliva, Francesco; Link, Thomas M.; Pedoia, Valentina; Majumdar, Sharmila			Deep Learning for Hierarchical Severity Staging of Anterior Cruciate Ligament Injuries from MRI	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To evaluate the diagnostic utility of two convolutional neural networks (CNNs) for severity staging of anterior cruciate ligament (ACL) injuries. Materials and Methods: In this retrospective study, 1243 knee MR images (1008 intact, 18 partially torn, 77 fully torn, and 140 reconstructed ACLs) from 224 patients (mean age, 47 years +/- 14 [standard deviation]; 54% women) were analyzed. The MRI examinations were performed between 2011 and 2014. A modified scoring metric was used. Classification of ACL injuries using deep learning involved use of two types of CNN, one with three-dimensional (3D) and the other with two-dimensional (2D) convolutional kernels. Performance metrics included sensitivity, specificity, weighted Cohen k, and overall accuracy, and the McNemar test was used to compare the performance of the CNNs. Results: The overall accuracies for ACL injury classification using the 3D CNN and 2D CNN were 89% (225 of 254) and 92% (233 of 254), respectively (P=.27), and both CNNs had a weighted Cohen k of 0.83. The 2D CNN and 3D CNN performed similarly in classifying intact ACLs (2D CNN, sensitivity of 93% [188 of 203] and specificity of 90% [46 of 51] vs 3D CNN, sensitivity of 89% [180 of 203] and specificity of 88% [45 of 51]). Classification of full tears by both networks was also comparable (2D CNN, sensitivity of 82% [14 of 17] and specificity of 94% [222 of 237] vs 3D CNN, sensitivity of 76% [13 of 17] and specificity of 100% [236 of 237]). The 2D CNN classified all reconstructed ACLs correctly. Conclusion: Two-dimensional and 3D CNNs applied to ACL lesion classification had high sensitivity and specificity, suggesting that these networks could be used to help nonexperts grade ACL injuries. (C) RSNA, 2020	[Namiri, Nikan K.] Univ Calif San Francisco, Dept Radiol & Biomed Imaging, 1700 Fourth St,Suite 201,QB3 Bldg, San Francisco, CA 94107 USA; Univ Calif San Francisco, Ctr Intelligent Imaging, 1700 Fourth St,Suite 201,QB3 Bldg, San Francisco, CA 94107 USA		Namiri, NK (corresponding author), Univ Calif San Francisco, Dept Radiol & Biomed Imaging, 1700 Fourth St,Suite 201,QB3 Bldg, San Francisco, CA 94107 USA.	nikan.namiri@ucsf.edu	; Astuto Arouche Nunes, Bruno/C-2367-2014	Tibrewala, Radhika/0000-0002-3837-1144; Astuto Arouche Nunes, Bruno/0000-0002-8890-7963; Namiri, Nikan/0000-0003-2943-9546; Link, Thomas M./0000-0002-2850-8143				Ai T, 2012, CLIN RADIOL, V67, pE58, DOI 10.1016/j.crad.2012.07.020; Anumanchipalli GK, 2019, NATURE, V568, P493, DOI 10.1038/s41586-019-1119-1; Bien N, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002699; BRANDT KD, 1991, ARTHRITIS RHEUM, V34, P1381; Brophy RH, 2009, AM J SPORT MED, V37, P2102, DOI 10.1177/0363546509349035; Chang PD, 2019, J DIGIT IMAGING, V32, P980, DOI 10.1007/s10278-019-00193-4; Crawford R, 2007, BRIT MED BULL, V84, P5, DOI 10.1093/bmb/ldm022; Cui Y, 2018 IEEE CVF C COMP, P4109; Germann C, 2020, INVEST RADIOL; Han S, 2015, ADV NEUR IN, V28; Hong ZP, 2019, INT ORTHOP, V43, P1123, DOI 10.1007/s00264-018-4099-0; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Hunter DJ, 2014, OSTEOARTHR CARTILAGE, V22, P959, DOI 10.1016/j.joca.2014.05.014; Hunter DJ, 2011, OSTEOARTHR CARTILAGE, V19, P990, DOI 10.1016/j.joca.2011.05.004; Johnston JT, 2018, AM J SPORT MED, V46, P862, DOI 10.1177/0363546518756328; Kretzschmar M, 2015, ARTHRIT CARE RES, V67, P1272, DOI 10.1002/acr.22586; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Li K, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-08133-4; Liu F, 2019, RADIOL ARTIF INTELL, V1; Pedoia V, 2019, J MAGN RESON IMAGING, V49, P400, DOI 10.1002/jmri.26246; Peterfy CG, 2004, OSTEOARTHR CARTILAGE, V12, P177, DOI 10.1016/j.joca.2003.11.003; Prodromos CC, 2007, ARTHROSCOPY, V23, P1320, DOI 10.1016/j.arthro.2007.07.003; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Roemer FW, 2014, OSTEOARTHR CARTILAGE, V22, P668, DOI 10.1016/j.joca.2014.03.006; Shakoor D, 2019, J MAGN RESON IMAGING, V50, P1545, DOI 10.1002/jmri.26713; Spindler KP, 2008, NEW ENGL J MED, V359, P2135, DOI 10.1056/NEJMcp0804745; Suter LG, 2017, ARTHRIT CARE RES, V69, P201, DOI 10.1002/acr.22940; Warrens MJ, 2012, ADV DATA ANAL CLASSI, V6, P67, DOI 10.1007/s11634-011-0094-7; Yang X, 2019, J ORTHOP SURG RES, V14, DOI 10.1186/s13018-019-1172-3; Zhou X. H., 2011, STAT METHODS DIAGNOS, DOI 10.1002/9780470906514	30	13	16	2	8	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2020	2	4							e190207	10.1148/ryai.2020190207	http://dx.doi.org/10.1148/ryai.2020190207			8	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CX	32793889	Green Published			2022-12-18	WOS:000826472900008
J	Pan, I; Baird, GL; Mutasa, S; Merck, D; Ruzal-Shapiro, C; Swenson, DW; Ayyala, RS				Pan, Ian; Baird, Grayson L.; Mutasa, Simukayi; Merck, Derek; Ruzal-Shapiro, Carrie; Swenson, David W.; Ayyala, Rama S.			Rethinking Greulich and Pyle: A Deep Learning Approach to Pediatric Bone Age Assessment Using Pediatric Trauma Hand Radiographs	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To develop a deep learning approach to bone age assessment based on a training set of developmentally normal pediatric hand radiographs and to compare this approach with automated and manual bone age assessment methods based on Greulich and Pyle (GP). Methods: In this retrospective study, a convolutional neural network (trauma hand radiograph-trained deep learning bone age assessment method [TDL-BAAM]) was trained on 15 129 frontal view pediatric trauma hand radiographs obtained between December 14, 2009, and May 31, 2017, from Children's Hospital of New York, to predict chronological age. A total of 214 trauma hand radiographs from Hasbro Children's Hospital were used as an independent test set. The test set was rated by the TDL-BAAM model as well as a GP-based deep learning model (GPDL-BAAM) and two pediatric radiologists (radiologists 1 and 2) using the GP method. All ratings were compared with chronological age using mean absolute error (MAE), and standard concordance analyses were performed. Results: The MAE of the TDL-BAAM model was 11.1 months, compared with 12.9 months for GPDL-BAAM (P=.0005), 14.6 months for radiologist 1 (P<.0001), and 16.0 for radiologist 2 (P<.0001). For TDL-BAAM, 95.3% of predictions were within 24 months of chronological age compared with 91.6% for GPDL-BAAM (P=.096), 86.0% for radiologist 1 (P<.0001), and 84.6% for radiologist 2 (P<.0001). Concordance was high between all methods and chronological age (intraclass coefficient > 0.93). Deep learning models demonstrated a systematic bias with a tendency to overpredict age for younger children versus radiologists who showed a consistent mean bias. Conclusion: A deep learning model trained on pediatric trauma hand radiographs is on par with automated and manual GP-based methods for bone age assessment and provides a foundation for developing population-specific deep learning algorithms for bone age assessment in modern pediatric populations. (C) RSNA, 2020	[Pan, Ian; Swenson, David W.; Ayyala, Rama S.] Brown Univ, Warren Alpert Med Sch, Hasbro Childrens Hosp, Dept Diagnost Imaging,Rhode Isl Hosp, 593 Eddy St, Providence, RI 02903 USA; [Baird, Grayson L.] Rhode Isl Hosp, Dept Diagnost Imaging & Lifespan Biostat Core, Providence, RI USA; [Mutasa, Simukayi; Ruzal-Shapiro, Carrie] Columbia Univ, Med Ctr, Dept Radiol, New York, NY USA; [Merck, Derek] Univ Florida, Shards Hosp, Dept Emergency Med, Gainesville, FL USA		Pan, I (corresponding author), Brown Univ, Warren Alpert Med Sch, Hasbro Childrens Hosp, Dept Diagnost Imaging,Rhode Isl Hosp, 593 Eddy St, Providence, RI 02903 USA.	ianpan358@gmail.com	; Merck, Derek/H-7726-2014	Pan, Ian/0000-0002-0650-6614; Merck, Derek/0000-0003-3242-517X				Alshamrani K, 2019, EUR RADIOL, V29, P2910, DOI 10.1007/s00330-018-5792-5; [Anonymous], 1999, 10153 BS EN; [Anonymous], RHOD ISL RAC ETHN OR; [Anonymous], TOTAL POPULATION MUT; Berst MJ, 2001, AM J ROENTGENOL, V176, P507, DOI 10.2214/ajr.176.2.1760507; Breen MA, 2016, PEDIATR RADIOL, V46, P1269, DOI 10.1007/s00247-016-3618-7; Bull RK, 1999, ARCH DIS CHILD, V81, P172, DOI 10.1136/adc.81.2.172; Dallora AL, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0220242; Greulich W., 1999, RADIOGRAPHIC ATLAS B; Halabi SS, 2019, RADIOLOGY, V290, P498, DOI 10.1148/radiol.2018180736; Huang G, ARXIV 160806993 PREP; JOHNSON GF, 1973, AM J ROENTGENOL, V118, P320, DOI 10.2214/ajr.118.2.320; Kim JR, 2017, AM J ROENTGENOL, V209, P1374, DOI 10.2214/AJR.17.18224; Larson DB, 2018, RADIOLOGY, V287, P313, DOI 10.1148/radiol.2017170236; Lee H, 2017, J DIGIT IMAGING, V30, P427, DOI 10.1007/s10278-017-9955-8; Martin DD, 2011, HORM RES PAEDIAT, V76, P1, DOI 10.1159/000329372; Mohammed RB, 2015, J PHARM BIOALLIED SC, V7, P218, DOI 10.4103/0975-7406.160031; Mutasa S, 2018, J DIGIT IMAGING, V31, P513, DOI 10.1007/s10278-018-0053-3; Paszke A., 2017, AUTOMATIC DIFFERENTI, DOI DOI 10.1016/J.COMPAG.2018.04.002; Spampinato C, 2017, MED IMAGE ANAL, V36, P41, DOI 10.1016/j.media.2016.10.010; Tajmir SH, 2019, SKELETAL RADIOL, V48, P275, DOI 10.1007/s00256-018-3033-2; Thodberg HH, 2010, ACAD RADIOL, V17, P1425, DOI 10.1016/j.acra.2010.06.007; Thodberg HH, 2009, IEEE T MED IMAGING, V28, P52, DOI 10.1109/TMI.2008.926067; Tong C, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1091-6; Tsehay B, 2017, ETHIOP J HEALTH SCI, V27, P631, DOI 10.4314/ejhs.v27i6.8; Zhang AF, 2009, RADIOLOGY, V250, P228, DOI 10.1148/radiol.2493080468	26	13	13	2	2	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2020	2	4							e190198	10.1148/ryai.2020190198	http://dx.doi.org/10.1148/ryai.2020190198			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CX	33937834	Green Published			2022-12-18	WOS:000826472900007
J	Zhu, YJ; Fahmy, AS; Duan, C; Nakamori, S; Nezafat, R				Zhu, Yanjie; Fahmy, Ahmed S.; Duan, Chong; Nakamori, Shiro; Nezafat, Reza			Automated Myocardial T2 and Extracellular Volume Quantification in Cardiac MRI Using Transfer Learning-based Myocardium Segmentation	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							MOTION CORRECTION; INVERSION-RECOVERY; T-1; REPRODUCIBILITY; REGISTRATION; MOLLI; VENTRICLE; NETWORKS; DISEASE; SHMOLLI	Purpose: To assess the performance of an automated myocardial T2 and extracellular volume (ECV) quantification method using transfer learning of a fully convolutional neural network (CNN) pretrained to segment the myocardium on T1 mapping images. Materials and Methods: A single CNN previously trained and tested using 11 550 manually segmented native T1-weighted images was used to segment the myocardium for automated myocardial T2 and ECV quantification. Reference measurements from 1525 manually processed T2 maps and 1525 ECV maps (from 305 patients) were used to evaluate the performance of the pretrained network. Correlation coefficient (R) and Bland-Altman analysis were used to assess agreement between automated and reference values on per-patient, per-slice, and per-segment analyses. Furthermore, transfer learning effectiveness in the CNN was evaluated by comparing its performance to four CNNs trained using manually segmented T2-weighted and postcontrast T1-weighted images and initialized using random-weights or weights of the pretrained CNN. Results: T2 and ECV measurements using the pretrained CNN strongly correlated with reference values in per-patient (T2: R = 0.88, 95% confidence interval [CI]: 0.85, 0.91; ECV: R = 0.91, 95% CI: 0.89, 0.93), per-slice (T2: R = 0.83, 95% CI: 0.81, 0.85; ECV: R = 0.84, 95% CI: 0.82, 0.86), and per-segment (T2: R = 0.75, 95% CI: 0.74, 0.77; ECV: R = 0.76, 95% CI: 0.75, 0.77) analyses. In Bland-Altman analysis, the automatic and reference values were in good agreement in per-patient (T2: 0.3 msec +/- 2.9; ECV: -0.3% +/- 1.7), per-slice (T2: 0.1 msec +/- 4.6; ECV: -0.3% +/- 2.5), and per-segment (T2: 0.0 msec +/- 6.5; ECV: -0.4% +/- 3.5) analyses. The performance of the pretrained network was comparable to networks refined or trained from scratch using additional manually segmented images. Conclusion: Transfer learning extends the utility of pretrained CNN-based automated native T1 mapping analysis to T2 and ECV mapping without compromising performance. (c) RSNA, 2020	[Zhu, Yanjie; Fahmy, Ahmed S.; Duan, Chong; Nakamori, Shiro; Nezafat, Reza] Beth Israel Deaconess Med Ctr, Div Cardiovasc, Dept Med, 330 Brookline Ave, Boston, MA 02215 USA; [Zhu, Yanjie; Fahmy, Ahmed S.; Duan, Chong; Nakamori, Shiro; Nezafat, Reza] Harvard Med Sch, 330 Brookline Ave, Boston, MA 02215 USA; [Zhu, Yanjie] Chinese Acad Sci, Paul C Lauterbur Res Ctr Biomed Imaging, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China; [Duan, Chong] Pfizer, Digital Med & Translat Imaging Grp, Cambridge, MA USA	Harvard University; Beth Israel Deaconess Medical Center; Harvard University; Harvard Medical School; Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS; Pfizer	Nezafat, R (corresponding author), Beth Israel Deaconess Med Ctr, Div Cardiovasc, Dept Med, 330 Brookline Ave, Boston, MA 02215 USA.; Nezafat, R (corresponding author), Harvard Med Sch, 330 Brookline Ave, Boston, MA 02215 USA.	rnezafat@bidmc.harvard.edu	Nakamori, Shiro/GQP-8013-2022	Nakamori, Shiro/0000-0001-8165-5268; Nezafat, Reza/0000-0002-1963-7138; /0000-0003-1992-6893	National Institutes of Health [R01HL129185, R01HL129157]; American Heart Association [15EIA22710040]; National Natural Science Foundation of China [61771463, 81971611]	National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); American Heart Association(American Heart Association); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	Supported by National Institutes of Health (R01HL129185 and R01HL129157) and American Heart Association (15EIA22710040). Y.Z. is funded by National Natural Science Foundation of China (61771463 and 81971611)	Akcakaya M, 2015, MAGN RESON MED, V74, P93, DOI 10.1002/mrm.25377; [Anonymous], 2009, HDB RES MACHINE LEAR; Avendi MR, 2017, MAGN RESON MED, V78, P2439, DOI 10.1002/mrm.26631; Bai WJ, 2018, J CARDIOVASC MAGN R, V20, DOI 10.1186/s12968-018-0471-x; Bellm S, 2016, J MAGN RESON IMAGING, V44, P1159, DOI 10.1002/jmri.25255; Chow K, 2014, MAGN RESON MED, V71, P2082, DOI 10.1002/mrm.24878; El-Rewaidy H, 2018, MAGN RESON MED, V80, P780, DOI 10.1002/mrm.27068; Fahmy A, 2019, J CARDIOVASC MAGN R, V21, DOI 10.1186/s12968-018-0516-1; Fahmy AS, 2018, JACC-CARDIOVASC IMAG, V11, P1917, DOI 10.1016/j.jcmg.2018.04.030; Giri S, 2009, J CARDIOVASC MAGN R, V11, DOI 10.1186/1532-429X-11-56; Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384; Haaf P, 2016, J CARDIOVASC MAGN R, V18, DOI 10.1186/s12968-016-0308-4; Kato S, 2016, AM J CARDIOL, V118, P1057, DOI 10.1016/j.amjcard.2016.07.010; Kellman P, 2012, J CARDIOVASC MAGN R, V14, DOI 10.1186/1532-429X-14-63; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Margeta J, 2017, COMP M BIO BIO E-IV, V5, P339, DOI 10.1080/21681163.2015.1061448; Messroghli DR, 2004, MAGN RESON MED, V52, P141, DOI 10.1002/mrm.20110; Moon JC, 2013, J CARDIOVASC MAGN R, V15, DOI 10.1186/1532-429X-15-92; Pica S, 2014, J CARDIOVASC MAGN R, V16, DOI 10.1186/s12968-014-0099-4; Piechnik SK, 2010, J CARDIOVASC MAGN R, V12, DOI 10.1186/1532-429X-12-69; Rogers T, 2013, J CARDIOVASC MAGN R, V15, DOI 10.1186/1532-429X-15-78; Ronneberger O., ARXIV 150504597 PREP; Roujol S, 2015, J CARDIOVASC MAGN R, V17, DOI 10.1186/s12968-015-0141-1; Roujol S, 2015, MAGN RESON MED, V73, P1469, DOI 10.1002/mrm.25270; Roujol S, 2014, RADIOLOGY, V272, P683, DOI 10.1148/radiol.14140296; Shah RV, 2016, AM J CARDIOL, V117, P282, DOI 10.1016/j.amjcard.2015.10.046; Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI 10.1146/annurev-bioeng-071516-044442; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Taylor AJ, 2016, JACC-CARDIOVASC IMAG, V9, P67, DOI 10.1016/j.jcmg.2015.11.005; Ngo TA, 2017, MED IMAGE ANAL, V35, P159, DOI 10.1016/j.media.2016.05.009; Verhaert D, 2011, JACC-CARDIOVASC IMAG, V4, P269, DOI 10.1016/j.jcmg.2010.09.023; Weingartner S, 2015, MAGN RESON MED, V74, P115, DOI 10.1002/mrm.25387; Xue H, 2013, MAGN RESON MED, V69, P1408, DOI 10.1002/mrm.24385; Xue H, 2012, MAGN RESON MED, V67, P1644, DOI 10.1002/mrm.23153	35	13	13	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2020	2	1							e190034	10.1148/ryai.2019190034	http://dx.doi.org/10.1148/ryai.2019190034			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CR	32076664	Green Published			2022-12-18	WOS:000826298000004
J	Wiggins, WF; Caton, MT; Magudia, K; Glomski, SHA; George, E; Rosenthal, MH; Gaviola, GC; Andriole, KP				Wiggins, Walter F.; Caton, M. Travis; Magudia, Kirti; Glomski, Sha-har A.; George, Elizabeth; Rosenthal, Michael H.; Gaviola, Glenn C.; Andriole, Katherine P.			Preparing Radiologists to Lead in the Era of Artificial Intelligence: Designing and Implementing a Focused Data Science Pathway for Senior Radiology Residents	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							DEEP	Artificial intelligence and machine learning (AI-ML) have taken center stage in medical imaging. To develop as leaders in AI-ML, radiology residents may seek a formative data science experience. The authors piloted an elective Data Science Pathway (DSP) for 4th-year residents at the authors' institution in collaboration with the MGH & BWH Center for Clinical Data Science (CCDS). The goal of the DSP was to provide an introduction to AI-ML through a flexible schedule of educational, experiential, and research activities. The study describes the initial experience with the DSP tailored to the AI-ML interests of three senior radiology residents. The authors also discuss logistics and curricular design with common core elements and shared mentorship. Residents were provided dedicated, full-time immersion into the CCDS work environment. In the initial DSP pilot, residents were successfully integrated into AI-ML projects at CCDS. Residents were exposed to all aspects of AI-ML application development, including data curation, model design, quality control, and clinical testing. Core concepts in AI-ML were taught through didactic sessions and daily collaboration with data scientists and other staff. Work during the pilot period led to 12 accepted abstracts for presentation at national meetings. The DSP is a feasible, well-rounded introductory experience in AI-ML for senior radiology residents. Residents contributed to model and tool development at multiple stages and were academically productive. Feedback from the pilot resulted in establishment of a formal AI-ML curriculum for future residents. The described logistical, planning, and curricular considerations provide a framework for DSP implementation at other institutions. (C) RSNA, 2020	[Wiggins, Walter F.; Caton, M. Travis; Magudia, Kirti; Glomski, Sha-har A.; George, Elizabeth; Rosenthal, Michael H.; Gaviola, Glenn C.; Andriole, Katherine P.] Harvard Med Sch, Brigham & Womens Hosp, Dept Radiol, Boston, MA 02115 USA; [Wiggins, Walter F.; Caton, M. Travis; Magudia, Kirti; Andriole, Katherine P.] MGH & BWH Ctr Clin Data Sci, Boston, MA USA	Harvard University; Brigham & Women's Hospital; Harvard Medical School	Wiggins, WF (corresponding author), Duke Univ Hosp, Dept Radiol, 2301 Erwin Rd, Durham, NC 27710 USA.	walter.wiggins@duke.edu		Magudia, Kirti/0000-0001-7037-433X; Wiggins, Walter/0000-0002-0258-2708; Rosenthal, Michael/0000-0002-5085-3904				[Anonymous], NATL IMAGING INFORMA; Balthazar P, 2020, ACAD RADIOL, V27, P136, DOI 10.1016/j.acra.2019.10.005; Chilamkurthy S, 2018, LANCET, V392, P2388, DOI 10.1016/S0140-6736(18)31645-3; Choy G, 2018, RADIOLOGY, V288, P318, DOI 10.1148/radiol.2018171820; Collado-Mesa F, 2018, J AM COLL RADIOL, V15, P1753, DOI 10.1016/j.jacr.2017.12.021; Cook TS, 2020, ACAD RADIOL, V27, P113, DOI 10.1016/j.acra.2019.10.002; Costello JR, 2013, ACAD RADIOL, V20, P243, DOI 10.1016/j.acra.2012.08.011; Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056; Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216; Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5; Jha S, 2016, JAMA-J AM MED ASSOC, V316, P2353, DOI 10.1001/jama.2016.17438; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Lee EJ, 2017, J STROKE, V19, P277, DOI 10.5853/jos.2017.02054; Liew C, 2018, EUR J RADIOL, V102, P152, DOI 10.1016/j.ejrad.2018.03.019; Makeeva V, 2020, J DIGIT IMAGING, V33, P547, DOI 10.1007/s10278-019-00292-2; Matalon SA, 2018, CURR PROBL DIAGN RAD, V47, P359, DOI 10.1067/j.cpradiol.2017.12.006; Montgomery BL, 2017, SAGE OPEN, V7, DOI 10.1177/2158244017710288; Naeger DM, 2011, ACAD RADIOL, V18, P640, DOI 10.1016/j.acra.2010.11.020; Nguyen GK, 2018, J AM COLL RADIOL, V15, P1320, DOI 10.1016/j.jacr.2018.05.024; Sharpe RE, 2015, RADIOGRAPHICS, V35, P239, DOI 10.1148/rg.351140064; Shenoy-Bhangle AS, 2018, ACAD RADIOL, V25, P708, DOI 10.1016/j.acra.2017.12.033; Sundgren PC, 2012, ACAD RADIOL, V19, P1110, DOI 10.1016/j.acra.2012.04.008; Tang A, 2018, CAN ASSOC RADIOL J, V69, P120, DOI 10.1016/j.carj.2018.02.002; Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369; Wood MJ, 2019, J AM COLL RADIOL, V16, P740, DOI 10.1016/j.jacr.2018.10.008	25	12	12	0	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2020	2	6							e200057	10.1148/ryai.2020200057	http://dx.doi.org/10.1148/ryai.2020200057			6	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CZ	33937848	Green Published			2022-12-18	WOS:000826480100009
J	Baur, C; Wiestler, B; Muehlau, M; Zimmer, C; Navab, N; Albarqouni, S				Baur, Christoph; Wiestler, Benedikt; Muehlau, Mark; Zimmer, Claus; Navab, Nassir; Albarqouni, Shadi			Modeling Healthy Anatomy with Artificial Intelligence for Unsupervised Anomaly Detection in Brain MRI	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To develop an unsupervised deep learning model on MR images of normal brain anatomy to automatically detect deviations indicative of pathologic states on abnormal MR images. Materials and Methods: In this retrospective study, spatial autoencoders with skip-connections (which can learn to compress and reconstruct data) were leveraged to learn the normal variability of the brain from MR scans of healthy individuals. A total of 100 normal, in-house MR scans were used for training. Subsequently, as the model was unable to reconstruct anomalies well, this characteristic was exploited for detecting and delineating various diseases by computing the difference between the input data and their reconstruction. The unsupervised model was compared with a supervised U-Net- and threshold-based classifier trained on data from 50 patients with multiple sclerosis (in-house dataset) and 50 patients from The Cancer Imaging Archive. Both the unsupervised and supervised U-Net models were tested on five different datasets containing MR images of microangiopathy, glioblastoma, and multiple sclerosis. Precision-recall statistics and derivations thereof (mean area under the precision-recall curve, Dice score) were used to quantify lesion detection and segmentation performance. Results: The unsupervised approach outperformed the naive thresholding approach in lesion detection (mean F1 scores ranging from 17% to 62% vs 6.4% to 15% across the five different datasets) and performed similarly to the supervised U-Net (20%-64%) across a variety of pathologic conditions. This outperformance was mostly driven by improved precision compared with the thresholding approach (mean precisions, 15%-59% vs 3.4%-10%). The model was also developed to create an anomaly heatmap display. Conclusion: The unsupervised deep learning model was able to automatically detect anomalies on brain MR images with high performance. (C)RSNA, 2021	[Baur, Christoph; Navab, Nassir; Albarqouni, Shadi] Tech Univ Munich, Dept Comp Aided Med Procedures, Boltzmannstr 3, D-85748 Garching, Germany; [Wiestler, Benedikt; Zimmer, Claus] Tech Univ Munich, Klinikum Rechts Isar, Dept Diagnost & Intervent Neuroradiol, Munich, Germany; [Muehlau, Mark] Tech Univ Munich, Klinikum Rechts Isar, Dept Neurol, Munich, Germany; [Navab, Nassir] Johns Hopkins Univ, Whiting Sch Engn, Baltimore, MD USA	Technical University of Munich; Technical University of Munich; Technical University of Munich; Johns Hopkins University	Baur, C (corresponding author), Tech Univ Munich, Dept Comp Aided Med Procedures, Boltzmannstr 3, D-85748 Garching, Germany.	c.baur@tum.de	Albarqouni, Shadi/GSN-5618-2022; Albarqouni, Shadi/H-5441-2019; Baur, Christoph/K-8109-2017	Albarqouni, Shadi/0000-0003-2157-2211; Albarqouni, Shadi/0000-0003-2157-2211; Baur, Christoph/0000-0002-4262-5864	Deutsche Forschungsgemeinschaft [SFB-824]; Zentrum Digitalisierung Bayern	Deutsche Forschungsgemeinschaft(German Research Foundation (DFG)); Zentrum Digitalisierung Bayern	Supported by the Zentrum Digitalisierung Bayern. B.W. is supported by the Deutsche Forschungsgemeinschaft SFB-824.	Bakas S, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.117; Baur C, 2006, ARXIV; Baur C, 2020, ARXIV 200403271 PREP; Baur C, 2020, I S BIOMED IMAGING, P1905, DOI 10.1109/ISBI45749.2020.9098686; Baur C, 2019, LECT NOTES COMPUT SC, V11383, P161, DOI 10.1007/978-3-030-11723-8_16; Baur Christoph, 2019, P MED IMAG DEEP LEAR, V102, P63; Bruno MA, 2015, RADIOGRAPHICS, V35, P1668, DOI 10.1148/rg.2015150023; Chen X, 2018, ARXIV 180604972 PREP; Chilamkurthy S, 2018, LANCET, V392, P2388, DOI 10.1016/S0140-6736(18)31645-3; Gal Y, 2016, PR MACH LEARN RES, V48; Huber T, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0173112; Iglesias JE, 2011, IEEE T MED IMAGING, V30, P1617, DOI 10.1109/TMI.2011.2138152; Kuijf HJ, 2019, IEEE T MED IMAGING, V38, P2556, DOI 10.1109/TMI.2019.2905770; Li H, 2020, ARXIV 200109313 PREP; Rohlfing T, 2010, HUM BRAIN MAPP, V31, P798, DOI 10.1002/hbm.20906; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Schlegl T, 2017, LECT NOTES COMPUT SC, V10265, P146, DOI 10.1007/978-3-319-59050-9_12; Schmidt P, 2012, NEUROIMAGE, V59, P3774, DOI 10.1016/j.neuroimage.2011.11.032; Sethian J. A., 2003, J COMPUTING INFORM T, V11, P1; Vaidhya Kiran, 2016, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries. First International Workshop, Brainles 2015, held in conjunction with MICCAI 2015. Revised Selected Papers: LNCS 9556, P181, DOI 10.1007/978-3-319-30858-6_16; Zhang HK, 2019, NEUROIMAGE-CLIN, V21, DOI 10.1016/j.nicl.2018.11.003	21	11	11	3	4	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2021	3	3							e190169	10.1148/ryai.2021190169	http://dx.doi.org/10.1148/ryai.2021190169			8	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SA	34136814	Green Published			2022-12-18	WOS:000826907000001
J	Castiglione, J; Somasundaram, E; Gilligan, LA; Trout, AT; Brady, S				Castiglione, James; Somasundaram, Elanchezhian; Gilligan, Leah A.; Trout, Andrew T.; Brady, Samuel			Automated Segmentation of Abdominal Skeletal Muscle on Pediatric CT Scans Using Deep Learning	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							SARCOPENIA; VALIDATION	Purpose: To automate skeletal muscle segmentation in a pediatric population using convolutional neural networks that identify and segment the L3 level at CT. Materials and Methods: In this retrospective study, two sets of U-Net-based models were developed to identify the L3 level in the sagittal plane and segment the skeletal muscle from the corresponding axial image. For model development, 370 patients (sampled uniformly across age group from 0 to 18 years and including both sexes) were selected between January 2009 and January 2019, and ground truth L3 location and skeletal muscle segmentation were manually defined. Twenty percent (74 of 370) of the examinations were reserved for testing the L3 locator and muscle segmentation, while the remaining were used for training. For the L3 locator models, maximum intensity projections (MIPs) from a fixed number of central sections of sagittal reformats (either 12 or 18 sections) were used as input with or without transfer learning using an L3 localizer trained on an external dataset (four models total). For the skeletal muscle segmentation models, two loss functions (weighted Dice similarity coefficient [DSC] and binary cross-entropy) were used on models trained with or without data augmentation (four models total). Outputs from each model were compared with ground truth, and the mean relative error and DSC from each of the models were compared with one another. Results: L3 section detection trained with an 18-section MIP model with transfer learning had a mean error of 3.23 mm 6 2.61 standard deviation, which was within the reconstructed image thickness (3 or 5 mm). Skeletal muscle segmentation trained with the weighted DSC loss model without data augmentation had a mean DSC of 0.93 +/- 0.03 and mean relative error of 0.04 +/- 0.04. Conclusion: Convolutional neural network models accurately identified the L3 level and segmented the skeletal muscle on pediatric CT scans. Supplemental material is available for this article. (C) RSNA, 2021.	[Castiglione, James; Somasundaram, Elanchezhian; Gilligan, Leah A.; Trout, Andrew T.; Brady, Samuel] Cincinnati Childrens Hosp Med Ctr, Dept Radiol, 3333 Burnet Ave,MLC 5031, Cincinnati, OH 45229 USA; [Somasundaram, Elanchezhian] Univ Cincinnati, Coll Med, Dept Radiol, Cincinnati, OH 45221 USA; [Trout, Andrew T.] Univ Cincinnati, Dept Pediat, Coll Med, Cincinnati, OH USA	Cincinnati Children's Hospital Medical Center; University System of Ohio; University of Cincinnati; University System of Ohio; University of Cincinnati	Somasundaram, E (corresponding author), Cincinnati Childrens Hosp Med Ctr, Dept Radiol, 3333 Burnet Ave,MLC 5031, Cincinnati, OH 45229 USA.; Somasundaram, E (corresponding author), Univ Cincinnati, Coll Med, Dept Radiol, Cincinnati, OH 45221 USA.	Elanchezhian.somasundaram@cchmc.org		Somasundaram, Elanchezhian/0000-0002-0440-5238; Brady, Samuel/0000-0002-2785-4626; Gilligan, Leah/0000-0002-4632-7004				Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; Bilic P, 2019, ARXIV190104056 PREPR; Burns JE, 2020, ACAD RADIOL, V27, P311, DOI 10.1016/j.acra.2019.03.011; Chen LK, 2016, J AM MED DIR ASSOC, V17, DOI 10.1016/j.jamda.2016.05.016; Chen LK, 2014, J AM MED DIR ASSOC, V15, P95, DOI 10.1016/j.jamda.2013.11.025; Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7; Crum WR, 2006, IEEE T MED IMAGING, V25, P1451, DOI 10.1109/TMI.2006.880587; Cruz-Jentoft AJ, 2019, AGE AGEING, V48, P16, DOI 10.1093/ageing/afy169; Cruz-Jentoft AJ, 2010, AGE AGEING, V39, P412, DOI 10.1093/ageing/afq034; Eaton-Rosen Z, 2018, IMPROVING DATA AUGME; Fielding RA, 2011, J AM MED DIR ASSOC, V12, P249, DOI 10.1016/j.jamda.2011.01.003; Gilligan LA, 2020, PEDIATR RADIOL, V50, P455, DOI 10.1007/s00247-019-04562-7; Gulli A., 2017, DEEP LEARNING KERAS; Hiasa Y, 2020, IEEE T MED IMAGING, V39, P1030, DOI 10.1109/TMI.2019.2940555; Kanavati F, 2018, ARXIV181109244 PREPR; Kingma DP, 2014, ARXIV14126980 PREPRI; Mangus RS, 2017, J PEDIATR GASTR NUTR, V65, P579, DOI 10.1097/MPG.0000000000001651; McCarthy HD, 2014, PEDIATR OBES, V9, P249, DOI 10.1111/j.2047-6310.2013.00168.x; Mitsiopoulos N, 1998, J APPL PHYSIOL, V85, P115, DOI 10.1152/jappl.1998.85.1.115; Patro SGK, ARXIV150306462; Prado CMM, 2012, CLIN NUTR, V31, P583, DOI 10.1016/j.clnu.2012.06.010; Ronneberger O., U NET CONVOLUTIONAL; Somasundaram E, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aac944; Steffl M, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177006; Studenski SA, 2014, J GERONTOL A-BIOL, V69, P547, DOI 10.1093/gerona/glu010; Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28; Tate J, 2016, SEG3D BASIC FUNCTION; van Vugt JLA, 2017, J CACHEXIA SARCOPENI, V8, P285, DOI 10.1002/jcsm.12158; Weston AD, 2019, RADIOLOGY, V290, P669, DOI 10.1148/radiol.2018181432; Woo J, 2017, CLIN GERIATR MED, V33, P305, DOI 10.1016/j.cger.2017.02.003	30	11	11	1	3	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2021	3	2							e200130	10.1148/ryai.2021200130	http://dx.doi.org/10.1148/ryai.2021200130			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z3LD	33937859	Green Published			2022-12-18	WOS:000826483100007
J	Kwon, YJ; Toussie, D; Finkelstein, M; Cedillo, MA; Maron, SZ; Manna, S; Voutsinas, N; Eber, C; Jacobi, A; Bernheim, A; Gupta, YS; Chung, MS; Fayad, ZA; Glicksberg, BS; Oermann, EK; Costa, AB				Kwon, Young Joon (Fred); Toussie, Danielle; Finkelstein, Mark; Cedillo, Mario A.; Maron, Samuel Z.; Manna, Sayan; Voutsinas, Nicholas; Eber, Corey; Jacobi, Adam; Bernheim, Adam; Gupta, Yogesh Sean; Chung, Michael S.; Fayad, Zahi A.; Glicksberg, Benjamin S.; Oermann, Eric K.; Costa, Anthony B.			Combining Initial Radiographs and Clinical Variables Improves Deep Learning Prognostication in Patients with COVID-19 from the Emergency Department	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							PNEUMONIA	Purpose: To train a deep learning classification algorithm to predict chest radiograph severity scores and clinical outcomes in patients with coronavirus disease 2019 (COVID-19). Materials and Methods: In this retrospective cohort study, patients aged 21-50 years who presented to the emergency department (ED) of a multicenter urban health system from March 10 to 26, 2020, with COVID-19 confirmation at real-time reverse-transcription polymerase chain reaction screening were identified. The initial chest radiographs, clinical variables, and outcomes, including admission, intubation, and survival, were collected within 30 days (n = 338; median age, 39 years; 210 men). Two fellowship-trained cardiothoracic radiologists examined chest radiographs for opacities and assigned a clinically validated severity score. A deep learning algorithm was trained to predict outcomes on a holdout test set composed of patients with confirmed COVID-19 who presented between March 27 and 29, 2020 (n = 161; median age, 60 years; 98 men) for both younger (age range, 21-50 years; n = 51) and older (age.50 years, n = 110) populations. Bootstrapping was used to compute CIs. Results: The model trained on the chest radiograph severity score produced the following areas under the receiver operating characteristic curves (AUCs): 0.80 (95% CI: 0.73, 0.88) for the chest radiograph severity score, 0.76 (95% CI: 0.68, 0.84) for admission, 0.66 (95% CI: 0.56, 0.75) for intubation, and 0.59 (95% CI: 0.49, 0.69) for death. The model trained on clinical variables produced an AUC of 0.64 (95% CI: 0.55, 0.73) for intubation and an AUC of 0.59 (95% CI: 0.50, 0.68) for death. Combining chest radiography and clinical variables increased the AUC of intubation and death to 0.88 (95% CI: 0.79, 0.96) and 0.82 (95% CI: 0.72, 0.91), respectively. Conclusion: The combination of imaging and clinical information improves outcome predictions. Supplemental material is available for this article. (C) RSNA, 2020.	[Kwon, Young Joon (Fred); Toussie, Danielle; Finkelstein, Mark; Cedillo, Mario A.; Maron, Samuel Z.; Manna, Sayan; Voutsinas, Nicholas; Eber, Corey; Jacobi, Adam; Bernheim, Adam; Gupta, Yogesh Sean; Chung, Michael S.; Fayad, Zahi A.] Icahn Sch Med Mt Sinai, Dept Diagnost Mol & Intervent Radiol, 1 Gustave L Levy Pl,Box 1136, New York, NY 10029 USA; [Kwon, Young Joon (Fred); Oermann, Eric K.; Costa, Anthony B.] Icahn Sch Med Mt Sinai, Dept Neurosurg, 1 Gustave L Levy Pl,Box 1136, New York, NY 10029 USA; [Kwon, Young Joon (Fred); Costa, Anthony B.] Icahn Sch Med Mt Sinai, Sinai BioDesign, 1 Gustave L Levy Pl,Box 1136, New York, NY 10029 USA; [Fayad, Zahi A.] Icahn Sch Med Mt Sinai, BioMed Engn & Imaging Inst, 1 Gustave L Levy Pl,Box 1136, New York, NY 10029 USA; [Fayad, Zahi A.; Glicksberg, Benjamin S.] Icahn Sch Med Mt Sinai, Mt Sinai COVID Informat Ctr, 1 Gustave L Levy Pl,Box 1136, New York, NY 10029 USA; [Glicksberg, Benjamin S.] Icahn Sch Med Mt Sinai, Hasso Planner Inst Digital Hlth Mt Sinai, 1 Gustave L Levy Pl,Box 1136, New York, NY 10029 USA	Icahn School of Medicine at Mount Sinai; Icahn School of Medicine at Mount Sinai; Icahn School of Medicine at Mount Sinai; Icahn School of Medicine at Mount Sinai; Icahn School of Medicine at Mount Sinai; Icahn School of Medicine at Mount Sinai	Kwon, YJ (corresponding author), Icahn Sch Med Mt Sinai, Dept Diagnost Mol & Intervent Radiol, 1 Gustave L Levy Pl,Box 1136, New York, NY 10029 USA.; Kwon, YJ (corresponding author), Icahn Sch Med Mt Sinai, Dept Neurosurg, 1 Gustave L Levy Pl,Box 1136, New York, NY 10029 USA.; Kwon, YJ (corresponding author), Icahn Sch Med Mt Sinai, Sinai BioDesign, 1 Gustave L Levy Pl,Box 1136, New York, NY 10029 USA.	fred.kwon@icahn.mssm.edu		Jacobi, Adam/0000-0002-9057-9129; Oermann, Eric/0000-0002-1876-5963; , Mario/0000-0002-2014-4664; Manna, Sayan/0000-0001-8649-2592; Toussie, Danielle/0000-0002-8947-7002; Maron, Samuel/0000-0002-9805-2268				Abdulaal A, 2020, J MED INTERNET RES, V22, DOI 10.2196/20259; Annarumma M, 2019, RADIOLOGY, V291, P195, DOI 10.1148/radiol.2018180921; Boyd Kendrick, 2013, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2013. Proceedings: LNCS 8190, P451, DOI 10.1007/978-3-642-40994-3_29; Cardinale L, 2014, WORLD J RADIOL, V6, P230, DOI 10.4329/wjr.v6.i6.230; Cellina M, 2020, RADIOLOGY, V297, pE238, DOI 10.1148/radiol.2020202326; Choi Hyewon, 2020, Radiol Cardiothorac Imaging, V2, pe204001, DOI [10.1148/ryct.2020200107, 10.1148/ryct.2020204001]; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; DiCiccio TJ, 1996, STAT SCI, V11, P189; Do S, 2020, KOREAN J RADIOL, V21, P33, DOI 10.3348/kjr.2019.0312; Fine MJ, 1997, ARCH INTERN MED, V157, P36, DOI 10.1001/archinte.157.1.36; Fine MJ, 1997, NEW ENGL J MED, V336, P243, DOI 10.1056/NEJM199701233360402; Garg S, 2020, MMWR-MORBID MORTAL W, V69, P458, DOI 10.15585/mmwr.mm6915e3; Gozes O, ARXIV EESSIV PREPRIN; Hall P, 2004, BIOMETRIKA, V91, P743, DOI 10.1093/biomet/91.3.743; Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5; Huang GL, 2017, IEEE ICC; Huang Lu, 2020, Radiol Cardiothorac Imaging, V2, pe200075, DOI 10.1148/ryct.2020200075; Hurt B, 2020, J THORAC IMAG, V35, pW87, DOI 10.1097/RTI.0000000000000512; Hwang EJ, 2020, KOREAN J RADIOL, V21, P511, DOI 10.3348/kjr.2019.0821; Joseph NP, 2020, RADIOLOGY, V297, pE303, DOI 10.1148/radiol.2020202602; Kelly CJ, 2019, BMC MED, V17, DOI 10.1186/s12916-019-1426-2; Kingma DP, ARXIV CS LG PREPRINT; Kundu S, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020200053; Lee JG, 2017, KOREAN J RADIOL, V18, P570, DOI 10.3348/kjr.2017.18.4.570; Li L, 2020, RADIOLOGY, V296, pE65, DOI 10.1148/radiol.2020200905; Li Matthew D, 2020, medRxiv, DOI 10.1101/2020.05.20.20108159; Li T, ARXIV EESSIV PREPRIN; Liu FJ, 2020, THERANOSTICS, V10, P5613, DOI 10.7150/thno.45985; Lu MT, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.7416; Mei XY, 2020, NAT MED, V26, P1224, DOI 10.1038/s41591-020-0931-3; Murphy K, 2020, RADIOLOGY, V296, pE166, DOI 10.1148/radiol.2020201874; Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792; Rajpurkar P, ARXIV CSCV PREPRINT; Subudhi S, 2020, INT J CLIN PRACT, V74, DOI 10.1111/ijcp.13685; Toussie D, 2020, RADIOLOGY, V297, pE197, DOI 10.1148/radiol.2020201754; Wong HYF, 2020, RADIOLOGY, V296, pE72, DOI 10.1148/radiol.2020201160; Wu QX, 2020, THERANOSTICS, V10, P7231, DOI 10.7150/thno.46428; Yoon SH, 2020, KOREAN J RADIOL, V21, P494, DOI 10.3348/kjr.2020.0132; Yu KH, 2019, BMJ QUAL SAF, V28, P238, DOI 10.1136/bmjqs-2018-008551; Zech JR, ARXIV CSCV PREPRINT; Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319	41	11	11	0	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2021	3	2							e200098	10.1148/ryai.2020200098	http://dx.doi.org/10.1148/ryai.2020200098			13	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z3LD	33928257	Green Published			2022-12-18	WOS:000826483100003
J	Yang, J; Sohn, JH; Behr, SC; Gullberg, GT; Seo, Y				Yang, Jaewon; Sohn, Jae Ho; Behr, Spencer C.; Gullberg, Grant T.; Seo, Youngho			CT-less Direct Correction of Attenuation and Scatter in the Image Space Using Deep Learning for Whole-Body FDG PET: Potential Benefits and Pitfalls	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							RADIATION-DOSIMETRY; BIODISTRIBUTION	Purpose: To demonstrate the feasibility of CT-less attenuation and scatter correction (ASC) in the image space using deep learning for whole-body PET, with a focus on the potential benefits and pitfalls. Materials and Methods: In this retrospective study, 110 whole-body fluorodeoxyglucose (FDG) PET/CT studies acquired in 107 patients (mean age 6 standard deviation, 58 years 6 18; age range, 11-92 years; 72 females) from February 2016 through January 2018 were randomly collected. A total of 37.3% (41 of 110) of the studies showed metastases, with diverse FDG PET findings throughout the whole body. A U-Net-based network was developed for directly transforming noncorrected PET (PET NC) into attenuation- and scatter-corrected PET (PET ASC). Deep learning-corrected PET (PET DL) images were quantitatively evaluated by using the standardized uptake value (SUV) of the normalized root mean square error, the peak signal-to-noise ratio, and the structural similarity index, in addition to a joint histogram for statistical analysis. Qualitative reviews by radiologists revealed the potential benefits and pitfalls of this correction method. Results: The normalized root mean square error (0.21 6 0.05 [mean SUV 6 standard deviation]), mean peak signal-to-noise ratio (36.3 6 3.0), mean structural similarity index (0.98 6 0.01), and voxelwise correlation (97.62%) of PET DL demonstrated quantitatively high similarity with PET ASC. Radiologist reviews revealed the overall quality of PET DL. The potential benefits of PET DL include a radiation dose reduction on follow-up scans and artifact removal in the regions with attenuation correction- and scatter correction-based artifacts. The pitfalls involve potential false-negative results due to blurring or missing lesions or false-positive results due to pseudo-low-uptake patterns. Conclusion: Deep learning-based direct ASC at whole-body PET is feasible and potentially can be used to overcome the current limitations of CT-based approaches, benefiting patients who are sensitive to radiation from CT. Supplemental material is available for this article. (C) RSNA, 2020.	[Yang, Jaewon; Sohn, Jae Ho; Behr, Spencer C.; Gullberg, Grant T.; Seo, Youngho] Univ Calif San Francisco, Dept Radiol & Biomed Imaging, 185 Berry St,Suite 350, San Francisco, CA 94143 USA; [Yang, Jaewon; Gullberg, Grant T.; Seo, Youngho] Univ Calif San Francisco, Phys Res Lab, 185 Berry St,Suite 350, San Francisco, CA 94143 USA	University of California System; University of California San Francisco; University of California System; University of California San Francisco	Yang, J (corresponding author), Univ Calif San Francisco, Dept Radiol & Biomed Imaging, 185 Berry St,Suite 350, San Francisco, CA 94143 USA.; Yang, J (corresponding author), Univ Calif San Francisco, Phys Res Lab, 185 Berry St,Suite 350, San Francisco, CA 94143 USA.	jaewon.yang@ucf.edu		Yang, Jaewon/0000-0001-7637-0436	National Institutes of Health [R01HL135490, R01EB026331]	National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	Supported in part by the National Institutes of Health (grants R01HL135490 and R01EB026331).	Armanious K, 2019, HELL J NUCL MED, V22, P179, DOI 10.1967/s002449911053; Attenberger U, 2015, ABDOM IMAGING, V40, P1374, DOI 10.1007/s00261-015-0455-3; Bebbington NA, 2019, EJNMMI PHYS, V6, DOI 10.1186/s40658-019-0266-7; Beyer T, 2000, J NUCL MED, V41, P1369; Darby SC, 2010, INT J RADIAT ONCOL, V76, P656, DOI 10.1016/j.ijrobp.2009.09.064; Dong X, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/ab652c; Dong X, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab4eb7; Gong K, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aac763; Hohberg M, 2019, EJNMMI RES, V9, DOI 10.1186/s13550-019-0540-7; Hong JY, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.10584; Huang BS, 2009, RADIOLOGY, V251, P166, DOI 10.1148/radiol.2511081300; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Lakhani A, 2017, RADIOGRAPHICS, V37, P577, DOI 10.1148/rg.2017160059; Lawhn-Heath C, 2018, MOL IMAGING, V17, DOI 10.1177/1536012118811741; Leynes AP, 2018, J NUCL MED, V59, P852, DOI 10.2967/jnumed.117.198051; Liu F, 2018, EJNMMI PHYS, V5, DOI 10.1186/s40658-018-0225-8; Liu F, 2018, RADIOLOGY, V286, P676, DOI 10.1148/radiol.2017170700; Mathews JD, 2013, BMJ-BRIT MED J, V346, DOI 10.1136/bmj.f2360; Meikle SR, 2005, POSITRON EMIS SION T, P93; Renieblas GP, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.3.035501; Shiri I, 2020, EUR J NUCL MED MOL I, V47, P2533, DOI 10.1007/s00259-020-04852-5; Song TA, 2019, IEEE T COMPUT IMAG, V5, P530, DOI 10.1109/TCI.2019.2913287; Sureshbabu W, 2005, J NUCL MED TECHNOL, V33, P156; Task Group on Control of Radiation Dose in Computed Tomography, 2000, Ann ICRP, V30, P7; Truong MT, 2014, RADIOL CLIN N AM, V52, P17, DOI 10.1016/j.rcl.2013.08.005; Watanabe S, 2019, EJNMMI RES, V9, DOI 10.1186/s13550-019-0525-6; Yang J, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab0606; Zaharchuk G, 2019, EUR J NUCL MED MOL I, V46, P2700, DOI 10.1007/s00259-019-04374-9; Zhang XZ, 2017, PHYS MED BIOL, V62, P2465, DOI 10.1088/1361-6560/aa5e46	29	11	11	2	4	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2021	3	2							e200137	10.1148/ryai.2020200137	http://dx.doi.org/10.1148/ryai.2020200137			12	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z3LD	33937860	Green Submitted, Green Published			2022-12-18	WOS:000826483100004
J	Tadavarthi, Y; Vey, B; Krupinski, E; Prater, A; Gichoya, J; Safdar, N; Trivedi, H				Tadavarthi, Yasasvi; Vey, Brianna; Krupinski, Elizabeth; Prater, Adam; Gichoya, Judy; Safdar, Nabile; Trivedi, Hari			The State of Radiology AI: Considerations for Purchase Decisions and Current Market Offerings	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To provide an overview of important factors to consider when purchasing radiology artificial intelligence (AI) software and current software offerings by type, subspecialty, and modality. Materials and Methods: Important factors for consideration when purchasing AI software, including key decision makers, data ownership and privacy, cost structures, performance indicators, and potential return on investment are described. For the market overview, a list of radiology AI companies was aggregated from the Radiological Society of North America and the Society for Imaging Informatics in Medicine conferences (November 2016-June 2019), then narrowed to companies using deep learning for imaging analysis and diagnosis. Software created for image enhancement, reporting, or workflow management was excluded. Software was categorized by task (repetitive, quantitative, explorative, and diagnostic), modality, and subspecialty. Results: A total of 119 software offerings from 55 companies were identified. There were 46 algorithms that currently have Food and Drug Administration and/or Conformite Europeenne approval (as of November 2019). Of the 119 offerings, distribution of software targets was 34 of 70 (49%), 21 of 70 (30%), 14 of 70 (20%), and one of 70 (1%) for diagnostic, quantitative, repetitive, and explorative tasks, respectively. A plurality of companies are focused on nodule detection at chest CT and two-dimensional mammography. There is very little activity in certain subspecialties, including pediatrics and nuclear medicine. A comprehensive table is available on the website hitilab.org/pages/ai-companies. Conclusion: The radiology AI marketplace is rapidly maturing, with an increase in product offerings. Radiologists and practice administrators should educate themselves on current product offerings and important factors to consider before purchase and implementation. (C) RSNA, 2020	[Tadavarthi, Yasasvi] Augusta Univ, Med Coll Georgia, Dept Radiol, 1120 15th St, Augusta, GA 30912 USA; [Vey, Brianna; Krupinski, Elizabeth; Prater, Adam; Gichoya, Judy; Safdar, Nabile; Trivedi, Hari] Emory Univ, Dept Radiol, Atlanta, GA 30322 USA	University System of Georgia; Augusta University; Emory University	Tadavarthi, Y (corresponding author), Augusta Univ, Med Coll Georgia, Dept Radiol, 1120 15th St, Augusta, GA 30912 USA.	ytadavarthi@gmail.com		Tadavarthi, Yasasvi/0000-0002-0387-2299; Safdar, Nabile/0000-0002-1131-8052				[Anonymous], MQSA INSIGHTS; Armato SG, 2004, RADIOLOGY, V232, P739, DOI 10.1148/radiol.2323032035; Bell J, 2015, MACHINE LEARNING HAN, DOI 10.1002/9781119183464; Choy G, 2018, RADIOLOGY, V288, P318, DOI 10.1148/radiol.2018171820; Dikici E, 2020, J MED IMAGING, V7, DOI 10.1117/1.JMI.7.1.016502; Figueroa RL, 2012, BMC MED INFORM DECIS, V12, DOI 10.1186/1472-6947-12-8; FRYBACK DG, 1991, MED DECIS MAKING, V11, P88, DOI 10.1177/0272989X9101100203; Geis JR, 2019, RADIOLOGY, V293, P436, DOI 10.1148/radiol.2019191586; GOTTLIEB S, 2017, FDA ANNOUNCES NEW ST; Grzybowski A, 2020, EYE, V34, P451, DOI 10.1038/s41433-019-0566-0; Hopkins BS, 2020, J NEUROSURG-SPINE, V32, P399, DOI 10.3171/2019.9.SPINE19860; Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5; Huang K, 2019, ARXIV 190405342 CSCL; Kumar Raman, 2018, J Family Med Prim Care, V7, P841, DOI 10.4103/jfmpc.jfmpc_218_18; Kuo WC, 2019, P NATL ACAD SCI USA, V116, P22737, DOI 10.1073/pnas.1908021116; Lee MH, 2017, ACAD RADIOL, V24, P483, DOI 10.1016/j.acra.2016.08.027; Liew C, 2018, EUR J RADIOL, V102, P152, DOI 10.1016/j.ejrad.2018.03.019; Morgan DJ, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.0348; Neri E, 2019, INSIGHTS IMAGING, V10, DOI 10.1186/s13244-019-0738-2; Norrie J, 2015, LANCET RESP MED, V3, P5, DOI 10.1016/S2213-2600(14)70268-1; O'Donoghue C, 2014, ANN INTERN MED, V160, P145, DOI 10.7326/M13-1217; Raman R, 2019, EYE, V33, P97, DOI 10.1038/s41433-018-0269-y; Rodriguez-Ruiz A, 2019, RADIOLOGY, V290, P305, DOI 10.1148/radiol.2018181371; Russakovsky O, ARXIV 14090575 CSCV; Schemmel A, 2016, J AM COLL RADIOL, V13, P1210, DOI 10.1016/j.jacr.2016.04.009; Shimabukuro DW, 2017, BMJ OPEN RESPIR RES, V4, DOI 10.1136/bmjresp-2017-000234; U.S. Food and Drug Administration, 2019, ARTIF INTELL; Yamashita R., 2018, INSIGHTS IMAGING, V9, P611, DOI [10.1007/s13244-018-0639-9, DOI 10.1007/s13244-018-0639-9]; Yuan BC, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16061070	29	10	10	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2020	2	6							e200004	10.1148/ryai.2020200004	http://dx.doi.org/10.1148/ryai.2020200004			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CZ	33937846	Green Published			2022-12-18	WOS:000826480100006
J	Verma, R; Correa, R; Hill, VB; Statsevych, V; Bera, K; Beig, N; Mahammedi, A; Madabhushi, A; Ahluwalia, M; Tiwari, P				Verma, Ruchika; Correa, Ramon; Hill, Virginia B.; Statsevych, Volodymyr; Bera, Kaustav; Beig, Niha; Mahammedi, Abdelkader; Madabhushi, Anant; Ahluwalia, Manmeet; Tiwari, Pallavi			Tumor Habitat-derived Radiomic Features at Pretreatment MRI That Are Prognostic for Progression-free Survival in Glioblastoma Are Associated with Key Morphologic Attributes at Histopathologic Examination: A Feasibility Study	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To identify radiomic features extracted from the tumor habitat on routine MR images that are prognostic for progression-free survival (PFS) and to assess their morphologic basis with corresponding histopathologic attributes in glioblastoma (GBM). Materials and Methods: In this retrospective study, 156 pretreatment GBM MR images (gadolinium-enhanced T1-weighted, T2-weighted, and fluid-attenuated inversion recovery [FLAIR] images) were curated. Of these 156 images, 122 were used for training (90 from The Cancer Imaging Archive and 32 from the Cleveland Clinic, acquired between December 1, 2011, and May 1, 2018) and 34 were used for validation. The validation set was obtained from the Ivy Glioblastoma Atlas Project database, for which the percentage extent of 11 histologic attributes was available on corresponding histopathologic specimens of the resected tumor. Following expert annotations of the tumor habitat (necrotic core, enhancing tumor, and FLAIR-hyperintense subcompartments), 1008 radiomic descriptors (eg, Haralick texture features, Laws energy features, co-occurrence of local anisotropic gradient orientations [CoLIAGe]) were extracted from the three MRI sequences. The top radiomic features were obtained from each subcompartment in the training set on the basis of their ability to risk-stratify patients according to PFS. These features were then concatenated to create a radiomics risk score (RRS). The RRS was independently validated on a holdout set. In addition, correlations (P<.05) of RRS features were computed, with the percentage extent of the 11 histopathologic attributes, using Spearman correlation analysis. Results: RRS yielded a concordance index of 0.80 on the validation set and constituted radiomic features, including Laws (capture edges, waves, ripple patterns) and CoLIAGe (capture disease heterogeneity) from enhancing tumor and FLAIR hyperintensity. These radiomic features were correlated with histopathologic attributes associated with disease aggressiveness in GBM, particularly tumor infiltration (P=.0044) and hyperplastic blood vessels (P=.0005). Conclusion: Preliminary findings demonstrated significant associations of prognostic radiomic features with disease-specific histologic attributes, with implications for risk-stratifying patients with GBM for personalized treatment decisions. (C) RSNA, 2020	[Verma, Ruchika; Correa, Ramon; Bera, Kaustav; Beig, Niha; Madabhushi, Anant; Tiwari, Pallavi] Case Western Reserve Univ, Dept Biomed Engn, 10900 Euclid Ave, Cleveland, OH 44106 USA; [Hill, Virginia B.] Northwestern Univ, Feinberg Sch Med, Dept Neuroradiol, Chicago, IL 60611 USA; [Statsevych, Volodymyr; Ahluwalia, Manmeet] Cleveland Clin, Brain Tumor & Neuro Oncol Ctr, Cleveland, OH 44106 USA; [Mahammedi, Abdelkader] Cleveland Clin, Dept Diagnost Radiol, Cleveland, OH 44106 USA; [Madabhushi, Anant] Louis Stokes Cleveland Vet Adm Med Ctr, Cleveland, OH USA		Tiwari, P (corresponding author), Case Western Reserve Univ, Dept Biomed Engn, 10900 Euclid Ave, Cleveland, OH 44106 USA.	pallavi.tiwari@case.edu	; Mahammedi, Abdelkader/J-3222-2018	Statsevych, Volodymyr/0000-0003-2991-4730; Hill, Virginia/0000-0001-9146-9370; Verma, Ruchika/0000-0003-4870-128X; Mahammedi, Abdelkader/0000-0002-8726-9269; Madabhushi, Anant/0000-0002-5741-0399; Correa, Ramon/0000-0003-2247-7777				[Anonymous], IVY GLIOBLASTOMA ATL; Bae S, 2018, RADIOLOGY, V289, P797, DOI 10.1148/radiol.2018180200; Beig N, 2020, CLIN CANCER RES, V26, P1866; BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x; Braman NM, 2017, BREAST CANCER RES, V19, DOI 10.1186/s13058-017-0846-1; Camp RL, 2004, CLIN CANCER RES, V10, P7252, DOI 10.1158/1078-0432.CCR-04-0713; Cantanhede IG, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-15045-w; Chukwueke UN, 2019, CNS ONCOL, V8; Cui Y, 2016, RADIOLOGY, V278, P546, DOI 10.1148/radiol.2015150358; Ekman A., 2017, SIMULATION STUDY COM; Faraway JJ, 2016, EXTENDING LINEAR MOD, DOI DOI 10.1201/B21296; Gillies RJ, 2016, RADIOLOGY, V278, P563, DOI 10.1148/radiol.2015151169; Gonen M, 2005, BIOMETRIKA, V92, P965, DOI 10.1093/biomet/92.4.965; HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314; Huang LL, 2003, PATTERN RECOGN, V36, P2501, DOI 10.1016/S0031-3203(03)00130-4; Ishii A, 2016, PLOS ONE, V11; Juratli TA, 2012, J NEURO-ONCOL, V110, P325, DOI 10.1007/s11060-012-0977-2; Kickingereder P, 2016, RADIOLOGY, V280, P880, DOI 10.1148/radiol.2016160845; Labussiere M, 2014, NEUROLOGY, V83, P1200, DOI 10.1212/WNL.0000000000000814; Lamborn KR, 2004, NEURO-ONCOLOGY, V6, P227, DOI 10.1215/S1152851703000620; Laws K. I., 1980, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V238, P376; Mu L, 2017, FRONTIMMUNOL, V8, P1451; Narang S, 2017, ONCOTARGET, V8; Penzias G, 2018, PLOS ONE, V13; Prasanna P, 2017, EUR RADIOL, V27, P4188, DOI 10.1007/s00330-016-4637-3; Prasanna P, 2016, SCI REP-UK, V6, DOI 10.1038/srep37241; Puchalski RB, 2018, SCIENCE, V360, P660, DOI 10.1126/science.aaf2666; Rosen BS, 2017, INT J RADIAT ONCOL, V99, pS81, DOI 10.1016/j.ijrobp.2017.06.196; Schiffer D, 2018, NEUROL SCI, V39, P1161, DOI 10.1007/s10072-018-3408-0; Shah N., 2016, **DATA OBJECT**, DOI 10.7937/K9/TCIA.2016.XLWAN6NL; Silver DJ, 2018, J PATHOL, V244, P260, DOI 10.1002/path.5024; Stupp R, 2005, NEW ENGL J MED, V352, P987, DOI 10.1056/NEJMoa043330; Wen PY, 2010, J CLIN ONCOL, V28, P1963, DOI 10.1200/JCO.2009.26.3541; Wong ET, 2007, J CLIN ONCOL, V25, P4705; Zwanenburg A, 2019, ARXIV161207003	35	10	10	2	3	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2020	2	6							e190168	10.1148/ryai.2020190168	http://dx.doi.org/10.1148/ryai.2020190168			12	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CZ	33330847	Green Published			2022-12-18	WOS:000826480100002
J	Federau, C; Christensen, S; Scherrer, N; Ospel, JM; Schulze-Zachau, V; Schmidt, N; Breit, HC; Maclaren, J; Lansberg, M; Kozerke, S				Federau, Christian; Christensen, Soren; Scherrer, Nino; Ospel, Johanna M.; Schulze-Zachau, Victor; Schmidt, Noemi; Breit, Hanns-Christian; Maclaren, Julian; Lansberg, Maarten; Kozerke, Sebastian			Improved Segmentation and Detection Sensitivity of Diffusion-weighted Stroke Lesions with Synthetically Enhanced Deep Learning	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							ENDOVASCULAR REPERFUSION; AUGMENTATION; TIME; CNN	Purpose: To compare the segmentation and detection performance of a deep learning model trained on a database of human-labeled clinical stroke lesions on diffusion-weighted (DW) images to a model trained on the same database enhanced with synthetic stroke lesions. Materials and Methods: In this institutional review board-approved study, a stroke database of 962 cases (mean patient age 6 standard deviation, 65 years 6 17; 255 male patients; 449 scans with DW positive stroke lesions) and a normal database of 2027 patients (mean age, 38 years 6 24; 1088 female patients) were used. Brain volumes with synthetic stroke lesions on DW images were produced by warping the relative signal increase of real strokes to normal brain volumes. A generic three-dimensional (3D) U-Net was trained on four different databases to generate four different models: (a) 375 neuroradiologist-labeled clinical DW positive stroke cases (CDB); (b) 2000 synthetic cases (S2DB); (c) CDB plus 2000 synthetic cases (CS2DB); and (d) CDB plus 40 000 synthetic cases (CS40DB). The models were tested on 20% (n = 192) of the cases of the stroke database, which were excluded from the training set. Segmentation accuracy was characterized using Dice score and lesion volume of the stroke segmentation, and statistical significance was tested using a paired two-tailed Student t test. Detection sensitivity and specificity were compared with labeling done by three neuroradiologists. Results: The performance of the 3D U-Net model trained on the CS40DB (mean Dice score, 0.72) was better than models trained on the CS2DB (Dice score, 0.70; P,.001) or the CDB (Dice score, 0.65; P,.001). The deep learning model (CS40DB) was also more sensitive (91% [95% confidence interval {CI}: 89%, 93%]) than each of the three human readers (human reader 3, 84% [95% CI: 81%, 87%]; human reader 1, 78% [95% CI: 75%, 81%]; human reader 2, 79% [95% CI: 76%, 82%]), but was less specific (75% [95% CI: 72%, 78%]) than each of the three human readers (human reader 3, 96% [95% CI: 94%, 98%]; human reader 1, 92% [95% CI: 90%, 94%]; human reader 2, 89% [95% CI: 86%, 91%]). Conclusion: Deep learning training for segmentation and detection of stroke lesions on DW images was significantly improved by enhancing the training set with synthetic lesions. (C) RSNA, 2020	[Federau, Christian; Scherrer, Nino; Kozerke, Sebastian] Swiss Fed Inst Technol, Inst Biomed Engn, Gloriastr 35, CH-8092 Zurich, Switzerland; [Federau, Christian; Scherrer, Nino; Kozerke, Sebastian] Univ Zurich, Gloriastr 35, CH-8092 Zurich, Switzerland; [Christensen, Soren; Maclaren, Julian; Lansberg, Maarten] Stanford Univ, Stanford Stroke Ctr, Dept Neurol, Stanford, CA 94305 USA; [Ospel, Johanna M.; Schulze-Zachau, Victor; Schmidt, Noemi; Breit, Hanns-Christian] Univ Hosp Basel, Dept Radiol, Div Diagnost & Intervent Neuroradiol, Basel, Switzerland	Swiss Federal Institutes of Technology Domain; ETH Zurich; University of Zurich; Stanford University; University of Basel	Federau, C (corresponding author), Swiss Fed Inst Technol, Inst Biomed Engn, Gloriastr 35, CH-8092 Zurich, Switzerland.; Federau, C (corresponding author), Univ Zurich, Gloriastr 35, CH-8092 Zurich, Switzerland.	federau@biomed.ee.ethz.ch	; Kozerke, Sebastian/J-3209-2015	Scherrer, Nino/0000-0001-5976-4257; Ospel, Johanna/0000-0003-0029-6764; Kozerke, Sebastian/0000-0003-3725-8884; Schulze-Zachau, Victor/0000-0003-0945-8379; Federau, Christian/0000-0002-3803-6602				[Anonymous], 1999, 10153 BS EN; [Anonymous], ADV NORMALIZATION TO; Benjamini Y, 2001, ANN STAT, V29, P1165; Chen L, 2017, NEUROIMAGE-CLIN, V15, P633, DOI 10.1016/j.nicl.2017.06.016; De Fauw J, 2018, NAT MED, V24, P1342, DOI 10.1038/s41591-018-0107-6; Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056; Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013; Hainc N, 2017, FRONT NEUROL, V8, DOI 10.3389/fneur.2017.00489; Han C, ARXIV190513456 CS EE; Han C, 2019, INT CONF 3D VISION, P729, DOI 10.1109/3DV.2019.00085; Horos Project Web site, US; ImageNet Web site, US; Inoue M, 2014, STROKE, V45, P1024, DOI 10.1161/STROKEAHA.113.002135; Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90; Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004; Kingma D.P., ARXIV14126980 CS; Kingma DP, ARXIV13126114 CS STA; Liu Z, ARXIV180305848 CS; Maier O, 2017, MED IMAGE ANAL, V35, P250, DOI 10.1016/j.media.2016.07.009; Ronneberger O, ARXIV150504597 CS; Sandfort V, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-52737-x; Saver JL, 2016, JAMA-J AM MED ASSOC, V316, P1279, DOI 10.1001/jama.2016.13647; TensorFlow Web site, US; The McConnell Brain Imaging Centre, 2016, US; Titano JJ, 2018, NAT MED, V24, P1337, DOI 10.1038/s41591-018-0147-y; Tsai JP, 2018, STROKE, V49, P952, DOI 10.1161/STROKEAHA.117.018858; Wu O, 2019, STROKE, V50, P1734, DOI 10.1161/STROKEAHA.119.025373; Zhang RZ, 2018, IEEE T MED IMAGING, V37, P2149, DOI 10.1109/TMI.2018.2821244	28	10	10	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2020	2	5							e190217	10.1148/ryai.2020190217	http://dx.doi.org/10.1148/ryai.2020190217			8	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CY	33937840	Green Published, Green Submitted			2022-12-18	WOS:000826477600005
J	Gastounioti, A; Kontos, D				Gastounioti, Aimilia; Kontos, Despina			Is It Time to Get Rid of Black Boxes and Cultivate Trust in AI?	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Gastounioti, Aimilia; Kontos, Despina] Univ Penn, Dept Radiol, 3700 Hamilton Walk,Richards Bldg,Room D702, Philadelphia, PA 19104 USA		Kontos, D (corresponding author), Univ Penn, Dept Radiol, 3700 Hamilton Walk,Richards Bldg,Room D702, Philadelphia, PA 19104 USA.	Despina.Kontos@pennmedicine.upenn.edu		Gastounioti, Aimilia/0000-0002-3359-7195; KONTOS, DESPINA/0000-0001-9031-5126				Haas Robert, 2017, Curr Opin Syst Biol, V6, P37, DOI 10.1016/j.coisb.2017.08.009; Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5; Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236; Reyes M, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190043; Rodriguez-Ruiz A, 2019, JNCI-J NATL CANCER I, V111, P916, DOI 10.1093/jnci/djy222; Xiong W, 2017, IEEE-ACM T AUDIO SPE, V25, P2410, DOI 10.1109/TASLP.2017.2756440	6	10	10	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2020	2	3							e200088	10.1148/ryai.2020200088	http://dx.doi.org/10.1148/ryai.2020200088			2	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CW	32510520	Green Published			2022-12-18	WOS:000826470300013
J	Piccini, D; Demesmaeker, R; Heerfordt, J; Yerly, J; Di Sopra, L; Masci, PG; Schwitter, J; Van De Ville, D; Richiardi, J; Kober, T; Stuber, M				Piccini, Davide; Demesmaeker, Robin; Heerfordt, John; Yerly, Jerome; Di Sopra, Lorenzo; Masci, Pier Giorgio; Schwitter, Juerg; Van De Ville, Dimitri; Richiardi, Jonas; Kober, Tobias; Stuber, Matthias			Deep Learning to Automate Reference-Free Image Quality Assessment of Whole-Heart MR Images	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							MAGNETIC-RESONANCE; ANGIOGRAPHY	Purpose: To develop and characterize an algorithm that mimics human expert visual assessment to quantitatively determine the quality of three-dimensional (3D) whole-heart MR images. Materials and Methods: In this study, 3D whole-heart cardiac MRI scans from 424 participants (average age, 57 years +/- 18 [standard deviation]; 66.5% men) were used to generate an image quality assessment algorithm. A deep convolutional neural network for image quality assessment (IQ-DCNN) was designed, trained, optimized, and cross-validated on a clinical database of 324 (training set) scans. On a separate test set (100 scans), two hypotheses were tested: (a) that the algorithm can assess image quality in concordance with human expert assessment as assessed by human-machine correlation and intra- and interobserver agreement and (b) that the IQ-DCNN algorithm may be used to monitor a compressed sensing reconstruction process where image quality progressively improves. Weighted k values, agreement and disagreement counts, and Krippendorff a reliability coefficients were reported. Results: Regression performance of the IQ-DCNN was within the range of human intra- and interobserver agreement and in very good agreement with the human expert (R-2 = 0.78, k = 0.67). The image quality assessment during compressed sensing reconstruction correlated with the cost function at each iteration and was successfully applied to rank the results in very good agreement with the human expert. Conclusion: The proposed IQ-DCNN was trained to mimic expert visual image quality assessment of 3D whole-heart MR images. The results from the IQ-DCNN were in good agreement with human expert reading, and the network was capable of automatically comparing different reconstructed volumes. Supplemental material is available for this article. (C) RSNA, 2020.	[Piccini, Davide; Demesmaeker, Robin; Heerfordt, John; Richiardi, Jonas; Kober, Tobias] Siemens Healthcare, Adv Clin Imaging Ledinokgy, Lausanne, Switzerland; [Piccini, Davide; Heerfordt, John; Yerly, Jerome; Di Sopra, Lorenzo; Richiardi, Jonas; Kober, Tobias; Stuber, Matthias] Lausanne Univ Hosp, Dept Diagnost & Intervent Radiol, Rue Bugnon 46,BH 8-80, CH-1011 Lausanne, Switzerland; [Piccini, Davide; Heerfordt, John; Yerly, Jerome; Di Sopra, Lorenzo; Masci, Pier Giorgio; Schwitter, Juerg; Richiardi, Jonas; Kober, Tobias; Stuber, Matthias] Univ Lausanne, Rue Bugnon 46,BH 8-80, CH-1011 Lausanne, Switzerland; [Piccini, Davide; Richiardi, Jonas; Kober, Tobias] Ecole Polytech Fed Lausanne EPFL, LTS5, Lausanne, Switzerland; [Demesmaeker, Robin] Ecole Polytech Fed Lausanne EPFL, Inst Elect Engn, Lausanne, Switzerland; [Demesmaeker, Robin; Van De Ville, Dimitri] Ecole Polytech Fed Lausanne EPFL, Inst Bioengn, Ctr Neuroprosthet, Lausanne, Switzerland; [Yerly, Jerome; Stuber, Matthias] Ctr Biomed Imaging CIBM, Lausanne, Switzerland; [Masci, Pier Giorgio; Schwitter, Juerg] Lausanne Univ Hosp, Div Cardiol, Lausanne, Switzerland; [Masci, Pier Giorgio; Schwitter, Juerg] Lausanne Univ Hosp, Cardiac MR Ctr, Lausanne, Switzerland; [Van De Ville, Dimitri] Univ Hosp Geneva HUG, Dept Radiol & Med Informat, Geneva, Switzerland	Siemens AG; University of Lausanne; Centre Hospitalier Universitaire Vaudois (CHUV); University of Lausanne; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; University of Lausanne; Centre Hospitalier Universitaire Vaudois (CHUV); University of Lausanne; Centre Hospitalier Universitaire Vaudois (CHUV); University of Geneva	Piccini, D (corresponding author), Siemens Healthcare, Adv Clin Imaging Ledinokgy, Lausanne, Switzerland.; Piccini, D (corresponding author), Lausanne Univ Hosp, Dept Diagnost & Intervent Radiol, Rue Bugnon 46,BH 8-80, CH-1011 Lausanne, Switzerland.; Piccini, D (corresponding author), Univ Lausanne, Rue Bugnon 46,BH 8-80, CH-1011 Lausanne, Switzerland.; Piccini, D (corresponding author), Ecole Polytech Fed Lausanne EPFL, LTS5, Lausanne, Switzerland.	piccinidavide@gmail.com		Richiardi, Jonas/0000-0002-6975-5634; Demesmaeker, Robin/0000-0003-0856-0929; Masci, Pier Giorgio/0000-0001-5196-9530; Heerfordt, John/0000-0002-6837-4733; Van De Ville, Dimitri/0000-0002-2879-3861				Albrecht MH, 2018, EUR RADIOL, V28, P1267, DOI 10.1007/s00330-017-5035-1; Bianco S, 2018, SIGNAL IMAGE VIDEO P, V12, P355, DOI 10.1007/s11760-017-1166-8; Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518; Camps SM, 2018, INT C MED IMAGING DE; Chow LS, 2016, BIOMED SIGNAL PROCES, V27, P145, DOI 10.1016/j.bspc.2016.02.006; Esses SJ, 2018, J MAGN RESON IMAGING, V47, P723, DOI 10.1002/jmri.25779; Etienne A, 2002, MAGNET RESON MED, V48, P658, DOI 10.1002/mrm.10253; Feng L, 2018, MAGN RESON MED, V79, P826, DOI 10.1002/mrm.26745; Feng L, 2016, MAGN RESON MED, V75, P775, DOI 10.1002/mrm.25665; Ginami G, 2016, MAGN RESON MED, V75, P1594, DOI 10.1002/mrm.25761; He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239; Klinke V, 2013, J CARDIOVASC MAGN R, V15, DOI 10.1186/1532-429X-15-55; Krupinski EA, 2010, ATTEN PERCEPT PSYCHO, V72, P1205, DOI 10.3758/APP.72.5.1205; Kryszczuk K, 2006, P 2 WORK MULT US AUT; Kustner T, 2018, MAGN RESON MATER PHY, V31, P243, DOI 10.1007/s10334-017-0650-z; Kundel HL, 2003, RADIOLOGY, V228, P303, DOI 10.1148/radiol.2282011860; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Mahapatra D, 2016, LECT NOTES COMPUT SC, V10019, P172, DOI 10.1007/978-3-319-47157-0_21; Martin CJ, 1999, APPL RADIAT ISOTOPES, V50, P21, DOI 10.1016/S0969-8043(98)00022-0; McConnell MV, 1997, AM J ROENTGENOL, V168, P1369, DOI 10.2214/ajr.168.5.9129447; Monney P, 2015, J CARDIOVASC MAGN R, V17, DOI 10.1186/s12968-015-0156-7; Piccini D, 2017, MAGN RESON MED, V77, P1473, DOI 10.1002/mrm.26221; Piccini D, 2014, RADIOLOGY, V270, P378, DOI 10.1148/radiol.13132045; Piccini D, 2012, MAGN RESON MED, V68, P571, DOI 10.1002/mrm.23247; Rutz T, 2016, INT J CARDIOVAS IMAG, V32, P1735, DOI 10.1007/s10554-016-0963-4; Saha SK, 2018, J DIGIT IMAGING, V31, P869, DOI 10.1007/s10278-018-0084-9; Schwitter J, 2016, CIRC-CARDIOVASC IMAG, V9, DOI 10.1161/CIRCIMAGING.115.004025; Schwitter J, 2013, HEART RHYTHM, V10, P864, DOI 10.1016/j.hrthm.2013.02.019; Simonyan K, 2015, C TRACK PROC 2015 AR; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Vincenti G, 2014, JACC-CARDIOVASC IMAG, V7, P882, DOI 10.1016/j.jcmg.2014.04.016; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Watson PF, 2010, THERIOGENOLOGY, V73, P1167, DOI 10.1016/j.theriogenology.2010.01.003; Zhang L., 2017, INT WORKSH SIM SYNTH, P61; Zhang L, 2016, LECT NOTES COMPUT SC, V9968, P138, DOI 10.1007/978-3-319-46630-9_14	36	10	10	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2020	2	3							e190123	10.1148/ryai.2020190123	http://dx.doi.org/10.1148/ryai.2020190123			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CW	33937825	Green Published			2022-12-18	WOS:000826470300005
J	Wu, SC; Li, HY; Quang, D; Guan, YF				Wu, Shaocheng; Li, Hongyang; Quang, Daniel; Guan, Yuanfang			Three-Plane-assembled Deep Learning Segmentation of Gliomas	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							MEDICAL IMAGE SEGMENTATION; BRAIN-TUMOR SEGMENTATION; EXTRACTION; NETWORKS; CELL	Purpose: To design a computational method for automatic brain glioma segmentation of multimodal MRI scans with high efficiency and accuracy. Materials and Methods: The 2018 Multimodal Brain Tumor Segmentation Challenge (BraTS) dataset was used in this study, consisting of routine clinically acquired preoperative multimodal MRI scans. Three subregions of glioma-the necrotic and nonenhancing tumor core, the peritumoral edema, and the contrast-enhancing tumor-were manually labeled by experienced radiologists. Two-dimensional U-Net models were built using a three-plane-assembled approach to segment three subregions individually (three-region model) or to segment only the whole tumor (WT) region (WT-only model). The term three-plane-assembled means that coronal and sagittal images were generated by reformatting the original axial images. The model performance for each case was evaluated in three classes: enhancing tumor (ET), tumor core (TC), and WT. Results: On the internal unseen testing dataset split from the 2018 BraTS training dataset, the proposed models achieved mean Sorensen-Dice scores of 0.80, 0.84, and 0.91, respectively, for ET, TC, and WT. On the BraTS validation dataset, the proposed models achieved mean 95% Hausdorff distances of 3.1 mm, 7.0 mm, and 5.0 mm, respectively, for ET, TC, and WT and mean SorensenDice scores of 0.80, 0.83, and 0.91, respectively, for ET, TC, and WT. On the BraTS testing dataset, the proposed models ranked fourth out of 61 teams. The source code is available at https://github.com/GuanLab/Brain_Glioma. Conclusion: This deep learning method consistently segmented subregions of brain glioma with high accuracy, efficiency, reliability, and generalization ability on screening images from a large population, and it can be efficiently implemented in clinical practice to assist neuro-oncologists or radiologists. Supplemental material is available for this article. (c) RSNA, 2020	[Wu, Shaocheng; Li, Hongyang; Quang, Daniel; Guan, Yuanfang] Univ Michigan, Dept Computat Med & Bioinformat, 100 Washtenaw Ave, Ann Arbor, MI 48109 USA	University of Michigan System; University of Michigan	Guan, YF (corresponding author), Univ Michigan, Dept Computat Med & Bioinformat, 100 Washtenaw Ave, Ann Arbor, MI 48109 USA.	gyuanfan@umich.edu		Guan, Yuanfang/0000-0001-8275-2852	American Heart Association; Amazon Web Services 3.0 Data Grant Portfolio: Artificial Intelligence and Machine Learning Training Grants [19AMTG34850176]; National Science Foundation [NSF-US14-PAF07599]; National Institute of General Medical Sciences (NIGMS) [R35GM133346-01]; Michael J. Fox Foundation for Parkinson's Research [17373]	American Heart Association(American Heart Association); Amazon Web Services 3.0 Data Grant Portfolio: Artificial Intelligence and Machine Learning Training Grants; National Science Foundation(National Science Foundation (NSF)); National Institute of General Medical Sciences (NIGMS)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of General Medical Sciences (NIGMS)); Michael J. Fox Foundation for Parkinson's Research	H.L. is supported by American Heart Association and Amazon Web Services 3.0 Data Grant Portfolio: Artificial Intelligence and Machine Learning Training Grants (19AMTG34850176). Y.G. supported by the National Science Foundation (NSF-US14-PAF07599; CAREER: On-line Service for Predicting Protein Phosphorylation Dynamics Under Unseen Perturbations NSF), National Institute of General Medical Sciences (NIGMS R35GM133346-01), Michael J. Fox Foundation for Parkinson's Research (17373), and a donation from Amazon.	Aganj I, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-31333-5; Bakas S, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.117; Bauer S, 2013, PHYS MED BIOL, V58, pR97, DOI 10.1088/0031-9155/58/13/R97; Brosch T, 2016, IEEE T MED IMAGING, V35, P1229, DOI 10.1109/TMI.2016.2528821; Cancer Imaging Archive Public Access, TCGA GBM; Cancer Imaging Archive Public Access, TCGA LGG; Cicek Ozgun, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P424, DOI 10.1007/978-3-319-46723-8_49; Davis J., 2006, 23 INT C MACH LEARN, P233, DOI [10.1145/1143844.1143874, DOI 10.1145/1143844.1143874]; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dong H, 2017, COMM COM INF SC, V723, P506, DOI 10.1007/978-3-319-60964-5_44; Dou Q, 2016, IEEE T MED IMAGING, V35, P1182, DOI 10.1109/TMI.2016.2528129; Egger J, 2013, SCI REP-UK, V3, DOI 10.1038/srep01364; Guan YF, 2019, NAT MACH INTELL, V1, P67, DOI 10.1038/s42256-018-0011-2; Havaei Mohammad, 2016, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries. First International Workshop, Brainles 2015, held in conjunction with MICCAI 2015. Revised Selected Papers: LNCS 9556, P195, DOI 10.1007/978-3-319-30858-6_17; Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004; Huang MY, 2014, IEEE T BIO-MED ENG, V61, P2633, DOI 10.1109/TBME.2014.2325410; Jiang YQ, 2020, BRIT J DERMATOL, V182, P754, DOI 10.1111/bjd.18026; Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004; Kleesiek J, 2016, NEUROIMAGE, V129, P460, DOI 10.1016/j.neuroimage.2016.01.024; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Li HY, 2018, CANCER RES, V78, P5446, DOI 10.1158/0008-5472.CAN-18-0740; Llaguno SRA, 2016, BRIT J CANCER, V115, P1445, DOI 10.1038/bjc.2016.354; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Mazzara GP, 2004, INT J RADIAT ONCOL, V59, P300, DOI 10.1016/j.ijrobp.2004.01.026; Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694; Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465; Randhawa RS, 2016, LECT NOTES COMPUT SC, V10154, P65, DOI 10.1007/978-3-319-55524-9_7; Ronneberger O, LECT NOTES COMPUTER; Sachdeva J, 2013, J DIGIT IMAGING, V26, P1141, DOI 10.1007/s10278-013-9600-0; Smistad E, 2015, MED IMAGE ANAL, V20, P1, DOI 10.1016/j.media.2014.10.012; Taha AA, 2015, BMC MED IMAGING, V15, DOI 10.1186/s12880-015-0068-x; Togao O, 2016, NEURO-ONCOLOGY, V18, P132, DOI 10.1093/neuonc/nov147; Weltens C, 2001, RADIOTHER ONCOL, V60, P49, DOI 10.1016/S0167-8140(01)00371-1; Yamahara T, 2010, BRAIN TUMOR PATHOL, V27, P81, DOI 10.1007/s10014-010-0275-7	35	10	10	1	7	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2020	2	2							e190011	10.1148/ryai.2020190011	http://dx.doi.org/10.1148/ryai.2020190011			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CS	32280947	Green Published, Bronze			2022-12-18	WOS:000826298800001
J	Yi, X; Adams, SJ; Henderson, RDE; Babyn, P				Yi, Xin; Adams, Scott J.; Henderson, Robert D. E.; Babyn, Paul			Computer-aided Assessment of Catheters and Tubes on Radiographs: How Good Is Artificial Intelligence for Assessment?	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Review							CRITICALLY-ILL; CHEST; MALPOSITION; CARE; COMPLICATIONS; MANAGEMENT; PLACEMENT; AIRWAY; LINES	Catheters are the second most common abnormal finding on radiographs. The position of catheters must be assessed on all radiographs because serious complications can arise if catheters are malpositioned. However, due to the large number of radiographs obtained each day, there can be substantial delays between the time a radiograph is obtained and when it is interpreted by a radiologist. Computer-aided approaches hold the potential to assist in prioritizing radiographs with potentially malpositioned catheters for interpretation and automatically insert text indicating the placement of catheters in radiology reports, thereby improving radiologists' efficiency. After 50 years of research in computer-aided diagnosis, there is still a paucity of study in this area. With the development of deep learning approaches, the problem of catheter assessment is far more solvable. This review provides an overview of current algorithms and identifies key challenges in building a reliable computer-aided diagnosis system for assessment of catheters on radiographs. This review may serve to further the development of machine learning approaches for this important use case. (c) RSNA, 2020	[Yi, Xin; Adams, Scott J.; Babyn, Paul] Univ Saskatchewan, Dept Med Imaging, 103 Hosp Dr, Saskatoon, SK S7N 0W8, Canada; [Henderson, Robert D. E.] Univ Saskatchewan, Coll Med, 103 Hosp Dr, Saskatoon, SK S7N 0W8, Canada	University of Saskatchewan; University of Saskatchewan	Yi, X (corresponding author), Univ Saskatchewan, Dept Med Imaging, 103 Hosp Dr, Saskatoon, SK S7N 0W8, Canada.	xiy525@mail.usaskca	yi, xin/AAC-9894-2020	yi, xin/0000-0001-8546-0580				Ades Anne, 2003, J Perinatol, V23, P24, DOI 10.1038/sj.jp.7210851; Ambrosini Pierre, 2017, Medical Image Computing and Computer-Assisted Intervention, MICCAI 2017. 20th International Conference. Proceedings: LNCS 10434, P577, DOI 10.1007/978-3-319-66185-8_65; [Anonymous], 1999, 10153 BS EN; Arvaniti E, ARXIV 181107013; Baiter S, 2014, AM J ROENTGENOL, V203, pW234, DOI 10.2214/AJR.13.11041; Bingham KL., 2015, PSEUDO RANDOM FOREST; Brunelli R., 2009, TEMPLATE MATCHING TE; Chen S, 2016, INT J COMPUT ASS RAD, V11, P2049, DOI 10.1007/s11548-016-1430-3; Concepcion NDP, 2017, EUR J RADIOL, V95, P409, DOI 10.1016/j.ejrad.2016.06.015; DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Godoy MCB, 2012, AM J ROENTGENOL, V198, P563, DOI 10.2214/AJR.10.7226; GOODMAN LR, 1976, AM J ROENTGENOL, V127, P433, DOI 10.2214/ajr.127.3.433; Green C, 1998, Neonatal Netw, V17, P23; Huber-Wagner S, 2007, RESUSCITATION, V72, P226, DOI 10.1016/j.resuscitation.2006.06.038; Huo ZM, 2008, PROC SPIE, V6915, DOI 10.1117/12.770546; Huo ZM, 2007, INT J COMPUT ASS RAD, V2, pS370; Jain Sanjay N, 2011, Indian J Radiol Imaging, V21, P182, DOI 10.4103/0971-3026.85365; Kao EF, 2015, COMPUT METH PROG BIO, V118, P1, DOI 10.1016/j.cmpb.2014.10.009; Keller BM, 2007, PROC SPIE, V6514, DOI 10.1117/12.707769; Lakhani P, 2017, J DIGIT IMAGING, V30, P460, DOI 10.1007/s10278-017-9980-7; Lee H, 2018, J DIGIT IMAGING, V31, P393, DOI 10.1007/s10278-017-0025-z; LODWICK GS, 1963, RADIOLOGY, V81, P185, DOI 10.1148/81.2.185; Ma YL, 2018, MED PHYS, V45, P5066, DOI 10.1002/mp.13190; MacDonald MG, 2013, ATLAS PROCEDURES NEO, V5th; Meng Q, 2017, INT J COMPUT ASS RAD, V12, P245, DOI 10.1007/s11548-016-1492-2; Mercan CA, 2014, IET IMAGE PROCESS, V8, P122, DOI 10.1049/iet-ipr.2013.0239; Milletari F, 2013, LECT NOTES COMPUT SC, V8151, P371, DOI 10.1007/978-3-642-40760-4_47; Muhm M, 1997, WIEN KLIN WOCHENSCHR, V109, P400; Nayeemuddin M, 2013, CLIN RADIOL, V68, P529, DOI 10.1016/j.crad.2012.10.013; O'Connor CJ, 2005, ANESTH ANALG, V101, P735, DOI 10.1213/01.ane.0000167068.71601.e4; OPPENHEIMER DA, 1982, AM J ROENTGENOL, V138, P1025, DOI 10.2214/ajr.138.6.1025; Ramakrishna B, 2012, PROC SPIE, V8315, DOI 10.1117/12.911839; Ramakrishna B, 2011, PROC SPIE, V7963, DOI 10.1117/12.878172; Ramasethu J, 2008, CLIN PERINATOL, V35, P199, DOI 10.1016/j.clp.2007.11.007; Remerand F, 2007, ANESTHESIOLOGY, V106, P1112; Schmidt U, 2008, CHEST, V134, P288, DOI 10.1378/chest.07-3011; Schummer W, 2007, INTENS CARE MED, V33, P1055, DOI 10.1007/s00134-007-0560-z; Sheng C, 2009, INT J MED ROBOT COMP, V5, P332, DOI 10.1002/rcs.265; Singh R, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0204155; Singh V, 2019, J DIGIT IMAGING, V32, P651, DOI 10.1007/s10278-019-00229-9; Thomas BW, 1998, J AM COLL NUTR, V17, P195, DOI 10.1080/07315724.1998.10718746; van Ginneken B, 2009, EUR J RADIOL, V72, P226, DOI 10.1016/j.ejrad.2009.05.061; Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369; Wu YD, 2018, IEEE IJCNN; Yi X, 2020, J DIGIT IMAGING, V33, P181, DOI 10.1007/s10278-019-00201-7; Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865	47	10	10	0	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2020	2	1							e190082	10.1148/ryai.2020190082	http://dx.doi.org/10.1148/ryai.2020190082			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CR	33937813	Green Submitted, Green Published			2022-12-18	WOS:000826298000009
J	Demirer, M; Candemir, S; Bigelow, MT; Yu, SM; Gupta, V; Prevedello, LM; White, RD; Yu, JS; Grimmer, R; Wels, M; Wimmer, A; Halabi, AH; Ihsani, A; O'Donnell, TP; Erdal, BS				Demirer, Mutlu; Candemir, Sema; Bigelow, Matthew T.; Yu, Sarah M.; Gupta, Vikash; Prevedello, Luciano M.; White, Richard D.; Yu, Joseph S.; Grimmer, Rainer; Wels, Michael; Wimmer, Andreas; Halabi, Abdul H.; Ihsani, Alvin; O'Donnell, Thomas P.; Erdal, Barbaros S.			A User Interface for Optimizing Radiologist Engagement in Image Data Curation for Artificial Intelligence	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To delineate image data curation needs and describe a locally designed graphical user interface (GUI) to aid radiologists in image annotation for artificial intelligence (AI) applications in medical imaging. Materials and Methods: GUI components support image analysis toolboxes, picture archiving and communication system integration, third-party applications, processing of scripting languages, and integration of deep learning libraries. For clinical AI applications, GUI components included two-dimensional segmentation and classification; three-dimensional segmentation and quantification; and three-dimensional segmentation, quantification, and classification. To assess radiologist engagement and performance efficiency associated with GUI-related capabilities, image annotation rate (studies per day) and speed (minutes per case) were evaluated in two clinical scenarios of varying complexity: hip fracture detection and coronary atherosclerotic plaque demarcation and stenosis grading. Results: For hip fracture, 1050 radiographs were annotated over 7 days (150 studies per day; median speed: 10 seconds per study [inter-quartile range, 3-21 seconds per study]). A total of 294 coronary CT angiographic studies with 1843 arteries and branches were annotated for atherosclerotic plaque over 23 days (15.2 studies [80.1 vessels] per day; median speed: 6.08 minutes per study [inter-quartile range, 2.8-10.6 minutes per study] and 73 seconds per vessel [interquartile range, 20.9-155 seconds per vessel]). Conclusion: GUI-component compatibility with common image analysis tools facilitates radiologist engagement in image data curation, including image annotation, supporting AI application development and evolution for medical imaging. When complemented by other GUI elements, a continuous integrated workflow supporting formation of an agile deep neural network life cycle results. Supplemental material is available for this article. (c) RSNA, 2019	[Demirer, Mutlu; Candemir, Sema; Bigelow, Matthew T.; Yu, Sarah M.; Gupta, Vikash; Prevedello, Luciano M.; White, Richard D.; Yu, Joseph S.; Erdal, Barbaros S.] Ohio State Univ, Coll Med, OSU Wexner Medial Ctr,Dept Radiol, Div Med Imaging Informat,Lab Augmented Intelligen, 395 W 12th Ave,Suite 452, Columbus, OH 43210 USA; [Grimmer, Rainer; Wels, Michael; Wimmer, Andreas] Siemens Healthineers, Erlangen, Germany; [Halabi, Abdul H.; Ihsani, Alvin] NVIDIA, Santa Clara, CA USA; [O'Donnell, Thomas P.] Siemens Healthineers, Malvern, PA USA	University System of Ohio; Ohio State University; Siemens AG; Nvidia Corporation; Siemens AG	White, RD (corresponding author), Ohio State Univ, Coll Med, OSU Wexner Medial Ctr,Dept Radiol, Div Med Imaging Informat,Lab Augmented Intelligen, 395 W 12th Ave,Suite 452, Columbus, OH 43210 USA.	Richard.White@osumc.edu	Candemir, Sema/X-2002-2019	Candemir, Sema/0000-0001-8619-5619; Gupta, Vikash/0000-0002-6786-9865; Prevedello, Luciano/0000-0002-6768-6452; Yu, Joseph/0000-0001-6832-7243; Bigelow, Matthew/0000-0002-4733-5911; Demirer, Mutlu/0000-0002-6842-282X				Erickson BJ, 2018, J AM COLL RADIOL, V15, P521, DOI 10.1016/j.jacr.2017.12.027; Fielding R. T., 2000, THESIS U CALIFORNIA; HHS.gov site, GUIDANCE REGARDING M; HUMMEL R, 1977, COMPUT VISION GRAPH, V6, P184, DOI 10.1016/S0146-664X(77)80011-7; Iakovidis D, 2012, STUD HEALTH TECHNOL, V180, P574, DOI 10.3233/978-1-61499-101-4-574; Jodogne S, 2018, J DIGIT IMAGING, V31, P341, DOI 10.1007/s10278-018-0082-y; Karargyris A, 2016, INT J COMPUT ASS RAD, V11, P99, DOI 10.1007/s11548-015-1242-x; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Orthanc, ORTH SERV SIT; Pons E, 2016, RADIOLOGY, V279, P329, DOI 10.1148/radiol.16142770; Prevedello LM, 2017, RADIOLOGY, V285, P923, DOI 10.1148/radiol.2017162664; Qt. Qt site, ABOUTUS; Ravi D, 2017, IEEE J BIOMED HEALTH, V21, P4, DOI 10.1109/JBHI.2016.2636665; restfulapi, REST API TUTORIAL; Ritter F, 2011, IEEE PULSE, V2, P60, DOI 10.1109/MPUL.2011.942929; Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8; Schoenhagen P, 2002, HEART, V88, P91, DOI 10.1136/heart.88.1.91; Seo JD, GENERATING PIXELATED; Syngo.via, SIEM HEALTH SIT; Tang A, 2018, CAN ASSOC RADIOL J, V69, P120, DOI 10.1016/j.carj.2018.02.002; Udupa JK, 2006, COMPUT MED IMAG GRAP, V30, P75, DOI 10.1016/j.compmedimag.2005.12.001; Yank V, 2017, AM J PUBLIC HEALTH, V107, P1283, DOI 10.2105/AJPH.2017.303824; Yosinski J, 2014, ADV NEUR IN, V27; Zheng YF, 2013, LECT NOTES COMPUT SC, V8151, P74, DOI 10.1007/978-3-642-40760-4_10	24	10	10	2	2	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2019	1	6							e180095	10.1148/ryai.2019180095	http://dx.doi.org/10.1148/ryai.2019180095			7	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CQ	33937804	Green Published, Bronze			2022-12-18	WOS:000826296100004
J	Oakden-Rayner, L				Oakden-Rayner, Luke			The Rebirth of CAD: How Is Modern AI Different from the CAD We Know?	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Oakden-Rayner, Luke] Royal Adelaide Hosp, Dept Radiol, North Terrace, Adelaide, SA 5000, Australia; [Oakden-Rayner, Luke] Univ Adelaide, Sch Publ Hlth, Adelaide, SA, Australia; [Oakden-Rayner, Luke] Australian Inst Machine Learning, Adelaide, SA, Australia		Oakden-Rayner, L (corresponding author), Royal Adelaide Hosp, Dept Radiol, North Terrace, Adelaide, SA 5000, Australia.; Oakden-Rayner, L (corresponding author), Univ Adelaide, Sch Publ Hlth, Adelaide, SA, Australia.; Oakden-Rayner, L (corresponding author), Australian Inst Machine Learning, Adelaide, SA, Australia.	luke.oakden-rayner@adelaide.edu.au		Oakden-Rayner, Lauren/0000-0001-5471-5202				[Anonymous], 2019, ETHICS RADIOLOGY EUR; Australian Therapeutic Goods Administration, 2019, CONS REG SOFTW INCL; Chilamkurthy S, 2018, LANCET, V392, P2388, DOI 10.1016/S0140-6736(18)31645-3; Chokshi FH, 2019, RADIOL ARTIF INTELL, V1; Donahue J, 2014, PR MACH LEARN RES, V32; Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056; Fenton JJ, 2007, NEW ENGL J MED, V356, P1399, DOI 10.1056/NEJMoa066099; Gilbert FJ, 2008, NEW ENGL J MED, V359, P1675, DOI 10.1056/NEJMoa0803545; Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216; IMDRF, 2014, SOFTW MED DEV POSS F; Krafcik J, NEXT 10 MILLION MILE; Lehman CD, 2015, JAMA INTERN MED, V175, P1828, DOI 10.1001/jamainternmed.2015.5231; Li Fei-Fei, 2017, IMAGENET HAVE WE BEE; Philpotts LE, 2009, RADIOLOGY, V253, P17, DOI 10.1148/radiol.2531090689; Rao VM, 2010, J AM COLL RADIOL, V7, P802, DOI 10.1016/j.jacr.2010.05.019; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Tchou PM, 2010, RADIOLOGY, V257, P40, DOI 10.1148/radiol.10092170; U.S. Food and Drug Administration, 2018, FDA PERM MARK CLIN D; U.S. Food and Drug Administration, 2012, COMP ASS DEV APPL RA	19	10	10	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2019	1	3							e180089	10.1148/ryai.2019180089	http://dx.doi.org/10.1148/ryai.2019180089			3	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CN	33937793	Green Published			2022-12-18	WOS:000826290100003
J	Kahn, CE				Kahn, Charles E., Jr.			Artificial Intelligence, Real Radiology	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material												ckahn@rsna.org						Erickson BJ, 2017, RADIOGRAPHICS, V37, P505, DOI 10.1148/rg.2017160130; Li F-F, 2018, NY TIMES	2	10	10	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2019	1	1							e184001	10.1148/ryai2019184001	http://dx.doi.org/10.1148/ryai2019184001			1	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CL	33937786				2022-12-18	WOS:000826287700007
J	Chakrabarty, S; Sotiras, A; Milchenko, M; LaMontagne, P; Hileman, M; Marcus, D				Chakrabarty, Satrajit; Sotiras, Aristeidis; Milchenko, Mikhail; LaMontagne, Pamela; Hileman, Michael; Marcus, Daniel			MRI-based Identification and Classification of Major Intracranial Tumor Types by Using a 3D Convolutional Neural Network: A Retrospective Multi-institutional Analysis	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						MR-Imaging; CNS; Brain/Brain Stem; Diagnosis/Classification/Application Domain; Supervised Learning; Convolutional Neural Network; Deep Learning Algorithms; Machine Learning Algorithms		Purpose: To develop an algorithm to classify postcontrast T1-weighted MRI scans by tumor classes (high-grade glioma, low-grade glioma [LGG], brain metastasis, meningioma, pituitary adenoma, and acoustic neuroma) and a healthy tissue (HLTH) class. Materials and Methods: In this retrospective study, preoperative postcontrast T1-weighted MR scans from four publicly available datasets-the Brain Tumor Image Segmentation dataset (n = 378), the LGG-1p19q dataset (n = 145), The Cancer Genome Atlas Glioblastoma Multiforme dataset (n = 141), and The Cancer Genome Atlas Low Grade Glioma dataset (n = 68)-and an internal clinical dataset (n = 1373) were used. In all, a total of 2105 images were split into a training dataset (n = 1396), an internal test set (n = 361), and an external test dataset (n = 348). A convolutional neural network was trained to classify the tumor type and to discriminate between images depicting HLTH and images depicting tumors. The performance of the model was evaluated by using cross-validation, internal testing, and external testing. Feature maps were plotted to visualize network attention. The accuracy, positive predictive value (PPV), negative predictive value, sensitivity, specificity, F1 score, area under the receiver operating characteristic curve (AUC), and area under the precision-recall curve (AUPRC) were calculated. Results: On the internal test dataset, across the seven different classes, the sensitivities, PPVs, AUCs, and AUPRCs ranged from 87% to 100%, 85% to 100%, 0.98 to 1.00, and 0.91 to 1.00, respectively. On the external data, they ranged from 91% to 97%, 73% to 99%, 0.97 to 0.98, and 0.9 to 1.0, respectively. Conclusion: The developed model was capable of classifying postcontrast T1-weighted MRI scans of different intracranial tumor types and discriminating images depicting pathologic conditions from images depicting HLTH. Supplemental material is available for this article. (C) RSNA, 2021.	[Chakrabarty, Satrajit] Washington Univ, Dept Elect & Syst Engn, 1 Brookings Dr, St Louis, MO 63130 USA; [Sotiras, Aristeidis] Washington Univ, Sch Med, Dept Radiol, St Louis, MO USA; [Sotiras, Aristeidis] Washington Univ, Sch Med, Inst Informat, St Louis, MO USA; [Milchenko, Mikhail; LaMontagne, Pamela; Hileman, Michael; Marcus, Daniel] Washington Univ, Sch Med, Mallincicrodt Inst Radiol, St Louis, MO USA	Washington University (WUSTL); Washington University (WUSTL); Washington University (WUSTL); Washington University (WUSTL)	Chakrabarty, S (corresponding author), Washington Univ, Dept Elect & Syst Engn, 1 Brookings Dr, St Louis, MO 63130 USA.	satrajit.chakrabarty@wustl.edu		Sotiras, Aristeidis/0000-0003-0795-8820; LaMontagne, Pamela/0000-0002-6752-8518; Chakrabarty, Satrajit/0000-0002-9664-4470	National Institutes of Health [P30 NS098577, U24 CA204854, R01 EB009352]	National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	D.M. is supported by the National Institutes of Health (grants P30 NS098577, U24 CA204854, and R01 EB009352).	Adebayo J, 2018, ADV NEUR IN, V31; Afshar P, 2019, INT CONF ACOUST SPEE, P1368, DOI 10.1109/ICASSP.2019.8683759; Akkus Z, 2017, J DIGIT IMAGING, V30, P469, DOI 10.1007/s10278-017-9984-3; [Anonymous], BRAIN TUMORS; Bakas S., 2017, CANC IMAGING ARCH, DOI 10.7937/K9/TCIA.2017.GJQ7R0EF286; Bakas S, ARXIV 181102629 PREP; Bakas S, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.117; Bergstra J, 2012, J MACH LEARN RES, V13, P281; Chakrabarty S, 2020, PROC SPIE, V11318, DOI 10.1117/12.2548371; Cheng J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0140381; Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; Erickson B, DATA LGG 1P19QDELETI; Isensee F, 2018, LECT NOTES COMPUT SC, V10670, P287, DOI 10.1007/978-3-319-75238-9_25; Ismael SAA, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101779; Leisenring W, 2000, BIOMETRICS, V56, P345, DOI 10.1111/j.0006-341X.2000.00345.x; McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996; Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694; Mohsen H., 2018, FUTURE COMPUT INFORM, V3, P68; Muhammad K, 2021, IEEE T NEUR NET LEAR, V32, P507, DOI 10.1109/TNNLS.2020.2995800; Paul JS, 2017, PROC SPIE, V10137, DOI 10.1117/12.2254195; Sajjad M, 2019, J COMPUT SCI-NETH, V30, P174, DOI 10.1016/j.jocs.2018.12.003; Seetha J., 2018, BIOMED PHARMACOL J, V11, P1457, DOI [10.13005/bpj/1511, DOI 10.13005/bpj/1511]; Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74; Zacharaki EI, 2009, MAGN RESON MED, V62, P1609, DOI 10.1002/mrm.22147	25	9	9	1	2	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2021	3	5							e200301	10.1148/ryai.2021200301	http://dx.doi.org/10.1148/ryai.2021200301			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9TT	34617029	Green Published			2022-12-18	WOS:000826911500010
J	Cai, JC; Akkus, Z; Philbrick, KA; Boonrod, A; Hoodeshenas, S; Weston, AD; Rouzrokh, P; Conte, GM; Zeinoddini, A; Vogelsang, DC; Huang, Q; Erickson, BJ				Cai, Jason C.; Akkus, Zeynettin; Philbrick, Kenneth A.; Boonrod, Arunnit; Hoodeshenas, Safa; Weston, Alexander D.; Rouzrokh, Pouria; Conte, Gian Marco; Zeinoddini, Atefeh; Vogelsang, David C.; Huang, Qiao; Erickson, Bradley J.			Fully Automated Segmentation of Head CT Neuroanatomy Using Deep Learning	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							COMPUTED-TOMOGRAPHY; STROKE	Purpose: To develop a deep learning model that segments intracranial structures on head CT scans. Materials and Methods: In this retrospective study, a primary dataset containing 62 normal noncontrast head CT scans from 62 patients (mean age, 73 years; age range, 27-95 years) acquired between August and December 2018 was used for model development. Eleven intracranial structures were manually annotated on the axial oblique series. The dataset was split into 40 scans for training, 10 for validation, and 12 for testing. After initial training, eight model configurations were evaluated on the validation dataset and the highest performing model was evaluated on the test dataset. Interobserver variability was reported using multirater consensus labels obtained from the test dataset. To ensure that the model learned generalizable features, it was further evaluated on two secondary datasets containing 12 volumes with idiopathic normal pressure hydrocephalus (iNPH) and 30 normal volumes from a publicly available source. Statistical significance was determined using categorical linear regression with P<.05. Results: Overall Dice coefficient on the primary test dataset was 0.84 +/- 0.05 (standard deviation). Performance ranged from 0.96 +/- 0.01 (brainstem and cerebrum) to 0.74 +/- 0.06 (internal capsule). Dice coefficients were comparable to expert annotations and exceeded those of existing segmentation methods. The model remained robust on external CT scans and scans demonstrating ventricular enlargement. The use of within-network normalization and class weighting facilitated learning of underrepresented classes. Conclusion: Automated segmentation of CT neuroanatomy is feasible with a high degree of accuracy. The model generalized to external CT scans as well as scans demonstrating iNPH. (C) RSNA, 2020	[Cai, Jason C.; Philbrick, Kenneth A.; Hoodeshenas, Safa; Rouzrokh, Pouria; Conte, Gian Marco; Vogelsang, David C.; Huang, Qiao; Erickson, Bradley J.] Mayo Clin Rochester, Dept Radiol, 200 First St SW,RO PB 02 RIL, Rochester, MN 55905 USA; [Akkus, Zeynettin] Mayo Clin Rochester, Dept Cardiovasc Sci, 200 First St SW,RO PB 02 RIL, Rochester, MN 55905 USA; [Boonrod, Arunnit] Khon Kaen Univ, Dept Radiol, Khon Kaen, Thailand; [Weston, Alexander D.] Mayo Clin Florida, Dept Hlth Sci Res, Jacksonville, FL USA; [Zeinoddini, Atefeh] Ascens St John Hosp, Dept Internal Med, Detroit, MI USA	Mayo Clinic; Mayo Clinic; Khon Kaen University; Mayo Clinic	Cai, JC (corresponding author), Mayo Clin Rochester, Dept Radiol, 200 First St SW,RO PB 02 RIL, Rochester, MN 55905 USA.	jason.ccai@gmail.com	; Conte, Gian Marco/K-2801-2018	AKKUS, Zeynettin/0000-0003-3920-1515; /0000-0002-9190-0252; hoodeshenas, safa/0000-0001-8640-0184; Conte, Gian Marco/0000-0001-5926-7517	Mayo Clinic	Mayo Clinic	We would like to thank Mayo Clinic for funding this study. The RSNA Intracranial Hemorrhage Detection Challenge is a publicly available dataset made possible by the Radiological Society of North America.	Akkus Z, 2020, NEUROCOMPUTING, V392, P189, DOI 10.1016/j.neucom.2018.12.085; Akkus Z, 2019, J AM COLL RADIOL, V16, P1318, DOI 10.1016/j.jacr.2019.06.004; Akkus Z, 2017, J DIGIT IMAGING, V30, P449, DOI 10.1007/s10278-017-9983-4; Anderson RC, 2002, J NEUROSURG, V97, P73, DOI 10.3171/jns.2002.97.1.0073; [Anonymous], 1999, 10153 BS EN; Barber PA, 2000, LANCET, V355, P1670, DOI 10.1016/S0140-6736(00)02237-6; Chang PD, 2018, AM J NEURORADIOL, V39, P1609, DOI 10.3174/ajnr.A5742; Despotovic I, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/450341; Diprose WK, 2019, STROKE, V50, P3636, DOI 10.1161/STROKEAHA.119.027120; Erickson BJ, 2018, J AM COLL RADIOL, V15, P521, DOI 10.1016/j.jacr.2017.12.027; Frisoni GB, 2002, AM J NEURORADIOL, V23, P35; Fritscher KD, 2014, MED PHYS, V41, DOI 10.1118/1.4871623; Gao XW, P SPIE MEDICAL IMAGI; Golby AJ, 2015, IMAGE GUIDED NEUROSU; Irimia A, 2019, FRONT NEUROINFORM, V13, DOI 10.3389/fninf.2019.00009; Islam M, 2019, LECT NOTES COMPUT SC, V11383, P456, DOI 10.1007/978-3-030-11723-8_46; Kauw F, 2019, STROKE, V50, pE304, DOI 10.1161/STROKEAHA.119.026853; Kingma DP, ARXIV E PRINTS PREPR; Lei Ba J, ARXIV E PRINTS PREPR; Milletari F., ARXIV E PRINTS PREPR; Paciaroni M, 2003, EUR J NEUROL, V10, P361, DOI 10.1046/j.1468-1331.2003.00646.x; Patel A, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254022; Philbrick KA, 2019, J DIGIT IMAGING, V32, P571, DOI 10.1007/s10278-019-00232-0; Relkin N, 2005, NEUROSURGERY, V57, P4, DOI 10.1227/01.NEU.0000168185.29659.C5; Ronneberger O., ARXIV E PRINTS PREPR; Rosman DA, 2018, AM J ROENTGENOL, V210, P364, DOI [10.2214/AJR.17.18214, 10.2214/AJr17.18214]; Santurkar S., ARXIV E PRINTS PREPR; Toma AK, 2011, NEUROSURGERY, V68, P939, DOI 10.1227/NEU.0b013e318208f5e0; Zhang A., ARXIV E PRINTS PREPR	29	9	9	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2020	2	5							e190183	10.1148/ryai.2020190183	http://dx.doi.org/10.1148/ryai.2020190183			12	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CY	33937839	Green Published, Bronze			2022-12-18	WOS:000826477600004
J	Humpire-Mamani, GE; Bukala, J; Scholten, ET; Prokop, M; van Ginneken, B; Jacobs, C				Humpire-Mamani, Gabriel E.; Bukala, Joris; Scholten, Ernst T.; Prokop, Mathias; van Ginneken, Bram; Jacobs, Colin			Fully Automatic Volume Measurement of the Spleen at CT Using Deep Learning	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To develop a fully automated algorithm for spleen segmentation and to assess the performance of this algorithm in a large dataset. Materials and Methods: In this retrospective study, a three-dimensional deep learning network was developed to segment the spleen on thorax-abdomen CT scans. Scans were extracted from patients undergoing oncologic treatment from 2014 to 2017. A total of 1100 scans from 1100 patients were used in this study, and 400 were selected for development of the algorithm. For testing, a dataset of 50 scans was annotated to assess the segmentation accuracy and was compared against the splenic index equation. In a qualitative observer experiment, an enriched set of 100 scan-pairs was used to evaluate whether the algorithm could aid a radiologist in assessing splenic volume change. The reference standard was set by the consensus of two other independent radiologists. A Mann-Whitney U test was conducted to test whether there was a performance difference between the algorithm and the independent observer. Results: The algorithm and the independent observer obtained comparable Dice scores (P=.834) on the test set of 50 scans of 0.962 and 0.964, respectively. The radiologist had an agreement with the reference standard in 81% (81 of 100) of the cases after a visual classification of volume change, which increased to 92% (92 of 100) when aided by the algorithm. Conclusion: A segmentation method based on deep learning can accurately segment the spleen on CT scans and may help radiologists to detect abnormal splenic volumes and splenic volume changes. (C) RSNA, 2020	[Humpire-Mamani, Gabriel E.; Bukala, Joris; Scholten, Ernst T.; Prokop, Mathias; van Ginneken, Bram; Jacobs, Colin] Radboud Univ Nijmegen, Med Ctr, Diagnost Image Anal Grp, Geert Grootepl 10,Route 767, NL-6525 GA Nijmegen, Netherlands; [van Ginneken, Bram] Fraunhofer MEVIS, Bremen, Germany		Humpire-Mamani, GE (corresponding author), Radboud Univ Nijmegen, Med Ctr, Diagnost Image Anal Grp, Geert Grootepl 10,Route 767, NL-6525 GA Nijmegen, Netherlands.	g.humpiremamani@radboudumc.nl	; Jacobs, Colin/P-6938-2015	Humpire-Mamani, Gabriel Efrain/0000-0002-3199-8163; Jacobs, Colin/0000-0003-1180-3805; Prokop, Mathias/0000-0001-8157-8055; Scholten, Ernst/0000-0002-1982-2763				Ahmad SS, 2012, BRIT MED J, V345, DOI 10.1136/bmj.e7765; Aresta G, 2018, LECT NOTES COMPUT SC, V11040, P310, DOI 10.1007/978-3-030-00946-5_31; Balagopal A, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aaf11c; Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585; Bergman RA, 2002, COMPLETE SPLEEN STRU, P3; Bobo MF, 2018, PROC SPIE, V10574, DOI 10.1117/12.2293751; Chlebus G, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-33860-7; Cruz-Romero C, 2016, EMERG RADIOL, V23, P315, DOI 10.1007/s10140-016-1402-5; Dalmis MU, 2017, MED PHYS, V44, P533, DOI 10.1002/mp.12079; De Odorico I, 1999, J ULTRAS MED, V18, P231, DOI 10.7863/jum.1999.18.3.231; Gauriau R, 2015, I S BIOMED IMAGING, P359, DOI 10.1109/ISBI.2015.7163887; Gibson E, 2018, IEEE T MED IMAGING, V37, P1822, DOI 10.1109/TMI.2018.2806309; Gloger O, 2017, PHYS MED BIOL, V62, P5861, DOI 10.1088/1361-6560/aa766e; Guo ZH, 2018, I S BIOMED IMAGING, P1230; Hammon M, 2012, ROFO-FORTSCHR RONTG, V184, P734, DOI 10.1055/s-0031-1299495; Harris A, 2010, EUR J RADIOL, V75, pE97, DOI 10.1016/j.ejrad.2009.08.013; Humpire-Mamani GE, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aab4b3; Huo YK, 2018, PROC SPIE, V10574, DOI 10.1117/12.2293406; Isensee F, ARXIV190408128 CS; Jacobs KE, 2012, CLIN RADIOL, V67, P982, DOI 10.1016/j.crad.2012.03.013; Joiner BJ, 2015, ABDOM IMAGING, V40, P2338, DOI 10.1007/s00261-015-0451-7; Linguraru MG, 2010, MED PHYS, V37, P771, DOI 10.1118/1.3284530; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Moroz P, 2001, J SURG ONCOL, V78, P248, DOI 10.1002/jso.1162; Okada T, 2015, MED IMAGE ANAL, V26, P1, DOI 10.1016/j.media.2015.06.009; Pattanayak P, 2017, ACAD RADIOL, V24, P831, DOI 10.1016/j.acra.2017.02.001; Prassopoulos P, 1997, EUR RADIOL, V7, P246, DOI 10.1007/s003300050145; Robertson F, 2001, EUR RADIOL, V11, P80, DOI 10.1007/s003300000528; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Roth HR, 2018, COMPUT MED IMAG GRAP, V66, P90, DOI 10.1016/j.compmedimag.2018.03.001; Setio AAA, 2017, MED IMAGE ANAL, V42, P1, DOI 10.1016/j.media.2017.06.015; Simpson AL, 2015, J AM COLL SURGEONS, V220, P271, DOI 10.1016/j.jamcollsurg.2014.12.008; Tong T, 2015, MED IMAGE ANAL, V23, P92, DOI 10.1016/j.media.2015.04.015; Wolz R, 2013, IEEE T MED IMAGING, V32, P1723, DOI 10.1109/TMI.2013.2265805; Wood A, 2018, IEEE ENG MED BIO, P53, DOI 10.1109/EMBC.2018.8512182; Yetter EM, 2003, AM J ROENTGENOL, V181, P1615, DOI 10.2214/ajr.181.6.1811615; Zhou XR, 2016, LECT NOTES COMPUT SC, V10008, P111, DOI 10.1007/978-3-319-46976-8_12; Zhu WT, 2019, MED PHYS, V46, P576, DOI 10.1002/mp.13300	38	9	9	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2020	2	4							e190102	10.1148/ryai.2020190102	http://dx.doi.org/10.1148/ryai.2020190102			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CX	33937830	Bronze, Green Published			2022-12-18	WOS:000826472900003
J	Yan, WJ; Huang, L; Xia, LM; Gu, SJ; Yan, FH; Wang, YY; Tao, Q				Yan, Wenjun; Huang, Lu; Xia, Liming; Gu, Shengjia; Yan, Fuhua; Wang, Yuanyuan; Tao, Qian			MRI Manufacturer Shift and Adaptation: Increasing the Generalizability of Deep Learning Segmentation for MR Images Acquired with Different Scanners	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To quantitatively evaluate the generalizability of a deep learning segmentation tool to MRI data from scanners of different MRI manufacturers and to improve the cross-manufacturer performance by using a manufacturer-adaptation strategy. Materials and Methods: This retrospective study included 150 cine MRI datasets from three MRI manufacturers, acquired between 2017 and 2018 (n = 50 for manufacturer 1, manufacturer 2, and manufacturer 3). Three convolutional neural networks (CNNs) were trained to segment the left ventricle (LV), using datasets exclusively from images from a single manufacturer. A generative adversarial network (GAN) was trained to adapt the input image before segmentation. The LV segmentation performance, end-diastolic volume (EDV), end-systolic volume (ESV), LV mass, and LV ejection fraction (LVEF) were evaluated before and after manufacturer adaptation. Paired Wilcoxon signed rank tests were performed. Results: The segmentation CNNs exhibited a significant performance drop when applied to datasets from different manufacturers (Dice reduced from 89.7% +/- 2.3 [standard deviation] to 68.7% +/- 10.8, P<.05, from 90.6% +/- 2.1 to 59.5% +/- 13.3, P<.05, from 89.2% +/- 2.3 to 64.1% +/- 12.0, P<.05, for manufacturer 1, 2, and 3, respectively). After manufacturer adaptation, the segmentation performance was significantly improved (from 68.7% +/- 10.8 to 84.3% +/- 6.2, P<.05, from 72.4% +/- 10.2 to 85.7% +/- 6.5, P<.05, for manufacturer 2 and 3, respectively). Quantitative LV function parameters were also significantly improved. For LVEF, the manufacturer adaptation increased the Pearson correlation from 0.005 to 0.89 for manufacturer 2 and from 0.77 to 0.94 for manufacturer 3. Conclusion: A segmentation CNN well trained on datasets from one MRI manufacturer may not generalize well to datasets from other manufacturers. The proposed manufacturer adaptation can largely improve the generalizability of a deep learning segmentation tool without additional annotation. (C) RSNA, 2020	[Yan, Wenjun; Wang, Yuanyuan] Fudan Univ, Biomed Engn Ctr, Shanghai, Peoples R China; [Huang, Lu; Xia, Liming] Huazhong Univ Sci & Technol, Tongji Hosp, Tongji Med Coll, Dept Radiol, Wuhan, Peoples R China; [Gu, Shengjia; Yan, Fuhua] Shanghai Jiao Tong Univ, Ruijin Hosp, Dept Radiol, Shanghai, Peoples R China; [Tao, Qian] Leiden Univ, Med Ctr, Dept Radiol, Div Image Proc, Albinusdreef 2, NL-2333 ZA Leiden, Netherlands	Fudan University; Huazhong University of Science & Technology; Shanghai Jiao Tong University; Leiden University; Leiden University Medical Center (LUMC); Leiden University - Excl LUMC	Tao, Q (corresponding author), Leiden Univ, Med Ctr, Dept Radiol, Div Image Proc, Albinusdreef 2, NL-2333 ZA Leiden, Netherlands.	q.tao@lumc.nl	wangwangwang, yuanyaun/HHN-6432-2022; Wang, Yu/GZL-9655-2022; Wang, Yuan/HHC-1520-2022; Lv, Yuanjie/AER-0767-2022	Huang, Lu/0000-0003-0067-9423	National Key Research and Development Program of China [2018YFC0116303]	National Key Research and Development Program of China	W.Y. Activities related to the present article: institution received money from National Key Research and Development Program of China under Grant 2018YFC0116303. Activities not related to the present article: disclosed no relevant relationships. Other relationships: disclosed no relevant relationships. L.H. disclosed no relevant relationships. L.X. disclosed no relevant relationships. S.G. disclosed no relevant relationships. F.Y. disclosed no relevant relationships. Y.W. Activities related to the present article: institution received money from National Key Research and Development Program of China under Grant 2018YFC0116303. Activities not related to the present article: disclosed no relevant relationships. Other relationships: disclosed no relevant relationships. Q.T.	Allen B, 2019, J AM COLL RADIOL, V16, P1179, DOI 10.1016/j.jacr.2019.04.014; Bai WJ, 2018, J CARDIOVASC MAGN R, V20, DOI 10.1186/s12968-018-0471-x; Bakas S, ARXIV181102629 CS ST; Bernard O, 2018, IEEE T MED IMAGING, V37, P2514, DOI 10.1109/TMI.2018.2837502; Bhuva AN, 2019, CIRC-CARDIOVASC IMAG, V12, DOI 10.1161/CIRCIMAGING.119.009214; Bluemke DA, 2020, RADIOLOGY, V294, P487, DOI 10.1148/radiol.2019192515; Chen AT, 2018, LECT NOTES COMPUT SC, V10663, P21, DOI 10.1007/978-3-319-75541-0_3; Chen L, 2018, IEEE T MED IMAGING, V37, P2453, DOI 10.1109/TMI.2018.2835303; Colletti PM, 2019, CIRC-CARDIOVASC IMAG, V12, DOI 10.1161/CIRCIMAGING.119.009759; Crammer K, 2008, J MACH LEARN RES, V9, P1757; Duda R.O., 2017, PATTERN CLASSIFICATI; Goodfellow I, 2016, DEEP LEARNING; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Karras T, ARXIV181204948 CS ST; Kurata Y, 2019, COMPUT BIOL MED, V114, DOI 10.1016/j.compbiomed.2019.103438; Lakhani P, 2018, J AM COLL RADIOL, V15, P350, DOI 10.1016/j.jacr.2017.09.044; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; McRobbie D. W., 2006, MRI PICTURE PROTON; Pooley RA, 2005, RADIOGRAPHICS, V25, P1087, DOI 10.1148/rg.254055027; Raghu M, 2019, ARXIV190207208 CS ST; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI 10.1146/annurev-bioeng-071516-044442; Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640; Tao Q, 2019, RADIOLOGY, V290, P81, DOI 10.1148/radiol.2018180513; Yan WJ, 2019, LECT NOTES COMPUT SC, V11765, P623, DOI 10.1007/978-3-030-32245-8_69; Zhu JY, ARXIV170310593 CS PR; Zou KH, 2004, ACAD RADIOL, V11, P178, DOI 10.1016/S1076-6332(03)00671-8	27	9	9	0	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2020	2	4							e190195	10.1148/ryai.2020190195	http://dx.doi.org/10.1148/ryai.2020190195			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CX	33937833	Bronze, Green Published			2022-12-18	WOS:000826472900006
J	Sekuboyina, A; Rempfler, M; Valentinitsch, A; Menze, BH; Kirschke, JS				Sekuboyina, Anjany; Rempfler, Markus; Valentinitsch, Alexander; Menze, Bjoern H.; Kirschke, Jan S.			Labeling Vertebrae with Two-dimensional Reformations of Multidetector CT Images: An Adversarial Approach for Incorporating Prior Knowledge of Spine Anatomy	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To use and test a labeling algorithm that operates on two-dimensional reformations, rather than three-dimensional data to locate and identify vertebrae. Materials and Methods: The authors improved the Btrfly Net, a fully convolutional network architecture described by Sekuboyina et al, which works on sagittal and coronal maximum intensity projections (MIPs) and augmented it with two additional components: spine localization and adversarial a priori learning. Furthermore, two variants of adversarial training schemes that incorporated the anatomic a priori knowledge into the Btrfly Net were explored. The superiority of the proposed approach for labeling vertebrae on three datasets was investigated: a public benchmarking dataset of 302 CT scans and two in-house datasets with a total of 238 CT scans. The Wilcoxon signed rank test was employed to compute the statistical significance of the improvement in performance observed with various architectural components in the authors' approach. Results: On the public dataset, the authors' approach using the described Btrfly Net with energy-based prior encoding (Btrfly(pe-eb)) network performed as well as current state-of-the-art methods, achieving a statistically significant (P < .001) vertebrae identification rate of 88.5% +/- 0.2 (standard deviation) and localization distances of less than 7 mm. On the in-house datasets that had a higher interscan data variability, an identification rate of 85.1% +/- 1.2 was obtained. Conclusion: An identification performance comparable to existing three-dimensional approaches was achieved when labeling vertebrae on two-dimensional MIPs. The performance was further improved using the proposed adversarial training regimen that effectively enforced local spine a priori knowledge during training. Spine localization increased the generalizability of our approach by homogenizing the content in the MIPs. Supplemental material is available for this article. (c) RSNA, 2020	[Sekuboyina, Anjany; Menze, Bjoern H.] Tech Univ Munich, Dept Informat, Munich, Germany; [Sekuboyina, Anjany; Valentinitsch, Alexander; Kirschke, Jan S.] Tech Univ Munich, Sch Med, Dept Neuroradiol, Munich, Germany; [Sekuboyina, Anjany] Klinikum Rechrs Isar, Dept Diagnost & Intervent Neuroradiol, Ismaninger Str 22, D-81675 Munich, Germany; [Rempfler, Markus] Friedrich Miescher Inst Biomed Engn, Basel, Switzerland	Technical University of Munich; Technical University of Munich	Sekuboyina, A (corresponding author), Tech Univ Munich, Dept Informat, Munich, Germany.; Sekuboyina, A (corresponding author), Tech Univ Munich, Sch Med, Dept Neuroradiol, Munich, Germany.; Sekuboyina, A (corresponding author), Klinikum Rechrs Isar, Dept Diagnost & Intervent Neuroradiol, Ismaninger Str 22, D-81675 Munich, Germany.	anjany.sekuboyina@tum.de	Kirschke, Jan/E-2550-2012	Kirschke, Jan/0000-0002-7557-0003; Menze, Bjoern/0000-0003-4136-5690; Sekuboyina, Anjany/0000-0002-5601-284X	European Research Council under the European Union [GA637164-iBack-ERC-2014-STG]	European Research Council under the European Union(European Research Council (ERC))	Work supported by the European Research Council under the European Union's Horizon 2020 Research and Innovation program (GA637164-iBack-ERC-2014-STG).	Arjovsky M, ARXIV 170107875; Chen H, 2015, LECT NOTES COMPUT SC, V9349, P515, DOI 10.1007/978-3-319-24553-9_63; Glocker B, 2013, LECT NOTES COMPUT SC, V8150, P262, DOI 10.1007/978-3-642-40763-5_33; Glocker B, 2012, LECT NOTES COMPUT SC, V7512, P590, DOI 10.1007/978-3-642-33454-2_73; Klinder T, 2009, MED IMAGE ANAL, V13, P471, DOI 10.1016/j.media.2009.02.004; Liao HF, 2018, IEEE T MED IMAGING, V37, P1266, DOI 10.1109/TMI.2018.2798293; Ma J, 2013, COMPUT VIS IMAGE UND, V117, P1072, DOI 10.1016/j.cviu.2012.11.016; Oktay O, ARXIV 170508302; Ravishankar Hariharan, 2017, INT C MED IM COMP CO, DOI DOI 10.1007/978-3-319-66182-7_24; Schmidt S, 2007, INFORM PROCESSING ME; Sekuboyina A, 2018, LECT NOTES COMPUT SC, V11073, P649, DOI 10.1007/978-3-030-00937-3_74; Suzani A, 2015, MEDICAL IMAGE COMPUT; Valentinitsch A, 2019, OSTEOPOROSIS INT, V30, P1275, DOI 10.1007/s00198-019-04910-1; Valentinitsch A, 2017, BONE, V103, P233, DOI 10.1016/j.bone.2017.06.013; Yang D, 2017, MEDICAL IMAGE COMPUT; Yang D, 2017, LECT NOTES COMPUT SC, V10265, P633, DOI 10.1007/978-3-319-59050-9_50	16	9	9	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2020	2	2							e190074	10.1148/ryai.2020190074	http://dx.doi.org/10.1148/ryai.2020190074			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CS	33937818	Bronze, Green Published			2022-12-18	WOS:000826298800006
J	MacDougall, RD; Zhang, YB; Callahan, MJ; Perez-Rossello, J; Breen, MA; Johnston, PR; Yu, HY				MacDougall, Robert D.; Zhang, Yanbo; Callahan, Michael J.; Perez-Rossello, Jeannette; Breen, Micheal A.; Johnston, Patrick R.; Yu, Hengyong			Improving Low-Dose Pediatric Abdominal CT by Using Convolutional Neural Networks	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							IMAGE QUALITY; SYSTEM; NOISE	Purpose: To evaluate the efficacy of convolutional neural networks (CNNs) to improve the image quality of low-dose pediatric abdominal CT images. Materials and Methods: Images from 11 pediatric abdominal CT examinations acquired between June and July 2018 were reconstructed with filtered back projection (FBP) and an iterative reconstruction (IR) algorithm. A residual CNN was trained using the FBP image as the input and the difference between FBP and IR as the target such that the network was able to predict the residual image and simulate the IR. CNN-based postprocessing was applied to 20 low-dose pediatric image datasets acquired between December 2016 and December 2017 on a scanner limited to reconstructing FBP images. The FBP and CNN images were evaluated based on objective image noise and subjective image review by two pediatric radiologists. For each of five features, readers rated images on a five-point Likert scale and also indicated their preferred series. Readers also indicated their "overall preference" for CNN versus FBP. Preference and Likert scores were analyzed for individual and combined readers. Interreader agreement was assessed. Results: The CT number remained unchanged between FBP and CNN images. Image noise was reduced by 31% for CNN images (P < .001). CNN was preferred for overall image quality for individual and combined readers. For combined Likert scores, at least one of the two score types (Likert or binary preference) indicated a significant favoring of CNN over FBP for low contrast, image noise, artifacts, and high contrast, whereas the reverse was true for spatial resolution. Conclusion: FBP images can be improved in image space by a well-trained CNN, which may afford a reduction in dose or improvement in image quality on scanners limited to FBP reconstruction. (c) RSNA, 2019	[MacDougall, Robert D.; Callahan, Michael J.; Perez-Rossello, Jeannette; Breen, Micheal A.; Johnston, Patrick R.] Boston Childrens Hosp, Dept Radiol, 300 Longwood Ave, Boston, MA 02115 USA; [MacDougall, Robert D.] Univ Massachusetts, Dept Biomed Engn, Lowell, MA 01854 USA; [Zhang, Yanbo; Yu, Hengyong] Univ Massachusetts, Dept Elect & Comp Engn, Lowell, MA USA; [Zhang, Yanbo] US Res Lab, Ping An Technol, Palo Alto, CA USA	Harvard University; Boston Children's Hospital; University of Massachusetts System; University of Massachusetts Lowell; University of Massachusetts System; University of Massachusetts Lowell	MacDougall, RD (corresponding author), Boston Childrens Hosp, Dept Radiol, 300 Longwood Ave, Boston, MA 02115 USA.; MacDougall, RD (corresponding author), Univ Massachusetts, Dept Biomed Engn, Lowell, MA 01854 USA.	Robert.D.MacDougall@childrens.harvard.edu		Callahan, Michael J./0000-0002-7833-4524; MacDougall, Robert/0000-0002-1383-6275				Agresti A., 2003, CATEGORICAL DATA ANA, V482, DOI DOI 10.1002/0471249688; [Anonymous], 1999, 10153 BS EN; Brink JA, 2010, RADIOLOGY, V257, P601, DOI 10.1148/radiol.10101335; Chen H, 2017, BIOMED OPT EXPRESS, V8, P679, DOI 10.1364/BOE.8.000679; Dahl GE, 2013, INT CONF ACOUST SPEE, P8609, DOI 10.1109/ICASSP.2013.6639346; Fitzmaurice GM, 2011, APPL LONGITUDINAL AN; Fleiss JL, 1981, STAT METHODS RATES P; Ioffe S., ARXIV150203167V3; Kang E, 2017, MED PHYS, V44, pe360, DOI 10.1002/mp.12344; Larson DB, 2013, RADIOLOGY, V269, P177, DOI 10.1148/radiol.13122321; Li G, 2016, J APPL CLIN MED PHYS, V17, P428, DOI 10.1120/jacmp.v17i5.6225; Mileto A, 2018, RADIOLOGY, V289, P443, DOI 10.1148/radiol.2018180137; SAS, 2015, SAS STAT 14 1 US GUI; Solomon J, 2015, MED PHYS, V42, P4941, DOI 10.1118/1.4923172; Strauss KJ, 2010, AM J ROENTGENOL, V194, P868, DOI 10.2214/AJR.09.4091; Wang G, 2016, IEEE ACCESS, V4, P8914, DOI 10.1109/ACCESS.2016.2624938; Wellek S., 2010, TESTING STAT HYPOTHE, V2nd; Yang W, 2017, IEEE ACCESS, V5, P24698, DOI 10.1109/ACCESS.2017.2766438; Yi X, 2018, J DIGIT IMAGING, V31, P655, DOI 10.1007/s10278-018-0056-0; Zhang H, 2018, MED PHYS, V45, pE886, DOI 10.1002/mp.13123; Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206; Zhang Y, 2018, 5 INT C IMAGE FORMAT, P411	22	9	9	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2019	1	6							e180087	10.1148/ryai.2019180087	http://dx.doi.org/10.1148/ryai.2019180087			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CQ	32090205	Bronze, Green Published			2022-12-18	WOS:000826296100003
J	Gaonkar, B; Beckett, J; Villaroman, D; Ahn, C; Edwards, M; Moran, S; Attiah, M; Babayan, D; Ames, C; Villablanca, JP; Salamon, N; Bui, A; Macyszyn, L				Gaonkar, Bilwaj; Beckett, Joel; Villaroman, Diane; Ahn, Christine; Edwards, Matthew; Moran, Steven; Attiah, Mark; Babayan, Diana; Ames, Christopher; Villablanca, J. Pablo; Salamon, Noriko; Bui, Alex; Macyszyn, Luke			Quantitative Analysis of Neural Foramina in the Lumbar Spine: An Imaging Informatics and Machine Learning Study	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To use machine learning tools and leverage big data informatics to statistically model the variation in the area of lumbar neural foramina in a large asymptomatic population. Materials and Methods: By using an electronic health record and imaging archive, lumbar MRI studies in 645 male (mean age, 50.07 years) and 511 female (mean age, 48.23 years) patients between 20 and 80 years old were identified. Machine learning algorithms were used to delineate lumbar neural foramina autonomously and measure their areas. The relationship between neural foraminal area and patient age, sex, and height was studied by using multivariable linear regression. Results: Neural foraminal areas correlated directly with patient height and inversely with patient age. The associations involved were statistically significant (P <.01). Conclusion: By using machine learning and big data techniques, a linear model encoding variation in lumbar neural foraminal areas in asymptomatic individuals has been established. This model can be used to make quantitative assessments of neural foraminal areas in patients by comparing them to the age-, sex-, and height-adjusted population averages. (C) RSNA, 2019	[Gaonkar, Bilwaj; Beckett, Joel; Villaroman, Diane; Ahn, Christine; Edwards, Matthew; Attiah, Mark; Babayan, Diana; Macyszyn, Luke] Univ Calif Los Angeles, Dept Neurosurg, 300 Stein Plaza,Suite 554E, Los Angeles, CA 90095 USA; [Villablanca, J. Pablo; Salamon, Noriko; Bui, Alex] Univ Calif Los Angeles, Dept Radiol Sci, 300 Stein Plaza,Suite 554E, Los Angeles, CA 90095 USA; [Moran, Steven] Univ Calif Los Angeles, Dept Elect Engn, 300 Stein Plaza,Suite 554E, Los Angeles, CA 90095 USA; [Ames, Christopher] Univ Calif San Francisco, Dept Neurosurg, San Francisco, CA USA	University of California System; University of California Los Angeles; University of California System; University of California Los Angeles; University of California System; University of California Los Angeles; University of California System; University of California San Francisco	Gaonkar, B (corresponding author), Univ Calif Los Angeles, Dept Neurosurg, 300 Stein Plaza,Suite 554E, Los Angeles, CA 90095 USA.	bilwaj@gmail.com		Edwards, Matthew/0000-0002-0846-0146; Attiah, Mark/0000-0001-8609-7883; Villaroman, Diane/0000-0003-1475-1238; Moran, Steven/0000-0001-7914-5525				Ali Farhadi, 2018, Arxiv, DOI arXiv:1804.02767; Alpert Hillel R, 2004, J Am Coll Radiol, V1, P127, DOI 10.1016/j.jacr.2003.11.001; [Anonymous], 1970, J AMER MED ASSOC, V212, P873; Aslan MS, 2009, LECT NOTES COMPUT SC, V5876, P519; Bankier AA, 2010, RADIOLOGY, V257, P14, DOI 10.1148/radiol.10100252; Bishop C.M., 2006, PATTERN RECOGN, DOI [DOI 10.1007/978-0-387-45528-0, DOI 10.1016/C2009-0-22409-3]; Brady Adrian, 2012, Ulster Med J, V81, P3; Brinjikji W, 2015, AM J NEURORADIOL, V36, P811, DOI 10.3174/ajnr.A4173; Centers for Disease Control and Prevention National Healthcare and Safety Network, NEW ICD 10 CM COD 2; Chad DA, 2007, NEUROL CLIN, V25, P407, DOI 10.1016/j.ncl.2007.01.003; Chen ZL, 2017, IEEE INT VEH SYM, P1856, DOI 10.1109/IVS.2017.7995975; Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177; Gaonkar Bilwaj, 2017, IEEE J Transl Eng Health Med, V5, P1800412, DOI 10.1109/JTEHM.2017.2717982; Gaonkar B, 2015, ACAD RADIOL, V22, P653, DOI 10.1016/j.acra.2015.01.005; Genevay S, 2010, BEST PRACT RES CL RH, V24, P253, DOI 10.1016/j.berh.2009.11.001; Hall FM, 2009, RADIOLOGY, V251, P313, DOI 10.1148/radiol.2512090177; Kamper SJ, 2015, BMJ-BRIT MED J, V350, DOI 10.1136/bmj.h444; Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241; Krizhevsky A., 2012, NIPS, P1106, DOI DOI 10.1145/3065386; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Lurie J, 2016, BMJ-BRIT MED J, V352, DOI 10.1136/bmj.h6234; Mirzaalian H, 2013, IEEE ENG MED BIO, P3379, DOI 10.1109/EMBC.2013.6610266; Peng ZG, 2005, P ANN INT IEEE EMBS, P2527; Rice J.A., 2006, MATH STAT DATA ANAL; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Sekuboyina A, ARXIV PREPRINT; Soh M, LEARNING CNN LSTM AR; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Xing Ji, 2016, Computational Methods and Clinical Applications for Spine Imaging. 4th International Workshop and Challenge, CSI 2016, held in conjunction with MICCAI 2016. Revised Selected Papers: LNCS 10182, P92, DOI 10.1007/978-3-319-55050-3_9; Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015; Zukic D, 2012, VISION MODELING VISU, P135, DOI DOI 10.2312/PE/VMV/VMV12/135-142	32	9	9	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2019	1	2							e180037	10.1148/ryai.2019180037	http://dx.doi.org/10.1148/ryai.2019180037			6	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CM	33937788	Green Published			2022-12-18	WOS:000826288900004
J	Driggs, D; Selby, I; Roberts, M; Gkrania-Klotsas, E; Rudd, JHF; Yang, G; Babar, J; Sala, E; Schonlieb, CB				Driggs, Derek; Selby, Ian; Roberts, Michael; Gkrania-Klotsas, Effrossyni; Rudd, James H. F.; Yang, Guang; Babar, Judith; Sala, Evis; Schonlieb, Carola-Bibiane		AIX-COVNET Collaboration	Machine Learning for COVID-19 Diagnosis and Prognostication: Lessons for Amplifying the Signal While Reducing the Noise	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material							ARTIFICIAL-INTELLIGENCE		[Driggs, Derek; Roberts, Michael; Schonlieb, Carola-Bibiane] Univ Cambridge, Dept Appl Math & Theoret Phys, Cambridge, England; [Rudd, James H. F.] Univ Cambridge, Div Cardiovasc Med, Cambridge, England; [Selby, Ian; Babar, Judith; Sala, Evis] Univ Cambridge, Sch Clin Med, Dept Radiol, Cambridge CB2 0QQ, England; [Selby, Ian; Babar, Judith; Sala, Evis] CRUK Cambridge Ctr, Biomed Campus, Cambridge, England; [Roberts, Michael] AstraZeneca, Oncol R&D, Cambridge, England; [Gkrania-Klotsas, Effrossyni] Univ Cambridge Hosp, Dept Infect Dis, Cambridge, England; [Yang, Guang] Imperial Coll London, Natl Heart & Lung Inst, London, England	University of Cambridge; University of Cambridge; University of Cambridge; CRUK Cambridge Institute; AstraZeneca; Imperial College London	Sala, E (corresponding author), Univ Cambridge, Sch Clin Med, Dept Radiol, Cambridge CB2 0QQ, England.; Sala, E (corresponding author), CRUK Cambridge Ctr, Biomed Campus, Cambridge, England.	es220@medschl.cam.ac.uk	; Yang, Guang/S-5032-2016	Rudd, James/0000-0003-2243-3117; Gkrania-Klotsas, Effrossyni/0000-0002-0930-8330; Yang, Guang/0000-0001-7344-7733; Selby, Ian/0000-0003-4244-8893; Driggs, Derek/0000-0003-1582-5884; Sala, Evis/0000-0002-5518-9360	NIHR Cambridge Biomedical Research Centre; Engineering and Physical Sciences Research Council (EPSRC); British Heart Foundation; Cancer Research UK National Cancer Imaging Translational Accelerator (NCITA) [C22479/A28667]; Intel; DRAGON consortium - Innovative Medicines Initiative 2 Joint Undertaking (JU) [101005122]; Cambridge Mathematics of Information in Healthcare (CMIH) Hub [EP/T017961/1]; Royal Society Wolfson Fellowship; EPSRC [EP/S026045/1, EP/T003553/1, EP/N014588/1]; Wellcome Innovator Award [RG98755]; European Union [777826]; Cantab Capital Institute for the Mathematics of Information; Alan Turing Institute	NIHR Cambridge Biomedical Research Centre(National Institute for Health Research (NIHR)); Engineering and Physical Sciences Research Council (EPSRC)(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); British Heart Foundation(British Heart Foundation); Cancer Research UK National Cancer Imaging Translational Accelerator (NCITA); Intel(Intel Corporation); DRAGON consortium - Innovative Medicines Initiative 2 Joint Undertaking (JU); Cambridge Mathematics of Information in Healthcare (CMIH) Hub; Royal Society Wolfson Fellowship; EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Wellcome Innovator Award; European Union(European Commission); Cantab Capital Institute for the Mathematics of Information; Alan Turing Institute	Supported by the NIHR Cambridge Biomedical Research Centre, the Engineering and Physical Sciences Research Council (EPSRC), the British Heart Foundation, Cancer Research UK National Cancer Imaging Translational Accelerator (NCITA) (C22479/A28667), Intel, and the DRAGON consortium, which received funding from the Innovative Medicines Initiative 2 Joint Undertaking (JU) under grant agreement no 101005122, and the Cambridge Mathematics of Information in Healthcare (CMIH) Hub EP/T017961/1. C.B.S. further acknowledges support from the Philip Leverhulme Prize, the Royal Society Wolfson Fellowship, the EPSRC grants EP/S026045/1 and EP/T003553/1, EP/N014588/1, the Wellcome Innovator Award RG98755, European Union Horizon 2020 research and innovation programme under the Marie SklodowskaCurie grant agreement no. 777826 Nonlocal Methods for Arbitrary Data Sources (NoMADS), the Cantab Capital Institute for the Mathematics of Information, and the Alan Turing Institute.	AIX-COVNET Collaboration Website, COVID19AIMATHSCAMACU; British Society of Thoracic Imaging, 2020, RAD DEC TOOL SUSP CO; Collins GS, 2019, LANCET, V393, P1577, DOI 10.1016/S0140-6736(19)30037-6; Collins GS, 2015, ANN INTERN MED, V162, P55, DOI [10.7326/M14-0697, 10.1038/bjc.2014.639, 10.1161/CIRCULATIONAHA.114.014508, 10.1186/s12916-014-0241-z, 10.1002/bjs.9736, 10.7326/M14-0698, 10.1016/j.jclinepi.2014.11.010, 10.1136/bmj.g7594, 10.1016/j.eururo.2014.11.025]; Fisher M, 2020, PRACT DIABETES, V37, P191, DOI 10.1002/pdi.2294; Gog JR, 2020, NAT REV PHYS, V2, P274, DOI 10.1038/s42254-020-0175-7; Goncalves J, 2021, NAT MACH INTELL, V3, P28, DOI 10.1038/s42256-020-00251-5; He K, ARXIV 191105722; Irvin J, 2019, AAAI CONF ARTIF INTE, P590; Jacob J, 2020, EUR RESPIR J, V56, DOI 10.1183/13993003.01809-2020; Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010; Kundu S, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020200053; Kurakin A, 5 INT C LEARN REPRES; Lambin P, 2017, NAT REV CLIN ONCOL, V14, P749, DOI 10.1038/nrclinonc.2017.141; Liu XX, 2020, NAT MED, V26, P1364, DOI 10.1038/s41591-020-1034-x; Neyman J, 1934, J R STAT SOC, V97, P558, DOI 10.2307/2342192; Raghu M, 2019, ADV NEUR IN, V32; Rajpurkar P, ARXIV PREPRINT; Rivera SC, 2020, NAT MED, V26, P1351, DOI 10.1038/s41591-020-1037-7; Roberts M, NAT MACH INTELL ARXI; Shih G, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180041; Soltan AAS, 2021, LANCET DIGIT HEALTH, V3, pe78, DOI 10.1016/S2589-7500(20)30274-0; Sriram A, ARXIV 210104909 PREP; Summers RM, 2021, RADIOLOGY, V298, pE162, DOI [10.1148/radiol.2020204226, 10.1148/radiol.20202042226]; Sysmex UK Ltd, SYSM EURE GMBH; The Royal College of Radiologists, 2020, ROL CT PAT SUSP COVI; Tsai EB, 2021, RADIOLOGY, V299, pE204, DOI 10.1148/radiol.2021203957; Wolff RF, 2019, ANN INTERN MED, V170, P51, DOI 10.7326/M18-1376; Zhang C, ARXIV PREPRINT; Zhao J, ARXIV 200313865 PREP	30	8	8	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2021	3	4							e210011	10.1148/ryai.2021210011	http://dx.doi.org/10.1148/ryai.2021210011			4	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SU	34240059	Green Published, Green Submitted			2022-12-18	WOS:000826909000013
J	Rudie, JD; Weiss, DA; Colby, JB; Rauschecker, AM; Laguna, B; Braunstein, S; Sugrue, LP; Hess, CP; Villanueva-Meyer, JE				Rudie, Jeffrey D.; Weiss, David A.; Colby, John B.; Rauschecker, Andreas M.; Laguna, Benjamin; Braunstein, Steve; Sugrue, Leo P.; Hess, Christopher P.; Villanueva-Meyer, Javier E.			Three-dimensional U-Net Convolutional Neural Network for Detection and Segmentation of Intracranial Metastases	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						MR Imaging; Neuro-Oncology; Neural Networks; CNS; Brain/Brain Stem; Segmentation/Feature Detection/Quantification (Vision and Application Domain)	BRAIN METASTASES; MANAGEMENT	Purpose: To develop and validate a neural network for automated detection and segmentation of intracranial metastases on brain MRI studies obtained for stereotactic radiosurgery treatment planning. Materials and Methods: In this retrospective study, 413 patients (average age, 61 years +/- 12 [standard deviation]; 238 women) with a total of 5202 intracranial metastases (median volume, 0.05 cm(3); interquartile range, 0.02-0.18 cm(3)) undergoing stereotactic radiosurgery at one institution were included (January 2017 to February 2020). A total of 563 MRI examinations were performed among the patients, and studies were split into training (n = 413), validation (n = 50), and test (n = 100) datasets. A three-dimensional (3D) U-Net convolutional network was trained and validated on 413 T1 postcontrast or subtraction scans, and several loss functions were evaluated. After model validation, 100 discrete test patients, who underwent imaging after the training and validation patients, were used for final model evaluation. Performance for detection and segmentation of metastases was evaluated using Dice scores, false discovery rates, and false-negative rates, and a comparison with neuroradiologist interrater reliability was performed. Results: The median Dice score for segmenting enhancing metastases in the test set was 0.75 (interquartile range, 0.63-0.84). There were strong correlations between manually segmented and predicted metastasis volumes (r = 0.98, P < .001) and between the number of manually segmented and predicted metastases (R = 0.95, P < .001). Higher Dice scores were strongly correlated with larger metastasis volumes on a logarithmically transformed scale (r = 0.71). Sensitivity across the whole test sample was 70.0% overall and 96.4% for metastases larger than 6 mm. There was an average of 0.46 false-positive results per scan, with the positive predictive value being 91.5%. In comparison, the median Dice score between two neuroradiologists was 0.85 (interquartile range, 0.80-0.89), with sensitivity across the test sample being 87.9% overall and 98.4% for metastases larger than 6 mm. Conclusion: A 3D U-Net-based convolutional neural network was able to segment brain metastases with high accuracy and perform detection at the level of human interrater reliability for metastases larger than 6 mm. (C) RSNA, 2021	[Rudie, Jeffrey D.; Weiss, David A.; Colby, John B.; Rauschecker, Andreas M.; Laguna, Benjamin; Braunstein, Steve; Sugrue, Leo P.; Hess, Christopher P.; Villanueva-Meyer, Javier E.] Univ Calif San Francisco, Dept Radiol & Biomed Imaging, 513 Parnassus Ave, San Francisco, CA 94143 USA	University of California System; University of California San Francisco	Rudie, JD (corresponding author), Univ Calif San Francisco, Dept Radiol & Biomed Imaging, 513 Parnassus Ave, San Francisco, CA 94143 USA.	jeffrey.rudie@gmail.com		Villanueva-Meyer, Javier/0000-0002-5910-0757; Rudie, Jeffrey/0000-0001-8609-8421; Rauschecker, Andreas/0000-0003-0633-9876; Hess, Christopher/0000-0002-5132-5302; Weiss, David/0000-0002-7494-2987				Abadi M, ARXIV 160304467 PREP; Abraham N, 2019, I S BIOMED IMAGING, P683, DOI 10.1109/ISBI.2019.8759329; Ambrosini RD, 2010, J MAGN RESON IMAGING, V31, P85, DOI 10.1002/jmri.22009; Arvold ND, 2016, NEURO-ONCOLOGY, V18, P1043, DOI 10.1093/neuonc/now127; Bakas S, ARXIV181102629V2 PRE; Bousabarah K, 2020, RADIAT ONCOL, V15, DOI 10.1186/s13014-020-01514-6; Charron O, 2018, COMPUT BIOL MED, V95, P43, DOI 10.1016/j.compbiomed.2018.02.004; DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409; Duong MT, 2019, AM J NEURORADIOL, V40, P1282, DOI 10.3174/ajnr.A6138; Flanders AE, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190211; Grovik E, 2020, J MAGN RESON IMAGING, V51, P175, DOI 10.1002/jmri.26766; Kingma D. P., 2015, 3 INT C LEARN REPR I, P1; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826; Liu Y, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0185844; Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79; Mills SJ, 2019, BRIT J RADIOL, V92, DOI 10.1259/bjr.20190059; Ostrom Quinn T, 2018, Handb Clin Neurol, V149, P27, DOI 10.1016/B978-0-12-811161-1.00002-5; Perez-Ramirez U, 2016, J MAGN RESON IMAGING, V44, P642, DOI 10.1002/jmri.25207; Rudie JD, 2019, FRONT COMPUT NEUROSC, V13, DOI 10.3389/fncom.2019.00084; Rudie JD, 2019, RADIOLOGY, V290, P607, DOI 10.1148/radiol.2018181928; Simard PY, 2003, PROC INT CONF DOC, P958; Smith SM, 2002, HUM BRAIN MAPP, V17, P143, DOI 10.1002/hbm.10062; Xue J, 2020, NEURO-ONCOLOGY, V22, P505, DOI 10.1093/neuonc/noz234; Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015; Zhou ZJ, 2020, RADIOLOGY, V295, P407, DOI 10.1148/radiol.2020191479	26	8	9	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2021	3	3							e200204	10.1148/ryai.2021200204	http://dx.doi.org/10.1148/ryai.2021200204			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SA	34136817	Green Published			2022-12-18	WOS:000826907000008
J	Matthews, TP; Singh, S; Mombourquette, B; Su, J; Shah, MP; Pedemonte, S; Long, A; Maffit, D; Gurney, J; Hoil, RM; Ghare, N; Smith, D; Moore, SM; Marks, SC; Wahl, RL				Matthews, Thomas P.; Singh, Sadanand; Mombourquette, Brent; Su, Jason; Shah, Meet P.; Pedemonte, Stefano; Long, Aaron; Maffit, David; Gurney, Jenny; Hoil, Rodrigo Morales; Ghare, Nikita; Smith, Douglas; Moore, Stephen M.; Marks, Susan C.; Wahl, Richard L.			A Multisite Study of a Breast Density Deep Learning Model for Full-Field Digital Mammography and Synthetic Mammography	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							CANCER RISK; TOMOSYNTHESIS; RADIOLOGISTS; IMAGES	Purpose: To develop a Breast Imaging Reporting and Data System (BI-RADS) breast density deep learning (DL) model in a multisite setting for synthetic two-dimensional mammographic (SM) images derived from digital breast tomosynthesis examinations by using full-field digital mammographic (FFDM) images and limited SM data. Materials and Methods: A DL model was trained to predict BI-RADS breast density by using FFDM images acquired from 2008 to 2017 (site 1: 57 492 patients, 187 627 examinations, 750 752 images) for this retrospective study. The FFDM model was evaluated by using SM datasets from two institutions (site 1: 3842 patients, 3866 examinations, 14 472 images, acquired from 2016 to 2017; site 2: 7557 patients, 16283 examinations, 63 973 images, 2015 to 2019). Each of the three datasets were then split into training, validation, and test. Adaptation methods were investigated to improve performance on the SM datasets, and the effect of dataset size on each adaptation method was considered. Statistical significance was assessed by using CIs, which were estimated by bootstrapping. Results: Without adaptation, the model demonstrated substantial agreement with the original reporting radiologists for all three datasets (site 1 FFDM: linearly weighted Cohen k [k(w)] = 0.75 [95% CI: 0.74, 0.76]; site 1 SM: k(w) = 0.71 [95% CI: 0.64, 0.78]; site 2 SM: k(w) = 0.72 [95% CI: 0.70, 0.75]). With adaptation, performance improved for site 2 (site 1: k(w) = 0.72 [95% CI: 0.66, 0.79], 0.71 vs 0.72, P=.80; site 2: k(w) = 0.79 [95% CI: 0.76, 0.81], 0.72 vs 0.79, P<.001) by using only 500 SM images from that site. Conclusion: A BI-RADS breast density DL model demonstrated strong performance on FFDM and SM images from two institutions without training on SM images and improved by using few SM images. Published under a CC BY 4.0 license.	[Matthews, Thomas P.; Singh, Sadanand; Mombourquette, Brent; Su, Jason; Shah, Meet P.; Pedemonte, Stefano; Long, Aaron; Hoil, Rodrigo Morales; Ghare, Nikita; Smith, Douglas] Whiterabbit AI Inc, 3930 Freedom Circle,Suite 101, Santa Clara, CA 95054 USA; [Maffit, David; Gurney, Jenny; Moore, Stephen M.; Wahl, Richard L.] Washington Univ, Sch Med, Mallinekrodt Inst Radiol, St Louis, MO USA; [Marks, Susan C.] Peninsula Diagnost Imaging, San Mateo, CA USA	Washington University (WUSTL)	Matthews, TP (corresponding author), Whiterabbit AI Inc, 3930 Freedom Circle,Suite 101, Santa Clara, CA 95054 USA.	thomas@whiterabbit.ai		Morales Hoil, Rodrigo/0000-0002-0573-8587				Berg WA, 2000, AM J ROENTGENOL, V174, P1769, DOI 10.2214/ajr.174.6.1741769; Boyd NF, 2007, NEW ENGL J MED, V356, P227, DOI 10.1056/NEJMoa062790; Brandt KR, 2016, RADIOLOGY, V279, P710, DOI 10.1148/radiol.2015151261; Carpenter J, 2000, STAT MED, V19, P1141, DOI 10.1002/(SICI)1097-0258(20000515)19:9<1141::AID-SIM479>3.0.CO;2-F; FLEISS JL, 1969, PSYCHOL BULL, V72, P323, DOI 10.1037/h0028106; Fornvik D, 2019, EUR RADIOL, V29, P330, DOI 10.1007/s00330-018-5582-0; Friedewald SM, 2014, JAMA-J AM MED ASSOC, V311, P2499, DOI 10.1001/jama.2014.6095; Gandomkar Z, 2019, PROC SPIE, V10952, DOI 10.1117/12.2513185; Guo CA, 2017, PR MACH LEARN RES, V70; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Kerlikowske K, 2010, J CLIN ONCOL, V28, P3830, DOI 10.1200/JCO.2009.26.4770; Kressin NR, 2016, JAMA-J AM MED ASSOC, V315, P1786, DOI 10.1001/jama.2016.1712; Lehman CD, 2019, RADIOLOGY, V290, P52, DOI 10.1148/radiol.2018180694; Ma XY, 2019, PROC SPIE, V10950, DOI 10.1117/12.2511544; Mandelson MT, 2000, J NATL CANCER I, V92, P1081, DOI 10.1093/jnci/92.13.1081; McCormack VA, 2006, CANCER EPIDEM BIOMAR, V15, P1159, DOI 10.1158/1055-9965.EPI-06-0034; Mohamed AA, 2018, MED PHYS, V45, P314, DOI 10.1002/mp.12683; Pertuz S, 2016, RADIOLOGY, V279, P65, DOI 10.1148/radiol.2015150277; Rafferty EA, 2014, AM J ROENTGENOL, V202, P273, DOI 10.2214/AJR.13.11240; Richman IB, 2019, JAMA INTERN MED, V179, P1292, DOI 10.1001/jamainternmed.2019.1058; Sickles EA, 2013, ACR BI RADS ATLAS BR, V5th, P46; Skaane P, 2013, RADIOLOGY, V267, P47, DOI 10.1148/radiol.12121373; Spayne MC, 2012, BREAST J, V18, P326, DOI 10.1111/j.1524-4741.2012.01250.x; Sprague BL, 2016, ANN INTERN MED, V165, P457, DOI 10.7326/M15-2934; Tagliafico AS, 2013, BRIT J RADIOL, V86, DOI 10.1259/bjr.20130255; Wu N, ARXIV 171103674; Wu YX, 2020, INT J COMPUT VISION, V128, P742, DOI 10.1007/s11263-019-01198-w; Yi PH, 2018, SIIM C MACHINE INTEL; Yosinski J, 2014, ADV NEUR IN, V27; Youk JH, 2016, AM J ROENTGENOL, V206, P1056, DOI 10.2214/AJR.15.15472	31	8	8	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2021	3	1							e200015	10.1148/ryai.2020200015	http://dx.doi.org/10.1148/ryai.2020200015			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z3HE	33937850	Green Submitted, Green Published			2022-12-18	WOS:000826472300002
J	Mu, W; Liang, Y; Hall, LO; Tan, Y; Balagurunathan, Y; Wenham, R; Wu, N; Tian, J; Gillies, RJ				Mu, Wei; Liang, Ying; Hall, Lawrence O.; Tan, Yan; Balagurunathan, Yoganand; Wenham, Robert; Wu, Ning; Tian, Jie; Gillies, Robert J.			F-18-FDG PET/CT Habitat Radiomics Predicts Outcome of Patients with Cervical Cancer Treated with Chemoradiotherapy	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							TUMOR HETEROGENEITY; LOCAL RECURRENCE; FEATURES; SEGMENTATION; FUSION; IMAGES; TOOL	Purpose: To determine if quantitative features extracted from pretherapy fluorine 18 fluorodeoxyglucose (F-18-FDG) PET/CT estimate prognosis in patients with locally advanced cervical cancer treated with chemoradiotherapy. Materials and Methods: In this retrospective study, PET/CT images and outcomes were curated from 154 patients with locally advanced cervical cancer, who underwent chemoradiotherapy from two institutions between March 2008 and June 2016, separated into independent training (n=78; mean age, 51 years 6 13 [standard deviation]) and testing (n=76; mean age, 50 years 6 10) cohorts. Radiomic features were extracted from PET, CT, and habitat (subregions with different metabolic characteristics) images that were derived by fusing PET and CT images. Parsimonious sets of these features were identified by the least absolute shrinkage and selection operator analysis and used to generate predictive radiomics signatures for progression-free survival (PFS) and overall survival (OS) estimation. Prognostic validation of the radiomic signatures as independent prognostic markers was performed using multivariable Cox regression, which was expressed as nomograms, together with other clinical risk factors. Results: The radiomics nomograms constructed with T stage, lymph node status, and radiomics signatures resulted in significantly better performance for the estimation of PFS (Harrell concordance index [C-index], 0.85 for training and 0.82 for test) and OS (C-index, 0.86 for training and 0.82 for test) compared with International Federation of Gynecology and Obstetrics staging system (C-index for PFS, 0.70 for training [P=.001] and 0.70 for test [P=.002]; C-index for OS, 0.73 for training [P<.001] and 0.70 for test [P<.001]), respectively. Conclusion: Prognostic models were generated and validated from quantitative analysis of F-18-FDG PET/CT habitat images and clinical data, and may have the potential to identify the patients who need more aggressive treatment in clinical practice, pending further validation with larger prospective cohorts. (C) RSNA, 2020	[Mu, Wei; Tan, Yan; Balagurunathan, Yoganand; Gillies, Robert J.] H Lee Moffitt Canc Ctr & Res Inst, Dept Canc Physiol, 12902 Magnolia Dr, Tampa, FL 33612 USA; [Wenham, Robert] H Lee Moffitt Canc Ctr & Res Inst, Gynecol Oncol, 12902 Magnolia Dr, Tampa, FL 33612 USA; [Liang, Ying; Wu, Ning] Chinese Acad Med Sci, Canc Inst & Hosp, Beijing, Peoples R China; [Hall, Lawrence O.] Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA; [Tian, Jie] Beihang Univ, Sch Med, Beijing Adv Innovat Ctr Big Data Based Precis Med, Beijing, Peoples R China; [Tian, Jie] Chinese Acad Sci, Inst Automat, CAS Key Lab Mol Imaging, Beijing, Peoples R China	H Lee Moffitt Cancer Center & Research Institute; H Lee Moffitt Cancer Center & Research Institute; Chinese Academy of Medical Sciences - Peking Union Medical College; Cancer Institute & Hospital - CAMS; State University System of Florida; University of South Florida; Beihang University; Chinese Academy of Sciences; Institute of Automation, CAS	Gillies, RJ (corresponding author), H Lee Moffitt Canc Ctr & Res Inst, Dept Canc Physiol, 12902 Magnolia Dr, Tampa, FL 33612 USA.	Robert.Gillies@moffitt.org	Mu, Wei/U-9256-2019	Mu, Wei/0000-0001-7970-8666	U.S. Public Health Service [U01 CA143062, R01 CA190105]	U.S. Public Health Service(United States Department of Health & Human ServicesUnited States Public Health Service)	Supported by U.S. Public Health Service research grants U01 CA143062 and R01 CA190105 (principal investigator R.J.G.).	Aerts HJWL, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5006; Bar-Shalom R, 2003, J NUCL MED, V44, P1200; Bhatla N, 2019, INT J GYNECOL OBSTET, V145, P129, DOI 10.1002/ijgo.12749; Camp RL, 2004, CLIN CANCER RES, V10, P7252, DOI 10.1158/1078-0432.CCR-04-0713; Chang YCCN, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-09932-5; Chicklore S, 2013, EUR J NUCL MED MOL I, V40, P133, DOI 10.1007/s00259-012-2247-0; Crivellaro C, 2012, GYNECOL ONCOL, V127, P131, DOI 10.1016/j.ygyno.2012.06.041; Farhidzadeh H, 2015, PROC SPIE, V9414, DOI 10.1117/12.2082324; Friedman J, PACKAGE GLMNET LASSO; Fukunaga H, 2005, ANN SURG ONCOL, V12, P561, DOI 10.1245/ASO.2005.08.001; Gatenby RA, 2013, RADIOLOGY, V269, P8, DOI 10.1148/radiol.13122697; Grossmann P, 2017, ELIFE, V6, DOI 10.7554/eLife.23421; Grove O, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0118261; Hollebecque A, 2017, J CLIN ONCOL, V35, DOI 10.1200/JCO.2017.35.15_suppl.5504; Huang YQ, 2016, J CLIN ONCOL, V34, P2157, DOI 10.1200/JCO.2015.65.9128; Koh WJ, 2019, J NATL COMPR CANC NE, V17, P64, DOI 10.6004/jnccn.2019.0001; Lai C, 2006, J CLIN ONCOL, V24, p268S; Lucia F, 2017, RADIOTHER ONCOL, V123, pS378, DOI 10.1016/S0167-8140(17)31158-1; Lucia F, 2018, EUR J NUCL MED MOL I, V45, P768, DOI 10.1007/s00259-017-3898-7; Matsuo K, 2019, GYNECOL ONCOL, V152, P87, DOI 10.1016/j.ygyno.2018.10.026; McGuire S, 2016, ADV NUTR, V7, P418, DOI 10.3945/an.116.012211; Mirpour S, 2013, AM J ROENTGENOL, V201, pW192, DOI 10.2214/AJR.12.9830; Mu W, 2015, IEEE T BIO-MED ENG, V62, P2465, DOI 10.1109/TBME.2015.2433397; Mu W, 2015, PHYS MED BIOL, V60, P5123, DOI 10.1088/0031-9155/60/13/5123; Nakamoto Y, 2008, MOL IMAGING BIOL, V10, P147, DOI 10.1007/s11307-008-0131-x; Napel S, 2018, CANCER-AM CANCER SOC, V124, P4633, DOI 10.1002/cncr.31630; Onal C, 2013, INT J GYNECOL CANCER, V23, P1104, DOI 10.1097/IGC.0b013e3182989483; OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076; Reuze S, 2017, ONCOTARGET, V8, P43169, DOI 10.18632/oncotarget.17856; Schaarschmidt BM, 2016, EUR J NUCL MED MOL I, V43, P92, DOI 10.1007/s00259-015-3145-z; Siegel RL, 2016, CA-CANCER J CLIN, V66, P7, DOI [10.3322/caac.21332, 10.3322/caac.21590, 10.3322/caac.21708]; Tefera B, 2016, GLOB J MED RES, V16, P24; Wright JD, 2019, OBSTET GYNECOL, V134, P49, DOI 10.1097/AOG.0000000000003311; Yushkevich PA, 2017, IEEE PULSE, V8, P54, DOI 10.1109/MPUL.2017.2701493; Zwanenburg A, 2020, RADIOLOGY, V295, P328, DOI 10.1148/radiol.2020191145	35	8	8	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2020	2	6							e190218	10.1148/ryai.2020190218	http://dx.doi.org/10.1148/ryai.2020190218			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CZ	33937845	Green Published			2022-12-18	WOS:000826480100004
J	Marinelli, B; Kang, M; Martini, M; Zech, JR; Titano, J; Cho, S; Costa, AB; Oermann, EK				Marinelli, Brett; Kang, Martin; Martini, Michael; Zech, John R.; Titano, Joseph; Cho, Samuel; Costa, Anthony B.; Oermann, Eric K.			Combination of Active Transfer Learning and Natural Language Processing to Improve Liver Volumetry Using Surrogate Metrics with Deep Learning	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							SEGMENTATION; CT	Purpose: To determine if weakly supervised learning with surrogate metrics and active transfer learning can hasten clinical deployment of deep learning models. Materials and Methods: By leveraging Liver Tumor Segmentation (LiTS) challenge 2017 public data (n = 131 studies), natural language processing of reports, and an active learning method, a model was trained to segment livers on 239 retrospectively collected portal venous phase abdominal CT studies obtained between January 1, 2014, and December 31, 2016. Absolute volume differences between predicted and originally reported liver volumes were used to guide active learning and assess accuracy. Overall survival based on liver volumes predicted by this model (n = 34 patients) versus radiology reports and Model for End-Stage Liver Disease with sodium (MELD-Na) scores was assessed. Differences in absolute liver volume were compared by using the paired Student t test, Bland-Altman analysis, and intraclass correlation; survival analysis was performed with the Kaplan-Meier method and a Mantel-Cox test. Results: Data from patients with poor liver volume prediction (n = 10) with a model trained only with publicly available data were incorporated into an active learning method that trained a new model (LiTS data plus over- and underestimated active learning cases [LiTS-OU]) that performed significantly better on a held-out institutional test set (absolute volume difference of 231 vs 176 mL, P =.0005). In overall survival analysis, predicted liver volumes using the best active learning-trained model (LiTS-OU) were at least comparable with liver volumes extracted from radiology reports and MELD-Na scores in predicting survival. Conclusion: Active transfer learning using surrogate metrics facilitated deployment of deep learning models for clinically meaningful liver segmentation at a major liver transplant center. (C) RSNA, 2019	[Marinelli, Brett; Kang, Martin; Martini, Michael; Titano, Joseph] Mt Sinai Hlth Syst, Dept Radiol, 1468 Madison Ave,Annenberg Bldg,8th Floor, New York, NY 10029 USA; [Cho, Samuel] Mt Sinai Hlth Syst, Dept Orthoped Surg, 1468 Madison Ave,Annenberg Bldg,8th Floor, New York, NY 10029 USA; [Costa, Anthony B.; Oermann, Eric K.] Mt Sinai Hlth Syst, Dept Neurol Surg, 1468 Madison Ave,Annenberg Bldg,8th Floor, New York, NY 10029 USA; [Zech, John R.] Calif Pacific Med Ctr, Dept Med, San Francisco, CA USA	Icahn School of Medicine at Mount Sinai; Icahn School of Medicine at Mount Sinai; Icahn School of Medicine at Mount Sinai; California Pacific Medical Center	Oermann, EK (corresponding author), Mt Sinai Hlth Syst, Dept Neurol Surg, 1468 Madison Ave,Annenberg Bldg,8th Floor, New York, NY 10029 USA.	eric.oermann@mountsinai.org	Costa, Anthony/C-5471-2009	Costa, Anthony/0000-0002-2202-6450; Martini, Michael/0000-0001-8169-7679				Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585; Christ P, LIVER TUMOR SEGMENTA; Cicek O, ARXIV ARXIV160606650; Collins B, 2008, COMPUTER VISION ECCV, V5302; Dou Q, ARXIV160700582; Ertreo M, 2018, CARDIOVASC INTER RAD, V41, P1857, DOI 10.1007/s00270-018-2030-0; Fedorov A, 2012, MAGN RESON IMAGING, V30, P1323, DOI 10.1016/j.mri.2012.05.001; Ghafoorian M, ARXIV170207841; Ghafoorian M, ARXIV180105040; Gotra A, 2017, INSIGHTS IMAGING, V8, P377, DOI 10.1007/s13244-017-0558-1; Gotra A, 2015, ACAD RADIOL, V22, P1088, DOI 10.1016/j.acra.2015.03.010; Hagan MT, 2014, DIGEST DIS SCI, V59, P886, DOI 10.1007/s10620-014-3038-1; Heimann T, 2009, IEEE T MED IMAGING, V28, P1251, DOI 10.1109/TMI.2009.2013851; Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004; Kapoor A, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P877; Lee CS, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0190261; Nakayama Y, 2006, RADIOLOGY, V240, P743, DOI 10.1148/radiol.2403050850; Settles B., 2012, SYNTH LECT ARTIF INT, V6, P1; Tong Cong, 2012, Front Med, V6, P421, DOI 10.1007/s11684-012-0223-5; URATA K, 1995, HEPATOLOGY, V21, P1317, DOI 10.1002/hep.1840210515; van Opbroek A, 2013, LECT NOTES COMPUT SC, V8184, P49, DOI 10.1007/978-3-319-02267-3_7; Vezhnevets V., 2005, P 15 INT C COMP GRAP, P150, DOI DOI 10.1016/J.AJ0D0.2004.07.036; Zech JR, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002683; Zhang C., ARXIV161103530	24	8	8	0	2	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2019	1	1							e180019	10.1148/ryai.2019180019	http://dx.doi.org/10.1148/ryai.2019180019			8	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CL	33937782	Green Published			2022-12-18	WOS:000826287700003
J	Xue, H; Artico, J; Fontana, M; Moon, JC; Davies, RH; Kellman, P				Xue, Hui; Artico, Jessica; Fontana, Marianna; Moon, James C.; Davies, Rhodri H.; Kellman, Peter			Landmark Detection in Cardiac MRI by Using a Convolutional Neural Network	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Cardiac; Heart; Convolutional Neural Network (CNN); Deep Learning Algorithms; Machine Learning Algorithms; Feature Detection; Quantification; Supervised Learning; MR Imaging	SENSITIVE INVERSION-RECOVERY; MOTION CORRECTION; ENHANCEMENT	Purpose: To develop a convolutional neural network (CNN) solution for landmark detection in cardiac MRI (CMR). Materials and Methods: This retrospective study included cine, late gadolinium enhancement (LGE), and T1 mapping examinations from two hospitals. The training set included 2329 patients (34 089 images; mean age, 54.1 years; 1471 men; December 2017 to March 2020). A hold-out test set included 531 patients (7723 images; mean age, 51.5 years; 323 men; May 2020 to July 2020). CNN models were developed to detect two mitral valve plane and apical points on long-axis images. On short-axis images, anterior and posterior right ventricular (RV) insertion points and left ventricular (LV) center points were detected. Model outputs were compared with manual labels assigned by two readers. The trained model was deployed to MRI scanners. Results: For the long-axis images, successful detection of cardiac landmarks ranged from 99.7% to 100% for cine images and from 99.2% to 99.5% for LGE images. For the short-axis images, detection rates were 96.6% for cine, 97.6% for LGE, and 98.7% for T1 mapping. The Euclidean distances between model-assigned and manually assigned labels ranged from 2 to 3.5 mm for different landmarks, indicating close agreement between model-derived landmarks and manually assigned labels. For all views and imaging sequences, no differences between the models' assessment of images and the readers' assessment of images were found for the anterior RV insertion angle or LV length. Model inference for a typical cardiac cine series took 610 msec with the graphics processing unit and 5.6 seconds with central processing unit. Conclusion: A CNN was developed for landmark detection on both long- and short-axis CMR images acquired with cine, LGE, and T1 mapping sequences, and the accuracy of the CNN was comparable with the interreader variation. Supplemental material is available for this article.	[Xue, Hui; Kellman, Peter] NHLBI, NIH, 10 Ctr Dr, Bethesda, MD 20892 USA; [Artico, Jessica; Moon, James C.; Davies, Rhodri H.] Barts Heart Ctr, Natl Hlth Serv, London, England; [Fontana, Marianna] Royal Free Hosp, Natl Amyloidosis Ctr, London, England	National Institutes of Health (NIH) - USA; NIH National Heart Lung & Blood Institute (NHLBI); NHS Blood & Transplant (NHSBT); University of London; University College London; Royal Free London NHS Foundation Trust; UCL Medical School	Xue, H (corresponding author), NHLBI, NIH, 10 Ctr Dr, Bethesda, MD 20892 USA.	hui.xue@nih.gov	Moon, James/AAA-9905-2020	Moon, James/0000-0001-8071-1491; Xue, Hui/0000-0002-4561-5530; Davies, Rhodri/0000-0001-7630-7517	Division of Intramural Research of the National Heart, Lung, and Blood Institute, National Institutes of Health [Z1A-HL006214-05, Z1A-HL006242-02]	Division of Intramural Research of the National Heart, Lung, and Blood Institute, National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Heart Lung & Blood Institute (NHLBI))	Supported in part by the Division of Intramural Research of the National Heart, Lung, and Blood Institute, National Institutes of Health (grants Z1A-HL006214-05 and Z1A-HL006242-02).	Agarwal N, ARXIV 171000977V1; Asgeirsson D, 2017, BMC CARDIOVASC DISOR, V17, DOI 10.1186/s12872-017-0641-z; Bai WJ, 2018, J CARDIOVASC MAGN R, V20, DOI 10.1186/s12968-018-0471-x; Belagiannis V, 2017, IEEE INT CONF AUTOMA, P468, DOI 10.1109/FG.2017.64; Bernard O, 2018, IEEE T MED IMAGING, V37, P2514, DOI 10.1109/TMI.2018.2837502; Bhuva AN, 2019, CIRC-CARDIOVASC IMAG, V12, DOI 10.1161/CIRCIMAGING.119.009214; Blansit K, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180069; Breuer FA, 2005, MAGN RESON MED, V53, P981, DOI 10.1002/mrm.20430; Colaco Savina, 2020, 2020 International Conference on Artificial Intelligence in Information and Communication (ICAIIC), P671, DOI 10.1109/ICAIIC48513.2020.9065279; Fahmy AS, 2020, RADIOLOGY, V294, P52, DOI 10.1148/radiol.2019190737; Giri S, 2009, J CARDIOVASC MAGN R, V11, DOI 10.1186/1532-429X-11-56; Jadon S., ARXIV 200614822; Kellman P, 2005, MAGN RESON MED, V53, P194, DOI 10.1002/mrm.20333; Kellman P, 2002, MAGNET RESON MED, V47, P372, DOI 10.1002/mrm.10051; Kellman P, 2017, J CARDIOVASC MAGN R, V19, DOI 10.1186/s12968-017-0355-5; Kellman P, 2014, J CARDIOVASC MAGN R, V16, DOI 10.1186/1532-429X-16-2; Kellman P, 2010, CURR CARDIOVASC IMAG, V3, P83, DOI 10.1007/s12410-010-9012-1; Lang RM, 2015, EUR HEART J-CARD IMG, V16, P233, DOI 10.1093/ehjci/jev014; Messroghli DR, 2007, MAGN RESON MED, V58, P34, DOI 10.1002/mrm.21272; Nickander J, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-67196-y; Noothout JMH, ARXIV 180404963; Pfister T, 2015, IEEE I CONF COMP VIS, P1913, DOI 10.1109/ICCV.2015.222; Piehler KM, 2013, CIRC-CARDIOVASC IMAG, V6, P423, DOI 10.1161/CIRCIMAGING.112.000022; Schulz-Menger J, 2020, J CARDIOVASC MAGN R, V22, DOI 10.1186/s12968-020-00610-6; Shvets AA, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P624, DOI 10.1109/ICMLA.2018.00100; Steiner B, 2019, P ADV NEURAL INFORM; Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28; Tao Q, 2019, RADIOLOGY, V290, P81, DOI 10.1148/radiol.2018180513; Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664; van Zon M, 2019, PROC SPIE, V10949, DOI 10.1117/12.2512048; Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6; Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566; Xue H., 2019, P 27 ANN ISMRM M EXH, V27, P4837; Xue H, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020200009; Xue H, 2020, MAGN RESON MED, V83, P712, DOI 10.1002/mrm.27954; Xue H, 2020, MAGN RESON MED, V84, P2788, DOI 10.1002/mrm.28291; Xue H, 2013, MAGN RESON MED, V69, P1408, DOI 10.1002/mrm.24385; Xue H, 2012, MAGN RESON MED, V67, P1644, DOI 10.1002/mrm.23153; Xue H, 2009, LECT NOTES COMPUT SC, V5762, P741, DOI 10.1007/978-3-642-04271-3_90; Yan WJ, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190195; Zhang ZP, 2019, IEEE ACM T COMPUT BI, V16, P407, DOI 10.1109/TCBB.2017.2704587	41	7	7	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2021	3	5							e200197	10.1148/ryai.2021200197	http://dx.doi.org/10.1148/ryai.2021200197			11	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9TT	34617022	Green Published, Green Submitted			2022-12-18	WOS:000826911500003
J	Gauriau, R; Bizzo, BC; Kitamura, FC; Junior, OL; Ferraciolli, SF; Macruz, FBC; Sanchez, TA; Garcia, MRT; Vedolin, LM; Domingues, RC; Gasparetto, EL; Andriole, KP				Gauriau, Romane; Bizzo, Bernardo C.; Kitamura, Felipe C.; Junior, Osvaldo Landi; Ferraciolli, Suely F.; Macruz, Fabiola B. C.; Sanchez, Tiago A.; Garcia, Marcio R. T.; Vedolin, Leonardo M.; Domingues, Romeu C.; Gasparetto, Emerson L.; Andriole, Katherine P.			A Deep Learning-based Model for Detecting Abnormalities on Brain MR Images for Triaging: Preliminary Results from a Multisite Experience	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						MR-Imaging; Head/Neck; Computer Applications-General (Informatics); Convolutional Neural Network (CNN); Deep Learning Algorithms; Machine Learning Algorithms		Purpose: To develop a deep learning model for detecting brain abnormalities on MR images. Materials and Methods: In this retrospective study, a deep learning approach using T2-weighted fluid-attenuated inversion recovery images was developed to classify brain MRI findings as "likely normal" or "likely abnormal." A convolutional neural network model was trained on a large, heterogeneous dataset collected from two different continents and covering a broad panel of pathologic conditions, including neoplasms, hemorrhages, infarcts, and others. Three datasets were used. Dataset A consisted of 2839 patients, dataset B consisted of 6442 patients, and dataset C consisted of 1489 patients and was only used for testing. Datasets A and B were split into training, validation, and test sets. A total of three models were trained: model A (using only dataset A), model B (using only dataset B), and model A + B (using training datasets from A and B). All three models were tested on subsets from dataset A, dataset B, and dataset C separately. The evaluation was performed by using annotations based on the images, as well as labels based on the radiology reports. Results: Model A trained on dataset A from one institution and tested on dataset C from another institution reached an F1 score of 0.72 (95% CI: 0.70, 0.74) and an area under the receiver operating characteristic curve of 0.78 (95% CI: 0.75, 0.80) when compared with findings from the radiology reports. Conclusion: The model shows relatively good performance for differentiating between likely normal and likely abnormal brain examination findings by using data from different institutions.	[Gauriau, Romane; Bizzo, Bernardo C.; Macruz, Fabiola B. C.; Andriole, Katherine P.] MGH & BWH Ctr Clin Data Sci, Ste 1303,Floor 13,100 Cambridge St, Boston, MA 02114 USA; [Bizzo, Bernardo C.; Kitamura, Felipe C.; Junior, Osvaldo Landi; Ferraciolli, Suely F.; Garcia, Marcio R. T.; Vedolin, Leonardo M.; Domingues, Romeu C.; Gasparetto, Emerson L.] Diagnost Amer, Dept Artificial Intelligence, Sao Paulo, Brazil; [Kitamura, Felipe C.] Diagnost Amer SA, AI, Sao Paulo, Brazil; [Bizzo, Bernardo C.; Sanchez, Tiago A.; Gasparetto, Emerson L.] Univ Fed Rio de Janeiro, Dept Radiol, Rio De Janeiro, Brazil; [Bizzo, Bernardo C.] Massachusetts Gen Hosp, Dept Radiol, Boston, MA USA; [Andriole, Katherine P.] Harvard Univ, Brigham & Womens Hosp, Dept Radiol, Boston, MA 02115 USA; [Andriole, Katherine P.] Harvard Univ, Harvard Med Sch, Boston, MA 02115 USA	Universidade Federal do Rio de Janeiro; Harvard University; Massachusetts General Hospital; Harvard University; Brigham & Women's Hospital; Harvard University; Harvard Medical School	Gauriau, R (corresponding author), MGH & BWH Ctr Clin Data Sci, Ste 1303,Floor 13,100 Cambridge St, Boston, MA 02114 USA.	romanegauriau@gmail.com	Sanchez, Tiago Arruda/ABI-1783-2020; Kitamura, Felipe Campos/AAC-7075-2021	Sanchez, Tiago Arruda/0000-0002-2853-1490; Kitamura, Felipe Campos/0000-0002-9992-5630; Garcia, Marcio/0000-0002-9097-6546; Macruz, Fabiola/0000-0001-6009-7631	Diagnosticos da America (Sao Paulo, Brazil)	Diagnosticos da America (Sao Paulo, Brazil)	Supported in part by Diagnosticos da America (Sao Paulo, Brazil).	Abadi M, ARXIV 160304467 PREP; Andriole KP, 2004, J DIGIT IMAGING, V17, P235, DOI 10.1007/s10278-004-1027-1; Baltruschat I, 2021, EUR RADIOL, V31, P3837, DOI 10.1007/s00330-020-07480-7; Fortin JP, 2017, NEUROIMAGE, V161, P149, DOI 10.1016/j.neuroimage.2017.08.047; Gal Y, 2018, SOC IMAGING IN FORMA; Gauriau R, 2020, J DIGIT IMAGING, V33, P747, DOI 10.1007/s10278-019-00308-x; Glocker B, ARXIV191004597; Halsted MJ, 2013, U.S. patent application, Patent No. [8,484,048(B2), 84840482]; Hosseini-Asl E, 2016, IEEE IMAGE PROC, P126, DOI 10.1109/ICIP.2016.7532332; HYDE RJ, 1994, MAGN RESON IMAGING, V12, P1089, DOI 10.1016/0730-725X(94)91241-N; Isin A, 2016, PROCEDIA COMPUT SCI, V102, P317, DOI 10.1016/j.procs.2016.09.407; Johnson K.A., WHOLE BRAIN ATLAS; Kingma D.P, P 3 INT C LEARNING R; Lu D, ARXIV 171004782 PREP; Lu SY, 2019, J COMPUT SCI-NETH, V30, P41, DOI 10.1016/j.jocs.2018.11.008; Morgan MB, 2006, J DIGIT IMAGING, V19, P69, DOI 10.1007/s10278-005-8732-2; Payan A, ARXIV 150202506; Rinck P.A., 2018, BASIC TXB OFTHE EURO; Smith SM, 2018, NEURON, V97, P263, DOI 10.1016/j.neuron.2017.12.018; Wachinger C, ARXIV 190704102; Wachinger C, 2016, NEUROIMAGE, V139, P470, DOI 10.1016/j.neuroimage.2016.05.053; Wang SH, 2015, ENTROPY-SWITZ, V17, P8278, DOI 10.3390/e17127877; Yang GL, 2016, MULTIMED TOOLS APPL, V75, P15601, DOI [10.1007/s11042-015-2649-7, 10.1155/2015/932029]; Yang M, 2017, P 2017 5 INT C MACHI	24	7	7	0	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2021	3	4							e200184	10.1148/ryai.2021200184	http://dx.doi.org/10.1148/ryai.2021200184			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SU	34350408	Green Published			2022-12-18	WOS:000826909000006
J	Chen, MM; Golding, LP; Nicola, GN				Chen, Melissa M.; Golding, Lauren Parks; Nicola, Gregory N.			Who Will Pay for AI?	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Computer Applications-General (Informatics); Technology Assessment	MEDICARE; QUALITY	In 2020, the largest U.S. health care payer, the Centers for Medicare & Medicaid Services (CMS), established payment for artificial intelligence (AI) through two different systems in the Medicare Physician Fee Schedule (MPFS) and the Inpatient Prospective Payment System (IPPS). Within the MPFS, a new Current Procedural Terminology code was valued for an AI tool for diagnosis of diabetic retinopathy, IDx-RX. In the IPPS, Medicare established a New Technology Add-on Payment for Viz.ai software, an AI algorithm that facilitates diagnosis and treatment of large-vessel occlusion strokes. This article describes reimbursement in these two payment systems and proposes future payment pathways for AI. (C)RSNA, 2021	[Chen, Melissa M.] Univ Texas MD Anderson Canc Ctr, Dept Radiol, 1400 Pressler St,Unit 1482, Houston, TX 70030 USA; [Golding, Lauren Parks] Triad Radiol, Winston Salem, NC USA; [Nicola, Gregory N.] Hackensack Radiol, Hackensack, NJ USA	University of Texas System; UTMD Anderson Cancer Center	Chen, MM (corresponding author), Univ Texas MD Anderson Canc Ctr, Dept Radiol, 1400 Pressler St,Unit 1482, Houston, TX 70030 USA.	Melissa.mei.chen@gmail.com		Chen, Melissa/0000-0002-3274-2653				[Anonymous], 2020, INTERVENTIONAL NEWS; Benjamens S, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00324-0; Centers for Medicare & Medicaid, 2020, PROP MED COV INN TEC; Centers for Medicare & Medicaid Services, 2012, ALL PRACT EXP MED FE, P1; Centers for Medicare & Medicaid Services, 2019, FISC YEAR FY 2020 ME; Chen Evan M, 2021, Ophthalmology, V128, P475, DOI 10.1016/j.ophtha.2020.07.043; Chen MM, 2017, AM J NEURORADIOL, V38, P1292, DOI 10.3174/ajnr.A5220; Clyde AT, 2008, HEALTH AFFAIR, V27, P1632, DOI 10.1377/hlthaff.27.6.1632; Department of Health and Human Services, 2020, MED COV INN TECHN MC; Department of Health and Human Services, 2020, PROP RUL CY 2021 PAY; Department of Health and Human Services, 2020, CY 2021 PAYM POL PHY; Department of Health and Human Services, 2018, CHANG HOSP OUTP PROS; Donovan WD, 2011, AM J NEURORADIOL, V32, P1583, DOI 10.3174/ajnr.A2767; Golding LP, 2019, J AM COLL RADIOL, V16, P1357, DOI 10.1016/j.jacr.2019.05.004; Hirsch JA, 2016, AM J NEURORADIOL, V37, P210, DOI 10.3174/ajnr.A4522; Hirsch JA, 2017, J NEUROINTERV SURG, V9, P713, DOI 10.1136/neurintsurg-2016-012845; Kassing P, 2020, J AM COLL RADIOL, V17, P534, DOI 10.1016/j.jacr.2019.11.015; Leslie-Mazwi TM, 2016, AM J NEURORADIOL, V37, P1972, DOI 10.3174/ajnr.A4863; Nicola GN, ACR B; Rosenkrantz AB, 2017, J AM COLL RADIOL, V14, P1298, DOI 10.1016/j.jacr.2017.02.042; Rosenkrantz AB, 2017, J AM COLL RADIOL, V14, P316, DOI 10.1016/j.jacr.2016.10.012; Schoppe K, 2018, J AM COLL RADIOL, V15, P1240, DOI 10.1016/j.jacr.2018.05.036; Silva E, 2013, J AM COLL RADIOL, V10, P820, DOI 10.1016/j.jacr.2013.08.001; Simonite T., WIRED; Taylor CA, 2013, J AM COLL CARDIOL, V61, P2233, DOI 10.1016/j.jacc.2012.11.083	25	7	7	3	3	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2021	3	3							e210030	10.1148/ryai.2021210030	http://dx.doi.org/10.1148/ryai.2021210030			5	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SA		Green Published			2022-12-18	WOS:000826907000011
J	Horng, S; Liao, RZ; Wan, X; Dalal, S; Golland, P; Berkowitz, SJ				Horng, Steven; Liao, Ruizhi; Wan, Xin; Dalal, Sandeep; Golland, Polina; Berkowitz, Seth J.			Deep Learning to Quantify Pulmonary Edema in Chest Radiographs	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							HEART-FAILURE; ASSOCIATION; CONGESTION; CARDIOLOGY; SOCIETY; WATER	Purpose: To develop a machine learning model to classify the severity grades of pulmonary edema on chest radiographs. Materials and Methods: In this retrospective study, 369 071 chest radiographs and associated radiology reports from 64 581 patients (mean age, 51.71 years; 54.51% women) from the MIMIC-CXR chest radiograph dataset were included. This dataset was split into patients with and without congestive heart failure (CHF). Pulmonary edema severity labels from the associated radiology reports were extracted from patients with CHF as four different ordinal levels: 0, no edema; 1, vascular congestion; 2, interstitial edema; and 3, alveolar edema. Deep learning models were developed using two approaches: a semisupervised model using a variational autoencoder and a pretrained supervised learning model using a dense neural network. Receiver operating characteristic curve analysis was performed on both models. Results: The area under the receiver operating characteristic curve (AUC) for differentiating alveolar edema from no edema was 0.99 for the semisupervised model and 0.87 for the pretrained models. Performance of the algorithm was inversely related to the difficulty in categorizing milder states of pulmonary edema (shown as AUCs for semisupervised model and pretrained model, respectively): 2 versus 0, 0.88 and 0.81; 1 versus 0, 0.79 and 0.66; 3 versus 1, 0.93 and 0.82; 2 versus 1, 0.69 and 0.73; and 3 versus 2, 0.88 and 0.63. Conclusion: Deep learning models were trained on a large chest radiograph dataset and could grade the severity of pulmonary edema on chest radiographs with high performance. Supplemental material is available for this article. (C) RSNA, 2021.	[Horng, Steven; Berkowitz, Seth J.] Harvard Med Sch, Beth Israel Deaconess Med Ctr, Dept Radiol, 330 Brookline Ave, Boston, MA 02215 USA; [Liao, Ruizhi; Golland, Polina] MIT, Dept Elect Engn & Comp Sci, Cambridge, MA 02139 USA; [Wan, Xin; Dalal, Sandeep] Philips Res, Clin Informat Solut & Serv, Cambridge, MA USA	Harvard University; Beth Israel Deaconess Medical Center; Harvard Medical School; Massachusetts Institute of Technology (MIT); Philips; Philips Research	Horng, S (corresponding author), Harvard Med Sch, Beth Israel Deaconess Med Ctr, Dept Radiol, 330 Brookline Ave, Boston, MA 02215 USA.	shorng@bidmc.harvard.edu		Horng, Steven/0000-0002-0958-1820; /0000-0001-6761-921X				Adams KF, 2005, AM HEART J, V149, P209, DOI 10.1016/j.ahj.2004.08.005; Borji A, 2018, ARXIV PREPRINT, Patent No. 0109068; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Dunnmon JA, 2019, RADIOLOGY, V290, P537, DOI 10.1148/radiol.2018181422; Gheorghiade M, 2010, EUR J HEART FAIL, V12, P423, DOI 10.1093/eurjhf/hfq045; Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215; Hammon M, 2014, BMC ANESTHESIOL, V14, DOI 10.1186/1471-2253-14-94; HARRISON MO, 1971, BRIT J RADIOL, V44, P265, DOI 10.1259/0007-1285-44-520-265; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Hunt SA, 2009, J AM COLL CARDIOL, V53, pE1, DOI 10.1016/j.jacc.2008.11.013; Johnson A., 2019, PHYSIONET, DOI 10.13026/C2JT1Q; Johnson AEW, 2019, CORR; Johnson AEW, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0322-0; Liao R, ARXIV ARXIV190210785; LOGUE RB, 1963, AM HEART J, V65, P464, DOI 10.1016/0002-8703(63)90096-6; MAHDYOON H, 1989, AM J CARDIOL, V63, P625, DOI 10.1016/0002-9149(89)90912-0; Majkowska A, 2020, RADIOLOGY, V294, P421, DOI 10.1148/radiol.2019191293; MILNE ENC, 1973, RADIOL CLIN N AM, V11, P17; NOBLE WH, 1975, CAN ANAESTH SOC J, V22, P171, DOI 10.1007/BF03004973; Seah JCY, 2019, RADIOLOGY, V290, P514, DOI 10.1148/radiol.2018180887; Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74; SNASHALL PD, 1981, BRIT J RADIOL, V54, P277, DOI 10.1259/0007-1285-54-640-277; VANDEWATER JM, 1970, J TRAUM, V10, P440, DOI 10.1097/00005373-197006000-00002; Wang X, PULMONARY EDEMA SEVE; Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369; Zhao CY, 2018, CIRCULATION, V138	26	7	7	2	5	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2021	3	2							e190228	10.1148/ryai.2021190228	http://dx.doi.org/10.1148/ryai.2021190228			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z3LD	33937857	Green Submitted, Green Published			2022-12-18	WOS:000826483100006
J	Lakhani, P; Flanders, A; Gorniak, R				Lakhani, Paras; Flanders, Adam; Gorniak, Richard			Endotracheal Tube Position Assessment on Chest Radiographs Using Deep Learning	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							CLASSIFICATION; CANCER; DEPTH	Purpose: To determine the efficacy of deep learning in assessing endotracheal tube (ETT) position on radiographs. Materials and Methods: In this retrospective study, 22 960 de-identified frontal chest radiographs from 11 153 patients (average age, 60.2 years +/- 19.9 [standard deviation], 55.6% men) between 2010 and 2018 containing an ETT were placed into 12 categories, including bronchial insertion and distance from the carina at 1.0-cm intervals (0.0-0.9 cm, 1.0-1.9 cm, etc), and greater than 10 cm. Images were split into training (80%, 18 368 images), validation (10%, 2296 images), and internal test (10%, 2296 images), derived from the same institution as the training data. One hundred external test radiographs were also obtained from a different hospital. The Inception V3 deep neural network was used to predict ETT-carina distance. ETT-carina distances and intraclass correlation coefficients (ICCs) for the radiologists and artificial intelligence (AI) system were calculated on a subset of 100 random internal and 100 external test images. Sensitivity and specificity were calculated for low and high ETT position thresholds. Results: On the internal and external test images, respectively, the ICCs of AI and radiologists were 0.84 (95% CI: 0.78, 0.92) and 0.89 (95% CI: 0.77, 0.94); the ICCs of the radiologists were 0.93 (95% CI: 0.90, 0.95) and 0.84 (95% CI: 0.71, 0.90). The AI model was 93.9% sensitive (95% CI: 90.0, 96.7) and 97.7% specific (95% CI: 96.9, 98.3) for detecting ETT-carina distance less than 1 cm. Conclusion: Deep learning predicted ETT-carina distance within 1 cm in most cases and showed excellent interrater agreement compared with radiologists. The model was sensitive and specific in detecting low ETT positions. (C) RSNA, 2020	[Lakhani, Paras; Flanders, Adam; Gorniak, Richard] Thomas Jefferson Univ Hosp, Sidney Kimmel Jefferson Med Coll, Dept Radiol, 132 S 10th St, Philadelphia, PA 19107 USA	Jefferson University	Lakhani, P (corresponding author), Thomas Jefferson Univ Hosp, Sidney Kimmel Jefferson Med Coll, Dept Radiol, 132 S 10th St, Philadelphia, PA 19107 USA.	paras.lakhani@jefferson.edu		Gorniak, Richard/0000-0003-2289-9064; Flanders, Adam/0000-0002-4679-0787				Allan E, 2019, EUROPEAN C RADIOLOGY, DOI [10.26044/ecr2019/C-3024, DOI 10.26044/ECR2019/C-3024]; Ardila D, 2019, NAT MED, V25, P954, DOI 10.1038/s41591-019-0447-x; BLAND JM, 1986, LANCET, V1, P307, DOI 10.1016/s0140-6736(86)90837-8; BRUNEL W, 1989, CHEST, V96, P1043, DOI 10.1378/chest.96.5.1043; Chen S, 2016, INT J COMPUT ASS RAD, V11, P2049, DOI 10.1007/s11548-016-1430-3; Cicchetti D.V., 1994, PSYCHOL ASSESSMENTS, V6, P284, DOI [10.1037/1040-3590.6.4.284, DOI 10.1037/1040-3590.6.4.284]; Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056; Frid-Adar M, 2019, LECT NOTES COMPUT SC, V11769, P784, DOI 10.1007/978-3-030-32226-7_87; GOODMAN LR, 1976, AM J ROENTGENOL, V127, P433, DOI 10.2214/ajr.127.3.433; Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216; Kao EF, 2015, COMPUT METH PROG BIO, V118, P1, DOI 10.1016/j.cmpb.2014.10.009; Koch G.G., 1982, ENCY STAT SCI, V4, P212, DOI DOI 10.1002/0471667196.ESS1275.PUB2; Koshy T, 2016, J CARDIOTHOR VASC AN, V30, P947, DOI 10.1053/j.jvca.2016.01.031; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lakhani P, 2017, J DIGIT IMAGING, V30, P460, DOI 10.1007/s10278-017-9980-7; Lakhani P, 2017, RADIOLOGY, V284, P574, DOI 10.1148/radiol.2017162326; Li Y, 2016, ANESTHESIOLOGY ANN M; McKinney SM, 2020, NATURE, V577, P89, DOI 10.1038/s41586-019-1799-6; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Szegedy C., 2016, P IEEE C COMP VIS PA, P2818, DOI DOI 10.1109/CVPR.2016.308; Varshney M, 2011, INDIAN J ANAESTH, V55, P488, DOI 10.4103/0019-5049.89880; Wu N, 2020, IEEE T MED IMAGING, V39, P1184, DOI 10.1109/TMI.2019.2945514; Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319; ZWILLICH CW, 1974, AM J MED, V57, P161, DOI 10.1016/0002-9343(74)90440-9	24	7	7	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2021	3	1							e200026	10.1148/ryai.2020200026	http://dx.doi.org/10.1148/ryai.2020200026			7	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z3HE	33937852	Green Published			2022-12-18	WOS:000826472300004
J	Eijgelaar, RS; Visser, M; Muller, DMJ; Barkhof, F; Vrenken, H; Van Herk, M; Bello, L; Nibali, MC; Rossi, M; Sciortino, T; Berger, MS; Hervey-Jumper, S; Kiesel, B; Widhalm, G; Furtner, J; Robe, PAJT; Mandonnet, E; Hamer, PCD; De Munck, JC; Witte, MG				Eijgelaar, Roelant S.; Visser, Martin; Muller, Domenique M. J.; Barkhof, Frederik; Vrenken, Hugo; van Herk, Marcel; Bello, Lorenzo; Nibali, Marco Conti; Rossi, Marco; Sciortino, Tommaso; Berger, Mitchel S.; Hervey-Jumper, Shawn; Kiesel, Barbara; Widhalm, Georg; Furtner, Julia; Robe, Pierre A. J. T.; Mandonnet, Emmanuel; Hamer, Philip C. De Witt; de Munck, Jan C.; Witte, Marnix G.			Robust Deep Learning-based Segmentation of Glioblastoma on Routine Clinical MRI Scans Using Sparsified Training	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							RESPONSE ASSESSMENT; BRAIN-TUMORS; CRITERIA	Purpose: To improve the robustness of deep learning-based glioblastoma segmentation in a clinical setting with sparsified datasets. Materials and Methods: In this retrospective study, preoperative T1-weighted, T2-weighted, T2-weighted fluid-attenuated inversion recovery, and postcontrast T1-weighted MRI from 117 patients (median age, 64 years; interquartile range [IQR], 55-73 years; 76 men) included within the Multimodal Brain Tumor Image Segmentation (BraTS) dataset plus a clinical dataset (2012-2013) with similar imaging modalities of 634 patients (median age, 59 years; IQR, 49-69 years; 382 men) with glioblastoma from six hospitals were used. Expert tumor delineations on the postcontrast images were available, but for various clinical datasets, one or more sequences were missing. The convolutional neural network, DeepMedic, was trained on combinations of complete and incomplete data with and without site-specific data. Sparsified training was introduced, which randomly simulated missing sequences during training. The effects of sparsified training and center-specific training were tested using Wilcoxon signed rank tests for paired measurements. Results: A model trained exclusively on BraTS data reached a median Dice score of 0.81 for segmentation on BraTS test data but only 0.49 on the clinical data. Sparsified training improved performance (adjusted P<.05), even when excluding test data with missing sequences, to median Dice score of 0.67. Inclusion of site-specific data during sparsified training led to higher model performance Dice scores greater than 0.8, on par with a model based on all complete and incomplete data. For the model using BraTS and clinical training data, inclusion of site-specific data or sparsified training was of no consequence. Conclusion: Accurate and automatic segmentation of glioblastoma on clinical scans is feasible using a model based on large, heterogeneous, and partially incomplete datasets. Sparsified training may boost the performance of a smaller model based on public and sitespecific data. Published under a CC BY 4.0 license.	[Eijgelaar, Roelant S.; van Herk, Marcel; Witte, Marnix G.] Netherlands Canc Inst, Dept Radiat Oncol, Plesmanlaan 121, NL-1066 CX Amsterdam, Netherlands; [Visser, Martin; Barkhof, Frederik; Vrenken, Hugo; de Munck, Jan C.] Locat Vrije Univ Amsterdam, Amsterdam UMC, Dept Radiol & Nucl Med, Amsterdam, Netherlands; [Muller, Domenique M. J.; Hamer, Philip C. De Witt] Locat Vrije Univ Amsterdam, Neurosurg Ctr Amsterdam, Amsterdam UMC, Amsterdam, Netherlands; [Barkhof, Frederik] UCL, Inst Neurol, London, England; [Barkhof, Frederik] UCL, Inst Healthcare Engn, London, England; [van Herk, Marcel] Univ Manchester & Christie NHS Trust, Fac Biol Med & Hlth, Div Canc Sci, Manchester, Lancs, England; [Bello, Lorenzo; Nibali, Marco Conti; Rossi, Marco; Sciortino, Tommaso] Univ Milan, Humanitas Res Hosp, IRCCS, Dept Oncol & Hematooncol,Neurosurg Oncol Unit, Milan, Italy; [Berger, Mitchel S.; Hervey-Jumper, Shawn] Univ Calif San Francisco, Dept Neurol Surg, San Francisco, CA 94143 USA; [Kiesel, Barbara; Widhalm, Georg] Med Univ Vienna, Dept Neurosurg, Vienna, Austria; [Furtner, Julia] Med Univ Vienna, Dept Biomed Imaging & Imageguided Therapy, Vienna, Austria; [Robe, Pierre A. J. T.] Univ Med Ctr Utrecht, Dept Neurol & Neurosurg, Utrecht, Netherlands; [Mandonnet, Emmanuel] Hop Lariboisiere, Dept Neurol Surg, Paris, France	Netherlands Cancer Institute; University of Amsterdam; University of Amsterdam; University of London; University College London; University of London; University College London; University of Milan; University of California System; University of California San Francisco; Medical University of Vienna; Medical University of Vienna; Utrecht University; Utrecht University Medical Center; Assistance Publique Hopitaux Paris (APHP); Hopital Universitaire Lariboisiere-Fernand-Widal - APHP; UDICE-French Research Universities; Universite Paris Cite	Witte, MG (corresponding author), Netherlands Canc Inst, Dept Radiat Oncol, Plesmanlaan 121, NL-1066 CX Amsterdam, Netherlands.	m.witte@nki.nl	Rossi, Marco/AAB-8556-2022; Widhalm, Georg/AFK-1669-2022	Rossi, Marco/0000-0002-0196-2370; Widhalm, Georg/0000-0001-6014-0273; Muller, Domenique/0000-0002-0638-8347; Barkhof, Frederik/0000-0003-3543-3706	SURF Cooperative; Translational Research IT (TraIT) project, an initiative from the Center for Translational Molecular Medicine (CTMM)	SURF Cooperative; Translational Research IT (TraIT) project, an initiative from the Center for Translational Molecular Medicine (CTMM)	This work was carried out on the Dutch national e-infrastructure with the support of SURF Cooperative and the Translational Research IT (TraIT) project, an initiative from the Center for Translational Molecular Medicine (CTMM). We thank BrainLab for generously providing us with the SmartBrush software, a segmentation software, as a contribution in kind to this study. The authors declare that they have no competing interests.	AlBadawy EA, 2018, MED PHYS, V45, P1150, DOI 10.1002/mp.12752; Avants BB., 2009, INSIGHT J, V2, P1, DOI [DOI 10.54294/UVNHIN, 10.54294/uvnhin]; Avants BB, 2011, NEUROINFORMATICS, V9, P381, DOI 10.1007/s12021-011-9109-y; Bakas S., 2017, CANC IMAGING ARCH, DOI 10.7937/K9/TCIA.2017.GJQ7R0EF286; Bakas S, 2017, SCI DATA, V4; Chang SM, 2015, NEURO-ONCOL PRACT, V2, P205, DOI 10.1093/nop/npv037; Crimi A, 2018, P BRAINLES 2017, V10670, P149; Crocetti E, 2012, EUR J CANCER, V48, P1532, DOI 10.1016/j.ejca.2011.12.013; Dar SUH, 2019, IEEE T MED IMAGING, V38, P2375, DOI 10.1109/TMI.2019.2901750; De Witt Hamer PC, 2013, PLOS ONE, V8; Eijgelaar R, 2019, PLOS ONE, V14; Eijgelaar RS, 2018, J NEURO-ONCOL, V139, P591, DOI 10.1007/s11060-018-2896-3; Freyschlag CF, 2018, J NEURO-ONCOL, V139, P699, DOI 10.1007/s11060-018-2916-3; Gibson E, 2018, COMPUT METH PROG BIO, V158, P113, DOI 10.1016/j.cmpb.2018.01.025; Havaei Mohammad, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P469, DOI 10.1007/978-3-319-46723-8_54; Iglesias JE, 2013, LECT NOTES COMPUT SC, V8149, P631, DOI 10.1007/978-3-642-40811-3_79; Kamnitsas K, 2018, LECT NOTES COMPUT SC, V10670, P450, DOI 10.1007/978-3-319-75238-9_38; Kamnitsas K, 2016, LECT NOTES COMPUT SC, V10154, P138, DOI 10.1007/978-3-319-55524-9_14; Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004; Kingma D.P, P 3 INT C LEARNING R; Krahenbuhl P, ARXIV 12105644; Louis DN, 2007, ACTA NEUROPATHOL, V114, P97, DOI 10.1007/s00401-007-0243-4; M_uller D.K., 2020, ARCTIC TOURISM TIMES; MACDONALD DR, 1990, J CLIN ONCOL, V8, P1277, DOI 10.1200/JCO.1990.8.7.1277; Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694; Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79; Muller DMJ, 2019, JCO CLIN CANCER INFO, V3, DOI 10.1200/CCI.18.00089; Nyul LG, 2000, IEEE T MED IMAGING, V19, P143, DOI 10.1109/42.836373; Ostrom QT, 2014, NEURO-ONCOLOGY, V16, P1, DOI 10.1093/neuonc/nou223; Pan YS, 2018, LECT NOTES COMPUT SC, V11072, P455, DOI 10.1007/978-3-030-00931-1_52; Perkuhn M, 2018, INVEST RADIOL, V53, P647, DOI 10.1097/RLI.0000000000000484; R Core Team, 2021, COMPUTER SOFTWARE; Stupp R, 2014, ANN ONCOL, V25, P93, DOI 10.1093/annonc/mdu050; Taha AA, 2015, BMC MED IMAGING, V15, DOI 10.1186/s12880-015-0068-x; Tustison NJ, 2010, IEEE T MED IMAGING, V29, P1310, DOI 10.1109/TMI.2010.2046908; VASARI Research Project, US; Visser M, 2019, NEUROIMAGE-CLIN, V22; Wen PY, 2010, J CLIN ONCOL, V28, P1963, DOI 10.1200/JCO.2009.26.3541	38	7	7	0	2	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2020	2	5							e190103	10.1148/ryai.2020190103	http://dx.doi.org/10.1148/ryai.2020190103			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CY	33937837	Green Submitted, Green Published, hybrid			2022-12-18	WOS:000826477600001
J	Kaye, EA; Aherne, EA; Duzgol, C; Haggstrom, I; Kobler, E; Mazaheri, Y; Fung, MM; Zhang, ZG; Otazo, R; Vargas, HA; Akin, O				Kaye, Elena A.; Aherne, Emily A.; Duzgol, Cihan; Haggstrom, Ida; Kobler, Erich; Mazaheri, Yousef; Fung, Maggie M.; Zhang, Zhigang; Otazo, Ricardo; Vargas, Hebert A.; Akin, Oguz			Accelerating Prostate Diffusion-weighted MRI Using a Guided Denoising Convolutional Neural Network: Retrospective Feasibility Study	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							RECTAL DISTENSION; IMAGE; REPEATABILITY	Purpose: To investigate the feasibility of accelerating prostate diffusion-weighted imaging (DWI) by reducing the number of acquired averages and denoising the resulting image using a proposed guided denoising convolutional neural network (DnCNN). Materials and Methods: Raw data from the prostate DWI scans were retrospectively gathered between July 2018 and July 2019 from six single-vendor MRI scanners. There were 103 datasets used for training (median age, 64 years; interquartile range [IQR], 11), 15 for validation (median age, 68 years; IQR, 12), and 37 for testing (median age, 64 years; IQR, 12). High b-value diffusion-weighted (hb DW) data were reconstructed into noisy images using two averages and reference images using all 16 averages. A conventional DnCNN was modified into a guided DnCNN, which uses the low b-value DW image as a guidance input. Quantitative and qualitative reader evaluations were performed on the denoised hb DW images. A cumulative link mixed regression model was used to compare the readers' scores. The agreement between the apparent diffusion coefficient (ADC) maps (denoised vs reference) was analyzed using Bland-Altman analysis. Results: Compared with the original DnCNN, the guided DnCNN produced denoised hb DW images with higher peak signal-tonoise ratio (32.79 +/- 3.64 [standard deviation] vs 33.74 +/- 3.64), higher structural similarity index (0.92 +/- 0.05 vs 0.93 +/- 0.04), and lower normalized mean square error (3.9% +/- 10 vs 1.6% 6 1.5) (P<.001 for all). Compared with the reference images, the denoised images received higher image quality scores from the readers (P<.0001). The ADC values based on the denoised hb DW images were in good agreement with the reference ADC values (mean ADC difference ranged from 20.04 to 0.02 x 10(-3) mm(2)/sec). Conclusion: Accelerating prostate DWI by reducing the number of acquired averages and denoising the resulting image using the proposed guided DnCNN is technically feasible. (C) RSNA, 2020	[Kaye, Elena A.; Haggstrom, Ida; Mazaheri, Yousef; Otazo, Ricardo] Mem Sloan Kettering Canc Ctr, Dept Med Phys, 1275 York Ave,Room S1212B, New York, NY 10065 USA; [Aherne, Emily A.; Duzgol, Cihan; Otazo, Ricardo; Vargas, Hebert A.; Akin, Oguz] Mem Sloan Kettering Canc Ctr, Dept Radiol, 1275 York Ave,Room S1212B, New York, NY 10065 USA; [Zhang, Zhigang] Mem Sloan Kettering Canc Ctr, Dept Epidemiol & Biostat, 1275 York Ave,Room S1212B, New York, NY 10065 USA; [Kobler, Erich] Graz Univ Technol, Inst Comp Graph & Vis, Graz, Austria; [Fung, Maggie M.] GE Healthcare, MR Applicat & Workflow Team, Chicago, IL USA	Memorial Sloan Kettering Cancer Center; Memorial Sloan Kettering Cancer Center; Memorial Sloan Kettering Cancer Center; Graz University of Technology; General Electric	Kaye, EA (corresponding author), Mem Sloan Kettering Canc Ctr, Dept Med Phys, 1275 York Ave,Room S1212B, New York, NY 10065 USA.	kayee@mskcc.org		Duzgol, Cihan/0000-0002-0310-576X; Otazo, Ricardo/0000-0002-3782-4930	NIH/NCI Cancer Center support grant [P30 CA008748]	NIH/NCI Cancer Center support grant	E.A.K. Activities related to the present article: work partly funded by NIH/NCI Cancer Center support grant (P30 CA008748). Activities not related to the present article: disclosed no relevant relationships. Other relationships: disclosed no relevant relationships. E.A.A. disclosed no relevant relationships. C.D. disclosed no relevant relationships. I.H. disclosed no relevant relationships. E.K. disclosed no relevant relationships. Y.M. disclosed no relevant relationships. M.M.F. Activities related to the present article: disclosed no relevant relationships. Activities not related to the present article: employee of GE Healthcare; holds stock options in GE Healthcare. Other relationships: disclosed no relevant relationships. Z.Z. disclosed no relevant relationships. R.O. disclosed no relevant relationships. H.A.V. disclosed no relevant relationships. O.A. Activities related to the present article: disclosed no relevant relationships. Activities not related to the present article: disclosed no relevant relationships. Other relationships: author is on the scientific advisory board for Ezra AI.	Barentsz JO, 2016, EUR UROL, V69, P41, DOI 10.1016/j.eururo.2015.08.038; Barrett T, 2019, EUR J RADIOL, V110, P22, DOI 10.1016/j.ejrad.2018.11.014; Bates D., ARXIV14065823; BLAND JM, 1986, LANCET, V1, P307, DOI 10.1016/s0140-6736(86)90837-8; Caglic I, 2017, EUR J RADIOL, V90, P174, DOI 10.1016/j.ejrad.2017.02.029; Gibbs P, 2007, MAGN RESON IMAGING, V25, P1423, DOI 10.1016/j.mri.2007.03.030; Gong E, 2017, P ANN M INT SOC MAGN; Gong E, 2018, J MAGN RESON IMAGING, V48, P330, DOI 10.1002/jmri.25970; GUDBJARTSSON H, 1995, MAGNET RESON MED, V34, P910, DOI 10.1002/mrm.1910340618; Ham B, 2018, IEEE T PATTERN ANAL, V40, P192, DOI 10.1109/TPAMI.2017.2669034; He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213; HENKELMAN RM, 1985, MED PHYS, V12, P232, DOI 10.1118/1.595711; Kim KH, 2018, RADIOLOGY, V287, P658, DOI 10.1148/radiol.2017171154; Lehtinen J, ARXIV180304189; Mazaheri Y, 2013, EUR J RADIOL, V82, pE515, DOI 10.1016/j.ejrad.2013.04.041; Mazaheri Y, 2013, ACAD RADIOL, V20, P1041, DOI 10.1016/j.acra.2013.04.005; O'Donohoe RL, 2019, ABDOM RADIOL, V44, P1062, DOI 10.1007/s00261-018-1804-9; Padhani AR, 1999, INT J RADIAT ONCOL, V44, P525, DOI 10.1016/S0360-3016(99)00040-1; Richenberg J, 2019, EUR RADIOL, V29, P6940, DOI 10.1007/s00330-019-06166-z; Rosenkrantz AB, 2015, ABDOM IMAGING, V40, P120, DOI 10.1007/s00261-014-0181-2; Shah ZK, 2015, ACAD RADIOL, V22, P467, DOI 10.1016/j.acra.2014.11.007; Soderman M, 2013, RADIOLOGY, V269, P553, DOI 10.1148/radiol.13121262; Sosna J, 2004, ACAD RADIOL, V11, P857, DOI 10.1016/j.acra.2004.04.013; TURNER R, 1990, J MAGN RESON, V86, P445, DOI 10.1016/0022-2364(90)90023-3; Xie D, ARXIV; Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206; Zhussip M, 2019, ARXIV	27	7	8	0	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2020	2	5							e200007	10.1148/ryai.2020200007	http://dx.doi.org/10.1148/ryai.2020200007			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CY	33033804	Green Submitted, Green Published			2022-12-18	WOS:000826477600007
J	Marcadent, S; Hofmeister, J; Preti, MG; Martin, SP; Van de Ville, D; Montet, X				Marcadent, Sandra; Hofmeister, Jeremy; Preti, Maria Giulia; Martin, Steve P.; Van de Ville, Dimitri; Montet, Xavier			Generative Adversarial Networks Improve the Reproducibility and Discriminative Power of Radiomic Features	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To assess the contribution of a generative adversarial network (GAN) to improve intermanufacturer reproducibility of radiomic features (RFs). Materials and Methods: The authors retrospectively developed a cycle-GAN to translate texture information from chest radiographs acquired using one manufacturer (Siemens) to chest radiographs acquired using another (Philips), producing fake chest radiographs with different textures. The authors prospectively evaluated the ability of this texture-translation cycle-GAN to reduce the intermanufacturer variability of RFs extracted from the lung parenchyma. This study assessed the cycle-GAN's ability to fool several machine learning (ML) classifiers tasked with recognizing the manufacturer on the basis of chest radiography inputs. The authors also evaluated the cycle-GAN's ability to mislead radiologists who were asked to perform the same recognition task. Finally, the authors tested whether the cycle-GAN had an impact on radiomic diagnostic accuracy for chest radiography in patients with congestive heart failure (CHF). Results: RFs, extracted from chest radiographs after the cycle-GAN's texture translation (fake chest radiographs), showed decreased intermanufacturer RF variability. Using cycle-GAN-generated chest radiographs as inputs, ML classifiers categorized the fake chest radiographs as belonging to the target manufacturer rather than to a native one. Moreover, cycle-GAN fooled two experienced radiologists who identified fake chest radiographs as belonging to a target manufacturer class. Finally, reducing intermanufacturer RF variability with cycle-GAN improved the discriminative power of RFs for patients without CHF versus patients with CHF (from 55% to 73.5%, P <.001). Conclusion: Both ML classifiers and radiologists had difficulty recognizing the chest radiographs' manufacturer. The cycle-GAN improved RF intermanufacturer reproducibility and discriminative power for identifying patients with CHF. This deep learning approach may help counteract the sensitivity of RFs to differences in acquisition. Supplemental material is available for this article. (C) RSNA, 2020	[Marcadent, Sandra; Hofmeister, Jeremy; Martin, Steve P.; Montet, Xavier] Geneva Univ Hosp, Dept Diagnost, Serv Radiol, Rue Gabrielle Perret Gentil 4, CH-1211 Geneva 14, Switzerland; [Marcadent, Sandra; Hofmeister, Jeremy; Preti, Maria Giulia; Martin, Steve P.; Van de Ville, Dimitri; Montet, Xavier] Univ Geneva, Dept Radiol & Med Informat, Geneva, Switzerland; [Marcadent, Sandra; Preti, Maria Giulia; Van de Ville, Dimitri] Ecole Polytech Fed Lausanne, Inst Bioengn, Ctr Neuroprosther, Lausanne, Switzerland		Montet, X (corresponding author), Geneva Univ Hosp, Dept Diagnost, Serv Radiol, Rue Gabrielle Perret Gentil 4, CH-1211 Geneva 14, Switzerland.; Montet, X (corresponding author), Univ Geneva, Dept Radiol & Med Informat, Geneva, Switzerland.	xavier.montet@infomaniak.ch		Martin, Steve/0000-0002-2318-2420; Marcadent, Sandra Maria/0000-0002-6470-3974; Van De Ville, Dimitri/0000-0002-2879-3861	Research and Development Grant of the Geneva University Hospital [PRD 11-2017-2]	Research and Development Grant of the Geneva University Hospital	Supported by a Research and Development Grant of the Geneva University Hospital (PRD 11-2017-2).	[Anonymous], 1999, 10153 BS EN; Berenguer R, 2018, RADIOLOGY, V288, P407, DOI 10.1148/radiol.2018172361; Choe J, 2019, RADIOLOGY, V292, P365, DOI 10.1148/radiol.2019181960; Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202; Gillies RJ, 2016, RADIOLOGY, V278, P563, DOI 10.1148/radiol.2015151169; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Goodfellow IJ, ARXIV 14126572; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; Kim H, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0164924; LIN LI, 1989, BIOMETRICS, V45, P255, DOI 10.2307/2532051; Lubner MG, 2017, RADIOGRAPHICS, V37, P1483, DOI 10.1148/rg.2017170056; Mackin D, 2015, INVEST RADIOL, V50, P757, DOI 10.1097/RLI.0000000000000180; O'Connor JPB, 2017, NAT REV CLIN ONCOL, V14, P169, DOI 10.1038/nrclinonc.2016.162; Orlhac F, 2019, RADIOLOGY, V291, P52, DOI 10.1148/radiol.2019182023; Orlhac F, 2018, J NUCL MED, V59, P1321, DOI 10.2967/jnumed.117.199935; Shafiq-ul-Hassan M, 2017, MED PHYS, V44, P1050, DOI 10.1002/mp.12123; Sullivan DC, 2015, RADIOLOGY, V277, P813, DOI 10.1148/radiol.2015142202; Szegedy C, ARXIV 13126199; Taigman Y, ARXIV 161102200; Thrall JH, 2018, J AM COLL RADIOL, V15, P504, DOI 10.1016/j.jacr.2017.12.026; Traverso A, 2018, INT J RADIAT ONCOL, V102, P1143, DOI 10.1016/j.ijrobp.2018.05.053; van Griethuysen JJM, 2017, CANCER RES, V77, pE104, DOI 10.1158/0008-5472.CAN-17-0339	23	7	7	1	2	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2020	2	3							e190035	10.1148/ryai.2020190035	http://dx.doi.org/10.1148/ryai.2020190035			8	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CW	33937823	Green Published			2022-12-18	WOS:000826470300002
J	Meier, R; Lux, P; Jung, SM; Fischer, U; Gralla, J; Reyes, M; Wiest, R; McKinley, R; Kaesmacher, J				Meier, Raphael; Lux, Paula; Jung, Simon; Fischer, Urs; Gralla, Jan; Reyes, Mauricio; Wiest, Roland; McKinley, Richard; Kaesmacher, Johannes			Neural Network derived Perfusion Maps for the Assessment of Lesions in Patients with Acute Ischemic Stroke	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							ARTERIAL INPUT FUNCTION; MR; SELECTION; PLATFORM; FLOW	Purpose: To perform a proof-of-concept study to investigate the clinical utility of perfusion maps derived from convolutional neural networks (CNNs) for the workup of patients with acute ischemic stroke presenting with a large vessel occlusion. Materials and Methods: Data on endovascularly treated patients with acute ischemic stroke (n = 151; median age, 68 years [interquartile range, 59-75 years]; 82 of 151 [54.3%] women) were retrospectively extracted from a single-center institutional prospective registry (between January 2011 and December 2015). Dynamic susceptibility perfusion imaging data were processed by applying a commercially available reference method and in parallel by a recently proposed CNN method to automatically infer time to maximum of the tissue residue function (Tmax) perfusion maps. The outputs were compared by using quantitative markers of tissue at risk derived from manual segmentations of perfusion lesions from two expert raters. Results: Strong correlations of lesion volumes (Tmax > 4 seconds, > 6 seconds, and > 8 seconds; R = 0.865-0.914; P < .001) and good spatial overlap of respective lesion segmentations (Dice coefficients, 0.70-0.85) between the CNN method and reference output were observed. Eligibility for late-window reperfusion treatment was feasible with use of the CNN method, with complete interrater agreement for the CNN method (Cohen kappa = 1; P < .001), although slight discrepancies compared with the reference-based output were observed (Cohen kappa = 0.609-0.64; P < .001). The CNN method tended to underestimate smaller lesion volumes, leading to a disagreement between the CNN and reference method in five of 45 patients (9%). Conclusion: Compared with standard deconvolution-based processing of raw perfusion data, automatic CNN-derived Tmax perfusion maps can be applied to patients who have acute ischemic large vessel occlusion stroke, with similar clinical utility. (C) RSNA, 2019	[Meier, Raphael; Lux, Paula; Gralla, Jan; Wiest, Roland; McKinley, Richard; Kaesmacher, Johannes] Univ Hosp, Inselspital, Univ Inst Diagnost & Intervent Neuroradiol, Support Ctr Adv Neuroimaging, Freiburgstr 4, CH-3010 Bern, Switzerland; [Jung, Simon; Fischer, Urs; Kaesmacher, Johannes] Univ Hosp, Inselspital, Dept Neurol, Freiburgstr 4, CH-3010 Bern, Switzerland; [Reyes, Mauricio] Univ Hosp, Inselspital, Inst Surg Technol & Biomech, Freiburgstr 4, CH-3010 Bern, Switzerland; [Kaesmacher, Johannes] Univ Hosp, Inselspital, Inst Diagnost Intervent & Pediat Radiol, Freiburgstr 4, CH-3010 Bern, Switzerland; [Kaesmacher, Johannes] Univ Bern, Freiburgstr 4, CH-3010 Bern, Switzerland	University of Bern; University Hospital of Bern; University of Bern; University Hospital of Bern; University of Bern; University Hospital of Bern; University of Bern; University Hospital of Bern; University of Bern	Meier, R (corresponding author), Univ Hosp, Inselspital, Univ Inst Diagnost & Intervent Neuroradiol, Support Ctr Adv Neuroimaging, Freiburgstr 4, CH-3010 Bern, Switzerland.	raphael.meier@insel.ch		Meier, Raphael/0000-0003-4632-0360; Kaesmacher, Johannes/0000-0002-9177-2289				ADAMS HP, 1993, STROKE, V24, P35, DOI 10.1161/01.STR.24.1.35; Albers GW, 2018, NEW ENGL J MED, V378, P708, DOI 10.1056/NEJMoa1713973; Albers GW, 2017, INT J STROKE, V12, P896, DOI 10.1177/1747493017701147; Albers GW, 2015, STROKE, V46, P2786, DOI 10.1161/STROKEAHA.115.010710; ALTMAN DG, 1983, J ROY STAT SOC D-STA, V32, P307, DOI 10.2307/2987937; Amiri H, 2016, INT J STROKE, V11, P260, DOI 10.1177/1747493015620805; Ba J., 2017, P 3 INT C LEARN REPR; Broeg-Morvay A, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0170045; Campbell BCV, 2018, INT J STROKE, V13, P554, DOI 10.1177/1747493018765235; Carroll TJ, 2003, RADIOLOGY, V227, P593, DOI 10.1148/radiol.2272020092; Copen WA, 2011, NEUROIMAG CLIN N AM, V21, P259, DOI 10.1016/j.nic.2011.02.007; Davis SM, 2008, LANCET NEUROL, V7, P299, DOI 10.1016/S1474-4422(08)70044-9; Fedorov A, 2012, MAGN RESON IMAGING, V30, P1323, DOI 10.1016/j.mri.2012.05.001; Grant H, ARXIV 190302026 PREP; Hess A, 2019, BRAINLESION GLIOMA M; Ho KC, 2016, INT C PATT RECOG, P1315, DOI 10.1109/ICPR.2016.7899819; Kendall A., 2017, P ADV NEUR INF PROC, V30; Kim J, 2010, COMPUT METH PROG BIO, V98, P204, DOI 10.1016/j.cmpb.2009.12.005; Kosior JC, 2007, J MAGN RESON IMAGING, V25, P653, DOI 10.1002/jmri.20843; Kudo K, 2013, RADIOLOGY, V267, P201, DOI 10.1148/radiol.12112618; Livne M, 2018, STROKE, V49, P912, DOI 10.1161/STROKEAHA.117.019440; Maier O, 2017, MED IMAGE ANAL, V35, P250, DOI 10.1016/j.media.2016.07.009; McKinley R, 2017, J CEREBR BLOOD F MET, V37, P2728, DOI 10.1177/0271678X16674221; Mlynash M, 2009, NEUROLOGY, V72, P1127, DOI 10.1212/01.wnl.0000340983.00152.69; Mouridsen K, 2006, MAGN RESON MED, V55, P524, DOI 10.1002/mrm.20759; Nielsen A, 2018, STROKE, V49, P1394, DOI 10.1161/STROKEAHA.117.019740; Pinto A., ARXIV 180604413; Plis SM, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00229; R Core Team, 2021, COMPUTER SOFTWARE; Restrepo L, 2004, AM J NEURORADIOL, V25, P1645; Ribo M, 2005, STROKE, V36, P602, DOI 10.1161/01.STR.0000155737.43566.ad; Schaafs LA, 2016, EUR RADIOL, V26, P4204, DOI 10.1007/s00330-016-4244-3; Ulas C., ARXIV 180402745 PREP; Welker K, 2015, AM J NEURORADIOL, V36, pE41, DOI 10.3174/ajnr.A4341; Wu O, 2003, MAGNET RESON MED, V50, P164, DOI 10.1002/mrm.10522; Zaharchuk G, 2018, AM J NEURORADIOL, V39, P1776, DOI 10.3174/ajnr.A5543; Zaro-Weber O, 2015, STROKE, V46, P2795, DOI 10.1161/STROKEAHA.115.010246	37	7	7	0	3	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2019	1	5							e190019	10.1148/ryai.2019190019	http://dx.doi.org/10.1148/ryai.2019190019			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CP	33937801	Bronze, Green Published			2022-12-18	WOS:000826294400003
J	Steinkamp, JM; Chambers, CM; Lalevic, D; Zafar, HM; Cook, TS				Steinkamp, Jackson M.; Chambers, Charles M.; Lalevic, Darco; Zafar, Hanna M.; Cook, Tessa S.			Automated Organ-Level Classification of Free-Text Pathology Reports to Support a Radiology Follow-up Tracking Engine	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To evaluate the performance of machine learning algorithms on organ-level classification of semistructured pathology reports, to incorporate surgical pathology monitoring into an automated imaging recommendation follow-up engine. Materials and Methods: This retrospective study included 2013 pathology reports from patients who underwent abdominal imaging at a large tertiary care center between 2012 and 2018. The reports were labeled by two annotators as relevant to four abdominal organs: liver, kidneys, pancreas and/or adrenal glands, or none. Automated classification methods were compared: simple string matching, random forests, extreme gradient boosting, support vector machines, and two neural network architectures-convolutional neural networks and long short-term memory networks. Three methods from the literature were used to provide interpretability and qualitative validation of the learned network features. Results: The neural networks performed well on the four-organ classification task (F1 score: 96.3% for convolutional neural network and 96.7% for long short-term memory vs 89.9% for support vector machines, 93.9% for extreme gradient boosting, 82.8% for random forests, and 75.2% for simple string matching). Multiple methods were used to visualize the decision-making process of the network, verifying that the networks used similar heuristics to a human annotator. The neural networks were able to classify, with a high degree of accuracy, pathology reports written in unseen formats, suggesting the networks had learned a generalizable encoding of the salient features. Conclusion: Neural network-based approaches achieve high performance on organ-level pathology report classification, suggesting that it is feasible to use them within automated tracking systems. (C) RSNA, 2019	[Steinkamp, Jackson M.; Chambers, Charles M.; Lalevic, Darco; Zafar, Hanna M.; Cook, Tessa S.] Hosp Univ Penn, Dept Radiol, 3400 Spruce St, Philadelphia, PA 19104 USA; [Steinkamp, Jackson M.] Boston Univ, Sch Med, Dept Radiol, Boston, MA 02118 USA	University of Pennsylvania; Pennsylvania Medicine; Boston University	Steinkamp, JM (corresponding author), Hosp Univ Penn, Dept Radiol, 3400 Spruce St, Philadelphia, PA 19104 USA.; Steinkamp, JM (corresponding author), Boston Univ, Sch Med, Dept Radiol, Boston, MA 02118 USA.	jacksonsteinkamp@gmail.com		Steinkamp, Jackson/0000-0001-7888-0691; Lalevic, Darco/0000-0003-3970-9554	Penn Center for Innovation	Penn Center for Innovation	J.M.S. disclosed no relevant relationships. C.M.C. disclosed no relevant relationships. D.L. disclosed no relevant relationships. H.M.Z. Activities related to the present article: institution received grant from Penn Center for Innovation. Activities not related to the present article: institution received grant from Eastern Cooperative Oncology Group and American College of Radiology Imaging Network (ECOG-ACRIN); author received payment for lectures including service on speakers bureaus from ACVR and Jefferson Health System. Other relationships: disclosed no relevant relationships. T.S.C. Activities related to the present article: disclosed no relevant relationships. Activities not related to the present article: is a board member of AUR, PRS, PRRS, and SIIM; has grants/grants pending with ACRIN, AUR, and Beryl Institute; received payment for lectures including service on speakers bureaus from AIRP VOICE program, Cornell University, Emory University, Thomas Jefferson University Hospital, and University of Wisconsin; received royalties from Osler Institute for lectures on cardiac imaging. Other relationships: disclosed no relevant relationships.	[Anonymous], 1999, 10153 BS EN; Cook TS, 2017, J AM COLL RADIOL, V14, P629, DOI 10.1016/j.jacr.2017.01.024; Gao S, 2017, J AM MED INFORM ASS; Hassanpour S, 2016, ARTIF INTELL MED, V66, P29, DOI 10.1016/j.artmed.2015.09.007; Hassanpour S, 2016, J DIGIT IMAGING, V29, P59, DOI 10.1007/s10278-015-9823-3; Hochreiter S., 1997, STUD COMPUT INTELL, V9, P1735, DOI DOI 10.1007/978-3-642-24797-2; Kim Y., 2014, ARXIV PREPRINT ARXIV, DOI DOI 10.3115/V1/D14-1181; Kingma DP, ARXIV CSLG; Nowak J, 2017, LECT NOTES ARTIF INT, V10246, P553, DOI 10.1007/978-3-319-59060-8_50; Oliveira L, 2015, STUD HEALTH TECHNOL, V216, P1028, DOI 10.3233/978-1-61499-564-7-1028; Pennington Jeffrey, GLOVE GLOBAL VECTORS; Peters ME, ARXIV CSCL; Pons E, 2016, RADIOLOGY, V279, P329, DOI 10.1148/radiol.16142770; Yoon H, 2018, 2018 IEEE EMBS INT C, P345; ZeilerMD FergusR, ARXIV CSCV; Zhang Y, ARXIV CSCL	17	7	7	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2019	1	5							e180052	10.1148/ryai.2019180052	http://dx.doi.org/10.1148/ryai.2019180052			7	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CP	33937800	Green Published			2022-12-18	WOS:000826294400002
J	Hendrix, N; Scholten, E; Vernhout, B; Bruijnen, S; Maresch, B; de Jong, M; Diepstraten, S; Bollen, S; Schalekamp, S; de Rooij, M; Scholtens, A; Hendrix, W; Samson, T; Ong, LLS; Postma, E; van Ginneken, B; Rutten, M				Hendrix, Nils; Scholten, Ernst; Vernhout, Bastiaan; Bruijnen, Stefan; Maresch, Bas; de Jong, Mathijn; Diepstraten, Suzanne; Bollen, Stijn; Schalekamp, Steven; de Rooij, Maarten; Scholtens, Alexander; Hendrix, Ward; Samson, Tijs; Ong, Lee-Ling Sharon; Postma, Eric; van Ginneken, Bram; Rutten, Matthieu			Development and Validation of a Convolutional Neural Network for Automated Detection of Scaphoid Fractures on Conventional Radiographs	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							WRIST FRACTURES; DIAGNOSIS; SCINTIGRAPHY; SENSITIVITY	Purpose: To compare the performance of a convolutional neural network (CNN) to that of 11 radiologists in detecting scaphoid bone fractures on conventional radiographs of the hand, wrist, and scaphoid. Materials and Methods: At two hospitals (hospitals A and B), three datasets consisting of conventional hand, wrist, and scaphoid radiographs were retrospectively retrieved: a dataset of 1039 radiographs (775 patients [mean age, 48 years +/- 23 {standard deviation}; 505 female patients], period: 2017-2019, hospitals A and B) for developing a scaphoid segmentation CNN, a dataset of 3000 radiographs (1846 patients [mean age, 42 years +/- 22; 937 female patients], period: 2003-2019, hospital B) for developing a scaphoid fracture detection CNN, and a dataset of 190 radiographs (190 patients [mean age, 43 years +/- 20; 77 female patients], period: 2011-2020, hospital A) for testing the complete fracture detection system. Both CNNs were applied consecutively: The segmentation CNN localized the scaphoid and then passed the relevant region to the detection CNN for fracture detection. In an observer study, the performance of the system was compared with that of 11 radiologists. Evaluation metrics included the Dice similarity coefficient (DSC), Hausdorff distance (HD), sensitivity, specificity, positive predictive value (PPV), and area under the receiver operating characteristic curve (AUC). Results: The segmentation CNN achieved a DSC of 97.4% +/- 1.4 with an HD of 1.31 mm +/- 1.03. The detection CNN had sensitivity of 78% (95% CI: 70, 86), specificity of 84% (95% CI: 77, 92), PPV of 83% (95% CI: 77, 90), and AUC of 0.87 (95% CI: 0.81, 0.91). There was no difference between the AUC of the CNN and that of the radiologists (0.87 [95% CI: 0.81, 0.91] vs 0.83 [radiologist range: 0.79-0.85]; P = .09). Conclusion: The developed CNN achieved radiologist-level performance in detecting scaphoid bone fractures on conventional radiographs of the hand, wrist, and scaphoid. (C) RSNA, 2021	[Hendrix, Nils; Vernhout, Bastiaan; Bruijnen, Stefan; de Jong, Mathijn; Hendrix, Ward; Samson, Tijs; Rutten, Matthieu] Jeroen Bosch Ziekenhuis, Dept Radiol, Henri Dunantstr 1, NL-5223 GZ Shertogenbosch, Netherlands; [Hendrix, Nils; Ong, Lee-Ling Sharon; Postma, Eric] Jheronimus Acad Data Sci, Shertogenbosch, Netherlands; [Hendrix, Nils; Scholten, Ernst; Vernhout, Bastiaan; Bruijnen, Stefan; Schalekamp, Steven; de Rooij, Maarten; Hendrix, Ward; van Ginneken, Bram; Rutten, Matthieu] Radboud Univ Nijmegen, Dept Imaging, Med Ctr, Nijmegen, Netherlands; [Maresch, Bas] Ziekenhuis Gelderse Vallei, Dept Radiol, Ede, Netherlands; [Diepstraten, Suzanne] Sint Maartensklin, Dept Radiol, Nijmegen, Netherlands; [Bollen, Stijn] Groene Hart Ziekenhuis, Dept Radiol, Gouda, Netherlands; [Scholtens, Alexander] Tergooi, Dept Radiol & Nucl Med, Hilversum, Netherlands; [Scholtens, Alexander] Tergooi, Dept Radiol & Nucl Med, Blaricum, Netherlands; [Ong, Lee-Ling Sharon; Postma, Eric] Tilburg Univ, Dept Cognit Sci & Artificial Intelligence, Tilburg, Netherlands	Jeroen Bosch Ziekenhuis; Radboud University Nijmegen; Gelderse Vallei Hospital; Sint Maartens Clinic; Tergooi Blaricum; Tilburg University	Hendrix, N (corresponding author), Jeroen Bosch Ziekenhuis, Dept Radiol, Henri Dunantstr 1, NL-5223 GZ Shertogenbosch, Netherlands.; Hendrix, N (corresponding author), Jheronimus Acad Data Sci, Shertogenbosch, Netherlands.; Hendrix, N (corresponding author), Radboud Univ Nijmegen, Dept Imaging, Med Ctr, Nijmegen, Netherlands.	n.hendrix@jbz.nl	; de Rooij, Maarten/P-7805-2015	De Jong, Mathijn/0000-0001-8321-0748; Ong, Lee Ling/0000-0002-4120-163X; de Rooij, Maarten/0000-0001-7257-7907; Vernhout, Bastiaan/0000-0001-8175-5357				Balci A, 2015, EMERG RADIOL, V22, P251, DOI 10.1007/s10140-014-1278-1; Blum A, 2007, J RADIOL, V88, P741, DOI 10.1016/S0221-0363(07)91342-6; Burns MJ, 2013, SCOT MED J, V58, P143, DOI 10.1177/0036933013496950; de Zwart AD, 2016, EUR J TRAUMA EMERG S, V42, P725, DOI 10.1007/s00068-015-0594-9; Dutta A, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2276, DOI 10.1145/3343031.3350535; Gallas BD, 2014, J MED IMAGING, V1, DOI 10.1117/1.JMI.1.3.031006; Gibney B, 2019, AM J ROENTGENOL, V213, P1117, DOI 10.2214/AJR.19.21478; Holzinger A, ARXIV; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Kingma D.P., ARXIV PREPRINT; Langerhuizen DWG, 2020, CLIN ORTHOP RELAT R, V478, P2653, DOI 10.1097/CORR.0000000000001318; Mahajan V, 2020, ACAD RADIOL, V27, P132, DOI 10.1016/j.acra.2019.09.009; Maier O., 2016, MEDPY MED IMAGE PROC; NEVIASER RJ, 1986, CLIN ORTHOP RELAT R, P12; Obuchowski NA, 2012, ACAD RADIOL, V19, P1508, DOI 10.1016/j.acra.2012.09.012; Omeiza D, ARXIV; Paszke A, 2019, ADV NEUR IN, V32; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Prosser GH, 2003, INJURY, V34, P65, DOI 10.1016/S0020-1383(02)00162-6; Rhemrev SJ, 2011, INT J EMERG MED, V4, DOI 10.1186/1865-1380-4-4; Roolker W, 1999, ARCH ORTHOP TRAUM SU, V119, P428, DOI 10.1007/s004020050014; Steinmann SP, 2006, J ORTHOP SCI, V11, P424, DOI 10.1007/s00776-006-1025-x; TIELVANBUUL MMC, 1993, J BONE JOINT SURG BR, V75, P61, DOI 10.1302/0301-620X.75B1.8421037; Welling RD, 2008, AM J ROENTGENOL, V190, P10, DOI 10.2214/AJR.07.2699	24	6	6	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2021	3	4							e200260	10.1148/ryai.2021200260	http://dx.doi.org/10.1148/ryai.2021200260			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SU	34350413	Green Published			2022-12-18	WOS:000826909000012
J	Shin, Y; Yang, J; Lee, YH				Shin, YiRang; Yang, Jaemoon; Lee, Young Han			Deep Generative Adversarial Networks: Applications in Musculoskeletal Imaging	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Review						Adults and Pediatrics; Computer Aided Diagnosis (CAD); Computer Applications-General (Informatics); Skeletal-Appendicular; Skeletal-Axial; Soft Tissues/Skin	LOW-DOSE CT; RECONSTRUCTION; PERFORMANCE; MRI; SYSTEM; IMAGES; SPINE	In recent years, deep learning techniques have been applied in musculoskeletal radiology to increase the diagnostic potential of acquired images. Generative adversarial networks (GANs), which are deep neural networks that can generate or transform images, have the potential to aid in faster imaging by generating images with a high level of realism across multiple contrast and modalities from existing imaging protocols. This review introduces the key architectures of GANs as well as their technical background and challenges. Key research trends are highlighted, including: (a) reconstruction of high-resolution MRI; (b) image synthesis with different modalities and contrasts; (c) image enhancement that efficiently preserves high-frequency information suitable for human interpretation; (d) pixel-level segmentation with annotation sharing between domains; and (e) applications to different musculoskeletal anatomies. In addition, an overview is provided of the key issues wherein clinical applicability is challenging to capture with conventional performance metrics and expert evaluation. When clinically validated, GANs have the potential to improve musculoskeletal imaging. (C) RSNA, 2021	[Shin, YiRang; Yang, Jaemoon; Lee, Young Han] Yonsei Univ, Coll Med, Dept Radiol, Res Inst Radiol Sci, 250 Seongsanno, Seoul 220701, South Korea; [Shin, YiRang; Yang, Jaemoon; Lee, Young Han] Yonsei Univ, Coll Med, Ctr Clin Imaging Data Sci CCIDS, 250 Seongsanno, Seoul 220701, South Korea; [Yang, Jaemoon] Syst Mol Radiol Yonsei SysMolRaY, Seoul, South Korea; [Yang, Jaemoon] Yonsei Univ, Severance Biomed Sci Inst SBSI, Coll Med, Seoul, South Korea	Yonsei University; Yonsei University Health System; Yonsei University; Yonsei University Health System; Yonsei University; Yonsei University Health System	Lee, YH (corresponding author), Yonsei Univ, Coll Med, Dept Radiol, Res Inst Radiol Sci, 250 Seongsanno, Seoul 220701, South Korea.; Lee, YH (corresponding author), Yonsei Univ, Coll Med, Ctr Clin Imaging Data Sci CCIDS, 250 Seongsanno, Seoul 220701, South Korea.	sando@yuhs.ac		Yang, Jaemoon/0000-0001-7365-0395; Lee, Young Han/0000-0002-5602-391X	National Research Foundation (NRF) - Korean government, Ministry of Science and ICT (MSIP) [2018R1A2B6009076]	National Research Foundation (NRF) - Korean government, Ministry of Science and ICT (MSIP)	Supported by a National Research Foundation (NRF) grant funded by the Korean government, Ministry of Science and ICT (MSIP, 2018R1A2B6009076).	Blau Y, 2018, PROC CVPR IEEE, P6228, DOI 10.1109/CVPR.2018.00652; Bowles C, 2018, PROC SPIE, V10574, DOI 10.1117/12.2293256; Chang PD, 2019, J DIGIT IMAGING, V32, P980, DOI 10.1007/s10278-019-00193-4; Chaudhari AS, 2020, J MAGN RESON IMAGING, V51, P768, DOI [10.1002/jmri.26872, 10.1002/jmri.26991]; Chaudhari AS, 2018, MAGN RESON MED, V80, P2139, DOI 10.1002/mrm.27178; Chea P, 2020, SKELETAL RADIOL, V49, P183, DOI 10.1007/s00256-019-03284-z; Chen H, 2017, IEEE T MED IMAGING, V36, P2524, DOI 10.1109/TMI.2017.2715284; Chen H, 2017, BIOMED OPT EXPRESS, V8, P679, DOI 10.1364/BOE.8.000679; Cheng CT, 2019, EUR RADIOL, V29, P5469, DOI 10.1007/s00330-019-06167-y; Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916; Chuquicusma MJM, 2018, I S BIOMED IMAGING, P240; Cohen JP, 2018, LECT NOTES COMPUT SC, V11070, P529, DOI 10.1007/978-3-030-00928-1_60; Deng M, 2020, OPT EXPRESS, V28, P2511, DOI 10.1364/OE.381301; Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281; Finlayson SG, ARXIV181201547; Forsberg D, 2017, J DIGIT IMAGING, V30, P406, DOI 10.1007/s10278-017-9945-x; Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013; Fu H, 2019, PROC CVPR IEEE, P2422, DOI [10.1109/CVPR.2019.00253, 10.1109/cvpr.2019.00253]; Gadelha M, 2017, INT CONF 3D VISION, P402, DOI 10.1109/3DV.2017.00053; Gadermayr M, 2019, J MAGN RESON IMAGING, V49, P1676, DOI 10.1002/jmri.26544; Galbusera Fabio, 2018, Eur Radiol Exp, V2, P29, DOI 10.1186/s41747-018-0060-7; Galbusera F, 2018, FRONT BIOENG BIOTECH, V6, DOI 10.3389/fbioe.2018.00053; Ge YH, 2019, PROC SPIE, V10949, DOI 10.1117/12.2512479; Gholamrezanezhad A, 2017, J AM COLL RADIOL, V14, P1585, DOI 10.1016/j.jacr.2017.06.019; Gokaslan A, 2018, LECT NOTES COMPUT SC, V11216, P662, DOI 10.1007/978-3-030-01258-8_40; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gupta A, ARXIV190202248; Hammernik K, 2018, MAGN RESON MED, V79, P3055, DOI 10.1002/mrm.26977; Han ZY, 2018, MED IMAGE ANAL, V50, P23, DOI 10.1016/j.media.2018.08.005; Heidemann RM, 2003, EUR RADIOL, V13, P2323, DOI 10.1007/s00330-003-1992-7; Hendee WR, 2012, RADIOLOGY, V264, P312, DOI 10.1148/radiol.12112678; Hensel M, 2017, ADV NEUR IN, V30; Hiasa Y, 2018, LECT NOTES COMPUT SC, V11037, P31, DOI 10.1007/978-3-030-00536-8_4; Isola P., 2017, IMAGE TO IMAGE TRANS, P1125; Kang E, 2017, MED PHYS, V44, pe360, DOI 10.1002/mp.12344; Knoll F, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190007; Kudo A, 2019, LECT NOTES COMPUT SC, V11905, P91, DOI 10.1007/978-3-030-33843-5_9; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Lee D, 2017, I S BIOMED IMAGING, P15, DOI 10.1109/ISBI.2017.7950457; Lee H, 2017, J DIGIT IMAGING, V30, P427, DOI 10.1007/s10278-017-9955-8; Lee JG, 2017, KOREAN J RADIOL, V18, P570, DOI 10.3348/kjr.2017.18.4.570; Lei Y, 2019, MED PHYS, V46, P3565, DOI 10.1002/mp.13617; Leuschner J, ARXIV191001113; Liang D, ARXIV190711711; Liu F, 2019, MAGN RESON MED, V81, P3330, DOI 10.1002/mrm.27627; Liu F, 2018, RADIOLOGY, V289, P160, DOI 10.1148/radiol.2018172986; Liu F, 2018, MAGN RESON MED, V79, P2379, DOI 10.1002/mrm.26841; Liu F, 2018, RADIOLOGY, V286, P676, DOI 10.1148/radiol.2017170700; Lustig M, 2008, IEEE SIGNAL PROC MAG, V25, P72, DOI 10.1109/MSP.2007.914728; Lustig M, 2007, MAGN RESON MED, V58, P1182, DOI 10.1002/mrm.21391; Mardani M, 2019, IEEE T MED IMAGING, V38, P167, DOI 10.1109/TMI.2018.2858752; Maspero M, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aada6d; Miller TT, 2008, RADIOLOGY, V246, P662, DOI 10.1148/radiol.2463061038; Nie Dong, 2017, Med Image Comput Comput Assist Interv, V10435, P417, DOI 10.1007/978-3-319-66179-7_48; Odena A., 2016, DISTILL, V1, DOI [10.23915/distill.00003, DOI 10.23915/DISTILL.00003]; PfauD, ARXIV161001945; Radford A., 2015, ARXIV PREPR ARXIV151; Ravishankar S, 2011, IEEE T MED IMAGING, V30, P1028, DOI 10.1109/TMI.2010.2090538; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Russ T, 2019, INT J COMPUT ASS RAD, V14, P1741, DOI 10.1007/s11548-019-02042-9; Salimans T, 2016, ADV NEUR IN, V29; Schlegl T, 2017, LECT NOTES COMPUT SC, V10265, P146, DOI 10.1007/978-3-319-59050-9_12; Schlemper J, 2018, IEEE T MED IMAGING, V37, P491, DOI 10.1109/TMI.2017.2760978; Sekuboyina A, 2018, LECT NOTES COMPUT SC, V11073, P649, DOI 10.1007/978-3-030-00937-3_74; Simonyan K, ARXIV14091556 PREPRI; Stajduhar I, 2017, COMPUT METH PROG BIO, V140, P151, DOI 10.1016/j.cmpb.2016.12.006; Tanenbaum LN, 2017, AM J NEURORADIOL, V38, P1103, DOI 10.3174/ajnr.A5227; Tang J, 2009, PHYS MED BIOL, V54, P5781, DOI 10.1088/0031-9155/54/19/008; Tang YB, 2018, LECT NOTES COMPUT SC, V11046, P46, DOI 10.1007/978-3-030-00919-9_6; Tiulpin A, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-20132-7; Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7; Quan TM, 2018, IEEE T MED IMAGING, V37, P1488, DOI 10.1109/TMI.2018.2820120; Quan TM, 2016, I S BIOMED IMAGING, P518, DOI 10.1109/ISBI.2016.7493321; von Schacky CE, 2020, RADIOLOGY, V295, P136, DOI 10.1148/radiol.2020190925; Wang SS, 2016, I S BIOMED IMAGING, P514, DOI 10.1109/ISBI.2016.7493320; Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917; Watanabe Haruna, 2019, 2019 IEEE 1st Global Conference on Life Sciences and Technologies (LifeTech), P235, DOI 10.1109/LifeTech.2019.8883999; Wolterink JM., 2017, DEEP MR CT SYNTHESIS, P14, DOI [10.1007/978-3-319-68127-6_2, DOI 10.1007/978-3-319-68127-6_2]; Wu WY, 2019, PROC CVPR IEEE, P8004, DOI 10.1109/CVPR.2019.00820; Xue Y, 2018, NEUROINFORMATICS, V16, P383, DOI 10.1007/s12021-018-9377-x; Yang G, 2018, IEEE T MED IMAGING, V37, P1310, DOI 10.1109/TMI.2017.2785879; Yang QS, 2018, IEEE T MED IMAGING, V37, P1348, DOI 10.1109/TMI.2018.2827462; Yang Y, 2016, ADV NEUR IN, V29; Yi J, 2018, KOREAN J RADIOL, V19, P311, DOI 10.3348/kjr.2018.19.2.311; Yi X, 2018, J DIGIT IMAGING, V31, P655, DOI 10.1007/s10278-018-0056-0; Ying XD, 2019, PROC CVPR IEEE, P10611, DOI 10.1109/CVPR.2019.01087; You CY, 2020, IEEE T MED IMAGING, V39, P188, DOI 10.1109/TMI.2019.2922960; You CY, 2018, IEEE ACCESS, V6, P41839, DOI 10.1109/ACCESS.2018.2858196; Zbontar J, ARXIV181108839; Zhou ZY, 2018, MAGN RESON MED, V80, P2759, DOI 10.1002/mrm.27229; Zhu B, 2018, NATURE, V555, P487, DOI 10.1038/nature25988; Zhu Jun-Yan, 2017, ICCV	95	6	6	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2021	3	3							e200157	10.1148/ryai.2021200157	http://dx.doi.org/10.1148/ryai.2021200157			16	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SA		Green Published, Green Submitted			2022-12-18	WOS:000826907000004
J	Kustner, T; Hepp, T; Fischer, M; Schwartz, M; Fritsche, A; Haring, HU; Nikolaou, K; Bamberg, F; Yang, B; Schick, F; Gatidis, S; Machann, J				Kuestner, Thomas; Hepp, Tobias; Fischer, Marc; Schwartz, Martin; Fritsche, Andreas; Haering, Hans-Ulrich; Nikolaou, Konstantin; Bamberg, Fabian; Yang, Bin; Schick, Fritz; Gatidis, Sergios; Machann, Juergen			Fully Automated and Standardized Segmentation of Adipose Tissue Compartments via Deep Learning in 3D Whole-Body MRI of Epidemiologic Cohort Studies	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To enable fast and reliable assessment of subcutaneous and visceral adipose tissue compartments derived from whole-body MRI. Materials and Methods: Quantification and localization of different adipose tissue compartments derived from whole-body MR images is of high interest in research concerning metabolic conditions. For correct identification and phenotyping of individuals at increased risk for metabolic diseases, a reliable automated segmentation of adipose tissue into subcutaneous and visceral adipose tissue is required. In this work, a three-dimensional (3D) densely connected convolutional neural network (DCNet) is proposed to provide robust and objective segmentation. In this retrospective study, 1000 cases (average age, 66 years +/- 13 [standard deviation]; 523 women) from the Tuebingen Family Study database and the German Center for Diabetes research database and 300 cases (average age, 53 years +/- 11; 152 women) from the German National Cohort (NAKO) database were collected for model training, validation, and testing, with transfer learning between the cohorts. These datasets included variable imaging sequences, imaging contrasts, receiver coil arrangements, scanners, and imaging field strengths. The proposed DCNet was compared to a similar 3D U-Net segmentation in terms of sensitivity, specificity, precision, accuracy, and Dice overlap. Results: Fast (range, 5-7 seconds) and reliable adipose tissue segmentation can be performed with high Dice overlap (0.94), sensitivity (96.6%), specificity (95.1%), precision (92.1%), and accuracy (98.4%) from 3D whole-body MRI datasets (field of view coverage, 450 x 450 x 2000 mm). Segmentation masks and adipose tissue profiles are automatically reported back to the referring physician. Conclusion: Automated adipose tissue segmentation is feasible in 3D whole-body MRI datasets and is generalizable to different epidemiologic cohort studies with the proposed DCNet. (C) RSNA, 2020	[Kuestner, Thomas; Hepp, Tobias; Fischer, Marc; Nikolaou, Konstantin; Gatidis, Sergios] Univ Hosp Tubingen, Dept Diagnost & Intervent Radiol Med Image & Data, Hoppe Seyler Str 3, D-72076 Tubingen, Germany; [Kuestner, Thomas; Fischer, Marc; Schwartz, Martin; Yang, Bin] Univ Stuttgart, Dept Signal Proc & Syst Theory, Stuttgart, Germany; [Kuestner, Thomas] St Thomas Hosp, Kings Coll London, Sch Biomed Engn & Imaging Sci, London, England; [Hepp, Tobias] Max Planck Inst Intelligent Syst, Dept Empir Inference, Tubingen, Germany; [Fischer, Marc; Schwartz, Martin; Schick, Fritz; Machann, Juergen] Univ Hosp Tubingen, Sect Expt Radiol, Dept Diagnost & Intervent Radiol, Tubingen, Germany; [Fritsche, Andreas] Eberhard Karls Univ Tubingen, Dept Internal Med 4, Tubingen, Germany; [Fritsche, Andreas; Schick, Fritz; Machann, Juergen] Univ Tubingen, Inst Diabet Res & Metab Dis Helmholtz Zentrum Man, Tubingen, Germany; [Fritsche, Andreas; Haering, Hans-Ulrich; Schick, Fritz; Machann, Juergen] German Ctr Diabet Res DZD, Tubingen, Germany; [Bamberg, Fabian] Univ Freiburg, Med Ctr, Fac Med, Dept Diagnost & Intervent Radiol, Freiburg, Germany		Kustner, T (corresponding author), Univ Hosp Tubingen, Dept Diagnost & Intervent Radiol Med Image & Data, Hoppe Seyler Str 3, D-72076 Tubingen, Germany.; Kustner, T (corresponding author), St Thomas Hosp, Kings Coll London, Sch Biomed Engn & Imaging Sci, London, England.	thomas.kuestner@med.uni-tuebingen.de	Schwartz, Martin/AGE-0051-2022; Gatidis, Sergios/AAF-4858-2020	Gatidis, Sergios/0000-0002-6928-4967; Schick, Fritz/0000-0002-4231-3406; Kustner, Thomas/0000-0002-0353-4898	German Federal Ministry of Education and Research (BMBF) [01GI0925]; Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)	German Federal Ministry of Education and Research (BMBF)(Federal Ministry of Education & Research (BMBF)); Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)(German Research Foundation (DFG))	Supported in part by a grant (01GI0925) from the German Federal Ministry of Education and Research (BMBF) to the German Center for Diabetes Research (DZD e.V.) and by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation).	Addeman BT, 2015, J MAGN RESON IMAGING, V41, P233, DOI 10.1002/jmri.24526; Artham Surya M, 2008, J Cardiometab Syndr, V3, P155, DOI 10.1111/j.1559-4572.2008.00001.x; Bai WJ, 2018, J CARDIOVASC MAGN R, V20, DOI 10.1186/s12968-018-0471-x; Bamberg F, 2015, RADIOLOGY, V277, P206, DOI 10.1148/radiol.2015142272; Borga M, 2018, J INVEST MED, V66, P887, DOI 10.1136/jim-2018-000722; Borga M, 2018, BRIT J RADIOL, V91, DOI 10.1259/bjr.20180252; Cicek Ozgun, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P424, DOI 10.1007/978-3-319-46723-8_49; Criminisil A, 2011, FOUND TRENDS COMPUT, V7, P81, DOI [10.1561/0600000035, 10.1501/0000000035]; de Vos BD, 2016, PROC SPIE, V9784, DOI 10.1117/12.2216971; DIXON WT, 1984, RADIOLOGY, V153, P189, DOI 10.1148/radiology.153.1.6089263; Doyle SL, 2012, P NUTR SOC, V71, P181, DOI 10.1017/S002966511100320X; Estrada S, 2020, MAGN RESON MED, V83, P1471, DOI 10.1002/mrm.28022; Iglesias JE, 2015, MED IMAGE ANAL, V24, P205, DOI 10.1016/j.media.2015.06.012; Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004; He K., 2016, PROC IEEE C COMPUTER, P770, DOI DOI 10.1109/CVPR.2016.90; Heimann T, 2009, MED IMAGE ANAL, V13, P543, DOI 10.1016/j.media.2009.05.004; Hu H, 2016, MAGN RESON MATER PHY, V29, P259, DOI 10.1007/s10334-015-0498-z; Huang G., ARXIV160806993; Ibtehaz N, ARXIV190204049; Karlsson A, 2015, J MAGN RESON IMAGING, V41, P1558, DOI 10.1002/jmri.24726; KISSEBAH AH, 1982, J CLIN ENDOCR METAB, V54, P254, DOI 10.1210/jcem-54-2-254; KROTKIEWSKI M, 1983, J CLIN INVEST, V72, P1150, DOI 10.1172/JCI111040; Kurioka S, 2002, ENDOCR J, V49, P459, DOI 10.1507/endocrj.49.459; Langner T, 2019, MAGN RESON MED, V81, P2736, DOI 10.1002/mrm.27550; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Linge J, 2019, OBESITY, V27, P1190, DOI 10.1002/oby.22510; Linge J, 2018, OBESITY, V26, P1785, DOI 10.1002/oby.22210; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Machann J, 2005, J MAGN RESON IMAGING, V21, P455, DOI 10.1002/jmri.20292; Machann J, 2010, RADIOLOGY, V257, P353, DOI 10.1148/radiol.10092284; Milletari F, ARXIVE PRINTS; Moeskops P, 2016, IEEE T MED IMAGING, V35, P1252, DOI 10.1109/TMI.2016.2548501; OHLSON LO, 1985, DIABETES, V34, P1055, DOI 10.2337/diabetes.34.10.1055; Payer Christian, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P230, DOI 10.1007/978-3-319-46723-8_27; Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465; Qin WJ, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aabd19; Reeder SB, 2012, J MAGN RESON IMAGING, V36, P1011, DOI 10.1002/jmri.23741; Ronneberger O, LECT NOTES COMPUTER; Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI 10.1146/annurev-bioeng-071516-044442; Vaswani A., 2017, P 31 INT C NEUR INF, P5998, DOI DOI 10.5555/3295222.3295349; Vovk U, 2007, IEEE T MED IMAGING, V26, P405, DOI 10.1109/TMI.2006.891486; Wurslin C, 2010, J MAGN RESON IMAGING, V31, P430, DOI 10.1002/jmri.22036; Yang D, 2015, I S BIOMED IMAGING, P17, DOI 10.1109/ISBI.2015.7163806; Yu F., ARXIV151107122; Yu HZ, 2008, MAGN RESON MED, V60, P1122, DOI 10.1002/mrm.21737; Zhang WL, 2015, NEUROIMAGE, V108, P214, DOI 10.1016/j.neuroimage.2014.12.061; Zhao L, ARXIV161107718	47	6	6	1	2	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2020	2	6							e200010	10.1148/ryai.2020200010	http://dx.doi.org/10.1148/ryai.2020200010			13	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CZ	33937847	Green Published			2022-12-18	WOS:000826480100008
J	Chokshi, FH; Flanders, AE; Prevedello, LM; Langlotz, CP				Chokshi, Falgun H.; Flanders, Adam E.; Prevedello, Luciano M.; Langlotz, Curtis P.			Fostering a Healthy AI Ecosystem for Radiology: Conclusions of the 2018 RSNA Summit on AI in Radiology	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								The 2018 RSNA Summit on AI in Radiology brought together a diverse group of stakeholders to identify and prioritize areas of need related to artificial intelligence in radiology. This article presents the proceedings of the summit with emphasis on RSNA's role in leading, organizing, and catalyzing change during this important time in radiology. (C) RSNA, 2019	[Chokshi, Falgun H.] Emory Univ, Sch Med, Dept Radiol & Imaging Sci, 1364 Clifton Rd NE, Atlanta, GA 30322 USA; [Chokshi, Falgun H.] Emory Univ, Sch Med, Dept Biomed Informat, 1364 Clifton Rd NE, Atlanta, GA 30322 USA; [Flanders, Adam E.] Thomas Jefferson Univ Hosp, Dept Radiol, Philadelphia, PA 19107 USA; [Prevedello, Luciano M.] Ohio State Univ, Dept Radiol, Wexner Med Ctr, Columbus, OH 43210 USA; [Langlotz, Curtis P.] Stanford Univ, Sch Med, Dept Radiol, Stanford, CA 94305 USA; [Langlotz, Curtis P.] Stanford Univ, Sch Med, Dept Biomed Informat, Stanford, CA 94305 USA		Chokshi, FH (corresponding author), Emory Univ, Sch Med, Dept Radiol & Imaging Sci, 1364 Clifton Rd NE, Atlanta, GA 30322 USA.; Chokshi, FH (corresponding author), Emory Univ, Sch Med, Dept Biomed Informat, 1364 Clifton Rd NE, Atlanta, GA 30322 USA.	falgun.chokshi@emory.edu		Flanders, Adam/0000-0002-4679-0787; Langlotz, Curtis/0000-0002-8972-8051; Prevedello, Luciano/0000-0002-6768-6452				Abujudeh HH, 2010, RADIOGRAPHICS, V30, P571, DOI 10.1148/rg.303095761; [Anonymous], 2018, NATL IMAGING INFORM; Cath C, 2018, SCI ENG ETHICS, V24, P505, DOI 10.1007/s11948-017-9901-7; Chan S, 2019, BRIT J RADIOL, V92, DOI 10.1259/bjr.20180416; Chang K, 2018, J AM MED INFORM ASSN, V25, P945, DOI 10.1093/jamia/ocy017; Chartrand G, 2017, RADIOGRAPHICS, V37, P2113, DOI 10.1148/rg.2017170077; Choy G, 2018, RADIOLOGY, V288, P318, DOI 10.1148/radiol.2018171820; Desai V, 2018, SEMIN MUSCULOSKEL R, V22, P528, DOI 10.1055/s-0038-1673385; Erickson BJ, 2017, RADIOGRAPHICS, V37, P505, DOI 10.1148/rg.2017160130; Flanders AE, 2019, AM J NEURORADIOL, V40, P14, DOI 10.3174/ajnr.A5780; Halabi SS, 2019, RADIOLOGY, V290, P498, DOI 10.1148/radiol.2018180736; Handelman GS, 2019, AM J ROENTGENOL, V212, P38, DOI 10.2214/AJR.18.20224; Harrington SG, 2019, J AM COLL RADIOL, V16, P743, DOI 10.1016/j.jacr.2018.09.057; Harvey HB, 2018, J AM COLL RADIOL, V15, P1000, DOI 10.1016/j.jacr.2018.04.006; Kahn CE, 2009, RADIOLOGY, V252, P852, DOI 10.1148/radiol.2523081992; Karami Mahtab, 2014, Acta Inform Med, V22, P341, DOI 10.5455/aim.2014.22.341-346; Kohli M, 2018, J AM COLL RADIOL, V15, P1317, DOI 10.1016/j.jacr.2018.05.020; Kruskal JB, 2017, J AM COLL RADIOL, V14, P811, DOI 10.1016/j.jacr.2017.02.019; Lakhani P, 2018, J AM COLL RADIOL, V15, P350, DOI 10.1016/j.jacr.2017.09.044; Langlotz CP, 2006, RADIOGRAPHICS, V26, P1595, DOI 10.1148/rg.266065168; Larson DB, 2018, RADIOLOGY, V287, P313, DOI 10.1148/radiol.2017170236; Mazurowski MA, 2019, J MAGN RESON IMAGING, V49, P939, DOI 10.1002/jmri.26534; Morgan TA, 2014, RADIOLOGY, V273, P642, DOI 10.1148/radiol.14141227; Pesapane F, 2018, INSIGHTS IMAGING, V9, P745, DOI 10.1007/s13244-018-0645-y; Prevedello LM, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180031; Rubin DL, 2008, J DIGIT IMAGING, V21, P355, DOI 10.1007/s10278-007-9073-0; Rubin DL, 2017, RADIOLOGY, V283, P836, DOI 10.1148/radiol.2016161553; Shih G, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180041; Tabaie Azade, 2018, Annu Int Conf IEEE Eng Med Biol Soc, V2018, P3256, DOI 10.1109/EMBC.2018.8513076; Vreeman DJ, 2018, J AM MED INFORM ASSN, V25, P885, DOI 10.1093/jamia/ocy053; Wood MJ, 2019, J AM COLL RADIOL, V16, P740, DOI 10.1016/j.jacr.2018.10.008; Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319	33	6	6	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2019	1	2							e190021	10.1148/ryai.2019190021	http://dx.doi.org/10.1148/ryai.2019190021			6	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CM	33937789	Green Published			2022-12-18	WOS:000826288900005
J	Yu, AC; Mohajer, B; Eng, J				Yu, Alice C.; Mohajer, Bahram; Eng, John			External Validation of Deep Learning Algorithms for Radiologic Diagnosis: A Systematic Review	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Review						Meta-Analysis; Computer Applications-Detection/Diagnosis; Neural Networks; Computer Applications-General (Informatics); Epidemiology; Technology Assessment; Diagnosis; Informatics	CHEST RADIOGRAPHS; CLINICAL-RESEARCH; MODEL; CLASSIFICATION; PERFORMANCE; PROGNOSIS; DISEASE	Purpose: To assess generalizability of published deep learning (DL) algorithms for radiologic diagnosis. Materials and Methods: In this systematic review, the PubMed database was searched for peer-reviewed studies of DL algorithms for image-based radiologic diagnosis that included external validation, published from January 1, 2015, through April 1, 2021. Studies using nonimaging features or incorporating non-DL methods for feature extraction or classification were excluded. Two reviewers independently evaluated studies for inclusion, and any discrepancies were resolved by consensus. Internal and external performance measures and pertinent study characteristics were extracted, and relationships among these data were examined using nonparametric statistics. Results: Eighty-three studies reporting 86 algorithms were included. The vast majority (70 of 86, 81%) reported at least some decrease in external performance compared with internal performance, with nearly half (42 of 86, 49%) reporting at least a modest decrease (>0.05 on the unit scale) and nearly a quarter (21 of 86, 24%) reporting a substantial decrease (>0.10 on the unit scale). No study characteristics were found to be associated with the difference between internal and external performance. Conclusion: Among published external validation studies of DL algorithms for image-based radiologic diagnosis, the vast majority demonstrated diminished algorithm performance on the external dataset, with some reporting a substantial performance decrease. Supplemental material is available for this article. (C) RSNA, 2022.	[Yu, Alice C.; Mohajer, Bahram; Eng, John] Johns Hopkins Univ, Russell H Morgan Dept Radiol & Radiol Sci, Sch Med, 1800 Orleans St, Baltimore, MD 21287 USA	Johns Hopkins University	Eng, J (corresponding author), Johns Hopkins Univ, Russell H Morgan Dept Radiol & Radiol Sci, Sch Med, 1800 Orleans St, Baltimore, MD 21287 USA.	jeng@jhmi.edu		Mohajer, Bahram/0000-0001-6398-8448; Eng, John/0000-0002-9129-5160				Anderson TS, 2020, JAMA INTERN MED, V180, P795, DOI 10.1001/jamainternmed.2020.0051; [Anonymous], 2018, NATURE, V555, P285, DOI 10.1038/d41586-018-03067-x; Bae JB, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-79243-9; Balki I, 2019, CAN ASSOC RADIOL J, V70, P344, DOI 10.1016/j.carj.2019.06.002; Becker AS, 2017, INVEST RADIOL, V52, P434, DOI 10.1097/RLI.0000000000000358; Bien N, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002699; Blackmore CC, 2001, AM J ROENTGENOL, V176, P327, DOI 10.2214/ajr.176.2.1760327; Bluemke DA, 2020, RADIOLOGY, V294, P487, DOI 10.1148/radiol.2019192515; Bluthgen C, 2020, EUR J RADIOL, V126, DOI 10.1016/j.ejrad.2020.108925; Bo ZH, 2021, PATTERNS, V2, DOI 10.1016/j.patter.2020.100197; Bossuyt PM, 2015, BMJ-BRIT MED J, V351, DOI [10.1148/radiol.2015151516, 10.1136/bmj.h5527, 10.1373/clinchem.2015.246280]; Chang K, 2018, CLIN CANCER RES, V24, P1073, DOI 10.1158/1078-0432.CCR-17-2236; Chee CG, 2019, AM J ROENTGENOL, V213, P155, DOI 10.2214/AJR.18.20817; Chen Xi, 2020, Neurooncol Adv, V2, pvdaa079, DOI 10.1093/noajnl/vdaa079; Cheng JT, 2020, SCI REP-UK, V10, DOI [10.1038/s41598-020-62884-1, 10.1038/s41598-020-76282-0]; Chilamkurthy S, 2018, LANCET, V392, P2388, DOI 10.1016/S0140-6736(18)31645-3; Choi JW, 2020, INVEST RADIOL, V55, P101, DOI 10.1097/RLI.0000000000000615; Choi KJ, 2018, RADIOLOGY, V289, P688, DOI 10.1148/radiol.2018180763; Ciritsis A, 2019, EUR RADIOL, V29, P5458, DOI 10.1007/s00330-019-06118-7; Cole SR, 2010, AM J EPIDEMIOL, V172, P107, DOI 10.1093/aje/kwq084; Collins GS, 2015, ANN INTERN MED, V162, P55, DOI [10.7326/M14-0697, 10.1038/bjc.2014.639, 10.1161/CIRCULATIONAHA.114.014508, 10.1186/s12916-014-0241-z, 10.1002/bjs.9736, 10.7326/M14-0698, 10.1016/j.jclinepi.2014.11.010, 10.1136/bmj.g7594, 10.1016/j.eururo.2014.11.025]; Cui SJ, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-70629-3; Decuyper M, 2021, COMPUT MED IMAG GRAP, V88, DOI 10.1016/j.compmedimag.2020.101831; Ding Y, 2019, RADIOLOGY, V290, P456, DOI 10.1148/radiol.2018180958; Dou Q, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00431-6; Eng J, 2004, ACAD RADIOL, V11, P149, DOI 10.1016/S1076-6332(03)00652-4; England JR, 2019, AM J ROENTGENOL, V212, P513, DOI 10.2214/AJR.18.20490; Futoma J, 2020, LANCET DIGIT HEALTH, V2, pE489, DOI 10.1016/S2589-7500(20)30186-2; Gao K, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101836; Gao X, 2020, DIAGN INTERV IMAG, V101, P91, DOI 10.1016/j.diii.2019.07.002; Gonzalez G, 2018, AM J RESP CRIT CARE, V197, P193, DOI 10.1164/rccm.201705-0860OC; Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216; Harmon SA, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17971-2; He Y, 2020, EBIOMEDICINE, V62, DOI 10.1016/j.ebiom.2020.103121; Huang SC, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00310-6; Hwang EJ, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.1095; Hwang EJ, 2019, CLIN INFECT DIS, V69, P739, DOI 10.1093/cid/ciy967; Jin C, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-18685-1; Joo B, 2020, EUR RADIOL, V30, P5785, DOI 10.1007/s00330-020-06966-8; Kann BH, 2020, J CLIN ONCOL, V38, P1304, DOI 10.1200/JCO.19.02031; Kaufman S, 2012, ACM T KNOWL DISCOV D, V6, DOI 10.1145/2382577.2382579; Kennedy-Martin T, 2015, TRIALS, V16, DOI 10.1186/s13063-015-1023-4; Kim DW, 2019, KOREAN J RADIOL, V20, DOI 10.3348/kjr.2019.0025; Kim T, 2019, EBIOMEDICINE, V40, P636, DOI 10.1016/j.ebiom.2018.12.043; Kim Y, 2019, INVEST RADIOL, V54, P7, DOI 10.1097/RLI.0000000000000503; Kitamura G, 2020, CLIN IMAG, V61, P15, DOI 10.1016/j.clinimag.2020.01.008; Koh J, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-72270-6; KRAMER MS, 1984, JAMA-J AM MED ASSOC, V252, P2739, DOI 10.1001/jama.252.19.2739; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Kuo WC, 2019, P NATL ACAD SCI USA, V116, P22737, DOI 10.1073/pnas.1908021116; Kwon Gitaek, 2020, Sci Rep, V10, P17582, DOI 10.1038/s41598-020-74653-1; Lee JH, 2020, EUR RADIOL, V30, P3066, DOI 10.1007/s00330-019-06652-4; Lee JH, 2020, EUR RADIOL, V30, P1264, DOI 10.1007/s00330-019-06407-1; Lee KJ, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0241796; Lessmann N, 2021, RADIOLOGY, V298, pE18, DOI 10.1148/radiol.2020202439; Li XC, 2019, LANCET ONCOL, V20, P193, DOI 10.1016/S1470-2045(18)30762-9; Li XC, 2020, ARTIF INTELL MED, V103, DOI 10.1016/j.artmed.2019.101744; Lin F, 2020, EUR J RADIOL, V129, DOI 10.1016/j.ejrad.2020.109079; Maruyama T, 2018, J X-RAY SCI TECHNOL, V26, P885, DOI 10.3233/XST-18386; Massion PP, 2020, AM J RESP CRIT CARE, V202, P241, DOI 10.1164/rccm.201903-0505OC; Mongan J, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020200029; Moreno-Torres JG, 2012, PATTERN RECOGN, V45, P521, DOI 10.1016/j.patcog.2011.06.019; Nael K, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-86022-7; Nam JG, 2021, EUR RESPIR J, V57, DOI 10.1183/13993003.03061-2020; Nam JG, 2019, RADIOLOGY, V290, P218, DOI 10.1148/radiol.2018180237; Nature Portfolio, REP STAND AV DAT MAT; Nguyen AV, 2018, NEUROSURG FOCUS, V45, DOI 10.3171/2018.8.FOCUS18325; Pan I, 2019, AM J ROENTGENOL, V213, P568, DOI 10.2214/AJR.19.21512; Pan I, 2019, J DIGIT IMAGING, V32, P888, DOI 10.1007/s10278-019-00180-9; Park JJ, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-66674-7; Park SH, 2019, RADIOLOGY, V290, P272, DOI 10.1148/radiol.2018182294; Park SH, 2018, RADIOLOGY, V286, P800, DOI 10.1148/radiol.2017171920; Peng J, 2020, EUR RADIOL, V30, P413, DOI 10.1007/s00330-019-06318-1; Rajpurkar P, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002686; Remedios SW, 2020, MED PHYS, V47, P89, DOI 10.1002/mp.13880; Rothwell PM, 2006, PLOS CLIN TRIALS, V1, DOI 10.1371/journal.pctr.0010009; Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x; Rueckel J, 2020, CRIT CARE MED, V48, pE574, DOI 10.1097/CCM.0000000000004397; Salvatore C, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11030530; Schaffter T, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.0265; Shi Z, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-19527-w; Shin DH, 2021, PARKINSONISM RELAT D, V85, P84, DOI 10.1016/j.parkreldis.2021.03.004; Shin I, 2021, AM J NEURORADIOL, V42, P838, DOI 10.3174/ajnr.A7003; Singh R, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0204155; Song J, 2019, MEDICINE, V98, DOI 10.1097/MD.0000000000015133; Song ZB, 2021, EUR J NUCL MED MOL I, V48, P361, DOI 10.1007/s00259-020-04986-6; Suzuki K, 2022, ACAD RADIOL, V29, pS11, DOI 10.1016/j.acra.2020.07.030; Tang LYW, 2020, LANCET DIGIT HEALTH, V2, pE259, DOI 10.1016/S2589-7500(20)30064-9; Tang YX, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0273-z; Taylor AG, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002697; von Schacky CE, 2020, RADIOLOGY, V295, P136, DOI 10.1148/radiol.2020190925; Walsh SLF, 2018, LANCET RESP MED, V6, P837, DOI 10.1016/S2213-2600(18)30286-8; Wang HK, 2017, EJNMMI RES, V7, DOI 10.1186/s13550-017-0260-9; Wang MH, 2020, LANCET DIGIT HEALTH, V2, pE506, DOI 10.1016/S2589-7500(20)30199-0; Wang S, 2020, EUR RESPIR J, V56, DOI 10.1183/13993003.00775-2020; Wang S, 2019, EUR RESPIR J, V53, DOI 10.1183/13993003.00986-2018; Wang XQ, 2020, J AM COLL RADIOL, V17, P796, DOI 10.1016/j.jacr.2020.01.006; Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369; Weikert T, 2020, KOREAN J RADIOL, V21, P891, DOI 10.3348/kjr.2019.0653; Whiting PF, 2011, ANN INTERN MED, V155, P529, DOI 10.7326/0003-4819-155-8-201110180-00009; Wu JY, 2019, MED PHYS, V46, P5544, DOI 10.1002/mp.13739; Wu N, 2020, IEEE T MED IMAGING, V39, P1184, DOI 10.1109/TMI.2019.2945514; Wu QX, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.11625; Xia XW, 2020, FRONT ONCOL, V10, DOI 10.3389/fonc.2020.00418; Xiao LS, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.00898; Xie QC, 2021, EUR RADIOL, V31, P3864, DOI 10.1007/s00330-020-07553-7; Xu XY, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101772; Yao AD, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190026; Yap MH, 2018, IEEE J BIOMED HEALTH, V22, P1218, DOI 10.1109/JBHI.2017.2731873; Yu AC, 2020, RADIOGRAPHICS, V40, P1932, DOI 10.1148/rg.2020200040; Yun J, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-42276-w; Zech JR, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002683; Zhang C, 2019, ONCOLOGIST, V24, P1159, DOI 10.1634/theoncologist.2018-0908; Zhao W, 2019, CANCER MED-US, V8, P3532, DOI 10.1002/cam4.2233; Zhao XY, 2020, EBIOMEDICINE, V56, DOI 10.1016/j.ebiom.2020.102780; Zhou LQ, 2020, RADIOLOGY, V294, P19, DOI 10.1148/radiol.2019190372; Zhou M, 2021, ANN TRANSL MED, V9, DOI 10.21037/atm-20-5328; Zhou QQ, 2021, EUR RADIOL, V31, P3815, DOI 10.1007/s00330-020-07418-z; Zou XL, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0236378	119	5	5	5	5	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2022	4	3							e210064	10.1148/ryai.210064	http://dx.doi.org/10.1148/ryai.210064			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9YQ	35652114	Green Published			2022-12-18	WOS:000826924200001
J	Rauschecker, AM; Gleason, TJ; Nedelec, P; Duong, MT; Weiss, DA; Calabrese, E; Colby, JB; Sugrue, LP; Rudie, JD; Hess, CP				Rauschecker, Andreas M.; Gleason, Tyler J.; Nedelec, Pierre; Duong, Michael Tran; Weiss, David A.; Calabrese, Evan; Colby, John B.; Sugrue, Leo P.; Rudie, Jeffrey D.; Hess, Christopher P.			Interinstitutional Portability of a Deep Learning Brain MRI Lesion Segmentation Algorithm	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Neural Networks; Brain/Brain Stem; Segmentation		Purpose: To assess how well a brain MRI lesion segmentation algorithm trained at one institution performed at another institution, and to assess the effect of multi-institutional training datasets for mitigating performance loss. Materials and Methods: In this retrospective study, a three-dimensional U-Net for brain MRI abnormality segmentation was trained on data from 293 patients from one institution (IN1) (median age, 54 years; 165 women; patients treated between 2008 and 2018) and tested on data from 51 patients from a second institution (IN2) (median age, 46 years; 27 women; patients treated between 2003 and 2019). The model was then trained on additional data from various sources: (a) 285 multi-institution brain tumor segmentations, (b) 198 IN2 brain tumor segmentations, and (c) 34 IN2 lesion segmentations from various brain pathologic conditions. All trained models were tested on IN1 and external IN2 test datasets, assessing segmentation performance using Dice coefficients. Results: The U-Net accurately segmented brain MRI lesions across various pathologic conditions. Performance was lower when tested at an external institution (median Dice score, 0.70 [IN2] vs 0.76 [IN1]). Addition of 483 training cases of a single pathologic condition, including from IN2, did not raise performance (median Dice score, 0.72; P =.10). Addition of IN2 training data with heterogeneous pathologic features, representing only 10% (34 of 329) of total training data, increased performance to baseline (Dice score, 0.77; P<.001). This final model produced total lesion volumes with a high correlation to the reference standard (Spearman r = 0.98). Conclusion: For brain MRI lesion segmentation, adding a modest amount of relevant training data from an external institution to a previously trained model supported successful application of the model to this external institution. (C) RSNA, 2021	[Rauschecker, Andreas M.; Gleason, Tyler J.; Nedelec, Pierre; Weiss, David A.; Calabrese, Evan; Colby, John B.; Sugrue, Leo P.; Rudie, Jeffrey D.; Hess, Christopher P.] Univ Calif San Francisco, Dept Radiol & Biomed Imaging, 513 Parnassus Ave,Room S-261,Box 0628, San Francisco, CA 94143 USA; [Duong, Michael Tran; Weiss, David A.] Hosp Univ Penn, Dept Radiol, 3400 Spruce St, Philadelphia, PA 19104 USA	University of California System; University of California San Francisco; University of Pennsylvania; Pennsylvania Medicine	Rauschecker, AM (corresponding author), Univ Calif San Francisco, Dept Radiol & Biomed Imaging, 513 Parnassus Ave,Room S-261,Box 0628, San Francisco, CA 94143 USA.	andreas.rauschecker@ucsf.edu		Nedelec, Pierre/0000-0002-8535-1541; Rudie, Jeffrey/0000-0001-8609-8421; Rauschecker, Andreas/0000-0003-0633-9876; Weiss, David/0000-0002-7494-2987; Duong, Michael Tran/0000-0003-0312-5530; Hess, Christopher/0000-0002-5132-5302; Calabrese, Evan/0000-0002-1464-0354	American Society of Neuroradiology trainee research award; National Institutes of Health T-32 institutional training grant [T32EB001631-14]; Carestream Health/RSNA Research Scholar Grant; RSNA Research & Education (RE) Foundation [RSCH2025]	American Society of Neuroradiology trainee research award; National Institutes of Health T-32 institutional training grant(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Carestream Health/RSNA Research Scholar Grant; RSNA Research & Education (RE) Foundation	A.M.R. supported by an American Society of Neuroradiology trainee research award, a National Institutes of Health T-32 institutional training grant (T32EB001631-14), and a Carestream Health/RSNA Research Scholar Grant. The project described was supported by RSNA Research & Education (R&E) Foundation, through grant number RSCH2025. The content is solely the responsibility of the authors and does not necessarily represent the official views of the RSNA R&E Foundation.	Abadi M., TENSORFLOW LARGE SCA; Bakas S, ARXIV 181102629 PREP; Beam AL, 2020, JAMA-J AM MED ASSOC, V323, P305, DOI 10.1001/jama.2019.20866; Bhuva AN, 2019, CIRC-CARDIOVASC IMAG, V12, DOI 10.1161/CIRCIMAGING.119.009214; Bruno MA, 2015, RADIOGRAPHICS, V35, P1668, DOI 10.1148/rg.2015150023; Chang K, 2018, J AM MED INFORM ASSN, V25, P945, DOI 10.1093/jamia/ocy017; DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409; Duong MT, 2019, AM J NEURORADIOL, V40, P1282, DOI 10.3174/ajnr.A6138; Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5; Langlotz CP, 2019, RADIOLOGY, V291, P781, DOI 10.1148/radiol.2019190613; Larson DB, 2020, RADIOLOGY, V295, P675, DOI 10.1148/radiol.2020192536; Onofrey JA, 2019, I S BIOMED IMAGING, P348, DOI [10.1109/isbi.2019.8759295, 10.1109/ISBI.2019.8759295]; Rauschecker AM, 2020, RADIOLOGY, V295, P626, DOI 10.1148/radiol.2020190283; Rothwell PM, 2005, LANCET, V365, P82, DOI 10.1016/S0140-6736(04)17670-8; Rudie JD, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190146; Rudie JD, 2019, FRONT COMPUT NEUROSC, V13, DOI 10.3389/fncom.2019.00084; Sheller MJ, 2019, LECT NOTES COMPUT SC, V11383, P92, DOI 10.1007/978-3-030-11723-8_9; Tustison NJ, 2010, IEEE T MED IMAGING, V29, P1310, DOI 10.1109/TMI.2010.2046908; Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015; Zech JR, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002683	20	5	5	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2022	4	1							e200152	10.1148/ryai.2021200152	http://dx.doi.org/10.1148/ryai.2021200152			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9WA	35146430	Green Published			2022-12-18	WOS:000826917400002
J	Eche, T; Schwartz, LH; Mokrane, FZ; Dercle, L				Eche, Thomas; Schwartz, Lawrence H.; Mokrane, Fatima-Zohra; Dercle, Laurent			Toward Generalizability in the Deployment of Artificial Intelligence in Radiology: Role of Computation Stress Testing to Overcome Underspecification	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Computer Applications-General; Informatics; Computer-aided Diagnosis	LUNG-CANCER DETECTION; FATTY LIVER-DISEASE; IMAGING DATA; DEEP; CT; DIAGNOSIS; CLASSIFICATION; PERFORMANCE; VALIDATION; INFARCTION	The clinical deployment of artificial intelligence (AI) applications in medical imaging is perhaps the greatest challenge facing radiology in the next decade. One of the main obstacles to the incorporation of automated AI-based decision-making tools in medicine is the failure of models to generalize when deployed across institutions with heterogeneous populations and imaging protocols. The most well-understood pitfall in developing these AI models is overfitting, which has, in part, been overcome by optimizing training protocols. However, overfitting is not the only obstacle to the success and generalizability of AI. Underspecification is also a serious impediment that requires conceptual understanding and correction. It is well known that a single AI pipeline, with prescribed training and testing sets, can produce several models with various levels of generalizability. Underspecification defines the inability of the pipeline to identify whether these models have embedded the structure of the underlying system by using a test set independent of, but distributed identically, to the training set. An underspecified pipeline is unable to assess the degree to which the models will be generalizable. Stress testing is a known tool in AI that can limit underspecification and, importantly, assure broad generalizability of AI models. However, the application of stress tests is new in radiologic applications. This report describes the concept of underspecification from a radiologist perspective, discusses stress testing as a specific strategy to overcome underspecification, and explains how stress tests could be designed in radiology-by modifying medical images or stratifying testing datasets. In the upcoming years, stress tests should become in radiology the standard that crash tests have become in the automotive industry. (C) RSNA, 2021	[Eche, Thomas; Mokrane, Fatima-Zohra] Toulouse Rangueil Hosp, Dept Radiol, Toulouse, France; [Eche, Thomas; Schwartz, Lawrence H.; Dercle, Laurent] Columbia Univ, Irving Med Ctr, NewYork Presbyterian Hosp, Dept Radiol, 622 West 168th St, New York, NY 10032 USA	CHU de Toulouse; Columbia University; NewYork-Presbyterian Hospital	Dercle, L (corresponding author), Columbia Univ, Irving Med Ctr, NewYork Presbyterian Hosp, Dept Radiol, 622 West 168th St, New York, NY 10032 USA.	ld2752@cumc.columbia.edu		Mokrane, Fatima-Zohra/0000-0003-1610-1474	Alain Rahmouni Grant (French College of Professors of Radiology); Alain Rahmouni Grant (French Society of Radiology)	Alain Rahmouni Grant (French College of Professors of Radiology); Alain Rahmouni Grant (French Society of Radiology)	T.E. funded by Alain Rahmouni Grant (grant funded by the French College of Professors of Radiology and French Society of Radiology).	Armato SG, 2020, RADIOLOGY, V297, P697, DOI 10.1148/radiol.2020203538; Bae MS, 2020, RADIOLOGY, V294, P29, DOI 10.1148/radiol.2019192339; Bahl M, 2020, RADIOLOGY, V294, P273, DOI 10.1148/radiol.2019192471; Bai HX, 2020, RADIOLOGY, V296, pE156, DOI 10.1148/radiol.2020201491; Belkin M, ARXIV 181211118; Bluemke DA, 2020, RADIOLOGY, V294, P487, DOI 10.1148/radiol.2019192515; Chang PJ, 2020, RADIOLOGY, V294, P432, DOI 10.1148/radiol.2019192527; Choi KS, 2020, RADIOLOGY, V297, P178, DOI 10.1148/radiol.2020192763; Collins GS, 2015, EUR UROL, V67, P1142, DOI 10.1016/j.eururo.2014.11.025; Dadario AMV, 2020, RADIOLOGY, V296, pE192, DOI 10.1148/radiol.2020201178; DAmour A, 2011, ARXIV; Dembrower K, 2020, RADIOLOGY, V294, P265, DOI 10.1148/radiol.2019190872; Deng F, 2020, RADIOLOGY, V295, pE1, DOI 10.1148/radiol.2020200227; Dong NQ, 2018, LECT NOTES COMPUT SC, V11071, P544, DOI 10.1007/978-3-030-00934-2_61; Elsken T, 2019, J MACH LEARN RES, V20; Eun NL, 2020, RADIOLOGY, V294, P31, DOI 10.1148/radiol.2019182718; Fahmy AS, 2020, RADIOLOGY, V294, P52, DOI 10.1148/radiol.2019190737; Folke T, ARXIV; Fort S, ARXIV 191202757 PREP; Froelich JW, 2020, RADIOLOGY, V294, P453, DOI 10.1148/radiol.2019192425; Fursevich DM, 2016, RADIOGRAPHICS, V36, P1076, DOI 10.1148/rg.2016150198; Futoma J, 2020, LANCET DIGIT HEALTH, V2, pE489, DOI 10.1016/S2589-7500(20)30186-2; Gallego AJ, 2021, IEEE T NEUR NET LEAR, V32, P4864, DOI 10.1109/TNNLS.2020.3025954; Geirhos R, 2020, NAT MACH INTELL, V2, P665, DOI 10.1038/s42256-020-00257-z; GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1; Han A, 2020, RADIOLOGY, V295, P342, DOI 10.1148/radiol.2020191160; Humphries SM, 2020, RADIOLOGY, V294, P434, DOI 10.1148/radiol.2019191022; Jacobson FL, 2020, RADIOLOGY, V294, P210, DOI 10.1148/radiol.2019192252; Jang S, 2020, RADIOLOGY, V296, P652, DOI 10.1148/radiol.2020200165; Ji GW, 2020, RADIOLOGY, V294, P568, DOI 10.1148/radiol.2020191470; Kikinis R, 2020, RADIOLOGY, V295, P416, DOI 10.1148/radiol.2020200261; Kim H, 2020, RADIOLOGY, V296, P216, DOI 10.1148/radiol.2020192764; Koh DM, 2020, RADIOLOGY, V296, P65, DOI 10.1148/radiol.2020200417; Kuhl CK, 2020, RADIOLOGY, V295, P339, DOI 10.1148/radiol.2020200059; Lafarge MW, 2019, FRONT MED-LAUSANNE, V6, DOI 10.3389/fmed.2019.00162; Lakshminarayanan B, ARXIV 161201474 PREP; Lambin P, 2017, NAT REV CLIN ONCOL, V14, P749, DOI 10.1038/nrclinonc.2017.141; Larson DB, 2020, RADIOLOGY, V295, P675, DOI 10.1148/radiol.2020192536; Lee JH, 2020, RADIOLOGY, V297, P687, DOI 10.1148/radiol.2020201240; Li L, 2020, RADIOLOGY, V296, pE65, DOI 10.1148/radiol.2020200905; Lockhart ME, 2020, RADIOLOGY, V295, P351, DOI 10.1148/radiol.2020200058; Masutani EM, 2020, RADIOLOGY, V295, P552, DOI 10.1148/radiol.2020192173; McMillan AB, 2020, RADIOLOGY, V297, P15, DOI 10.1148/radiol.2020202664; Meyrignac O, 2020, RADIOLOGY, V295, pE9, DOI 10.1148/radiol.2020200187; Mollura DJ, 2020, RADIOLOGY, V297, P513, DOI 10.1148/radiol.2020201434; Murphy K, 2020, RADIOLOGY, V296, pE166, DOI 10.1148/radiol.2020201874; Nael K, 2020, RADIOLOGY, V294, P645, DOI 10.1148/radiol.2020192703; Naik A, ARXIV 180600692 PREP; Nakkiran P, ARXIV 191202292; Narayana PA, 2020, RADIOLOGY, V294, P398, DOI 10.1148/radiol.2019191061; Nishino M, 2020, RADIOLOGY, V297, P459; Ospel JM, 2020, RADIOLOGY, V297, P650, DOI 10.1148/radiol.2020203527; Park SH, 2018, RADIOLOGY, V286, P800, DOI 10.1148/radiol.2017171920; Pianykh OS, 2020, RADIOLOGY, V297, P6, DOI 10.1148/radiol.2020200038; Pickhardt PJ, 2020, RADIOLOGY, V297, P64, DOI 10.1148/radiol.2020200466; Qiu W, 2020, RADIOLOGY, V294, P638, DOI 10.1148/radiol.2020191193; Rauschecker AM, 2020, RADIOLOGY, V295, P626, DOI 10.1148/radiol.2020190283; Richardson ML, 2020, RADIOLOGY, V296, P594, DOI 10.1148/radiol.2020202332; Shaffer K, 2020, RADIOLOGY, V296, P225, DOI 10.1148/radiol.2020201366; Sibille L, 2020, RADIOLOGY, V294, P445, DOI 10.1148/radiol.2019191114; Sim Y, 2020, RADIOLOGY, V294, P199, DOI 10.1148/radiol.2019182465; Smith AD, 2020, RADIOLOGY, V297, P73, DOI 10.1148/radiol.2020202900; Soffer S, 2019, RADIOLOGY, V290, P590, DOI 10.1148/radiol.2018180547; Stib MT, 2020, RADIOLOGY, V297, P640, DOI 10.1148/radiol.2020200334; U.S. Food and Drug Administration, 2020, PROP REG FRAM MOD AR; van Rijn RR, 2020, RADIOLOGY, V296, P159, DOI 10.1148/radiol.2020200855; van Velzen SGM, 2020, RADIOLOGY, V295, P66, DOI 10.1148/radiol.2020191621; Vannier MW, 2020, RADIOLOGY, V295, P80, DOI 10.1148/radiol.2020192718; von Schacky CE, 2020, RADIOLOGY, V295, P136, DOI 10.1148/radiol.2020190925; Willemink MJ, 2020, RADIOLOGY, V295, P4, DOI 10.1148/radiol.2020192224; Wu GY, 2020, RADIOLOGY, V297, P451, DOI 10.1148/radiol.2020192431; Yang Q., 2019, ACM T INTEL SYST TEC, V10, P19, DOI [10.1145/3298981, DOI 10.1145/3298981]; Young AT, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-020-00380-6; Zaharchuk G, 2020, RADIOLOGY, V295, P638, DOI 10.1148/radiol.2020200819; Zhang XY, 2020, RADIOLOGY, V296, P56, DOI 10.1148/radiol.2020190936; Zheng Q, 2020, RADIOLOGY, V296, P152, DOI 10.1148/radiol.2020192003; Zhou LQ, 2020, RADIOLOGY, V294, P19, DOI 10.1148/radiol.2019190372; Zhou ZJ, 2020, RADIOLOGY, V295, P407, DOI 10.1148/radiol.2020191479; Zwanenburg A, 2020, RADIOLOGY, V295, P328, DOI 10.1148/radiol.2020191145	79	5	5	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2021	3	6							e210097	10.1148/ryai.2021210097	http://dx.doi.org/10.1148/ryai.2021210097			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9UW	34870222	Green Published			2022-12-18	WOS:000826914400012
J	Koch, KM; Sherafati, M; Arpinar, VE; Bhave, S; Ausman, R; Nencka, AS; Lebel, RM; McKinnon, G; Kaushik, SS; Vierck, D; Stetz, MR; Fernando, S; Mannem, R				Koch, Kevin M.; Sherafati, Mohammad; Arpinar, V. Emre; Bhave, Sampada; Ausman, Robin; Nencka, Andrew S.; Lebel, R. Marc; McKinnon, Graeme; Kaushik, S. Sivaram; Vierck, Douglas; Stetz, Michael R.; Fernando, Sujan; Mannem, Rajeev			Analysis and Evaluation of a Deep Learning Reconstruction Approach with Denoising for Orthopedic MRI	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						MRI Reconstruction Method; Deep Learning; Image Analysis; Signal-to-Noise Ratio; MR-Imaging; Neural Networks; Hip; Shoulder; Physics; Observer Performance; Technology Assessment		Purpose: To evaluate two settings (noise reduction of 50% or 75%) of a deep learning (DL) reconstruction model relative to each other and to conventional MR image reconstructions on clinical orthopedic MRI datasets. Materials and Methods: This retrospective study included 54 patients who underwent two-dimensional fast spin-echo MRI for hip (n = 22; mean age, 44 years 6 13 [standard deviation]; nine men) or shoulder (n = 32; mean age, 56 years 6 17; 17 men) conditions between March 2019 and June 2020. MR images were reconstructed with conventional methods and the vendor-provided and commercially available DL model applied with 50% and 75% noise reduction settings (DL 50 and DL 75, respectively). Quantitative analytics, including relative anatomic edge sharpness, relative signal-to-noise ratio (rSNR), and relative contrast-to-noise ratio (rCNR) were computed for each dataset. In addition, the image sets were randomized, blinded, and presented to three board-certified musculoskeletal radiologists for ranking based on overall image quality and diagnostic confidence. Statistical analysis was performed with a nonparametric hypothesis comparing derived quantitative metrics from each reconstruction approach. In addition, inter- and intrarater agreement analysis was performed on the radiologists' rankings. Results: Both denoising settings of the DL reconstruction showed improved edge sharpness, rSNR, and rCNR relative to the conventional reconstructions. The reader rankings demonstrated strong agreement, with both DL reconstructions outperforming the conventional approach (Gwet agreement coefficient = 0.98). However, there was lower agreement between the readers on which DL reconstruction denoising setting produced higher-quality images (Gwet agreement coefficient = 0.31 for DL 50 and 0.35 for DL 75). Conclusion: The vendor-provided DL MRI reconstruction showed higher edge sharpness, rSNR, and rCNR in comparison with conventional methods; however, optimal levels of denoising may need to be further assessed. Supplemental material is available for this article. (C) RSNA, 2021.	[Koch, Kevin M.; Sherafati, Mohammad; Arpinar, V. Emre; Bhave, Sampada; Ausman, Robin; Nencka, Andrew S.; Stetz, Michael R.; Fernando, Sujan; Mannem, Rajeev] Med Coll Wisconsin, Dept Radiol, 8701 Watertown Plank Rd, Milwaukee, WI 53226 USA; [Lebel, R. Marc; McKinnon, Graeme; Kaushik, S. Sivaram] GE Healthcare, Dept MR Applicat & Workflow, Waukesha, WI USA; [Vierck, Douglas] Ctr Diagnost Imaging, Milwaukee, WI USA	Medical College of Wisconsin; General Electric	Koch, KM (corresponding author), Med Coll Wisconsin, Dept Radiol, 8701 Watertown Plank Rd, Milwaukee, WI 53226 USA.	kmkoch@mcw.edu		Lebel, Robert/0000-0002-7526-9974	GE Healthcare	GE Healthcare(General ElectricGE Healthcare)	Supported in part by a grant from GE Healthcare.	Aggarwal HK, 2019, IEEE T MED IMAGING, V38, P394, DOI 10.1109/TMI.2018.2865356; Biswas S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6533, DOI 10.1109/icassp.2018.8462637; Candes EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083; Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582; GEHealthcare, TRUE FIDELITYCT REC; Geyer LL, 2015, RADIOLOGY, V276, P338, DOI 10.1148/radiol.2015132766; Girard J, MRELIABILITY RELIABI; Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401; Griswold MA, 2002, MAGN RESON MED, V47, P1202, DOI 10.1002/mrm.10171; GUDBJARTSSON H, 1995, MAGNET RESON MED, V34, P910, DOI 10.1002/mrm.1910340618; Gwet KL, 2008, BRIT J MATH STAT PSY, V61, P29, DOI 10.1348/000711006X126600; Hammernik K, 2018, MAGN RESON MED, V79, P3055, DOI 10.1002/mrm.26977; Han Y, 2018, IEEE T MED IMAGING, V37, P1418, DOI 10.1109/TMI.2018.2823768; Han Y, 2018, MAGN RESON MED, V80, P1189, DOI 10.1002/mrm.27106; Kang E, 2017, MED PHYS, V44, pe360, DOI 10.1002/mp.12344; Kilem L, 2014, HDB INTERRATER RELIA; Kingma D.P, P 3 INT C LEARNING R; Knoll F, ARXIV 190401112; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Lebel RM, ARXIV200806559; Lustig M, 2007, MAGN RESON MED, V58, P1182, DOI 10.1002/mrm.21391; MCGIBNEY G, 1993, MAGNET RESON MED, V30, P51, DOI 10.1002/mrm.1910300109; Pruessmann KP, 1999, MAGNET RESON MED, V42, P952, DOI 10.1002/(SICI)1522-2594(199911)42:5<952::AID-MRM16>3.0.CO;2-S; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Schlemper J, ARXIV 170300555; Sodickson DK, 1997, MAGNET RESON MED, V38, P591, DOI 10.1002/mrm.1910380414; Vallat R., 2018, J OPEN SOURCE SOFTW, V3, P1026, DOI [10.21105/joss.01026, DOI 10.21105/JOSS.01026]; Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2; WILCOXON F, 1946, J ECON ENTOMOL, V39, P269, DOI 10.1093/jee/39.2.269; Willemink MJ, 2013, EUR RADIOL, V23, P1632, DOI 10.1007/s00330-012-2764-z; Yaman B, 2020, I S BIOMED IMAGING, P921, DOI 10.1109/ISBI45749.2020.9098514; Zhu B, 2018, NATURE, V555, P487, DOI 10.1038/nature25988	33	5	5	4	6	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2021	3	6							e200278	10.1148/ryai.2021200278	http://dx.doi.org/10.1148/ryai.2021200278			8	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9UW	34870214	Green Published			2022-12-18	WOS:000826914400004
J	Sandfort, V; Yan, K; Graffy, PM; Pickhardt, PJ; Summers, RM				Sandfort, Veit; Yan, Ke; Graffy, Peter M.; Pickhardt, Perry J.; Summers, Ronald M.			Use of Variational Autoencoders with Unsupervised Learning to Detect Incorrect Organ Segmentations at CT	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Convolutional Neural Network (CNN); Deep Learning Algorithms; Machine Learning Algorithms; Segmentation; CT		Purpose: To develop a deep learning model to detect incorrect organ segmentations at CT. Materials and Methods: In this retrospective study, a deep learning method was developed using variational autoencoders (VAEs) to identify problematic organ segmentations. First, three different three-dimensional (3D) U-Nets were trained on segmented CT images of the liver (n = 141), spleen (n = 51), and kidney (n = 66). A total of 12 495 CT images then were segmented by the 3D U-Nets, and output segmentations were used to train three different VAEs for the detection of problematic segmentations. Automatic reconstruction errors (Dice scores) were then calculated. A random sampling of 2510 segmented images each for the liver, spleen, and kidney models were assessed manually by a human reader to determine problematic and correct segmentations. The ability of the VAEs to identify unusual or problematic segmentations was evaluated using receiver operating characteristic curve analysis and compared with traditional nondeep learning methods for outlier detection. Using the VAE outputs, passive and active learning approaches were performed on the original 3D U-Nets to determine if training could decrease segmentation error rates (15 CT scans were added to the original training data, according to each approach). Results: The mean area under the receiver operating characteristic curve (AUC) for detecting problematic segmentations using the VAE method was 0.90 (95% CI: 0.89, 0.92) for kidney, 0.94 (95% CI: 0.93, 0.95) for liver, and 0.81 (95% CI: 0.80, 0.82) for spleen. The VAE performance was higher compared with traditional methods in most cases. For example, for liver segmentation, the highest performing non-deep learning method for outlier detection had an AUC of 0.83 (95% CI: 0.77, 0.90) compared with 0.94 (95% CI: 0.93, 0.95) using the VAE method (P < .05). Using the information on problematic segmentations for active learning approaches decreased 3D U-Net segmentation error rates (original error rate, 7.1%; passive learning, 6.0%; active learning, 5.7%). Conclusion: A method was developed to screen for unusual and problematic automatic organ segmentations using a 3D VAE.	[Sandfort, Veit; Yan, Ke; Summers, Ronald M.] NIH, Imaging Biomarkers & Comp Aided Diag Lab, Radiol & Imaging Sci, Ctr Clin, Bethesda, MD 20892 USA; [Graffy, Peter M.; Pickhardt, Perry J.] Univ Wisconsin, Sch Med & Publ Hlth, Dept Radiol, Madison, WI 53706 USA	National Institutes of Health (NIH) - USA; NIH Clinical Center (CC); University of Wisconsin System; University of Wisconsin Madison	Sandfort, V (corresponding author), NIH, Imaging Biomarkers & Comp Aided Diag Lab, Radiol & Imaging Sci, Ctr Clin, Bethesda, MD 20892 USA.	veit.sandfort@gmail.com	yan, keyu/GXW-2126-2022	Graffy, Peter/0000-0002-2156-7175	Intramural Research Program of the National Institutes of Health Clinical Center	Intramural Research Program of the National Institutes of Health Clinical Center(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	This research was supported in part by the Intramural Research Program of the National Institutes of Health Clinical Center. Conflicts of interest are listed at the end of this article.	Apostolova LG, 2012, ALZ DIS ASSOC DIS, V26, P17, DOI 10.1097/WAD.0b013e3182163b62; Baur C, 2019, LECT NOTES COMPUT SC, V11383, P161, DOI 10.1007/978-3-030-11723-8_16; Breunig MM, 2000, SIGMOD REC, V29, P93, DOI 10.1145/335191.335388; Burgess CP, ARXIV 180403599 PREP; Dupont E., ARXIV 180400104 PREP; Isensee F., 2019, BILDVERARBEITUNG MED, VI, P22; Isensee F, 2018, LECT NOTES COMPUT SC, V10670, P287, DOI 10.1007/978-3-319-75238-9_25; Kayalibay B, ARXIV 170103056 PREP; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Liu FT, 2008, IEEE DATA MINING, P413, DOI 10.1109/ICDM.2008.17; Mandrekar JN, 2010, J THORAC ONCOL, V5, P1315, DOI 10.1097/JTO.0b013e3181ec173d; medicaldecathlon.com, MED SEGMENTATION DEC; Mourao-Miranda J, 2011, NEUROIMAGE, V58, P793, DOI 10.1016/j.neuroimage.2011.06.042; Pickhardt PJ, 2020, LANCET DIGIT HEALTH, V2, pE192, DOI 10.1016/S2589-7500(20)30025-X; Rousseeuw PJ, 1999, TECHNOMETRICS, V41, P212, DOI 10.2307/1270566; Sandfort V, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-52737-x; Uzunova H, 2019, INT J COMPUT ASS RAD, V14, P451, DOI 10.1007/s11548-018-1898-0; Cao VL, 2019, IEEE T CYBERNETICS, V49, P3074, DOI 10.1109/TCYB.2018.2838668; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244	19	5	5	0	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2021	3	4							e200218	10.1148/ryai.2021200218	http://dx.doi.org/10.1148/ryai.2021200218			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SU	34350410	Green Accepted			2022-12-18	WOS:000826909000008
J	Shu, H; Chiang, TY; Wei, P; Do, KA; Lesslie, MD; Cohen, EO; Srinivasan, A; Moseley, TW; Sen, LQC; Leung, JWT; Dennison, JB; Hanash, SM; Weaver, OO				Shu, Hai; Chiang, Tingyu; Wei, Peng; Do, Kim-Anh; Lesslie, Michele D.; Cohen, Ethan O.; Srinivasan, Ashmitha; Moseley, Tanya W.; Sen, Lauren Q. Chang; Leung, Jessica W. T.; Dennison, Jennifer B.; Hanash, Sam M.; Weaver, Olena O.			A Deep Learning Approach to Re-create Raw Full-Field Digital Mammograms for Breast Density and Texture Analysis	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Mammography; Breast; Supervised Learning; Convolutional Neural Network (CNN); Deep learning algorithms; Machine Learning Algorithms	CANCER RISK; AGREEMENT	Purpose: To develop a computational approach to re-create rarely stored for-processing (raw) digital mammograms from routinely stored for-presentation (processed) mammograms. Materials and Methods: In this retrospective study, pairs of raw and processed mammograms collected in 884 women (mean age, 57 years 6 10 [standard deviation]; 3713 mammograms) from October 5, 2017, to August 1, 2018, were examined. Mammograms were split 3088 for training and 625 for testing. A deep learning approach based on a U-Net convolutional network and kernel regression was developed to estimate the raw images. The estimated raw images were compared with the originals by four image error and similarity metrics, breast density calculations, and 29 widely used texture features. Results: In the testing dataset, the estimated raw images had small normalized mean absolute error (0.022 +/- 0.015), scaled mean absolute error (0.134 +/- 0.078) and mean absolute percentage error (0.115 +/- 0.059), and a high structural similarity index (0.986 +/- 0.007) for the breast portion compared with the original raw images. The estimated and original raw images had a strong correlation in breast density percentage (Pearson r = 0.946) and a strong agreement in breast density grade (Cohen k = 0.875). The estimated images had satisfactory correlations with the originals in 23 texture features (Pearson r = 0.503 or Spearman r = 0.705) and were well complemented by processed images for the other six features. Conclusion: This deep learning approach performed well in re-creating raw mammograms with strong agreement in four image evaluation metrics, breast density, and the majority of 29 widely used texture features.	[Shu, Hai; Wei, Peng; Do, Kim-Anh] Univ Texas MD Anderson Canc Ctr, Dept Biostat, 1515 Holcombe Blvd, Houston, TX 77030 USA; [Chiang, Tingyu; Lesslie, Michele D.; Cohen, Ethan O.; Srinivasan, Ashmitha; Moseley, Tanya W.; Sen, Lauren Q. Chang; Leung, Jessica W. T.; Weaver, Olena O.] Univ Texas MD Anderson Canc Ctr, Dept Diagnost Radiol, 1515 Holcombe Blvd, Houston, TX 77030 USA; [Dennison, Jennifer B.; Hanash, Sam M.] Univ Texas MD Anderson Canc Ctr, Dept Clin Canc Prevent, 1515 Holcombe Blvd, Houston, TX 77030 USA; [Shu, Hai] NYU, Sch Global Publ Hlth, Dept Biostat, New York, NY USA	University of Texas System; UTMD Anderson Cancer Center; University of Texas System; UTMD Anderson Cancer Center; University of Texas System; UTMD Anderson Cancer Center; New York University	Weaver, OO (corresponding author), Univ Texas MD Anderson Canc Ctr, Dept Diagnost Radiol, 1515 Holcombe Blvd, Houston, TX 77030 USA.	OOWeaver@mdanderson.org		Wei, Peng/0000-0001-7758-6116; Shu, Hai/0000-0002-6968-4063; Do, Kim-Anh/0000-0001-8710-7131	National Institutes of Health/National Cancer Institute Cancer Center Support Grant [P30 CA016672]; Little Green Book Foundation; McCombs Institute at MD Anderson; Center for Global Early Detection at MD Anderson	National Institutes of Health/National Cancer Institute Cancer Center Support Grant; Little Green Book Foundation; McCombs Institute at MD Anderson; Center for Global Early Detection at MD Anderson	Supported in part by grants from National Institutes of Health/National Cancer Institute Cancer Center Support Grant (P30 CA016672), Little Green Book Foundation, Center for Global Early Detection at MD Anderson, and McCombs Institute at MD Anderson.	Aresta G, 2019, MED IMAGE ANAL, V56, P122, DOI 10.1016/j.media.2019.05.010; Bakas S, ARXIV181102629 PREPR; BLAND JM, 1986, LANCET, V1, P307, DOI 10.1016/s0140-6736(86)90837-8; Boyd NF, 2007, NEW ENGL J MED, V356, P227, DOI 10.1056/NEJMoa062790; Burton A, 2016, BREAST CANCER RES, V18, DOI 10.1186/s13058-016-0787-0; Cortez P, 2010, LECT NOTES ARTIF INT, V6171, P572, DOI 10.1007/978-3-642-14400-4_44; Follmann D, 2003, BIOMETRICS, V59, P420, DOI 10.1111/1541-0420.00049; Gastounioti A, 2016, MED PHYS, V43, P5862, DOI 10.1118/1.4963810; Gastounioti A, 2016, BREAST CANCER RES, V18, DOI 10.1186/s13058-016-0755-8; Goodfellow I, 2016, DEEP LEARNING; Gupta S, 2005, MED PHYS, V32, P1598, DOI 10.1118/1.1915013; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Hoffman EB, 2001, BIOMETRIKA, V88, P1121, DOI 10.1093/biomet/88.4.1121; International Atomic Energy Agency, 2011, QUALITY ASSURANCE PR; Jacobsen N, 2019, Z MED PHYS, V29, P128, DOI 10.1016/j.zemedi.2018.11.004; Keller BM, 2014, PROC SPIE, V9035, DOI 10.1117/12.2043710; Kingma D.P, P 3 INT C LEARNING R; Krouwer JS, 2008, STAT MED, V27, P778, DOI 10.1002/sim.3086; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Lehman CD, 2019, RADIOLOGY, V290, P52, DOI 10.1148/radiol.2018180694; Li Q, 2007, THEDA SKOCPOL; Lorenz DJ, 2018, STAT METHODS MED RES, V27, P1806, DOI 10.1177/0962280216669184; Nielsen M, 2014, BREAST CANCER RES, V16, DOI 10.1186/bcr3641; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Porwal P, 2020, MED IMAGE ANAL, V59, DOI 10.1016/j.media.2019.101561; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Shen L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48995-4; Sickles EA, 2013, ACR BI RADS ATLAS BR, V5th, P46; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Tabar L, 2003, LANCET, V361, P1405, DOI 10.1016/S0140-6736(03)13143-1; Wang AT, 2014, MAYO CLIN PROC, V89, P548, DOI 10.1016/j.mayocp.2013.12.014; Wang C, 2017, BREAST CANCER RES, V19, DOI 10.1186/s13058-017-0906-6; Wang J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0081653; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Yang Z, 2015, COMPUT STAT DATA AN, V82, P1, DOI 10.1016/j.csda.2014.08.004; Zheng YJ, 2015, MED PHYS, V42, P4149, DOI 10.1118/1.4921996	36	5	5	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2021	3	4							e200097	10.1148/ryai.2021200097	http://dx.doi.org/10.1148/ryai.2021200097			11	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SU	34350403	Green Published			2022-12-18	WOS:000826909000001
J	Thian, YL; Ng, D; Hallinan, JTPD; Jagmohan, P; Sia, SY; Tan, CH; Ting, YH; Kei, PL; Pulickal, GG; Tiong, VTY; Quek, ST; Feng, ML				Thian, Yee Liang; Ng, Dianwen; Hallinan, James Thomas Patrick Decourcy; Jagmohan, Pooja; Sia, Soon Yiew; Tan, Cher Heng; Ting, Yong Han; Kei, Pin Lin; Pulickal, Geoiphy George; Tiong, Vincent Tze Yang; Quek, Swee Tian; Feng, Mengling			Deep Learning Systems for Pneumothorax Detection on Chest Radiographs: A Multicenter External Validation Study	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Thorax; Computer Applications-Detection/Diagnosis	ARTIFICIAL-INTELLIGENCE; PERFORMANCE; ALGORITHM	Purpose: To assess the generalizability of a deep learning pneumothorax detection model on datasets from multiple external institutions and examine patient and acquisition factors that might influence performance. Materials and Methods: In this retrospective study, a deep learning model was trained for pneumothorax detection by merging two large open-source chest radiograph datasets: ChestX-ray14 and CheXpert. It was then tested on six external datasets from multiple independent institutions (labeled A-F) in a retrospective case-control design (data acquired between 2016 and 2019 from institutions A-E; institution F consisted of data from the MIMIC-CXR dataset). Performance on each dataset was evaluated by using area under the receiver operating characteristic curve (AUC) analysis, sensitivity, specificity, and positive and negative predictive values, with two radiologists in consensus being used as the reference standard. Patient and acquisition factors that influenced performance were analyzed. Results: The AUCs for pneumothorax detection for external institutions A-F were 0.91 (95% CI: 0.88, 0.94), 0.97 (95% CI: 0.94, 0.99), 0.91 (95% CI: 0.85, 0.97), 0.98 (95% CI: 0.96, 1.0), 0.97 (95% CI: 0.95, 0.99), and 0.92 (95% CI: 0.90, 0.95), respectively, compared with the internal test AUC of 0.93 (95% CI: 0.92, 0.93). The model had lower performance for small compared with large pneumothoraces (AUC, 0.88 [95% CI: 0.85, 0.91] vs AUC, 0.96 [95% CI: 0.95, 0.97]; P =.005). Model performance was not different when a chest tube was present or absent on the radiographs (AUC, 0.95 [95% CI: 0.92, 0.97] vs AUC, 0.94 [95% CI: 0.92, 0.05]; P > .99). Conclusion: A deep learning model trained with a large volume of data on the task of pneumothorax detection was able to generalize well to multiple external datasets with patient demographics and technical parameters independent of the training data.	[Thian, Yee Liang; Ng, Dianwen; Hallinan, James Thomas Patrick Decourcy; Jagmohan, Pooja; Sia, Soon Yiew; Tiong, Vincent Tze Yang; Quek, Swee Tian] Natl Univ Singapore Hosp, Dept Diagnost Imaging, S Lower Kent Ridge Rd, Singapore 119074, Singapore; [Ng, Dianwen; Feng, Mengling] Natl Univ Singapore, Saw Swee Hock Sch Publ Hlth, Sch Comp Sci, Singapore, Singapore; [Ng, Dianwen; Feng, Mengling] Natl Univ Singapore, Yong Loo Lin Sch Med, Singapore, Singapore; [Hallinan, James Thomas Patrick Decourcy] Alexandra Hosp, Dept Diagnost Radiol, Singapore, Singapore; [Tan, Cher Heng; Ting, Yong Han] Tan Tock Seng Hosp, Dept Diagnost Radiol, Singapore, Singapore; [Tan, Cher Heng] Nanyang Technol Univ, Lee Kong Chian Sch Med, Singapore, Singapore; [Kei, Pin Lin] Ng Teng Fong Gen Hosp, Dept Diagnost Radiol, Singapore, Singapore; [Pulickal, Geoiphy George] Khoo Teck Puat Hosp, Dept Diagnost Radiol, Singapore, Singapore	National University of Singapore; National University of Singapore; National University of Singapore; Tan Tock Seng Hospital; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University	Thian, YL (corresponding author), Natl Univ Singapore Hosp, Dept Diagnost Imaging, S Lower Kent Ridge Rd, Singapore 119074, Singapore.	yee_liang_thian@nuhs.edu.sg		Ting, Yonghan/0000-0002-8682-9914; KEI, Pin Lin/0000-0003-1349-8058; Thian, Yee Liang/0000-0001-9899-205X; Hallinan, James/0000-0002-0082-9033; Sia, David/0000-0002-8609-9587; Jagmohan, Pooja/0000-0001-8491-0375; Tiong, Tze Yang Vincent/0000-0002-6433-8815	National University Health System (NUHS) [NUHSRO/2018/097/R0515/Seed-Nov/07, NUHSRO/2018/019/RO515/NUHS]; National Medical Research Council Health Services Research Grant [HSRG-OC17nov004]	National University Health System (NUHS); National Medical Research Council Health Services Research Grant	Supported by National University Health System (NUHS) internal grant funding under the NUHS Seed Fund (NUHSRO/2018/097/R0515/Seed-Nov/07 and NUHSRO/2018/019/RO515/NUHS) and a National Medical Research Council Health Services Research Grant (HSRG-OC17nov004).	Baltruschat IM, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-42294-8; Brar MS, 2010, J TRAUMA, V69, P1335, DOI 10.1097/TA.0b013e3181f6f525; Chang PJ, 2020, RADIOLOGY, V294, P432, DOI 10.1148/radiol.2019192527; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; Frenay B, 2014, IEEE T NEUR NET LEAR, V25, P845, DOI 10.1109/TNNLS.2013.2292894; Gundel Sebastian, 2019, Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications. 23rd Iberoamerican Congress, CIARP 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11401), P757, DOI 10.1007/978-3-030-13469-3_88; Haber E, 2018, AAAI CONF ARTIF INTE, P3142; Hu K, 2018, NEUROCOMPUTING, V309, P179, DOI 10.1016/j.neucom.2018.05.011; Hwang EJ, 2020, EUR RADIOL, V30, P3660, DOI 10.1007/s00330-020-06771-3; Irvin J, 2019, AAAI CONF ARTIF INTE, P590; Johnson AE, ARXIV 190107042 PREP; Kim DW, 2019, KOREAN J RADIOL, V20, DOI 10.3348/kjr.2019.0025; Kitamura G, 2020, CLIN IMAG, V61, P15, DOI 10.1016/j.clinimag.2020.01.008; MacDuff A, 2010, THORAX, V65, P18, DOI 10.1136/thx.2010.136986; Majkowska A, 2020, RADIOLOGY, V294, P421, DOI 10.1148/radiol.2019191293; Oakden-Rayner L, 2020, ACAD RADIOL, V27, P106, DOI 10.1016/j.acra.2019.10.006; Park SH, 2019, RADIOLOGY, V290, P272, DOI 10.1148/radiol.2018182294; Park SH, 2018, RADIOLOGY, V286, P800, DOI 10.1148/radiol.2017171920; Rajpurkar P, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002686; Ruopp MD, 2008, BIOMETRICAL J, V50, P419, DOI 10.1002/bimj.200710415; Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74; Sun C, 2017, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2017.97; Surleti S, 2011, G CHIR, V32, P473; Tan M, ARXIV 190511946 PREP; Taylor AG, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002697; TAYLOR JMG, 1986, STAT MED, V5, P29, DOI 10.1002/sim.4780050106; Wang XQ, 2020, J AM COLL RADIOL, V17, P796, DOI 10.1016/j.jacr.2020.01.006; Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369; Zech JR, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002683; ZWEIG MH, 1993, CLIN CHEM, V39, P561	30	5	5	2	5	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2021	3	4							e200190	10.1148/ryai.2021200190	http://dx.doi.org/10.1148/ryai.2021200190			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SU	34350409	Green Published			2022-12-18	WOS:000826909000007
J	Erickson, BJ; Kitamura, F				Erickson, Bradley J.; Kitamura, Felipe			Magician's Corner: 9. Performance Metrics for Machine Learning Models	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Erickson, Bradley J.] Mayo Clin, Dept Radiol, 200 First St SW, Rochester, MN 55905 USA; [Kitamura, Felipe] Univ Fed Sao Paulo, Dept Diagnost Imaging, Sao Paulo, Brazil; [Kitamura, Felipe] Diagnost Amer SA, Sao Paulo, Brazil	Mayo Clinic; Universidade Federal de Sao Paulo (UNIFESP)	Erickson, BJ (corresponding author), Mayo Clin, Dept Radiol, 200 First St SW, Rochester, MN 55905 USA.	bje@mayo.edu	Kitamura, Felipe Campos/AAC-7075-2021	Kitamura, Felipe Campos/0000-0002-9992-5630; Erickson, Bradley/0000-0001-7926-6095				DUBUISSON MP, 1994, INT C PATT RECOG, P566, DOI 10.1109/ICPR.1994.576361; Hausdorff F., 1914, GRUNDZUGE MENGENLEHR; Vogelsang DC, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020200012	3	5	5	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2021	3	3							e200126	10.1148/ryai.2021200126	http://dx.doi.org/10.1148/ryai.2021200126			7	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SA	34136815	Green Published			2022-12-18	WOS:000826907000003
J	Wang, B; Perronne, L; Burke, C; Adler, RS				Wang, Benjamin; Perronne, Laetitia; Burke, Christopher; Adler, Ronald S.			Artificial Intelligence for Classification of Soft-Tissue Masses at US	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							DIAGNOSIS; CANCER; AREAS	Purpose: To train convolutional neural network (CNN) models to classify benign and malignant soft-tissue masses at US and to differentiate three commonly observed benign masses. Materials and Methods: In this retrospective study, US images obtained between May 2010 and June 2019 from 419 patients (mean age, 52 years +/- 18 [standard deviation]; 250 women) with histologic diagnosis confirmed at biopsy or surgical excision (n = 227) or masses that demonstrated imaging characteristics of lipoma, benign peripheral nerve sheath tumor, and vascular malformation (n = 192) were included. Images in patients with a histologic diagnosis (n = 227) were used to train and evaluate a CNN model to distinguish malignant and benign lesions. Twenty percent of cases were withheld as a test dataset, and the remaining cases were used to train the model with a 75%-25% training-validation split and fourfold cross-validation. Performance of the model was compared with retrospective interpretation of the same dataset by two experienced musculoskeletal radiologists, blinded to clinical history. A second group of US images from 275 of the 419 patients containing the three common benign masses was used to train and evaluate a separate model to differentiate between the masses. The models were trained on the Keras machine learning platform (version 2.3.1), with a modified pretrained VGG16 network. Performance metrics of the model and of the radiologists were compared by using the McNemar test, and 95% CIs for performance metrics were estimated by using the Clopper-Pearson method (accuracy, recall, specificity, and precision) and the DeLong method (area under the receiver operating characteristic curve). Results: The model trained to classify malignant and benign masses demonstrated an accuracy of 79% (95% CI: 68, 88) on the test data, with an area under the receiver operating characteristic curve of 0.91 (95% CI: 0.84, 0.98), matching the performance of two expert readers. Performance of the model distinguishing three benign masses was lower, with an accuracy of 71% (95% CI: 61, 80) on the test data. Conclusion: The trained CNN was capable of differentiating between benign and malignant soft-tissue masses depicted on US images, with performance matching that of two experienced musculoskeletal radiologists. (C) RSNA, 2020	[Wang, Benjamin; Burke, Christopher; Adler, Ronald S.] NYU Langone Hlth, Div Musculoskeletal Radiol, Dept Radiol, 301 E 17th St,6th Floor, New York, NY 10003 USA; [Perronne, Laetitia] Hop Lariboisiere, Dept Musculoskeletal Imaging, Paris, France	NYU Langone Medical Center; Assistance Publique Hopitaux Paris (APHP); Hopital Universitaire Lariboisiere-Fernand-Widal - APHP; UDICE-French Research Universities; Universite Paris Cite	Wang, B (corresponding author), NYU Langone Hlth, Div Musculoskeletal Radiol, Dept Radiol, 301 E 17th St,6th Floor, New York, NY 10003 USA.	benjamin.wang@nyulangone.org		Burke, Christopher/0000-0001-7609-1146; Perronne, Laetitia/0000-0002-6752-3354				Aarti Bagul, 2017, Arxiv, DOI arXiv:1711.05225; Abadi M., TENSORFLOW LARGE SCA; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Buda M, 2020, ULTRASOUND MED BIOL, V46, P415, DOI 10.1016/j.ultrasmedbio.2019.10.003; Carra BJ, 2014, AM J ROENTGENOL, V202, P1281, DOI 10.2214/AJR.13.11564; Charnock M, 2018, CLIN RADIOL, V73, P1025, DOI 10.1016/j.crad.2018.07.102; Chollet F., 2015, KERAS; Ciompi F, 2017, SCI REP-UK, V7, DOI 10.1038/srep46479; Clopper CJ, 1934, BIOMETRIKA, V26, P404, DOI 10.2307/2331986; Cunningham RJ, 2020, J R SOC INTERFACE, V17, DOI 10.1098/rsif.2019.0715; Nguyen DT, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20071822; Nguyen DT, 2019, J CLIN MED, V8, DOI 10.3390/jcm8111976; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056; Grimer RJ, 2010, J BONE JOINT SURG BR, V92B, P1489, DOI 10.1302/0301-620X.92B11.24326; Hu SY, 2019, IEEE ENG MED BIO, P993, DOI 10.1109/EMBC.2019.8856367; Hwang Sinchun, 2005, Ultrasound Q, V21, P259, DOI 10.1097/01.ruq.0000191657.87569.08; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Lakhani P, 2017, RADIOLOGY, V284, P574, DOI 10.1148/radiol.2017162326; Lakkaraju A, 2009, CLIN RADIOL, V64, P615, DOI 10.1016/j.crad.2009.01.012; Lin BS, 2020, IEEE J BIOMED HEALTH, V24, P1037, DOI 10.1109/JBHI.2020.2968815; Liu D, 2020, EUR RADIOL, V30, P2365, DOI 10.1007/s00330-019-06553-6; McNally EG, 2011, SKELETAL RADIOL, V40, P1223, DOI 10.1007/s00256-011-1220-5; McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996; Orlando N, 2020, MED PHYS, V47, P2413, DOI 10.1002/mp.14134; Sun QC, 2020, FRONT ONCOL, V10, DOI 10.3389/fonc.2020.00053; Sun X, 2014, IEEE SIGNAL PROC LET, V21, P1389, DOI 10.1109/LSP.2014.2337313; Tanaka H, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab5093; Wagner JM, 2013, J ULTRAS MED, V32, P1443, DOI 10.7863/ultra.32.8.1443; Wang L, 2019, WORLD J SURG ONCOL, V17, DOI 10.1186/s12957-019-1558-z; Zhou GQ, 2020, IEEE T ULTRASON FERR, V3010, P1	31	5	5	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2021	3	1							e200125	10.1148/ryai.2020200125	http://dx.doi.org/10.1148/ryai.2020200125			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z3HE	33937855	Bronze, Green Published			2022-12-18	WOS:000826472300007
J	Dreizin, D; Zhou, YY; Fu, SH; Wang, Y; Li, G; Champ, K; Siegel, E; Wang, Z; Chen, TN; Yuille, AL				Dreizin, David; Zhou, Yuyin; Fu, Shuhao; Wang, Yan; Li, Guang; Champ, Kathryn; Siegel, Eliot; Wang, Ze; Chen, Tina; Yuille, Alan L.			A Multiscale Deep Learning Method for Quantitative Visualization of Traumatic Hemoperitoneum at CT: Assessment of Feasibility and Comparison with Subjective Categorical Estimation	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To evaluate the feasibility of a multiscale deep learning algorithm for quantitative visualization and measurement of traumatic hemoperitoneum and to compare diagnostic performance for relevant outcomes with categorical estimation. Materials and Methods: This retrospective, single-institution study included 130 patients (mean age, 38 years; interquartile range, 25-50 years; 79 men) with traumatic hemoperitoneum who underwent CT of the abdomen and pelvis at trauma admission between January 2016 and April 2019. Labeled cases were separated into five combinations of training (80%) and test (20%) sets, and fivefold cross-validation was performed. Dice similarity coefficients (DSCs) were compared with those from a three-dimensional (3D) U-Net and a coarse-to-fine deep learning method. Areas under the receiver operating characteristic curve (AUCs) for a composite outcome, including hemostatic intervention, transfusion, and in-hospital mortality, were compared with consensus categorical assessment by two radiologists. An optimal cutoff was derived by using a radial basis function-based support vector machine. Results: Mean DSC for the multiscale algorithm was 0.61 +/- 0.15 (standard deviation) compared with 0.32 +/- 0.16 for the 3D U-Net method and 0.52 +/- 0.17 for the coarse-to-fine method (P<.0001). Correlation and agreement between automated and manual volumes were excellent (Pearson r = 0.97, intraclass correlation coefficient = 0.93). The algorithm produced intuitive and explainable visual results. AUCs for automated volume measurement and categorical estimation were 0.86 and 0.77, respectively (P=.004). An optimal cutoff of 278.9 mL yielded accuracy of 84%, sensitivity of 82%, specificity of 93%, positive predictive value of 86%, and negative predictive value of 83%. Conclusion: A multiscale deep learning method for traumatic hemoperitoneum quantitative visualization had improved diagnostic performance for predicting hemorrhage-control interventions and mortality compared with subjective volume estimation. (C) RSNA, 2020	[Dreizin, David] Univ Maryland, Med Ctr, Sect Trauma & Emergency Radiol, R Adams Cowley Shock Trauma Ctr, 22 S Greene St, Baltimore, MD 21201 USA; [Li, Guang; Champ, Kathryn; Siegel, Eliot; Wang, Ze; Chen, Tina] Univ Maryland, Med Ctr, Dept Diagnost Radiol & Nucl Med, 22 S Greene St, Baltimore, MD 21201 USA; [Zhou, Yuyin; Fu, Shuhao; Wang, Yan; Yuille, Alan L.] Johns Hopkins Univ, Dept Comp Sci, Computat Cognit Vis & Learning, Baltimore, MD 21218 USA		Dreizin, D (corresponding author), Univ Maryland, Med Ctr, Sect Trauma & Emergency Radiol, R Adams Cowley Shock Trauma Ctr, 22 S Greene St, Baltimore, MD 21201 USA.	daviddreizin@gmail.com						Abramson RG, 2015, ACAD RADIOL, V22, P25, DOI 10.1016/j.acra.2014.09.001; Battey TWK, 2019, ABDOM RADIOL, V44, P2648, DOI 10.1007/s00261-019-02000-8; Becker CD, 1998, EUR RADIOL, V8, P553, DOI 10.1007/s003300050433; Berg RJ, 2014, INJURY, V45, P1394, DOI 10.1016/j.injury.2014.04.025; Cancio LC, 2008, J TRAUMA, V64, pS51, DOI 10.1097/TA.0b013e3181608c21; Charbit J, 2013, AM J EMERG MED, V31, P130, DOI 10.1016/j.ajem.2012.06.024; Cicchetti D.V., 1994, PSYCHOL ASSESSMENTS, V6, P284, DOI [10.1037/1040-3590.6.4.284, DOI 10.1037/1040-3590.6.4.284]; Costantini TW, 2016, J TRAUMA ACUTE CARE, V80, P717, DOI 10.1097/TA.0000000000001034; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; Dreizin D, 2020, J TRAUMA ACUTE CARE, V88, P425, DOI 10.1097/TA.0000000000002566; Dreizin D, 2019, RADIOGRAPHICS, V39, P2130, DOI 10.1148/rg.2019190192; Dreizin D, 2020, J DIGIT IMAGING, V33, P243, DOI 10.1007/s10278-019-00207-1; Dreizin D, 2018, RADIOLOGY, V287, P1061, DOI 10.1148/radiol.2018170997; Dreizin D, 2016, RADIOLOGY, V281, P749, DOI 10.1148/radiol.2015152335; Dreizin D, 2016, ABDOM RADIOL, V41, P2203, DOI 10.1007/s00261-016-0822-8; Dreizin D, 2015, RADIOLOGY, V277, P337, DOI 10.1148/radiol.2015142282; Dreizin D, 2012, RADIOGRAPHICS, V32, P609, DOI 10.1148/rg.323115099; Erickson Bradley J, 2019, Radiol Artif Intell, V1, pe190126, DOI 10.1148/ryai.2019190126; Fang JF, 2006, J TRAUMA, V61, P547, DOI 10.1097/01.ta.0000196571.12389.ee; FEDERLE MP, 1983, RADIOLOGY, V148, P187, DOI 10.1148/radiology.148.1.6856833; Gan KF, 2019, ACTA ORTHOP, V90, P394, DOI 10.1080/17453674.2019.1600125; Goan YG, 1998, J TRAUMA, V45, P360, DOI 10.1097/00005373-199808000-00026; Levine CD, 1996, AM J ROENTGENOL, V166, P1089, DOI 10.2214/ajr.166.5.8615249; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Lubner M, 2007, RADIOGRAPHICS, V27, P109, DOI 10.1148/rg.271065042; McKenney KL, 2001, J TRAUMA, V50, P650, DOI 10.1097/00005373-200104000-00009; Mejino Jose L V, 2008, AMIA Annu Symp Proc, P465; MOON KL, 1983, AM J ROENTGENOL, V141, P309, DOI 10.2214/ajr.141.2.309; Pawlowski N, ARXIV 171106853; Rosenkrantz AB, 2015, ACAD RADIOL, V22, P33, DOI 10.1016/j.acra.2014.08.011; Shuman WP, 1997, RADIOLOGY, V205, P297, DOI 10.1148/radiology.205.2.9356606; Teuben M, 2019, EUR J TRAUMA EMERG S, V45, P979, DOI 10.1007/s00068-019-01117-1; van der Vlies CH, 2010, CARDIOVASC INTER RAD, V33, P1079, DOI 10.1007/s00270-010-9943-6; Wang Z, 2007, NEUROIMAGE, V36, P1139, DOI 10.1016/j.neuroimage.2007.03.072; Wang Z, 2017, ADDICT BIOL, V22, P1622, DOI 10.1111/adb.12459; Xie LX, 2020, IEEE T MED IMAGING, V39, P514, DOI 10.1109/TMI.2019.2930679; Zhou YY, 2019, LECT NOTES COMPUT SC, V11861, P461, DOI 10.1007/978-3-030-32692-0_53	37	5	5	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2020	2	6							e190220	10.1148/ryai.2020190220	http://dx.doi.org/10.1148/ryai.2020190220			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CZ	33330848	Green Published			2022-12-18	WOS:000826480100005
J	Huber, NR; Missert, AD; Erickson, BJ				Huber, Nathan Robert; Missert, Andrew D.; Erickson, Bradley J.			Magician's Corner: 7. Using Convolutional Neural Networks to Reduce Noise in Medical Images	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Huber, Nathan Robert; Missert, Andrew D.; Erickson, Bradley J.] Mayo Clin, Dept Radiol, 200 First St SW, Rochester, MN 55905 USA		Erickson, BJ (corresponding author), Mayo Clin, Dept Radiol, 200 First St SW, Rochester, MN 55905 USA.	bje@mayo.edu		Erickson, Bradley/0000-0001-7926-6095; Huber, Nathan/0000-0002-6285-789X	National Institute of Biomedical Imaging and Bioengineering [EB017095, EB017185]	National Institute of Biomedical Imaging and Bioengineering(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB))	We acknowledge Cynthia McCollough, PhD, the Mayo Clinic, the American Association of Physicists in Medicine, and grants EB017095 and EB017185 from the National Institute of Biomedical Imaging and Bioengineering for distributing the data used within this publication.	[Anonymous], LOW DOSE CT GRAND CH; Kim B, 2019, MED PHYS, V46, P3906, DOI 10.1002/mp.13713; Missert AD, 2020, MED PHYS, V47, P422, DOI 10.1002/mp.13918; Shan HM, 2019, NAT MACH INTELL, V1, P269, DOI 10.1038/s42256-019-0057-9; Tian C, PREPRINTS; Yang QS, 2018, IEEE T MED IMAGING, V37, P1348, DOI 10.1109/TMI.2018.2827462	6	5	5	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2020	2	5							e200036	10.1148/ryai.2020200036	http://dx.doi.org/10.1148/ryai.2020200036			4	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CY		Bronze, Green Published			2022-12-18	WOS:000826477600009
J	Rodrigues, TC; Deniz, CM; Alaia, EF; Gorelik, N; Babb, JS; Dublin, J; Gyftopoulos, S				Rodrigues, Tatiane Cantarelli; Deniz, Cem M.; Alaia, Erin F.; Gorelik, Natalia; Babb, James S.; Dublin, Jared; Gyftopoulos, Soterios			Three-dimensional MRI Bone Models of the Glenohumeral Joint Using Deep Learning: Evaluation of Normal Anatomy and Glenoid Bone Loss	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To use convolutional neural networks (CNNs) for fully automated MRI segmentation of the glenohumeral joint and evaluate the accuracy of three-dimensional (3D) MRI models created with this method. Materials and Methods: Shoulder MR images of 100 patients (average age, 44 years; range, 14-80 years; 60 men) were retrospectively collected from September 2013 to August 2018. CNNs were used to develop a fully automated segmentation model for proton density-weighted images. Shoulder MR images from an additional 50 patients (mean age, 33 years; range, 16-65 years; 35 men) were retrospectively collected from May 2014 to April 2019 to create 3D MRI glenohumeral models by transfer learning using Dixon-based sequences. Two musculoskeletal radiologists performed measurements on fully and semiautomated segmented 3D MRI models to assess glenohumeral anatomy, glenoid bone loss (GBL), and their impact on treatment selection. Performance of the CNNs was evaluated using Dice similarity coefficient (DSC), sensitivity, precision, and surface-based distance measurements. Measurements were compared using matched-pairs Wilcoxon signed rank test. Results: The two-dimensional CNN model for the humerus and glenoid achieved a DSC of 0.95 and 0.86, a precision of 95.5% and 87.5%, an average precision of 98.6% and 92.3%, and a sensitivity of 94.8% and 86.1%, respectively. The 3D CNN model, for the humerus and glenoid, achieved a DSC of 0.95 and 0.86, precision of 95.1% and 87.1%, an average precision of 98.7% and 91.9%, and a sensitivity of 94.9% and 85.6%, respectively. There was no difference between glenoid and humeral head width fully and semiautomated 3D model measurements (P value range,.097-.99). Conclusion: CNNs could potentially be used in clinical practice to provide rapid and accurate 3D MRI glenohumeral bone models and GBL measurements. (C) RSNA, 2020	[Rodrigues, Tatiane Cantarelli] Hosp Coracao HCOR, Dept Radiol, Rua Desembargador Eliseu Guilherme 53,7th Floor, BR-04004030 Sao Paulo, SP, Brazil; [Rodrigues, Tatiane Cantarelli] Teleimagem, Rua Desembargador Eliseu Guilherme 53,7th Floor, BR-04004030 Sao Paulo, SP, Brazil; [Deniz, Cem M.; Alaia, Erin F.; Gyftopoulos, Soterios] NYU Langone Med Ctr, Dept Radiol, New York, NY USA; [Gorelik, Natalia] McGill Univ, Hlth Ctr, Dept Radiol, Montreal, PQ, Canada; [Babb, James S.; Dublin, Jared] NYU, Sch Med, Dept Radiol, New York, NY USA		Rodrigues, TC (corresponding author), Hosp Coracao HCOR, Dept Radiol, Rua Desembargador Eliseu Guilherme 53,7th Floor, BR-04004030 Sao Paulo, SP, Brazil.; Rodrigues, TC (corresponding author), Teleimagem, Rua Desembargador Eliseu Guilherme 53,7th Floor, BR-04004030 Sao Paulo, SP, Brazil.	tcantarelli@gmail.com	; Cantarelli Rodrigues, Tatiane/S-4577-2018	Babb, James/0000-0003-1798-1186; Deniz, Cem/0000-0001-8809-5945; Cantarelli Rodrigues, Tatiane/0000-0002-7635-8397				Bishop JY, 2013, CLIN ORTHOP RELAT R, V471, P1251, DOI 10.1007/s11999-012-2607-x; Deniz CM, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-34817-6; Di Giacomo G, 2016, KNEE SURG SPORT TR A, V24, P479, DOI 10.1007/s00167-015-3927-7; Gray DJ, 1942, AM J PHYS ANTHROPOL, V29, P57, DOI 10.1002/ajpa.1330290106; Gyftopoulos S, 2014, SKELETAL RADIOL, V43, P213, DOI 10.1007/s00256-013-1774-5; Gyftopoulos S, 2013, SKELETAL RADIOL, V42, P347, DOI 10.1007/s00256-012-1489-z; He X, EPRINT ARXIV19020852; Lee JG, 2014, MED PHYS, V41, DOI 10.1118/1.4893533; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Liu F, 2018, RADIOLOGY, V289, P160, DOI 10.1148/radiol.2018172986; Liu F, 2018, MAGN RESON MED, V79, P2379, DOI 10.1002/mrm.26841; Norman B, 2018, RADIOLOGY, V288, P177, DOI 10.1148/radiol.2018172322; Prasoon A, 2013, LECT NOTES COMPUT SC, V8150, P246, DOI 10.1007/978-3-642-40763-5_31; Rerko MA, 2013, J SHOULDER ELB SURG, V22, P528, DOI 10.1016/j.jse.2012.05.034; Ronneberger O, CORR ARXIV150504597; Samim M, 2019, SKELETAL RADIOL, V48, P429, DOI 10.1007/s00256-018-3049-7; Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI 10.1146/annurev-bioeng-071516-044442; Strauss EJ, 2009, J SHOULDER ELB SURG, V18, P819, DOI 10.1016/j.jse.2009.05.008; Taghanaki SA, ARXIV191007655; Taha AA, 2015, BMC MED IMAGING, V15, DOI 10.1186/s12880-015-0068-x; Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015; Zeng GD, 2018, ADV EXP MED BIOL, V1093, P73, DOI 10.1007/978-981-13-1396-7_6; Zhou ZY, 2018, MAGN RESON MED, V80, P2759, DOI 10.1002/mrm.27229	23	5	5	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2020	2	5							e190116	10.1148/ryai.2020190116	http://dx.doi.org/10.1148/ryai.2020190116			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CY		Green Published, Bronze			2022-12-18	WOS:000826477600002
J	Rudie, JD; Rauschecker, AM; Xie, L; Wang, JC; Duong, MT; Botzolakis, EJ; Kovalovich, A; Egan, JM; Cook, T; Bryan, RN; Nasrallah, IM; Mohan, S; Gee, JC				Rudie, Jeffrey D.; Rauschecker, Andreas M.; Xie, Long; Wang, Jiancong; Duong, Michael Tran; Botzolakis, Emmanuel J.; Kovalovich, Asha; Egan, John M.; Cook, Tessa; Bryan, R. Nick; Nasrallah, Ilya M.; Mohan, Suyash; Gee, James C.			Subspecialty-Level Deep Gray Matter Differential Diagnoses with Deep Learning and Bayesian Networks on Clinical Brain MRI: A Pilot Study	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							MISDIAGNOSIS; PERFORMANCE; RADIOLOGY; MODEL	Purpose: To develop and validate a system that could perform automated diagnosis of common and rare neurologic diseases involving deep gray matter on clinical brain MRI studies. Materials and Methods: In this retrospective study, multimodal brain MRI scans from 212 patients (mean age, 55 years 6 17 [standard deviation]; 113 women) with 35 neurologic diseases and normal brain MRI scans obtained between January 2008 and January 2018 were included (110 patients in the training set, 102 patients in the test set). MRI scans from 178 patients (mean age, 48 years 6 17; 106 women) were used to supplement training of the neural networks. Three-dimensional convolutional neural networks and atlasbased image processing were used for extraction of 11 imaging features. Expert-derived Bayesian networks incorporating domain knowledge were used for differential diagnosis generation. The performance of the artificial intelligence (AI) system was assessed by comparing diagnostic accuracy with that of radiologists of varying levels of specialization by using the generalized estimating equation with robust variance estimator for the top three differential diagnoses (T3DDx) and the correct top diagnosis (TDx), as well as with receiver operating characteristic analyses. Results: In the held-out test set, the imaging pipeline detected 11 key features on brain MRI scans with 89% accuracy (sensitivity, 81%; specificity, 95%) relative to academic neuroradiologists. The Bayesian network, integrating imaging features with clinical information, had an accuracy of 85% for T3DDx and 64% for TDx, which was better than that of radiology residents (n = 4; 56% for T3DDx, 36% for TDx; P,.001 for both) and general radiologists (n = 2; 53% for T3DDx, 31% for TDx; P,.001 for both). The accuracy of the Bayesian network was better than that of neuroradiology fellows (n = 2) for T3DDx (72%; P =.003) but not for TDx (59%; P =.19) and was not different from that of academic neuroradiologists (n = 2; 84% T3DDx, 65% TDx; P..09 for both). Conclusion: A hybrid AI system was developed that simultaneously provides a quantitative assessment of disease burden, explainable intermediate imaging features, and a probabilistic differential diagnosis that performed at the level of academic neuroradiologists. This type of approach has the potential to improve clinical decision making for common and rare diseases. (C) RSNA, 2020	[Rudie, Jeffrey D.; Xie, Long; Kovalovich, Asha; Egan, John M.; Cook, Tessa; Nasrallah, Ilya M.; Mohan, Suyash; Gee, James C.] Hosp Univ Penn, Dept Radiol, 3400 Spruce St, Philadelphia, PA 19104 USA; [Rudie, Jeffrey D.; Rauschecker, Andreas M.] Univ Calif San Francisco, Dept Radiol & Biomed Imaging, San Francisco, CA 94143 USA; [Xie, Long; Wang, Jiancong] Univ Penn, Penn Image Comp & Sci Lab, Philadelphia, PA 19104 USA; [Duong, Michael Tran] Univ Penn, Perelman Sch Med, Philadelphia, PA 19104 USA; [Botzolakis, Emmanuel J.] Mecklenburg Radiol Associates, Charlotte, NC USA; [Bryan, R. Nick] Univ Texas Austin, Dept Radiol, Austin, TX 78712 USA; [Nasrallah, Ilya M.] Univ Penn, Dept Radiol, Div Nucl Med & Clin Mol Imaging, Philadelphia, PA 19104 USA	University of Pennsylvania; Pennsylvania Medicine; University of California System; University of California San Francisco; University of Pennsylvania; University of Pennsylvania; Pennsylvania Medicine; University of Texas System; University of Texas Austin; University of Pennsylvania	Rudie, JD (corresponding author), Hosp Univ Penn, Dept Radiol, 3400 Spruce St, Philadelphia, PA 19104 USA.; Rudie, JD (corresponding author), Univ Calif San Francisco, Dept Radiol & Biomed Imaging, San Francisco, CA 94143 USA.	Jeff.Rudie@gmail.com		Rauschecker, Andreas/0000-0003-0633-9876; Duong, Michael Tran/0000-0003-0312-5530; Xie, Long/0000-0002-7184-7028; Rudie, Jeffrey/0000-0001-8609-8421; Botzolakis, Emmanuel/0000-0002-2494-9670	NVIDIA	NVIDIA	We thank the following individuals who helped generate some of the preliminary manual segmentations: Rachit Saluja, David A. Weiss, and Vanessa Franca Rudie. We gratefully acknowledge the support of NVIDIA, who donated the Titan Xp GPUs used for this research as part of the NVIDIA GPU grant program (J.D.R., A.M.R.).	Avants BB, 2011, NEUROIMAGE, V54, P2033, DOI 10.1016/j.neuroimage.2010.09.025; Bielza C, 2014, FRONT COMPUT NEUROSC, V8, DOI 10.3389/fncom.2014.00131; Briggs GM, 2008, CLIN RADIOL, V63, P791, DOI 10.1016/j.crad.2007.12.002; Bruno MA, 2015, RADIOGRAPHICS, V35, P1668, DOI 10.1148/rg.2015150023; Busby LP, 2018, RADIOGRAPHICS, V38, P236, DOI 10.1148/rg.2018170107; Chartrand G, 2017, RADIOGRAPHICS, V37, P2113, DOI 10.1148/rg.2017170077; Chowdhury FA, 2008, EUR J NEUROL, V15, P1034, DOI 10.1111/j.1468-1331.2008.02260.x; Cicek Ozgun, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P424, DOI 10.1007/978-3-319-46723-8_49; Das SR, 2009, NEUROIMAGE, V45, P867, DOI 10.1016/j.neuroimage.2008.12.016; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; Do BH, 2017, J DIGIT IMAGING, V30, P640, DOI 10.1007/s10278-017-0001-7; Duong MT, 2019, AM J NEURORADIOL, V40, P1282, DOI 10.3174/ajnr.A6138; ESR, 2016, INSIGHTS IMAGING, V7, P1, DOI 10.1007/s13244-015-0453-6; Gunderman RB, 2009, AM J ROENTGENOL, V192, P561, DOI 10.2214/AJR.08.1220; Hegde AN, 2011, RADIOGRAPHICS, V31, P5, DOI 10.1148/rg.311105041; Kahn CE, 2001, J DIGIT IMAGING, V14, P56, DOI [10.1007/BF03190296, 10.1053/jdim.2001.23816]; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Lee H, 2019, NAT BIOMED ENG, V3, P173, DOI 10.1038/s41551-018-0324-9; McDonald RJ, 2015, ACAD RADIOL, V22, P1191, DOI 10.1016/j.acra.2015.05.007; Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79; Parasuraman R, 2000, IEEE T SYST MAN CY A, V30, P286, DOI 10.1109/3468.844354; Park SH, 2018, RADIOLOGY, V286, P800, DOI 10.1148/radiol.2017171920; Pearl J., 1988, PROBABILISTIC REASON, DOI 10.1016/B978-0-08-051489-5.50008-4; Rauschecker AM, 2020, RADIOLOGY, V295, P626, DOI 10.1148/radiol.2020190283; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Solomon AJ, 2016, NEUROLOGY, V87, P1393, DOI 10.1212/WNL.0000000000003152; Tarnutzer AA, 2017, NEUROLOGY, V88, P1468, DOI 10.1212/WNL.0000000000003814; TVERSKY A, 1973, COGNITIVE PSYCHOL, V5, P207, DOI 10.1016/0010-0285(73)90033-9; Yasaka K, 2018, RADIOLOGY, V286, P899, DOI 10.1148/radiol.2017170706	29	5	6	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2020	2	5							e190146	10.1148/ryai.2020190146	http://dx.doi.org/10.1148/ryai.2020190146			13	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CY	33937838	Green Published			2022-12-18	WOS:000826477600003
J	Retson, TA; Masutani, EM; Golden, D; Hsiao, A				Retson, Tara A.; Masutani, Evan M.; Golden, Daniel; Hsiao, Albert			Clinical Performance and Role of Expert Supervision of Deep Learning for Cardiac Ventricular Volumetry: A Validation Study	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To evaluate the performance of a deep learning (DL) algorithm for clinical measurement of right and left ventricular volume and function across cardiac MR images obtained for a range of clinical indications and pathologies. Materials and Methods: A retrospective, Health Insurance Portability and Accountability Act-compliant study was conducted using the first 200 noncongenital clinical cardiac MRI examinations from June 2015 to June 2017 for which volumetry was available. Images were analyzed using commercially available software for automated DL-based and manual contouring of biventricular volumes. Fully automated measurements were compared using Pearson correlations, relative volume errors, and Bland-Altman analyses. Manual, automated, and expert revised contours for 50 MR images were examined by comparing regional Dice coefficients at the base, midventricle, and apex to further analyze the contour quality. Results: Fully automated and manual left ventricular volumes were strongly correlated for end-systolic volume (ESV: Pearson r = 0.99, P<.001), end-diastolic volume (EDV: r = 0.97, P<.001), and ejection fraction (EF: r = 0.94, P<.001). Right ventricular measurements were also correlated for ESV (r = 0.93, P<.001), EDV (r = 0.92, P<.001), and EF (r = 0.73, P<.001). Visual inspection of segmentation quality showed most errors (73%) occurred at the cardiac base. Mean Dice coefficients between manual, automated, and expert revised contours ranged from 0.92 to 0.95, with greatest variance at the base and apex. Conclusion: Fully automated ventricular segmentation by the tested algorithm provides contours and ventricular volumes that could be used to aid expert segmentation, but can benefit from expert supervision, particularly to resolve errors at the basal and apical slices.(C) RSNA, 2020	[Retson, Tara A.; Hsiao, Albert] Univ Calif San Diego, Altman Clin & Translat Res Inst, Dept Radiol, 9452 Med Ctr Dr,4th Floor, La Jolla, CA 92037 USA; [Masutani, Evan M.] Univ Calif San Diego, Sch Med, Dept Bioengn, La Jolla, CA 92037 USA; [Golden, Daniel] Anerys, San Francisco, CA USA		Retson, TA (corresponding author), Univ Calif San Diego, Altman Clin & Translat Res Inst, Dept Radiol, 9452 Med Ctr Dr,4th Floor, La Jolla, CA 92037 USA.	tretson@ucs.edu		Retson, Tara/0000-0002-0009-7733; Hsiao, Albert/0000-0002-9412-1369	NIH T32 training grant [EB005970]; National Institutes of Health [T32 HL 105373]	NIH T32 training grant(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	T.A.R. Activities related to the present article: disclosed no relevant relationships. Activities not related to the present article: institution receives RSNA Resident Research grant; institution (UC San Diego) receives money for patent for MRI plane prescription software; author part of research residency at UCSD funded by NIH T32 training grant EB005970. Other relationships: disclosed no relevant relationships. E.M.M. Activities related to the present article: institution receives grant from National Institutes of Health (T32 HL 105373). Activities not related to the present article: disclosed no relevant relationships. Other relationships: disclosed no relevant relationships. D.G. Activities related to the present article: disclosed no relevant relationships. Activities not related to the present article: employed by Arterys. Other relationships: disclosed no relevant relationships. A.H. Activities related to the present article: disclosed no relevant relationships. Activities not related to the present article: author is consultant/cofounder for Arterys; institution receives grant from GE Healthcare and Bayer; author paid for lectures by GE Healthcare and Bayer; institution has patent (Stan-ford University, UC San Diego, and Arterys); author receives royalties from Stanford University; author is founding shareholder in Arterys; author receives travel accommodations from GE Healthcare and Arterys. Other relationships: disclosed no relevant relationships.	Avendi MR, 2017, MAGN RESON MED, V78, P2439, DOI 10.1002/mrm.26631; Bahrami N, 2019, MAGN RESON MED, V81, P3283, DOI 10.1002/mrm.27680; Beerbaum P, 2009, J MAGN RESON IMAGING, V30, P956, DOI 10.1002/jmri.21948; Bernard O, 2018, IEEE T MED IMAGING, V37, P2514, DOI 10.1109/TMI.2018.2837502; Bonnemains L, 2012, MAGN RESON MED, V67, P1740, DOI 10.1002/mrm.23143; Catalano O, 2007, J CARDIOVASC MED, V8, P807, DOI 10.2459/JCM.0b013e32801105ef; Caudron J, 2011, EUR RADIOL, V21, P2111, DOI 10.1007/s00330-011-2152-0; Childs H, 2011, J CARDIOVASC MAGN R, V13, DOI 10.1186/1532-429X-13-40; Cocosco CA, 2008, J MAGN RESON IMAGING, V28, P366, DOI 10.1002/jmri.21451; Flett AS, 2009, CIRC-CARDIOVASC IMAG, V2, P243, DOI 10.1161/CIRCIMAGING.108.840975; Groth M, 2012, ROFO-FORTSCHR RONTG, V184, P1131, DOI 10.1055/s-0032-1313171; Hendel RC, 2006, J AM COLL CARDIOL, V48, P1475, DOI 10.1016/j.jacc.2006.07.003; Karamiltsos TD, 2007, J CARDIOVASC MAGN R, V9, P777, DOI 10.1080/10976640701545073; Lehnert B, 2015, BLANDALTMANLEH; Lieman-Sifry J, ARXIV PREPRINT; Lorenzo-Valdes M, 2004, MED IMAGE ANAL, V8, P255, DOI 10.1016/j.media.2004.06.005; Narayan T, AUTOMATED LEFT VENTR; Pednekar AS, 2008, J MAGN RESON IMAGING, V28, P39, DOI 10.1002/jmri.21363; Peng P, 2016, MAGN RESON MATER PHY, V29, P155, DOI 10.1007/s10334-015-0521-4; Pesenti-Rossi D, 2013, ANN CARDIOL ANGEIOL, V62, P326, DOI 10.1016/j.ancard.2013.08.010; Petersen SE, 2013, J CARDIOVASC MAGN R, V15, DOI 10.1186/1532-429X-15-46; Petitjean C, RIGHT VENTRICLE SEGM; Petitjean C, 2011, MED IMAGE ANAL, V15, P169, DOI 10.1016/j.media.2010.12.004; Radau P, MIDAS J CARDIAC MR L; Radau P., CARDIAC ATLAS PROJEC; Revelle W., **DATA OBJECT**; Ringenberg J, 2014, COMPUT MED IMAG GRAP, V38, P190, DOI 10.1016/j.compmedimag.2013.12.011; Schulz-Menger J, 2013, J CARDIOVASC MAGN R, V15, DOI 10.1186/1532-429X-15-35; Slomka PJ, 2017, EXPERT REV MED DEVIC, V14, P197, DOI 10.1080/17434440.2017.1300057; Suinesiaputra Avail, 2012, Statistical Atlases and Computational Models of the Heart. Imaging and Modelling Challenges. Second International Workshop, STACOM 2011 Held in Conjunction with MICCAI 2011. Revised Selected Papers, P88, DOI 10.1007/978-3-642-28326-0_9; Suinesiaputra A, 2015, J CARDIOVASC MAGN R, V17, DOI 10.1186/s12968-015-0170-9; Suinesiaputra A, 2014, MED IMAGE ANAL, V18, P50, DOI 10.1016/j.media.2013.09.001; Tan LK, 2018, J MAGN RESON IMAGING, V48, P140, DOI 10.1002/jmri.25932; Tao Q, 2019, RADIOLOGY, V290, P81, DOI 10.1148/radiol.2018180513; Wickham H, 2009, USE R, P1, DOI 10.1007/978-0-387-98141-3_1; Zhuang X, 2008, PROC SPIE, V6914, DOI 10.1117/12.769445	36	5	5	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2020	2	4							e190064	10.1148/ryai.2020190064	http://dx.doi.org/10.1148/ryai.2020190064			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CX	32797119	Bronze, Green Published			2022-12-18	WOS:000826472900002
J	Mongan, J; Kohli, M				Mongan, John; Kohli, Marc			Artificial Intelligence and Human Life: Five Lessons for Radiology from the 737 MAX Disasters	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Mongan, John; Kohli, Marc] Univ Calif San Francisco, Dept Radiol & Biomed Imaging, 505 Parnassus Ave, San Francisco, CA 94143 USA	University of California System; University of California San Francisco	Mongan, J (corresponding author), Univ Calif San Francisco, Dept Radiol & Biomed Imaging, 505 Parnassus Ave, San Francisco, CA 94143 USA.	john.mongan@ucsf.edu		Mongan, John/0000-0003-2765-7451; Kohli, Marc D/0000-0003-3720-0156				FAA, 2011, FAA NEEDS STRENGTH I; Food and Drugs Administration, 2019, PROP REG FRAM MOD AR; Gallagher S., 2019, LION AIR 737 MAX CRE; Gallagher S., 2019, IBID; Gates D., 2019, SEATTLE TIMES 0321; Helmreich RL, 2000, BRIT MED J, V320, P781, DOI 10.1136/bmj.320.7237.781; Newburger E, 2019, CNBC; Vartabedian R., 2019, LOS ANGELES TIMES; Wachter R, 2015, HLTH CARE BLOG	9	5	5	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2020	2	2							e190111	10.1148/ryai.2020190111	http://dx.doi.org/10.1148/ryai.2020190111			3	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CS		Bronze, Green Published			2022-12-18	WOS:000826298800007
J	Erickson, BJ; Cai, JS				Erickson, Bradley J.; Cai, Jason			Magician's Corner: 4. Image Segmentation with U-Net	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Erickson, Bradley J.; Cai, Jason] Mayo Clin, Dept Radiol, 200 First St SW, Rochester, MN 55905 USA	Mayo Clinic	Erickson, BJ (corresponding author), Mayo Clin, Dept Radiol, 200 First St SW, Rochester, MN 55905 USA.	bje@mayo.edu		/0000-0002-9190-0252; Erickson, Bradley/0000-0001-7926-6095				[Anonymous], 1999, 10153 BS EN; keras, OPTIMIZERS KERAS DOC; Kingma DP, ARXIV CSLG PREPRINT; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Sharma N, 2010, J MED PHYS, V35, P3, DOI 10.4103/0971-6203.58777; SORENSEN R, 1948, NORD MED, V40, P2389; SUETENS P, 1993, EUR J RADIOL, V17, P14, DOI 10.1016/0720-048X(93)90023-G; Sullivan DC, 2015, RADIOLOGY, V277, P813, DOI 10.1148/radiol.2015142202	8	5	5	0	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2020	2	1							e190161	10.1148/ryai.2020190161	http://dx.doi.org/10.1148/ryai.2020190161			4	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CR	33937814	Green Published			2022-12-18	WOS:000826298000010
J	Rudie, JD; Gleason, T; Barkovich, MJ; Wilson, DM; Shankaranarayanan, A; Zhang, T; Wang, L; Gong, EH; Zaharchuk, G; Villanueva-Meyer, JE				Rudie, Jeffrey D.; Gleason, Tyler; Barkovich, Matthew J.; Wilson, David M.; Shankaranarayanan, Ajit; Zhang, Tao; Wang, Long; Gong, Enhao; Zaharchuk, Greg; Villanueva-Meyer, Javier E.			Clinical Assessment of Deep Learning-based Super-Resolution for 3D Volumetric Brain MRI	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						MR Imaging; CNS; Brain/Brain Stem; Reconstruction Algorithms		Artificial intelligence (AI)-based image enhancement has the potential to reduce scan times while improving signal-to-noise ratio (SNR) and maintaining spatial resolution. This study prospectively evaluated AI-based image enhancement in 32 consecutive patients undergoing clinical brain MRI. Standard-of-care (SOC) three-dimensional (3D) T1 precontrast, 3D T2 fluid-attenuated inversion recovery, and 3D T1 post-contrast sequences were performed along with 45% faster versions of these sequences using half the number of phase-encoding steps. Images from the faster sequences were processed by a Food and Drug Administration-cleared AI-based image enhancement software for resolution enhancement. Four board-certified neuroradiologists scored the SOC and AI-enhanced image series independently on a five-point Likert scale for image SNR, anatomic conspicuity, overall image quality, imaging artifacts, and diagnostic confidence. While interrater k was low to fair, the AI-enhanced scans were noninferior for all metrics and actually demonstrated a qualitative SNR improvement. Quantitative analyses showed that the AI software restored the high spatial resolution of small structures, such as the septum pellucidum. In conclusion, AI-based software can achieve noninferior image quality for 3D brain MRI sequences with a 45% scan time reduction, potentially improving the patient experience and scanner efficiency without sacrificing diagnostic quality. (C)RSNA, 2022	[Rudie, Jeffrey D.; Gleason, Tyler; Barkovich, Matthew J.; Wilson, David M.; Villanueva-Meyer, Javier E.] Univ Calif San Francisco, Dept Radiol & Biomed Imaging, 505 Parnassus Ave,L-352, San Francisco, CA 94143 USA; [Shankaranarayanan, Ajit; Zhang, Tao; Wang, Long; Gong, Enhao] Subtle Med, Menlo Pk, CA USA; [Zaharchuk, Greg] Stanford Univ, Dept Radiol, Stanford, CA 94305 USA	University of California System; University of California San Francisco; Stanford University	Villanueva-Meyer, JE (corresponding author), Univ Calif San Francisco, Dept Radiol & Biomed Imaging, 505 Parnassus Ave,L-352, San Francisco, CA 94143 USA.	javier.villanueva-meyer@ucsf.edu		Villanueva-Meyer, Javier/0000-0002-5910-0757; Rudie, Jeffrey/0000-0001-8609-8421				Antun V, 2020, P NATL ACAD SCI USA, V117, P30088, DOI 10.1073/pnas.1907377117; Bahrami K, 2016, IEEE T MED IMAGING, V35, P2085, DOI 10.1109/TMI.2016.2549918; Bash S, 2021, AM J NEURORADIOL, V42, P2130, DOI 10.3174/ajnr.A7358; Chaudhari AS, 2018, MAGN RESON MED, V80, P2139, DOI 10.1002/mrm.27178; Darestani M. Z., ARXIV; Do WJ, 2020, MED PHYS, V47, P983, DOI 10.1002/mp.14006; Gong E, 2018, J MAGN RESON IMAGING, V48, P330, DOI 10.1002/jmri.25970; Hamilton J, 2017, PROG NUCL MAG RES SP, V101, P71, DOI 10.1016/j.pnmrs.2017.04.002; Mardani M, 2019, IEEE T MED IMAGING, V38, P167, DOI 10.1109/TMI.2018.2858752; MELENDEZ JC, 1993, JAMA-J AM MED ASSOC, V270, P745, DOI 10.1001/jama.270.6.745; Pham CH, 2017, I S BIOMED IMAGING, P197, DOI 10.1109/ISBI.2017.7950500; SCHUNK H, 1963, RADIOLOGY, V81, P610, DOI 10.1148/81.4.610; Ye Jong Chul, 2019, BMC Biomed Eng, V1, P8, DOI 10.1186/s42490-019-0006-z; Zech JR, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002683	15	4	4	4	5	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2022	4	2							e210059	10.1148/ryai.210059	http://dx.doi.org/10.1148/ryai.210059			6	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9YB	35391765	Green Published			2022-12-18	WOS:000826922700002
J	Seyam, M; Weikert, T; Sauter, A; Brehm, A; Psychogios, MN; Blackham, KA				Seyam, Muhannad; Weikert, Thomas; Sauter, Alexander; Brehm, Alex; Psychogios, Marios-Nikos; Blackham, Kristine A.			Utilization of Artificial Intelligence-based Intracranial Hemorrhage Detection on Emergent Noncontrast CT Images in Clinical Workflow	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						CT; CNS; Stroke; Diagnosis; Classification; Application Domain	INTRACEREBRAL HEMORRHAGE	Authors implemented an artificial intelligence (AI)-based detection tool for intracranial hemorrhage (ICH) on noncontrast CT images into an emergent workflow, evaluated its diagnostic performance, and assessed clinical workflow metrics compared with pre-AI implementation. The finalized radiology report constituted the ground truth for the analysis, and CT examinations (n = 4450) before and after implementation were retrieved using various keywords for ICH. Diagnostic performance was assessed, and mean values with their respective 95% CIs were reported to compare workflow metrics (report turnaround time, communication time of a finding, consultation time of another specialty, and turnaround time in the emergency department). Although practicable diagnostic performance was observed for overall ICH detection with 93.0% diagnostic accuracy, 87.2% sensitivity, and 97.8% negative predictive value, the tool yielded lower detection rates for specific subtypes of ICH (eg, 69.2% [74 of 107] for subdural hemorrhage and 77.4% [24 of 31] for acute subarachnoid hemorrhage). Common false-positive findings included postoperative and postischemic defects (23.6%, 37 of 157), artifacts (19.7%, 31 of 157), and tumors (15.3%, 24 of 157). Although workflow metrics such as communicating a critical finding (70 minutes [95% CI: 54, 85] vs 63 minutes [95% CI: 55, 71]) were on average reduced after implementation, future efforts are necessary to streamline the workflow all along the workflow chain. It is crucial to define a clear framework and recognize limitations as AI tools are only as reliable as the environment in which they are deployed. (C)RSNA, 2022	[Seyam, Muhannad; Brehm, Alex; Psychogios, Marios-Nikos; Blackham, Kristine A.] Univ Hosp Basel, Dept Diagnost & Intervent Neuroradiol, Clin Radiol & Nucl Med, Petersgraben 4, CH-4031 Basel, Switzerland; [Weikert, Thomas; Sauter, Alexander] Univ Hosp Basel, Dept Radiol & Nucl Med, Petersgraben 4, CH-4031 Basel, Switzerland; [Seyam, Muhannad] Univ Vermont, Dept Neurol Sci, Med Ctr, Burlington, VT USA	University of Basel; University of Basel; University of Vermont; University of Vermont Medical Center	Blackham, KA (corresponding author), Univ Hosp Basel, Dept Diagnost & Intervent Neuroradiol, Clin Radiol & Nucl Med, Petersgraben 4, CH-4031 Basel, Switzerland.	kristineann.blackham@usb.ch		Sauter, Alexander/0000-0002-6707-2258; Weikert, Thomas/0000-0001-9274-053X				Anderson CS, 2013, NEW ENGL J MED, V368, P2355, DOI 10.1056/NEJMoa1214609; Arbabshirani MR, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-017-0015-z; Blok KM, 2015, NEUROLOGY, V84, P1927, DOI 10.1212/WNL.0000000000001562; BRODERICK JP, 1993, STROKE, V24, P987, DOI 10.1161/01.STR.24.7.987; Connolly ES, 2012, STROKE, V43, P1711, DOI 10.1161/STR.0b013e3182587839; Cortnum S, 2010, NEUROSURGERY, V66, P900, DOI [10.1227/01.NEU.0000367722.66098.21, 10.1227/01. NEU.0000367722.66098.21]; Davis MA, 2020, CURR PROBL DIAGN RAD; Ginat D, 2021, BRAIN SCI, V11, DOI 10.3390/brainsci11070832; Ginat DT, 2020, NEURORADIOLOGY, V62, P335, DOI 10.1007/s00234-019-02330-w; Hassan AE, 2021, J NEUROINTERV SURG, V13, P406, DOI 10.1136/neurintsurg-2020-016897; Hassan AE, 2020, INTERV NEURORADIOL, V26, P615, DOI 10.1177/1591019920953055; Hemphill JC, 2015, STROKE, V46, P2032, DOI 10.1161/STR.0000000000000069; Khurram A, 2014, STROKE, V45, P1151, DOI 10.1161/STROKEAHA.113.004298; O'Neill TJ, 2020, RADIOL ARTIF INTELL, V3; Olive-Gadea M, 2020, STROKE, V51, P3133, DOI 10.1161/STROKEAHA.120.030326; Rao B, 2021, ACAD RADIOL, V28, P85, DOI 10.1016/j.acra.2020.01.035; Weikert T, 2020, EUR RADIOL, V30, P6545, DOI 10.1007/s00330-020-06998-0; Yeo M, 2021, J NEUROINTERV SURG, V13, P369, DOI 10.1136/neurintsurg-2020-017099; Zahuranec DB, 2014, NEUROLOGY, V82, P2180, DOI 10.1212/WNL.0000000000000519	19	4	4	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2022	4	2							e210168	10.1148/ryai.210168	http://dx.doi.org/10.1148/ryai.210168			6	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9YB	35391777	Green Published			2022-12-18	WOS:000826922700011
J	Candemir, S; Nguyen, XV; Folio, LR; Prevedello, LM				Candemir, Sema; Nguyen, Xuan, V; Folio, Les R.; Prevedello, Luciano M.			Training Strategies for Radiology Deep Learning Models in Data-limited Scenarios	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Computer-aided Detection/Diagnosis; Transfer Learning; Limited Annotated Data; Augmentation; Synthetic Data; Semisupervised Learning; Federated Learning; Few-Shot Learning; Class Imbalance	CONVOLUTIONAL NEURAL-NETWORKS; PERFORMANCE; AUGMENTATION; TECHNOLOGY; GUIDE	Data-driven approaches have great potential to shape future practices in radiology. The most straightforward strategy to obtain clinically accurate models is to use large, well-curated and annotated datasets. However, patient privacy constraints, tedious annotation processes, and the limited availability of radiologists pose challenges to building such datasets. This review details model training strategies in scenarios with limited data, insufficiently labeled data, and/or limited expert resources. This review discusses strategies to enlarge the data sample, decrease the time burden of manual supervised labeling, adjust the neural network architecture to improve model performance, apply semisupervised approaches, and leverage efficiencies from pretrained models. (C) RSNA, 2021.	[Candemir, Sema; Nguyen, Xuan, V; Prevedello, Luciano M.] Ohio State Univ, Coll Med, Dept Radiol, 395 W 12th Ave, Columbus, OH 43212 USA; [Folio, Les R.] NIH, Dept Radiol & Imaging Sci, Clin Ctr, Bldg 10, Bethesda, MD 20892 USA	University System of Ohio; Ohio State University; National Institutes of Health (NIH) - USA; NIH Clinical Center (CC)	Candemir, S (corresponding author), Ohio State Univ, Coll Med, Dept Radiol, 395 W 12th Ave, Columbus, OH 43212 USA.	sema.candemir@osumc.edu	Candemir, Sema/X-2002-2019	Candemir, Sema/0000-0001-8619-5619; Prevedello, Luciano/0000-0002-6768-6452	Department of Radiology of The Ohio State University College of Medicine; Intramural Research Program of the National Institutes of Health Clinical Center	Department of Radiology of The Ohio State University College of Medicine(General Electric); Intramural Research Program of the National Institutes of Health Clinical Center(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	Supported by the Department of Radiology of The Ohio State University College of Medicine and in part by the Intramural Research Program of the National Institutes of Health Clinical Center.	Beam AL, 2020, JAMA-J AM MED ASSOC, V323, P305, DOI 10.1001/jama.2019.20866; Beesley SD, 2019, J AM COLL RADIOL, V16, P465, DOI 10.1016/j.jacr.2018.10.009; Cai ZX, 2019, IEEE DATA MINING, P41, DOI 10.1109/ICDM.2019.00014; Calimeri F, 2017, LECT NOTES COMPUT SC, V10614, P626, DOI 10.1007/978-3-319-68612-7_71; Candemir S, 2020, J MED IMAGING, V7, DOI 10.1117/1.JMI.7.4.044501; Candemir S, 2018, 2018 IEEE LIFE SCIENCES CONFERENCE (LSC), P109, DOI 10.1109/LSC.2018.8572113; Carneiro G, 2015, LECT NOTES COMPUT SC, V9351, P652, DOI 10.1007/978-3-319-24574-4_78; Chartrand G, 2017, RADIOGRAPHICS, V37, P2113, DOI 10.1148/rg.2017170077; Chawla NV, 2010, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, SECOND EDITION, P875, DOI 10.1007/978-0-387-09823-4_45; Chen MC, 2018, RADIOLOGY, V286, P845, DOI 10.1148/radiol.2017171115; Chen S, ARXIV 190400625 PREP; Cheplygina V, 2019, MED IMAGE ANAL, V54, P280, DOI 10.1016/j.media.2019.03.009; Chuquicusma MJM, 2018, I S BIOMED IMAGING, P240; Dikici E, 2021, J MED IMAGING, V8, DOI 10.1117/1.JMI.8.2.024004; Do HM, 2020, ACAD RADIOL, V27, P96, DOI 10.1016/j.acra.2019.09.014; Esmaeilzadeh S, 2018, LECT NOTES COMPUT SC, V11046, P337, DOI 10.1007/978-3-030-00919-9_39; Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z; Filipovych R, 2011, NEUROIMAGE, V54, P2185, DOI 10.1016/j.neuroimage.2010.09.074; Folio LR, 2015, AM J ROENTGENOL, V205, pW233, DOI 10.2214/AJR.14.14054; Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Gupta V, 2020, J DIGIT IMAGING, V33, P431, DOI 10.1007/s10278-019-00267-3; Gur Y, 2017, LECT NOTES COMPUT SC, V10552, P87, DOI 10.1007/978-3-319-67534-3_10; Han X, ARXIV 170407239 PREP; He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239; ImageNet, US; Ioffe S., 2015, P 32 INT C INT C MAC, V37, P448; Kingma DP, 2014, ADV NEUR IN, V27; Koch G., 2015, ICML DEEP LEARN WORK; Krawczyk B, 2016, PROG ARTIF INTELL, V5, P221, DOI 10.1007/s13748-016-0094-0; Kukacka J, ARXIV 171010686 PREP; Lampert TA, 2016, IEEE T IMAGE PROCESS, V25, P2557, DOI 10.1109/TIP.2016.2544703; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Liang M, 2015, PROC CVPR IEEE, P3367, DOI 10.1109/CVPR.2015.7298958; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Lundervold A. S., 2017, P 2 INT SCI S FUNCT; Madani A, 2018, PROC SPIE, V10574, DOI 10.1117/12.2293971; Maleki F, 2020, NEUROIMAG CLIN N AM, V30, P433, DOI 10.1016/j.nic.2020.08.004; Medela A, 2019, I S BIOMED IMAGING, P1860, DOI 10.1109/ISBI.2019.8759182; Moradi M, 2018, LECT NOTES COMPUT SC, V11070, P449, DOI 10.1007/978-3-030-00928-1_51; Mullick SS, 2019, IEEE I CONF COMP VIS, P1695, DOI 10.1109/ICCV.2019.00178; Park SH, 2018, RADIOLOGY, V286, P800, DOI 10.1148/radiol.2017171920; Paul A, 2021, IEEE T MED IMAGING, V40, P2642, DOI 10.1109/TMI.2021.3054817; Pouyanfar S, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P112, DOI 10.1109/MIPR.2018.00027; Qizhe Xie, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10684, DOI 10.1109/CVPR42600.2020.01070; Radiology preprocessing curriculum, RAD PREPR COURS WEB; Raghu M, ARXIV 190207208 PREP; Rajpurkar P, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002686; Rieke N, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00323-1; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Saier MH, 2007, WATER AIR SOIL POLL, V181, P1, DOI 10.1007/s11270-007-9372-6; Salehinejad H, 2019, IEEE T MED IMAGING, V38, P1197, DOI 10.1109/TMI.2018.2881415; Salimans T, 2016, ADV NEUR IN, V29; Santoro A, ARXIV 160506065 PREP; Schlegl T, 2017, LECT NOTES COMPUT SC, V10265, P146, DOI 10.1007/978-3-319-59050-9_12; Sheller MJ, 2019, LECT NOTES COMPUT SC, V11383, P92, DOI 10.1007/978-3-030-11723-8_9; Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI 10.1146/annurev-bioeng-071516-044442; Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162; Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0; Signoroni A, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102046; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Stember J.N., 2020, RADIOL, V3, DOI [10.1148/ryai.2020200047, DOI 10.1148/RYAI.2020200047]; Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302; Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369; Wei Q, 2018, PROC SPIE, V10575, DOI 10.1117/12.2293408; Willemink MJ, 2020, RADIOLOGY, V295, P4, DOI 10.1148/radiol.2020192224; Wong TT, 2015, PATTERN RECOGN, V48, P2839, DOI 10.1016/j.patcog.2015.03.009; Yan K, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.3.036501; Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981; Yi X, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101552; Yosinski J, 2014, ADV NEUR IN, V27; Zhe L, 2018, PROC CVPR IEEE, P8290, DOI 10.1109/CVPR.2018.00865; Zhou SK, 2021, P IEEE, V109, P820, DOI 10.1109/JPROC.2021.3054390; Zhu Z, 2019, COMPUT BIOL MED, V109, P85, DOI 10.1016/j.compbiomed.2019.04.018	76	4	4	8	12	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2021	3	6							e210014	10.1148/ryai.2021210014	http://dx.doi.org/10.1148/ryai.2021210014			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9UW	34870217	Green Published			2022-12-18	WOS:000826914400007
J	McCrindle, B; Zukotynski, K; Doyle, TE; Noseworthy, MD				McCrindle, Brian; Zukotynski, Katherine; Doyle, Thomas E.; Noseworthy, Michael D.			A Radiology-focused Review of Predictive Uncertainty for AI Interpretability in Computer-assisted Segmentation	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Review						Segmentation; Quantification; Ethics; Bayesian Network (BN)		The recent advances and availability of computer hardware, software tools, and massive digital data archives have enabled the rapid development of artificial intelligence (AI) applications. Concerns over whether AI tools can "communicate" decisions to radiologists and primary care physicians is of particular importance because automated clinical decisions can substantially impact patient outcome. A challenge facing the clinical implementation of AI stems from the potential lack of trust clinicians have in these predictive models. This review will expand on the existing literature on interpretability methods for deep learning and review the state-of-the-art methods for predictive uncertainty estimation for computer-assisted segmentation tasks. Last, we discuss how uncertainty can improve predictive performance and model interpretability and can act as a tool to help foster trust. (C) RSNA, 2021.	[McCrindle, Brian; Doyle, Thomas E.; Noseworthy, Michael D.] McMaster Univ, Dept Elect & Comp Engn, 1280 Main St W, Hamilton, ON L8S 4L8, Canada; [Zukotynski, Katherine; Noseworthy, Michael D.] McMaster Univ, Fac Hlth Sci, Dept Radiol, 1280 Main St W, Hamilton, ON L8S 4L8, Canada; [Zukotynski, Katherine; Doyle, Thomas E.; Noseworthy, Michael D.] McMaster Univ, Sch Biomed Engn, 1280 Main St W, Hamilton, ON L8S 4L8, Canada; [Doyle, Thomas E.] Vector Inst Artificial Intelligence, Toronto, ON, Canada	McMaster University; McMaster University; McMaster University	Noseworthy, MD (corresponding author), McMaster Univ, Dept Elect & Comp Engn, 1280 Main St W, Hamilton, ON L8S 4L8, Canada.; Noseworthy, MD (corresponding author), McMaster Univ, Fac Hlth Sci, Dept Radiol, 1280 Main St W, Hamilton, ON L8S 4L8, Canada.; Noseworthy, MD (corresponding author), McMaster Univ, Sch Biomed Engn, 1280 Main St W, Hamilton, ON L8S 4L8, Canada.	nosewor@mcmaster.ca	; Noseworthy, Michael/B-2957-2011	Doyle, Thomas/0000-0003-1059-110X; Noseworthy, Michael/0000-0003-1464-159X	Defence Research and Development Canada via the Innovation for Defence Excellence and Security program [CFPMN2-017-McMaster]	Defence Research and Development Canada via the Innovation for Defence Excellence and Security program	Supported in part by Defence Research and Development Canada (grant no. CFPMN2-017-McMaster) via the Innovation for Defence Excellence and Security program.	64McLeod C., 2020, TRUST STANFORD ENCY; Arya V, ARXIV190903012 PREPR; Bakas S, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.117; Blei DM, 2017, J AM STAT ASSOC, V112, P859, DOI 10.1080/01621459.2017.1285773; Castro DC, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17478-w; Chokshi FH, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019190021; De Fauw J, 2018, NAT MED, V24, P1342, DOI 10.1038/s41591-018-0107-6; Gaertig C, 2018, PSYCHOL SCI, V29, P504, DOI 10.1177/0956797617739369; Gal Y, 2016, THESIS CAMBRIDGE MAC; Gal Y, 2016, PR MACH LEARN RES, V48; Gaube S, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00385-9; Grote T, 2020, J MED ETHICS, V46, P205, DOI 10.1136/medethics-2019-105586; Guo CA, 2017, PR MACH LEARN RES, V70; Hoebel K, 2020, MED IMAGING 2020 IMA, P381; Jungo A, 2019, LECT NOTES COMPUT SC, V11765, P48, DOI 10.1007/978-3-030-32245-8_6; Kendall A., 2017, ADV NEURAL INFORM PR, P5575, DOI DOI 10.5555/3295222.3295309; Kim B, 2015, CSAIL TECHNICAL REP, P1; Kwon Y, 2020, COMPUT STAT DATA AN, V142, DOI 10.1016/j.csda.2019.106816; Lakkaraju Himabindu, 2020, INT C MACH LEARN, V119, P5628; Lakshminarayanan B, 2017, ADV NEUR IN, V30; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Lipton ZC, 2018, COMMUN ACM, V61, P36, DOI 10.1145/3233231; Liu XX, 2019, LANCET DIGIT HEALTH, V1, pE271, DOI 10.1016/S2589-7500(19)30123-2; Mehrtash A, ARXIV191113273; Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694; Nair T, 2018, LECT NOTES COMPUT SC, V11070, P655, DOI 10.1007/978-3-030-00928-1_74; Ovadia Y, 2019, ARXIV190602530 PREPR; Pearce T, ARXIV181005546 PREPR; Reyes M, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190043; Roy AG, 2018, LECT NOTES COMPUT SC, V11070, P664, DOI 10.1007/978-3-030-00928-1_75; Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x; Shankar Vaishaal, 2020, INT C MACH LEARN ICM; Shridhar K, ARXIV190102731 PREPR; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Wilson AG., 2020, INT C MACHINE LEARNI	38	4	4	0	2	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2021	3	6							e210031	10.1148/ryai.2021210031	http://dx.doi.org/10.1148/ryai.2021210031			7	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9UW	34870219	Green Published			2022-12-18	WOS:000826914400009
J	Sveinsson, B; Chaudhari, AS; Zhu, B; Koonjoo, N; Torriani, M; Gold, GE; Rosen, MS				Sveinsson, Bragi; Chaudhari, Akshay S.; Zhu, Bo; Koonjoo, Neha; Torriani, Martin; Gold, Garry E.; Rosen, Matthew S.			Synthesizing Quantitative T2 Maps in Right Lateral Knee Femoral Condyles from Multicontrast Anatomic Data with a Conditional Generative Adversarial Network	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Cartilage Imaging; Knee; Experimental Investigations; Quantification; Vision; Application Domain; Convolutional Neural Network (CNN); Deep Learning Algorithms; Machine Learning Algorithms	RELAXATION-TIME; ARTICULAR-CARTILAGE; PULSE SEQUENCES; MRI; DESIGN	Purpose: To develop a proof-of-concept convolutional neural network (CNN) to synthesize T2 maps in right lateral femoral condyle articular cartilage from anatomic MR images by using a conditional generative adversarial network (cGAN). Materials and Methods: In this retrospective study, anatomic images (from turbo spin-echo and double-echo in steady-state scans) of the right knee of 4621 patients included in the 2004-2006 Osteoarthritis Initiative were used as input to a cGAN-based CNN, and a predicted CNN T2 was generated as output. These patients included men and women of all ethnicities, aged 45-79 years, with or at high risk for knee osteoarthritis incidence or progression who were recruited at four separate centers in the United States. These data were split into 3703 (80%) for training, 462 (10%) for validation, and 456 (10%) for testing. Linear regression analysis was performed between the multiecho spin-echo (MESE) and CNN T2 in the test dataset. A more detailed analysis was performed in 30 randomly selected patients by means of evaluation by two musculoskeletal radiologists and quantification of cartilage subregions. Radiologist assessments were compared by using two-sided t tests. Results: The readers were moderately accurate in distinguishing CNN T2 from MESE T2, with one reader having random-chance categorization. CNN T2 values were correlated to the MESE values in the subregions of 30 patients and in the bulk analysis of all patients, with best-fit line slopes between 0.55 and 0.83. Conclusion: With use of a neural network-based cGAN approach, it is feasible to synthesize T2 maps in femoral cartilage from anatomic MRI sequences, giving good agreement with MESE scans. (C) RSNA, 2021.	[Sveinsson, Bragi; Zhu, Bo; Koonjoo, Neha; Rosen, Matthew S.] Harvard Med Sch, Arhinoula A Martins Ctr Biomed Imaging, Dept Radiol, Massachusetts Gen Hosp, 149 13th St,Suite 2301, Boston, MA 02129 USA; [Torriani, Martin] Harvard Med Sch, Massachusetts Gen Hosp, Dept Radiol, Div Musculoskeletal Imaging & Intervent, Boston, MA 02115 USA; [Chaudhari, Akshay S.; Gold, Garry E.] Stanford Univ, Dept Radiol, Stanford, CA 94305 USA; [Rosen, Matthew S.] Harvard Univ, Dept Phys, Cambridge, MA 02138 USA	Harvard University; Harvard Medical School; Massachusetts General Hospital; Harvard University; Harvard Medical School; Massachusetts General Hospital; Stanford University; Harvard University	Sveinsson, B (corresponding author), Harvard Med Sch, Arhinoula A Martins Ctr Biomed Imaging, Dept Radiol, Massachusetts Gen Hosp, 149 13th St,Suite 2301, Boston, MA 02129 USA.	bsveinsson@mgh.harvard.edu		Rosen, Matthew/0000-0002-7194-002X; Chaudhari, Akshay/0000-0002-3667-6796; Gold, Garry/0000-0002-3207-822X; Sveinsson, Bragi/0000-0001-8109-0404	DARPA [2016D006054]; National Institutes of Health [K99AG066815]	DARPA(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	Supported by DARPA (grant 2016D006054) and the National Institutes of Health (grant K99AG066815).	Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; Buckwalter JA, 1997, J BONE JOINT SURG AM, V79A, P600, DOI 10.2106/00004623-199704000-00021; Chaudhari AS, 2020, J MAGN RESON IMAGING, V51, P768, DOI [10.1002/jmri.26872, 10.1002/jmri.26991]; Chaudhari AS, 2019, J MAGN RESON IMAGING, V49, pE183, DOI 10.1002/jmri.26582; Chaudhari AS, 2018, J MAGN RESON IMAGING, V47, P1328, DOI 10.1002/jmri.25883; Chaudhari AS, 2018, MAGN RESON MED, V80, P2139, DOI 10.1002/mrm.27178; Chollet F., 2015, KERAS; Dardzinski BJ, 1997, RADIOLOGY, V205, P546, DOI 10.1148/radiology.205.2.9356643; Desai AD, ARXIV 190201977; Dunn TC, 2004, RADIOLOGY, V232, P592, DOI 10.1148/radiol.2322030976; Eckstein F, 2012, NAT REV RHEUMATOL, V8, P622, DOI 10.1038/nrrheum.2012.113; Gaj S, 2020, MAGN RESON MED, V84, P437, DOI 10.1002/mrm.28111; Galbusera Fabio, 2018, Eur Radiol Exp, V2, P29, DOI 10.1186/s41747-018-0060-7; Gold GE, 2006, OSTEOARTHR CARTILAGE, V14, pA76, DOI 10.1016/j.joca.2006.03.010; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; HENKELMAN RM, 1994, MAGNET RESON MED, V32, P592, DOI 10.1002/mrm.1910320508; Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5; Hunter DJ, 2011, OSTEOARTHR CARTILAGE, V19, P990, DOI 10.1016/j.joca.2011.05.004; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Leung K, 2020, RADIOLOGY, V296, P584, DOI 10.1148/radiol.2020192091; Link TM, 2018, OSTEOARTHR CARTILAGE, V26, P1137, DOI 10.1016/j.joca.2018.02.902; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Lusse S, 2000, MAGN RESON IMAGING, V18, P423, DOI 10.1016/S0730-725X(99)00144-7; Matzat SJ, 2015, J MAGN RESON IMAGING, V42, P105, DOI 10.1002/jmri.24757; Mirza M, ARXIV 14111784; Mosher TJ, 2004, SEMIN MUSCULOSKEL R, V8, P355, DOI 10.1055/s-2004-861764; Nevitt M., 2006, OSTEOARTHRITIS INITI; OUTERBRIDGE RE, 1961, J BONE JOINT SURG BR, V43, P752; Pedoia V, 2019, OSTEOARTHR CARTILAGE, V27, P1002, DOI 10.1016/j.joca.2019.02.800; Peterfy CG, 2008, OSTEOARTHR CARTILAGE, V16, P1433, DOI 10.1016/j.joca.2008.06.016; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; RUBENSTEIN JD, 1993, RADIOLOGY, V188, P219, DOI 10.1148/radiology.188.1.8511302; Sveinsson B, 2017, MAGN RESON IMAGING, V38, P63, DOI 10.1016/j.mri.2016.12.018; Sveinsson B, 2019, MAGN RESON MED, V81, P711, DOI 10.1002/mrm.27436; tensorflow, PIX2PIX IMAGE TO IMA; Thomas KA, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190065; Xu JF, 2011, J RADIOL CASE REP, V5, P13, DOI 10.3941/jrcr.v5i2.515; Zhu B, 2018, NATURE, V555, P487, DOI 10.1038/nature25988	38	4	4	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2021	3	5							e200122	10.1148/ryai.2021200122	http://dx.doi.org/10.1148/ryai.2021200122			13	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9TT	34617020	Green Published			2022-12-18	WOS:000826911500001
J	Zormpas-Petridis, K; Tunariu, N; Curcean, A; Messiou, C; Curcean, S; Collins, DJ; Hughes, JC; Jamin, Y; Koh, DM; Blackledge, MD				Zormpas-Petridis, Konstantinos; Tunariu, Nina; Curcean, Andra; Messiou, Christina; Curcean, Sebastian; Collins, David J.; Hughes, Julie C.; Jamin, Yann; Koh, Dow-Mu; Blackledge, Matthew D.			Accelerating Whole-Body Diffusion-weighted MRI with Deep Learning-based Denoising Image Filters	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Image Postprocessing; MR-Diffusion-weighted Imaging; Neural Networks; Oncology; Whole-Body Imaging; Supervised Learning; MR-Functional Imaging; Metastases; Prostate; Lung	PROSTATE-CANCER	Purpose: To use deep learning to improve the image quality of subsampled images (number of acquisitions = 1 [NOA 1]) to reduce whole-body diffusion-weighted MRI (WBDWI) acquisition times. Materials and Methods: Both retrospective and prospective patient groups were used to develop a deep learning-based denoising image filter (DNIF) model. For initial model training and validation, 17 patients with metastatic prostate cancer with acquired WBDWI NOA 1 and NOA 9 images (acquisition period, 2015-2017) were retrospectively included. An additional 22 prospective patients with advanced prostate cancer, myeloma, and advanced breast cancer were used for model testing (2019), and the radiologic quality of DNIF-processed NOA 1 (NOA 1-DNIF) images were compared with NOA 1 images and clinical NOA 16 images by using a three-point Likert scale (good, average, or poor; statistical significance was calculated by using a Wilcoxon signed ranked test). The model was also retrained and tested in 28 patients with malignant pleural mesothelioma (MPM) who underwent lung MRI (2015-2017) to demonstrate feasibility in other body regions. Results: The model visually improved the quality of NOA 1 images in all test patients, with the majority of NOA 1-DNIF and NOA 16 images being graded as either "average" or "good" across all image-quality criteria. From validation data, the mean apparent diffusion coefficient (ADC) values within NOA 1-DNIF images of bone disease deviated from those within NOA 9 images by an average of 1.9% (range, 1.1%-2.6%). The model was also successfully applied in the context of MPM; the mean ADCs from NOA 1-DNIF images of MPM deviated from those measured by using clinical-standard images (NOA 12) by 3.7% (range, 0.2%-10.6%). Conclusion: Clinical-standard images were generated from subsampled images by using a DNIF. Supplemental material is available for this article. Published under a CC BY 4.0 license.	[Zormpas-Petridis, Konstantinos; Tunariu, Nina; Curcean, Andra; Messiou, Christina; Curcean, Sebastian; Collins, David J.; Hughes, Julie C.; Jamin, Yann; Koh, Dow-Mu; Blackledge, Matthew D.] Inst Canc Res, Div Radiat Therapy & Imaging, 123 Old Brompton Rd, London SW7 3RP, England; [Tunariu, Nina; Curcean, Andra; Messiou, Christina; Curcean, Sebastian; Hughes, Julie C.; Koh, Dow-Mu] Royal Marsden Natl Hlth Serv Fdn Trust, Dept Radiol, Sutton, Surrey, England	Royal Marsden NHS Foundation Trust; University of London; Institute of Cancer Research - UK; Royal Marsden NHS Foundation Trust	Blackledge, MD (corresponding author), Inst Canc Res, Div Radiat Therapy & Imaging, 123 Old Brompton Rd, London SW7 3RP, England.	matthew.blackledge@icr.ac.uk	Curcean, Sebastian/AAO-9488-2021	Curcean, Sebastian/0000-0002-7256-461X; Collins, David/0000-0001-8281-1496; Jamin, yann/0000-0003-0350-3757; Koh, Dow-Mu/0000-0001-7654-8011; Messiou, Christina/0000-0002-0557-9379; Curcean, Andra/0000-0003-2385-2954; Blackledge, Matthew/0000-0001-8117-9003; Tunariu, Nina/0000-0001-6656-3699	Cancer Research UK and Engineering and Physical Sciences Research Council; Department of Health [C1060/A10334, C1060/A16464]; Rosetrees Trust [M593]; Children with Cancer UK Research Fellowship [2014/176]; Betty Lawes Foundation; Invention for Innovation Award for "Advanced Computer Diagnostics for Whole-Body MRI to Improve Treatment of Patients with Metastatic Bone Cancer" [II-LA-0216-20007]; National Health Service; National Institute for Health Research; Medical Research Council	Cancer Research UK and Engineering and Physical Sciences Research Council; Department of Health; Rosetrees Trust(Rosetrees Trust); Children with Cancer UK Research Fellowship; Betty Lawes Foundation; Invention for Innovation Award for "Advanced Computer Diagnostics for Whole-Body MRI to Improve Treatment of Patients with Metastatic Bone Cancer"; National Health Service; National Institute for Health Research(National Institute for Health Research (NIHR)); Medical Research Council(UK Research & Innovation (UKRI)Medical Research Council UK (MRC))	Supported in part by Cancer Research UK and Engineering and Physical Sciences Research Council funding to the Cancer Imaging Centre at the Institute of Cancer Research and Royal Marsden Hospital in association with the Medical Research Council and Department of Health (C1060/A10334, C1060/A16464); a Rosetrees Trust grant (M593); a Children with Cancer UK Research Fellowship (to Y.J. [2014/176]); the Betty Lawes Foundation; an Invention for Innovation Award for "Advanced Computer Diagnostics for Whole-Body MRI to Improve Treatment of Patients with Metastatic Bone Cancer" (II-LA-0216-20007); and National Health Service funding to the National Institute for Health Research Biomedical Research Centre and the National Institute for Health Research Royal Marsden Clinical Research Facility. This report is independent research funded by the National Institute for Health Research. The views expressed in this publication are those of the authors and not necessarily those of the National Health Service, the National Institute for Health Research, or the Department of Health.	[Anonymous], 2016, MYEL DIAGN MAN NICE; Blackledge MD, 2020, FRONT ONCOL, V10, DOI 10.3389/fonc.2020.00704; Blackledge MD, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0091779; Bollmann S, 2019, NEUROIMAGE, V195, P373, DOI 10.1016/j.neuroimage.2019.03.060; Buades A, 2011, IMAGE PROCESS ON LIN, V1, P208, DOI 10.5201/ipol.2011.bcm_nlm; Chantry A, 2017, BRIT J HAEMATOL, V178, P380, DOI 10.1111/bjh.14827; Cheng L, 2015, LUNG CANCER, V90, P433, DOI 10.1016/j.lungcan.2015.08.012; Eiber M, 2011, J MAGN RESON IMAGING, V33, P1160, DOI 10.1002/jmri.22542; Evans R, 2017, BMJ OPEN, V7, DOI 10.1136/bmjopen-2017-016391; Evans REC, 2018, BRIT J RADIOL, V91, DOI 10.1259/bjr.20170731; Foi A, 2011, I S BIOMED IMAGING, P1809, DOI 10.1109/ISBI.2011.5872758; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43; Kingma D.P, P 3 INT C LEARNING R; Kingsley PB, 2006, CONCEPT MAGN RESON A, V28A, P123, DOI 10.1002/cmr.a.20049; Koh DM, 2012, AM J ROENTGENOL, V199, P252, DOI 10.2214/AJR.11.7866; Lee D, 2017, I S BIOMED IMAGING, P15, DOI 10.1109/ISBI.2017.7950457; Messiou C, 2019, RADIOLOGY, V291, P4, DOI 10.1148/radiol.2019181949; Muckley MJ, 2021, MAGN RESON MED, V85, P413, DOI 10.1002/mrm.28395; Norman B, 2018, RADIOLOGY, V288, P177, DOI 10.1148/radiol.2018172322; O'Connor JPB, 2017, NAT REV CLIN ONCOL, V14, P169, DOI 10.1038/nrclinonc.2016.162; Padhani AR, 2017, EUR UROL, V71, P81, DOI 10.1016/j.eururo.2016.05.033; Padhani AR, 2011, RADIOLOGY, V261, P700, DOI 10.1148/radiol.11110474; Pieper S, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 and 2, P632; Ran MS, 2019, MED IMAGE ANAL, V55, P165, DOI 10.1016/j.media.2019.05.001; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Schelb P, 2019, RADIOLOGY, V293, P607, DOI 10.1148/radiol.2019190938; Thoeny HC, 2010, J MAGN RESON IMAGING, V32, P2, DOI 10.1002/jmri.22167; Tripathi PC, 2020, PATTERN RECOGN LETT, V135, P57, DOI 10.1016/j.patrec.2020.03.036; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Winfield JM, 2017, RADIOLOGY, V284, P88, DOI 10.1148/radiol.2017161965; Zhang L, 2012, IEEE IMAGE PROC, P1477, DOI 10.1109/ICIP.2012.6467150; Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068; Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865; Zhu B, 2018, P 26 ANN M ISMRM PAR, P572; Zhu B, 2018, NATURE, V555, P487, DOI 10.1038/nature25988	37	4	4	4	5	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2021	3	5							e200279	10.1148/ryai.2021200279	http://dx.doi.org/10.1148/ryai.2021200279			13	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9TT	34617028	Green Published			2022-12-18	WOS:000826911500009
J	Patel, R; Thong, EHE; Batta, V; Bharath, AA; Francis, D; Howard, J				Patel, Ravi; Thong, Elizabeth H. E.; Batta, Vineet; Bharath, Anil Anthony; Francis, Darrel; Howard, James			Automated Identification of Orthopedic Implants on Radiographs Using Deep Learning	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Neural Networks; Skeletal-Appendicular; Knee; Hip; Computer Applications-General (Informatics); Prostheses; Technology Assessment; Observer Performance	CLASSIFICATION; CANCER; HIP	Accurate identification of metallic orthopedic implant design is important for preoperative planning of revision arthroplasty. Surgical records of implant models are frequently unavailable. The aim of this study was to develop and evaluate a convolutional neural network for identifying orthopedic implant models using radiographs. In this retrospective study, 427 knee and 922 hip unilateral anteroposterior radiographs, including 12 implant models from 650 patients, were collated from an orthopedic center between March 2015 and November 2019 to develop classification networks. A total of 198 images paired with autogenerated image masks were used to develop a U-Net segmentation network to automatically zero-mask around the implants on the radiographs. Classification networks processing original radiographs, and two-channel conjoined original and zero-masked radiographs, were ensembled to provide a consensus prediction. Accuracies of five senior orthopedic specialists assisted by a reference radiographic gallery were compared with network accuracy using McNemar exact test. When evaluated on a balanced unseen dataset of 180 radiographs, the final network achieved a 98.9% accuracy (178 of 180) and 100% top-three accuracy (180 of 180). The network performed superiorly to all five specialists (76.1% [137 of 180] median accuracy and 85.6% [154 of 180] best accuracy; both P < .001), with robustness to scan quality variation and difficult to distinguish implants. A neural network model was developed that outperformed senior orthopedic specialists at identifying implant models on radiographs; real-world application can now be readily realized through training on a broader range of implants and joints, supported by all code and radiographs being made freely available.	[Patel, Ravi; Thong, Elizabeth H. E.; Francis, Darrel; Howard, James] Imperial Coll Healthcare NHS Trust, Fac Med, London, England; [Patel, Ravi; Bharath, Anil Anthony] Imperial Coll London, Dept Bioengn, Level 2,Fac Bldg,South Kensington Campus, London SW7 2AZ, England; [Batta, Vineet] Luton & Dunstable Univ Hosp, Dept Orthopaed Surg, Luton, Beds, England	Imperial College London; Imperial College London	Patel, R (corresponding author), Imperial Coll Healthcare NHS Trust, Fac Med, London, England.	ravi.patel@doctors.org.uk		Howard, James/0000-0002-9989-6331; Thong, Elizabeth/0000-0001-5204-1072	Wellcome Trust [212183/Z/18/Z]	Wellcome Trust(Wellcome Trust)	J.H. supported by the Wellcome Trust (grant 212183/Z/18/Z).	[Anonymous], WHICH ORTHOPAEDIC IM; [Anonymous], MEDICAL APPARATUS IM; Borjali A, 2020, J ORTHOP RES, V38, P1465, DOI 10.1002/jor.24617; Cunningham P, 2000, ARTIF INTELL MED, V20, P217, DOI 10.1016/S0933-3657(00)00065-8; De Fauw J, 2018, NAT MED, V24, P1342, DOI 10.1038/s41591-018-0107-6; Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z; Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056; HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871; Howard J, ORTHONET TESTING; Howard James P, 2020, J Med Artif Intell, V3, DOI 10.21037/jmai.2019.10.03; Howard JP, 2019, JACC-CLIN ELECTROPHY, V5, P579, DOI 10.1016/j.jacep.2019.02.003; Huang G., DENSELY CONNECTED CO; Johnson JM, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0192-5; Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90; Kang YJ, 2020, J ORTHOP TRANSL, V21, P13, DOI 10.1016/j.jot.2019.11.004; Lambert EW, 2006, J ARTHROPLASTY, V21, P1203, DOI 10.1016/j.arth.2006.06.016; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Loshchilov I, DECOUPLED WEIGHT DEC; Mazurowski MA, 2008, NEURAL NETWORKS, V21, P427, DOI 10.1016/j.neunet.2007.12.031; OrthopaedicLIST.com, US; Paszke A, PYTORCH ANIMPERATIVE; R Core Team, R LANG ENV STAT COMP; Ronneberger O, LECT NOTES COMPUTER; Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474; Shen L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48995-4; Szegedy C., 2015, P IEEE C COMP VIS PA, P2818; Tan M, EFFICIENTNET RETHINK; Wilson N, 2015, HEALTHCARE-J DEL SCI, V3, P196, DOI 10.1016/j.hjdsi.2015.04.003; Wilson NA, 2014, J ARTHROPLASTY, V29, P251, DOI 10.1016/j.arth.2013.06.027; Xie S, AGGREGATED RESIDUAL; Yi PH, 2020, KNEE, V27, P535, DOI 10.1016/j.knee.2019.11.020; Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064	32	4	4	1	2	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2021	3	4							e200183	10.1148/ryai.2021200183	http://dx.doi.org/10.1148/ryai.2021200183			8	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SU	34350407	Green Published			2022-12-18	WOS:000826909000005
J	Zhou, LL; Yin, XD; Zhang, T; Feng, Y; Zhao, Y; Jin, MX; Peng, MY; Xing, CH; Li, FF; Wang, ZT; Wei, GL; Jia, X; Liu, YJ; Wu, XY; Lu, LQ				Zhou, Leilei; Yin, Xindao; Zhang, Tao; Feng, Yuan; Zhao, Ying; Jin, Mingxu; Peng, Mingyang; Xing, Chunhua; Li, Fengfang; Wang, Ziteng; Wei, Guoliang; Jia, Xiao; Liu, Yujun; Wu, Xinying; Lu, Lingquan			Detection and Semiquantitative Analysis of Cardiomegaly, Pneumothorax, and Pleural Effusion on Chest Radiographs	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Computer-Aided Diagnosis (CAD); Thorax; Cardiac	LEARNING-MODELS	Purpose: To develop and evaluate deep learning models for the detection and semiquantitative analysis of cardiomegaly, pneumothorax, and pleural effusion on chest radiographs. Materials and Methods: In this retrospective study, models were trained for lesion detection or for lung segmentation. The first dataset for lesion detection consisted of 2838 chest radiographs from 2638 patients (obtained between November 2018 and January 2020) containing findings positive for cardiomegaly, pneumothorax, and pleural effusion that were used in developing Mask region-based convolutional neural networks plus Point-based Rendering models. Separate detection models were trained for each disease. The second dataset was from two public datasets, which included 704 chest radiographs for training and testing a U-Net for lung segmentation. Based on accurate detection and segmentation, semiquantitative indexes were calculated for cardiomegaly (cardiothoracic ratio), pneumothorax (lung compression degree), and pleural effusion (grade of pleural effusion). Detection performance was evaluated by average precision (AP) and free-response receiver operating characteristic (FROC) curve score with the intersection over union greater than 75% (AP75; FROC score75). Segmentation performance was evaluated by Dice similarity coefficient. Results: The detection models achieved high accuracy for detecting cardiomegaly (AP75, 98.0%; FROC score75, 0.985), pneumothorax (AP75, 71.2%; FROC score75, 0.728), and pleural effusion (AP75, 78.2%; FROC score75, 0.802), and they also weakened boundary aliasing. The segmentation effect of the lung field (Dice, 0.960), cardiomegaly (Dice, 0.935), pneumothorax (Dice, 0.827), and pleural effusion (Dice, 0.826) was good, which provided important support for semiquantitative analysis. Conclusion: The developed models could detect cardiomegaly, pneumothorax, and pleural effusion, and semiquantitative indexes could be calculated from segmentations.	[Zhou, Leilei; Yin, Xindao; Zhang, Tao; Feng, Yuan; Zhao, Ying; Jin, Mingxu; Peng, Mingyang; Xing, Chunhua; Li, Fengfang; Wu, Xinying; Lu, Lingquan] Nanjing Med Univ, Dept Radiol, Nanjing Hosp 1, Nanjing 210006, Peoples R China; [Wang, Ziteng; Wei, Guoliang; Jia, Xiao; Liu, Yujun] Yizhun Med AI Co Ltd, Beijing, Peoples R China	Nanjing Medical University	Wu, XY (corresponding author), Nanjing Med Univ, Dept Radiol, Nanjing Hosp 1, Nanjing 210006, Peoples R China.	rebeccahxt@163.com		Zhao, Ying/0000-0002-6436-671X	National Natural Science Foundation of China [81901806]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	Supported by the National Natural Science Foundation of China (grant 81901806).	Abdelhafiz D, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2823-4; [Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.322; [Anonymous], 2019, NIH CHEST XRAY DATAS; Armato SG, 1998, ACAD RADIOL, V5, P329, DOI 10.1016/S1076-6332(98)80151-7; Behzadi-khormouji H, 2020, COMPUT METH PROG BIO, V185, DOI 10.1016/j.cmpb.2019.105162; Brady Adrian, 2012, Ulster Med J, V81, P3; Chen BZ, 2019, BIOMED SIGNAL PROCES, V53, DOI 10.1016/j.bspc.2019.04.031; Chen C, ARXIV 180600600; Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195; Chondro P, 2018, NEUROCOMPUTING, V275, P1002, DOI 10.1016/j.neucom.2017.09.053; Guan QJ, 2020, PATTERN RECOGN LETT, V131, P38, DOI 10.1016/j.patrec.2019.11.040; Guan QJ, 2020, PATTERN RECOGN LETT, V130, P259, DOI 10.1016/j.patrec.2018.10.027; Hansell DM, 2008, RADIOLOGY, V246, P697, DOI 10.1148/radiol.2462070712; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Irvin J, 2019, AAAI CONF ARTIF INTE, P590; Jaeger S, 2014, QUANT IMAGING MED SU, V4, P475, DOI 10.3978/j.issn.2223-4292.2014.11.20; Johnson AE, ARXIV 190107042 PREP; KIRCHER LT, 1954, JAMA-J AM MED ASSOC, V155, P24, DOI 10.1001/jama.1954.03690190030009; Kirillov A, ARXIV 191208193; Li XC, 2020, ARTIF INTELL MED, V103, DOI 10.1016/j.artmed.2019.101744; Maduskar P, 2016, MED IMAGE ANAL, V28, P22, DOI 10.1016/j.media.2015.09.004; Majkowska A, 2020, RADIOLOGY, V294, P421, DOI 10.1148/radiol.2019191293; Rajpurkar P, ARXIV 171105225; Rajpurkar P, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002686; RAZAVI MK, 1995, RADIOLOGY, V197, P801, DOI 10.1148/radiology.197.3.7480759; Rodriguez-Ruiz A, 2019, RADIOLOGY, V290, P305, DOI 10.1148/radiol.2018181371; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sirazitdinov I, 2019, COMPUT ELECTR ENG, V78, P388, DOI 10.1016/j.compeleceng.2019.08.004; Souza JC, 2019, COMPUT METH PROG BIO, V177, P285, DOI 10.1016/j.cmpb.2019.06.005; Stirenko S, ARXIV 180301199; Tajbakhsh N, 2017, PATTERN RECOGN, V63, P476, DOI 10.1016/j.patcog.2016.09.029; Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369; Zotin A, 2019, PROCEDIA COMPUT SCI, V159, P1439, DOI 10.1016/j.procs.2019.09.314	34	4	4	2	6	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2021	3	4							e200172	10.1148/ryai.2021200172	http://dx.doi.org/10.1148/ryai.2021200172			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SU	34350406	Green Published			2022-12-18	WOS:000826909000004
J	Korkinof, D; Harvey, H; Heindl, A; Karpati, E; Williams, G; Rijken, T; Kecskemethy, P; Glocker, B				Korkinof, Dimitrios; Harvey, Hugh; Heindl, Andreas; Karpati, Edith; Williams, Gareth; Rijken, Tobias; Kecskemethy, Peter; Glocker, Ben			Perceived Realism of High-Resolution Generative Adversarial Network-derived Synthetic Mammograms	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To explore whether generative adversarial networks (GANs) can enable synthesis of realistic medical images that are indiscernible from real images, even by domain experts. Materials and Methods: In this retrospective study, progressive growing GANs were used to synthesize mammograms at a resolution of 1280 3 1024 pixels by using images from 90 000 patients (average age, 56 years 6 9) collected between 2009 and 2019. To evaluate the results, a method to assess distributional alignment for ultra-high-dimensional pixel distributions was used, which was based on moment plots. This method was able to reveal potential sources of misalignment. A total of 117 volunteer participants (55 radiologists and 62 nonradiologists) took part in a study to assess the realism of synthetic images from GANs. Results: A quantitative evaluation of distributional alignment shows 60%-78% mutual-information score between the real and synthetic image distributions, and 80%-91% overlap in their support, which are strong indications against mode collapse. It also reveals shape misalignment as the main difference between the two distributions. Obvious artifacts were found by an untrained observer in 13.6% and 6.4% of the synthetic mediolateral oblique and craniocaudal images, respectively. A reader study demonstrated that real and synthetic images are perceptually inseparable by the majority of participants, even by trained breast radiologists. Only one out of the 117 participants was able to reliably distinguish real from synthetic images, and this study discusses the cues they used to do so. Conclusion: On the basis of these findings, it appears possible to generate realistic synthetic full-field digital mammograms by using a progressive GAN architecture up to a resolution of 1280 3 1024 pixels. Supplemental material is available for this article. (C) RSNA, 2020.	[Korkinof, Dimitrios; Harvey, Hugh; Heindl, Andreas; Karpati, Edith; Williams, Gareth; Rijken, Tobias; Kecskemethy, Peter] Kheiron Med Technol Ltd, 116 Old St, London EC1V 9BG, England; [Glocker, Ben] Imperial Coll London, Dept Comp, London, England	Imperial College London	Heindl, A (corresponding author), Kheiron Med Technol Ltd, 116 Old St, London EC1V 9BG, England.	andreas@kheironmed.com		Glocker, Ben/0000-0002-4897-9356				Brock A, 2018, ARXIV 180911096 PREP; Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916; Frid-Adar M, 2018, I S BIOMED IMAGING, P289; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Kamnitsas K, 2017, LECT NOTES COMPUT SC, V10265, P597, DOI 10.1007/978-3-319-59050-9_47; Karras T, 2017, ARXIV171010196; Kingma DP, 2018, ADV NEUR IN, V31; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Ross BC, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0087357; Salehinejad H, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P990; Ulyanov D, 2018, PROC CVPR IEEE, P9446, DOI 10.1109/CVPR.2018.00984; Yi X, 2018, J DIGIT IMAGING, V31, P655, DOI 10.1007/s10278-018-0056-0; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244	13	4	4	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2021	3	2							e190181	10.1148/ryai.2020190181	http://dx.doi.org/10.1148/ryai.2020190181			8	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z3LD	33937856	Green Published			2022-12-18	WOS:000826483100001
J	Banja, J				Banja, John			AI Hype and Radiology: A Plea for Realism and Accuracy	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article									[Banja, John] Emory Univ, Ctr Eth, 1531 Dickey Dr, Atlanta, GA 30322 USA	Emory University	Banja, J (corresponding author), Emory Univ, Ctr Eth, 1531 Dickey Dr, Atlanta, GA 30322 USA.	jbanja@emory.edu		Banja, John/0000-0002-9464-3298				[Anonymous], 2019, IDC EXP AS PAC ART I; ASTM International, 2018, STANDARD SPECIFICATI; Bonetti M., 2017, WILL SPINTRONICS SOO; Chockley K, 2016, J AM COLL RADIOL, V13, P1415, DOI 10.1016/j.jacr.2016.07.010; Dastin J, 2019, REUTERS; Epstein D., ATLANTIC; Gardiner B., 2007, WIRED; Goasduff L., 2019, TOP TRENDS GARTNER H; Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216; HandS, 2018, IDX DRBECOMES 1 FDA; Harvey H, WHY AI WILL NOT REPL; Healy T., 2005, UNANTICIPATED CONSEQ; Horgan J., 2017, SCI AM; Kim W, 2019, RADIOLOGY TODAY, V20, P6; Langlotz CP, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019190058; Lashinsky A., 2019, FORTUNE; Manyika J., 2018, PROMISE CHALLENGE AG; Mazzucato M., 2018, WASHINGTON POST; McCain J., 2005, FUTURE GENE THERAPY; Mullin E., 2016, MIT TECHNOL REV; Naude WA, 2019, CONVERSATION; Neri E, 2019, INSIGHTS IMAGING, V10, DOI 10.1186/s13244-019-0738-2; Shuman LS, 2018, J LANCASTER GEN HOSP, V13, P102; Spencer M., 2019, FORBES; van Hoek J, 2019, EUR J RADIOL, V121, DOI 10.1016/j.ejrad.2019.108742	25	4	4	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2020	2	4							e190223	10.1148/ryai.2020190223	http://dx.doi.org/10.1148/ryai.2020190223			3	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CX	33937835	Green Published, Bronze			2022-12-18	WOS:000826472900009
J	Filice, RW; Ratwani, RM				Filice, Ross W.; Ratwani, Raj M.			The Case for User-Centered Artificial Intelligence in Radiology	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Filice, Ross W.] MedStar Georgetown Univ Hosp, MedStar Hlth, 3800 Reservoir Rd,NW CG201, Washington, DC 20007 USA; [Ratwani, Raj M.] Natl Ctr Human Factors Healthcare, MedStar Hlth, Washington, DC USA		Filice, RW (corresponding author), MedStar Georgetown Univ Hosp, MedStar Hlth, 3800 Reservoir Rd,NW CG201, Washington, DC 20007 USA.	ross.w.filice@gunet.georgetown.edu						[Anonymous], USER CENTERED DESIGN; Berkowitz SJ, 2018, RADIOGRAPHICS, V38, P1761, DOI 10.1148/rg.2018180161; Choy G, 2018, RADIOLOGY, V288, P318, DOI 10.1148/radiol.2018171820; Health Information Technology for Economic and Clinical Health Act (HITECH Act), US; Howe JL, 2018, JAMA-J AM MED ASSOC, V319, P1276, DOI 10.1001/jama.2018.1171; International Organization for Standardization (ISO), 2010, 9241210 ISO; Jorritsma W, 2015, CLIN RADIOL, V70, P115, DOI 10.1016/j.crad.2014.09.017; Lakhani P, 2018, J AM COLL RADIOL, V15, P350, DOI 10.1016/j.jacr.2017.09.044; Ratwani RM, 2018, HEALTH AFFAIR, V37, P1752, DOI 10.1377/hlthaff.2018.0699; Ratwani RM, 2015, J AM MED INFORM ASSN, V22, P1179, DOI 10.1093/jamia/ocv050; Wickens CD, 2013, ENGINEERINGPSYCHOLOG, V4; Wynn RM, 2018, ACAD RADIOL, V25, P1515, DOI 10.1016/j.acra.2018.03.016	12	4	4	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2020	2	3							e190095	10.1148/ryai.2020190095	http://dx.doi.org/10.1148/ryai.2020190095			4	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CW		Green Published			2022-12-18	WOS:000826470300004
J	Kaddioui, H; Duong, L; Joncas, J; Bellefleur, C; Nahle, I; Chemaly, O; Nault, ML; Parent, S; Grimard, G; Labelle, H				Kaddioui, Houda; Luc Duong; Joncas, Julie; Bellefleur, Christian; Nahle, Imad; Chemaly, Olivier; Nault, Marie-Lyne; Parent, Stefan; Grimard, Guy; Labelle, Hubert			Convolutional Neural Networks for Automatic Risser Stage Assessment	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							BONE-AGE; CLASSIFICATION; SIGN; AGREEMENT; SYSTEM; IMAGE	Purpose: To develop an automatic method for the assessment of the Risser stage using deep learning that could be used in the management panel of adolescent idiopathic scoliosis (AIS). Materials and Methods: In this institutional review board approved-study, a total of 1830 posteroanterior radiographs of patients with AIS (age range, 10-18 years, 70% female) were collected retrospectively and graded manually by six trained readers using the United States Risser staging system. Each radiograph was preprocessed and cropped to include the entire pelvic region. A convolutional neural network was trained to automatically grade conventional radiographs according to the Risser classification. The network was then validated by comparing its accuracy against the interobserver variability of six trained graders from the authors' institution using the Fleiss k statistical measure. Results: Overall agreement between the six observers was fair, with a k coefficient of 0.65 for the experienced graders and agreement of 74.5%. The automatic grading method obtained a k coefficient of 0.72, which is a substantial agreement with the ground truth, and an overall accuracy of 78.0%. Conclusion: The high accuracy of the model presented here compared with human readers suggests that this work may provide a new method for standardization of Risser grading. The model could assist physicians with the task, as well as provide additional insights in the assessment of bone maturity based on radiographs. (C) RSNA, 2020.	[Kaddioui, Houda; Luc Duong] Ecole Technol Super, Dept Software & IT Engn, 1100 Rue Notre Dame Ouest, Montreal, PQ H3C 1K3, Canada; [Joncas, Julie; Bellefleur, Christian; Nahle, Imad; Chemaly, Olivier; Parent, Stefan; Grimard, Guy; Labelle, Hubert] St Justine Hosp, Div Orthoped, Montreal, PQ, Canada; [Nault, Marie-Lyne; Parent, Stefan; Grimard, Guy; Labelle, Hubert] Univ Montreal, Dept Surg, Montreal, PQ, Canada	University of Quebec; Ecole de Technologie Superieure - Canada; Universite de Montreal; Centre Hospitalier Universitaire Sainte-Justine; Universite de Montreal	Kaddioui, H (corresponding author), Ecole Technol Super, Dept Software & IT Engn, 1100 Rue Notre Dame Ouest, Montreal, PQ H3C 1K3, Canada.	houda.kaddioui@gmail.com		Duong, Luc/0000-0003-3118-5389				Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; Abdolmanafi A, 2017, BIOMED OPT EXPRESS, V8, P1203, DOI 10.1364/BOE.8.001203; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; DHAR S, 1993, SPINE, V18, P14, DOI 10.1097/00007632-199301000-00003; FLEISS JL, 1973, EDUC PSYCHOL MEAS, V33, P613, DOI 10.1177/001316447303300309; GOLDBERG MS, 1994, SPINE, V19, P1562, DOI 10.1097/00007632-199407001-00004; GOLDBERG MS, 1988, SPINE, V13, P1371, DOI 10.1097/00007632-198812000-00008; Hacquebord JH, 2012, CLIN ORTHOP RELAT R, V470, P2335, DOI 10.1007/s11999-012-2371-y; Hammond KE, 2011, J PEDIATR ORTHOPED, V31, pE80, DOI 10.1097/BPO.0b013e318236b1c9; IZUMI Y, 1995, SPINE, V20, P1868, DOI 10.1097/00007632-199509000-00004; Kotikalapudi R, GITHUB; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Lee H, 2017, J DIGIT IMAGING, V30, P427, DOI 10.1007/s10278-017-9955-8; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Minkara A, 2020, J PEDIATR ORTHOPED, V40, P60, DOI 10.1097/BPO.0000000000001135; Nault ML, 2010, J BONE JOINT SURG AM, V92A, P1073, DOI 10.2106/JBJS.H.01759; Novak R, ARXIV180208760 PREPR; Reem J, 2009, SKELETAL RADIOL, V38, P371, DOI 10.1007/s00256-008-0603-8; Sanders JO, 2008, J BONE JOINT SURG AM, V90A, P540, DOI 10.2106/JBJS.G.00004; SHUREN N, 1992, SPINE, V17, P359, DOI 10.1097/00007632-199203000-00020; Soffer S, 2019, RADIOLOGY, V290, P590, DOI 10.1148/radiol.2018180547; Spampinato C, 2017, MED IMAGE ANAL, V36, P41, DOI 10.1016/j.media.2016.10.010; Thian YL, 2019, RADIOL ARTIF INTELL, V1; Torres F, 2017, P SPIE 13 INT C MEDI, V0572; Troy MJ, 2019, EUR SPINE J, V28, P559, DOI 10.1007/s00586-018-5821-8; Weinstein SL, 2008, LANCET, V371, P1527, DOI 10.1016/S0140-6736(08)60658-3	28	4	4	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2020	2	3							e180063	10.1148/ryai.2020180063	http://dx.doi.org/10.1148/ryai.2020180063			7	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CW	33937822	Green Published			2022-12-18	WOS:000826470300001
J	Buda, M; AlBadawy, EA; Saha, A; Mazurowski, MA				Buda, Mateusz; AlBadawy, Ehab A.; Saha, Ashirbani; Mazurowski, Maciej A.			Deep Radiogenomics of Lower-Grade Gliomas: Convolutional Neural Networks Predict Tumor Genomic Subtypes Using MR Images	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							IDH	Purpose: To employ deep learning to predict genomic subtypes of lower-grade glioma (LLG) tumors based on their appearance at MRI. Materials and Methods: Imaging data from The Cancer Imaging Archive and genomic data from The Cancer Genome Atlas from 110 patients from five institutions with lower-grade gliomas (World Health Organization grade II and III) were used in this study. A convolutional neural network was trained to predict tumor genomic subtype based on the MRI of the tumor. Two different deep learning approaches were tested: training from random initialization and transfer learning. Deep learning models were pretrained on glioblastoma MRI, instead of natural images, to determine if performance was improved for the detection of LGGs. The models were evaluated using area under the receiver operating characteristic curve (AUC) with cross-validation. Imaging data and annotations used in this study are publicly available. Results: The best performing model was based on transfer learning from glioblastoma MRI. It achieved AUC of 0.730 (95% confidence interval [CI]: 0.605, 0.844) for discriminating cluster-of-clusters 2 from others. For the same task, a network trained from scratch achieved an AUC of 0.680 (95% CI: 0.538, 0.811), whereas a model pretrained on natural images achieved an AUC of 0.640 (95% CI: 0.521, 0.763). Conclusion: These findings show the potential of utilizing deep learning to identify relationships between cancer imaging and cancer genomics in LGGs. However, more accurate models are needed to justify clinical use of such tools, which might be obtained using substantially larger training datasets. (c) RSNA, 2020	[Buda, Mateusz; AlBadawy, Ehab A.; Saha, Ashirbani; Mazurowski, Maciej A.] Duke Univ, Sch Med, Dept Radiol, 2424 Erwin Rd,Suite 302, Durham, NC 27705 USA; [Mazurowski, Maciej A.] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27705 USA; [Mazurowski, Maciej A.] Duke Univ, Dept Biostat & Bioinformat, Durham, NC 27705 USA	Duke University; Duke University; Duke University	Buda, M (corresponding author), Duke Univ, Sch Med, Dept Radiol, 2424 Erwin Rd,Suite 302, Durham, NC 27705 USA.	mateuzc.buda@duke.edu						AlBadawy EA, 2018, MED PHYS, V45, P1150, DOI 10.1002/mp.12752; Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Azizpour Hossein, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P36, DOI 10.1109/CVPRW.2015.7301270; Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2; Brat DJ, 2015, NEW ENGL J MED, V372, P2481, DOI 10.1056/NEJMoa1402121; Buda M, 2019, COMPUT BIOL MED, V109, P218, DOI 10.1016/j.compbiomed.2019.05.002; Buda M, 2018, NEURAL NETWORKS, V106, P249, DOI 10.1016/j.neunet.2018.07.011; Eckel-Passow JE, 2015, NEW ENGL J MED, V372, P2499, DOI 10.1056/NEJMoa1407279; Glorot X., 2011, P 14 INT C ART INT S, P315; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Jakola AS, 2018, CLIN NEUROL NEUROSUR, V164, P114, DOI 10.1016/j.clineuro.2017.12.007; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Mazurowski MA, 2019, J MAGN RESON IMAGING, V49, P939, DOI 10.1002/jmri.26534; Mazurowski MA, 2017, J NEURO-ONCOL, V133, P27, DOI 10.1007/s11060-017-2420-1; Mazurowski MA, 2017, PROC SPIE, V10134, DOI 10.1117/12.2255579; Mazurowski MA, 2015, J AM COLL RADIOL, V12, P862, DOI 10.1016/j.jacr.2015.04.019; Park YW, 2018, AM J NEURORADIOL, V39, P37, DOI 10.3174/ajnr.A5421; Pedano N., 2016, CANC IMAGING ARCH, DOI [10.7937/K9/TCIA.2016.L4LTD3TK, DOI 10.7937/K9/TCIA.2016.L4LTD3TK]; Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Szegedy C, 2015, P IEEE C COMP VIS PA, P1, DOI [10.1109/cvpr.2015.7298594, 10.1109/CVPR.2015.7298594]; Yu JH, 2017, EUR RADIOL, V27, P3509, DOI 10.1007/s00330-016-4653-3; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang CM, 2016, CHIN J CANCER, V35, DOI 10.1186/s40880-015-0071-1; Zhang Chiyuan, 2016, ARXIV161103530	27	4	5	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2020	2	1							e180050	10.1148/ryai.2019180050	http://dx.doi.org/10.1148/ryai.2019180050			7	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CR	33937809	Green Published			2022-12-18	WOS:000826298000001
J	Hsu, W; Hoyt, AC				Hsu, William; Hoyt, Anne C.			Using Time as a Measure of Impact for AI Systems: Implications in Breast Screening COMMENT	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Hsu, William; Hoyt, Anne C.] Univ Calif Los Angeles, David Geffen Sch Med, Dept Radiol Sci, 924 Westwood Blvd,Suite 420, Los Angeles, CA 90024 USA		Hsu, W (corresponding author), Univ Calif Los Angeles, David Geffen Sch Med, Dept Radiol Sci, 924 Westwood Blvd,Suite 420, Los Angeles, CA 90024 USA.	whsu@mednet.ucla.edu	Hsu, William/AAA-1935-2021	Hsu, William/0000-0002-5168-070X				Balleyguier C, 2005, EUR J RADIOL, V54, P90, DOI 10.1016/j.ejrad.2004.11.021; Conant EF, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180096; Enzmann DR, 2012, RADIOLOGY, V263, P243, DOI 10.1148/radiol.12110227; Gao YM, 2019, AM J ROENTGENOL, V212, P300, DOI 10.2214/AJR.18.20392; HANLEY JA, 1983, RADIOLOGY, V148, P839, DOI 10.1148/radiology.148.3.6878708; Hsu W, 2019, JNCI-J NATL CANCER I, V111, P877, DOI 10.1093/jnci/djy226; Marinovich ML, 2018, JNCI-J NATL CANCER I, V110, P942, DOI 10.1093/jnci/djy121; Stec N, 2018, AM J ROENTGENOL, V210, P799, DOI 10.2214/AJR.17.18613	8	4	4	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2019	1	4							e190107	10.1148/ryai.2019190107	http://dx.doi.org/10.1148/ryai.2019190107			2	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CO	33937798	Green Published			2022-12-18	WOS:000826292900006
J	Wang, K; Mamidipalli, A; Retson, T; Bahrami, N; Hasenstab, K; Blansit, K; Bass, E; Delgado, T; Cunha, G; Middleton, MS; Loomba, R; Neuschwander-Tetri, BA; Sirlin, CB; Hsiao, A				Wang, Kang; Mamidipalli, Adrija; Retson, Tara; Bahrami, Naeim; Hasenstab, Kyle; Blansit, Kevin; Bass, Emily; Delgado, Timoteo; Cunha, Guilherme; Middleton, Michael S.; Loomba, Rohit; Neuschwander-Tetri, Brent A.; Sirlin, Claude B.; Hsiao, Albert		NASH Clinical Res Network	Automated CT and MRI Liver Segmentation and Biometry Using a Generalized Convolutions Neural Network	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							COMPUTER-AIDED DIAGNOSIS; VOLUMETRY; QUANTIFICATION; REGISTRATION; SURFACE; ADULTS	Purpose: To assess feasibility of training a convolutional neural network (CNN) to automate liver segmentation across different imaging modalities and techniques used in clinical practice and to apply this technique to enable automation of liver biometry. Materials and Methods: A two-dimensional U-Net CNN was trained for liver segmentation in two stages by using 330 abdominal MRI and CT examinations. First, the neural network was trained with unenhanced multiecho spoiled gradient-echo images from 300 MRI examinations to yield multiple signal weightings. Then, transfer learning was used to generalize the CNN with additional images from 30 contrast material-enhanced MRI and CT examinations. Performance of the CNN was assessed by using a distinct multi-institutional dataset curated from multiple sources (498 subjects). Segmentation accuracy was evaluated by computing Dice scores. These segmentations were used to compute liver volume from CT and T1-weighted MRI examinations and to estimate hepatic proton density fat fraction (PDFF) from multiecho T2*-weighted MRI examinations. Quantitative volumetry and PDFF estimates were compared between automated and manual segmentation by using Pearson correlation and Bland-Altman statistics. Results: Dice scores were 0.94 +/- 0.06 for CT (n = 230), 0.95 +/- 0.03 (n = 100) for T1-weighted MRI, and 0.92 +/- 0.05 for T2*-weighted MRI (n = 168). Liver volume measured with manual and automated segmentation agreed closely for CT (95% limits of agreement: -298 mL, 180 mL) and T1-weighted MRI (95% limits of agreement: -358 mL, 180 mL). Hepatic PDFF measured by the two segmentations also agreed closely (95% limits of agreement: -0.62%, 0.80%). Conclusion: By using a transfer-learning strategy, this study has demonstrated the feasibility of a CNN to be generalized to perform liver segmentation across different imaging techniques and modalities. With further refinement and validation, CNNs may have broad applicability for multimodal liver volumetry and hepatic tissue characterization. (C) RSNA, 2019	[Wang, Kang; Retson, Tara; Bahrami, Naeim; Blansit, Kevin; Hsiao, Albert] Univ Calif San Diego, Dept Radiol, Artificial Intelligence & Data Analyt Lab AIDA La, 9452 Med Ctr Dr, La Jolla, CA 92037 USA; [Wang, Kang; Mamidipalli, Adrija; Retson, Tara; Hasenstab, Kyle; Bass, Emily; Delgado, Timoteo; Cunha, Guilherme; Middleton, Michael S.; Sirlin, Claude B.] Univ Calif San Diego, Dept Radiol, Liver Imaging Grp, 9452 Med Ctr Dr, La Jolla, CA 92037 USA; [Loomba, Rohit] Univ Calif San Diego, Dept Hepatol, 9452 Med Ctr Dr, La Jolla, CA 92037 USA; [Neuschwander-Tetri, Brent A.] St Louis Univ, Sch Med, Dept Internal Med, St Louis, MO USA	University of California System; University of California San Diego; University of California System; University of California San Diego; University of California System; University of California San Diego; Saint Louis University	Wang, K (corresponding author), Univ Calif San Diego, Dept Radiol, Artificial Intelligence & Data Analyt Lab AIDA La, 9452 Med Ctr Dr, La Jolla, CA 92037 USA.; Wang, K (corresponding author), Univ Calif San Diego, Dept Radiol, Liver Imaging Grp, 9452 Med Ctr Dr, La Jolla, CA 92037 USA.	kaw016@ucsd.edu			National Institute of Diabetes and Digestive and Kidney Diseases [1R01DK088925-01]; National Institute of Biomedical Imaging and Bioengineering [5T32EB005970-09]; National Institute of Diabetes and Digestive and Kidney Diseases; Intercept Pharmaceuticals	National Institute of Diabetes and Digestive and Kidney Diseases(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Diabetes & Digestive & Kidney Diseases (NIDDK)); National Institute of Biomedical Imaging and Bioengineering(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB)); National Institute of Diabetes and Digestive and Kidney Diseases(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Diabetes & Digestive & Kidney Diseases (NIDDK)); Intercept Pharmaceuticals	Supported by the National Institute of Diabetes and Digestive and Kidney Diseases (1R01DK088925-01), the National Institute of Biomedical Imaging and Bioengineering (5T32EB005970-09), and a collaborative research and development agreement between the National Institute of Diabetes and Digestive and Kidney Diseases and Intercept Pharmaceuticals.	Bereciartua A, 2016, COMPUT METH PROG BIO, V132, P149, DOI 10.1016/j.cmpb.2016.04.028; Berzigotti A, 2010, J HEPATOL, V52, P846, DOI 10.1016/j.jhep.2009.12.031; Bydder M, 2008, MAGN RESON IMAGING, V26, P347, DOI 10.1016/j.mri.2007.08.012; Campo CA, 2017, AM J ROENTGENOL, V209, P592, DOI 10.2214/AJR.17.17812; Chen XJ, 2012, IEEE T IMAGE PROCESS, V21, P2035, DOI 10.1109/TIP.2012.2186306; Christ P, 2017, LIVER TUMOR SEGMENTA; D'Onofrio M, 2014, WORLD J RADIOL, V6, P62, DOI 10.4329/wjr.v6.i4.62; Doi K, 2007, COMPUT MED IMAG GRAP, V31, P198, DOI 10.1016/j.compmedimag.2007.02.002; Elhawary H, 2010, ACAD RADIOL, V17, P1334, DOI 10.1016/j.acra.2010.06.004; Farraher SW, 2005, RADIOLOGY, V237, P322, DOI 10.1148/radiol.2371041416; Gloger O, 2011, LECT NOTES COMPUT SC, V6688, P512, DOI 10.1007/978-3-642-21227-7_48; Goceri E, 2016, INT J NUMER METH BIO, V32, DOI 10.1002/cnm.2765; Gotra A, 2017, INSIGHTS IMAGING, V8, P377, DOI 10.1007/s13244-017-0558-1; Heimann T, 2009, IEEE T MED IMAGING, V28, P1251, DOI 10.1109/TMI.2009.2013851; Joo S, 2004, IEEE T MED IMAGING, V23, P1292, DOI 10.1109/TMI.2004.834617; Kallini JR, 2016, ADV THER, V33, P699, DOI 10.1007/s12325-016-0324-7; Kessler LG, 2015, STAT METHODS MED RES, V24, P9, DOI 10.1177/0962280214537333; Kinner S, 2016, DIGEST DIS SCI, V61, P1337, DOI 10.1007/s10620-016-4037-1; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Lee J, 2014, MAGN RESON MED, V72, P640, DOI 10.1002/mrm.24964; Linguraru MG, 2012, ACAD RADIOL, V19, P588, DOI 10.1016/j.acra.2012.01.015; Liu CY, 2007, MAGN RESON MED, V58, P354, DOI 10.1002/mrm.21301; Lopez-Mir F, 2014, COMPUT METH PROG BIO, V114, DOI 10.1016/j.cmpb.2013.12.022; Masoumi H, 2012, BIOMED SIGNAL PROCES, V7, P429, DOI 10.1016/j.bspc.2012.01.002; Middleton MS, 2017, GASTROENTEROLOGY, V153, P753, DOI 10.1053/j.gastro.2017.06.005; Mohamed RG, 2017, INT J COMPUT APPL, V176, P30; Nakayama Y, 2006, RADIOLOGY, V240, P743, DOI 10.1148/radiol.2403050850; Reeder SB, 2007, J MAGN RESON IMAGING, V25, P644, DOI 10.1002/jmri.20831; Rohlfing T, 2004, MED PHYS, V31, P427, DOI 10.1118/1.1644513; Roth HR, 2017, ARXIV170406382 CS PR; Smith AD, 2017, RADIOLOGY, V283, P710, DOI 10.1148/radiol.2016160799; Summers Ronald M, 2016, AJR Am J Roentgenol, V207, P67, DOI 10.2214/AJR.15.15996; Suzuki K, 2011, AM J ROENTGENOL, V197, pW706, DOI 10.2214/AJR.10.5958; Tang A, 2015, ABDOM IMAGING, V40, P26, DOI 10.1007/s00261-014-0175-0; Yan ZN, 2015, COMPUT MED IMAG GRAP, V41, P80, DOI 10.1016/j.compmedimag.2014.05.012; Yang D, 2017, P INT C MED IM COMP, P507, DOI [10.1007/978-3-319-66179-7_58, DOI 10.1007/978-3-319-66179-758]; Yokoo T, 2009, RADIOLOGY, V251, P67, DOI 10.1148/radiol.2511080666; Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015	38	4	4	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2019	1	2							e180022	10.1148/ryai.2019180022	http://dx.doi.org/10.1148/ryai.2019180022			14	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CM		Green Published, Green Submitted, Green Accepted			2022-12-18	WOS:000826288900003
J	Lincoln, CM; Chatterjee, R; Willis, MH				Lincoln, Christie M.; Chatterjee, Ritodhi; Willis, Marc H.			Augmented Radiology: Looking Over the Horizon	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Lincoln, Christie M.; Chatterjee, Ritodhi; Willis, Marc H.] Baylor Coll Med, Dept Radiol, One Baylor Plaza MS360, Houston, TX 77030 USA		Lincoln, CM (corresponding author), Baylor Coll Med, Dept Radiol, One Baylor Plaza MS360, Houston, TX 77030 USA.	Christie.Lincoln@bcm.edu		Chatterjee, Ritodhi/0000-0002-3976-9445				Allen B, 2017, DIAGNOSIS, V4, P113, DOI 10.1515/dx-2017-0020; Berwick DM, 2008, HEALTH AFFAIR, V27, P759, DOI 10.1377/hlthaff.27.3.759; Chavis S., RADIOL TODAY2015, V16, P24; Christensen CM, 2015, HARVARD BUS REV, V93, P44; Davenport TH, 2018, NEJM CATALYST; Dreyer K, 2018, J AM COLL RADIOL, V15, P655, DOI 10.1016/j.jacr.2018.01.010; Dutta S, 2013, ANN EMERG MED, V62, P162, DOI 10.1016/j.annemergmed.2013.02.001; Ellenbogen PH, 2013, J AM COLL RADIOL, V10, P229, DOI 10.1016/j.jacr.2013.02.011; Hagland M, HEALTHC INFORM; Halabi SS, 2019, RADIOLOGY, V290, P498, DOI 10.1148/radiol.2018180736; Institute for Health Technology Transformation, 2012, POP HLTH MAN ROADM P; Kauffman L., RADIOLOGIST POPULATI; McGinty GB, 2018, J AM COLL RADIOL, V15, P577, DOI 10.1016/j.jacr.2017.12.024; Oliveira L, 2015, STUD HEALTH TECHNOL, V216, P1028, DOI 10.3233/978-1-61499-564-7-1028; Sankar S., 2012, RISE HUMAN COMPUTER; Sarwar A, 2015, RADIOGRAPHICS, V35, P866, DOI 10.1148/rg.2015140221; Schraudolph N.N., 2007, ARTIF INTELL, P436; Skochelak SE, 2016, HLTH SYSTEMS SCI; Willis MH, 2015, J AM COLL RADIOL, V12, P127, DOI 10.1016/j.jacr.2014.03.013	19	4	4	0	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2019	1	1							e180039	10.1148/ryai.2019180039	http://dx.doi.org/10.1148/ryai.2019180039			3	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CL	33937784	Green Published			2022-12-18	WOS:000826287700005
J	Huang, WJ; Li, X; Li, H; Wang, WX; Chen, KW; Xu, K; Zhang, JY; Chen, YJ; Wei, DF; Shu, N; Zhang, ZJ				Huang, Weijie; Li, Xin; Li, He; Wang, Wenxiao; Chen, Kewei; Xu, Kai; Zhang, Junying; Chen, Yaojing; Wei, Dongfeng; Shu, Ni; Zhang, Zhanjun			Accelerated Brain Aging in Amnestic Mild Cognitive Impairment: Relationships with Individual Cognitive Decline, Risk Factors for Alzheimer Disease, and Clinical Progression	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						MR Imaging; Brain/Brain Stem; Brain Age; Machine Learning; Mild Cognitive Impairment; Structural MRI	LONGITUDINAL PATTERN; AGE; VOXEL; ATROPHY; MEMORY	Purpose: To determine whether a brain age prediction model could quantify individual deviations from a healthy brain-aging trajectory (predicted age difference [PAD]) in patients with amnestic mild cognitive impairment (aMCI) and to determine if PAD was associated with individual cognitive impairment. Materials and Methods: In this retrospective study, a machine learning approach was trained to determine brain age based on T1-weighted MRI scans. Two datasets were used for model training and testing-the Beijing Aging Brain Rejuvenation Initiative (BABRI) (616 healthy controls and 80 patients with aMCI, 2010-2018) and the Alzheimer's Disease Neuroimaging Initiative (ADNI) (589 healthy controls and 144 patients with aMCI, 2010-2018). A total of 974 healthy controls were used for model training (490 from BABRI and 484 from ADNI; age range, 49-95 years). The trained model was then tested on both healthy controls (126 from BABRI and 105 from ADNI) and patients with aMCI (80 from BABRI and 144 from ADNI) to estimate PAD (predicted age - actual age). Furthermore, the associations between PAD with cognitive impairment, genetic risk factors and pathologic markers of Alzheimer disease (AD), and clinical progression in patients with aMCI were examined using a partial correlation analysis, a two-way analysis of covariance, and a general linear model, respectively. Results: Based on the prediction model, patients with aMCI were found to have higher PADs than those of healthy controls (BABRI: 2.65 +/- 4.91 [standard deviation] vs 0.18 +/- 4.79 [P < .001]; ADNI: 1.68 +/- 5.28 vs 0.05 +/- 4.41 [P < .001]). Moreover, the PAD was significantly associated with individual cognitive impairment in several cognitive domains in patients with aMCI (P > .05, corrected). When considering different AD-related risk factors, apolipoprotein E ' 4 allele carriers were observed to have higher PADs than noncarriers (3.76 +/- 4.82 vs 0.10 +/- 5.05; P =.017), and patients with amyloid-positive aMCI were observed to have higher PADs than patients with amyloid-negative status (2.40 +/- 5.25 vs 0.93 +/- 5.20; P =.003). Finally, PAD combined with other markers of AD at baseline for differentiating between progressive and stable aMCI resulted in an area under the curve value of 0.87. Conclusion: The PAD is a sensitive imaging marker related to individual cognitive differences in patients with aMCI. Supplemental material is available for this article. (C) RSNA, 2021.	[Huang, Weijie; Li, Xin; Li, He; Wang, Wenxiao; Xu, Kai; Zhang, Junying; Chen, Yaojing; Wei, Dongfeng; Shu, Ni; Zhang, Zhanjun] Beijing Normal Univ, State Key Lab Cognit Neurosci & Learning, Beijing 100875, Peoples R China; [Huang, Weijie; Li, Xin; Li, He; Wang, Wenxiao; Chen, Kewei; Xu, Kai; Zhang, Junying; Chen, Yaojing; Wei, Dongfeng; Shu, Ni; Zhang, Zhanjun] Beijing Normal Univ, Beijing Aging Brain Rejuvenat Initiat Ctr, Beijing, Peoples R China; [Li, He; Zhang, Junying; Wei, Dongfeng] China Acad Tradit Chinese Med, Inst Basic Res Clin Med, Beijing, Peoples R China; [Chen, Kewei] Banner Alzheimers Inst, Phoenix, AZ USA	Beijing Normal University; Beijing Normal University; China Academy of Chinese Medical Sciences; Institute of Basic Research In Clinical Medicine, CACMS; Banner Research; Banner Health; Banner Alzheimer's Institute	Shu, N (corresponding author), Beijing Normal Univ, State Key Lab Cognit Neurosci & Learning, Beijing 100875, Peoples R China.; Shu, N (corresponding author), Beijing Normal Univ, Beijing Aging Brain Rejuvenat Initiat Ctr, Beijing, Peoples R China.	nshu@bnu.edu.cn	Chen, kewei/P-6304-2015	Chen, kewei/0000-0001-8497-3069; huang, weijie/0000-0002-2481-1188; Wei, Dongfeng/0000-0002-2803-2974	National Natural Science Foundation of China [81471732, 81671761, 81871425]; National Science Fund for Distinguished Young Scholars [81625025]; Funds for International Cooperation and Exchange of the National Natural Science Foundation of China [81820108034]; National Key Research and Development Project of China [2018YFC1315200]; State Key Program of National Natural Science of China [81430100]; Fundamental Research Funds for the Central Universities [2017XTCX04]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Science Fund for Distinguished Young Scholars(National Natural Science Foundation of China (NSFC)National Science Fund for Distinguished Young Scholars); Funds for International Cooperation and Exchange of the National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Key Research and Development Project of China; State Key Program of National Natural Science of China(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities)	Supported by the National Natural Science Foundation of China (grant nos. 81471732, 81671761, and 81871425); National Science Fund for Distinguished Young Scholars (grant no. 81625025); Funds for International Cooperation and Exchange of the National Natural Science Foundation of China (grant no. 81820108034); National Key Research and Development Project of China (grant no. 2018YFC1315200); State Key Program of National Natural Science of China (grant no. 81430100); and Fundamental Research Funds for the Central Universities (grant no. 2017XTCX04).	Aguilar Carlos, 2014, Front Aging Neurosci, V6, P145, DOI 10.3389/fnagi.2014.00145; Barretina J, 2012, NATURE, V483, P603, DOI 10.1038/nature11003; Beheshti I, 2018, BRAIN BEHAV, V8, DOI 10.1002/brb3.1020; Chetelat G, 2002, NEUROREPORT, V13, P1939; Cole JH, 2019, MOL PSYCHIATR, V24, P266, DOI 10.1038/s41380-018-0098-1; Cole JH, 2017, TRENDS NEUROSCI, V40, P681, DOI 10.1016/j.tins.2017.10.001; Cole JH, 2017, NEUROIMAGE, V163, P115, DOI 10.1016/j.neuroimage.2017.07.059; Cole JH, 2017, NEUROBIOL AGING, V56, P41, DOI 10.1016/j.neurobiolaging.2017.04.006; Cole JH, 2017, NEUROLOGY, V88, P1349, DOI [10.1212/WNL.0000000000003790, 10.1212/wnl.0000000000003790]; Cole JH, 2015, ANN NEUROL, V77, P571, DOI 10.1002/ana.24367; Crivello F, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0114478; Cui ZX, 2018, CEREB CORTEX, V28, P1656, DOI 10.1093/cercor/bhx061; Curiati PK, 2009, AM J NEURORADIOL, V30, P1850, DOI 10.3174/ajnr.A1727; deToledo-Morrell L, 2004, NEUROBIOL AGING, V25, P1197, DOI 10.1016/j.neurobiolaging.2003.12.007; Dickerson BC, 2011, J NEUROL NEUROSUR PS, V82, P45, DOI 10.1136/jnnp.2009.199505; Driscoll I, 2009, NEUROLOGY, V72, P1906, DOI 10.1212/WNL.0b013e3181a82634; Franke K, 2012, NEUROIMAGE, V63, P1305, DOI 10.1016/j.neuroimage.2012.08.001; Franke K, 2010, NEUROIMAGE, V50, P883, DOI 10.1016/j.neuroimage.2010.01.005; Gaser C, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0067346; Jack CR, 2008, J MAGN RESON IMAGING, V27, P685, DOI 10.1002/jmri.21049; Jack CR, 2019, JAMA-J AM MED ASSOC, V321, P2316, DOI 10.1001/jama.2019.7437; Jack CR, 2017, ALZHEIMERS DEMENT, V13, P205, DOI 10.1016/j.jalz.2016.08.005; Jack CR, 2010, ALZHEIMERS DEMENT, V6, P212, DOI 10.1016/j.jalz.2010.03.004; Johnson JW, 2004, ORGAN RES METHODS, V7, P238, DOI 10.1177/1094428104266510; Kantarci K, 2020, NEUROLOGY, V94, pE282, DOI 10.1212/WNL.0000000000008818; Li X, 2020, CEREB CORTEX, V30, P4651, DOI 10.1093/cercor/bhaa066; Liem F, 2017, NEUROIMAGE, V148, P179, DOI 10.1016/j.neuroimage.2016.11.005; Lim YY, 2012, NEUROLOGY, V79, P1645, DOI 10.1212/WNL.0b013e31826e9ae6; Lowe LC, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157514; Ly M, 2020, NEUROBIOL AGING, V87, P44, DOI 10.1016/j.neurobiolaging.2019.11.005; Mielke MM, 2018, ALZHEIMERS DEMENT, V14, P989, DOI 10.1016/j.jalz.2018.02.013; Nho K, 2012, BRAIN IMAGING BEHAV, V6, P551, DOI 10.1007/s11682-012-9203-2; Petersen RC, 1999, ARCH NEUROL-CHICAGO, V56, P303, DOI 10.1001/archneur.56.3.303; Petersen RC, 2004, J INTERN MED, V256, P183, DOI 10.1111/j.1365-2796.2004.01388.x; Scheinost D, 2019, NEUROIMAGE, V193, P35, DOI 10.1016/j.neuroimage.2019.02.057; Schnack HG, 2016, AM J PSYCHIAT, V173, P607, DOI 10.1176/appi.ajp.2015.15070922; Smits LL, 2014, ALZHEIMERS DEMENT, V10, pS299, DOI 10.1016/j.jalz.2013.06.007; Su F, 2017, J ALZHEIMERS DIS, V56, P491, DOI 10.3233/JAD-160787; Tisserand DJ, 2004, CEREB CORTEX, V14, P966, DOI 10.1093/cercor/bhh057; Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978; Wang J, 2019, P NATL ACAD SCI USA, V116, P21213, DOI 10.1073/pnas.1902376116	41	3	2	4	4	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2021	3	5							e200171	10.1148/ryai.2021200171	http://dx.doi.org/10.1148/ryai.2021200171			13	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9TT	34617021	Green Published			2022-12-18	WOS:000826911500002
J	Wu, MX; Chai, ZZ; Qian, GW; Lin, HJ; Wang, Q; Wang, LS; Chen, H				Wu, Mingxiang; Chai, Zhizhong; Qian, Guangwu; Lin, Huangjing; Wang, Qiong; Wang, Liansheng; Chen, Hao			Development and Evaluation of a Deep Learning Algorithm for Rib Segmentation and Fracture Detection from Multicenter Chest CT Images	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						CT; Ribs		Purpose: To evaluate the performance of a deep learning-based algorithm for automatic detection and labeling of rib fractures from multicenter chest CT images. Materials and Methods: This retrospective study included 10943 patients (mean age, 55 years; 6418 men) from six hospitals (January 1, 2017 to December 30, 2019), which consisted of patients with and without rib fractures who underwent CT. The patients were separated into one training set (n = 2425), two lesion-level test sets (n = 362 and 105), and one examination-level test set (n = 8051). Free-response receiver operating characteristic (FROC) score (mean sensitivity of seven different false-positive rates), precision, sensitivity, and F1 score were used as metrics to assess rib fracture detection performance. Area under the receiver operating characteristic curve (AUC), sensitivity, and specificity were employed to evaluate the classification accuracy. The mean Dice coefficient and accuracy were used to assess the performance of rib labeling. Results: In the detection of rib fractures, the model showed an FROC score of 84.3% on test set 1. For test set 2, the algorithm achieved a detection performance (precision, 82.2%; sensitivity, 84.9%; F1 score, 83.3%) comparable to three radiologists (precision, 81.7%, 98.0%, 92.0%; sensitivity, 91.2%, 78.6%, 69.2%; F1 score, 86.1%, 87.2%, 78.9%). When the radiologists used the algorithm, the mean sensitivity of the three radiologists showed an improvement (from 79.7% to 89.2%), with precision achieving similar performance (from 90.6% to 88.4%). Furthermore, the model achieved an AUC of 0.93 (95% CI: 0.91, 0.94), sensitivity of 87.9% (95% CI: 83.7%, 91.4%), and specificity of 85.3% (95% CI: 74.6%, 89.8%) on test set 3. On a subset of test set 1, the model achieved a Dice score of 0.827 with an accuracy of 96.0% for rib segmentation. Conclusion: The developed deep learning algorithm was capable of detecting rib fractures, as well as corresponding anatomic locations on CT images. (C) RSNA, 2021.	[Wu, Mingxiang] Shenzhen Peoples Hosp, Dept Radiol, Luohu, Peoples R China; [Chai, Zhizhong; Lin, Huangjing] Imsight Technol, AI Res Lab, Nanshan, Peoples R China; [Qian, Guangwu] Peng Cheng Lab, Nanshan, Peoples R China; [Wang, Qiong] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China; [Wang, Liansheng] Xiamen Univ, Sch Informat, Dept Comp Sci, Xiamen, Peoples R China; [Chen, Hao] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Peoples R China	Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS; Xiamen University; Hong Kong University of Science & Technology	Chen, H (corresponding author), Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Peoples R China.	jhc@cse.ust.hk	Wang, Liansheng/HGA-8949-2022; Chen, Hao/V-4299-2019	Wang, Liansheng/0000-0002-2096-454X; Chen, Hao/0000-0002-8400-3780; Mingxiang, Wu/0000-0003-2454-1752	Shenzhen Science and Technology Program [JCYJ20180507182410327]; National Natural Science Foundation of China [62072452]	Shenzhen Science and Technology Program; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	Supported by the Shenzhen Science and Technology Program (grant JCYJ20180507182410327) and National Natural Science Foundation of China (grant 62072452).	Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; Ali Farhadi, 2018, Arxiv, DOI arXiv:1804.02767; Cho SH, 2012, BRIT J RADIOL, V85, pE845, DOI 10.1259/bjr/28575455; Chollet F, KERAS; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Girshick R., 2014, PROC IEEE C COMPUT V; Gu Y, 2018, COMPUT BIOL MED, V103, P220, DOI 10.1016/j.compbiomed.2018.10.011; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Huseyn E., 2020, NAT SCI, V02, P7; Jiang HY, 2018, IEEE J BIOMED HEALTH, V22, P1227, DOI 10.1109/JBHI.2017.2725903; Kuo WC, 2019, P NATL ACAD SCI USA, V116, P22737, DOI 10.1073/pnas.1908021116; Lin T.Y., 2016, FEATURE PYRAMID NETW; Liu F, 2018, RADIOLOGY, V289, P160, DOI 10.1148/radiol.2018172986; Miller LA, 2006, RADIOL CLIN N AM, V44, P213, DOI 10.1016/j.rcl.2005.10.006; Monteiro M, 2020, LANCET DIGIT HEALTH, V2, pE314, DOI 10.1016/S2589-7500(20)30085-6; Nazib A, 2019, I S BIOMED IMAGING, P512, DOI 10.1109/ISBI.2019.8759291; Norman B, 2018, RADIOLOGY, V288, P177, DOI 10.1148/radiol.2018172322; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ren S., 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.169; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Sirmali M, 2003, EUR J CARDIO-THORAC, V24, P133, DOI 10.1016/S1010-7940(03)00256-2; Suk HI, 2016, NEUROIMAGE, V129, P292, DOI 10.1016/j.neuroimage.2016.01.005; van der Walt S, 2014, PEERJ, V2, DOI 10.7717/peerj.453; Weikert T, 2020, KOREAN J RADIOL, V21, P891, DOI 10.3348/kjr.2019.0653; Wu GR, 2016, IEEE T BIO-MED ENG, V63, P1505, DOI 10.1109/TBME.2015.2496253; Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015; Zhang WL, 2015, NEUROIMAGE, V108, P214, DOI 10.1016/j.neuroimage.2014.12.061; Zhou QQ, 2020, KOREAN J RADIOL, V21, P869, DOI 10.3348/kjr.2019.0651	31	3	3	1	3	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2021	3	5							e200248	10.1148/ryai.2021200248	http://dx.doi.org/10.1148/ryai.2021200248			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9TT	34617026	Green Published			2022-12-18	WOS:000826911500007
J	Wiggins, WF; Kitamura, F; Santos, I; Prevedello, LM				Wiggins, Walter F.; Kitamura, Felipe; Santos, Igor; Prevedello, Luciano M.			Natural Language Processing of Radiology Text Reports: Interactive Text Classification	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							ARTIFICIAL-INTELLIGENCE	This report presents a hands-on introduction to natural language processing (NLP) of radiology reports with deep neural networks in Google Colaboratory (Colab) to introduce readers to the rapidly evolving field of NLP. The implementation of the Google Colab notebook was designed with code hidden to facilitate learning for noncoders (ie, individuals with little or no computer programming experience). The data used for this module are the corpus of radiology reports from the Indiana University chest x-ray collection available from the National Library of Medicine's Open-I service. The module guides learners through the process of exploring the data, splitting the data for model training and testing, preparing the data for NLP analysis, and training a deep NLP model to classify the reports as normal or abnormal. Concepts in NLP, such as tokenization, numericalization, language modeling, and word embeddings, are demonstrated in the module. The module is implemented in a guided fashion with the authors presenting the material and explaining concepts. Interactive features and extensive text commentary are provided directly in the notebook to facilitate self-guided learning and experimentation with the module. (C)RSNA, 2021	[Wiggins, Walter F.] Duke Univ Hlth Syst, Duke Univ Hosp, Dept Radiol, Box 3808,2301 Erwin Rd, Durham, NC 27710 USA; [Kitamura, Felipe; Santos, Igor] Univ Fed Sao Paulo, Dept Diagnost Imaging, Escola Paulista Med, Sao Paulo, Brazil; [Kitamura, Felipe] Diagnost Amer SA DASA, AI, Sao Paulo, Brazil; [Santos, Igor] NESS Hlth, FIDI, Sao Paulo, Brazil; [Prevedello, Luciano M.] Ohio State Univ, Dept Radiol, Columbus, OH 43210 USA	Duke University; Universidade Federal de Sao Paulo (UNIFESP); University System of Ohio; Ohio State University	Wiggins, WF (corresponding author), Duke Univ Hlth Syst, Duke Univ Hosp, Dept Radiol, Box 3808,2301 Erwin Rd, Durham, NC 27710 USA.	walter.wiggins@duke.edu	Kitamura, Felipe Campos/AAC-7075-2021	Kitamura, Felipe Campos/0000-0002-9992-5630; Prevedello, Luciano/0000-0002-6768-6452; Wiggins, Walter/0000-0002-0258-2708				Allen C, 1901, ARXIV; Bressem KK, 2020, BIOINFORMATICS, DOI [10.1093/bio-informatics/btaa668, DOI 10.1093/BIO-INFORMATICS/BTAA668]; Cai TR, 2016, RADIOGRAPHICS, V36, P176, DOI 10.1148/rg.2016150080; Chen PH, 2020, ACAD RADIOL, V27, P6, DOI 10.1016/j.acra.2019.08.010; Demner-Fushman D, 2016, J AM MED INFORM ASSN, V23, P304, DOI 10.1093/jamia/ocv080; Erickson Bradley J, 2019, Radiol Artif Intell, V1, pe190113, DOI 10.1148/ryai.2019190113; Erickson BJ, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190215; Erickson BJ, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190161; Erickson BJ, 2019, RADIOL-ARTIF INTELL, V1, DOI [10.1148/ryai.2019190072, 10.1148/ryai.2019190113, 10.1148/ryai.2019190126]; Howard J, ARXIV 180106146; Huber NR, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020200036; Lindqwister AL, 2021, ACAD RADIOL, V28, P1810, DOI 10.1016/j.acra.2020.09.017; Ong CJ, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0234908; Pons E, 2016, RADIOLOGY, V279, P329, DOI 10.1148/radiol.16142770; Rubin DL, 2019, J AM COLL RADIOL, V16, P1309, DOI 10.1016/j.jacr.2019.05.036; Simpson SA, 2020, J AM COLL RADIOL, V17, P1388, DOI 10.1016/j.jacr.2020.09.028; Slanetz PJ, 2020, J AM COLL RADIOL, V17, P1705, DOI 10.1016/j.jacr.2020.04.022; Tajmir SH, 2018, ACAD RADIOL, V25, P747, DOI 10.1016/j.acra.2018.03.007; Wiggins WF, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020200057; Wood MJ, 2019, J AM COLL RADIOL, V16, P740, DOI 10.1016/j.jacr.2018.10.008	20	3	3	2	3	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2021	3	4							e210035	10.1148/ryai.2021210035	http://dx.doi.org/10.1148/ryai.2021210035			7	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SU	34350414	Green Published			2022-12-18	WOS:000826909000014
J	Demircioglu, A; Kim, MS; Stein, MC; Guberina, N; Umutlu, L; Nassenstein, K				Demircioglu, Aydin; Kim, Moon-Sung; Stein, Magdalena Charis; Guberina, Nika; Umutlu, Lale; Nassenstein, Kai			Automatic Scan Range Delimitation in Chest CT Using Deep Learning	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							EQUIVALENCE; TESTS	Purpose: To develop and evaluate fully automatic scan range delimitation for chest CT by using deep learning. Materials and Methods: For this retrospective study, scan ranges were annotated by two expert radiologists in consensus in 1149 (mean age, +/- 5 years +/- 16 [standard deviation]; 595 male patients) chest CT topograms acquired between March 2002 and February 2019 (350 with pleural effusion, 376 with atelectasis, 409 with neither, 14 with both). A conditional generative adversarial neural network was trained on 1000 randomly selected topograms to generate virtual scan range delimitations. On the remaining 149 topograms the software-based scan delimitations, scan lengths, and estimated radiation exposure were compared with those from clinical routine. For statistical analysis an equivalence test (two one-sided t tests) was used, with equivalence limits of 10 mm. Results: The software-based scan ranges were similar to the radiologists' annotations, with a mean Dice score coefficient of 0.99 +/- 0.01 and an absolute difference of 1.8 mm +/- 1.9 and 3.3 mm +/- 5.6 at the upper and lower boundary, respectively. An equivalence test indicated that both scan range delimitations were similar (P < .001). The software-based scan delimitation led to shorter scan ranges compared with those used in clinical routine (298.2 mm +/- 32.7 vs 327.0 mm +/- 42.0; P,.001), resulting in a lower simulated total radiation exposure (3.9 mSv +/- 3.0 vs 4.2 mSv +/- 3.3; P < .001). Conclusion: A conditional generative adversarial neural network was capable of automating scan range delimitation with high accuracy, potentially leading to shorter scan times and reduced radiation exposure. (C)RSNA, 2021	[Demircioglu, Aydin; Kim, Moon-Sung; Stein, Magdalena Charis; Guberina, Nika; Nassenstein, Kai] Univ Duisburg Essen, Univ Hosp Essen, Dept Diagnost & Intervent Radiol & Neuroradiol, Hufelandstr 55, D-45147 Essen, Germany; [Umutlu, Lale] Univ Duisburg Essen, Univ Hosp Essen, Dept Radiotherapy, Hufelandstr 55, D-45147 Essen, Germany	University of Duisburg Essen; University of Duisburg Essen	Demircioglu, A (corresponding author), Univ Duisburg Essen, Univ Hosp Essen, Dept Diagnost & Intervent Radiol & Neuroradiol, Hufelandstr 55, D-45147 Essen, Germany.	aydin.demircioglu@uk-essen.de						ALTMAN DG, 1983, J ROY STAT SOC D-STA, V32, P307, DOI 10.2307/2987937; [Anonymous], 2007, Ann ICRP, V37, P1, DOI 10.1016/j.icrp.2008.08.001; [Anonymous], 1999, 10153 BS EN; Ardila D, 2019, NAT MED, V25, P954, DOI 10.1038/s41591-019-0447-x; Cohen SL, 2020, CLIN IMAG, V62, P76, DOI 10.1016/j.clinimag.2019.11.020; Colevray M, 2019, DIAGN INTERV IMAG, V100, P177, DOI 10.1016/j.diii.2018.11.001; Du SS, ARXIV180507883; Guberina N, 2017, ROFO-FORTSCHR RONTG, V189, P356, DOI 10.1055/s-0042-116684; Huo DL, 2019, J DIGIT IMAGING, V32, P931, DOI 10.1007/s10278-019-00233-z; Lakens D, 2017, SOC PSYCHOL PERS SCI, V8, P355, DOI 10.1177/1948550617697177; Little MP, 2018, BMJ OPEN, V8, DOI 10.1136/bmjopen-2018-021536; Majkowska A, 2020, RADIOLOGY, V294, P421, DOI 10.1148/radiol.2019191293; Mirza M., 2014, ARXIV PREPRINT ARXIV; OECD, 2020, COMPUT TOMOGR, DOI [10.1787/bedece12-en, DOI 10.1787/BEDECE12-EN]; Paszke A., ARXIV191201703; Rehani MM, 2020, EUR RADIOL, V30, P1828, DOI 10.1007/s00330-019-06523-y; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Ronneberger O., 2015, P INT C MED IMAG COM, P234, DOI [DOI 10.1007/978-3-319-24574-4_28, DOI 10.48550/ARXIV.1505.04597]; SCHUIRMANN DJ, 1987, J PHARMACOKINET BIOP, V15, P657, DOI 10.1007/BF01068419; Schwartz F, 2018, EUR J RADIOL, V102, P49, DOI 10.1016/j.ejrad.2018.03.005; Sejnowski TJ, 2020, P NATL ACAD SCI USA, V117, P30033, DOI 10.1073/pnas.1907373117; Walsh SLF, 2018, LANCET RESP MED, V6, P837, DOI 10.1016/S2213-2600(18)30286-8; Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917; Wiest PW, 2002, SEMIN ULTRASOUND CT, V23, P402, DOI 10.1016/S0887-2171(02)90011-9; Zhang W, 2010, PROC SPIE, V7623, DOI [10.1117/12.844559, 10.1109/iCECE.2010.569]	25	3	3	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2021	3	3							e200211	10.1148/ryai.2021200211	http://dx.doi.org/10.1148/ryai.2021200211			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SA	34136818	Green Published			2022-12-18	WOS:000826907000009
J	O'Connor, SD; Bhalla, M				O'Connor, Stacy D.; Bhalla, Manav			Should Artificial Intelligence Tell Radiologists Which Study to Read Next?	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[O'Connor, Stacy D.; Bhalla, Manav] Med Coll Wisconsin, Dept Radiol, 9200 W Wisconsin Ave, Milwaukee, WI 53226 USA; [O'Connor, Stacy D.] Med Coll Wisconsin, Dept Surg, 9200 W Wisconsin Ave, Milwaukee, WI 53226 USA	Medical College of Wisconsin; Medical College of Wisconsin	O'Connor, SD (corresponding author), Med Coll Wisconsin, Dept Radiol, 9200 W Wisconsin Ave, Milwaukee, WI 53226 USA.; O'Connor, SD (corresponding author), Med Coll Wisconsin, Dept Surg, 9200 W Wisconsin Ave, Milwaukee, WI 53226 USA.	soconnor@mcw.edu		O'Connor, Stacy/0000-0002-0813-1414				Arbabshirani MR, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-017-0015-z; Gaskin CM, 2016, AM J ROENTGENOL, V206, P1031, DOI 10.2214/AJR.15.14837; Miller K, 2018, J AM MED INFORM ASSN, V25, P585, DOI 10.1093/jamia/ocx118; O'Neill TJ, 2021, RADIOL-ARTIF INTELL, V3, DOI 10.1148/ryai.2020200024; Osborne TF, 2018, J STROKE CEREBROVASC, V27, P1190, DOI 10.1016/j.jstrokecerebrovasdis.2017.11.038; Radiology Technical Committee, IHE RAD TECHN FRAM S; Yang QH, 2017, MMWR-MORBID MORTAL W, V66, P933, DOI 10.15585/mmwr.mm6635e1	7	3	3	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2021	3	2							e210009	10.1148/ryai.2021210009	http://dx.doi.org/10.1148/ryai.2021210009			2	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z3LD	33939773	Green Published			2022-12-18	WOS:000826483100012
J	Tiwari, P; Verma, R				Tiwari, Pallavi; Verma, Ruchika			The Pursuit of Generalizability to Enable Clinical Translation of Radiomics	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material							SURVIVAL		[Tiwari, Pallavi; Verma, Ruchika] Case Western Reserve Univ, Case Sch Engn Biomed Engn, 2095 Martin Luther King Jr Dr,Hall Room 500, Cleveland, OH 44106 USA	Case Western Reserve University	Tiwari, P (corresponding author), Case Western Reserve Univ, Case Sch Engn Biomed Engn, 2095 Martin Luther King Jr Dr,Hall Room 500, Cleveland, OH 44106 USA.	pxt130@case.edu	Verma, Ruchika/AAD-9345-2019	Verma, Ruchika/0000-0003-4870-128X; Tiwari, Pallavi/0000-0001-9477-4856	National Institutes of Health [NCI/ITCR: 1U01CA248226-01]; Department of Defense (DoD) Peer Reviewed Cancer Research Program [W81XWH-18-1-0404]; Johnson & Johnson Research Scholar Award; Dana Foundation David Mahoney Neuroimaging Grant; CCCC Brain Tumor Pilot Award; CWRU Technology Validation Start-Up Fund (CTP); V Foundation Translational Research Award	National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Department of Defense (DoD) Peer Reviewed Cancer Research Program; Johnson & Johnson Research Scholar Award; Dana Foundation David Mahoney Neuroimaging Grant; CCCC Brain Tumor Pilot Award; CWRU Technology Validation Start-Up Fund (CTP); V Foundation Translational Research Award	Activities related to the present article: research partly supported by the National Institutes of Health under award number NCI/ITCR: 1U01CA248226-01, as well as by the Department of Defense (DoD) Peer Reviewed Cancer Research Program (W81XWH-18-1-0404), Johnson & Johnson Research Scholar Award, Dana Foundation David Mahoney Neuroimaging Grant, the CCCC Brain Tumor Pilot Award, the CWRU Technology Validation Start-Up Fund (CTP), and The V Foundation Translational Research Award. Activities not related to the present article: disclosed no relevant relationships. Other relationships: disclosed no relevant relationships. V.R. disclosed no relevant relationships.	Beig N, 2020, CLIN CANCER RES, V26, P1866, DOI 10.1158/1078-0432.CCR-19-2556; Chirra P, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.2.024502; Hoebel KV, 2021, RADIOL-ARTIF INTELL, V3, DOI 10.1148/ryai.2020190199; Khorrami M, 2020, LUNG CANCER, V142, P90, DOI 10.1016/j.lungcan.2020.02.018; Khorrami M, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180012; Kickingereder P, 2016, RADIOLOGY, V280, P880, DOI 10.1148/radiol.2016160845; Mackin D, 2015, INVEST RADIOL, V50, P757, DOI 10.1097/RLI.0000000000000180; Shiri I, 2020, MED PHYS, V47, P4265, DOI 10.1002/mp.14368; Tixier F, 2019, MED PHYS, V46, P3582, DOI 10.1002/mp.13624; Um H, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab2f44; Zwanenburg A, 2020, RADIOLOGY, V295, P328, DOI 10.1148/radiol.2020191145	11	3	3	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2021	3	1							e200227	10.1148/ryai.2020200227	http://dx.doi.org/10.1148/ryai.2020200227			3	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z3HE	33847697	Green Published			2022-12-18	WOS:000826472300008
J	Meijs, M; Pegge, SAH; Vos, MHE; Patel, A; van de Leemput, SC; Koschmieder, K; Prokop, M; Meijer, FJA; Manniesing, R				Meijs, Midas; Pegge, Sjoert A. H.; Vos, Maria H. E.; Patel, Ajay; van de Leemput, Sil C.; Koschmieder, Kevin; Prokop, Mathias; Meijer, Frederick J. A.; Manniesing, Rashindra			Cerebral Artery and Vein Segmentation in Four-dimensional CT Angiography Using Convolutional Neural Networks	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To implement and test a deep learning approach for the segmentation of the arterial and venous cerebral vasculature with four-dimensional (4D) CT angiography. Materials and Methods: Patients who had undergone 4D CT angiography for the suspicion of acute ischemic stroke were retrospectively identified. A total of 390 patients evaluated in 2014 (n = 113) or 2018 (n = 277) were included in this study, with each patient having undergone one 4D CT angiographic scan. One hundred patients from 2014 were randomly selected, and the arteries and veins on their CT scans were manually annotated by five experienced observers. The weighted temporal average and weighted temporal variance from 4D CT angiography were used as input for a three-dimensional Dense-U-Net. The network was trained with the fully annotated cerebral vessel artery-vein maps from 60 patients. Forty patients were used for quantitative evaluation. The relative absolute volume difference and the Dice similarity coefficient are reported. The neural network segmentations from 277 patients who underwent scanning in 2018 were qualitatively evaluated by an experienced neuroradiologist using a five-point scale. Results: The average time for processing arterial and venous cerebral vasculature with the network was less than 90 seconds. The mean Dice similarity coefficient in the test set was 0.80 +/- 0.04 (standard deviation) for the arteries and 0.88 +/- 0.03 for the veins. The mean relative absolute volume difference was 7.3% +/- 5.7 for the arteries and 8.5% +/- 4.8 for the veins. Most of the segmentations (n = 273, 99.3%) were rated as very good to perfect. Conclusion: The proposed convolutional neural network enables accurate artery and vein segmentation with 4D CT angiography with a processing time of less than 90 seconds. (C) RSNA, 2020	[Meijs, Midas; Pegge, Sjoert A. H.; Vos, Maria H. E.; Patel, Ajay; van de Leemput, Sil C.; Koschmieder, Kevin; Prokop, Mathias; Meijer, Frederick J. A.; Manniesing, Rashindra] Radboud Univ Nijmegen, Dept Radiol & Nucl Med, Med Ctr, Geert Grootepl Zuid 10, NL-6500 HB Nijmegen, Netherlands		Meijs, M (corresponding author), Radboud Univ Nijmegen, Dept Radiol & Nucl Med, Med Ctr, Geert Grootepl Zuid 10, NL-6500 HB Nijmegen, Netherlands.	midas.meijs@radboudumc.nl	; Manniesing, Rashindra/G-9728-2015; Meijer, Frederick/L-4516-2015	Pegge, Sjoert/0000-0001-9314-6137; Prokop, Mathias/0000-0001-8157-8055; Manniesing, Rashindra/0000-0002-4616-6298; Meijer, Frederick/0000-0001-5921-639X				Albers GW, 2018, NEW ENGL J MED, V378, P708, DOI 10.1056/NEJMoa1713973; Bhuiyan Alauddin, 2018, Annu Int Conf IEEE Eng Med Biol Soc, V2018, P870, DOI 10.1109/EMBC.2018.8512287; Cicek Ozgun, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P424, DOI 10.1007/978-3-319-46723-8_49; DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409; Girard F, 2019, ARTIF INTELL MED, V94, P96, DOI 10.1016/j.artmed.2019.02.004; Hemelings R, 2019, COMPUT MED IMAG GRAP, V76, DOI 10.1016/j.compmedimag.2019.05.004; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Jimenez-Carretero D, 2019, MED IMAGE ANAL, V52, P144, DOI 10.1016/j.media.2018.11.011; Kingma DP, ARXIV 14126980 PREPR; Kortman HGJ, 2015, AM J NEURORADIOL, V36, P1026, DOI 10.3174/ajnr.A4162; Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Ma H, 2019, NEW ENGL J MED, V380, P1795, DOI 10.1056/NEJMoa1813046; Maas MB, 2009, STROKE, V40, P3001, DOI 10.1161/STROKEAHA.109.552513; Manniesing R, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-00239-z; Meijs M, 2018, PROC SPIE, V10575, DOI 10.1117/12.2292974; Meijs M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-15617-w; Mendrik A, 2010, MED PHYS, V37, P2956, DOI 10.1118/1.3397813; Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045; Nardelli P, 2018, IEEE T MED IMAGING, V37, P2428, DOI 10.1109/TMI.2018.2833385; Nogueira RG, 2018, NEW ENGL J MED, V378, P11, DOI 10.1056/NEJMoa1706442; Powers WJ, 2018, STROKE, V49, pE46, DOI 10.1161/STR.0000000000000158; Robben D, 2016, MED IMAGE ANAL, V32, P201, DOI 10.1016/j.media.2016.03.006; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Sakai K, 2019, JPN J RADIOL, V37, P34, DOI 10.1007/s11604-018-0794-4; Shi XJ, 2015, ADV NEUR IN, V28; Shirasaka T, 2017, BRIT J RADIOL, V90, DOI 10.1259/bjr.20160634; Willems PWA, 2012, NEURORADIOLOGY, V54, P123, DOI 10.1007/s00234-011-0864-0; Zhao YT, 2018, LECT NOTES COMPUT SC, V11071, P56, DOI 10.1007/978-3-030-00934-2_7	29	3	3	5	7	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2020	2	4							e190178	10.1148/ryai.2020190178	http://dx.doi.org/10.1148/ryai.2020190178			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CX	33937832	Green Published			2022-12-18	WOS:000826472900005
J	Erickson, BJ; Cai, JS				Erickson, Bradley J.; Cai, Jason			Magician's Corner: 5. Generative Adversarial Networks	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Erickson, Bradley J.; Cai, Jason] Mayo Clin, Dept Radiol, 200 First St SW, Rochester, MN 55905 USA	Mayo Clinic	Erickson, BJ (corresponding author), Mayo Clin, Dept Radiol, 200 First St SW, Rochester, MN 55905 USA.	bje@mayo.edu		/0000-0002-9190-0252; Erickson, Bradley/0000-0001-7926-6095				[Anonymous], WHAT AR SOM REC POT; [Anonymous], 1999, 10153 BS EN; Ben-Cohen A, 2019, ENG APPL ARTIF INTEL, V78, P186, DOI 10.1016/j.engappai.2018.11.013; dos Santos Tanaka FHK., 2019, ARXIV CSLG; Erickson BJ, 2020, RADIOL ARTIF INTELL, V2; Erickson Bradley J, 2019, Radiol Artif Intell, V1, pe190113, DOI 10.1148/ryai.2019190113; Erickson BJ, 2019, RADIOL-ARTIF INTELL, V1, DOI [10.1148/ryai.2019190072, 10.1148/ryai.2019190113, 10.1148/ryai.2019190126]; Gong E, 2018, J MAGN RESON IMAGING, V48, P330, DOI 10.1002/jmri.25970; Goodfellow IJ, ARXIV STATML; Huo YK, 2018, I S BIOMED IMAGING, P1217; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Shmelkov K, 2018, LECT NOTES COMPUT SC, V11206, P218, DOI 10.1007/978-3-030-01216-8_14; Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262; Wolterink JM, 2017, IEEE T MED IMAGING, V36, P2536, DOI 10.1109/TMI.2017.2708987	14	3	3	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2020	2	2							e190215	10.1148/ryai.2020190215	http://dx.doi.org/10.1148/ryai.2020190215			4	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CS	33937820	Green Published, Bronze			2022-12-18	WOS:000826298800008
J	Lakhani, P				Lakhani, Paras			The Importance of Image Resolution in Building Deep Learning Models for Medical Imaging	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Lakhani, Paras] Thomas Jefferson Univ Hosp, Sidney Kimmel Jefferson Med Coll, Dept Radiol, 132 S 10th St,10th Floor,Main Bldg, Philadelphia, PA 19107 USA	Jefferson University	Lakhani, P (corresponding author), Thomas Jefferson Univ Hosp, Sidney Kimmel Jefferson Med Coll, Dept Radiol, 132 S 10th St,10th Floor,Main Bldg, Philadelphia, PA 19107 USA.	Paras.Lakhani@jefferson.edu						[Anonymous], 1999, 10153 BS EN; Ching T, 2018, J R SOC INTERFACE, V15, DOI 10.1098/rsif.2017.0387; Halabi SS, 2019, RADIOLOGY, V290, P498, DOI 10.1148/radiol.2018180736; Krizhevsky A, 2012, ADV NEURAL INFORM PR, V25, P1097, DOI 10.1145/3065386; Lakhani P, 2017, RADIOLOGY, V284, P574, DOI 10.1148/radiol.2017162326; Rajpurkar P, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002686; Ribli D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22437-z; Sabottke CF, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2019190015; siim, PNEUM CHALL; Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369	10	3	3	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2020	2	1							e190177	10.1148/ryai.2019190177	http://dx.doi.org/10.1148/ryai.2019190177			2	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CR	33939779	Bronze, Green Published			2022-12-18	WOS:000826298000007
J	Ohta, Y; Yunaga, H; Kitao, S; Fukuda, T; Ogawa, T				Ohta, Yasutoshi; Yunaga, Hiroto; Kitao, Shinichiro; Fukuda, Tetsuya; Ogawa, Toshihide			Detection and Classification of Myocardial Delayed Enhancement Patterns on MR Images with Deep Neural Networks: A Feasibility Study	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							TASK-FORCE	Purpose: To evaluate whether deep neural networks trained on a similar number of images to that required during physician in the American College of Cardiology Core Cardiovascular Training Statement can acquire the capability to detect and classify myocardial delayed enhancement (MDE) patterns. Materials and methods: The authors retrospectively evaluated 1995 MDE images for training and validation of a deep neural network. Images were from 200 consecutive patients who underwent cardiovascular MRI and were obtained from the institutional database. Experienced cardiac MR image readers classified the images as showing the following MDE patterns: no pattern, epicardial enhancement, subendocardial enhancement, midwall enhancement, focal enhancement, transmural enhancement, and nondiagnostic. Data were divided into training and validation datasets by using a fourfold cross-validation method. Three untrained deep neural network architectures using the convolutional neural network (CNN) technique were trained with the training dataset images. The detection and classification accuracies of the trained CNNs were calculated with validation data. Results: The 1995 MDE images were classified by human readers as follows: no pattern, 926; epicardial enhancement, 91; subendocardial enhancement, 458; midwall enhancement, 118; focal enhancement, 141; transmural enhancement, 190; and nondiagnostic, 71. GoogLeNet, AlexNet, and ResNet-152 CNNs demonstrated accuracies of 79.5% (1592 of 1995 images), 78.9% (1574 of 1995 images), and 82.1% (1637 of 1995 images), respectively. Conclusion: Deep learning with CNNs using a limited amount of training data, less than that required during physician training, achieved high diagnostic performance in the detection of MDE on MR images. (C) RNA, 2019	[Ohta, Yasutoshi; Yunaga, Hiroto; Kitao, Shinichiro] Tottori Univ, Fac Med, Dept Pathophysiol Therapeut Sci, Div Radiol, Yonago, Tottori 6838504, Japan; [Ohta, Yasutoshi; Fukuda, Tetsuya] Natl Cerebral & Cardiovasc Ctr, Dept Radiol, Suita, Osaka, Japan; [Ogawa, Toshihide] Kurashiki Heisei Hosp, Dept Radiol, Kurashiki, Okayama, Japan	Tottori University; National Cerebral & Cardiovascular Center - Japan	Ohta, Y (corresponding author), Tottori Univ, Fac Med, Dept Pathophysiol Therapeut Sci, Div Radiol, Yonago, Tottori 6838504, Japan.; Ohta, Y (corresponding author), Natl Cerebral & Cardiovasc Ctr, Dept Radiol, Suita, Osaka, Japan.	ohtayasu@gmail.com						Agresti A, 1998, AM STAT, V52, P119, DOI 10.2307/2685469; Bar Y, 2015, PROC SPIE, V9414, DOI 10.1117/12.2083124; Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585; Hajian-Tilaki K, 2014, J BIOMED INFORM, V48, P193, DOI 10.1016/j.jbi.2014.02.013; Hastie T, 2009, ELEMENTS STAT LEARNI; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Hua KL, 2015, ONCOTARGETS THER, V8, P2015, DOI 10.2147/OTT.S80733; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Kanda Y, 2013, BONE MARROW TRANSPL, V48, P452, DOI 10.1038/bmt.2012.244; Kramer CM, 2015, J AM COLL CARDIOL, V65, P1822, DOI 10.1016/j.jacc.2015.03.022; Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386; Kundel HL, 2003, RADIOLOGY, V228, P303, DOI 10.1148/radiol.2282011860; Lakhani P, 2017, RADIOLOGY, V284, P574, DOI 10.1148/radiol.2017162326; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Larson DB, 2018, RADIOLOGY, V287, P313, DOI 10.1148/radiol.2017170236; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Mahrholdt H, 2005, EUR HEART J, V26, P1461, DOI 10.1093/eurheartj/ehi258; Marra MP, 2011, EUR HEART J, V32, P284, DOI 10.1093/eurheartj/ehq409; Obuchowski NA, 2003, RADIOLOGY, V229, P3, DOI 10.1148/radiol.2291010898; Schulz-Menger J, 2013, J CARDIOVASC MAGN R, V15, DOI 10.1186/1532-429X-15-35; Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Wu R, PREPRINTS; Yasaka K, 2018, RADIOLOGY, V286, P899, DOI 10.1148/radiol.2017170706	25	3	3	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2019	1	3							e180061	10.11488/ryai.2019180061	http://dx.doi.org/10.11488/ryai.2019180061			7	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CN	33937791				2022-12-18	WOS:000826290100001
J	Bridge, CP; Best, TD; Wrobel, MM; Marquardt, JP; Magudia, K; Javidan, C; Chung, JH; Kalpathy-Cramer, J; Andriole, KP; Fintelmann, FJ				Bridge, Christopher P.; Best, Till D.; Wrobel, Maria M.; Marquardt, J. Peter; Magudia, Kirti; Javidan, Cylen; Chung, Jonathan H.; Kalpathy-Cramer, Jayashree; Andriole, Katherine P.; Fintelmann, Florian J.			A Fully Automated Deep Learning Pipeline for Multi-Vertebral Level Quantification and Characterization of Muscle and Adipose Tissue on Chest CT Scans	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							SKELETAL-MUSCLE	Body composition on chest CT scans encompasses a set of important imaging biomarkers. This study developed and validated a fully automated analysis pipeline for multi-vertebral level assessment of muscle and adipose tissue on routine chest CT scans. This study retrospectively trained two convolutional neural networks on 629 chest CT scans from 629 patients (55% women; mean age, 67 years 6 10 [standard deviation]) obtained between 2014 and 2017 prior to lobectomy for primary lung cancer at three institutions. A slice-selection network was developed to identify an axial image at the level of the fifth, eighth, and 10th thoracic vertebral bodies. A segmentation network (U-Net) was trained to segment muscle and adipose tissue on an axial image. Radiologist-guided manual-level selection and segmentation generated ground truth. The authors then assessed the predictive performance of their approach for cross-sectional area (CSA) (in centimeters squared) and attenuation (in Hounsfield units) on an independent test set. For the pipeline, median absolute error and intraclass correlation coefficients for both tissues were 3.6% (interquartile range, 1.3%-7.0%) and 0.959-0.998 for the CSA and 1.0 HU (interquartile range, 0.0-2.0 HU) and 0.95-0.99 for median attenuation. This study demonstrates accurate and reliable fully automated multi-vertebral level quantification and characterization of muscle and adipose tissue on routine chest CT scans. (C)RSNA, 2022	[Bridge, Christopher P.; Kalpathy-Cramer, Jayashree; Andriole, Katherine P.] Massachusetts Gen Hosp & Brigham & Womens Hosp Ct, 55 Fruit St, Boston, MA 02114 USA; [Bridge, Christopher P.; Andriole, Katherine P.] Massachusetts Gen Hosp, Martinos Ctr Biomed Imaging, Dept Radiol, 55 Fruit St, Boston, MA 02114 USA; [Best, Till D.; Wrobel, Maria M.; Marquardt, J. Peter; Fintelmann, Florian J.] Massachusetts Gen Hosp, Div Thorac Imaging & Intervent, Dept Radiol, 55 Fruit St, Boston, MA 02114 USA; [Andriole, Katherine P.] Brigham & Womens Hosp, Dept Radiol, 55 Fruit St, Boston, MA 02114 USA; [Best, Till D.] Charite Univ Med Berlin, Berlin, Germany; [Best, Till D.] Free Univ Berlin, Berlin, Germany; [Best, Till D.] Humboldt Univ, Dept Radiol, Berlin, Germany; [Best, Till D.] Berlin Inst Hlth, Dept Radiol, Berlin, Germany; [Wrobel, Maria M.] Ludwig Maximilians Univ Munchen, Dept Radiol, Munich, Germany; [Magudia, Kirti] Univ Calif San Francisco, Dept Radiol & Biomed Imaging, San Francisco, CA 94143 USA; [Javidan, Cylen] Washington Univ, Sch Med, Mallinckrodt Inst Radiol, St Louis, MO USA; [Chung, Jonathan H.] Univ Chicago, Dept Med, Chicago, IL 60637 USA; [Chung, Jonathan H.] Univ Chicago, Dept Radiol, Chicago, IL 60637 USA	Harvard University; Massachusetts General Hospital; Harvard University; Massachusetts General Hospital; Harvard University; Brigham & Women's Hospital; Free University of Berlin; Humboldt University of Berlin; Charite Universitatsmedizin Berlin; Free University of Berlin; Humboldt University of Berlin; Berlin Institute of Health; University of Munich; University of California System; University of California San Francisco; Washington University (WUSTL); University of Chicago; University of Chicago	Fintelmann, FJ (corresponding author), Massachusetts Gen Hosp, Div Thorac Imaging & Intervent, Dept Radiol, 55 Fruit St, Boston, MA 02114 USA.	fintelmann@mgh.harvard.edu		Marquardt, Jan Peter/0000-0002-5596-1357; Magudia, Kirti/0000-0001-7037-433X; Kalpathy-Cramer, Jayashree/0000-0001-8906-9618	American Roentgen Ray Society scholarship grant	American Roentgen Ray Society scholarship grant	F.J.F. supported by American Roentgen Ray Society scholarship grant.	Best TD, 2022, ANN SURG, V275, pE708, DOI 10.1097/SLA.0000000000004040; Bridge CP, 2018, LECT NOTES COMPUT SC, V11041, P204, DOI 10.1007/978-3-030-01201-4_22; Castiglione J., 2021, RADIOL-ARTIF INTELL, V3, DOI DOI 10.1148/RYAI.2021200130; Cruz-Jentoft AJ, 2019, AGE AGEING, V48, P16, DOI 10.1093/ageing/afy169; Fearon K, 2011, LANCET ONCOL, V12, P489, DOI 10.1016/S1470-2045(10)70218-7; Fedorov A, 2012, MAGN RESON IMAGING, V30, P1323, DOI 10.1016/j.mri.2012.05.001; Fuchs G, 2018, J CRIT CARE, V44, P117, DOI 10.1016/j.jcrc.2017.10.033; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Lenchik L, 2021, J GERONTOL A-BIOL, V76, P277, DOI 10.1093/gerona/glaa141; Magudia K, 2021, RADIOLOGY, V298, P319, DOI 10.1148/radiol.2020201640; Martin L, 2013, J CLIN ONCOL, V31, P1539, DOI 10.1200/JCO.2012.45.2722; Pickhardt PJ, 2020, LANCET DIGIT HEALTH, V2, pE192, DOI 10.1016/S2589-7500(20)30025-X; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Shen W, 2004, J APPL PHYSIOL, V97, P2333, DOI 10.1152/japplphysiol.00744.2004; Shen W, 2004, AM J CLIN NUTR, V80, P271, DOI 10.1093/ajcn/80.2.271; Troschel AS, 2021, AM J ROENTGENOL, V217, P177, DOI 10.2214/AJR.20.23280; Troschel AS, 2020, J THORAC IMAG, V35, P91, DOI 10.1097/RTI.0000000000000428; Vallat R., 2018, J OPEN SOURCE SOFTW, V3, P1026, DOI [10.21105/joss.01026, DOI 10.21105/JOSS.01026]; van Seventer E, 2021, J NATL COMPR CANC NE, V19, P319, DOI 10.6004/jnccn.2020.7618; Weston AD, 2019, RADIOLOGY, V290, P669, DOI 10.1148/radiol.2018181432	20	2	2	4	4	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2022	4	1							e210080	10.1148/ryai.210080	http://dx.doi.org/10.1148/ryai.210080			7	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9WA	35146434	Green Published			2022-12-18	WOS:000826917400007
J	Hirsch, L; Huang, Y; Luo, SJ; Saccarelli, CR; Lo Gullo, R; Naranjo, ID; Bitencourt, AGV; Onishi, N; Ko, ES; Leithner, D; Avendano, D; Eskreis-Winkler, S; Hughes, M; Martinez, DF; Pinker, K; Juluru, K; El-Rowmeim, AE; Elnajjar, P; Morris, EA; Makse, HA; Parra, LC; Sutton, EJ				Hirsch, Lukas; Huang, Yu; Luo, Shaojun; Saccarelli, Carolina Rossi; Lo Gullo, Roberto; Naranjo, Isaac Daimiel; Bitencourt, Almir G., V; Onishi, Natsuko; Ko, Eun Sook; Leithner, Doris; Avendano, Daly; Eskreis-Winkler, Sarah; Hughes, Mary; Martinez, Danny F.; Pinker, Katja; Juluru, Krishna; El-Rowmeim, Amin E.; Elnajjar, Pierre; Morris, Elizabeth A.; Makse, Hernan A.; Parra, Lucas C.; Sutton, Elizabeth J.			Radiologist-level Performance by Using Deep Learning for Segmentation of Breast Cancers on MRI Scans	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						MRI; Breast; Segmentation; Supervised Learning; Convolutional Neural Network (CNN); Deep Learning Algorithms; Machine Learning Algorithms	TUMOR VOLUME; MAMMOGRAPHY; LESIONS; ENHANCEMENT; IMAGES	Purpose: To develop a deep network architecture that would achieve fully automated radiologist-level segmentation of cancers at breast MRI. Materials and Methods: In this retrospective study, 38 229 examinations (composed of 64 063 individual breast scans from 14 475 patients) were performed in female patients (age range, 12-94 years; mean age, 52 years 6 10 [standard deviation]) who presented between 2002 and 2014 at a single clinical site. A total of 2555 breast cancers were selected that had been segmented on two-dimensional (2D) images by radiologists, as well as 60 108 benign breasts that served as examples of noncancerous tissue; all these were used for model training. For testing, an additional 250 breast cancers were segmented independently on 2D images by four radiologists. Authors selected among several three-dimensional (3D) deep convolutional neural network architectures, input modalities, and harmonization methods. The outcome measure was the Dice score for 2D segmentation, which was compared between the network and radiologists by using the Wilcoxon signed rank test and the two one-sided test procedure. Results: The highest-performing network on the training set was a 3D U-Net with dynamic contrast-enhanced MRI as input and with intensity normalized for each examination. In the test set, the median Dice score of this network was 0.77 (interquartile range, 0.26). The performance of the network was equivalent to that of the radiologists (two one-sided test procedures with radiologist performance of 0.69-0.84 as equivalence bounds, P < .001 for both; n = 250). Conclusion: When trained on a sufficiently large dataset, the developed 3D U-Net performed as well as fellowship-trained radiologists in detailed 2D segmentation of breast cancers at routine clinical MRI. Published under a CC BY 4.0 license.	[Hirsch, Lukas; Huang, Yu; Parra, Lucas C.] CUNY City Coll, Dept Biomed Engn, 160 Convent Ave, New York, NY 10031 USA; [Luo, Shaojun; Makse, Hernan A.] CUNY City Coll, Benjamin Levich Inst, 160 Convent Ave, New York, NY 10031 USA; [Luo, Shaojun; Makse, Hernan A.] CUNY City Coll, Dept Phys, 160 Convent Ave, New York, NY 10031 USA; [Huang, Yu; Saccarelli, Carolina Rossi; Lo Gullo, Roberto; Naranjo, Isaac Daimiel; Bitencourt, Almir G., V; Onishi, Natsuko; Ko, Eun Sook; Leithner, Doris; Avendano, Daly; Eskreis-Winkler, Sarah; Hughes, Mary; Martinez, Danny F.; Pinker, Katja; Juluru, Krishna; El-Rowmeim, Amin E.; Elnajjar, Pierre; Morris, Elizabeth A.; Sutton, Elizabeth J.] Mem Sloan Kettering Canc Ctr, Dept Radiol, New York, NY 10065 USA; [Bitencourt, Almir G., V] AC Camargo Canc Ctr, Dept Imaging, Sao Paulo, Brazil; [Onishi, Natsuko] Univ Calif San Francisco, Dept Radiol, San Francisco, CA USA; [Ko, Eun Sook] Sungkyunkwan Univ, Sch Med, Samsung Med Ctr, Dept Radiol, Seoul, South Korea; [Avendano, Daly] ITFSM Monterry, Breast Canc Ctr TecSalud, Dept Breast Imaging, Monterrey, Mexico	City University of New York (CUNY) System; City College of New York (CUNY); City University of New York (CUNY) System; City College of New York (CUNY); City University of New York (CUNY) System; City College of New York (CUNY); Memorial Sloan Kettering Cancer Center; A.C.Camargo Cancer Center; University of California System; University of California San Francisco; Sungkyunkwan University (SKKU); Samsung Medical Center; Tecnologico de Monterrey	Parra, LC (corresponding author), CUNY City Coll, Dept Biomed Engn, 160 Convent Ave, New York, NY 10031 USA.	parra@ccny.cuny.edu		Daimiel Naranjo, Isaac/0000-0002-4878-1710; Hirsch, Lukas/0000-0003-3173-9142; Avendano, Daly/0000-0002-8433-7211; Huang, Yu/0000-0003-4178-0739; Ko, Eun Sook/0000-0002-0399-7956; Onishi, Natsuko/0000-0003-4495-9187; Eskreis-Winkler, Sarah/0000-0003-2427-3532	National Institutes of Health [NIH P30CA008748, NIH R01MH111896, NIH R01EB022720, R01 EB028157, NIH-NCI R01CA247910]; National Science Foundation [NSF DMR1945909, NSF DRL-1660548]; Alfonso Martin Escudero Foundation; RSNA Research and Education Foundation [RF1905]; Breast Cancer Research Foundation	National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); National Science Foundation(National Science Foundation (NSF)); Alfonso Martin Escudero Foundation; RSNA Research and Education Foundation; Breast Cancer Research Foundation	Study supported in part by the National Institutes of Health and National Science Foundation (NIH P30CA008748, NIH R01MH111896, NIH R01EB022720, R01 EB028157, NSF DMR1945909, NSF DRL-1660548, NIH-NCI R01CA247910); I.D.N. supported by the Alfonso Martin Escudero Foundation; S.E.W. supported by RSNA Research and Education Foundation (RF1905); supported by the Breast Cancer Research Foundation.	Aitken A, ARXIV 170702937; [Anonymous], 2015, P 3 MICCAI WORKSHOP; Becker AS, 2017, INVEST RADIOL, V52, P434, DOI 10.1097/RLI.0000000000000358; BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7; Bhooshan N, 2010, RADIOLOGY, V254, P680, DOI 10.1148/radiol.09090838; Chen MJ, 2018, LECT NOTES COMPUT SC, V11307, P358, DOI 10.1007/978-3-030-04239-4_32; Chen WJ, 2006, ACAD RADIOL, V13, P63, DOI 10.1016/j.acra.2005.08.035; Chiarelli AM, 2014, J CLIN ONCOL, V32, P2224, DOI 10.1200/JCO.2013.52.8331; de Moor T, ARXIV 180206865; Dhungel Neeraj, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P106, DOI 10.1007/978-3-319-46723-8_13; Dhungel N, 2015, 2015 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P160; DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409; Dontchos BN, 2015, RADIOLOGY, V276, P371, DOI 10.1148/radiol.2015142304; Drukker K, 2018, CANCER IMAGING, V18, DOI 10.1186/s40644-018-0145-9; El Adoui M, 2019, COMPUTERS, V8, DOI 10.3390/computers8030052; Hirsch L, ARXIV 190510010; Hylton NM, 2016, RADIOLOGY, V279, P44, DOI 10.1148/radiol.2015150013; Kallenberg M, 2016, IEEE T MED IMAGING, V35, P1322, DOI 10.1109/TMI.2016.2532122; Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004; Kooi T, 2017, MED IMAGE ANAL, V35, P303, DOI 10.1016/j.media.2016.07.007; Lehman CD, 2007, RADIOLOGY, V244, P381, DOI 10.1148/radiol.2442060461; Li KL, 2007, MAGN RESON MED, V58, P572, DOI 10.1002/mrm.21361; Maicas G, 2017, I S BIOMED IMAGING, P305, DOI 10.1109/ISBI.2017.7950525; Marinovich ML, 2013, JNCI-J NATL CANCER I, V105, P321, DOI 10.1093/jnci/djs528; McKinney SM, 2020, NATURE, V577, P89, DOI 10.1038/s41586-019-1799-6; Parekh VS, 2020, MED PHYS, V47, P75, DOI 10.1002/mp.13849; Ribli D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22437-z; Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284; Spuhler KD, 2019, MAGN RESON MED, V82, P786, DOI 10.1002/mrm.27758; Vargha A, 2000, J EDUC BEHAV STAT, V25, P101, DOI 10.3102/10769986025002101; Walker E, 2011, J GEN INTERN MED, V26, P192, DOI 10.1007/s11606-010-1513-8; Warner E, 2004, JAMA-J AM MED ASSOC, V292, P1317, DOI 10.1001/jama.292.11.1317; Wu N, 2020, IEEE T MED IMAGING, V39, P1184, DOI 10.1109/TMI.2019.2945514; Zhang J, 2019, IEEE T MED IMAGING, V38, P435, DOI 10.1109/TMI.2018.2865671; Zhu W, ARXIV 161205968; Zou KH, 2004, ACAD RADIOL, V11, P178, DOI 10.1016/S1076-6332(03)00671-8	36	2	2	1	5	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2022	4	1							e200231	10.1148/ryai.200231	http://dx.doi.org/10.1148/ryai.200231			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9WA	35146431	Green Published, Green Submitted			2022-12-18	WOS:000826917400001
J	Tushar, FI; D'Anniballe, VM; Hou, R; Mazurowski, MA; Fu, WY; Samei, E; Rubin, GD; Lo, JY				Tushar, Fakrul Islam; D'Anniballe, Vincent M.; Hou, Rui; Mazurowski, Maciej A.; Fu, Wanyi; Samei, Ehsan; Rubin, Geoffrey D.; Lo, Joseph Y.			Classification of Multiple Diseases on Body CT Scans Using Weakly Supervised Deep Learning	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							CANCER	Purpose: To design multidisease classifiers for body CT scans for three different organ systems using automatically extracted labels from radiology text reports. Materials and Methods: This retrospective study included a total of 12 092 patients (mean age, 57 years 6 18 [standard deviation]; 6172 women) for model development and testing. Rule-based algorithms were used to extract 19225 disease labels from 13 667 body CT scans performed between 2012 and 2017. Using a three-dimensional DenseVNet, three organ systems were segmented: lungs and pleura, liver and gallbladder, and kidneys and ureters. For each organ system, a three-dimensional convolutional neural network classified each as no apparent disease or for the presence of four common diseases, for a total of 15 different labels across all three models. Testing was performed on a subset of 2158 CT volumes relative to 2875 manually derived reference labels from 2133 patients (mean age, 58 years 6 18; 1079 women). Performance was reported as area under the receiver operating characteristic curve (AUC), with 95% CIs calculated using the DeLong method. Results: Manual validation of the extracted labels confirmed 91%-99% accuracy across the 15 different labels. AUCs for lungs and pleura labels were as follows: atelectasis, 0.77 (95% CI: 0.74, 0.81); nodule, 0.65 (95% CI: 0.61, 0.69); emphysema, 0.89 (95% CI: 0.86, 0.92); effusion, 0.97 (95% CI: 0.96, 0.98); and no apparent disease, 0.89 (95% CI: 0.87, 0.91). AUCs for liver and gallbladder were as follows: hepatobiliary calcification, 0.62 (95% CI: 0.56, 0.67); lesion, 0.73 (95% CI: 0.69, 0.77); dilation, 0.87 (95% CI: 0.84, 0.90); fatty, 0.89 (95% CI: 0.86, 0.92); and no apparent disease, 0.82 (95% CI: 0.78, 0.85). AUCs for kidneys and ureters were as follows: stone, 0.83 (95% CI: 0.79, 0.87); atrophy, 0.92 (95% CI: 0.89, 0.94); lesion, 0.68 (95% CI: 0.64, 0.72); cyst, 0.70 (95% CI: 0.66, 0.73); and no apparent disease, 0.79 (95% CI: 0.75, 0.83). Conclusion: Weakly supervised deep learning models were able to classify diverse diseases in multiple organ systems from CT scans. (C)RSNA, 2022	[Tushar, Fakrul Islam; Hou, Rui; Mazurowski, Maciej A.; Fu, Wanyi; Samei, Ehsan; Lo, Joseph Y.] Duke Univ, Ctr Virtual Imaging Trials, Dept Radiol, Carl E Ravin Adv Imaging Labs, 2424 Erwin Rd,Studio 302, Durham, NC 27705 USA; [Tushar, Fakrul Islam; Hou, Rui; Mazurowski, Maciej A.; Fu, Wanyi; Samei, Ehsan; Lo, Joseph Y.] Duke Univ, Dept Elect & Comp Engn, 2424 Erwin Rd,Studio 302, Durham, NC 27705 USA; [D'Anniballe, Vincent M.] Duke Univ, Dept Radiol, Durham, NC 27710 USA; [Rubin, Geoffrey D.] Univ Arizona, Dept Med Imaging, Tucson, AZ USA	Duke University; Duke University; Duke University; University of Arizona	Lo, JY (corresponding author), Duke Univ, Ctr Virtual Imaging Trials, Dept Radiol, Carl E Ravin Adv Imaging Labs, 2424 Erwin Rd,Studio 302, Durham, NC 27705 USA.; Lo, JY (corresponding author), Duke Univ, Dept Elect & Comp Engn, 2424 Erwin Rd,Studio 302, Durham, NC 27705 USA.	joseph.lo@duke.edu		D'Anniballe, Vincent/0000-0002-8536-633X; Samei, Ehsan/0000-0001-7451-3309; TUSHAR, FAKRUL ISLAM/0000-0001-7180-563X; Hou, Rui/0000-0002-0348-8772	Duke Cancer Institute as part of the NIH/NCI [P30 CA014236]; Center for Virtual Imaging Trials NIH/NIBIB [P41-EB028744]; GPU equipment grant from NVIDIA	Duke Cancer Institute as part of the NIH/NCI; Center for Virtual Imaging Trials NIH/NIBIB; GPU equipment grant from NVIDIA	Supported in part by developmental funds from the Duke Cancer Institute as part of the NIH/NCI P30 CA014236 Cancer Center Support Grant, the Center for Virtual Imaging Trials NIH/NIBIB P41-EB028744, and a GPU equipment grant from NVIDIA.	Banerjee I, 2019, ARTIF INTELL MED, V97, P79, DOI 10.1016/j.artmed.2018.11.004; Brady Adrian, 2012, Ulster Med J, V81, P3; Ciompi F, 2017, SCI REP-UK, V7, DOI 10.1038/srep46479; Ding Y, 2019, RADIOLOGY, V290, P456, DOI 10.1148/radiol.2018180958; Draelos RL, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101857; Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056; Eyuboglu S, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-22018-1; Faryna K, 2020, PROC SPIE, V11314, DOI 10.1117/12.2551370; Gibson E, 2018, IEEE T MED IMAGING, V37, P1822, DOI 10.1109/TMI.2018.2806309; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Irvin J, 2019, AAAI CONF ARTIF INTE, P590; Johnson AEW, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0322-0; Kim HE, 2020, LANCET DIGIT HEALTH, V2, pE138, DOI 10.1016/S2589-7500(20)30003-0; Lin HT, 2019, ECLINICALMEDICINE, V9, P52, DOI 10.1016/j.eclinm.2019.03.001; Mahajan D, 2018, LECT NOTES COMPUT SC, V11206, P185, DOI 10.1007/978-3-030-01216-8_12; Mori Y, 2018, ANN INTERN MED, V169, P357, DOI 10.7326/M18-0249; Pollack BL, 2021, RADIOL ARTIF INTELL, V3; Robin X, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-77; Schelb P, 2019, RADIOLOGY, V293, P607, DOI 10.1148/radiol.2019190938; Segars WP, 2013, MED PHYS, V40, DOI 10.1118/1.4794178; Shin HC, 2017, ELS MIC SOC BOOK SER, P405, DOI 10.1016/B978-0-12-810408-8.00023-7; Steinkamp JM, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180052; Tang RX, 2019, PROC SPIE, V10950, DOI 10.1117/12.2513576; Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369; Willemink MJ, 2020, RADIOLOGY, V295, P4, DOI 10.1148/radiol.2020192224; Yala A, 2019, RADIOLOGY, V293, P38, DOI 10.1148/radiol.2019182908; Yan K, 2021, IEEE T MED IMAGING, V40, P2759, DOI 10.1109/TMI.2020.3047598; Yan K, 2019, ADV COMPUT VIS PATT, P413, DOI 10.1007/978-3-030-13969-8_20; Yan K, 2019, PROC CVPR IEEE, P8515, DOI 10.1109/CVPR.2019.00872; Yan K, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.3.036501	30	2	2	1	2	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2022	4	1							e210026	10.1148/ryai.210026	http://dx.doi.org/10.1148/ryai.210026			11	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9WA	35146433	Green Submitted, Green Published			2022-12-18	WOS:000826917400006
J	Zaman, S; Petri, C; Vimalesvaran, K; Howard, J; Bharath, A; Francis, D; Peters, N; Cole, GD; Linton, N				Zaman, Sameer; Petri, Camille; Vimalesvaran, Kavitha; Howard, James; Bharath, Anil; Francis, Darrel; Peters, Nicholas; Cole, Graham D.; Linton, Nick			Automatic Diagnosis Labeling of Cardiovascular MRI by Using Semisupervised Natural Language Processing of Text Reports	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							PROGNOSTIC VALUE; CMR	Purpose: To assess whether the semisupervised natural language processing (NLP) of text from clinical radiology reports could provide useful automated diagnosis categorization for ground truth labeling to overcome manual labeling bottlenecks in the machine learning pipeline. Materials and Methods: In this retrospective study, 1503 text cardiac MRI reports from 2016 to 2019 were manually annotated for five diagnoses by clinicians: normal, dilated cardiomyopathy (DCM), hypertrophic cardiomyopathy, myocardial infarction (MI), and myocarditis. A semisupervised method that uses bidirectional encoder representations from transformers (BERT) pretrained on 1.14 million scientific publications was fine-tuned by using the manually extracted labels, with a report dataset split into groups of 801 for training, 302 for validation, and 400 for testing. The model's performance was compared with two traditional NLP models: a rulebased model and a support vector machine (SVM) model. The models' F1 scores and receiver operating characteristic curves were used to analyze performance. Results: After 15 epochs, the F1 scores on the test set of 400 reports were as follows: normal, 84%; DCM, 79%; hypertrophic cardiomyopathy, 86%; MI, 91%; and myocarditis, 86%. The pooled F1 score and area under the receiver operating curve were 86% and 0.96, respectively. On the same test set, the BERT model had a higher performance than the rule-based model (F1 score, 42%) and SVM model (F1 score, 82%). Diagnosis categories classified by using the BERT model performed the labeling of 1000 MR images in 0.2 second. Conclusion: The developed model used labels extracted from radiology reports to provide automated diagnosis categorization of MR images with a high level of performance. (C)RSNA, 2021	[Zaman, Sameer; Petri, Camille; Vimalesvaran, Kavitha; Howard, James; Francis, Darrel; Peters, Nicholas; Cole, Graham D.] Imperial Coll London, Hammersmith Hosp, Natl Heart & Lung Inst, Du Cane Rd,Second Floor B Block, London W12 0HS, England; [Howard, James; Francis, Darrel; Peters, Nicholas; Cole, Graham D.; Linton, Nick] Imperial Coll Healthcare Natl Hlth Serv Trust, London, England; [Bharath, Anil; Linton, Nick] Imperial Coll London, Dept Bioengn, London, England	Imperial College London; Imperial College London; Imperial College London	Cole, GD (corresponding author), Imperial Coll London, Hammersmith Hosp, Natl Heart & Lung Inst, Du Cane Rd,Second Floor B Block, London W12 0HS, England.; Cole, GD (corresponding author), Imperial Coll Healthcare Natl Hlth Serv Trust, London, England.	g.cole@imperial.ac.uk		Zaman, Sameer/0000-0002-1467-8176; Cole, Graham/0000-0002-3157-0335; Vimalesvaran, Kavitha/0000-0003-2236-7279	UK Research and Innovation Centre for Doctoral Training in Artificial Intelligence for Healthcare [EP/S023283/1]	UK Research and Innovation Centre for Doctoral Training in Artificial Intelligence for Healthcare	S.Z. and C.P. supported by the UK Research and Innovation Centre for Doctoral Training in Artificial Intelligence for Healthcare (grant EP/S023283/1).	Alammar J., VISUALIZING MACHINE; Banerjee I, 2019, ARTIF INTELL MED, V97, P79, DOI 10.1016/j.artmed.2018.11.004; Becker MAJ, 2018, JACC-CARDIOVASC IMAG, V11, P1274, DOI 10.1016/j.jcmg.2018.03.006; Beltagy I, ARXIV 190310676; Bressem KK, 2020, BIOINFORMATICS, V36, P5255, DOI 10.1093/bioinformatics/btaa668; Carrodeguas E, 2019, J AM COLL RADIOL, V16, P336, DOI 10.1016/j.jacr.2018.10.020; Devlin J, ARXIV 181004805; Fiok K, ARXIV 210407225; Howard JP, 2021, INT J CARDIOVAS IMAG, V37, P1033, DOI 10.1007/s10554-020-02050-w; Juneau D, 2020, INT J CARDIOVAS IMAG, V36, P2199, DOI 10.1007/s10554-020-01923-4; Klang E, 2018, J THORAC DIS, V10, P1325, DOI 10.21037/jtd.2018.02.76; Lee C, 2019, AM J ROENTGENOL, V212, P734, DOI 10.2214/AJR.18.19869; Liu HL, 2021, J MED INTERNET RES, V23, DOI 10.2196/19689; Loshchilov I, ARXIV 171105101; Martini N, 2020, J CARDIOVASC MAGN R, V22, DOI 10.1186/s12968-020-00690-4; Paszke A, ARXIV 191201703; Raina S, 2016, JACC-CARDIOVASC IMAG, V9, P1267, DOI 10.1016/j.jcmg.2016.01.036; Sennrich R, ARXIV 150807909; Singh PK, 2020, P ICRIC 2019 REC INN; Sorin V, 2020, J AM COLL RADIOL, V17, P639, DOI 10.1016/j.jacr.2019.12.026; van den Hout WB, 2003, MED DECIS MAKING, V23, P160, DOI 10.1177/0272989X03251246; Van Rossum G, 2009, PYTHON 3 REFERENCE M; Wang YS, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-018-0723-6; Weng Z, 2016, JACC-CARDIOVASC IMAG, V9, P1392, DOI 10.1016/j.jcmg.2016.02.031; Wolf T, ARXIV 191003771; Ye Y, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174970	26	2	2	1	2	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2022	4	1							e210085	10.1148/ryai.210085	http://dx.doi.org/10.1148/ryai.210085			8	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9WA	35146435	Green Published			2022-12-18	WOS:000826917400008
J	Gupta, K; Sekhar, N; Vigneault, DM; Scott, AR; Colvert, B; Craine, A; Raghavan, A; Contijoch, FJ				Gupta, Kunal; Sekhar, Nitesh; Vigneault, Davis M.; Scott, Anderson R.; Colvert, Brendan; Craine, Amanda; Raghavan, Adhithi; Contijoch, Francisco J.			Octree Representation Improves Data Fidelity of Cardiac CT Images and Convolutional Neural Network Semantic Segmentation of Left Atrial and Ventricular Chambers	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						CT; Cardiac; Segmentation; Supervised Learning; Convolutional Neural Network (CNN); Deep Learning Algorithms; Machine Learning Algorithms		Purpose: To assess whether octree representation and octree-based convolutional neural networks (CNNs) improve segmentation accuracy of three-dimensional images. Materials and Methods: Cardiac CT angiographic examinations from 100 patients (mean age, 67 years 6 17 [standard deviation]; 60 men) performed between June 2012 and June 2018 with semantic segmentations of the left ventricular (LV) and left atrial (LA) blood pools at the end-diastolic and end-systolic cardiac phases were retrospectively evaluated. Image quality (root mean square error [RMSE]) and segmentation fidelity (global Dice and border Dice coefficients) metrics of the octree representation were compared with spatial downsampling for a range of memory footprints. Fivefold cross-validation was used to train an octree-based CNN and CNNs with spatial downsampling at four levels of image compression or spatial downsampling. The semantic segmentation performance of octree-based CNN (OctNet) was compared with the performance of U-Nets with spatial downsampling. Results: Octrees provided high image and segmentation fidelity (median RMSE, 1.34 HU; LV Dice coefficient, 0.970; LV border Dice coefficient, 0.843) with a reduced memory footprint (87.5% reduction). Spatial downsampling to the same memory footprint had lower data fidelity (median RMSE, 12.96 HU; LV Dice coefficient, 0.852; LV border Dice coefficient, 0.310). OctNet segmentation improved the border segmentation Dice coefficient (LV, 0.612; LA, 0.636) compared with the highest performance among U-Nets with spatial downsampling (Dice coefficients: LV, 0.579; LA, 0.592). Conclusion: Octree-based representations can reduce the memory footprint and improve segmentation border accuracy. (C) RSNA, 2021	[Gupta, Kunal; Sekhar, Nitesh] Univ Calif San Diego, Dept Comp Sci Engn, 9500 Gilman Dr,MC 0412, La Jolla, CA 92093 USA; [Vigneault, Davis M.; Scott, Anderson R.; Colvert, Brendan; Craine, Amanda; Raghavan, Adhithi; Contijoch, Francisco J.] Univ Calif San Diego, Dept Bioengn, 9500 Gilman Dr,MC 0412, La Jolla, CA 92093 USA; [Contijoch, Francisco J.] Univ Calif San Diego, Dept Radiol, 9500 Gilman Dr,MC 0412, La Jolla, CA 92093 USA; [Vigneault, Davis M.] Scripps Mercy Hosp, Dept Internal Med, San Diego, CA USA	University of California System; University of California San Diego; University of California System; University of California San Diego; University of California System; University of California San Diego	Contijoch, FJ (corresponding author), Univ Calif San Diego, Dept Bioengn, 9500 Gilman Dr,MC 0412, La Jolla, CA 92093 USA.; Contijoch, FJ (corresponding author), Univ Calif San Diego, Dept Radiol, 9500 Gilman Dr,MC 0412, La Jolla, CA 92093 USA.	fcontijoch@ucsd.edu	Contijoch, Francisco/H-6279-2019; Vigneault, Davis/AAX-9750-2020	Contijoch, Francisco/0000-0001-9616-3274; Vigneault, Davis/0000-0003-3798-9812; Craine, Amanda/0000-0002-0595-8061; Gupta, Kunal/0000-0001-8628-2202; Scott, Anderson/0000-0003-2825-7951	National Institutes of Health [NHLBI K01 HL143113-01, R01 HL144678-01]	National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	F.J.C. was supported by the National Institutes of Health (grants NHLBI K01 HL143113-01 and R01 HL144678-01).	Chen C, 2020, FRONT CARDIOVASC MED, V7, DOI 10.3389/fcvm.2020.00025; Chen Zhennong, 2021, Eur Heart J Digit Health, V2, P311, DOI 10.1093/ehjdh/ztab033; Contijoch FJ, 2017, INT J CARDIOL, V249, P461, DOI 10.1016/j.ijcard.2017.08.040; Desai AD, ARXIV 190201977; Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004; Lu HY, 2015, PROC CVPR IEEE, P806, DOI 10.1109/CVPR.2015.7298681; McVeigh ER, 2018, J CARDIOVASC COMPUT, V12, P372, DOI 10.1016/j.jcct.2018.05.002; Meagher D. J., 1982, Proceedings of PRIP 82. IEEE Computer Society Conference on Pattern Recognition and Image Processing, P473; Pourmorteza A, 2018, INT J CARDIOVAS IMAG, V34, P1277, DOI 10.1007/s10554-018-1332-2; Pourmorteza A, 2016, INT J CARDIOVAS IMAG, V32, P817, DOI 10.1007/s10554-015-0831-7; Pourmorteza A, 2012, CIRC-CARDIOVASC IMAG, V5, P243, DOI 10.1161/CIRCIMAGING.111.970061; Qi CR, 2017, ADV NEUR IN, V30; Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16; Riegler G, 2017, PROC CVPR IEEE, P6620, DOI 10.1109/CVPR.2017.701; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Roth H.R., 2018, MED IMAGING TECHNOL, V36, P63; Vorontsov E, 2019, RADIOL ARTIF INTELL, V2; Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015; Zhou XR, 2017, PROC SPIE, V10133, DOI 10.1117/12.2254201; Zhou XR, 2016, LECT NOTES COMPUT SC, V10008, P111, DOI 10.1007/978-3-319-46976-8_12	20	2	2	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2021	3	6							e210036	10.1148/ryai.2021210036	http://dx.doi.org/10.1148/ryai.2021210036			8	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9UW	34870221	Green Published			2022-12-18	WOS:000826914400011
J	Jacobs, C; Setio, AAA; Scholten, ET; Gerke, PK; Bhattacharya, H; Hoesein, FAM; Brink, M; Ranschaert, E; de Jong, PA; Silva, M; Geurts, B; Chung, K; Schalekamp, S; Meersschaert, J; Devaraj, A; Pinsky, PF; Lam, SC; van Ginneken, B; Farahani, K				Jacobs, Colin; Setio, Arnaud A. A.; Scholten, Ernst T.; Gerke, Paul K.; Bhattacharya, Haimasree; Hoesein, Firdaus A. M.; Brink, Monique; Ranschaert, Erik; de Jong, Pim A.; Silva, Mario; Geurts, Bram; Chung, Kaman; Schalekamp, Steven; Meersschaert, Joke; Devaraj, Anand; Pinsky, Paul F.; Lam, Stephen C.; van Ginneken, Bram; Farahani, Keyvan			Deep Learning for Lung Cancer Detection on Screening CT Scans: Results of a Large-Scale Public Competition and an Observer Study with 11 Radiologists	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Lung; CT; Thorax; Screening; Oncology	PULMONARY NODULES	Purpose: To determine whether deep learning algorithms developed in a public competition could identify lung cancer on low-dose CT scans with a performance similar to that of radiologists. Materials and Methods: In this retrospective study, a dataset consisting of 300 patient scans was used for model assessment; 150 patient scans were from the competition set and 150 were from an independent dataset. Both test datasets contained 50 cancer-positive scans and 100 cancer-negative scans. The reference standard was set by histopathologic examination for cancer-positive scans and imaging follow-up for at least 2 years for cancer-negative scans. The test datasets were applied to the three top-performing algorithms from the Kaggle Data Science Bowl 2017 public competition: grt123, Julian de Wit and Daniel Hammack (JWDH), and Aidence. Model outputs were compared with an observer study of 11 radiologists that assessed the same test datasets. Each scan was scored on a continuous scale by both the deep learning algorithms and the radiologists. Performance was measured using multireader, multicase receiver operating characteristic analysis. Results: The area under the receiver operating characteristic curve (AUC) was 0.877 (95% CI: 0.842, 0.910) for grt123, 0.902 (95% CI: 0.871, 0.932) for JWDH, and 0.900 (95% CI: 0.870, 0.928) for Aidence. The average AUC of the radiologists was 0.917 (95% CI: 0.889, 0.945), which was significantly higher than grt123 (P =.02); however, no significant difference was found between the radiologists and JWDH (P =.29) or Aidence (P =.26). Conclusion: Deep learning algorithms developed in a public competition for lung cancer detection in low-dose CT scans reached performance close to that of radiologists. Supplemental material is available for this article. (C) RSNA, 2021.	[Jacobs, Colin; Setio, Arnaud A. A.; Scholten, Ernst T.; Gerke, Paul K.; Bhattacharya, Haimasree; Brink, Monique; Geurts, Bram; Schalekamp, Steven; van Ginneken, Bram] Radboud Univ Nijmegen, Med Ctr, Dept Radiol Nucl Med & Anat, Geert Grootepl 10, NL-6525 GA Nijmegen, Netherlands; [Setio, Arnaud A. A.] Siemens Healthineers, Dept Digital Technol & Innovat, Erlangen, Germany; [Hoesein, Firdaus A. M.; de Jong, Pim A.] Univ Med Ctr Utrecht, Dept Radiol, Utrecht, Netherlands; [Ranschaert, Erik] ETZ Elisabeth TweeSteden Ziekenhuis, Tilburg, Netherlands; [Silva, Mario] Univ Parma, Dept Med & Surg DiMeC, Sect Radiol, Parma, Italy; [Chung, Kaman; Schalekamp, Steven] Meander Med Ctr, Dept Radiol, Amersfoort, Netherlands; [Meersschaert, Joke] AZ Zeno, Dept Radiol, Knokke Heist, Belgium; [Devaraj, Anand] Royal Brompton Hosp, Dept Imaging, London, England; [Pinsky, Paul F.] NCI, Div Canc Prevent, NIH, Bethesda, MD 20892 USA; [Farahani, Keyvan] NCI, Ctr Biomed Informat & Informat Technol, NIH, Bethesda, MD 20892 USA; [Lam, Stephen C.] British Columbia Canc Agcy, Vancouver, BC, Canada; [Lam, Stephen C.] Univ British Columbia, Vancouver, BC, Canada; [van Ginneken, Bram] Fraunhofer MEVIS, Bremen, Germany	Radboud University Nijmegen; Siemens AG; Utrecht University; Utrecht University Medical Center; University of Parma; Meander Medisch Centrum; Royal Brompton Hospital; National Institutes of Health (NIH) - USA; NIH National Cancer Institute (NCI); National Institutes of Health (NIH) - USA; NIH National Cancer Institute (NCI); British Columbia Cancer Agency; University of British Columbia	Jacobs, C (corresponding author), Radboud Univ Nijmegen, Med Ctr, Dept Radiol Nucl Med & Anat, Geert Grootepl 10, NL-6525 GA Nijmegen, Netherlands.	colin.jacobs@radboudumc.nl	Jacobs, Colin/P-6938-2015; de Jong, Pim A/G-7220-2014; Silva, Mario/B-9509-2016; Ranschaert, Erik R./Q-4577-2016	Jacobs, Colin/0000-0003-1180-3805; Setio, Arnaud Arindra Adiyoso/0000-0002-5447-4434; de Jong, Pim A/0000-0003-4840-6854; Scholten, Ernst/0000-0002-1982-2763; Silva, Mario/0000-0002-2538-7032; Ranschaert, Erik R./0000-0001-9375-9750	MeVis Medical Solutions, Bremen, Germany	MeVis Medical Solutions, Bremen, Germany	Supported by a research grant of MeVis Medical Solutions, Bremen, Germany.	Aberle DR, 2011, NEW ENGL J MED, V365, P395, DOI 10.1056/NEJMoa1102873; Ardila D, 2019, NAT MED, V25, P954, DOI 10.1038/s41591-019-0447-x; Armato SG, 2011, MED PHYS, V38, P915, DOI 10.1118/1.3528204; Centers for Disease Control and Prevention,, CAG00439N CTR DIS CO; de Koning HJ, 2020, NEW ENGL J MED, V382, P503, DOI 10.1056/NEJMoa1911793; Gallas BD, 2009, COMMUN STAT-THEOR M, V38, P2586, DOI 10.1080/03610920802610084; Huang P, 2019, LANCET DIGIT HEALTH, V1, pE353, DOI 10.1016/S2589-7500(19)30159-1; Jacobs C, 2019, NAT REV CLIN ONCOL, V16, P532, DOI 10.1038/s41571-019-0248-7; Kauczor HU, 2020, EUR RESPIR J, V55, DOI [10.1183/13993003.00506-2019, 10.1007/s00330-020-06727-7]; Kauczor HU, 2015, EUR RESPIR J, V46, P28, DOI 10.1183/09031936.00033015; McWilliams A, 2013, NEW ENGL J MED, V369, P910, DOI 10.1056/NEJMoa1214726; Moyer VA, 2014, ANN INTERN MED, V160, P330, DOI 10.7326/M13-2771; Pinsky PF, 2013, RADIOLOGY, V268, P865, DOI 10.1148/radiol.13121530; Setio AAA, 2017, MED IMAGE ANAL, V42, P1, DOI 10.1016/j.media.2017.06.015; Tammemagi MC, 2017, LANCET ONCOL, V18, P1523, DOI [10.1016/S1470-2045(17)30597-1, 10.1016/s1470-2045(17)30597-1]; van Riel SJ, 2019, EUR RADIOL, V29, P924, DOI 10.1007/s00330-018-5599-4; WHO, TOP 10 CAUS DEATH; World Health Organization, GLOB HLTH OBS GHO DA	18	2	2	3	5	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2021	3	6							e210027	10.1148/ryai.2021210027	http://dx.doi.org/10.1148/ryai.2021210027			7	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9UW	34870218	Green Published, Green Submitted			2022-12-18	WOS:000826914400008
J	Juluru, K; Shih, HH; Murthy, KNK; Elnajjar, P; El-Rowmeim, A; Roth, C; Genereaux, B; Fox, J; Siegel, E; Rubin, DL				Juluru, Krishna; Shih, Hao-Hsin; Murthy, Krishna Nand Keshava; Elnajjar, Pierre; El-Rowmeim, Amin; Roth, Christopher; Genereaux, Brad; Fox, Josef; Siegel, Eliot; Rubin, Daniel L.			Integrating Al Algorithms into the Clinical Workflow	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						PACS; Computer Applications-General (Informatics); Diagnosis		Integration of artificial intelligence (AI) applications within clinical workflows is an important step for leveraging developed AI algorithms. In this report, generalizable components for deploying AI systems into clinical practice are described that were implemented in a clinical pilot study using lymphoscintigraphy examinations as a prospective use case (July 1, 2019-October 31, 2020). Deployment of the AI algorithm consisted of seven software components, as follows: (a) image delivery, (b) quality control, (c) a results database, (d) results processing, (e) results presentation and delivery, (f) error correction, and (g) a dashboard for performance monitoring. A total of 14 users used the system (faculty radiologists and trainees) to assess the degree of satisfaction with the components and overall workflow. Analyses included the assessment of the number of examinations processed, error rates, and corrections. The AI system processed 1748 lymphoscintigraphy examinations. The system enabled radiologists to correct 146 AI results, generating real-time corrections to the radiology report. All AI results and corrections were successfully stored in a database for downstream use by the various integration components. A dashboard allowed monitoring of the AI system performance in real time. All 14 survey respondents "somewhat agreed" or "strongly agreed" that the AI system was well integrated into the clinical workflow. In all, a framework of processes and components for integrating AI algorithms into clinical workflows was developed. The implementation described could be helpful for assessing and monitoring AI performance in clinical practice. (C) RSNA, 2021.	[Juluru, Krishna; Shih, Hao-Hsin; Murthy, Krishna Nand Keshava; Elnajjar, Pierre; El-Rowmeim, Amin; Fox, Josef] Mem Sloan Kettering Canc Ctr, Dept Ratliol, 1275 York Ave,Box 29, New York, NY 10065 USA; [Roth, Christopher] Duke Univ, Med Ctr, Dept Radiol, Durham, NC 27710 USA; [Genereaux, Brad] NVIDIA, Santa Clara, CA USA; [Siegel, Eliot] Univ Maryland, Sch Med, Dept Diagnost Radiol & Nucl Med, Baltimore, MD 21201 USA; [Rubin, Daniel L.] Stanford Univ, Dept Radiol, Stanford, CA 94305 USA	Memorial Sloan Kettering Cancer Center; Duke University; Nvidia Corporation; University System of Maryland; University of Maryland Baltimore; Stanford University	Juluru, K (corresponding author), Mem Sloan Kettering Canc Ctr, Dept Ratliol, 1275 York Ave,Box 29, New York, NY 10065 USA.	juluruk@mskcc.org	; Roth, Christopher/L-3395-2016; Rubin, Daniel/E-3740-2010	Juluru, Krishna/0000-0001-8203-8894; Siegel, Eliot/0000-0002-7458-6281; Roth, Christopher/0000-0002-9634-7126; Rubin, Daniel/0000-0001-5057-4369; Keshava Murthy, Krishna Nand/0000-0003-2408-7414	National Institutes of Health/National Cancer Institute Cancer Center Support Grant [P30 CA008748]	National Institutes of Health/National Cancer Institute Cancer Center Support Grant	Supported in part by National Institutes of Health/National Cancer Institute Cancer Center Support Grant P30 CA008748.	Albertini JJ, 1996, JAMA-J AM MED ASSOC, V276, P1818, DOI 10.1001/jama.276.22.1818; [Anonymous], FDA CLEARED ALGORITH; [Anonymous], AI INT IM WHIT PAP; [Anonymous], IHE RAD TECHN FRAM S; Chartrand G, 2017, RADIOGRAPHICS, V37, P2113, DOI 10.1148/rg.2017170077; Choy G, 2018, RADIOLOGY, V288, P318, DOI 10.1148/radiol.2018171820; Clunie DA, 2007, CANCER INFORM, V4, P33; Fedorov A, 2016, PEERJ, V4, DOI 10.7717/peerj.2057; Kamel PI, 2018, J DIGIT IMAGING, V31, P327, DOI 10.1007/s10278-018-0087-6; Kerlikowske K, 2018, ANN INTERN MED, V168, P757, DOI 10.7326/M17-3008; Kinzie MB, 2002, J AM MED INFORM ASSN, V9, P320, DOI 10.1197/jamia.M0822; Ko I, 2017, HEALTHC INFORM RES, V23, P349, DOI 10.4258/hir.2017.23.4.349; Miller JD, 2017, BIG DATA VISUALIZATI; Ong L, 2017, AM J ROENTGENOL, V209, pW18, DOI 10.2214/AJR.16.17517; Tadavarthi Y, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020200004; Wanders JOP, 2017, BREAST CANCER RES, V19, DOI 10.1186/s13058-017-0859-9	16	2	2	0	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2021	3	6							e210013	10.1148/ryai.2021210013	http://dx.doi.org/10.1148/ryai.2021210013			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9UW	34870216	Green Published			2022-12-18	WOS:000826914400006
J	Calabrese, E; Rudie, JD; Rauschecker, AM; Villanueva-Meyer, JE; Cha, S				Calabrese, Evan; Rudie, Jeffrey D.; Rauschecker, Andreas M.; Villanueva-Meyer, Javier E.; Cha, Soonmee			Feasibility of Simulated Postcontrast MRI of Glioblastomas and Lower-Grade Gliomas by Using Three-dimensional Fully Convolutional Neural Networks	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						MR-Contrast Agent; MR-Imaging; CNS; Brain/Brain Stem; Contrast Agents-Intravenous; Neoplasms-Primary; Experimental Investigations; Technology Assessment; Supervised Learning; Transfer Learning; Convolutional Neural Network; Deep Learning Algorithms; Machine Learning Algorithms	GADOLINIUM DEPOSITION; PERFORMANCE; MOVEMENT	Purpose: To evaluate the feasibility and accuracy of simulated postcontrast T1-weighted brain MR images generated by using precontrast MR images in patients with brain glioma. Materials and Methods: In this retrospective study, a three-dimensional deep convolutional neural network was developed to simulate T1-weighted postcontrast images from eight precontrast sequences in 400 patients (mean age, 57 years; 239 men; from 2015 to 2020), including 332 with glioblastoma and 68 with lower-grade gliomas. Performance was evaluated by using quantitative image similarity and error metrics and enhancing tumor overlap analysis. Performance was also assessed on a multicenter external dataset (n = 286 from the 2019 Multimodal Brain Tumor Segmentation Challenge; mean age, 60 years; ratio of men to women unknown) by using transfer learning. A subset of cases was reviewed by neuroradiologist readers to assess whether simulated images affected the ability to determine the tumor grade. Results: Simulated whole-brain postcontrast images were both qualitatively and quantitatively similar to the real postcontrast images in terms of quantitative image similarity (structural similarity index of 0.84 +/- 0.05), pixelwise error (symmetric mean absolute percent error of 3.65%), and enhancing tumor compartment overlap (Dice coefficient, 0.65 +/- 0.25). Similar results were achieved with the external dataset (Dice coefficient, 0.62 +/- 0.27). There was no difference in the ability of the neuroradiologist readers to determine the tumor grade in real versus simulated images (accuracy, 87.7% vs 90.6%; P =.87). Conclusion: The developed model was capable of producing simulated postcontrast T1-weighted MR images that were similar to real acquired images as determined by both quantitative analysis and radiologist assessment. Supplemental material is available for this article. (C) RSNA, 2021.	[Calabrese, Evan; Rudie, Jeffrey D.; Rauschecker, Andreas M.; Villanueva-Meyer, Javier E.; Cha, Soonmee] Univ Calif San Francisco, Dept Radiol & Biomed Imaging, 350 Parnassus Ave,Suite 307H, San Francisco, CA 94143 USA; [Calabrese, Evan] Univ Calif San Francisco, Ctr Intelligent Imaging, 350 Parnassus Ave,Suite 307H, San Francisco, CA 94143 USA	University of California System; University of California San Francisco; University of California System; University of California San Francisco	Calabrese, E (corresponding author), Univ Calif San Francisco, Dept Radiol & Biomed Imaging, 350 Parnassus Ave,Suite 307H, San Francisco, CA 94143 USA.; Calabrese, E (corresponding author), Univ Calif San Francisco, Ctr Intelligent Imaging, 350 Parnassus Ave,Suite 307H, San Francisco, CA 94143 USA.	evan.calabrese@ucsf.edu		Calabrese, Evan/0000-0002-1464-0354; Rudie, Jeffrey/0000-0001-8609-8421; Cha, Soonmee/0000-0002-5924-5876; Villanueva-Meyer, Javier/0000-0002-5910-0757; Rauschecker, Andreas/0000-0003-0633-9876	National Institutes of Health Ruth L. Kirschstein Institutional National Research Service Award [T32EB001631]; Radiological Society of North America (RSNA) Research and Education (RE) Foundation [RR2011]; University of California San Francisco resident research fund	National Institutes of Health Ruth L. Kirschstein Institutional National Research Service Award(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Radiological Society of North America (RSNA) Research and Education (RE) Foundation; University of California San Francisco resident research fund	Supported by the National Institutes of Health Ruth L. Kirschstein Institutional National Research Service Award under award number T32EB001631. This project was also indirectly supported by the Radiological Society of North America (RSNA) Research and Education (R&E) Foundation, through grant number RR2011. The content is solely the responsibility of the authors and does not necessarily represent the official views of the RSNA R&E Foundation. The University of California San Francisco resident research fund provided financial support for some graphics processing hardware used in this study.	Andersson JLR, 2016, NEUROIMAGE, V141, P556, DOI 10.1016/j.neuroimage.2016.06.058; Andersson JLR, 2016, NEUROIMAGE, V125, P1063, DOI 10.1016/j.neuroimage.2015.10.019; Avants BB, 2011, NEUROIMAGE, V54, P2033, DOI 10.1016/j.neuroimage.2010.09.025; Bagley LJ, 1997, RADIOLOGY, V202, P511, DOI 10.1148/radiology.202.2.9015082; Bakas S, ARXIV 181102629 PREP; Bakas S, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.117; Calabrese E, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-68857-8; Clement P, 2018, J CEREBR BLOOD F MET, V38, P1418, DOI 10.1177/0271678X17702156; EARNEST F, 1988, RADIOLOGY, V166, P823, DOI 10.1148/radiology.166.3.2829270; Fonov V.S., 2009, NEUROIMAGE, V47, DOI [DOI 10.1016/S1053-8119(09)70884-5, 10.1016/S1053-8119(09)70884-5]; Gorgolewski Krzysztof, 2011, Front Neuroinform, V5, P13, DOI 10.3389/fninf.2011.00013; Gulani V, 2017, LANCET NEUROL, V16, P564, DOI 10.1016/S1474-4422(17)30158-8; Guo J, 2020, J CEREBR BLOOD F MET, V40, P2240, DOI 10.1177/0271678X19888123; Han X, 2017, MED PHYS, V44, P1408, DOI 10.1002/mp.12155; Jenkinson M, 2012, NEUROIMAGE, V62, P782, DOI 10.1016/j.neuroimage.2011.09.015; Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90; Kingma DP, ARXIV 14126980 PREPR; Kleesiek J, 2019, INVEST RADIOL, V54, P653, DOI 10.1097/RLI.0000000000000583; Kleesiek J, 2016, SCI REP-UK, V6, DOI 10.1038/srep25007; Lei Y, 2019, MED PHYS, V46, P3565, DOI 10.1002/mp.13617; McDonald RJ, 2015, RADIOLOGY, V275, P772, DOI 10.1148/radiol.15150025; Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694; Morley SK, 2018, SPACE WEATHER, V16, P69, DOI 10.1002/2017SW001669; Narayana PA, 2020, RADIOLOGY, V294, P398, DOI 10.1148/radiol.2019191061; Noguchi T, 2008, AM J NEURORADIOL, V29, P688, DOI 10.3174/ajnr.A0903; Prince MR, 2011, AM J ROENTGENOL, V196, pW138, DOI 10.2214/AJR.10.4885; Ronneberger O., 2015, P INT C MED IMAG COM, P234, DOI [DOI 10.1007/978-3-319-24574-4_28, DOI 10.48550/ARXIV.1505.04597]; Sun HR, 2020, I S BIOMED IMAGING, P908, DOI 10.1109/ISBI45749.2020.9098323; Tanenbaum LN, 2017, AM J NEURORADIOL, V38, P1103, DOI 10.3174/ajnr.A5227; Tustison NJ, 2010, IEEE T MED IMAGING, V29, P1310, DOI 10.1109/TMI.2010.2046908; Wang GT, 2018, LECT NOTES COMPUT SC, V10670, P178, DOI 10.1007/978-3-319-75238-9_16; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861	32	2	2	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2021	3	5							e200276	10.1148/ryai.2021200276	http://dx.doi.org/10.1148/ryai.2021200276			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9TT	34617027	Green Published			2022-12-18	WOS:000826911500008
J	Kway, YM; Thirumurugan, K; Tint, MT; Michael, N; Shek, LPC; Yap, FKP; Tan, KH; Godfrey, KM; Chong, YS; Fortier, MV; Marx, UC; Eriksson, JG; Lee, YS; Velan, SS; Feng, ML; Sadananthan, SA				Kway, Yeshe Manuel; Thirumurugan, Kashthuri; Tint, Mya Thway; Michael, Navin; Shek, Lynette Pei-Chi; Yap, Fabian Kok Peng; Tan, Kok Hian; Godfrey, Keith M.; Chong, Yap Seng; Fortier, Marielle Valerie; Marx, Ute C.; Eriksson, Johan G.; Lee, Yung Seng; Velan, S. Sendhil; Feng, Mengling; Sadananthan, Suresh Anand			Automated Segmentation of Visceral, Deep Subcutaneous, and Superficial Subcutaneous Adipose Tissue Volumes in MRI of Neonates and Young Children	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Pediatrics; Deep Learning; Convolutional Neural Networks; Water-Fat MRI; Image Segmentation; Deep and Superficial Subcutaneous Adipose Tissue; Visceral Adipose Tissue	ABDOMINAL FAT; BODY-FAT; RISK; CHILDHOOD; ETHNICITY; OBESITY; QUANTIFICATION; COMPARTMENTS; ASSOCIATION; OVERWEIGHT	Purpose: To develop and evaluate an automated segmentation method for accurate quantification of abdominal adipose tissue (AAT) depots (superficial subcutaneous adipose tissue [SSAT], deep subcutaneous adipose tissue [DSAT], and visceral adipose tissue [VAT]) in neonates and young children. Materials and Methods: This was a secondary analysis of prospectively collected data, which used abdominal MRI data from Growing Up in Singapore Towards healthy Outcomes, or GUSTO, a longitudinal mother-offspring cohort, to train and evaluate a convolutional neural network for volumetric AAT segmentation. The data comprised imaging volumes of 333 neonates obtained at early infancy (age <= 2 weeks, 180 male neonates) and 755 children aged either 4.5 years (n = 316, 150 male children) or 6 years (n = 439, 219 male children). The network was trained on images of 761 randomly selected volumes (neonates and children combined) and evaluated on 100 neonatal volumes and 227 child volumes by using 10-fold validation. Automated segmentations were compared with expert-generated manual segmentation. Segmentation performance was assessed using Dice scores. Results: When the model was tested on the test datasets across the 10 folds, the model had strong agreement with the ground truth for all testing sets, with mean Dice similarity scores for SSAT, DSAT, and VAT, respectively, of 0.960, 0.909, and 0.872 in neonates and 0.944, 0.851, and 0.960 in children. The model generalized well to different body sizes and ages and to all abdominal levels. Conclusion: The proposed segmentation approach provided accurate automated volumetric assessment of AAT compartments on MR images of neonates and children. (C)RSNA, 2021	[Kway, Yeshe Manuel; Thirumurugan, Kashthuri; Michael, Navin; Shek, Lynette Pei-Chi; Chong, Yap Seng; Fortier, Marielle Valerie; Eriksson, Johan G.; Lee, Yung Seng; Velan, S. Sendhil; Sadananthan, Suresh Anand] Agcy Sci Tech & Res, Singapore Inst Clin Sci, 30 Med Dr, Singapore 117609, Singapore; [Velan, S. Sendhil] Agcy Sci Tech & Res, Inst Bioengn & Bioimaging, 30 Med Dr, Singapore 117609, Singapore; [Kway, Yeshe Manuel; Eriksson, Johan G.] Natl Univ Singapore, Yong Loo Lin Sch Med, Dept Med, Singapore, Singapore; [Tint, Mya Thway; Chong, Yap Seng] Natl Univ Singapore, Yong Loo Lin Sch Med, Dept Obstet & Gynaecol, Singapore, Singapore; [Shek, Lynette Pei-Chi; Lee, Yung Seng] Natl Univ Singapore, Yong Loo Lin Sch Med, Dept Pediat, Singapore, Singapore; [Shek, Lynette Pei-Chi; Lee, Yung Seng] Natl Univ Singapore Hosp, Khoo Teck Puat Natl Univ Childrens Med Inst, Singapore, Singapore; [Yap, Fabian Kok Peng] KK Womens & Childrens Hosp, Dept Pediat Endocrinol, Singapore, Singapore; [Tan, Kok Hian] KK Womens & Childrens Hosp, Dept Obstet & Gynaecol, Singapore, Singapore; [Fortier, Marielle Valerie] KK Womens & Childrens Hosp, Dept Diagnost & Intervent Imaging, Singapore, Singapore; [Yap, Fabian Kok Peng] Duke Natl Univ Singapore, Pediat Acad Clin Programme, Med Sch, Singapore, Singapore; [Tan, Kok Hian] Duke Natl Univ Singapore, Acad Med, Med Sch, Singapore, Singapore; [Yap, Fabian Kok Peng; Tan, Kok Hian] Duke Natl Univ Singapore, Med Sch, Singapore, Singapore; [Yap, Fabian Kok Peng] Nanyang Technol Univ, Lee Kong Chian Sch Med, Singapore, Singapore; [Godfrey, Keith M.] Univ Southampton, Lifecourse Epidemiol Unit, MRC, Southampton, Hants, England; [Godfrey, Keith M.] Univ Southampton, Natl Inst Hlth Res, Southampton Biomed Res Ctr, Southampton, Hants, England; [Godfrey, Keith M.] Univ Hosp Southampton Natl Hlth Serv Fdn Trust, Southampton, Hants, England; [Marx, Ute C.] Pforzheim Univ, Sch Engn, Pforzheim, Germany; [Eriksson, Johan G.] Univ Helsinki, Dept Gen Practice & Primary Hlth Care, Helsinki, Finland; [Eriksson, Johan G.] Helsinki Univ Hosp, Helsinki, Finland; [Eriksson, Johan G.] Folkhalsan Res Ctr, Helsinki, Finland; [Feng, Mengling] Natl Univ Hlth Syst, Saw Swee Hock Sch Publ Hlth, Singapore, Singapore; [Feng, Mengling] Natl Univ Singapore, Singapore, Singapore; [Feng, Mengling] Natl Univ Singapore, Inst Data Sci, Singapore, Singapore	Agency for Science Technology & Research (A*STAR); A*STAR - Singapore Institute for Clinical Sciences (SICS); Agency for Science Technology & Research (A*STAR); A*STAR - Institute of Bioengineering & Bioimaging (IBB); National University of Singapore; National University of Singapore; National University of Singapore; National University of Singapore; KK Women's & Children's Hospital; KK Women's & Children's Hospital; KK Women's & Children's Hospital; National University of Singapore; National University of Singapore; National University of Singapore; Nanyang Technological University & National Institute of Education (NIE) Singapore; Nanyang Technological University; University of Southampton; University of Southampton; University of Helsinki; University of Helsinki; Helsinki University Central Hospital; Folkhalsan Research Center; National University of Singapore; National University of Singapore; National University of Singapore	Sadananthan, SA (corresponding author), Agcy Sci Tech & Res, Singapore Inst Clin Sci, 30 Med Dr, Singapore 117609, Singapore.	suresh@sics.a-star.edu.sg	Michael, Navin/HGF-2322-2022; Lee, Yung Seng/F-2169-2014; Velan, S. Sendhil/B-6374-2017; Tint, Mya-Thway/HGU-1202-2022	Michael, Navin/0000-0002-6170-2108; Lee, Yung Seng/0000-0002-1253-0557; Velan, S. Sendhil/0000-0002-4096-0722; Godfrey, Keith/0000-0002-4643-0618; Shek, Lynette/0000-0001-9064-8983; TINT, Mya Thway/0000-0002-9548-7186; Tan, Kok Hian/0000-0003-1945-0266; Fortier, Marielle/0000-0002-3294-1054	Singapore National Research Foundation under its Translational and Clinical Research (TCR) Flagship Programme; Singapore Ministry of Health National Medical Research Council, Singapore [NMRC/TCR/004-NUS/2008, NMRC/TCR/012-NUHS/2014]; Singapore Institute for Clinical Sciences, Agency for Science Technology and Research, Singapore	Singapore National Research Foundation under its Translational and Clinical Research (TCR) Flagship Programme(National Research Foundation, Singapore); Singapore Ministry of Health National Medical Research Council, Singapore; Singapore Institute for Clinical Sciences, Agency for Science Technology and Research, Singapore(Agency for Science Technology & Research (A*STAR))	Supported in part by the Singapore National Research Foundation under its Translational and Clinical Research (TCR) Flagship Programme and administered by the Singapore Ministry of Health National Medical Research Council, Singapore (NMRC/TCR/004-NUS/2008; NMRC/TCR/012-NUHS/2014). Additional funding is provided by the Singapore Institute for Clinical Sciences, Agency for Science Technology and Research, Singapore.	Addeman BT, 2015, J MAGN RESON IMAGING, V41, P233, DOI 10.1002/jmri.24526; [Anonymous], 1999, 10153 BS EN; Ayer J, 2015, EUR HEART J, V36, P1371, DOI 10.1093/eurheartj/ehv089; Bjerregaard LG, 2018, NEW ENGL J MED, V378, P1302, DOI [10.1056/NEJMoa1713231, 10.1056/nejmoa1713231]; Borga M, 2018, BRIT J RADIOL, V91, DOI 10.1259/bjr.20180252; DIXON WT, 1984, RADIOLOGY, V153, P189, DOI 10.1148/radiology.153.1.6089263; Estrada S, 2020, MAGN RESON MED, V83, P1471, DOI 10.1002/mrm.28022; Glorot X., 2010, PROC MACH LEARN RES, P249; Golan R, 2012, DIABETES CARE, V35, P640, DOI 10.2337/dc11-1583; Gonzalez-Alvarez C, 2017, EUR J CLIN NUTR, V71, P1068, DOI 10.1038/ejcn.2017.28; Hu H, 2016, MAGN RESON MATER PHY, V29, P259, DOI 10.1007/s10334-015-0498-z; Karlsson A, 2015, J MAGN RESON IMAGING, V41, P1558, DOI 10.1002/jmri.24726; Khoo CM, 2014, DIABETES, V63, P1093, DOI 10.2337/db13-1483; Kim SH, 2016, DIABETOL METAB SYNDR, V8, DOI 10.1186/s13098-016-0127-7; Kingma DP, ARXIV 14126980 PREPR; Kustner T, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020200010; Kullberg J, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-08925-8; Langner T, 2019, MAGN RESON MED, V81, P2736, DOI 10.1002/mrm.27550; Lee MJ, 2013, MOL ASPECTS MED, V34, P1, DOI 10.1016/j.mam.2012.10.001; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; Marinou K, 2014, DIABETES CARE, V37, P821, DOI 10.2337/dc13-1353; Mosbech TH, 2011, LECT NOTES COMPUT SC, V6688, P501, DOI 10.1007/978-3-642-21227-7_47; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Sadananthan SA, 2019, OBESITY, V27, P470, DOI 10.1002/oby.22408; Sadananthan SA, 2015, J MAGN RESON IMAGING, V41, P924, DOI 10.1002/jmri.24655; Simonyan K, ARXIV 14091556V6; Smith SR, 2001, METABOLISM, V50, P425, DOI 10.1053/meta.2001.21693; Soh SE, 2014, INT J EPIDEMIOL, V43, P1401, DOI 10.1093/ije/dyt125; Sun JJ, 2016, AM J HUM BIOL, V28, P757, DOI 10.1002/ajhb.22862; Tint MT, 2016, AM J CLIN NUTR, V103, P1311, DOI 10.3945/ajcn.115.108738; Wang YZ, 2017, COMPUT METH PROG BIO, V144, P97, DOI 10.1016/j.cmpb.2017.03.017; Whitaker RC, 1997, NEW ENGL J MED, V337, P869, DOI 10.1056/NEJM199709253371301; Woo JG, 2019, CURR NUTR REP, V8, P29, DOI 10.1007/s13668-019-0259-0; World Health Organization, WHO CHILD GROWTH STA	34	2	2	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2021	3	5							e200304	10.1148/ryai.2021200304	http://dx.doi.org/10.1148/ryai.2021200304			11	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9TT	34617030	Green Published			2022-12-18	WOS:000826911500011
J	Jacobson, FL; Krupinski, EA				Jacobson, Francine L.; Krupinski, Elizabeth A.			Clinical Validation Is the Key to Adopting AI in Clinical Practice	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Jacobson, Francine L.] Brigham & Womens Hosp, Dept Radiol, 75 Francis St, Boston, MA 02115 USA; [Krupinski, Elizabeth A.] Emory Univ, Dept Radiol & Imaging Sci, Atlanta, GA 30322 USA	Harvard University; Brigham & Women's Hospital; Emory University	Jacobson, FL (corresponding author), Brigham & Womens Hosp, Dept Radiol, 75 Francis St, Boston, MA 02115 USA.	fjacobson@bwh.harvard.edu						Dreiseitl S, 2002, J BIOMED INFORM, V35, P352, DOI 10.1016/S1532-0464(03)00034-0; Kundel Harold L, 2006, J Am Coll Radiol, V3, P402, DOI 10.1016/j.jacr.2006.02.023; KUNDEL HL, 1979, RADIOLOGY, V132, P265, DOI 10.1148/132.2.265; Szot A, 2004, INT J MED INFORM, V73, P65, DOI 10.1016/j.ijmedinf.2003.10.002; Thian Y. L., RADIOL ARTIF INTELL, V3	5	2	2	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2021	3	4							e210104	10.1148/ryai.2021210104	http://dx.doi.org/10.1148/ryai.2021210104			2	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SU	34350416	Green Published			2022-12-18	WOS:000826909000016
J	Bartoli, A; Fournel, J; Bentatou, Z; Habib, G; Lalande, A; Bernard, M; Boussel, L; Pontana, F; Dacher, JN; Ghattas, B; Jacquier, A				Bartoli, Axel; Fournel, Joris; Bentatou, Zakarya; Habib, Gilbert; Lalande, Alain; Bernard, Monique; Boussel, Loic; Pontana, Francois; Dacher, Jean-Nicolas; Ghattas, Badih; Jacquier, Alexis			Deep Learning-based Automated Segmentation of Left Ventricular Trabeculations and Myocardium on Cardiac MR Images: A Feasibility Study	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							NON-COMPACTION; SEMIAUTOMATIC DETECTION; PAPILLARY-MUSCLES; DIAGNOSIS; NONCOMPACTION; CARDIOMYOPATHY; ADULTS	Purpose: To develop and evaluate a complete deep learning pipeline that allows fully automated end-diastolic left ventricle (LV) cardiac MRI segmentation, including trabeculations and automatic quality control of the predicted segmentation. Materials and Methods: This multicenter retrospective study includes training, validation, and testing datasets of 272, 27, and 150 cardiac MR images, respectively, collected between 2012 and 2018. The reference standard was the manual segmentation of four LV anatomic structures performed on end-diastolic short-axis cine cardiac MRI: LV trabeculations, LV myocardium, LV papillary muscles, and the LV blood cavity. The automatic pipeline was composed of five steps with a DenseNet architecture. Intraobserver agreement, interobserver agreement, and interaction time were recorded. The analysis includes the correlation between the manual and automated segmentation, a reproducibility comparison, and Bland-Altman plots. Results: The automated method achieved mean Dice coefficients of 0.96 +/- 0.01 (standard deviation) for LV blood cavity, 0.89 +/- 0.03 for LV myocardium, and 0.62 +/- 0.08 for LV trabeculation (mean absolute error, 3.63 g +/- 3.4). Automatic quantification of LV end-diastolic volume, LV myocardium mass, LV trabeculation, and trabeculation mass-to-total myocardial mass (TMM) ratio showed a significant correlation with the manual measures (r = 0.99, 0.99, 0.90, and 0.83, respectively; all P<.01). On a subset of 48 patients, the mean Dice value for LV trabeculation was 0.63 +/- 0.10 or higher compared with the human interobserver (0.44 +/- 0.09; P<.01) and intraobserver measures (0.58 +/- 0.09; P<.01). Automatic quantification of the trabeculation mass-to-TMM ratio had a higher correlation (0.92) compared with the intra- and interobserver measures (0.74 and 0.39, respectively; both P<.01). Conclusion: Automated deep learning framework can achieve reproducible and quality-controlled segmentation of cardiac trabeculations, outperforming inter- and intraobserver analyses. (C) RSNA, 2020	[Bartoli, Axel; Jacquier, Alexis] Hop La Timone Adults, AP HM, Dept Radiol, 264 Rue St Pierre, F-13385 Marseille 05, France; [Habib, Gilbert] Hop La Timone Adults, AP HM, Dept Cardiol, 264 Rue St Pierre, F-13385 Marseille 05, France; [Bartoli, Axel; Fournel, Joris; Bentatou, Zakarya; Bernard, Monique; Jacquier, Alexis] Aix Marseille Univ, Med Fac, CRMBM UMR CNRS 7339, Marseille, France; [Fournel, Joris; Ghattas, Badih] Aix Marseille Univ, Cent Marseille, I2M UMR CNRS 7373, Marseille, France; [Lalande, Alain] Bourgogne Franche Comte Univ, ImVia Lab, Dijon, France; [Lalande, Alain] Bourgogne Franche Comte Univ, Univ Hosp Dijon, Dijon, France; [Boussel, Loic] Hosp Civils Lyon, Hop Croix Rousse, Dept Radiol, Lyon, France; [Pontana, Francois] Lille Univ Hosp, Dept Cardiovasc Imaging, Lille, France; [Dacher, Jean-Nicolas] Rouen Univ Hosp, Dept Diagnost Imaging, Rouen, France	UDICE-French Research Universities; Aix-Marseille Universite; Assistance Publique-Hopitaux de Marseille; UDICE-French Research Universities; Aix-Marseille Universite; Assistance Publique-Hopitaux de Marseille; Centre National de la Recherche Scientifique (CNRS); CNRS - Institute for Engineering & Systems Sciences (INSIS); UDICE-French Research Universities; Aix-Marseille Universite; UDICE-French Research Universities; Aix-Marseille Universite; Universite de Bourgogne; CHU Dijon Bourgogne; CHU Lyon; Universite de Lille - ISITE; CHU Lille; CHU de Rouen	Bartoli, A (corresponding author), Hop La Timone Adults, AP HM, Dept Radiol, 264 Rue St Pierre, F-13385 Marseille 05, France.; Bartoli, A (corresponding author), Aix Marseille Univ, Med Fac, CRMBM UMR CNRS 7339, Marseille, France.	axel.bartoli@ap-hm.fr	BERNARD, Monique/Q-7254-2017; HABIB, Gilbert/E-7007-2016	BERNARD, Monique/0000-0002-3179-8698; Fournel, Joris/0000-0002-3944-5061; BARTOLI, Axel/0000-0001-5876-5389; Dacher, Jean-Nicolas/0000-0002-7681-5252; HABIB, Gilbert/0000-0003-3899-9983				Arbustini E, 2014, J AM COLL CARDIOL, V64, P1840, DOI 10.1016/j.jacc.2014.08.030; Bai WJ, 2018, J CARDIOVASC MAGN R, V20, DOI 10.1186/s12968-018-0471-x; Bentatou Z, 2018, DIAGN INTERV IMAG, V99, P689, DOI 10.1016/j.diii.2018.08.014; Bernard O, 2018, IEEE T MED IMAGING, V37, P2514, DOI 10.1109/TMI.2018.2837502; Bluemke DA, 2020, RADIOLOGY, V294, P487, DOI 10.1148/radiol.2019192515; Bricq S, 2016, J MAGN RESON IMAGING, V43, P1398, DOI 10.1002/jmri.25113; Captur G, 2013, J CARDIOVASC MAGN R, V15, DOI 10.1186/1532-429X-15-36; Chuang ML, 2012, JACC-CARDIOVASC IMAG, V5, P1115, DOI 10.1016/j.jcmg.2012.05.015; Elliott P, 2008, EUR HEART J, V29, P270, DOI 10.1093/eurheartj/ehm342; Elliott PM, 2014, EUR HEART J, V35, P2733, DOI 10.1093/eurheartj/ehu284; Frandon J, 2018, J CARDIOVASC MAGN R, V20, DOI 10.1186/s12968-018-0489-0; Franklin Rodney C G, 2017, Cardiol Young, V27, P1872, DOI 10.1017/S1047951117002244; Gati S, 2014, CIRCULATION, V130, P475, DOI 10.1161/CIRCULATIONAHA.114.008554; Gati S, 2013, HEART, V99, P401, DOI 10.1136/heartjnl-2012-303418; Habib G, 2011, EUR J HEART FAIL, V13, P177, DOI 10.1093/eurjhf/hfq225; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Jacquier A, 2010, EUR HEART J, V31, P1098, DOI 10.1093/eurheartj/ehp595; Japp AG, 2016, J AM COLL CARDIOL, V67, P2996, DOI 10.1016/j.jacc.2016.03.590; Jenni R, 2007, HEART, V93, P11, DOI 10.1136/hrt.2005.082271; Jenni R, 2001, HEART, V86, P666, DOI 10.1136/heart.86.6.666; Jensen B, 2016, BBA-MOL CELL RES, V1863, P1696, DOI 10.1016/j.bbamcr.2015.10.018; Kawel N, 2012, CIRC-CARDIOVASC IMAG, V5, P357, DOI 10.1161/CIRCIMAGING.111.971713; Khened M, 2019, MED IMAGE ANAL, V51, P21, DOI 10.1016/j.media.2018.10.004; Kohli SK, 2008, EUR HEART J, V29, P89, DOI 10.1093/eurheartj/ehm481; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Lu YL, 2013, QUANT IMAG MED SURG, V3, P200, DOI 10.3978/j.issn.2223-4292.2013.08.02; Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79; Park SH, 2018, RADIOLOGY, V286, P800, DOI 10.1148/radiol.2017171920; Petersen SE, 2005, J AM COLL CARDIOL, V46, P101, DOI 10.1016/j.jacc.2005.03.045; Robinson R, 2018, ARXIV180606244 CS; Sandhu R, 2008, ECHOCARDIOGR-J CARD, V25, P8, DOI 10.1111/j.1540-8175.2007.00560.x; Stollberger C, 2019, HERZ, V44, P659, DOI 10.1007/s00059-018-4695-1; Tao Q, 2019, RADIOLOGY, V290, P81, DOI 10.1148/radiol.2018180513; Thuny F, 2010, ARCH CARDIOVASC DIS, V103, P150, DOI 10.1016/j.acvd.2010.01.002; Tran PV., 2016, ARXIV160400494 CS; Ngo TA, 2013, IEEE IMAGE PROC, P695, DOI 10.1109/ICIP.2013.6738143; Weinsaft JW, 2008, INT J CARDIOL, V126, P359, DOI 10.1016/j.ijcard.2007.04.179	37	2	2	1	4	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2021	3	1							e200021	10.1148/ryai.2020200021	http://dx.doi.org/10.1148/ryai.2020200021			14	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z3HE	33937851	Green Published			2022-12-18	WOS:000826472300003
J	Harvey, H; Oakden-Rayner, L				Harvey, Hugh; Oakden-Rayner, Luke			Guidance for Interventional Trials Involving Artificial Intelligence	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Letter									[Harvey, Hugh] UCL, Inst Cognit Neurosci, Alexandra House,17-19 Queen Sq, London WC1N 3AZ, England; [Oakden-Rayner, Luke] Royal Adelaide Hosp, Dept Med Imaging Res, Adelaide, SA, Australia; [Oakden-Rayner, Luke] Univ Adelaide, Australian Inst Machine Learning, Adelaide, SA, Australia		Harvey, H (corresponding author), UCL, Inst Cognit Neurosci, Alexandra House,17-19 Queen Sq, London WC1N 3AZ, England.	h.harvey@ucl.ac.uk		Oakden-Rayner, Lauren/0000-0001-5471-5202				Collins GS, 2019, LANCET, V393, P1577, DOI 10.1016/S0140-6736(19)30037-6; Kohli A, 2018, J AM COLL RADIOL, V15, P535, DOI 10.1016/j.jacr.2017.12.029; Liu XX, 2020, NAT MED, V26, P1364, DOI 10.1038/s41591-020-1034-x; Mongan J, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020200029; Nagendran M, 2020, BMJ-BRIT MED J, V368, DOI 10.1136/bmj.m689; Rivera SC, 2020, NAT MED, V26, P1351, DOI 10.1038/s41591-020-1037-7; Sounderajah V, 2020, NAT MED, V26, P807, DOI 10.1038/s41591-020-0941-1	7	2	2	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2020	2	6								10.1148/ryai.2020200228	http://dx.doi.org/10.1148/ryai.2020200228			2	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CZ	33937849	Green Published			2022-12-18	WOS:000826480100011
J	Sala, E; Ursprung, S				Sala, Evis; Ursprung, Stephan			Artificial Intelligence in Radiology: The Computer's Helping Hand Needs Guidance	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Sala, Evis] Univ Cambridge, Dept Radiol, Box 218,Cambridge Biomed Campus,Hills Rd, Cambridge CB2 0QQ, England; Univ Cambridge, Canc Res UK Cambridge Ctr, Box 218,Cambridge Biomed Campus,Hills Rd, Cambridge CB2 0QQ, England		Sala, E (corresponding author), Univ Cambridge, Dept Radiol, Box 218,Cambridge Biomed Campus,Hills Rd, Cambridge CB2 0QQ, England.	es220@medschl.cam.ac.uk		Ursprung, Stephan/0000-0003-2476-178X; Sala, Evis/0000-0002-5518-9360				Joshi I, 2020, BUYERS GUIDE AI HLTH; Kanis JA, 2008, OSTEOPOROSIS INT, V19, P385, DOI 10.1007/s00198-007-0543-5; Lee CS, 2020, LANCET DIGIT HEALTH, V2, pE279, DOI 10.1016/S2589-7500(20)30102-3; Lehman CD, 2015, JAMA INTERN MED, V175, P1828, DOI 10.1001/jamainternmed.2015.5231; Reyes M, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190043; Rodriguez-Ruiz A, 2019, JNCI-J NATL CANCER I, V111, P916, DOI 10.1093/jnci/djy222; Schlapfer J, 2017, J AM COLL CARDIOL, V70, P1183, DOI 10.1016/j.jacc.2017.07.723; Smith GB, 2013, RESUSCITATION, V84, P465, DOI 10.1016/j.resuscitation.2012.12.016; Tadavarthi Y, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020200004; Thomassin-Naggara I, 2013, RADIOLOGY, V267, P432, DOI 10.1148/radiol.13121161; Topol EJ, 2019, TOPOL REV PREPARING	11	2	2	0	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2020	2	6							e200207	10.1148/ryai.2020200207	http://dx.doi.org/10.1148/ryai.2020200207			3	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CZ	33939784	Green Published			2022-12-18	WOS:000826480100010
J	Steinkamp, JM; Pomeranz, T; Adleberg, J; Kahn, CE; Cook, TS				Steinkamp, Jackson M.; Pomeranz, Taylor; Adleberg, Jason; Kahn, Charles E., Jr.; Cook, Tessa S.			Evaluation of Automated Public De-Identification Tools on a Corpus of Radiology Reports	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article								Purpose: To evaluate publicly available de-identification tools on a large corpus of narrative-text radiology reports. Materials and Methods: In this retrospective study, 21 categories of protected health information (PHI) in 2503 radiology reports were annotated from a large multihospital academic health system, collected between January 1, 2012 and January 8, 2019. A subset consisting of 1023 reports served as a test set; the remainder were used as domain-specific training data. The types and frequencies of PHI present within the reports were tallied. Five public de-identification tools were evaluated: MITRE Identification Scrubber Toolkit, U.S. National Library of Medicine-Scrubber, Massachusetts Institute of Technology de-identification software, Emory Health Information DE-identification (HIDE) software, and Neuro named-entity recognition (NeuroNER). The tools were compared using metrics including recall, precision, and F1 score (the harmonic mean of recall and precision) for each category of PHI. Results: The annotators identified 3528 spans of PHI text within the 2503 reports. Cohen k for interrater agreement was 0.938. Dates accounted for the majority of PHI found in the dataset of radiology reports (n = 2755 [78%]). The two best-performing tools both used machine learning methods-NeuroNER (precision, 94.5%; recall, 92.6%; microaveraged F1 score [F1], 93.6%) and Emory HIDE (precision, 96.6%; recall, 88.2%; F1, 92.2%)-but none exceeded 50% F1 on the important patient names category. Conclusion: PHI appeared infrequently within the corpus of reports studied, which created difficulties for training machine learning systems. Out-of-the-box de-identification tools achieved limited performance on the corpus of radiology reports, suggesting the need for further advancements in public datasets and trained models. (C) RSNA, 2020	[Steinkamp, Jackson M.; Pomeranz, Taylor; Adleberg, Jason; Kahn, Charles E., Jr.; Cook, Tessa S.] Hosp Univ Penn, Dept Radiol, 3400 Spruce St, Philadelphia, PA 19104 USA; [Steinkamp, Jackson M.] Boston Univ, Sch Med, Boston, MA 02118 USA		Steinkamp, JM (corresponding author), Hosp Univ Penn, Dept Radiol, 3400 Spruce St, Philadelphia, PA 19104 USA.; Steinkamp, JM (corresponding author), Boston Univ, Sch Med, Boston, MA 02118 USA.	jacksonsteinkamp@gmail.com		Kahn, Charles/0000-0002-6654-7434; Steinkamp, Jackson/0000-0001-7888-0691				Aberdeen J, 2010, INT J MED INFORM, V79, P849, DOI 10.1016/j.ijmedinf.2010.09.007; Aryanto KYE, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0431-7; Chevrier R, 2019, J MED INTERNET RES, V21, DOI 10.2196/13484; Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7; Demner-Fushman D, 2016, J AM MED INFORM ASSN, V23, P304, DOI 10.1093/jamia/ocv080; Dernoncourt F, ARXIV CSCL PREPRINT; Dernoncourt F, 2017, J AM MED INFORM ASSN, V24, P596, DOI 10.1093/jamia/ocw156; Ferrandez O, 2012, BMC MED RES METHODOL, V12, DOI 10.1186/1471-2288-12-109; Gardner J, 2009, DATA KNOWL ENG, V68, P1441, DOI 10.1016/j.datak.2009.07.006; Henriksson A, 2017, STUD HEALTH TECHNOL, V245, P393, DOI 10.3233/978-1-61499-830-3-393; Jiang XQ, 2013, MED CARE, V51, pS58, DOI 10.1097/MLR.0b013e31829b1d10; Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35; Kayaalp Mehmet, 2014, AMIA Annu Symp Proc, V2014, P767; Khin K, ARXIV CS 150 PREPRIN; Langarizadeh M, 2018, STUD HEALTH TECHNOL, V248, P80, DOI 10.3233/978-1-61499-858-7-80; Lee Hee-Jin, 2017, AMIA Annu Symp Proc, V2017, P1070; Marcus MP., 1999, TEXT SPEECH LANG TEC, P157, DOI 10.1007/978-94-017-2390-9_10; Neamatullah I, 2008, BMC MED INFORM DECIS, V8, DOI 10.1186/1472-6947-8-32; Office for Civil Rights, 2012, GUIDANCE REGARDING M; Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369; Wellner B., 2009, THESIS MASS BRANDEIS	21	2	2	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2020	2	6							e190137	10.1148/ryai.2020190137	http://dx.doi.org/10.1148/ryai.2020190137			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CZ	33937843	Green Published			2022-12-18	WOS:000826480100001
J	Somasundaram, E; Dillman, JR; Crotty, EJ; Trout, AT; Towbin, AJ; Anton, CG; Logan, A; Wieland, CA; Felekey, S; Coley, BD; Brady, SL				Somasundaram, Elanchezhian; Dillman, Jonathan R.; Crotty, Eric J.; Trout, Andrew T.; Towbin, Alexander J.; Anton, Christopher G.; Logan, Angeline I. I. I. I.; Wieland, Catherine A. I. I. I. I.; Felekey, Samantha; Coley, Brian D.; Brady, Samuel L.			Automatic Detection of Inadequate Pediatric Lateral Neck Radiographs of the Airway and Soft Tissues using Deep Learning	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							COEFFICIENT; VARIANCE; KAPPA	Purpose: To develop and validate a deep learning (DL) algorithm to identify poor-quality lateral airway radiographs. Materials and Methods: A total of 1200 lateral airway radiographs obtained in emergency department patients between January 1, 2000, and July 1, 2019, were retrospectively queried from the picture archiving and communication system. Two radiologists classified each radiograph as adequate or inadequate. Disagreements were adjudicated by a third radiologist. The radiographs were used to train and test the DL classifiers. Three technologists and three different radiologists classified the images in the test dataset, and their performance was compared with that of the DL classifiers. Results: The training set had 961 radiographs and the test set had 239. The best DL classifier (ResNet-50) achieved sensitivity, specificity, and area under the receiver operating characteristic curve of 0.90 (95% confidence interval [CI]: 0.86, 0.94), 0.82 (95% CI: 0.76, 0.90), and 0.86 (95% CI: 0.81, 0.91), respectively. Interrater agreement for technologists was fair (Fleiss k, 0.36 [95% CI: 0.29, 0.43]), while that for radiologists was moderate (Fleiss k, 0.59 [95% CI: 0.52, 0.66]). Cohen k value comparing the consensus rating of ResNet-50 iterations from fivefold cross-validation, consensus technologists' rating, and consensus radiologists' rating to the ground truth were 0.76 (95% CI: 0.63, 0.89), 0.49 (95% CI: 0.37, 0.61), and 0.66 (95% CI: 0.54, 0.78), respectively. Conclusion: The development and validation of DL classifiers to distinguish between adequate and inadequate lateral airway radiographs is reported. The classifiers performed significantly better than a group of technologists and as well as the radiologists. (C) RSNA, 2020	[Somasundaram, Elanchezhian; Dillman, Jonathan R.; Crotty, Eric J.; Trout, Andrew T.; Towbin, Alexander J.; Anton, Christopher G.; Logan, Angeline I. I. I. I.; Wieland, Catherine A. I. I. I. I.; Felekey, Samantha; Coley, Brian D.; Brady, Samuel L.] Univ Cincinnati, Cincinnati Childrens Hosp Med Ctr, Dept Radiol, Coll Med, 3333 Burnet Ave,MLC 5033, Cincinnati, OH 45229 USA	Cincinnati Children's Hospital Medical Center; University System of Ohio; University of Cincinnati	Somasundaram, E (corresponding author), Univ Cincinnati, Cincinnati Childrens Hosp Med Ctr, Dept Radiol, Coll Med, 3333 Burnet Ave,MLC 5033, Cincinnati, OH 45229 USA.	Elanchezhian.Somasundaram@cchmc.org		Towbin, Alexander/0000-0003-1729-5071; Coley, Brian/0000-0003-0354-4727; Somasundaram, Elanchezhian/0000-0002-0440-5238; Dillman, Jonathan/0000-0003-0124-0164				Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; Bauerle A, ARXIV190204394 PREPR; Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16; Choy G, 2018, RADIOLOGY, V288, P318, DOI 10.1148/radiol.2018171820; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; FLEISS JL, 1973, EDUC PSYCHOL MEAS, V33, P613, DOI 10.1177/001316447303300309; Gallas BD, 2006, ACAD RADIOL, V13, P353, DOI 10.1016/j.acra.2005.11.030; Gallas BD, 2007, J OPT SOC AM A, V24, pB70, DOI 10.1364/JOSAA.24.000B70; Gamer M, 2014, VARIOUS COEFFICIENTS; Gulli A., 2017, DEEP LEARNING KERAS; Hastie T., 2009, ELEMENTS STAT LEARNI, V2nd, DOI DOI 10.1007/978-0-387-21606-5; He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Karnwal A, 2008, J LARYNGOL OTOL, V122, P845, DOI 10.1017/S0022215107000497; Lin M, ARXIV13124400 PREPRI; Peirce JW, 2007, J NEUROSCI METH, V162, P8, DOI 10.1016/j.jneumeth.2006.11.017; Perez L., ARXIV171204621 PREPR; R Core Team, 2021, COMPUTER SOFTWARE; Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74; Sim J, 2005, PHYS THER, V85, P257; Sprinthall R. C., 1990, BASIC STAT ANAL; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594; Virk JS, 2012, EMERG RADIOL, V19, P255, DOI 10.1007/s10140-012-1026-3; Zhang C, ARXIV161103530 PREPR	25	2	2	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2020	2	5							e190226	10.1148/ryai.2020190226	http://dx.doi.org/10.1148/ryai.2020190226			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CY	33937841	Bronze, Green Published			2022-12-18	WOS:000826477600006
J	Yousefi, B; Katz, SI; Roshkovan, L				Yousefi, Bardia; Katz, Sharyn, I; Roshkovan, Leonid			Radiomics: A Path Forward to Predict Immunotherapy Response in Non-Small Cell Lung Cancer	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Yousefi, Bardia; Katz, Sharyn, I; Roshkovan, Leonid] Univ Penn, Dept Radiol, Perelman Sch Med, 606E Goddard Bldg,3700 Hamilton Walk, Philadelphia, PA 19104 USA	University of Pennsylvania; Pennsylvania Medicine	Yousefi, B (corresponding author), Univ Penn, Dept Radiol, Perelman Sch Med, 606E Goddard Bldg,3700 Hamilton Walk, Philadelphia, PA 19104 USA.	YousefiB@upenn.edu		Roshkovan, Leonid/0000-0002-8890-8835				[Anonymous], 2018, TEAM CANC IMM RES; Colen RR, 2018, INVEST NEW DRUG, V36, P601, DOI 10.1007/s10637-017-0524-2; Ettinger DS, 2019, J NATL COMPR CANC NE, V17, P1464, DOI 10.6004/jnccn.2019.0059; Mu W, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2019190063; Rocco D, 2019, EXPERT REV ANTICANC, V19, P561, DOI 10.1080/14737140.2019.1631800; Siegel RL, 2019, CA-CANCER J CLIN, V69, P7, DOI 10.3322/caac.21551; Sun R, 2018, LANCET ONCOL, V19, P1180, DOI 10.1016/S1470-2045(18)30413-3; Trebeschi S, 2019, ANN ONCOL, V30, P998, DOI 10.1093/annonc/mdz108; Zwanenburg A, 2020, RADIOLOGY, V295, P328, DOI 10.1148/radiol.2020191145	9	2	2	0	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2020	2	5							e200075	10.1148/ryai.2020200075	http://dx.doi.org/10.1148/ryai.2020200075			2	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CY	33939781	Green Published, Bronze			2022-12-18	WOS:000826477600010
J	Kitamura, FC; Pan, I; Kline, TL				Kitamura, Felipe C.; Pan, Ian; Kline, Timothy L.			Reproducible Artificial Intelligence Research Requires Open Communication of Complete Source Code	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Letter									[Kitamura, Felipe C.] Univ Fed Sao Paulo, Dept Diagnost Imaging, Rua Napoleao Barros 800, BR-04024002 Sao Paulo, SP, Brazil; [Pan, Ian] Brown Univ, Warren Alpert Med Sch, Providence, RI 02912 USA; [Kline, Timothy L.] Mayo Clin, Dept Radiol, Rochester, MN USA		Kitamura, FC (corresponding author), Univ Fed Sao Paulo, Dept Diagnost Imaging, Rua Napoleao Barros 800, BR-04024002 Sao Paulo, SP, Brazil.	kitamura.felipe@gmail.com	Kitamura, Felipe Campos/AAC-4368-2021; Pan, Ian/ABD-3474-2021; Kitamura, Felipe Campos/AAC-7075-2021	Pan, Ian/0000-0002-0650-6614; Kitamura, Felipe Campos/0000-0002-9992-5630				Beam AL, 2020, JAMA-J AM MED ASSOC, V323, P305, DOI 10.1001/jama.2019.20866; Mongan J, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020200029; Stojnic R., NEURIPS	3	2	2	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2020	2	4								10.1148/ryai.2020200060	http://dx.doi.org/10.1148/ryai.2020200060			1	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CX	33937836	Green Published			2022-12-18	WOS:000826472900011
J	Vogelsang, DC; Erickson, BJ				Vogelsang, David C.; Erickson, Bradley J.			Magician's Corner: 6. TensorFlow and TensorBoard	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Vogelsang, David C.; Erickson, Bradley J.] Mayo Clin, Dept Radiol, 200 First St SW, Rochester, MN 55905 USA		Erickson, BJ (corresponding author), Mayo Clin, Dept Radiol, 200 First St SW, Rochester, MN 55905 USA.	bje@mayo.edu		Erickson, Bradley/0000-0001-7926-6095				Erickson BJ, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190161; Erickson BJ, 2019, RADIOL-ARTIF INTELL, V1, DOI [10.1148/ryai.2019190072, 10.1148/ryai.2019190113, 10.1148/ryai.2019190126]; Kingma DP, ARXIV CS LG PREPRINT	3	2	2	0	3	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2020	2	3							e200012	10.1148/ryai.2020200012	http://dx.doi.org/10.1148/ryai.2020200012			3	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CW	33937828	Bronze, Green Published			2022-12-18	WOS:000826470300010
J	Sun, J; Peng, L; Li, TH; Adila, D; Zaiman, Z; Melton-Meaux, GB; Ingraham, NE; Murray, E; Boley, D; Switzer, S; Burns, JL; Huang, K; Allen, T; Steenburg, SD; Gichoya, JW; Kummerfeld, E; Tignanelli, CJ				Sun, Ju; Peng, Le; Li, Taihui; Adila, Dyah; Zaiman, Zach; Melton-Meaux, Genevieve B.; Ingraham, Nicholas E.; Murray, Eric; Boley, Daniel; Switzer, Sean; Burns, John L.; Huang, Kun; Allen, Tadashi; Steenburg, Scott D.; Gichoya, Judy Wawira; Kummerfeld, Erich; Tignanelli, Christopher J.			Performance of a Chest Radiograph AI Diagnostic Tool for COVID-19: A Prospective Observational Study	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Diagnosis; Classification; Application Domain; Infection; Lung	ARTIFICIAL-INTELLIGENCE	Purpose: To conduct a prospective observational study across 12 U.S. hospitals to evaluate real-time performance of an interpretable artificial intelligence (AI) model to detect COVID-19 on chest radiographs. Materials and Methods: A total of 95363 chest radiographs were included in model training, external validation, and real-time validation. The model was deployed as a clinical decision support system, and performance was prospectively evaluated. There were 5335 total real-time predictions and a COVID-19 prevalence of 4.8% (258 of 5335). Model performance was assessed with use of receiver operating characteristic analysis, precision-recall curves, and F1 score. Logistic regression was used to evaluate the association of race and sex with AI model diagnostic accuracy. To compare model accuracy with the performance of board-certified radiologists, a third dataset of 1638 images was read independently by two radiologists. Results: Participants positive for COVID-19 had higher COVID-19 diagnostic scores than participants negative for COVID-19 (median, 0.1 [IQR, 0.0-0.8] vs 0.0 [IQR, 0.0-0.1], respectively; P<.001). Real-time model performance was unchanged over 19 weeks of implementation (area under the receiver operating characteristic curve, 0.70; 95% CI: 0.66, 0.73). Model sensitivity was higher in men than women (P =.01), whereas model specificity was higher in women (P =.001). Sensitivity was higher for Asian (P =.002) and Black (P =.046) participants compared with White participants. The COVID-19 AI diagnostic system had worse accuracy (63.5% correct) compared with radiologist predictions (radiologist 1 = 67.8% correct, radiologist 2 = 68.6% correct; McNemar P<.001 for both). Conclusion: AI-based tools have not yet reached full diagnostic potential for COVID-19 and underperform compared with radiologist prediction. (C) RSNA, 2022	[Sun, Ju; Peng, Le; Li, Taihui; Adila, Dyah; Boley, Daniel] Univ Minnesota, Dept Comp Sci & Engn, 420 Delaware St SE, Minneapolis, MN 55455 USA; [Melton-Meaux, Genevieve B.; Kummerfeld, Erich; Tignanelli, Christopher J.] Univ Minnesota, Inst Hlth Informat, 420 Delaware St SE, Minneapolis, MN 55455 USA; [Melton-Meaux, Genevieve B.; Tignanelli, Christopher J.] Univ Minnesota, Dept Surg, 420 Delaware St SE, Minneapolis, MN 55455 USA; [Ingraham, Nicholas E.] Univ Minnesota, Dept Med, Div Pulm & Crit Care, 420 Delaware St SE, Minneapolis, MN 55455 USA; [Switzer, Sean] Univ Minnesota, Dept Med, 420 Delaware St SE, Minneapolis, MN 55455 USA; [Allen, Tadashi] Univ Minnesota, Dept Radiol, 420 Delaware St SE, Minneapolis, MN 55455 USA; [Zaiman, Zach] Emory Univ, Dept Comp Sci, Atlanta, GA 30322 USA; [Gichoya, Judy Wawira] Emory Univ, Dept Radiol, Atlanta, GA 30322 USA; [Murray, Eric] M Hlth Fairview Informat, Minneapolis, MN USA; [Burns, John L.; Huang, Kun] Indiana Univ, Sch Med, Indianapolis, IN USA; [Steenburg, Scott D.] Indiana Univ, Dept Radiol, Indianapolis, IN USA; [Tignanelli, Christopher J.] North Mem Hlth Hosp, Dept Surg, Robbinsdak, MN 55422 USA	University of Minnesota System; University of Minnesota Twin Cities; University of Minnesota System; University of Minnesota Twin Cities; University of Minnesota System; University of Minnesota Twin Cities; University of Minnesota System; University of Minnesota Twin Cities; University of Minnesota System; University of Minnesota Twin Cities; University of Minnesota System; University of Minnesota Twin Cities; Emory University; Emory University; Indiana University System; Indiana University-Purdue University Indianapolis; Indiana University System; Indiana University-Purdue University Indianapolis	Tignanelli, CJ (corresponding author), Univ Minnesota, Inst Hlth Informat, 420 Delaware St SE, Minneapolis, MN 55455 USA.; Tignanelli, CJ (corresponding author), Univ Minnesota, Dept Surg, 420 Delaware St SE, Minneapolis, MN 55455 USA.; Tignanelli, CJ (corresponding author), North Mem Hlth Hosp, Dept Surg, Robbinsdak, MN 55422 USA.	ctignane@umn.edu	; Sun, Ju/Q-1200-2015	Peng, Le/0000-0001-5728-5965; Sun, Ju/0000-0002-2017-5903; Boley, Daniel/0000-0002-2685-8449; Ingraham, Nicholas/0000-0002-0292-0594; Tignanelli, Christopher/0000-0002-8079-5565; Li, Taihui/0000-0002-3758-8923	Agency for Healthcare Research and Quality (AHRQ) [K12HS026379]; Patient-Centered Outcomes Research Institute (PCORI) [K12HS026379]; National Institutes of Health (NIH) National Center for Advancing Translational Sciences [KL2TR002492, UL1TR002494]; NIH National Heart, Lung, and Blood Institute [T32HL07741]; NIH National Institute of Biomedical Imaging and Bioengineering [75N92020D00018/75N92020F00001]; National Institute of Biomedical Imaging and Bioengineering MIDRC grant of the National Institutes of Health [75N92020C00008, 75N92020C00021]; U.S. National Science Foundation from the Division of Electrical, Communication and Cyber Systems [1928481]; University of Minnesota Office of the Vice President of Research (OVPR) COVID-19 Impact Grant	Agency for Healthcare Research and Quality (AHRQ)(United States Department of Health & Human ServicesAgency for Healthcare Research & Quality); Patient-Centered Outcomes Research Institute (PCORI)(Patient-Centered Outcomes Research Institute - PCORI); National Institutes of Health (NIH) National Center for Advancing Translational Sciences; NIH National Heart, Lung, and Blood Institute(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Heart Lung & Blood Institute (NHLBI)); NIH National Institute of Biomedical Imaging and Bioengineering(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB)); National Institute of Biomedical Imaging and Bioengineering MIDRC grant of the National Institutes of Health; U.S. National Science Foundation from the Division of Electrical, Communication and Cyber Systems; University of Minnesota Office of the Vice President of Research (OVPR) COVID-19 Impact Grant	Supported by the Agency for Healthcare Research and Quality (AHRQ) and Patient-Centered Outcomes Research Institute (PCORI), grant K12HS026379 (C.J.T.); the National Institutes of Health (NIH) National Center for Advancing Translational Sciences, grants KL2TR002492 (C.J.T.) and UL1TR002494 (E.K.); NIH National Heart, Lung, and Blood Institute, grant T32HL07741 (N.E.I.); NIH National Institute of Biomedical Imaging and Bioengineering, grants 75N92020D00018/75N92020F00001 (J.W.G.); National Institute of Biomedical Imaging and Bioengineering MIDRC grant of the National Institutes of Health under contracts 75N92020C00008 and 75N92020C00021 (Z.Z., J.W.G.); U.S. National Science Foundation #1928481 from the Division of Electrical, Communication and Cyber Systems (J.W.G.); and the University of Minnesota Office of the Vice President of Research (OVPR) COVID-19 Impact Grant (J.S., E.K., C.J.T.).	A. J.DeGrave, 2020, medRxiv, DOI 10.1101/2020.09.13.20193565; Amara Tariq, 2020, Arxiv, DOI arXiv:2006.13262; [Anonymous], COVID 19 CHEST XRAY; [Anonymous], OPEN I OPEN ACCESS B; Bujang MA, 2016, J CLIN DIAGN RES, V10, pYE1, DOI 10.7860/JCDR/2016/18129.8744; Carlile M, 2020, JACEP OPEN, V1, P1459, DOI 10.1002/emp2.12297; Carmo D, 2021, HEALTH INFORM J, V27, DOI 10.1177/14604582211033017; Centers for Disease Control and Prevention, 2020, INT GUID COLL HAND T; de la Iglesia Vaya M., 2020, ARXIV; Guglielmi G, 2021, NATURE, V590, P202, DOI 10.1038/d41586-021-00332-4; Huang SG, 2021, INT J BIOL SCI, V17, P1581, DOI 10.7150/ijbs.58855; Ingraham NE, 2021, J GEN INTERN MED, V36, P3462, DOI 10.1007/s11606-021-06790-w; Ingraham NE, 2020, EUR RESPIR J, V56, DOI 10.1183/13993003.00912-2020; Johnson AEW, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0322-0; Joseph NP, 2020, RADIOLOGY, V297, pE303, DOI 10.1148/radiol.2020202602; Kortela E, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0251661; Mackey K, 2021, ANN INTERN MED, V174, P362, DOI 10.7326/M20-6306; McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996; MIDRC, US; Roberts M, 2021, NAT MACH INTELL, V3, P199, DOI 10.1038/s42256-021-00307-0; Sahoo HS, 2021, JAMIA OPEN, V4, DOI 10.1093/jamiaopen/ooab070; Shamsoddin Erfan, 2020, Evid Based Dent, V21, P84, DOI 10.1038/s41432-020-0115-5; Wang B, 2021, APPL SOFT COMPUT, V98, DOI 10.1016/j.asoc.2020.106897; White DB, 2020, JAMA-J AM MED ASSOC, V323, P1773, DOI 10.1001/jama.2020.5046; Woloshin S, 2020, NEW ENGL J MED, V383, DOI 10.1056/NEJMp2015897; Wynants L, 2020, BMJ-BRIT MED J, V369, DOI 10.1136/bmj.m1328; YOUDEN WJ, 1950, CANCER-AM CANCER SOC, V3, P32, DOI 10.1002/1097-0142(1950)3:1<32::AID-CNCR2820030106>3.0.CO;2-3	27	1	1	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2022	4	4							e210217	10.1148/ryai.210217	http://dx.doi.org/10.1148/ryai.210217			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	3B4GB	35923381	Green Published			2022-12-18	WOS:000827900000003
J	Yan, A; McAuley, J; Lu, X; Du, J; Chang, EY; Gentili, A; Hsu, CN				Yan, An; McAuley, Julian; Lu, Xing; Du, Jiang; Chang, Eric Y.; Gentili, Amilcare; Hsu, Chun-Nan			RadBERT: Adapting Transformer-based Language Models to Radiology	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Translation; Unsupervised Learning; Transfer Learning; Neural Networks; Informatics		Purpose: To investigate if tailoring a transformer-based language model to radiology is beneficial for radiology natural language processing (NLP) applications. Materials and Methods: This retrospective study presents a family of bidirectional encoder representations from transformers (BERT)based language models adapted for radiology, named RadBERT. Transformers were pretrained with either 2.16 or 4.42 million radiology reports from U.S. Department of Veterans Affairs health care systems nationwide on top of four different initializations (BERTbase, Clinical-BERT, robustly optimized BERT pretraining approach [RoBERTa], and BioMed-RoBERTa) to create six variants of RadBERT. Each variant was fine-tuned for three representative NLP tasks in radiology: (a) abnormal sentence classification: models classified sentences in radiology reports as reporting abnormal or normal findings; (b) report coding: models assigned a diagnostic code to a given radiology report for five coding systems; and (c) report summarization: given the findings section of a radiology report, models selected key sentences that summarized the findings. Model performance was compared by bootstrap resampling with five intensively studied transformer language models as baselines: BERT-base, BioBERT, Clinical-BERT, BlueBERT, and BioMed-RoBERTa. Results: For abnormal sentence classification, all models performed well (accuracies above 97.5 and F1 scores above 95.0). RadBERT variants achieved significantly higher scores than corresponding baselines when given only 10% or less of 12458 annotated training sentences. For report coding, all variants outperformed baselines significantly for all five coding systems. The variant RadBERT-BioMed-RoBERTa performed the best among all models for report summarization, achieving a Recall-Oriented Understudy for Gisting Evaluation-1 score of 16.18 compared with 15.27 by the corresponding baseline (BioMed-RoBERTa, P<.004). Conclusion: Transformer-based language models tailored to radiology had improved performance of radiology NLP tasks compared with baseline transformer language models. (C) RSNA, 2022	[Yan, An; McAuley, Julian; Lu, Xing; Du, Jiang; Chang, Eric Y.; Gentili, Amilcare; Hsu, Chun-Nan] Univ Calif San Diego, 9500 Gilman Dr, La Jolla, CA 92093 USA; [Chang, Eric Y.; Gentili, Amilcare] Vet Affairs San Diego Healthcare Syst, San Diego, CA USA	University of California System; University of California San Diego; US Department of Veterans Affairs; Veterans Health Administration (VHA); VA San Diego Healthcare System	Hsu, CN (corresponding author), Univ Calif San Diego, 9500 Gilman Dr, La Jolla, CA 92093 USA.	chunnan@ucsd.edu			Accelerating Innovation in Military Medicine Program, Office of the Assistant Secretary of Defense for Health Affairs, Department of Defense [W81XWH-20-1-0693, DM190543]; National Science Foundation [1750063]	Accelerating Innovation in Military Medicine Program, Office of the Assistant Secretary of Defense for Health Affairs, Department of Defense; National Science Foundation(National Science Foundation (NSF))	Supported by award no. W81XWH-20-1-0693, log no. DM190543, Accelerating Innovation in Military Medicine Program, Office of the Assistant Secretary of Defense for Health Affairs, Department of Defense; and Career Award no. 1750063, National Science Foundation.	Amilcare Gentili, 2020, Arxiv, DOI arXiv:2010.02467; Chen MC, 2018, RADIOLOGY, V286, P845, DOI 10.1148/radiol.2017171115; Danqi Chen, 2019, Arxiv, DOI arXiv:1907.11692; Demner-Fushman D, 2016, J AM MED INFORM ASSN, V23, P304, DOI 10.1093/jamia/ocv080; Derek Miller, 2019, Arxiv, DOI arXiv:1906.04165; Di Jin, 2019, Arxiv, DOI arXiv:1904.03323; Fiorini N, 2018, NAT BIOTECHNOL, V36, P937, DOI 10.1038/nbt.4267; Francine Chen, 2019, Arxiv, DOI arXiv:1908.02123; Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215; Greg Corrado, 2013, Arxiv, DOI arXiv:1301.3781; Gururangan S., 2020, ARXIV; Jacob Devlin, 2019, Arxiv, DOI arXiv:1810.04805; Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35; Kingma DP., 2014, ARXIV; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lin C.-Y., 2004, TEXT SUMMARIZATION B, P74, DOI DOI 10.3115/V1/D14-1020; Neamatullah I, 2008, BMC MED INFORM DECIS, V8, DOI 10.1186/1472-6947-8-32; Prodigy, 2017, RADICALLY EFFICIENT; Raffel C, 2020, J MACH LEARN RES, V21; Shankai Yan, 2019, Arxiv, DOI arXiv:1906.05474; Smith L, 2008, GENOME BIOL, V9, DOI 10.1186/gb-2008-9-S2-S2; VA Office of Information and Technology, 2021, VA TECHNICAL REFEREN; Vaswani A., 2017, ADV NEURAL INFORM PR, V30; Yan A, 2021, ARXIV; Zhifeng Chen, 2016, ARXIV	26	1	1	3	3	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2022	4	4							e210258	10.1148/ryai.210258	http://dx.doi.org/10.1148/ryai.210258			11	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	3B4GB	35923376	Green Published			2022-12-18	WOS:000827900000004
J	Rouzrokh, P; Wyles, CC; Kurian, SJ; Ramazanian, T; Cai, JC; Huang, Q; Zhang, K; Taunton, MJ; Kremers, HM; Erickson, BJ				Rouzrokh, Pouria; Wyles, Cody C.; Kurian, Shyam J.; Ramazanian, Taghi; Cai, Jason C.; Huang, Qiao; Zhang, Kuan; Taunton, Michael J.; Kremers, Hilal Maradit; Erickson, Bradley J.			Deep Learning for Radiographic Measurement of Femoral Component Subsidence Following Total Hip Arthroplasty	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Total Hip Arthroplasty; Femoral Component Subsidence; Artificial Intelligence; Deep Learning; Semantic Segmentation; Hip; Joints	STEM	Femoral component subsidence following total hip arthroplasty (THA) is a worrisome radiographic finding. This study developed and evaluated a deep learning tool to automatically quantify femoral component subsidence between two serial anteroposterior (AP) hip radiographs. The authors' institutional arthroplasty registry was used to retrospectively identify patients who underwent primary THA from 2000 to 2020. A deep learning dynamic U-Net model was trained to automatically segment femur, implant, and magnification markers on a dataset of 500 randomly selected AP hip radiographs from 386 patients with polished tapered cemented femoral stems. An image processing algorithm was then developed to measure subsidence by automatically annotating reference points on the femur and implant, calibrating that with respect to magnification markers. Algorithm and manual subsidence measurements by two independent orthopedic surgeon reviewers in 135 randomly selected patients were compared. The mean, median, and SD of measurement discrepancy between the automatic and manual measurements were 0.6, 0.3, and 0.7 mm, respectively, and did not demonstrate a systematic tendency between human and machine. Automatic and manual measurements were strongly correlated and showed no evidence of significant differences. In contrast to the manual approach, the deep learning tool needs no user input to perform subsidence measurements. Supplemental material is available for this article. (C) RSNA, 2022.	[Rouzrokh, Pouria; Cai, Jason C.; Huang, Qiao; Zhang, Kuan; Erickson, Bradley J.] Mayo Clin, Dept Radiol, Radiol Informat Lab, 200 First St SW, Rochester, MN 55905 USA; [Wyles, Cody C.; Ramazanian, Taghi; Taunton, Michael J.; Kremers, Hilal Maradit] Mayo Clin, Dept Hlth Sci Res, 200 First St SW, Rochester, MN 55905 USA; [Wyles, Cody C.; Ramazanian, Taghi; Taunton, Michael J.; Kremers, Hilal Maradit] Mayo Clin, Dept Orthoped Surg, 200 First St SW, Rochester, MN 55905 USA; [Wyles, Cody C.] Mayo Clin, Dept Clin Anat, 200 First St SW, Rochester, MN 55905 USA; [Kurian, Shyam J.] Mayo Clin, Alix Sch Med, 200 First St SW, Rochester, MN 55905 USA	Mayo Clinic; Mayo Clinic; Mayo Clinic; Mayo Clinic; Mayo Clinic	Kremers, HM (corresponding author), Mayo Clin, Dept Hlth Sci Res, 200 First St SW, Rochester, MN 55905 USA.; Kremers, HM (corresponding author), Mayo Clin, Dept Orthoped Surg, 200 First St SW, Rochester, MN 55905 USA.	maradit@mayo.edu		Maradit Kremers, Hilal/0000-0003-3882-602X; Erickson, Bradley/0000-0001-7926-6095; Wyles, Cody/0000-0002-8629-7567; Rouzrokh, Pouria/0000-0003-4664-0751; Huang, Qiao/0000-0002-9044-2464	Mayo Foundation Presidential Fund; National Institutes of Health [R01AR73147, P30AR76312]	Mayo Foundation Presidential Fund; National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	Supported by the Mayo Foundation Presidential Fund and the National Institutes of Health (grants R01AR73147 and P30AR76312).	Al-Najjim M, 2016, J ORTHOP, V13, P322, DOI 10.1016/j.jor.2016.06.026; Borjali A, 2022, Arxiv, DOI arXiv:1912.00943; [Anonymous], 1999, 10153 BS EN; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Enhua Wu, 2019, Arxiv, DOI arXiv:1709.01507; Ilchmann T, 2006, UPSALA J MED SCI, V111, P361, DOI 10.3109/2000-1967-062; Karachalios T, 2018, EFORT OPEN REV, V3, P232, DOI 10.1302/2058-5241.3.170068; KARRHOLM J, 1994, J BONE JOINT SURG BR, V76B, P912, DOI 10.1302/0301-620X.76B6.7983118; Krismer M, 1999, J BONE JOINT SURG BR, V81B, P273, DOI 10.1302/0301-620X.81B2.8840; Ries C, 2019, INT ORTHOP, V43, P307, DOI 10.1007/s00264-018-4020-x; Rouzrokh P, 2021, J ARTHROPLASTY, V36, P2510, DOI 10.1016/j.arth.2021.02.026; Schutz Uwe, 2005, Acta Orthop Belg, V71, P65; Springer BD, 2009, CLIN ORTHOP RELAT R, V467, P166, DOI 10.1007/s11999-008-0566-z; Sudhahar TA, 2009, J ORTHOP, V6, P3; Yakubovskiy P., 2020, SEGMENTATION MODELS; Yates PJ, 2008, J BONE JOINT SURG BR, V90B, P16, DOI 10.1302/0301-620X.90B1.19546	16	1	1	3	3	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2022	4	3							e210206	10.1148/ryai.210206	http://dx.doi.org/10.1148/ryai.210206			6	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9YQ	35652119	Green Published			2022-12-18	WOS:000826924200006
J	Ye, ZZ; Qian, JM; Hosny, A; Zeleznik, R; Plana, D; Likitlersuang, J; Zhang, ZY; Mak, RH; Aerts, HJWL; Kann, BH				Ye, Zezhong; Qian, Jack M.; Hosny, Ahmed; Zeleznik, Roman; Plana, Deborah; Likitlersuang, Jirapat; Zhang, Zhongyi; Mak, Raymond H.; Aerts, Hugo J. W. L.; Kann, Benjamin H.			Deep Learning-based Detection of Intravenous Contrast Enhancement on CT Scans	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						CT; Head and Neck; Supervised Learning; Transfer Learning; Convolutional Neural Network (CNN); Machine Learning Algorithms; Contrast Material		Identifying the presence of intravenous contrast material on CT scans is an important component of data curation for medical imaging-based artificial intelligence model development and deployment. Use of intravenous contrast material is often poorly documented in imaging metadata, necessitating impractical manual annotation by clinician experts. Authors developed a convolutional neural network (CNN)-based deep learning platform to identify intravenous contrast enhancement on CT scans. For model development and validation, authors used six independent datasets of head and neck (HN) and chest CT scans, totaling 133 480 axial two-dimensional sections from 1979 scans, which were manually annotated by clinical experts. Five CNN models were trained first on HN scans for contrast enhancement detection. Model performances were evaluated at the patient level on a holdout set and external test set. Models were then fine-tuned on chest CT data and externally validated. This study found that Digital Imaging and Communications in Medicine metadata tags for intravenous contrast material were missing or erroneous for 1496 scans (75.6%). An EfficientNetB4-based model showed the best performance, with areas under the curve (AUCs) of 0.996 and 1.0 in HN holdout (n = 216) and external (n = 595) sets, respectively, and AUCs of 1.0 and 0.980 in the chest holdout (n = 53) and external (n = 402) sets, respectively. This automated, scan-to-prediction platform is highly accurate at CT contrast enhancement detection and may be helpful for artificial intelligence model development and clinical application. Supplemental material is available for this article. (C) RSNA, 2022.	[Ye, Zezhong; Qian, Jack M.; Hosny, Ahmed; Zeleznik, Roman; Plana, Deborah; Likitlersuang, Jirapat; Zhang, Zhongyi; Mak, Raymond H.; Aerts, Hugo J. W. L.; Kann, Benjamin H.] Harvard Med Sch, Artificial Intelligence Med Program, Mass Gen Brigham, Boston, MA 02115 USA; [Ye, Zezhong; Qian, Jack M.; Hosny, Ahmed; Zeleznik, Roman; Likitlersuang, Jirapat; Zhang, Zhongyi; Mak, Raymond H.; Aerts, Hugo J. W. L.; Kann, Benjamin H.] Harvard Med Sch, Brigham & Womens Hosp, Dana Farber Canc Inst, Dept Radiat Oncol, 75 Francis St, Boston, MA 02113 USA; [Aerts, Hugo J. W. L.] Harvard Med Sch, Brigham & Womens Hosp, Dana Farber Canc Inst, Dept Radiol, 75 Francis St, Boston, MA 02113 USA; [Plana, Deborah] Harvard Mit Div Hlth Sci & Technol, Cambridge, MA USA; [Aerts, Hugo J. W. L.] Maastricht Univ, Dept Radiol & Nucl Med, Sch Cardiovasc Dis CARIM, Maastricht, Netherlands; [Aerts, Hugo J. W. L.] Maastricht Univ, Sch Oncol & Reprod GROW, Maastricht, Netherlands	Harvard University; Harvard Medical School; Harvard University; Brigham & Women's Hospital; Dana-Farber Cancer Institute; Harvard Medical School; Harvard University; Brigham & Women's Hospital; Dana-Farber Cancer Institute; Harvard Medical School; Harvard University; Maastricht University; Maastricht University	Kann, BH (corresponding author), Harvard Med Sch, Artificial Intelligence Med Program, Mass Gen Brigham, Boston, MA 02115 USA.; Kann, BH (corresponding author), Harvard Med Sch, Brigham & Womens Hosp, Dana Farber Canc Inst, Dept Radiat Oncol, 75 Francis St, Boston, MA 02113 USA.	Benjamin_Kann@dfci.harvard.edu	Zhang, Zhongyi/ABB-5613-2022	Zhang, Zhongyi/0000-0002-0851-9953; Kann, Benjamin/0000-0002-4313-2754; Qian, Jack/0000-0002-9522-6445; Mak, Raymond/0000-0002-8754-0565	National Institutes of Health [NIH-USA U24CA194354, NIH-USA U01CA190234, NIH-USA U01CA209414, NIH-USA R35CA22052, NIH-K08:DE030216]; European Union-European Research Council [866504]; Radiological Society of North America [RSCH2017]; National Institute of General Medical Sciences [T32-GM007753]	National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); European Union-European Research Council(European Research Council (ERC)European Commission); Radiological Society of North America; National Institute of General Medical Sciences(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of General Medical Sciences (NIGMS))	Supported by the National Institutes of Health (H.J.W.L.A.: NIH-USA U24CA194354, NIH-USA U01CA190234, NIH-USA U01CA209414, and NIH-USA R35CA22052; B.H.K.: NIH-K08:DE030216), the European Union-European Research Council (H.J.W.L.A.: 866504), the Radiological Society of North America (B.H.K.: RSCH2017), and the National Institute of General Medical Sciences (D.P.: T32-GM007753).	Bi WL, 2019, CA-CANCER J CLIN, V69, P127, DOI 10.3322/caac.21552; Bradley J, 2018, DATA NSCLC CETUXIMAB; Criminisi A, 2011, LECT NOTES COMPUT SC, V6893, P49, DOI 10.1007/978-3-642-23626-6_7; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Grossberg A, 2020, HNSCC DATASET; Gueld MO, 2002, P SPIE MEDICAL IMAGI, V4685; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He L, 2016, SCI REP-UK, V6, DOI 10.1038/srep34921; Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5; Kakino R, 2020, PHYS MEDICA, V69, P176, DOI 10.1016/j.ejmp.2019.12.019; Kallman HE, 2009, ACTA ONCOL, V48, P285, DOI 10.1080/02841860802258786; Kwan JYY, 2019, CANC IMAGING ARCHIVE; Lartaud PJ, 2019, LECT NOTES COMPUT SC, V11765, P768, DOI 10.1007/978-3-030-32245-8_85; Philbrick KA, 2018, AM J ROENTGENOL, V211, P1184, DOI 10.2214/AJR.18.20331; Sofka M, 2011, LECT NOTES COMPUT SC, V6893, P166, DOI 10.1007/978-3-642-23626-6_21; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Tan MX, 2019, PR MACH LEARN RES, V97; Tang Y., 2020, P SPIE MEDICAL IMAGI, V11313; Vallieres, 2017, DATA HEAD NECK PET C; Willemink MJ, 2020, RADIOLOGY, V295, P4, DOI 10.1148/radiol.2020192224	20	1	1	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2022	4	3							e210285	10.1148/ryai.210285	http://dx.doi.org/10.1148/ryai.210285			7	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9YQ	35652117	Green Published			2022-12-18	WOS:000826924200007
J	Garbin, C; Marques, O				Garbin, Christian; Marques, Oge			Assessing Methods and Tools to Improve Reporting, Increase Transparency, and Reduce Failures in Machine Learning Applications in Health Care	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Artificial Intelligence; Machine Learning; Lifecycle; Auditing; Transparency; Failures; Datasheets; Datasets; Model Cards		Artificial intelligence applications for health care have come a long way. Despite the remarkable progress, there are several examples of unfulfilled promises and outright failures. There is still a struggle to translate successful research into successful real-world applications. Machine learning (ML) products diverge from traditional software products in fundamental ways. Particularly, the main component of an ML solution is not a specific piece of code that is written for a specific purpose; rather, it is a generic piece of code, a model, customized by a training process driven by hyperparameters and a dataset. Datasets are usually large, and models are opaque. Therefore, datasets and models cannot be inspected in the same, direct way as traditional software products. Other methods are needed to detect failures in ML products. This report investigates recent advancements that promote auditing, supported by transparency, as a mechanism to detect potential failures in ML products for health care applications. It reviews practices that apply to the early stages of the ML lifecycle, when datasets and models are created; these stages are unique to ML products. Concretely, this report demonstrates how two recently proposed checklists, datasheets for datasets and model cards, can be adopted to increase the transparency of crucial stages of the ML lifecycle, using ChestX-ray8 and CheXNet as examples. The adoption of checklists to document the strengths, limitations, and applications of datasets and models in a structured format leads to increased transparency, allowing early detection of potential problems and opportunities for improvement. (C) RSNA, 2022	[Garbin, Christian; Marques, Oge] Florida Atlantic Univ, Coll Engn & Comp Sci, 777 Glades Rd,EE441, Boca Raton, FL 33431 USA	State University System of Florida; Florida Atlantic University	Marques, O (corresponding author), Florida Atlantic Univ, Coll Engn & Comp Sci, 777 Glades Rd,EE441, Boca Raton, FL 33431 USA.	omarques@fau.edu						Aarti Bagul, 2017, Arxiv, DOI arXiv:1711.05225; Amershi S, 2019, 2019 IEEE/ACM 41ST INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN PRACTICE (ICSE-SEIP 2019), P291, DOI 10.1109/ICSE-SEIP.2019.00042; Andrew Y. Ng, 2019, Arxiv, DOI arXiv:1901.07031; Baltruschat IM, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-42294-8; Bluemke DA, 2020, RADIOLOGY, V294, P487, DOI 10.1148/radiol.2019192515; Breck E, 2017, IEEE INT CONF BIG DA, P1123; Brundage M., 2020, ARXIV; Garbin C, 2021, Arxiv, DOI arXiv:2105.03020; CONSORT, CONSORT 2010 FLOWD; FAT/ML, PRINC ACC ALG SOC IM; Food and Drug Administration, CODE FEDERAL REGULAT; Garbin C., 2020, DISSERTATION; International Eletrotechnical Commission, 62304 2006 MED DEV S; Merriam-Webster, TRANSPARENT; Mitchell M, 2019, FAT 19 C FAIRNESS AC; Mongan J, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020200029; National Institutes of Health, NIH CLIN CTR PROV ON; Oakden-Rayner L, EXPLORING CHESTXRAY1; Oakden-Rayner L, QUICK THOUGHTS CHEST; Oakden-Rayner L., CHEXNET IN DEPTH REV; Obermeyer Z, 2019, SCIENCE, V366, P447, DOI 10.1126/science.aax2342; Raji ID, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P33, DOI 10.1145/3351095.3372873; Sambasivan N., 2021, P 2021 CHI C HUM FAC; Sendak MP, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0253-3; Summers R., 2017, CHESTX RAY8; Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369	28	1	1	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2022	4	2							e210127	10.1148/ryai.210127	http://dx.doi.org/10.1148/ryai.210127			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9YB	35391771	Green Published			2022-12-18	WOS:000826922700008
J	Goel, A; Shih, G; Riyahi, S; Jeph, S; Dev, H; Hu, R; Romano, D; Teichman, K; Blumenfeld, JD; Barash, I; Chicos, I; Rennert, H; Prince, MR				Goel, Akshay; Shih, George; Riyahi, Sadjad; Jeph, Sunil; Dev, Hreedi; Hu, Rejoice; Romano, Dominick; Teichman, Kurt; Blumenfeld, Jon D.; Barash, Irina; Chicos, Ines; Rennert, Hanna; Prince, Martin R.			Deployed Deep Learning Kidney Segmentation for Polycystic Kidney Disease MRI	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Convolutional Neural Network (CNN); Segmentation; Kidney	VOLUME; PROGRESSION; GROWTH; ADPKD	This study develops, validates, and deploys deep learning for automated total kidney volume (TKV) measurement (a marker of disease severity) on T2-weighted MRI studies of autosomal dominant polycystic kidney disease (ADPKD). The model was based on the U-Net architecture with an EfficientNet encoder, developed using 213 abdominal MRI studies in 129 patients with ADPKD. Patients were randomly divided into 70% training, 15% validation, and 15% test sets for model development. Model performance was assessed using Dice similarity coefficient (DSC) and Bland-Altman analysis. External validation in 20 patients from outside institutions demonstrated a DSC of 0.98 (IQR, 0.97-0.99) and a Bland-Altman difference of 2.6% (95% CI: 1.0%, 4.1%). Prospective validation in 53 patients demonstrated a DSC of 0.97 (IQR, 0.94-0.98) and a Bland-Altman difference of 3.6% (95% CI: 2.0%, 5.2%). Last, the efficiency of model-assisted annotation was evaluated on the first 50% of prospective cases (n = 28), with a 51% mean reduction in contouring time (P < .001), from 1724 seconds (95% CI: 1373, 2075) to 723 seconds (95% CI: 555, 892). In conclusion, our deployed artificial intelligence pipeline accurately performs automated segmentation for TKV estimation of polycystic kidneys and reduces expert contouring time. (C)RSNA, 2022	[Goel, Akshay; Shih, George; Riyahi, Sadjad; Jeph, Sunil; Dev, Hreedi; Hu, Rejoice; Romano, Dominick; Teichman, Kurt; Prince, Martin R.] Weill Cornell Med, Dept Radiol, 525 E 68th St, New York, NY 10021 USA; [Blumenfeld, Jon D.; Barash, Irina; Chicos, Ines] Weill Cornell Med, Dept Internal Med, 525 E 68th St, New York, NY 10021 USA; [Rennert, Hanna] Weill Cornell Med, Dept Pathol & Lab Med, 525 E 68th St, New York, NY 10021 USA	Cornell University; Cornell University; Cornell University	Goel, A (corresponding author), Weill Cornell Med, Dept Radiol, 525 E 68th St, New York, NY 10021 USA.	akg9006@med.cornell.edu		Dev, Hreedi/0000-0002-5341-8350; Goel, Akshay/0000-0003-4833-9356; Riyahi-Alam, Sadjad/0000-0002-7212-223X; Romano, Dominick/0000-0002-8691-406X; Shih, George/0000-0002-8356-2011	Weill Cornell Medicine Clinical & Translational Science Center; Shaw Foundation	Weill Cornell Medicine Clinical & Translational Science Center; Shaw Foundation	Supported by the Weill Cornell Medicine Clinical & Translational Science Center and the Shaw Foundation.	Brett M, 2016, NIBABEL 2 1 0 ZENODO; Buslaev A, 2020, INFORMATION, V11, DOI 10.3390/info11020125; Chapman AB, 2003, KIDNEY INT, V64, P1035, DOI 10.1046/j.1523-1755.2003.00185.x; Chapman AB, 2015, KIDNEY INT, V88, P17, DOI 10.1038/ki.2015.59; Conze PH, 2021, ARTIF INTELL MED, V117, DOI 10.1016/j.artmed.2021.102109; Fick-Brosnahan GM, 2002, AM J KIDNEY DIS, V39, P1127, DOI 10.1053/ajkd.2002.33379; Fourdan O, 2000, P 4 ANN LINUX SHOWCA; Ge CJ, 2020, BMC MED IMAGING, V20, DOI 10.1186/s12880-020-00485-0; Goel A, 2021, ADPKD SEGMENTATION P; Grantham JJ, 2006, CLIN J AM SOC NEPHRO, V1, P148, DOI 10.2215/CJN.00330705; Higashihara E, 2015, NEPHRON, V129, P253, DOI 10.1159/000381476; Irazabal MV, 2015, J AM SOC NEPHROL, V26, P160, DOI 10.1681/ASN.2013101138; Kistler AD, 2009, KIDNEY INT, V75, P235, DOI 10.1038/ki.2008.558; Kline TL, 2017, J DIGIT IMAGING, V30, P442, DOI 10.1007/s10278-017-9978-1; Lin YC, 2020, EUR RADIOL, V30, P1297, DOI 10.1007/s00330-019-06467-3; Mongan J, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020200029; Paszke A, 2019, ARXIV; SEDMAN A, 1987, KIDNEY INT, V31, P1000, DOI 10.1038/ki.1987.98; Sharma K, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-01779-0; Siddique N, 2021, PROC SPIE, V11735, DOI 10.1117/12.2591343; Tan M X, ARXIV; Torres VE, 2012, NEW ENGL J MED, V367, P2407, DOI 10.1056/NEJMoa1205511; Yakubovskiy P., 2020, GITHUB REPOS; Yu ASL, 2018, KIDNEY INT, V93, P691, DOI 10.1016/j.kint.2017.09.027; Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015	27	1	1	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2022	4	2							e210205	10.1148/ryai.210205	http://dx.doi.org/10.1148/ryai.210205			7	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9YB	35391774	Green Published			2022-12-18	WOS:000826922700015
J	Hahn, LD; Hall, K; Alebdi, T; Kligerman, SJ; Hsiao, A				Hahn, Lewis D.; Hall, Kent; Alebdi, Thamer; Kligerman, Seth J.; Hsiao, Albert			Automated Deep Learning Analysis for Quality Improvement of CT Pulmonary Angiography	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						CT Angiography; Pulmonary Arteries	IMAGE QUALITY; SEGMENTATION; ARTERY	CT pulmonary angiography (CTPA) is the first-line imaging test for evaluation of acute pulmonary emboli. However, diagnostic quality is heterogeneous across institutions and is frequently limited by suboptimal pulmonary artery (PA) contrast enhancement. In this retrospective study, a deep learning algorithm for measuring enhancement of the central PAs was developed and assessed for feasibility of its use in quality improvement of CTPA. In a convenience sample of 450 patients, automated measurement of CTPA enhancement showed high agreement with manual radiologist measurement (r = 0.996). Using a threshold of less than 250 HU for suboptimal enhancement, the sensitivity and specificity of the automated classification were 100% and 99.5%, respectively. The algorithm was further evaluated in a random sampling of 3195 CTPA examinations from January 2019 through May 2021. Beginning in January 2021, the scanning protocol was transitioned from bolus tracking to a timing bolus strategy. Automated analysis of these examinations showed that most suboptimal examinations following the change in protocol were performed using one scanner, highlighting the potential value of deep learning algorithms for quality improvement in the radiology department. (C)RSNA, 2022	[Hahn, Lewis D.; Alebdi, Thamer; Kligerman, Seth J.; Hsiao, Albert] Univ Calif San Diego, Dept Radiol, Sch Med, 9300 Campus Point Dr,MC 0841, La Jolla, CA 92037 USA; [Hall, Kent] Naval Hosp Camp Pendleton, Oceanside, CA USA	University of California System; University of California San Diego	Hahn, LD (corresponding author), Univ Calif San Diego, Dept Radiol, Sch Med, 9300 Campus Point Dr,MC 0841, La Jolla, CA 92037 USA.	Lebahn@health.ucsd.edu		Hsiao, Albert/0000-0002-9412-1369; Hahn, Lewis/0000-0003-0468-9442	UCSD Health Sciences Research Award [RG100830]	UCSD Health Sciences Research Award	Supported by UCSD Health Sciences Research Award RG100830.	Bae KT, 2007, RADIOLOGY, V242, P582, DOI 10.1148/radiol.2422052132; Bates DDB, 2016, EMERG RADIOL, V23, P603, DOI 10.1007/s10140-016-1425-y; Ch ol I., 2020, IMAGE SEGMENTATION U; Chen EL, 2017, J AM COLL RADIOL, V14, P648, DOI [10.1016/j.jacr.2016.11.007, 10.1016/j.jacr.201611.007]; Hahn Lewis D, 2020, Radiol Cardiothorac Imaging, V2, pe190179, DOI 10.1148/ryct.2020190179; Jones SE, 2005, RADIOLOGY, V237, P329, DOI 10.1148/radiol.2371041520; Kim C, 2017, MEDICINE, V96, DOI 10.1097/MD.0000000000009099; Lazarus MS, 2021, J NUCL MED, V62, P399, DOI 10.2967/jnumed.120.242776; Linguraru MG, 2010, MED PHYS, V37, P1522, DOI 10.1118/1.3355892; Roman KLL, 2018, LECT NOTES COMPUT SC, V11040, P225, DOI 10.1007/978-3-030-00946-5_23; Megyeri B, 2015, CLIN RADIOL, V70, P54, DOI 10.1016/j.crad.2014.09.014; Moses D, 2016, INT J COMPUT ASS RAD, V11, P381, DOI 10.1007/s11548-015-1265-3; Wittram C, 2007, AM J ROENTGENOL, V188, P1255, DOI 10.2214/AJR.06.1104; Zhao FJ, 2019, MULTIMEDIA SYST, V25, P109, DOI 10.1007/s00530-017-0580-7	14	1	1	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2022	4	2							e210162	10.1148/ryai.210162	http://dx.doi.org/10.1148/ryai.210162			6	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9YB	35391776	Green Published			2022-12-18	WOS:000826922700010
J	Macruz, FBD; Lu, C; Strout, J; Takigami, A; Brooks, R; Doyle, S; Yun, M; Buch, V; Hedgire, S; Ghoshhajra, B				Macruz, Fabiola Bezerra de Carvalho; Lu, Charles; Strout, Julia; Takigami, Angelo; Brooks, Rupert; Doyle, Sean; Yun, Min; Buch, Varun; Hedgire, Sandeep; Ghoshhajra, Brian			Quantification of the Thoracic Aorta and Detection of Aneurysm at CT: Development and Validation of a Fully Automatic Methodology	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Aorta; Convolutional Neural Network; Machine Learning; CT; Thorax; Aneurysms	DIAMETER MEASUREMENTS; COMPUTED-TOMOGRAPHY; SEGMENTATION; ANGIOGRAPHY	Purpose: To develop and validate a deep learning-based system that predicts the largest ascending and descending aortic diameters at chest CT through automatic thoracic aortic segmentation and identifies aneurysms in each segment. Materials and Methods: In this retrospective study conducted from July 2019 to February 2021, a U-Net and a postprocessing algorithm for thoracic aortic segmentation and measurement were developed by using a dataset (dataset A) that included 315 CT studies split into training, hyperparameter-tuning, and testing sets. The U-Net and postprocessing algorithm were associated with a Digital Imaging and Communications in Medicine series filter and visualization interface and were further validated by using a dataset (dataset B) that included 1400 routine CT studies. In dataset B, system-predicted measurements were compared with annotations made by two independent readers as well as radiology reports to evaluate system performance. Results: In dataset B, the mean absolute error between the automatic and reader-measured diameters was equal to or less than 0.27 cm for both the ascending aorta and the descending aorta. The intraclass correlation coefficients (ICCs) were greater than 0.80 for the ascending aorta and equal to or greater than 0.70 for the descending aorta, and the ICCs between readers were 0.91 (95% CI: 0.90, 0.92) and 0.82 (95% CI: 0.80, 0.84), respectively. Aneurysm detection accuracy was 88% (95% CI: 86, 90) and 81% (95% CI: 79, 83) compared with reader 1 and 90% (95% CI: 88, 91) and 82% (95% CI: 80, 84) compared with reader 2 for the ascending aorta and descending aorta, respectively. Conclusion: Thoracic aortic aneurysms were accurately predicted at CT by using deep learning. (C)RSNA, 2022	[Macruz, Fabiola Bezerra de Carvalho; Lu, Charles; Strout, Julia; Doyle, Sean; Yun, Min; Buch, Varun] Massachusetts Gen Hosp, 100 Cambridge St, Boston, MA 02114 USA; [Macruz, Fabiola Bezerra de Carvalho; Lu, Charles; Strout, Julia; Doyle, Sean; Yun, Min; Buch, Varun] Brigham & Womens Hosp, Ctr Clin Data Sci, 100 Cambridge St, Boston, MA 02114 USA; [Takigami, Angelo; Hedgire, Sandeep; Ghoshhajra, Brian] Massachusetts Gen Hosp, Dept Cardiovasc Imaging, Boston, MA 02114 USA; [Brooks, Rupert] Nuance Commun, Montreal, PQ, Canada	Harvard University; Massachusetts General Hospital; Harvard University; Brigham & Women's Hospital; Harvard University; Massachusetts General Hospital	Macruz, FBD (corresponding author), Massachusetts Gen Hosp, 100 Cambridge St, Boston, MA 02114 USA.; Macruz, FBD (corresponding author), Brigham & Womens Hosp, Ctr Clin Data Sci, 100 Cambridge St, Boston, MA 02114 USA.	fabiolamacruz@hotmail.com	; Ghoshhajra, Brian/J-2114-2016	Macruz, Fabiola/0000-0001-6009-7631; , Sandeep/0000-0001-8527-9386; Ghoshhajra, Brian/0000-0002-3865-3432; Takigami, Angelo/0000-0002-2605-1362	Nuance Communications	Nuance Communications	Supported in part by Nuance Communications.	Anirudh Chandrashekar, 2020, Arxiv, DOI arXiv:2002.03463; Biesdorf A, 2012, MED IMAGE ANAL, V16, P1187, DOI 10.1016/j.media.2012.05.010; Black JH, EPIDEMIOLOGY RISK FA; Blondheim DS, 2016, J CARDIOL, V67, P365, DOI 10.1016/j.jjcc.2015.06.008; Cicek Ozgun, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P424, DOI 10.1007/978-3-319-46723-8_49; Di Cesare E, 2016, OPEN MED-WARSAW, V11, P143, DOI 10.1515/med-2016-0028; Elattar MA, 2014, MED BIOL ENG COMPUT, V52, P611, DOI 10.1007/s11517-014-1165-7; Elefteriades JA, 2007, ACUTE AORTIC DIS, P89; Elefteriades JA, 2020, J AM COLL CARDIOL, V76, P201, DOI 10.1016/j.jacc.2020.03.084; Entezari P, 2013, EUR J RADIOL, V82, P1558, DOI 10.1016/j.ejrad.2013.03.024; Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658; Gamechi ZS, 2019, EUR RADIOL, V29, P4613, DOI 10.1007/s00330-018-5931-z; Gao XP, 2017, EUR J RADIOL, V93, P1, DOI 10.1016/j.ejrad.2017.04.020; Góes Junior Adenauer Marinho de Oliveira, 2016, J. vasc. bras., V15, P106, DOI 10.1590/1677-5449.007616; Isgum I, 2009, IEEE T MED IMAGING, V28, P1000, DOI 10.1109/TMI.2008.2011480; Isselbacher EM, 2005, CIRCULATION, V111, P816, DOI 10.1161/01.CIR.0000154569.08857.7A; Krueger M, 2019, INSIGHTS IMAGING, V10, DOI 10.1186/s13244-019-0693-y; Kurugol S, 2015, MED PHYS, V42, P5467, DOI 10.1118/1.4924500; Kuzmik GA, 2012, J VASC SURG, V56, P565, DOI 10.1016/j.jvs.2012.04.053; Lu TLC, 2010, INTERACT CARDIOV TH, V10, P217, DOI 10.1510/icvts.2009.216275; Noothout JMH, 2018, PROC SPIE, V10574, DOI 10.1117/12.2293114; Olsson C, 2006, CIRCULATION, V114, P2611, DOI 10.1161/CIRCULATIONAHA.106.630400; Quint LE, 2013, INT J CARDIOVAS IMAG, V29, P479, DOI 10.1007/s10554-012-0102-9; Quintana RA, 2019, CIRC RES, V124, P470, DOI 10.1161/CIRCRESAHA.119.314765; Ramchand J, 2021, AM J CARDIOL, V140, P78, DOI 10.1016/j.amjcard.2020.10.059; Rudarakanchana N, 2014, EUR J VASC ENDOVASC, V47, P19, DOI 10.1016/j.ejvs.2013.09.026; Rueckel J, 2021, EUR J RADIOL, V134, DOI 10.1016/j.ejrad.2020.109424; Schroeder W, 2004, VISUALIZATION TOOLKI; Sverzellati N, 2016, RADIOL MED, V121, P190, DOI 10.1007/s11547-015-0595-0; Xie YT, 2014, INT J COMPUT ASS RAD, V9, P211, DOI 10.1007/s11548-013-0924-5	30	1	1	2	3	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2022	4	2							e210076	10.1148/ryai.210076	http://dx.doi.org/10.1148/ryai.210076			11	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9YB	35391768	Green Published			2022-12-18	WOS:000826922700003
J	Monti, CB; van Assen, M; Stillman, AE; Lee, SJ; Hoelzer, P; Fung, GSK; Secchi, F; Sardanelli, F; De Cecco, CN				Monti, Caterina B.; van Assen, Marly; Stillman, Arthur E.; Lee, Scott J.; Hoelzer, Philipp; Fung, George S. K.; Secchi, Francesco; Sardanelli, Francesco; De Cecco, Carlo N.			Evaluating the Performance of a Convolutional Neural Network Algorithm for Measuring Thoracic Aortic Diameters in a Heterogeneous Population	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						CT; Vascular; Aorta	ANEURYSM; SEGMENTATION; DISSECTION	The purpose of this work was to assess the performance of a convolutional neural network (CNN) for automatic thoracic aortic measurements in a heterogeneous population. From June 2018 to May 2019, this study retrospectively analyzed 250 chest CT scans with or without contrast enhancement and electrocardiographic gating from a heterogeneous population with or without aortic pathologic findings. Aortic diameters at nine locations and maximum aortic diameter were measured manually and with an algorithm (Artificial Intelligence Rad Companion Chest CT prototype, Siemens Healthineers) by using a CNN. A total of 233 examinations performed with 15 scanners from three vendors in 233 patients (median age, 65 years [IQR, 54.72 years]; 144 men) were analyzed: 68 (29%) without pathologic findings, 72 (31%) with aneurysm, 51 (22%) with dissection, and 42 (18%) with repair. No evidence of a difference was observed in maximum aortic diameter between manual and automatic measurements (P =.48). Overall measurements displayed a bias of -1.5 mm and a coefficient of repeatability of 8.0 mm at BlandAltman analyses. Contrast enhancement, location, pathologic finding, and positioning inaccuracy negatively influenced reproducibility (P < .003). Sites with dissection or repair showed lower agreement than did sites without. The CNN performed well in measuring thoracic aortic diameters in a heterogeneous multivendor CT dataset. (C)RSNA, 2022	[Monti, Caterina B.; van Assen, Marly; Stillman, Arthur E.; Lee, Scott J.; De Cecco, Carlo N.] Emory Univ Hosp, Div Cardiothorac Imaging Nucl Med & Mol Imaging, Dept Radiol & Imaging Sci, 1364 Clifton Rd NE, Atlanta, GA 30322 USA; [Monti, Caterina B.; Secchi, Francesco; Sardanelli, Francesco] Univ Milan, Dept Biomed Sci Hlth, Milan, Italy; [Hoelzer, Philipp] Siemens Healthineers, Digital Hlth Imaging Decis Support, Princeton, NJ USA; [Fung, George S. K.] Siemens Healthineers, Computed Tomog, Malvern, PA USA; [Secchi, Francesco; Sardanelli, Francesco] Ist Ricovero & Cura Carat Dare Sci Policlin San D, Unit Radiol, San Donato Milanese, Italy	Emory University; University of Milan; Siemens AG; Siemens AG	De Cecco, CN (corresponding author), Emory Univ Hosp, Div Cardiothorac Imaging Nucl Med & Mol Imaging, Dept Radiol & Imaging Sci, 1364 Clifton Rd NE, Atlanta, GA 30322 USA.	carlo.dececco@emory.edu	Sardanelli, Francesco/M-2917-2016; De Cecco, Carlo N./C-8572-2017; Monti, Caterina Beatrice/AAD-7754-2019	Sardanelli, Francesco/0000-0001-6545-9427; De Cecco, Carlo N./0000-0002-2956-3101; Stillman, Arthur/0000-0002-7911-1920; Monti, Caterina Beatrice/0000-0002-9539-8642; van Assen, Marly/0000-0003-4044-4426				Martinez-Mera JA, 2013, COMPUT AIDED SURG, V18, P109, DOI 10.3109/10929088.2013.816978; Di Leo G, 2020, EUR RADIOL EXP, V4, DOI 10.1186/s41747-020-0145-y; Gao XP, 2019, INT J CARDIOVAS IMAG, V35, P711, DOI 10.1007/s10554-018-1488-9; Hiratzka LF, 2010, CIRCULATION, V121, pE266, DOI 10.1161/CIR.0b013e3181d4739e; Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5; Kovacs T., 2006, BILDVERARBEITUNG MED, P161; Olsson C, 2006, CIRCULATION, V114, P2611, DOI 10.1161/CIRCULATIONAHA.106.630400; Pierce LC, 2008, AM J EMERG MED, V26, P1042, DOI 10.1016/j.ajem.2007.12.014; Williams JA, 2007, ANN THORAC SURG, V83, pS757, DOI 10.1016/j.athoracsur.2006.10.091; Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015	10	1	1	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2022	4	2							e210196	10.1148/ryai.210196	http://dx.doi.org/10.1148/ryai.210196			5	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9YB	35391773	Green Published			2022-12-18	WOS:000826922700012
J	Sforazzini, F; Salome, P; Moustafa, M; Zhou, C; Schwager, C; Rein, K; Bougatf, N; Kudak, A; Woodruff, H; Dubois, L; Lambin, P; Debus, J; Abdollahi, A; Knoll, M				Sforazzini, Francesco; Salome, Patrick; Moustafa, Mahmoud; Zhou, Cheng; Schwager, Christian; Rein, Katrin; Bougatf, Nina; Kudak, Andreas; Woodruff, Henry; Dubois, Ludwig; Lambin, Philippe; Debus, Jurgen; Abdollahi, Amir; Knoll, Maximilian			Deep Learning-based Automatic Lung Segmentation on Multiresolution CT Scans from Healthy and Fibrotic Lungs in Mice	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Deep Learning; Lung Fibrosis; Radiation Therapy; Segmentation; Animal Studies; CT; Thorax; Lung		Purpose: To develop a model to accurately segment mouse lungs with varying levels of fibrosis and investigate its applicability to mouse images with different resolutions. Materials and Methods: In this experimental retrospective study, a U-Net was trained to automatically segment lungs on mouse CT images. The model was trained (n = 1200), validated (n = 300), and tested (n = 154) on longitudinally acquired and semiautomatically segmented CT images, which included both healthy and irradiated mice (group A). A second independent group of 237 mice (group B) was used for external testing. The Dice score coefficient (DSC) and Hausdorff distance (HD) were used as metrics to quantify segmentation accuracy. Transfer learning was applied to adapt the model to high-spatial-resolution mouse micro-CT segmentation (n = 20; group C [n = 16 for training and n = 4 for testing]). Results: The trained model yielded a high median DSC in both test datasets: 0.984 (interquartile range [IQR], 0.977-0.988) in group A and 0.966 (IQR, 0.955-0.972) in group B. The median HD in both test datasets was 0.47 mm (IQR, 0-0.51 mm [group A]) and 0.31 mm (IQR, 0.30-0.32 mm [group B]). Spatially resolved quantification of differences toward reference masks revealed two hot spots close to the air-tissue interfaces, which are particularly prone to deviation. Finally, for the higher-resolution mouse CT images, the median DSC was 0.905 (IQR, 0.902-0.929) and the median 95th percentile of the HD was 0.33 mm (IQR, 2.61-2.78 mm). Conclusion: The developed deep learning-based method for mouse lung segmentation performed well independently of disease state (healthy, fibrotic, emphysematous lungs) and CT resolution.	[Sforazzini, Francesco; Salome, Patrick; Moustafa, Mahmoud; Zhou, Cheng; Schwager, Christian; Rein, Katrin; Bougatf, Nina; Kudak, Andreas; Debus, Jurgen; Abdollahi, Amir; Knoll, Maximilian] German Canc Res Ctr DKEZ, Clin Cooperat Unit Radiat Oncol, Neuenheimer Feld 280, D-69120 Heidelberg, Germany; [Sforazzini, Francesco; Salome, Patrick; Moustafa, Mahmoud; Zhou, Cheng; Schwager, Christian; Rein, Katrin; Bougatf, Nina; Kudak, Andreas; Debus, Jurgen; Abdollahi, Amir; Knoll, Maximilian] Heidelberg Univ Hosp UKHD, Dept Radiat Oncol, Heidelberg, Germany; [Sforazzini, Francesco; Salome, Patrick; Moustafa, Mahmoud; Zhou, Cheng; Schwager, Christian; Rein, Katrin; Bougatf, Nina; Debus, Jurgen; Abdollahi, Amir; Knoll, Maximilian] Heidelberg Univ Hosp UKHD, Natl Ctr Tumor Dis NCT, Heidelberg, Germany; [Sforazzini, Francesco; Salome, Patrick; Moustafa, Mahmoud; Zhou, Cheng; Schwager, Christian; Rein, Katrin; Debus, Jurgen; Abdollahi, Amir; Knoll, Maximilian] German Canc Consortium DKTK, Core Ctr Heidelberg, Heidelberg, Germany; [Sforazzini, Francesco; Salome, Patrick; Moustafa, Mahmoud; Zhou, Cheng; Schwager, Christian; Rein, Katrin; Bougatf, Nina; Kudak, Andreas; Debus, Jurgen; Abdollahi, Amir; Knoll, Maximilian] Heidelberg Inst Radiat Oncol HIRO, Natl Ctr Radiat Oncol NCRO, Heidelberg, Germany; [Sforazzini, Francesco; Salome, Patrick; Moustafa, Mahmoud; Zhou, Cheng; Schwager, Christian; Rein, Katrin; Bougatf, Nina; Debus, Jurgen; Abdollahi, Amir; Knoll, Maximilian] Heidelberg Ion Beam Therapy Ctr HIT, Heidelberg, Germany; [Moustafa, Mahmoud] Suez Canal Univ, Dept Clin Pathol, Ismailia, Egypt; [Zhou, Cheng] Southern Med Univ, Dept Radiat Oncol, Nanfang Hosp, Guangzhou, Peoples R China; [Woodruff, Henry; Dubois, Ludwig; Lambin, Philippe] Maastricht Univ, GROW Sch Oncol, D Lab, Dept Precis Med, Maastricht, Netherlands; [Woodruff, Henry; Dubois, Ludwig; Lambin, Philippe] Maastricht Univ, GROW Sch Oncol, M Lab, Dept Precis Med, Maastricht, Netherlands	Helmholtz Association; German Cancer Research Center (DKFZ); Ruprecht Karls University Heidelberg; Helmholtz Association; German Cancer Research Center (DKFZ); Ruprecht Karls University Heidelberg; Egyptian Knowledge Bank (EKB); Suez Canal University; Southern Medical University - China; Maastricht University; Maastricht University	Knoll, M (corresponding author), German Canc Res Ctr DKEZ, Clin Cooperat Unit Radiat Oncol, Neuenheimer Feld 280, D-69120 Heidelberg, Germany.; Knoll, M (corresponding author), Heidelberg Univ Hosp UKHD, Dept Radiat Oncol, Heidelberg, Germany.; Knoll, M (corresponding author), Heidelberg Univ Hosp UKHD, Natl Ctr Tumor Dis NCT, Heidelberg, Germany.; Knoll, M (corresponding author), Heidelberg Inst Radiat Oncol HIRO, Natl Ctr Radiat Oncol NCRO, Heidelberg, Germany.; Knoll, M (corresponding author), Heidelberg Ion Beam Therapy Ctr HIT, Heidelberg, Germany.	m.knoll@dkfz.de		Moustafa, Mahmoud/0000-0002-9146-0808; Dubois, Ludwig/0000-0002-8887-4137; Woodruff, Henry/0000-0001-7911-5123; Salome, Patrick/0000-0003-4978-9156; Lambin, Philippe/0000-0001-7961-0191	European Research Council Advanced Grant (ERC-ADG-2015) [694812]; European Union [766276, 952172, 952103]	European Research Council Advanced Grant (ERC-ADG-2015); European Union(European Commission)	Financial support from European Research Council Advanced Grant (ERC-ADG-2015 n degrees 694812 -Hypoximmuno), the European Union Horizon 2020 Research and Innovation program under grant agreement: MSCA-ITN-PREDICT n degrees 766276, CHAIMELEON n degrees 952172, and EuCanImage n degrees 952103.	Baiker M, 2010, MED IMAGE ANAL, V14, P723, DOI 10.1016/j.media.2010.04.008; Drozdzal M, 2016, LECT NOTES COMPUT SC, V10008, P179, DOI 10.1007/978-3-319-46976-8_19; Fausto Milletari, 2016, Arxiv, DOI arXiv:1606.04797; Granton PV, 2014, INT J RADIAT ONCOL, V90, P696, DOI 10.1016/j.ijrobp.2014.07.004; Isensee F, 2019, HUM BRAIN MAPP, V40, P4952, DOI 10.1002/hbm.24750; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694; Pesapane Filippo, 2018, Eur Radiol Exp, V2, P35, DOI 10.1186/s41747-018-0061-6; Schoppe O, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-19449-7; Weng WH, 2021, IEEE ACCESS, V9, P16591, DOI 10.1109/ACCESS.2021.3053408; Wolf I, 2004, PROC SPIE, V5367, P16, DOI 10.1117/12.535112; Xiao D, 2011, PROC SPIE, V7965, DOI 10.1117/12.877921; Yan DM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169424; Zhou C, 2019, CLIN TRANSL RAD ONCO, V14, P25, DOI 10.1016/j.ctro.2018.10.005; Zhou C, 2017, RADIAT ONCOL, V12, DOI 10.1186/s13014-017-0912-y	15	1	1	2	4	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2022	4	2							e210095	10.1148/ryai.210095	http://dx.doi.org/10.1148/ryai.210095			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9YB	35391764	Green Published			2022-12-18	WOS:000826922700005
J	Hasenstab, KA; Tabalon, J; Yuan, N; Retson, T; Hsiao, A				Hasenstab, Kyle A.; Tabalon, Joseph; Yuan, Nancy; Retson, Tara; Hsiao, Albert			CNN-based Deformable Registration Facilitates Fast and Accurate Air Trapping Measurements at Inspiratory and Expiratory CT	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Air Trapping; Convolutional Neural Network; Deformable Registration; Small Airway Disease; CT; Lung; Semisupervised Learning; Unsupervised Learning	IMAGE REGISTRATION; COMPUTED-TOMOGRAPHY; LEARNING FRAMEWORK; COPDGENE; DISEASE; EMPHYSEMA; SMOKERS	Purpose: To develop a convolutional neural network (CNN)-based deformable lung registration algorithm to reduce computation time and assess its potential for lobar air trapping quantification. Materials and Methods: In this retrospective study, a CNN algorithm was developed to perform deformable registration of lung CT (LungReg) using data on 9118 patients from the COPDGene Study (data collected between 2007 and 2012). Loss function constraints included cross-correlation, displacement field regularization, lobar segmentation overlap, and the Jacobian determinant. LungReg was compared with a standard diffeomorphic registration (SyN) for lobar Dice overlap, percentage voxels with nonpositive Jacobian determinants, and inference runtime using paired t tests. Landmark colocalization error (LCE) across 10 patients was compared using a random effects model. Agreement between LungReg and SyN air trapping measurements was assessed using intraclass correlation coefficient. The ability of LungReg versus SyN emphysema and air trapping measurements to predict Global Initiative for Chronic Obstructive Lung Disease (GOLD) stages was compared using area under the receiver operating characteristic curves. Results: Average performance of LungReg versus SyN showed lobar Dice overlap score of 0.91-0.97 versus 0.89-0.95, respectively (P<.001); percentage voxels with nonpositive Jacobian determinant of 0.04 versus 0.10, respectively (P<.001); inference run time of 0.99 second (graphics processing unit) and 2.27 seconds (central processing unit) versus 418.46 seconds (central processing unit) (P<.001); and LCE of 7.21 mm versus 6.93 mm (P<.001). LungReg and SyN whole-lung and lobar air trapping measurements achieved excellent agreement (intraclass correlation coefficients. 0.98). LungReg versus SyN area under the receiver operating characteristic curves for predicting GOLD stage were not statistically different (range, 0.88-0.95 vs 0.88-0.95, respectively; P =.31-.95). Conclusion: CNN-based deformable lung registration is accurate and fully automated, with runtime feasible for clinical lobar air trapping quantification, and has potential to improve diagnosis of small airway diseases. (C) RSNA, 2021	[Hasenstab, Kyle A.; Yuan, Nancy; Retson, Tara; Hsiao, Albert] Univ Calif San Diego, Dept Radiol, 9500 Gilman Dr, La Jolla, CA 92093 USA; [Hasenstab, Kyle A.; Tabalon, Joseph] San Diego State Univ, Dept Math & Stat, San Diego, CA 92182 USA	University of California System; University of California San Diego; California State University System; San Diego State University	Hasenstab, KA (corresponding author), Univ Calif San Diego, Dept Radiol, 9500 Gilman Dr, La Jolla, CA 92093 USA.; Hasenstab, KA (corresponding author), San Diego State Univ, Dept Math & Stat, San Diego, CA 92182 USA.	kahasenstab@sdsu.edu		Retson, Tara/0000-0002-0009-7733; Yuan, Nancy/0000-0002-8325-8255; Hsiao, Albert/0000-0002-9412-1369	National Institutes of Health [T32 EB005970]; RSNA [RR1879]; Friedman Family Endowed Radiology Fellowship; National Heart, Lung, and Blood Institute [U01 HL089897, U01 HL089856]; COPD Foundation	National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); RSNA; Friedman Family Endowed Radiology Fellowship; National Heart, Lung, and Blood Institute(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Heart Lung & Blood Institute (NHLBI)); COPD Foundation	Training support for T.R. by the National Institutes of Health (T32 EB005970), RSNA (RR1879), and the Friedman Family Endowed Radiology Fellowship. Training support for N.Y. by the U.S. National Library of Medicine. The project described was supported by Award Number U01 HL089897 and Award Number U01 HL089856 from the National Heart, Lung, and Blood Institute. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Heart, Lung, and Blood Institute or the National Institutes of Health. COPD Foundation Funding: COPDGene is also supported by the COPD Foundation through contributions made to an Industry Advisory Board that has included AstraZeneca, Bayer Pharmaceuticals, Boehringer-Ingelheim, Genentech, GlaxoSmithKline, Novartis, Pfizer, and Sunovion.	Alter P, 2020, ERJ OPEN RES, V6, DOI 10.1183/23120541.00092-2020; Avants BB, 2008, MED IMAGE ANAL, V12, P26, DOI 10.1016/j.media.2007.06.004; Balakrishnan G, 2019, IEEE T MED IMAGING, V38, P1788, DOI 10.1109/TMI.2019.2897538; Boes JL, 2015, ACAD RADIOL, V22, P186, DOI 10.1016/j.acra.2014.08.015; Boveiri HR, 2020, COMPUT ELECTR ENG, V87, DOI 10.1016/j.compeleceng.2020.106767; Castillo R, DEFORMABLE IMAGE REG; Castillo R, 2013, PHYS MED BIOL, V58, P2861, DOI 10.1088/0031-9155/58/9/2861; Chen X, 2021, PROG BIOMED ENG, V3, DOI 10.1088/2516-1091/abd37c; Dalca AV, 2018, LECT NOTES COMPUT SC, V11070, P729, DOI 10.1007/978-3-030-00928-1_82; de Vos BD, 2019, MED IMAGE ANAL, V52, P128, DOI 10.1016/j.media.2018.11.010; de Vos BD, 2017, LECT NOTES COMPUT SC, V10553, P204, DOI 10.1007/978-3-319-67558-9_24; Eppenhof KAJ, 2019, PROC SPIE, V10949, DOI 10.1117/12.2512428; Eppenhof KAJ, 2019, IEEE T MED IMAGING, V38, P1097, DOI 10.1109/TMI.2018.2878316; Hansen L, 2021, IEEE T MED IMAGING, V40, P2246, DOI 10.1109/TMI.2021.3073986; Hering A, 2019, LECT NOTES COMPUT SC, V11769, P257, DOI 10.1007/978-3-030-32226-7_29; Hu RX, 2020, IEEE ENG MED BIO, P1368, DOI 10.1109/EMBC44109.2020.9176363; Jaderberg M., ARXIV150602025; Kirby M, 2017, RESPIRATION, V94, P336, DOI 10.1159/000478865; Kligerman SJ, 2015, RADIOGRAPHICS, V35, P1360, DOI 10.1148/rg.2015140308; Li HM, 2018, I S BIOMED IMAGING, P1075, DOI 10.1109/ISBI.2018.8363757; Lowe KE, 2019, COPD-J COPD FDN, V6, P384, DOI 10.15326/jcopdf.6.5.2019.0149; Lynch DA, 2013, J THORAC IMAG, V28, P284, DOI 10.1097/RTI.0b013e318298733c; Maselli DJ, 2021, RADIOLOGY, V300, P706, DOI 10.1148/radiol.2021204052; O'Grady NP, 2002, CLIN INFECT DIS, V35, P1281, DOI 10.1086/344188; Onieva JO, 2018, LECT NOTES COMPUT SC, V11040, P284, DOI 10.1007/978-3-030-00946-5_28; Ostridge K, 2019, ANN AM THORAC SOC, V16, P990, DOI 10.1513/AnnalsATS.201810-669OC; Pompe E, 2020, RADIOLOGY, V295, P218, DOI 10.1148/radiol.2020191429; Pompe E, 2017, RESP MED, V123, P48, DOI 10.1016/j.rmed.2016.11.021; Regan EA, 2010, COPD, V7, P32, DOI 10.3109/15412550903499522; Rosenow T, 2017, PEDIATR PULM, V52, P1150, DOI 10.1002/ppul.23754; Sharifi H, 2022, J THORAC IMAG, V37, P109, DOI 10.1097/RTI.0000000000000595; Sharifi H, 2020, CHEST, V158, P1090, DOI 10.1016/j.chest.2020.02.076; Vestbo J, 2013, AM J RESP CRIT CARE, V187, P347, DOI 10.1164/rccm.201204-0596PP	33	1	1	1	3	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2022	4	1							e210211	10.1148/ryai.2021210211	http://dx.doi.org/10.1148/ryai.2021210211			12	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9WA	35146437	Green Published			2022-12-18	WOS:000826917400004
J	Suri, A; Jones, BC; Ng, G; Anabaraonye, N; Beyrer, P; Domi, A; Choi, G; Tang, S; Terry, A; Leichner, T; Fathali, I; Bastin, N; Chesnais, H; Taratuta, E; Kneeland, BJ; Rajapakse, CS				Suri, Abhinav; Jones, Brandon C.; Ng, Grace; Anabaraonye, Nancy; Beyrer, Patrick; Domi, Albi; Choi, Grace; Tang, Sisi; Terry, Ashley; Leichner, Thomas; Fathali, Iman; Bastin, Nikita; Chesnais, Helene; Taratuta, Elena; Kneeland, Bruce J.; Rajapakse, Chamith S.			Vertebral Deformity Measurements at MRI, CT, and Radiography Using Deep Learning	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Computer Aided Diagnosis (CAD); MRI; CT; Spine; Demineralization-Bone; Feature Detection	QUALITY-OF-LIFE; POSTMENOPAUSAL WOMEN; FRACTURES; PREVALENT; OSTEOPOROSIS	Purpose: To construct and evaluate the efficacy of a deep learning system to rapidly and automatically locate six vertebral landmarks, which are used to measure vertebral body heights, and to output spine angle measurements (lumbar lordosis angles [LLAs]) across multiple modalities. Materials and Methods: In this retrospective study, MR (n = 1123), CT (n = 137), and radiographic (n = 484) images were used from a wide variety of patient populations, ages, disease stages, bone densities, and interventions (n = 1744 total patients, 64 years +/- 8, 76.8% women; images acquired 2005-2020). Trained annotators assessed images and generated data necessary for deformity analysis and for model development. A neural network model was then trained to output vertebral body landmarks for vertebral height measurement. The network was trained and validated on 898 MR, 110 CT, and 387 radiographic images and was then evaluated or tested on the remaining images for measuring deformities and LLAs. The Pearson correlation coefficient was used in reporting LLA measurements. Results: On the holdout testing dataset (225 MR, 27 CT, and 97 radiographic images), the network was able to measure vertebral heights (mean height percentage of error +/- 1 standard deviation: MR images, 1.5% +/- 0.3; CT scans, 1.9% +/- 0.2; radiographs, 1.7% 6 0.4) and produce other measures such as the LLA (mean absolute error: MR images, 2.90 degrees; CT scans, 2.26 degrees; radiographs, 3.60 degrees) in less than 1.7 seconds across MR, CT, and radiographic imaging studies. Conclusion: The developed network was able to rapidly measure morphometric quantities in vertebral bodies and output LLAs across multiple modalities. (C) RSNA, 2021	[Suri, Abhinav; Jones, Brandon C.; Ng, Grace; Anabaraonye, Nancy; Beyrer, Patrick; Domi, Albi; Choi, Grace; Tang, Sisi; Terry, Ashley; Leichner, Thomas; Fathali, Iman; Bastin, Nikita; Chesnais, Helene; Taratuta, Elena; Kneeland, Bruce J.; Rajapakse, Chamith S.] Univ Penn, Perelman Sch Med, Dept Radiol & Orthoped, 3400 Spruce St, Philadelphia, PA 19104 USA	University of Pennsylvania; Pennsylvania Medicine	Suri, A (corresponding author), Univ Penn, Perelman Sch Med, Dept Radiol & Orthoped, 3400 Spruce St, Philadelphia, PA 19104 USA.	suria@sas.upenn.edu		Anabaraonye, Nancy/0000-0003-2081-205X; SURI, ABHINAV/0000-0002-7900-8763; Jones, Brandon/0000-0002-9352-5521; Ng, Grace/0000-0001-5362-6144				Bartalena T, 2009, EUR J RADIOL, V69, P555, DOI 10.1016/j.ejrad.2007.11.036; COOPER C, 1992, J BONE MINER RES, V7, P221, DOI 10.1002/jbmr.5650070214; Cunha-Henriques Sylvia, 2011, J Clin Med Res, V3, P168, DOI 10.4021/jocmr537w; Ebrahimi S, 2019, COMP M BIO BIO E-IV, V7, P134, DOI 10.1080/21681163.2018.1463174; Engelke K, 2019, ARCH OSTEOPOROS, V14, DOI 10.1007/s11657-019-0577-2; Fink HA, 2005, J BONE MINER RES, V20, P1216, DOI 10.1359/JBMR.050314; He K, ARXIV 170306870; Kim YM, 2011, OSTEOPOROSIS INT, V22, P2677, DOI 10.1007/s00198-011-1530-4; Masad IS, 2019, ENG SCI TECHNOL, V22, P1027, DOI 10.1016/j.jestch.2019.03.002; Office of the U.S. Surgeon General, 2004, BON HLTH OST REP SUR; Rajapakse CS, 2014, OSTEOPOROSIS INT, V25, P973, DOI 10.1007/s00198-013-2569-1; Salaffi F, 2007, J RHEUMATOL, V34, P1551; Schwartz JT, 2021, SPINE, V46, pE671, DOI 10.1097/BRS.0000000000003830; Sekuboyina A, ARXIV 200109193; Silverman SL, 2001, ARTHRITIS RHEUM, V44, P2611, DOI 10.1002/1529-0131(200111)44:11<2611::AID-ART441>3.0.CO;2-N; Weaver J, 2017, J MANAG CARE SPEC PH, V23, P735, DOI [10.18553/jmcp.2017.23.7.735, 10.18553/jmcp.2017.23.4.461]; Wong CC, 2013, J MULTIDISCIP HEALTH, V6, P205, DOI 10.2147/JMDH.S31659; WU CY, 1995, OSTEOPOROSIS INT, V5, P354, DOI 10.1007/BF01622258	19	1	1	2	2	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2022	4	1							e210015	10.1148/ryai.2021210015	http://dx.doi.org/10.1148/ryai.2021210015			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9WA	35146432	Green Published			2022-12-18	WOS:000826917400003
J	Feng, SJ; Azzollini, D; Kim, JS; Jin, CK; Gordon, SP; Yeoh, J; Kim, E; Han, M; Lee, A; Patel, A; Wu, J; Urschler, M; Fong, A; Simmers, C; Tarr, GP; Barnard, S; Wilson, B				Feng, Sijing; Azzollini, Damian; Kim, Ji Soo; Jin, Cheng-Kai; Gordon, Simon P.; Yeoh, Jason; Kim, Eve; Han, Mina; Lee, Andrew; Patel, Aakash; Wu, Joy; Urschler, Martin; Fong, Amy; Simmers, Cameron; Tarr, Gregory P.; Barnard, Stuart; Wilson, Ben			Curation of the CANDID-PTX Dataset with Free-Text Reports	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material						Conventional Radiography; Thorax; Trauma; Ribs; Catheters; Segmentation; Diagnosis; Classification; Supervised Learning; Machine Learning			[Feng, Sijing; Fong, Amy; Simmers, Cameron; Wilson, Ben] Dunedin Publ Hosp, Dunedin Cent, Dept Radiol, 201 Great King St, Dunedin 9016, Otago, New Zealand; [Azzollini, Damian] Eastern Hlth, Melbourne, Vic, Australia; [Kim, Ji Soo; Yeoh, Jason; Kim, Eve; Han, Mina] Auckland Dist Hlth Board, Auckland, New Zealand; [Jin, Cheng-Kai] Waitemata Dist Hlth Board, Auckland, New Zealand; [Gordon, Simon P.] Waikato Dist Hlth Board, Hamilton, New Zealand; [Lee, Andrew] Univ Auckland, Fac Med & Hlth Sci, Auckland, New Zealand; [Patel, Aakash] Univ Otago, Med Sch, Dunedin, Otago, New Zealand; [Wu, Joy] IBM Almaden Res Ctr, San Jose, CA USA; [Urschler, Martin] Univ Auckland, Sch Comp Sci, Auckland, New Zealand; [Tarr, Gregory P.] Auckland City Hosp, Dept Radiol, Auckland, New Zealand; [Barnard, Stuart] Middlemore Hosp, Dept Radiol, Auckland, New Zealand	Dunedin Public Hospital; Auckland District Health Board; University of Auckland; University of Otago; International Business Machines (IBM); University of Auckland; Auckland City Hospital	Feng, SJ (corresponding author), Dunedin Publ Hosp, Dunedin Cent, Dept Radiol, 201 Great King St, Dunedin 9016, Otago, New Zealand.	sijingfeng@gmail.com	Urschler, Martin/M-1986-2019	Urschler, Martin/0000-0001-5792-3971; Kim, Eve Chae Won/0000-0002-0403-7535; Feng, Sijing/0000-0002-4967-7800; Kim, Ji Soo/0000-0002-5017-3554	Royal Australia and New Zealand College of Radiologists (RANZCR)	Royal Australia and New Zealand College of Radiologists (RANZCR)	Supported by a Royal Australia and New Zealand College of Radiologists (RANZCR) research grant in 2020.	Annarumma M, 2019, RADIOLOGY, V291, P195, DOI 10.1148/radiol.2018180921; [Anonymous], RADLEX VERSION 4 1; [Anonymous], MDAI SECURITY PRIVAC; Bastawrous S, 2017, J DIGIT IMAGING, V30, P309, DOI 10.1007/s10278-016-9937-2; Chartrand G, 2017, RADIOGRAPHICS, V37, P2113, DOI 10.1148/rg.2017170077; Dunnmon JA, 2019, RADIOLOGY, V290, P537, DOI 10.1148/radiol.2018181422; Filice RW, 2020, J DIGIT IMAGING, V33, P490, DOI 10.1007/s10278-019-00299-9; Kayaalp M, 2019, NLM SCRUBBER; Lam L, 2020, DICOMANONYMIZER V1 0; National Ethics Advisory Committee, 2019, NAT ETH STAND HLTH D; Rajpurkar P, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002686; Rimmer A, 2017, BMJ-BRIT MED J, V359, DOI 10.1136/bmj.j4683; Schaffter T, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.0265; Wu JT, 2020, AMIA 2020 VIRTUAL AN; Yates EJ, 2018, CLIN RADIOL, V73, P827, DOI 10.1016/j.crad.2018.05.015; Zhang R, 2021, RADIOLOGY, V298, pE88, DOI 10.1148/radiol.2020202944	16	1	1	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2021	3	6							e210136	10.1148/ryai.2021210136	http://dx.doi.org/10.1148/ryai.2021210136			6	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9UW	34870223	Green Published			2022-12-18	WOS:000826914400013
J	Theruvath, AJ; Siedek, F; Yerneni, K; Muehe, AM; Spunt, SL; Pribnow, A; Moseley, M; Lu, Y; Zhao, Q; Gulaka, P; Chaudhari, A; Daldrup-Link, HE				Theruvath, Ashok J.; Siedek, Florian; Yerneni, Ketan; Muehe, Anne M.; Spunt, Sheri L.; Pribnow, Allison; Moseley, Michael; Lu, Ying; Zhao, Qian; Gulaka, Praveen; Chaudhari, Akshay; Daldrup-Link, Heike E.			Validation of Deep Learning-based Augmentation for Reduced F-18-FDG Dose for PET/MRI in Children and Young Adults with Lymphoma	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Pediatrics; PET/MRI; Computer Applications Detection/Diagnosis; Lymphoma; Tumor Response; Whole-Body Imaging; Technology Assessment	HODGKIN-LYMPHOMA; PET; RISK; REDUCTION; CHILDHOOD; BRAIN; IMAGE; CHEMOTHERAPY; SIMULATION; IMPACT	Purpose: To investigate if a deep learning convolutional neural network (CNN) could enable low-dose fluorine 18 (F-18) fluorodeoxyglucose (FDG) PET/MRI for correct treatment response assessment of children and young adults with lymphoma. Materials and Methods: In this secondary analysis of prospectively collected data (ClinicalTrials.gov identifier: NCT01542879), 20 patients with lymphoma (mean age, 16.4 years 6 6.4 [standard deviation]) underwent F-18-FDG PET/MRI between July 2015 and August 2019 at baseline and after induction chemotherapy. Full-dose F-18-FDG PET data (3 MBq/kg) were simulated to lower F-18-FDG doses based on the percentage of coincidence events (representing simulated 75%, 50%, 25%, 12.5%, and 6.25% 18F-FDG dose [hereafter referred to as 75% Sim, 50% Sim, 25% Sim, 12.5% Sim, and 6.25% Sim, respectively]). A U.S. Food and Drug Administrationapproved CNN was used to augment input simulated low-dose scans to full-dose scans. For each follow-up scan after induction chemotherapy, the standardized uptake value (SUV) response score was calculated as the maximum SUV (SUV max) of the tumor normalized to the mean liver SUV; tumor response was classified as adequate or inadequate. Sensitivity and specificity in the detection of correct response status were computed using full-dose PET as the reference standard. Results: With decreasing simulated radiotracer doses, tumor SUV max increased. A dose below 75% Sim of the full dose led to erroneous upstaging of adequate responders to inadequate responders (43% [six of 14 patients] for 75% Sim; 93% [13 of 14 patients] for 50% Sim; and 100% [14 of 14 patients] below 50% Sim; P<.05 for all). CNN-enhanced low-dose PET/MRI scans at 75% Sim and 50% Sim enabled correct response assessments for all patients. Use of the CNN augmentation for assessing adequate and inadequate responses resulted in identical sensitivities (100%) and specificities (100%) between the assessment of 100% full-dose PET, augmented 75% Sim, and augmented 50% Sim images. Conclusion: CNN enhancement of PET/MRI scans may enable 50% 18F-FDG dose reduction with correct treatment response assessment of children and young adults with lymphoma. Clinical trial registration no: NCT01542879 Supplemental material is available for this article. (C) RSNA, 2021	[Theruvath, Ashok J.; Siedek, Florian; Yerneni, Ketan; Muehe, Anne M.; Moseley, Michael; Chaudhari, Akshay; Daldrup-Link, Heike E.] Stanford Univ, Dept Radiol, Mol Imaging Program Stanford, 725 Welch Rd, Stanford, CA 94304 USA; [Spunt, Sheri L.; Pribnow, Allison; Daldrup-Link, Heike E.] Stanford Univ, Div Hematol Oncol, Dept Pediat, Lucile Packard Childrens Hosp, 725 Welch Rd, Stanford, CA 94304 USA; [Lu, Ying; Zhao, Qian] Stanford Univ, Dept Biomed Data Sci, 725 Welch Rd, Stanford, CA 94304 USA; [Gulaka, Praveen] Subtle Med, Menlo Pk, CA USA	Stanford University; Lucile Packard Children's Hospital (LPCH); Stanford University; Stanford University	Daldrup-Link, HE (corresponding author), Stanford Univ, Dept Radiol, Mol Imaging Program Stanford, 725 Welch Rd, Stanford, CA 94304 USA.; Daldrup-Link, HE (corresponding author), Stanford Univ, Div Hematol Oncol, Dept Pediat, Lucile Packard Childrens Hosp, 725 Welch Rd, Stanford, CA 94304 USA.	heiked@stanford.edu		Yerneni, Ketan/0000-0003-2373-005X; Theruvath, Ashok Joseph/0000-0003-0764-6800; Chaudhari, Akshay/0000-0002-3667-6796; Muehe, Anne/0000-0003-3893-5242; Spunt, Sheri/0000-0002-1669-2676	Eunice Kennedy Shriver National Institute of Child Health and Human Development [R01 HD081123]; Andrew McDonough B+ Foundation; National Institutes of Health [1UL1TR003142]	Eunice Kennedy Shriver National Institute of Child Health and Human Development(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH Eunice Kennedy Shriver National Institute of Child Health & Human Development (NICHD)); Andrew McDonough B+ Foundation; National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	Supported in part by grants from the Eunice Kennedy Shriver National Institute of Child Health and Human Development (R01 HD081123) and the Andrew McDonough B+ Foundation. Y.L. supported by the National Institutes of Health (1UL1TR003142).	Ahmed BA, 2010, PEDIATRICS, V126, pE851, DOI 10.1542/peds.2009-2675; Banerjee I, 2018, COMPUT MED IMAG GRAP, V65, P167, DOI 10.1016/j.compmedimag.2017.05.002; Barrington SF, 2017, EUR J NUCL MED MOL I, V44, pS97, DOI 10.1007/s00259-017-3690-8; Behr SC, 2018, MOL IMAGING BIOL, V20, P492, DOI 10.1007/s11307-017-1145-z; Chaudhari AS, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00497-2; Chaudhari AS, 2018, MAGN RESON MED, V80, P2139, DOI 10.1002/mrm.27178; Chawla SC, 2010, PEDIATR RADIOL, V40, P681, DOI 10.1007/s00247-009-1434-z; Chen KT, 2019, RADIOLOGY, V290, P649, DOI 10.1148/radiol.2018180940; Cheson BD, 2014, J CLIN ONCOL, V32, P3059, DOI 10.1200/JCO.2013.54.8800; Daldrup-Link H, 2019, PEDIATR RADIOL, V49, P1384, DOI 10.1007/s00247-019-04360-1; Daldrup-Link Heike, 2017, Curr Radiol Rep, V5, DOI 10.1007/s40134-017-0207-y; Depas G, 2005, EUR J NUCL MED MOL I, V32, P31, DOI 10.1007/s00259-004-1604-z; Fahey FH, 2017, J NUCL MED, V58, P1360, DOI 10.2967/jnumed.116.182899; Friedman DL, 2014, J CLIN ONCOL, V32, P3651, DOI 10.1200/JCO.2013.52.5410; Gatidis S, 2016, EUR J NUCL MED MOL I, V43, P2283, DOI 10.1007/s00259-016-3503-5; Gatidis S, 2016, HELL J NUCL MED, V19, P15, DOI 10.1967/s002449910333; Gelfand MJ, 2011, J NUCL MED, V52, P318, DOI 10.2967/jnumed.110.084327; Gong E, 2018, J MAGN RESON IMAGING, V48, P330, DOI 10.1002/jmri.25970; Hirsch FW, 2013, PEDIATR RADIOL, V43, P860, DOI 10.1007/s00247-012-2570-4; Hong JY, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.10584; Kang JY, 2015, MED PHYS, V42, P5301, DOI 10.1118/1.4928400; Kaplan S, 2019, J DIGIT IMAGING, V32, P773, DOI 10.1007/s10278-018-0150-3; Karakatsanis NA, 2015, AM J NUCL MED MOLEC, V5, P527; Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010; Kleis M, 2009, EUR J NUCL MED MOL I, V36, P23, DOI 10.1007/s00259-008-0911-1; Knoll F, 2020, MAGN RESON MED, V84, P3054, DOI 10.1002/mrm.28338; Larson DB, 2018, RADIOLOGY, V287, P313, DOI 10.1148/radiol.2017170236; LIN LI, 1989, BIOMETRICS, V45, P255, DOI 10.2307/2532051; Lindemann ME, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0206573; Mathews JD, 2013, BMJ-BRIT MED J, V346, DOI 10.1136/bmj.f2360; McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031; Metzger ML, 2012, JAMA-J AM MED ASSOC, V307, P2609, DOI 10.1001/jama.2012.5847; Meulepas JM, 2019, JNCI-J NATL CANCER I, V111, P256, DOI 10.1093/jnci/djy104; Montravers F, 2002, EUR J NUCL MED MOL I, V29, P1155, DOI 10.1007/s00259-002-0861-y; Muehe AM, 2018, MOL IMAGING BIOL, V20, P324, DOI 10.1007/s11307-017-1105-7; Pearce MS, 2012, LANCET, V380, P499, DOI 10.1016/S0140-6736(12)60815-0; Rajpurkar P, ARXIV 171105225; Rauscher I, 2020, J NUCL MED, V61, P189, DOI 10.2967/jnumed.119.227207; Ronneberger O, LECT NOTES COMPUTER; Schaefferkoetter JD, 2017, J NUCL MED, V58, P399, DOI 10.2967/jnumed.116.177592; Seith F, 2017, J NUCL MED, V58, P1699, DOI 10.2967/jnumed.116.184440; Sekine T, 2018, RADIOLOGY, V286, P249, DOI 10.1148/radiol.2017162305; Shkumat NA, 2020, PEDIATR RADIOL, V50, P966, DOI 10.1007/s00247-020-04640-1; Theruvath AJ, 2020, RADIOLOGY, V296, P143, DOI 10.1148/radiol.2020192508; Wang Y, 2018, NEUROIMAGE, V174, P550, DOI 10.1016/j.neuroimage.2018.03.045; Wang YR, 2021, EUR J NUCL MED MOL I, V48, P2771, DOI 10.1007/s00259-021-05197-3; Wegner EA, 2005, EUR J NUCL MED MOL I, V32, P23, DOI 10.1007/s00259-004-1645-3; Xu J, ARXIV 171204119 PREP; Zucchetta P, 2019, BRIT J RADIOL, V92, DOI 10.1259/bjr.20180438	49	1	1	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2021	3	6							e200232	10.1148/ryai.2021200232	http://dx.doi.org/10.1148/ryai.2021200232			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9UW	34870211	Green Published			2022-12-18	WOS:000826914400001
J	Wiggins, WF; Magudia, K; Schmidt, TMS; O'Connor, SD; Carr, CD; Kohli, MD; Andriole, KP				Wiggins, Walter F.; Magudia, Kirti; Schmidt, Teri M. Sippel; O'Connor, Stacy D.; Carr, Christopher D.; Kohli, Marc D.; Andriole, Katherine P.			Imaging AI in Practice: A Demonstration of Future Workflow Using Integration Standards	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Computer Applications-General (Informatics); Technology Assessment		Artificial intelligence (AI) tools are rapidly being developed for radiology and other clinical areas. These tools have the potential to dramatically change clinical practice; however, for these tools to be usable and function as intended, they must be integrated into existing radiology systems. In a collaborative effort between the Radiological Society of North America, radiologists, and imaging-focused vendors, the Imaging AI in Practice (IAIP) demonstrations were developed to show how AI tools can generate, consume, and present results throughout the radiology workflow in a simulated clinical environment. The IAIP demonstrations highlight the critical importance of semantic and interoperability standards, as well as orchestration profiles for successful clinical integration of radiology AI tools. (C) RSNA, 2021	[Wiggins, Walter F.] Duke Univ, Dept Radiol, Sch Med, DUMC Box 3808,2301 Erwin Rd, Durham, NC 27710 USA; [Magudia, Kirti; Kohli, Marc D.] Univ Calif San Francisco, Dept Radiol & Biomed Imaging, San Francisco, CA 94143 USA; [Schmidt, Teri M. Sippel] Marquette Univ, Dept Biomed Engn, Milwaukee, WI 53233 USA; [Schmidt, Teri M. Sippel] Med Coll Wisconsin, Dept Biomed Engn, Milwaukee, WI 53226 USA; [O'Connor, Stacy D.] Med Coll Wisconsin, Dept Radiol, Milwaukee, WI 53226 USA; [Carr, Christopher D.] Radiol Soc North Amer, Dept Informat, Oak Brook, IL USA; [Andriole, Katherine P.] Harvard Med Sch, Brigham & Womens Hosp, Dept Radiol, Boston, MA 02115 USA; [Andriole, Katherine P.] Mass Gen Brigham Ctr Clin Data Sci, Boston, MA USA	Duke University; University of California System; University of California San Francisco; Marquette University; Medical College of Wisconsin; Medical College of Wisconsin; Harvard University; Brigham & Women's Hospital; Harvard Medical School	Wiggins, WF (corresponding author), Duke Univ, Dept Radiol, Sch Med, DUMC Box 3808,2301 Erwin Rd, Durham, NC 27710 USA.	walter.wiggins@duke.edu		Magudia, Kirti/0000-0001-7037-433X; Kohli, Marc D/0000-0003-3720-0156; O'Connor, Stacy/0000-0002-0813-1414; Wiggins, Walter/0000-0002-0258-2708				[Anonymous], IMAGINGAI PRACT DEM; [Anonymous], IHE RAD TECHN FRAM S; IHE Radiology Technical Framework Supplement, AI RES AIR INT HEALT; Kohli M, 2019, J AM COLL RADIOL, V16, P1464, DOI 10.1016/j.jacr.2019.06.009; Langlotz CP, 2019, RADIOLOGY, V291, P781, DOI 10.1148/radiol.2019190613; RSNA, IM AI PRACT DEM; Saba L, 2019, EUR J RADIOL, V114, P14, DOI 10.1016/j.ejrad.2019.02.038; Wang KC, 2017, RADIOGRAPHICS, V37, P1099, DOI 10.1148/rg.2017160188	8	1	1	2	3	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2021	3	6							e210152	10.1148/ryai.2021210152	http://dx.doi.org/10.1148/ryai.2021210152			6	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9UW	34870224	Green Published			2022-12-18	WOS:000826914400014
J	Bortsova, G; Bos, D; Dubost, F; Vernooij, MW; Ikram, MK; van Tulder, G; de Bruijne, M				Bortsova, Gerda; Bos, Daniel; Dubost, Florian; Vernooij, Meike W.; Ikram, M. Kamran; van Tulder, Gijs; de Bruijne, Marleen			Automated Segmentation and Volume Measurement of Intracranial Internal Carotid Artery Calcification at Noncontrast CT	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						CT; Neural Networks; Carotid Arteries; Calcifications/Calculi; Arteriosclerosis; Segmentation; Vision Application Domain; Stroke	ATHEROSCLEROSIS; STROKE	Purpose: To develop and evaluate a fully-automated deep learning-based method for assessment of intracranial internal carotid artery calcification (ICAC). Materials and Methods: This was a secondary analysis of prospectively collected data from the Rotterdam study (2003-2006) to develop and validate a deep learning-based method for automated ICAC delineation and volume measurement. Two observers manually delineated ICAC on noncontrast CT scans of 2319 participants (mean age, 69 years 6 7 [standard deviation]; 1154 women [53.2%]), and a deep learning model was trained to segment ICAC and quantify its volume. Model performance was assessed by comparing manual and automated segmentations and volume measurements to those produced by an independent observer (available on 47 scans), comparing the segmentation accuracy in a blinded qualitative visual comparison by an expert observer, and comparing the association with first stroke incidence from the scan date until 2016. All method performance metrics were computed using 10-fold cross-validation. Results: The automated delineation of ICAC reached a sensitivity of 83.8% and positive predictive value (PPV) of 88%. The intraclass correlation between automatic and manual ICAC volume measures was 0.98 (95% CI: 0.97, 0.98; computed in the entire dataset). Measured between the assessments of independent observers, sensitivity was 73.9%, PPV was 89.5%, and intraclass correlation coefficient was 0.91 (95% CI: 0.84, 0.95; computed in the 47-scan subset). In the blinded visual comparisons of 294 regions, automated delineations were judged as more accurate than manual delineations in 131 regions, less accurate in 94 regions, and equally accurate in the rest of the regions (131 of 225, 58.2%; P =.01). The association of ICAC volume with incident stroke was similarly strong for both automated (hazard ratio, 1.38 [95% CI: 1.12, 1.75]) and manually measured volumes (hazard ratio, 1.48 [95% CI: 1.20, 1.87]). Conclusion: The developed model was capable of automated segmentation and volume quantification of ICAC with accuracy comparable to human experts. Supplemental material is available for this article. (C) RSNA, 2021.	[Bortsova, Gerda; de Bruijne, Marleen] Erasmus MC, Biomed Imaging Grp Rotterdam, Dept Radiol & Nucl Med, POB 2040, NL-3000 CA Rotterdam, Netherlands; [Bos, Daniel; Vernooij, Meike W.; Ikram, M. Kamran] Erasmus MC, Dept Epidemiol, POB 2040, NL-3000 CA Rotterdam, Netherlands; [Vernooij, Meike W.] Erasmus MC, Dept Radiol & Nucl Med, POB 2040, NL-3000 CA Rotterdam, Netherlands; [Dubost, Florian] Stanford Univ, Dept Biomed Data Sci, Stanford, CA 94305 USA; [van Tulder, Gijs] Radboud Univ Nijmegen, Fac Sci, Nijmegen, Netherlands; [de Bruijne, Marleen] Univ Copenhagen, Dept Comp Sci, Machine Learning Sect, Copenhagen, Denmark	Erasmus University Rotterdam; Erasmus MC; Erasmus University Rotterdam; Erasmus MC; Erasmus University Rotterdam; Erasmus MC; Stanford University; Radboud University Nijmegen; University of Copenhagen	Bortsova, G (corresponding author), Erasmus MC, Biomed Imaging Grp Rotterdam, Dept Radiol & Nucl Med, POB 2040, NL-3000 CA Rotterdam, Netherlands.	g.bortsova@erasmusmc.nl		Bos, Daniel/0000-0001-8979-2603; Vernooij, Meike/0000-0003-4658-2176	Dutch Technology Foundation STW, Netherlands Organisation for Scientific Research - Ministry of Economic Affairs [P15-26]	Dutch Technology Foundation STW, Netherlands Organisation for Scientific Research - Ministry of Economic Affairs	This research is part of the research project Deep Learning for Medical Image Analysis (project no. P15-26), funded by the Dutch Technology Foundation STW, which is part of the Netherlands Organisation for Scientific Research, and which is partly funded by the Ministry of Economic Affairs.	Ahn SS, 2013, EUR RADIOL, V23, P20, DOI 10.1007/s00330-012-2586-z; Arenillas JF, 2011, STROKE, V42, pS20, DOI 10.1161/STROKEAHA.110.597278; Arnett DK, 2019, CIRCULATION, V140, pE596, DOI [10.1161/CIR.0000000000000678, 10.1016/j.jacc.2019.03.010, 10.1161/CIR.0000000000000677, 10.1016/j.jacc.2019.03.009]; BLAND JM, 1986, LANCET, V1, P307, DOI 10.1016/s0140-6736(86)90837-8; Bleeker L, 2012, NEURORADIOLOGY, V54, P919, DOI 10.1007/s00234-011-0998-0; Bortsova G, 2017, INT C MED IM COMP CO, P356; Bos D, 2015, ALZHEIMERS DEMENT, V11, P639, DOI 10.1016/j.jalz.2014.05.1758; Bos D, 2014, JAMA NEUROL, V71, P405, DOI 10.1001/jamaneurol.2013.6223; Chellamuthu K, 2017, I S BIOMED IMAGING, P388, DOI 10.1109/ISBI.2017.7950544; Compagne KCJ, 2018, STROKE, V49, P2961, DOI 10.1161/STROKEAHA.118.022400; de Weert TT, 2009, AM J NEURORADIOL, V30, P177, DOI 10.3174/ajnr.A1301; Dey D, 2019, J AM COLL CARDIOL, V73, P1317, DOI 10.1016/j.jacc.2018.12.054; Hernandez-Perez M, 2017, STROKE, V48, P342, DOI 10.1161/STROKEAHA.116.015166; Ikram MA, 2017, EUR J EPIDEMIOL, V32, P807, DOI 10.1007/s10654-017-0321-4; Kamnitsas K, 2018, LECT NOTES COMPUT SC, V10670, P450, DOI 10.1007/978-3-319-75238-9_38; Kockelkoren R, 2018, J AM COLL CARDIOL, V72, P582, DOI 10.1016/j.jacc.2018.05.021; Kockelkoren R, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0168360; Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Lessmann N, 2018, IEEE T MED IMAGING, V37, P615, DOI 10.1109/TMI.2017.2769839; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Marstal K, 2016, IEEE COMPUT SOC CONF, P574, DOI 10.1109/CVPRW.2016.78; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; SHROUT PE, 1979, PSYCHOL BULL, V86, P420, DOI 10.1037/0033-2909.86.2.420; Subedi D, 2015, STROKE, V46, P2504, DOI 10.1161/STROKEAHA.115.009716; Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28; Taoka T, 2006, J COMPUT ASSIST TOMO, V30, P624, DOI 10.1097/00004728-200607000-00012; van Engelen A, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0094840	29	1	1	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2021	3	5							e200226	10.1148/ryai.2021200226	http://dx.doi.org/10.1148/ryai.2021200226			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9TT	34617024	Green Published, Green Submitted			2022-12-18	WOS:000826911500005
J	Fischer, M; Walter, SS; Hepp, T; Zimmer, M; Notohamiprodjo, M; Schick, F; Yang, B				Fischer, Marc; Walter, Sven S.; Hepp, Tobias; Zimmer, Manuela; Notohamiprodjo, Mike; Schick, Fritz; Yang, Bin			Automated Morphometric Analysis of the Hip Joint on MRI from the German National Cohort Study	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Computer-Aided Diagnosis (CAD); Interventional-MSK; MR-Imaging; Neural Networks; Skeletal-Appendicular; Hip; Anatomy; Computer Applications-3D; Segmentation; Vision; Application Domain; Quantification	HEAD-NECK JUNCTION; FEMOROACETABULAR IMPINGEMENT; ALPHA ANGLE; CAM; CT; SHAPE; MORPHOLOGY; MODELS	Purpose: To develop and validate an automated morphometric analysis framework for the quantitative analysis of geometric hip joint parameters in MR images from the German National Cohort (GNC) study. Materials and Methods: A secondary analysis on 40 participants (mean age, 51 years; age range, 30-67 years; 25 women) from the prospective GNC MRI study (2015-2016) was performed. Based on a proton density-weighted three-dimensional fast spin-echo sequence, a morphometric analysis approach was developed, including deep learning-based landmark localization, bone segmentation of the femora and pelvis, and a shape model for annotation transfer. The centrum-collum-diaphyseal, center-edge (CE), three alpha angles, head-neck offset (HNO), and HNO ratio along with the acetabular depth, inclination, and anteversion were derived. Quantitative validation was provided by comparison with average manual assessments of radiologists in a cross-validation format. Paired-sample t tests with a Bonferroni-corrected significance level of.005 were employed alongside mean differences and 10th/90th percentiles, median absolute deviations (MADs), and intraclass correlation coefficients (ICCs). Results: High agreement in mean Dice similarity coefficients was achieved (average of 97.52% +/- 0.46 [standard deviation]). The subsequent morphometric analysis produced results with low mean MAD values, with the highest values of 3.34 degrees (alpha 03:00 o'clock position) and 0.87 mm (HNO) and ICC values ranging between 0.288 (HNO ratio) and 0.858 (CE) compared with manual assessments. These values were in line with interreader agreements, which at most had MAD values of 4.02 degrees (alpha 12:00 o'clock position) and 1.07 mm (HNO) and ICC values ranging between 0.218 (HNO ratio) and 0.777 (CE). Conclusion: Automatic extraction of geometric hip parameters from MRI is feasible using a morphometric analysis approach with deep learning. Supplemental material is available for this article. (C) RSNA, 2021.	[Fischer, Marc; Zimmer, Manuela; Yang, Bin] Univ Stuttgart, Inst Signal Prooessing & Syst Iheory, Plaffenwalthing 47, D-70550 Stuttgart, Germany; [Walter, Sven S.; Zimmer, Manuela; Notohamiprodjo, Mike; Schick, Fritz] Univ Hosp Tubingen, Sect Expt Radiol, Dept Diagnost & Intervent Radiol, Tubingen, Germany; [Hepp, Tobias] Max Planck Inst Intelligent Syst, Empir Inference Dept, Tubingen, Germany	University of Stuttgart; Eberhard Karls University of Tubingen; Eberhard Karls University Hospital; Max Planck Society	Fischer, M (corresponding author), Univ Stuttgart, Inst Signal Prooessing & Syst Iheory, Plaffenwalthing 47, D-70550 Stuttgart, Germany.	marc.fischer@iss.uni-stuttgart.de		Zimmer, Manuela/0000-0003-2405-863X; Schick, Fritz/0000-0002-4231-3406	Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) [325028047]	Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)(German Research Foundation (DFG))	Supported by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation; grant 325028047).	Bamberg F, 2015, RADIOLOGY, V277, P206, DOI 10.1148/radiol.2015142272; Cerveri P, 2010, ANN BIOMED ENG, V38, P1752, DOI 10.1007/s10439-010-9965-x; Chadayammuri V, 2015, J HIP PRESERV SURG, V2, P392, DOI 10.1093/jhps/hnv063; Chen RN, 2019, LECT NOTES COMPUT SC, V11766, P873, DOI 10.1007/978-3-030-32248-9_97; Clohisy JC, 2009, CLIN ORTHOP RELAT R, V467, P666, DOI 10.1007/s11999-008-0626-4; De Brabandere B, 2016, ADV NEUR IN, V29; Deniz CM, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-34817-6; Gollwitzer H, 2018, BONE JOINT J, V100B, P570, DOI 10.1302/0301-620X.100B5.BJJ-2017-0249.R3; Gras F, 2015, CLIN ORTHOP RELAT R, V473, P361, DOI 10.1007/s11999-014-3932-z; Hack K, 2010, J BONE JOINT SURG AM, V92A, P2436, DOI 10.2106/JBJS.J.01280; Harris MD, 2013, ANN BIOMED ENG, V41, P1162, DOI 10.1007/s10439-013-0762-1; Hartel MJ, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0149480; Heimann T, 2009, MED IMAGE ANAL, V13, P543, DOI 10.1016/j.media.2009.05.004; Hepp T, 2020, J THORAC IMAG, V35, P389, DOI 10.1097/RTI.0000000000000522; Higgins SW, 2014, J BONE JOINT SURG AM, V96A, P1776, DOI 10.2106/JBJS.L.01141; Lawin FJ, 2018, PROC CVPR IEEE, P3829, DOI 10.1109/CVPR.2018.00403; Lerch TD, 2019, AM J SPORT MED, V47, P2966, DOI 10.1177/0363546519869681; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Liu F, 2018, MAGN RESON MED, V79, P2379, DOI 10.1002/mrm.26841; Mascarenhas VV, 2017, EUR RADIOL, V27, P2011, DOI 10.1007/s00330-016-4530-0; Mehta S, 2018, LECT NOTES COMPUT SC, V11214, P561, DOI 10.1007/978-3-030-01249-6_34; Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46; Ng KCG, 2018, COMP M BIO BIO E-IV, V6, P293, DOI 10.1080/21681163.2016.1216805; Papandreou G, 2017, PROC CVPR IEEE, P3711, DOI 10.1109/CVPR.2017.395; Pfirrmann CWA, 2006, RADIOLOGY, V240, P778, DOI 10.1148/radiol.2403050767; Samim M, 2019, SKELETAL RADIOL, V48, P429, DOI 10.1007/s00256-018-3049-7; Schmaranzer F, 2019, CLIN ORTHOP RELAT R, V477, P1036, DOI 10.1097/CORR.0000000000000755; Schroder M., 2014, OPEN MED J, V1, P15, DOI DOI 10.2174/1874220301401010015; Sudlow C, 2015, PLOS MED, V12, DOI 10.1371/journal.pmed.1001779; Sutter R, 2012, RADIOLOGY, V264, P514, DOI 10.1148/radiol.12112479; Tawada K, 2015, J ORTHOP SCI, V20, P498, DOI 10.1007/s00776-015-0704-x; Terjesen T, 2012, SKELETAL RADIOL, V41, P811, DOI 10.1007/s00256-011-1293-1; Thiesen DM, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0204961; Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1; Xia Y, 2015, PHYS MED BIOL, V60, P7601, DOI 10.1088/0031-9155/60/19/7601; Zeng G, 2018, INT WORKSHOP COMPUTA, P35; Zhang C, 2015, CAN FAM PHYSICIAN, V61, P1055; Zhang J, 2014, COMP M BIO BIO E-IV, V2, P176, DOI 10.1080/21681163.2013.878668; Zhang RY, 2020, J ORTHOP SURG RES, V15, DOI 10.1186/s13018-020-01712-8	39	1	1	0	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2021	3	5							e200213	10.1148/ryai.2021200213	http://dx.doi.org/10.1148/ryai.2021200213			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9TT	34617023	Green Published			2022-12-18	WOS:000826911500004
J	Hu, L; Zhou, DW; Zha, YF; Li, L; He, H; Xu, WH; Qian, L; Zhang, YK; Fu, CX; Hu, H; Zhao, JG				Hu, Lei; Zhou, Da-wei; Zha, Yun-fei; Li, Liang; He, Huan; Xu, Wen-hao; Qian, Li; Zhang, Yi-kun; Fu, Cai-xia; Hu, Hui; Zhao, Jun-gong			Synthesizing High-b-Value Diffusion-weighted Imaging of the Prostate Using Generative Adversarial Networks	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							QUALITY; IMPACT; MRI	Purpose: To develop and evaluate a diffusion-weighted imaging (DWI) deep learning framework based on the generative adversarial network (GAN) to generate synthetic high-b-value (b = 1500 sec/mm(2)) DWI (SYNb1500) sets from acquired standard-b-value (b = 800 sec/mm(2)) DWI (ACQ(b800)) and acquired standard-b-value (b = 1000 sec/mm(2)) DWI (ACQ(b1000)) sets. Materials and Methods: This retrospective multicenter study included 395 patients who underwent prostate multiparametric MRI. This cohort was split into internal training (96 patients) and external testing (299 patients) datasets. To create SYNb1500 sets from ACQ(b800) and ACQ(b1000) sets, a deep learning model based on GAN (M-0 was developed by using the internal dataset. M-0 was trained and compared with a conventional model based on the cycle GAN (M-cyc). M-0 was further optimized by using denoising and edge-enhancement techniques (optimized version of the M-0 [Opt-M-0). The SYNb1500 sets were synthesized by using the M-0 and the Opt-M-0 were synthesized by using ACQ(b800 )and ACQ(b1000) sets from the external testing dataset. For comparison, traditional calculated (b = 1500 sec/mm(2)) DWI (CAL(b1500)) sets were also obtained. Reader ratings for image quality and prostate cancer detection were performed on the acquired high-b-value (b = 1500 sec/mm(2)) DWI (ACQ(b1500)), CAL(b1500), and SYNb1500 sets and the SYNb1500 set generated by the Opt-M-0 (Opt-SYNb1500). Wilcoxon signed rank tests were used to compare the readers' scores. A multiple-reader multiple-case receiver operating characteristic curve was used to compare the diagnostic utility of each DWI set. Results: When compared with the M-cyc, the M-0 yielded a lower mean squared difference and higher mean scores for the peak signal-to-noiseratio, structural similarity, and feature similarity (P<.001 for all). Opt-SYNb1500 resulted in significantly better image quality (P <=.001 for all) and a higher mean area under the curve than ACQ(b1500) and CAL(b1500) (P <=.042 for all). Conclusion: A deep learning framework based on GAN is a promising method to synthesize realistic high-b-value DWI sets with good image quality and accuracy in prostate cancer detection. (C) RSNA, 2021	[Hu, Lei; Xu, Wen-hao; Zhao, Jun-gong] Shanghai Jiao Tong Univ Affiliated Peoples Hosp 6, Dept Diagnost & Intervent Radiol, 600 Yi Shan Rd, Shanghai 200233, Peoples R China; [Zhou, Da-wei] Xidian Univ, Sch Telecommun Engn, State Key Lab Integrated Serv Networks, Xian, Peoples R China; [Zha, Yun-fei; Li, Liang; He, Huan; Qian, Li; Zhang, Yi-kun] Wuhan Univ, Renmin Hosp, Dept Radiol, Wuhan, Peoples R China; [Fu, Cai-xia] Siemens Shenzhen MR, MR Applicat Dev, Shenzhen, Peoples R China; [Hu, Hui] Jiangsu Univ, Affiliated Renmin Hosp, Dept Radiol, Zhenjiang, Jiangsu, Peoples R China	Shanghai Jiao Tong University; Xidian University; Wuhan University; Jiangsu University	Zhao, JG (corresponding author), Shanghai Jiao Tong Univ Affiliated Peoples Hosp 6, Dept Diagnost & Intervent Radiol, 600 Yi Shan Rd, Shanghai 200233, Peoples R China.	zhaojungongradio@hotmail.com		hu, lei/0000-0002-9124-5411; Zhou, Dawei/0000-0002-0694-3603; Zha, Yunfei/0000-0002-8714-7472				Armanious K, 2020, COMPUT MED IMAG GRAP, V79, DOI 10.1016/j.compmedimag.2019.101684; Ben-Amitay S, 2012, MAGN RESON MED, V67, P1694, DOI 10.1002/mrm.23186; Bittencourt LK, 2014, WORLD J RADIOL, V6, P374, DOI 10.4329/wjr.v6.i6.374; Brendle C, 2016, EUR J RADIOL, V85, P893, DOI 10.1016/j.ejrad.2016.02.020; Chartsias A, 2018, LECT NOTES COMPUT SC, V11071, P490, DOI 10.1007/978-3-030-00934-2_55; Chen CF, 2019, LECT NOTES COMPUT SC, V11361, P216, DOI 10.1007/978-3-030-20887-5_14; Chuquicusma MJM, 2018, I S BIOMED IMAGING, P240; Cohen JP, 2018, LECT NOTES COMPUT SC, V11070, P529, DOI 10.1007/978-3-030-00928-1_60; Glaister J, 2012, IEEE ENG MED BIO, P420, DOI 10.1109/EMBC.2012.6345957; Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622; Hectors SJ, 2018, RADIOLOGY, V286, P938, DOI 10.1148/radiol.2017170904; Jendoubi S, 2019, EUR RADIOL, V29, P5197, DOI 10.1007/s00330-019-06085-z; Kasivisvanathan V, 2018, NEW ENGL J MED, V378, P1767, DOI 10.1056/NEJMoa1801993; Katahira K, 2011, EUR RADIOL, V21, P188, DOI 10.1007/s00330-010-1883-7; Kim H, 2015, KOREAN J RADIOL, V16, P1216, DOI 10.3348/kjr.2015.16.6.1216; Kitchen A, ARXIV 170800129 PREP; Koh DM, 2012, AM J ROENTGENOL, V199, P252, DOI 10.2214/AJR.11.7866; Lee JH, 2020, J KOREAN NEUROSURG S, V63, P386, DOI 10.3340/jkns.2019.0084; Lei Y, 2019, MED PHYS, V46, P3565, DOI 10.1002/mp.13617; Li C, 2016, PROC CVPR IEEE, P2479, DOI 10.1109/CVPR.2016.272; Maas MC, 2013, INVEST RADIOL, V48, P779, DOI 10.1097/RLI.0b013e31829705bb; Ohgiya Y, 2012, CLIN IMAG, V36, P526, DOI 10.1016/j.clinimag.2011.11.016; Rosenkrantz AB, 2015, ABDOM IMAGING, V40, P120, DOI 10.1007/s00261-014-0181-2; Rosenkrantz AB, 2013, EUR RADIOL, V23, P3170, DOI 10.1007/s00330-013-2917-8; Rosenkrantz AB, 2013, J MAGN RESON IMAGING, V38, P694, DOI 10.1002/jmri.24016; Sara U, 2019, J COMPUT COMMUN, V07, P8, DOI [DOI 10.4236/JCC.2019.73002, 10.4236/jcc.2019.73002]; Tamada T, 2017, J COMPUT ASSIST TOMO, V41, P949, DOI 10.1097/RCT.0000000000000634; Thierfelder KM, 2014, EUR RADIOL, V24, P3233, DOI 10.1007/s00330-014-3347-y; Ueno Y, 2015, BRIT J RADIOL, V88, DOI 10.1259/bjr.20140738; Weinreb JC, 2016, EUR UROL, V69, P16, DOI 10.1016/j.eururo.2015.08.052; Wolterink JM, 2017, IEEE T MED IMAGING, V36, P2536, DOI 10.1109/TMI.2017.2708987; Yu ZK, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0682-x; Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206; Zhu YB, 2019, EUR J RADIOL, V116, P128, DOI 10.1016/j.ejrad.2019.04.022	34	1	1	3	5	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2021	3	5							e200237	10.1148/ryai.2021200237	http://dx.doi.org/10.1148/ryai.2021200237			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9TT	34617025	Green Published			2022-12-18	WOS:000826911500006
J	Mongan, J; Kalpathy-Cramer, J; Flanders, A; Linguraru, MG				Mongan, John; Kalpathy-Cramer, Jayashree; Flanders, Adam; Linguraru, Marius George			RSNA-MICCAI Panel Discussion: Machine Learning for Radiology from Challenges to Clinical Applications	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Back-Propagation; Artificial Neural Network Algorithms; Machine Learning Algorithms		On October 5, 2020, the Medical Image Computing and Computer Assisted Intervention Society (MICCAI) 2020 conference hosted a virtual panel discussion with members of the Machine Learning Steering Subcommittee of the Radiological Society of North America. The MICCAI Society brings together scientists, engineers, physicians, educators, and students from around the world. Both societies share a vision to develop radiologic and medical imaging techniques through advanced quantitative imaging biomarkers and artificial intelligence. The panel elaborated on how collaborations between radiologists and machine learning scientists facilitate the creation and clinical success of imaging technology for radiology. This report presents structured highlights of the moderated dialogue at the panel. (C) RSNA, 2021	[Mongan, John] Univ Calif San Francisco, Dept Radiol & Biomed Imaging, 505 Parnassus Ave,Room M-391, San Francisco, CA 94143 USA; [Kalpathy-Cramer, Jayashree] Massachusetts Gen Hosp, Dept Radiol, Boston, MA 02114 USA; [Kalpathy-Cramer, Jayashree] Massachusetts Gen Hosp, MGH & BWH Ctr Clin Data Sci, Boston, MA 02114 USA; [Flanders, Adam] Thomas Jefferson Univ Hosp, Dept Radiol, Philadelphia, PA 19107 USA; [Linguraru, Marius George] Childrens Natl Hosp, Sheikh Zayed Inst Pediat Surg Innovat, Washington, DC USA; [Linguraru, Marius George] George Washington Univ, Sch Med, Dept Pediat, Washington, DC 20052 USA; [Linguraru, Marius George] George Washington Univ, Sch Med, Dept Radiol, Washington, DC 20052 USA	University of California System; University of California San Francisco; Harvard University; Massachusetts General Hospital; Harvard University; Massachusetts General Hospital; Jefferson University; Children's National Health System; George Washington University; George Washington University	Mongan, J (corresponding author), Univ Calif San Francisco, Dept Radiol & Biomed Imaging, 505 Parnassus Ave,Room M-391, San Francisco, CA 94143 USA.	john.mongan@ucsf.edu		Flanders, Adam/0000-0002-4679-0787; Mongan, John/0000-0003-2765-7451; Kalpathy-Cramer, Jayashree/0000-0001-8906-9618				A. J.DeGrave, 2020, medRxiv, DOI 10.1101/2020.09.13.20193565; Saporta A, 2022, medRxiv, DOI 10.1101/2021.02.28.21252634; Adebayo J., 2018, ARXIV; Arun NT, 2020, ARXIV; Mongan J, 2020, RADIOL ARTIF INTELL, V2; Taylor AG, 2018, PLOS MED, V15; World Health Organization, 2012, SIGARCH COMPUT ARCHI, P1, DOI [DOI 10.1145/1186736.1186737, 10.1145/1186736.1186737]; Zhu GM, 2019, FRONT NEUROL, V10, DOI 10.3389/fneur.2019.00869	8	1	1	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2021	3	5							e210118	10.1148/ryai.2021210118	http://dx.doi.org/10.1148/ryai.2021210118			5	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9TT	34617032	Green Published			2022-12-18	WOS:000826911500013
J	Pan, I				Pan, Ian			Deep Learning for Pulmonary Embolism Detection: Tackling the RSNA 2020 AI Challenge	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						CT; Neural Networks; Thorax; Pulmonary Arteries; Embolism/Thrombosis; Supervised Learning; Convolutional Neural Networks (CNN); Machine Learning Algorithms		In 2020, the Radiological Society of North America and Society of Thoracic Radiology sponsored a machine learning competition to detect and classify pulmonary embolism (PE). This challenge was one of the largest of its kind, with more than 9000 CT pulmonary angiography examinations comprising almost 1.8 million expertly annotated images. More than 700 international teams competed to predict the presence of PE on individual axial images, the overall presence of PE in the CT examination (with chronicity and laterality), and the ratio of right ventricular size to left ventricular size. This article presents a detailed overview of the second-place solution. Source code and models are available at https://github.com/i-pan/kaggle-rsna-pe. (C)RSNA, 2021	[Pan, Ian] Univ Hosp Cleveland, Med Ctr, 11100 Euclid Ave, Cleveland, OH 44106 USA; [Pan, Ian] Case Western Reserve Univ, Sch Med, Cleveland, OH 44106 USA; [Pan, Ian] Harvard Med Sch, Dept Radiol, Brigham & Womens Hosp, Boston, MA 02115 USA	Case Western Reserve University; Case Western Reserve University Hospital; University Hospitals of Cleveland; Case Western Reserve University; Harvard University; Brigham & Women's Hospital; Harvard Medical School	Pan, I (corresponding author), Univ Hosp Cleveland, Med Ctr, 11100 Euclid Ave, Cleveland, OH 44106 USA.; Pan, I (corresponding author), Case Western Reserve Univ, Sch Med, Cleveland, OH 44106 USA.; Pan, I (corresponding author), Harvard Med Sch, Dept Radiol, Brigham & Womens Hosp, Boston, MA 02115 USA.	ianpan358@gmail.com		Pan, Ian/0000-0002-0650-6614				[Anonymous], PYTORCH IMAGE MODELS; [Anonymous], LABEL CONSISTENCY RE; Carion N, ARXIV PREPRINT; Cho K., 2014, P 2014 C EMP METH NA, P1724; Cob E, 2021, RADIOL-ARTIF INTELL, V3, DOI 10.1148/ryai.2021200254; Cubuk ED, 2020, IEEE COMPUT SOC CONF, P3008, DOI 10.1109/CVPRW50498.2020.00359; Dosovitskiy A, ARXIV PREPRINT; Flanders AE, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190211; Ghadiyaram D, 2019, PROC CVPR IEEE, P12038, DOI 10.1109/CVPR.2019.01232; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.8.1735, 10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Lee H, ARXIV PREPRINT; Liu L, ARXIV PREPRINT; Loshchilov I, ARXIV PREPRINT; Micikevicius Paulius, 2018, P 6 INT C LEARN REPR, DOI [10.48550/arXiv.1710.03740, DOI 10.1109/CAMAD.2018.8514963]; Prevedello LM, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180031; Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566; Shih G, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180041; Tan MX, 2019, PR MACH LEARN RES, V97; Vaswani A, 2017, ADV NEUR IN, V30; Wittram C, 2004, RADIOGRAPHICS, V24, P1219, DOI 10.1148/rg.245045008; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Wu C, ARXIV WEBSITE; Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981	24	1	1	1	3	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2021	3	5							e210068	10.1148/ryai.2021210068	http://dx.doi.org/10.1148/ryai.2021210068			7	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9TT	34617031	Green Published			2022-12-18	WOS:000826911500012
J	Hooper, SM; Dunnmon, JA; Lungren, MP; Mastrodicasa, D; Rubin, DL; Re, C; Wang, A; Patel, BN				Hooper, Sarah M.; Dunnmon, Jared A.; Lungren, Matthew P.; Mastrodicasa, Domenico; Rubin, Daniel L.; Re, Christopher; Wang, Adam; Patel, Bhavik N.			Impact of Upstream Medical Image Processing on Downstream Performance of a Head CT Triage Neural Network	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							COMPUTED-TOMOGRAPHY; DEEP	Purpose: To develop a convolutional neural network (CNN) to triage head CT (HCT) studies and investigate the effect of upstream medical image processing on the CNN's performance. Materials and Methods: A total of 9776 HCT studies were retrospectively collected from 2001 through 2014, and a CNN was trained to triage them as normal or abnormal. CNN performance was evaluated on a held-out test set, assessing triage performance and sensitivity to 20 disorders to assess differential model performance, with 7856 CT studies in the training set, 936 in the validation set, and 984 in the test set. This CNN was used to understand how the upstream imaging chain affects CNN performance by evaluating performance after altering three variables: image acquisition by reducing the number of x-ray projections, image reconstruction by inputting sinogram data into the CNN, and image preprocessing. To evaluate performance, the DeLong test was used to assess differences in the area under the receiver operating characteristic curve (AUROC), and the McNemar test was used to compare sensitivities. Results: The CNN achieved a mean AUROC of 0.84 (95% CI: 0.83, 0.84) in discriminating normal and abnormal HCT studies. The number of x-ray projections could be reduced by 16 times and the raw sensor data could be input into the CNN with no statistically significant difference in classification performance. Additionally, CT windowing consistently improved CNN performance, increasing the mean triage AUROC by 0.07 points. Conclusion: A CNN was developed to triage HCT studies, which may help streamline image evaluation, and the means by which upstream image acquisition, reconstruction, and preprocessing affect downstream CNN performance was investigated, bringing focus to this important part of the imaging chain. (C) RSNA, 2021	[Hooper, Sarah M.] Stanford Univ, Dept Elect Engn, 450 Serra Mall, Stanford, CA 94305 USA; [Dunnmon, Jared A.; Re, Christopher] Stanford Univ, Dept Comp Sci, 450 Serra Mall, Stanford, CA 94305 USA; [Lungren, Matthew P.; Mastrodicasa, Domenico; Rubin, Daniel L.; Wang, Adam] Stanford Univ, Dept Radiol, 450 Serra Mall, Stanford, CA 94305 USA; [Dunnmon, Jared A.; Rubin, Daniel L.] Stanford Univ, Dept Biomed Data Sci, 450 Serra Mall, Stanford, CA 94305 USA; [Lungren, Matthew P.; Rubin, Daniel L.] Stanford Univ, Ctr Artificial Intelligence Med & Imaging, 450 Serra Mall, Stanford, CA 94305 USA; [Patel, Bhavik N.] Mayo Clin, Dept Radiol, Scottsdale, AZ 85259 USA	Stanford University; Stanford University; Stanford University; Stanford University; Stanford University; Mayo Clinic; Mayo Clinic Phoenix	Patel, BN (corresponding author), Mayo Clin, Dept Radiol, Scottsdale, AZ 85259 USA.	patel.bhavik@mayo.edu	Mastrodicasa, Domenico/J-8637-2019; Rubin, Daniel/E-3740-2010	Mastrodicasa, Domenico/0000-0001-8227-0757; Rubin, Daniel/0000-0001-5057-4369; Hooper, Sarah/0000-0001-9366-2174; Wang, Adam/0000-0001-9234-1264; Lungren, Matthew/0000-0002-8591-5861	General Electric; Defense Advanced Research Projects Agency [FA86501827865, FA86501827882]; National Institutes of Health [U54EB020405]; National Science Foundation [CCF1763315, 1937301, N000141712266, <LF> DGE-1656518<LF>CCF1563078]; Office of Naval Research [N000141712266]; Moore Foundation; NXP; Xilinx; LETI-CEA; Intel; IBM; Microsoft; NEC; Toshiba; TSMC; ARM; Hitachi; BASF; Accenture; Ericsson; Qualcomm; Analog Devices; Okawa Foundation; American Family Insurance; Google Cloud; Swiss Re; HAI-AWS Cloud Credits for Research program; Teradata; Facebook; Google; Ant Financial; VMWare; Infosys; Fannie and John Hertz Foundation; National Science Foundation Graduate Research Fellowship [DGE-1656518]; Stanford Graduate Fellowship in Science and Engineering; Intelligence Community Postdoctoral Fellowship; National Institute of Biomedical Imaging and Bioengineering grant [5T32EB009035]	General Electric(General Electric); Defense Advanced Research Projects Agency(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); National Science Foundation(National Science Foundation (NSF)); Office of Naval Research(Office of Naval Research); Moore Foundation(Gordon and Betty Moore Foundation); NXP; Xilinx; LETI-CEA; Intel(Intel Corporation); IBM(International Business Machines (IBM)); Microsoft(Microsoft); NEC; Toshiba; TSMC; ARM; Hitachi; BASF(BASF); Accenture; Ericsson(Ericsson); Qualcomm; Analog Devices; Okawa Foundation; American Family Insurance; Google Cloud(Google Incorporated); Swiss Re; HAI-AWS Cloud Credits for Research program; Teradata; Facebook(Facebook Inc); Google(Google Incorporated); Ant Financial; VMWare; Infosys; Fannie and John Hertz Foundation; National Science Foundation Graduate Research Fellowship(National Science Foundation (NSF)); Stanford Graduate Fellowship in Science and Engineering; Intelligence Community Postdoctoral Fellowship; National Institute of Biomedical Imaging and Bioengineering grant	Supported by an industry-sponsored grant from General Electric. Also supported by Defense Advanced Research Projects Agency grants FA86501827865 (SDH) and FA86501827882 (ASED); National Institutes of Health grant U54EB020405 (Mobilize); National Science Foundation grants CCF1763315 (Beyond Sparsity), CCF1563078 (Volume to Velocity), and 1937301 (RTML); Office of Naval Research grant N000141712266 (Unifying Weak Supervision); and the Moore Foundation, NXP, Xilinx, LETI-CEA, Intel, IBM, Microsoft, NEC, Toshiba, TSMC, ARM, Hitachi, BASF, Accenture, Ericsson, Qualcomm, Analog Devices, the Okawa Foundation, American Family Insurance, Google Cloud, Swiss Re, the HAI-AWS Cloud Credits for Research program, and members of the Stanford DAWN project: Teradata, Facebook, Google, Ant Financial, NEC, VMWare, and Infosys. S.M.H. supported by the Fannie and John Hertz Foundation, a National Science Foundation Graduate Research Fellowship grant (DGE-1656518), and as a Texas Instruments Fellow under the Stanford Graduate Fellowship in Science and Engineering. J.A.D. supported by the Intelligence Community Postdoctoral Fellowship. D.M. supported in part by a National Institute of Biomedical Imaging and Bioengineering grant (5T32EB009035).	[Anonymous], 1999, 10153 BS EN; Arbabshirani MR, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-017-0015-z; Chang PD, 2018, AM J NEURORADIOL, V39, P1609, DOI 10.3174/ajnr.A5742; Chen H, 2017, IEEE T MED IMAGING, V36, P2524, DOI 10.1109/TMI.2017.2715284; Chilamkurthy S, 2018, LANCET, V392, P2388, DOI 10.1016/S0140-6736(18)31645-3; Coles JP, 2007, BRIT J ANAESTH, V99, P49, DOI 10.1093/bja/aem141; De Man B, 2007, P SPIE MEDICAL IMAGI, V6510; EISENBERG HM, 1990, J NEUROSURG, V73, P688, DOI 10.3171/jns.1990.73.5.0688; Gao XHW, 2017, COMPUT METH PROG BIO, V138, P49, DOI 10.1016/j.cmpb.2016.10.007; Gies M, 1999, MED PHYS, V26, P2235, DOI 10.1118/1.598779; Glorot X., 2010, P 13 INT C ART INT S, P249, DOI DOI 10.1.1/207.2059; Goldman LW, 2007, J NUCL MED TECHNOL, V35, DOI 10.2967/jnmt.106.037846; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123; Hooper SM, ARXIV200307977 PREPR; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Ker J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092167; Kingma DP, ARXIV14126980 PREPRI; Kuo WC, 2019, P NATL ACAD SCI USA, V116, P22737, DOI 10.1073/pnas.1908021116; Lee EJ, 2017, J STROKE, V19, P277, DOI 10.5853/jos.2017.02054; Lee H, ARXIV181200572 PREPR; Lee H, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-51779-5; Lee H, 2019, NAT BIOMED ENG, V3, P173, DOI 10.1038/s41551-018-0324-9; Lisowska A, 2017, PROCEEDINGS OF THE 10TH INTERNATIONAL JOINT CONFERENCE ON BIOMEDICAL ENGINEERING SYSTEMS AND TECHNOLOGIES, VOL 2: BIOIMAGING, P24, DOI 10.5220/0006114600240033; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Paszke A, 2019, ADV NEUR IN, V32; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Primak AN, 2006, RADIOGRAPHICS, V26, P1785, DOI 10.1148/rg.266065063; Seabold S., 2010, 9 PYTH SCI C, DOI [10.25080/Majora-92bf1922-011, DOI 10.25080/MAJORA-92BF1922-011]; Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI 10.1146/annurev-bioeng-071516-044442; Titano JJ, 2018, NAT MED, V24, P1337, DOI 10.1038/s41591-018-0147-y; Wurfl T, 2018, IEEE T MED IMAGING, V37, P1454, DOI 10.1109/TMI.2018.2833499; Yi X, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101552; Zaharchuk G, 2018, AM J NEURORADIOL, V39, P1776, DOI 10.3174/ajnr.A5543; zeiler MD, ARXIV12125701 PREPRI	35	1	1	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2021	3	4							e200229	10.1148/ryai.2021200229	http://dx.doi.org/10.1148/ryai.2021200229			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SU	34350412	Green Published			2022-12-18	WOS:000826909000011
J	Mazurowski, MA				Mazurowski, Maciej A.			Do We Expect More from Radiology AI than from Radiologists?	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material						Ethics; Technology Assessment	INTEROBSERVER VARIABILITY		[Mazurowski, Maciej A.] Duke Univ, Dept Radiol, 2424 Erwin Rd,Suite 302, Durham, NC 27705 USA	Duke University	Mazurowski, MA (corresponding author), Duke Univ, Dept Radiol, 2424 Erwin Rd,Suite 302, Durham, NC 27705 USA.	maciej.mazurowski@duke.edu						[Anonymous], WHY IS 2 2 G HINTON; Banja J, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190223; Brill S, 2015, AM BITTER PILL; Chen CF, 2019, ADV NEUR IN, V32; Chen X, 2016, ADV NEUR IN, V29; Cialdini R.B., 2009, INFLUENCE SCI PRACTI, V4; Doshi-Velez F, ARXIV PREPR ARXIV170; Haidt Jonathan, 2012, RIGHTEOUS MIND; Hoang JK, 2018, AM J ROENTGENOL, V211, P162, DOI 10.2214/AJR.17.19192; Kahneman D, 2015, FORTUNE, V172, P20; Langlotz CP, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019190058; Lazarus E, 2006, RADIOLOGY, V239, P385, DOI 10.1148/radiol.2392042127; Mazurowski MA, 2020, ACAD RADIOL, V27, P127, DOI 10.1016/j.acra.2019.04.024; Mazurowski MA, 2019, J AM COLL RADIOL, V16, P1077, DOI 10.1016/j.jacr.2019.01.026; Mazurowski MA, 2019, J MAGN RESON IMAGING, V49, P939, DOI 10.1002/jmri.26534; Rosenthal E, 2018, MO MED, V115, P128; Schier R, 2018, J AM COLL RADIOL, V15, P1004, DOI 10.1016/j.jacr.2018.03.046; Simonyan K, 2013, ARXIV PREPR ARXIV131; Strack F, 1997, J PERS SOC PSYCHOL, V73, P437, DOI 10.1037/0022-3514.73.3.437; Topol E., 2019, DEEP MED ARTIFICIAL; van Hoek J, 2019, EUR J RADIOL, V121, DOI 10.1016/j.ejrad.2019.108742	21	1	1	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2021	3	4							e200221	10.1148/ryai.2021200221	http://dx.doi.org/10.1148/ryai.2021200221			4	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SU	34350411	Green Published, Green Submitted			2022-12-18	WOS:000826909000010
J	Elhalawani, H; Mak, R				Elhalawani, Hesham; Mak, Raymond			Are Artificial Intelligence Challenges Becoming Radiology's New "Bee's Knees"?	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material							OSTEOARTHRITIS		[Elhalawani, Hesham] Harvard Med Sch, Brigham & Womens Hosp, Dept Radiat Oncol, 75 Francis St, Boston, MA 02115 USA; Harvard Med Sch, Dana Farber Canc Inst, 75 Francis St, Boston, MA 02115 USA	Harvard University; Brigham & Women's Hospital; Harvard Medical School; Harvard University; Dana-Farber Cancer Institute; Harvard Medical School	Elhalawani, H (corresponding author), Harvard Med Sch, Brigham & Womens Hosp, Dept Radiat Oncol, 75 Francis St, Boston, MA 02115 USA.	helhalawani@bwh.harvard.edu		Mak, Raymond/0000-0002-8754-0565				[Anonymous], GLOBAL ARTIFICIAL IN; Astuto B, 2021, RADIOL-ARTIF INTELL, V3, DOI 10.1148/ryai.2021200165; Chen PH, 2018, J DIGIT IMAGING, V31, P178, DOI 10.1007/s10278-017-0027-x; Desai AD, 2021, RADIOL-ARTIF INTELL, V3, DOI 10.1148/ryai.2021200078; Eckstein F, 2012, NAT REV RHEUMATOL, V8, P622, DOI 10.1038/nrrheum.2012.113; Emmanuel K, 2016, OSTEOARTHR CARTILAGE, V24, P262, DOI 10.1016/j.joca.2015.08.003; Mollura DJ, 2020, RADIOLOGY, V297, P513, DOI 10.1148/radiol.2020201434; Mongan J, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020200029; Welch ML, 2019, RADIOTHER ONCOL, V130, P2, DOI 10.1016/j.radonc.2018.10.027; Wilkinson MD, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.18; Zhu YT, 2019, JCO CLIN CANCER INFO, V3, DOI 10.1200/CCI.18.00073	11	1	1	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2021	3	3							e210056	10.1148/ryai.2021210056	http://dx.doi.org/10.1148/ryai.2021210056			3	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SA	34138989	Green Published			2022-12-18	WOS:000826907000012
J	Li, HL; Chen, M; Wang, JH; Illapani, VSP; Parikh, NA; He, LL				Li, Hailong; Chen, Ming; Wang, Jinghua; Illapani, Venkata Sita Priyanka; Parikh, Nehal A.; He, Lili			Automatic Segmentation of Diffuse White Matter Abnormality on T2-weighted Brain MR Images Using Deep Learning in Very Preterm Infants	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							HIGH SIGNAL INTENSITY; INJURY	About 50%-80% of very preterm infants (VPIs) (<= 32 weeks gestational age) exhibit diffuse white matter abnormality (DWMA) on their MR images at term-equivalent age. It remains unknown if DWMA is associated with developmental impairments, and further study is warranted. To aid in the assessment of DWMA, a deep learning model for DWMA quantification on T2-weighted MR images was developed. This secondary analysis of prospective data was performed with an internal cohort of 98 VPIs (data collected from December 2014 to April 2016) and an external cohort of 28 VPIs (data collected from January 2012 to August 2014) who had already undergone MRI at term-equivalent age. Ground truth DWMA regions were manually annotated by two human experts with the guidance of a prior published semiautomated algorithm. In a twofold cross-validation experiment using the internal cohort of 98 infants, the three-dimensional (3D) ResU-Net model accurately segmented DWMA with a Dice similarity coefficient of 0.907 +/- 0.041 (standard deviation) and balanced accuracy of 96.0% +/- 2.1, outperforming multiple peer deep learning models. The 3D ResU-Net model that was trained with the whole internal cohort (n = 98) was further tested on an independent external test cohort (n = 28) and achieved a Dice similarity coefficient of 0.877 +/- 0.059 and balanced accuracy of 92.3% +/- 3.9. The externally validated 3D ResU-Net deep learning model for accurately segmenting DWMA may facilitate the clinical diagnosis of DWMA in VPIs. (C) RSNA, 2021	[Li, Hailong; He, Lili] Cincinnati Childrens Hosp Med Ctr, Imaging Res Ctr, Dept Radiol, 3333 Burnet Ave,MLC 5033, Cincinnati, OH 45229 USA; [Li, Hailong; Illapani, Venkata Sita Priyanka; Parikh, Nehal A.; He, Lili] Cincinnati Childrens Hosp Med Ctr, Perinatal Inst, 3333 Burnet Ave,MLC 5033, Cincinnati, OH 45229 USA; [Chen, Ming] Univ Cincinnati, Dept Elect Engn & Comp Syst, Cincinnati, OH USA; [Wang, Jinghua] Deep MRI Imaging, Lewes, DE USA; [Parikh, Nehal A.; He, Lili] Univ Cincinnati, Coll Med, Dept Pediat, Cincinnati, OH 45267 USA	Cincinnati Children's Hospital Medical Center; Cincinnati Children's Hospital Medical Center; University System of Ohio; University of Cincinnati; University System of Ohio; University of Cincinnati	He, LL (corresponding author), Cincinnati Childrens Hosp Med Ctr, Imaging Res Ctr, Dept Radiol, 3333 Burnet Ave,MLC 5033, Cincinnati, OH 45229 USA.; He, LL (corresponding author), Cincinnati Childrens Hosp Med Ctr, Perinatal Inst, 3333 Burnet Ave,MLC 5033, Cincinnati, OH 45229 USA.; He, LL (corresponding author), Univ Cincinnati, Coll Med, Dept Pediat, Cincinnati, OH 45267 USA.	lili.he@ccbmc.org	Wang, Jinghua/U-8468-2018	Wang, Jinghua/0000-0002-9237-4418; Illapani, Venkata Sita Priyanka/0000-0002-6186-3286; Parikh, Nehal/0000-0002-1375-1247	National Institutes of Health [R01-EB029944, R21-HD094085, R01-NS094200, R01-NS096037]; Cincinnati Children's Hospital Medical Center	National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Cincinnati Children's Hospital Medical Center	Supported by the National Institutes of Health (grants R01-EB029944, R21-HD094085, R01-NS094200, and R01-NS096037) and a Trustee grant from Cincinnati Children's Hospital Medical Center.	Bhalerao Megh, 2020, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries. 5th International Workshop, BrainLes 2019. Held in Conjunction with MICCAI 2019. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 11993), P218, DOI 10.1007/978-3-030-46643-5_21; Cainelli E, 2020, PROG NEUROBIOL, V193, DOI 10.1016/j.pneurobio.2020.101845; de Bruine FT, 2011, RADIOLOGY, V261, P899, DOI 10.1148/radiol.11110797; Dyet LE, 2006, PEDIATRICS, V118, P536, DOI 10.1542/peds.2005-1866; Hagmann CF, 2009, RADIOLOGY, V252, P209, DOI 10.1148/radiol.2522080589; Hart AR, 2010, PEDIATR RADIOL, V40, P1390, DOI 10.1007/s00247-010-1633-7; Hart AR, 2010, DEV MED CHILD NEUROL, V52, P652, DOI 10.1111/j.1469-8749.2009.03590.x; He LL, 2015, PEDIATR NEUROL, V53, P330, DOI 10.1016/j.pediatrneurol.2015.05.001; He LL, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0085475; Inder TE, 2003, AM J NEURORADIOL, V24, P805; Iwata S, 2012, PEDIATRICS, V129, pE1138, DOI 10.1542/peds.2011-1735; Jeon TY, 2012, RADIOLOGY, V263, P518, DOI 10.1148/radiol.12111615; Keunen K, 2012, J MATERN-FETAL NEO M, V25, P89, DOI 10.3109/14767058.2012.664343; Kingma D.P, P 3 INT C LEARNING R; Krishnan ML, 2007, PEDIATRICS, V120, pE604, DOI 10.1542/peds.2006-3054; Li HL, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00610; Maalouf EF, 1999, J PEDIATR-US, V135, P351, DOI 10.1016/S0022-3476(99)70133-2; Mathur AM, 2010, SEMIN PERINATOL, V34, P57, DOI 10.1053/j.semperi.2009.10.006; Parikh NA, 2013, PEDIATR NEUROL, V49, P424, DOI 10.1016/j.pediatrneurol.2013.08.026; Pednekar GV, 2018, PROC SPIE, V10576, DOI 10.1117/12.2293622; Rath CP, 2021, ARCH DIS CHILD-FETAL, V106, pF9, DOI 10.1136/archdischild-2019-318207; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Skiold B, 2010, ACTA PAEDIATR, V99, P842, DOI 10.1111/j.1651-2227.2009.01634.x	23	1	2	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2021	3	3							e200166	10.1148/ryai.2021200166	http://dx.doi.org/10.1148/ryai.2021200166			6	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SA	34142089	Green Published			2022-12-18	WOS:000826907000007
J	Auffermann, WF				Auffermann, William F.			Quantifying Pulmonary Edema on Chest Radiographs	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Auffermann, William F.] Univ Utah, Sch Med, Dept Radiol & Imaging Sci, 30 North 1900 East,Room 1A71, Salt Lake City, UT 84132 USA	Utah System of Higher Education; University of Utah	Auffermann, WF (corresponding author), Univ Utah, Sch Med, Dept Radiol & Imaging Sci, 30 North 1900 East,Room 1A71, Salt Lake City, UT 84132 USA.	william.auffermann@hsc.utah.edu						Blecker S, 2014, AM HEART J, V168, P901, DOI 10.1016/j.ahj.2014.08.002; Chartrand G, 2017, RADIOGRAPHICS, V37, P2113, DOI 10.1148/rg.2017170077; Horng S, 2021, RADIOL-ARTIF INTELL, V3, DOI 10.1148/ryai.2021190228; Johnson AEW, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0322-0; Platz E, 2015, EUR J HEART FAIL, V17, P906, DOI 10.1002/ejhf.321; Yancy CW, 2013, CIRCULATION, V128, P1810, DOI 10.1161/CIR.0b013e31829e8807	6	1	1	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2021	3	2							e210004	10.1148/ryai.2021210004	http://dx.doi.org/10.1148/ryai.2021210004			2	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z3LD	33939783	Green Published			2022-12-18	WOS:000826483100010
J	Alderson, PO				Alderson, Philip O.			The Quest for Generalizability in Radiomics	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Alderson, Philip O.] St Louis Univ, Off Student Affairs, 1402 S Grand Blvd,Caroline 100, St Louis, MO 63104 USA		Alderson, PO (corresponding author), St Louis Univ, Off Student Affairs, 1402 S Grand Blvd,Caroline 100, St Louis, MO 63104 USA.	philip.alelersen@health.slu.edu		Alderson, Philip/0000-0003-3617-7433				[Anonymous], 1999, 10153 BS EN; Choe J, 2019, RADIOLOGY, V292, P365, DOI 10.1148/radiol.2019181960; Dercle L, 2020, J NATL CANC I; Lambin P, 2017, NAT REV CLIN ONCOL, V14, P749, DOI 10.1038/nrclinonc.2017.141; Mackin D, 2015, INVEST RADIOL, V50, P757, DOI 10.1097/RLI.0000000000000180; Marcadent S, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190035; Orlhac F, 2019, RADIOLOGY, V291, P52, DOI 10.1148/radiol.2019182023; Orlhac F, 2018, J NUCL MED, V59, P1321, DOI 10.2967/jnumed.117.199935; Zwanenburg A, 2020, RADIOLOGY, V295, P328, DOI 10.1148/radiol.2020191145	9	1	1	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2020	2	3							e200068	10.1148/ryai.2020200068	http://dx.doi.org/10.1148/ryai.2020200068			2	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CW	33939790	Green Published			2022-12-18	WOS:000826470300012
J	Chapiro, J; Duncan, JS				Chapiro, Julius; Duncan, James S.			From Code to Bedside: Introducing Predictive Intelligence to Interventional Oncology	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Chapiro, Julius; Duncan, James S.] Yale Univ, Sch Med, Dept Radiol & Biomed Imaging, Yale Intervent Oncol Res Lab, 300 Cedar St,TAC N312A, New Haven, CT 06510 USA		Chapiro, J (corresponding author), Yale Univ, Sch Med, Dept Radiol & Biomed Imaging, Yale Intervent Oncol Res Lab, 300 Cedar St,TAC N312A, New Haven, CT 06510 USA.	julius.chapiro@yale.edu						Abajian A, 2018, J VASC INTERV RADIOL, V29, P850, DOI 10.1016/j.jvir.2018.01.769; Bello GA, 2019, NAT MACH INTELL, V1, P95, DOI 10.1038/s42256-019-0019-2; European Assoc Study Liver, 2018, J HEPATOL, V69, P182, DOI 10.1016/j.jhep.2018.03.019; Morshid A, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180021; Park JW, 2015, LIVER INT, V35, P2155, DOI 10.1111/liv.12818; Zhuang JT, 2018, LECT NOTES COMPUT SC, V11121, P9, DOI 10.1007/978-3-030-00320-3_2	6	1	1	0	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2019	1	5							e190139	10.1148/ryai.2019190139	http://dx.doi.org/10.1148/ryai.2019190139			2	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CP	32076661	Green Published			2022-12-18	WOS:000826294400006
J	Kahn, CE				Kahn, Charles E., Jr.			We All Need a Little Magic	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material												ckahn@rsna.org						Buda M, 2019, RADIOLOGY; Erickson BJ, 2019, RADIOL-ARTIF INTELL, V1, DOI [10.1148/ryai.2019190072, 10.1148/ryai.2019190113, 10.1148/ryai.2019190126]; Khorrami M, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180012; Thian YL, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180001	4	1	1	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2019	1	4							e194002	10.1148/ryai.2019194002	http://dx.doi.org/10.1148/ryai.2019194002			1	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CO	33937799	Green Published			2022-12-18	WOS:000826292900007
J	Fink, MA; Kades, K; Bischoff, A; Moll, M; Schnell, M; Kuchler, M; Kohler, G; Sellner, J; Heussel, CP; Kauczor, HU; Schlemmer, HP; Maier-Hein, K; Weber, TF; Kleesiek, J				Fink, Matthias A.; Kades, Klaus; Bischoff, Arved; Moll, Martin; Schnell, Merle; Kuechler, Maike; Koehler, Gregor; Sellner, Jan; Heussel, Claus Peter; Kauczor, Hans-Ulrich; Schlemmer, Heinz-Peter; Maier-Hein, Klaus; Weber, Tim F.; Kleesiek, Jens			Deep Learning-based Assessment of Oncologic Outcomes from Natural Language Processing of Structured Radiology Reports	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Neural Networks; Computer Applications-Detection/Diagnosis; Oncology; Research Design; Staging; Tumor Response; Comparative Studies; Decision Analysis; Experimental Investigations; Observer Performance; Outcomes Analysis	GUIDELINE	Purpose: To train a deep natural language processing (NLP) model, using data mined structured oncology reports (SOR), for rapid tumor response category (TRC) classification from free-text oncology reports (FTOR) and to compare its performance with human readers and conventional NLP algorithms. Materials and Methods: In this retrospective study, databases of three independent radiology departments were queried for SOR and FTOR dated from March 2018 to August 2021. An automated data mining and curation pipeline was developed to extract Response Evaluation Criteria in Solid Tumors-related TRCs for SOR for ground truth definition. The deep NLP bidirectional encoder representations from transformers (BERT) model and three feature-rich algorithms were trained on SOR to predict TRCs in FTOR. Models' F1 scores were compared against scores of radiologists, medical students, and radiology technologist students. Lexical and semantic analyses were conducted to investigate human and model performance on FTOR. Results: Oncologic findings and TRCs were accurately mined from 9653 of 12 833 (75.2%) queried SOR, yielding oncology reports from 10 455 patients (mean age, 60 years +/- 14 [SD]; 5303 women) who met inclusion criteria. On 802 FTOR in the test set, BERT achieved better TRC classification results (F1, 0.70; 95% CI: 0.68, 0.73) than the best-performing reference linear support vector classifier (F1, 0.63; 95% CI: 0.61, 0.66) and technologist students (F1, 0.65; 95% CI: 0.63, 0.67), had similar performance to medical students (F1, 0.73; 95% CI: 0.72, 0.75), but was inferior to radiologists (F1, 0.79; 95% CI: 0.78, 0.81). Lexical complexity and semantic ambiguities in FTOR influenced human and model performance, revealing maximum F1 score drops of -0.17 and -0.19, respectively. Conclusion: The developed deep NLP model reached the performance level of medical students but not radiologists in curating oncologic outcomes from radiology FTOR.	[Fink, Matthias A.; Bischoff, Arved; Moll, Martin; Schnell, Merle; Kuechler, Maike; Heussel, Claus Peter; Kauczor, Hans-Ulrich; Weber, Tim F.] Heidelberg Univ Hosp, Clin Diagnost & Intervent Radiol, Neuenheimer Feld 420, D-69120 Heidelberg, Germany; [Maier-Hein, Klaus] Heidelberg Univ Hosp, Pattern Anal & Burning Grp, Dept Radiat Oncol, Neuenheimer Feld 420, D-69120 Heidelberg, Germany; [Fink, Matthias A.; Bischoff, Arved; Moll, Martin; Schnell, Merle; Kuechler, Maike; Heussel, Claus Peter; Kauczor, Hans-Ulrich; Weber, Tim F.] German Ctr Lung Res DZL, Translat Lung Res Ctr Heidelberg TLRC, Heidelberg, Germany; [Kades, Klaus] Heidelberg Univ, Fac Math & Comp Sci, Heidelberg, Germany; [Heussel, Claus Peter] Heidelberg Univ, Dept Diagnost & Intervent Radiol Nucl Med, Heidelberg Thorac Clin, Heidelberg, Germany; [Kades, Klaus; Koehler, Gregor; Maier-Hein, Klaus] German Canc Res Ctr, Div Med Image Comp, Heidelberg, Germany; [Sellner, Jan] German Canc Res Ctr, Dept Comp Assisted Med Intervent CAMI, Heidelberg, Germany; [Schlemmer, Heinz-Peter] German Canc Res Ctr, Dept Radiol, Heidelberg, Germany; [Schlemmer, Heinz-Peter; Maier-Hein, Klaus; Kleesiek, Jens] German Canc Consortium DKTK, Partner Sites Essen & Heidelberg, Heidelberg, Germany; [Kleesiek, Jens] Univ Med Essen, Inst Artificial Intelligence Med IKIM, Essen, Germany	Ruprecht Karls University Heidelberg; Ruprecht Karls University Heidelberg; Ruprecht Karls University Heidelberg; Ruprecht Karls University Heidelberg; Helmholtz Association; German Cancer Research Center (DKFZ); Helmholtz Association; German Cancer Research Center (DKFZ); Helmholtz Association; German Cancer Research Center (DKFZ); Helmholtz Association; German Cancer Research Center (DKFZ)	Fink, MA (corresponding author), Heidelberg Univ Hosp, Clin Diagnost & Intervent Radiol, Neuenheimer Feld 420, D-69120 Heidelberg, Germany.; Fink, MA (corresponding author), German Ctr Lung Res DZL, Translat Lung Res Ctr Heidelberg TLRC, Heidelberg, Germany.	matthias.fink@uni-heidelberg.de		Kades, Klaus/0000-0002-9387-9944; Fink, Matthias A./0000-0002-0189-7070				Agaronnik N, 2020, JAMA ONCOL, V6, P1628, DOI 10.1001/jamaoncol.2020.2708; Banerjee Imon, 2019, JCO Clin Cancer Inform, V3, P1, DOI 10.1200/CCI.19.00034; Bethard Steven, 2017, P 11 INT WORKSH SEM, P565, DOI [DOI 10.18653/V1/S17-2093, 10.18653/v1/S17-2093]; Bosmans JML, 2011, RADIOLOGY, V259, P184, DOI 10.1148/radiol.10101045; Devlin J., 2018, P 2019 C N AM CHAPTE, P4171, DOI DOI 10.18653/V1/N19-1423DIEZPF; Efron B, 1993, MONOGRAPHS STAT APPL, V57, DOI [10.1007/978-1-4899-4541-9, DOI 10.1007/978-1-4899-4541-9]; Eisenhauer EA, 2009, EUR J CANCER, V45, P228, DOI 10.1016/j.ejca.2008.10.026; ESR, 2018, INSIGHTS IMAGING, V9, P1, DOI 10.1007/s13244-017-0588-8; Fink MA, 2022, RADIOLOGY, V302, P175, DOI 10.1148/radiol.2021211013; Garofalakis M, 2002, IEEE T KNOWL DATA EN, V14, P530, DOI 10.1109/TKDE.2002.1000341; Gehrmann S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0192360; German BERT, STAT ART LANG MOD GE; Kehl KL, 2019, JAMA ONCOL, V5, P1421, DOI 10.1001/jamaoncol.2019.1800; Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012; Linna N, 2022, INT J MED INFORM, V163, DOI 10.1016/j.ijmedinf.2022.104779; Nakayama H, DOCCANO TEXT ANNOTAT; Nobel JM, 2020, INSIGHTS IMAGING, V11, DOI 10.1186/s13244-019-0831-6; Pons E, 2016, RADIOLOGY, V279, P329, DOI 10.1148/radiol.16142770; Receiver Operating Characteristic (ROC), SCIK LEARN; Savova GK, 2019, CANCER RES, V79, P5463, DOI 10.1158/0008-5472.CAN-19-0579; Scherer J, 2020, JCO CLIN CANCER INFO, V4, P1027, DOI 10.1200/CCI.20.00045; Steinkamp JM, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180052; Weber TF, 2020, INSIGHTS IMAGING, V11, DOI 10.1186/s13244-020-00907-1; Willemink MJ, 2020, RADIOLOGY, V295, P4, DOI 10.1148/radiol.2020192224; Wolf T., 2020, PROC C EMPIRICAL MET, P38, DOI 10.18653/v1/2020.emnlp-demos.6; Yim WW, 2016, JAMA ONCOL, V2, P797, DOI 10.1001/jamaoncol.2016.0213; Yule GU, 1939, BIOMETRIKA, V30, P363, DOI 10.2307/2332655; Zech J, 2018, RADIOLOGY, V287, P570, DOI 10.1148/radiol.2018171093	28	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2022	4	5							e220055	10.1148/ryai.220055	http://dx.doi.org/10.1148/ryai.220055			11	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	3O4LI	36204531	Green Published			2022-12-18	WOS:000836810200001
J	Abajian, AC; Cheung, H				Abajian, Aaron C.; Cheung, Hoiwan			No Knew Typos: Modernizing Radiology Dictation COMMENT	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Abajian, Aaron C.; Cheung, Hoiwan] Univ Washington, Dept Radiol, 1959 NE Pacific St, Seattle, WA 98195 USA	University of Washington; University of Washington Seattle	Abajian, AC (corresponding author), Univ Washington, Dept Radiol, 1959 NE Pacific St, Seattle, WA 98195 USA.	aabajian@gmail.com						Alex Wang, 2019, Arxiv, DOI arXiv:1804.07461; Chaudhari GR, 2022, RADIOL ARTIF INTELL, V4; Greg Corrado, 2013, Arxiv, DOI arXiv:1301.3781; Hammana I, 2015, HEALTH INF MANAG J, V44, P4, DOI 10.1177/183335831504400201; Huang WC, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P7343, DOI 10.1109/ICASSP39728.2021.9413668; Jacob Devlin, 2019, Arxiv, DOI arXiv:1810.04805; Lee CI, 2016, J AM COLL RADIOL, V13, P1608, DOI 10.1016/j.jacr.2016.09.007; Nayak P., UNDERSTANDING SEARCH	8	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2022	4	4							e220105	10.1148/ryai.220105	http://dx.doi.org/10.1148/ryai.220105			2	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	3B4GB	35923371	Green Published			2022-12-18	WOS:000827900000006
J	Anazodo, UC; Adewole, M; Dako, F				Anazodo, Udunna C.; Adewole, Maruf; Dako, Farouk			AI for Population and Global Health in Radiology	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Anazodo, Udunna C.] McGill Univ, Dept Neurol & Neurosurg, Montreal, PQ, Canada; [Adewole, Maruf] Univ Lagos, Dept Radiat Biol Radiotherapy & Radiodiag, Lagos, Nigeria; [Dako, Farouk] Hosp Univ Penn, Dept Radiol, 3400 Spruce St, Philadelphia, PA 19104 USA	McGill University; University of Lagos; University of Pennsylvania; Pennsylvania Medicine	Dako, F (corresponding author), Hosp Univ Penn, Dept Radiol, 3400 Spruce St, Philadelphia, PA 19104 USA.	farouk.dako@pennmedicine.upenn.edu		Adewole, Maruf/0000-0002-6562-2834; Anazodo, Udunna/0000-0001-8864-035X; Dako, Farouk/0000-0003-4765-9358				den Bouter MLD, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-10298-6; Elahi A, 2020, J DIGIT IMAGING, V33, P996, DOI 10.1007/s10278-020-00352-y; Lacuna Fund, ANNOUNCING AWARDS HL; Menze Bjoern H, 2015, IEEE Trans Med Imaging, V34, P1993, DOI 10.1109/TMI.2014.2377694; Mollura DJ, 2020, RADIOLOGY, V297, P513, DOI 10.1148/radiol.2020201434; Sun Q, 2020, ANN INTENSIVE CARE, V10, DOI 10.1186/s13613-020-00650-2; Wilkinson Mark D, 2016, Sci Data, V3, P160018, DOI 10.1038/sdata.2016.18; World Health Organization, 2021, WHO CONS GUID TUB MO	8	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2022	4	4							e220107	10.1148/ryai.220107	http://dx.doi.org/10.1148/ryai.220107			2	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	3B4GB	35923372	Green Published			2022-12-18	WOS:000827900000007
J	Chaudhari, GR; Liu, TX; Chen, TL; Joseph, GB; Vella, M; Lee, YJ; Vu, TH; Seo, Y; Rauschecker, AM; McCulloch, CE; Sohn, JH				Chaudhari, Gunvant R.; Liu, Tengxiao; Chen, Timothy L.; Joseph, Gabby B.; Vella, Maya; Lee, Yoo Jin; Vu, Thienkhai H.; Seo, Youngho; Rauschecker, Andreas M.; McCulloch, Charles E.; Sohn, Jae Ho			Application of a Domain-specific BERT for Detection of Speech Recognition Errors in Radiology Reports	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Computer Applications; Technology Assessment		Purpose: To develop radiology domain-specific bidirectional encoder representations from transformers (BERT) models that can identify speech recognition (SR) errors and suggest corrections in radiology reports. Materials and Methods: A pretrained BERT model, Clinical BioBERT, was further pretrained on a corpus of 114 008 radiology reports between April 2016 and August 2019 that were retrospectively collected from two hospitals. Next, the model was fine-tuned on a training dataset of generated insertion, deletion, and substitution errors, creating Radiology BERT. This model was retrospectively evaluated on an independent dataset of radiology reports with generated errors (n = 18 885) and on unaltered report sentences (n = 2000) and prospectively evaluated on true clinical SR errors (n = 92). Correction Radiology BERT was separately trained to suggest corrections for detected deletion and substitution errors. Area under the receiver operating characteristic curve (AUC) and bootstrapped 95% CIs were calculated for each evaluation dataset. Results: Radiology-specific BERT had AUC values of >.99 (95% CI: .0.99, .0.99), 0.94 (95% CI: 0.93, 0.94), 0.98 (95% CI: 0.98, 0.98), and 0.97 (95% CI: 0.97, 0.97) for detecting insertion, deletion, substitution, and all errors, respectively, on the independently generated test set. Testing on unaltered report impressions revealed a sensitivity of 82% (28 of 34; 95% CI: 70%, 93%) and specificity of 88% (1521 of 1728; 95% CI: 87%, 90%). Testing on prospective SR errors showed an accuracy of 75% (69 of 92; 95% CI: 65%, 83%). Finally, the correct word was the top suggestion for 45.6% (475 of 1041; 95% CI: 42.5%, 49.3%) of errors. Conclusion: Radiology-specific BERT models fine-tuned on generated errors were able to identify SR errors in radiology reports and suggest corrections. (C) RSNA, 2022	[Chaudhari, Gunvant R.; Liu, Tengxiao; Chen, Timothy L.; Joseph, Gabby B.; Vella, Maya; Lee, Yoo Jin; Vu, Thienkhai H.; Seo, Youngho; Rauschecker, Andreas M.; Sohn, Jae Ho] Univ Calif San Francisco, Dept Radiol & Biomed Imaging, 505 Parnassus Ave, San Francisco, CA 94143 USA; [McCulloch, Charles E.] Univ Calif San Francisco, Dept Epidemiol & Stat, 505 Parnassus Ave, San Francisco, CA 94143 USA	University of California System; University of California San Francisco; University of California System; University of California San Francisco	Sohn, JH (corresponding author), Univ Calif San Francisco, Dept Radiol & Biomed Imaging, 505 Parnassus Ave, San Francisco, CA 94143 USA.	sohn87@gmail.com		McCulloch, Charles/0000-0002-1279-6179; Rauschecker, Andreas/0000-0003-0633-9876				Beltagy I., 2019, ARXIV, DOI DOI 10.48550/ARXIV.1903.10676; Bikman J., 2018, SPEECH RECOGNITION R; Bressem KK, 2020, BIOINFORMATICS, V36, P5255, DOI 10.1093/bioinformatics/btaa668; Chen L, 2020, OSTEOARTHR CARTILAGE, V28, pS315; Danqi Chen, 2019, Arxiv, DOI arXiv:1907.11692; Datta Surabhi, 2020, Proc Conf Empir Methods Nat Lang Process, V2020, P50, DOI 10.18653/v1/2020.splu-1.6; Datta S, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P2251; Di Jin, 2019, Arxiv, DOI arXiv:1904.03323; Gutierrez F, 2017, J DATA SEMANT, V6, P139, DOI 10.1007/s13740-017-0079-6; Hammana I, 2015, HEALTH INF MANAG J, V44, P4, DOI 10.1177/183335831504400201; Jacob Devlin, 2019, Arxiv, DOI arXiv:1810.04805; Jaime Carbonell, 2020, Arxiv, DOI arXiv:1906.08237; Kevin Gimpel, 2020, Arxiv, DOI arXiv:1909.11942; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Meng Xing, 2020, AMIA Jt Summits Transl Sci Proc, V2020, P413; Minn MJ, 2015, J DIGIT IMAGING, V28, P492, DOI 10.1007/s10278-015-9781-9; Ong CJ, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0234908; Prevedello LM, 2014, J AM COLL RADIOL, V11, P402, DOI 10.1016/j.jacr.2013.07.008; Ringler MD, 2017, HEALTH INFORM J, V23, P3, DOI 10.1177/1460458215613614; Voll K, 2008, J DIGIT IMAGING, V21, P371, DOI 10.1007/s10278-007-9034-7; Wolf Thomas, 2019, ARXIV, DOI DOI 10.48550/ARXIV.1910.03771; Zech J, 2019, ANN TRANSL MED, V7, DOI 10.21037/atm.2018.08.11; Zhou L, 2018, JAMA NETW OPEN, V1, DOI 10.1001/jamanetworkopen.2018.0530	24	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2022	4	4							e210185	10.1148/ryai.210185	http://dx.doi.org/10.1148/ryai.210185			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	3B4GB	35923373	Green Published			2022-12-18	WOS:000827900000001
J	Kim, S; Kim, BR; Chae, HD; Lee, J; Ye, SJ; Kim, DH; Hong, SH; Choi, JY; Yoo, HJ				Kim, Sangwook; Kim, Bo Ram; Chae, Hee-Dong; Lee, Jimin; Ye, Sung-Joon; Kim, Dong Hyun; Hong, Sung Hwan; Choi, Ja-Young; Yoo, Hye Jin			Deep Radiomics-based Approach to the Diagnosis of Osteoporosis Using Hip Radiographs	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Skeletal-Appendicular; Hip; Absorptiometry/Bone Densitometry	FRACTURE RISK-ASSESSMENT	Purpose: To develop and validate deep radiomics models for the diagnosis of osteoporosis using hip radiographs. Materials and Methods: A deep radiomics model was developed using 4924 hip radiographs from 4308 patients (3632 women; mean age, 62 years 6 13 [SD]) obtained between September 2009 and April 2020. Ten deep features, 16 texture features, and three clinical features were used to train the model. T score measured with dual-energy x-ray absorptiometry was used as a reference standard for osteoporosis. Seven deep radiomics models that combined different types of features were developed: clinical (model C); texture (model T); deep (model D); texture and clinical (model TC); deep and clinical (model DC); deep and texture (model DT); and deep, texture, and clinical features (model DTC). A total of 444 hip radiographs obtained between January 2019 and April 2020 from another institution were used for the external test. Six radiologists performed an observer performance test. The area under the receiver operating characteristic curve (AUC) was used to evaluate diagnostic performance. Results: For the external test set, model D (AUC, 0.92; 95% CI: 0.89, 0.95) demonstrated higher diagnostic performance than model T (AUC, 0.77; 95% CI: 0.70, 0.83; adjusted P<.001). Model DC (AUC, 0.95; 95% CI: 0.92, 0.97; adjusted P =.03) and model DTC (AUC, 0.95; 95% CI: 0.92, 0.97; adjusted P =.048) showed improved diagnostic performance compared with model D. When observer performance without and with the assistance of the model DTC prediction was compared, performance improved from a mean AUC of 0.77 to 0.87 (P =.002). Conclusion: Deep radiomics models using hip radiographs could be used to diagnose osteoporosis with high performance. (C) RSNA, 2022	[Kim, Sangwook; Chae, Hee-Dong; Hong, Sung Hwan; Choi, Ja-Young; Yoo, Hye Jin] Seoul Natl Univ Hosp, Dept Radiol, 101 Daehak Ro, Seoul 03080, South Korea; [Kim, Bo Ram] Seoul Natl Univ, Bundang Hosp, Dept Radiol, Seongram, South Korea; [Lee, Jimin] Ulsan Natl Inst Sci & Technol, Dept Nucl Engn, Ulsan, South Korea; [Ye, Sung-Joon] Seoul Natl Univ, Grad Sch Convergence Sci & Technol, Dept Transdisciplinary Studies, Seoul, South Korea; [Kim, Dong Hyun] Seoul Natl Univ, Boramae Med Ctr, Seoul Metropolitan Govt, Dept Radiol, Seoul, South Korea; [Ye, Sung-Joon; Hong, Sung Hwan; Choi, Ja-Young; Yoo, Hye Jin] Seoul Natl Univ, Coll Med, Dept Radiol, Seoul, South Korea; [Hong, Sung Hwan] Seoul Natl Univ, Med Res Ctr, Inst Radiat Med, Seoul, South Korea	Seoul National University (SNU); Seoul National University Hospital; Seoul National University (SNU); Ulsan National Institute of Science & Technology (UNIST); Seoul National University (SNU); Seoul National University (SNU); Seoul National University Hospital; Seoul National University (SNU); Seoul National University (SNU)	Chae, HD (corresponding author), Seoul Natl Univ Hosp, Dept Radiol, 101 Daehak Ro, Seoul 03080, South Korea.	hdchae02@gmail.com		Kim, Bo Ram/0000-0002-5968-3884; Kim, Dong Hyun/0000-0002-3871-7002	Korea Health Technology R&D Project through the Korea Health Industry Development Institute - Ministry of Health & Welfare, Republic of Korea [HI20C2092]; SNUH Research Fund [04-2020-2060]	Korea Health Technology R&D Project through the Korea Health Industry Development Institute - Ministry of Health & Welfare, Republic of Korea; SNUH Research Fund	Supported by the Korea Health Technology R&D Project through the Korea Health Industry Development Institute, funded by the Ministry of Health & Welfare, Republic of Korea (grant HI20C2092), and the SNUH Research Fund (grant 04-2020-2060).	Afshar P, 2019, IEEE SIGNAL PROC MAG, V36, P132, DOI 10.1109/MSP.2019.2900993; Bae S, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-68980-6; Bizzego A, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY - CIBCB 2019, P19; Bliuc D, 2013, J BONE MINER RES, V28, P2317, DOI 10.1002/jbmr.1968; Cauley JA, 2013, J GERONTOL A-BIOL, V68, P1243, DOI 10.1093/gerona/glt093; Curtis JR, 2008, J BONE MINER RES, V23, P1061, DOI 10.1359/JBMR.080232; Dagan N, 2020, NAT MED, V26, P77, DOI 10.1038/s41591-019-0720-z; David Lopez-Paz, 2018, Arxiv, DOI arXiv:1710.09412; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; Dimai HP, 2017, BONE, V104, P39, DOI 10.1016/j.bone.2016.12.016; Forrest Iandola, 2014, Arxiv, DOI arXiv:1404.1869; Hauschild O, 2009, EUR J RADIOL, V71, P152, DOI 10.1016/j.ejrad.2008.03.019; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hosny A, 2019, LANCET DIGIT HEALTH, V1, pE106, DOI 10.1016/S2589-7500(19)30062-7; Jang S, 2019, RADIOLOGY, V291, P359, DOI 10.1148/radiol.2019181648; Klibanski A, 2001, JAMA-J AM MED ASSOC, V285, P785; Lespessailles E, 2008, OSTEOPOROSIS INT, V19, P1019, DOI 10.1007/s00198-007-0532-8; Zhang LJ, 2021, Arxiv, DOI arXiv:2010.04819; Michaelsson K, 2016, NEW ENGL J MED, V374, P2095, DOI 10.1056/NEJMc1602599; Mithal Ambrish, 2014, Indian J Endocrinol Metab, V18, P449, DOI 10.4103/2230-8210.137485; Pan YL, 2020, EUR RADIOL, V30, P4107, DOI 10.1007/s00330-020-06679-y; Park CM, 2019, RADIOLOGY, V292, P374, DOI 10.1148/radiol.2019191154; Pepe J, 2021, ENDOCRINE, V71, P484, DOI 10.1007/s12020-020-02553-5; Pickhardt PJ, 2020, RADIOLOGY, V297, P64, DOI 10.1148/radiol.2020200466; Sozen T, 2017, EUR J RHEUMATOL, V4, P46, DOI 10.5152/eurjrheum.2016.048; Summers RM, 2011, J COMPUT ASSIST TOMO, V35, P212, DOI 10.1097/RCT.0b013e3182032537; Tiulpin A, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-20132-7; van Griethuysen JJM, 2017, CANCER RES, V77, pE104, DOI 10.1158/0008-5472.CAN-17-0339; Wang YF, 2020, IEEE ACCESS, V8, P52010, DOI 10.1109/ACCESS.2020.2980290; Yamamoto N, 2020, BIOMOLECULES, V10, DOI 10.3390/biom10111534; Zheng KN, 2016, IEEE ENG MED BIO, P1034, DOI 10.1109/EMBC.2016.7590879; Zheng XY, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-15027-z; Zwanenburg A, 2020, RADIOLOGY, V295, P328, DOI 10.1148/radiol.2020191145	33	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2022	4	4							e210212	10.1148/ryai.210212	http://dx.doi.org/10.1148/ryai.210212			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	3B4GB	35923378	Green Published			2022-12-18	WOS:000827900000002
J	Neve, OM; Chen, YJ; Tao, Q; Romeijn, SR; de Boer, NP; Grootjans, W; Kruit, MC; Lelieveldt, BPF; Jansen, JC; Hensen, EF; Verbist, BM; Staring, M				Neve, Olaf M.; Chen, Yunjie; Tao, Qian; Romeijn, Stephan R.; de Boer, Nick P.; Grootjans, Willem; Kruit, Mark C.; Lelieveldt, Boudewijn P. F.; Jansen, Jeroen C.; Hensen, Erik F.; Verbist, Berit M.; Staring, Marius			Fully Automated 3D Vestibular Schwannoma Segmentation with and without Gadolinium-based Contrast Material: A Multicenter, Multivendor Study	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						MRI; Ear; Nose, and Throat; Skull Base; Segmentation; Convolutional Neural Network (CNN); Deep Learning Algorithms; Machine Learning Algorithms		Purpose: To develop automated vestibular schwannoma measurements on contrast-enhanced T1- and T2-weighted MRI scans. Materials and Methods: MRI data from 214 patients in 37 different centers were retrospectively analyzed between 2020 and 2021. Patients with hearing loss (134 positive for vestibular schwannoma [mean age 6 SD, 54 years 6 12; 64 men] and 80 negative for vestibular schwannoma) were randomly assigned to a training and validation set and to an independent test set. A convolutional neural network (CNN) was trained using fivefold cross-validation for two models (T1 and T2). Quantitative analysis, including Dice index, Hausdorff distance, surface-to-surface distance (S2S), and relative volume error, was used to compare the computer and the human delineations. An observer study was performed in which two experienced physicians evaluated both delineations. Results: The T1-weighted model showed state-of-the-art performance, with a mean S2S distance of less than 0.6 mm for the whole tumor and the intrameatal and extrameatal tumor parts. The whole tumor Dice index and Hausdorff distance were 0.92 and 2.1 mm in the independent test set, respectively. T2-weighted images had a mean S2S distance less than 0.6 mm for the whole tumor and the intrameatal and extrameatal tumor parts. The whole tumor Dice index and Hausdorff distance were 0.87 and 1.5 mm in the independent test set. The observer study indicated that the tool was similar to human delineations in 85%-92% of cases. Conclusion: The CNN model detected and delineated vestibular schwannomas accurately on contrast-enhanced T1- and T2-weighted MRI scans and distinguished the clinically relevant difference between intrameatal and extrameatal tumor parts. (C) RSNA, 2022	[Neve, Olaf M.; de Boer, Nick P.; Jansen, Jeroen C.; Hensen, Erik F.] Leiden Univ, Med Ctr, Dept Otorhinolaryngol & Head & Neck Surg, Otorhinolaryngol H5-P,POB 9600, NL-2300 RC Leiden, Netherlands; [Chen, Yunjie; Tao, Qian; Lelieveldt, Boudewijn P. F.; Staring, Marius] Leiden Univ, Med Ctr, Dept Radiol, Div Image Proc, Otorhinolaryngol H5-P,POB 9600, NL-2300 RC Leiden, Netherlands; [Romeijn, Stephan R.; Grootjans, Willem; Kruit, Mark C.; Verbist, Berit M.] Leiden Univ, Med Ctr, Dept Radiol, Otorhinolaryngol H5-P,POB 9600, NL-2300 RC Leiden, Netherlands; [Tao, Qian] Delft Univ Technol, Knowledge Driven AI Lab, Delft, Netherlands	Leiden University; Leiden University Medical Center (LUMC); Leiden University - Excl LUMC; Leiden University; Leiden University Medical Center (LUMC); Leiden University - Excl LUMC; Leiden University; Leiden University Medical Center (LUMC); Leiden University - Excl LUMC; Delft University of Technology	Neve, OM (corresponding author), Leiden Univ, Med Ctr, Dept Otorhinolaryngol & Head & Neck Surg, Otorhinolaryngol H5-P,POB 9600, NL-2300 RC Leiden, Netherlands.	kno@lumc.nl	Staring, Marius/A-9517-2009; Neve, Olaf/AAL-3636-2021	Staring, Marius/0000-0003-2885-5812; Neve, Olaf/0000-0002-5104-8448; Grootjans, Willem/0000-0003-4851-7167	Leiden University Medical Center; China Scholarship Council [202008130140]	Leiden University Medical Center; China Scholarship Council(China Scholarship Council)	Supported by a strategic fund of the Leiden University Medical Center. Y.C. supported by the China Scholarship Council (grant 202008130140).	Andre Klein, 2018, Arxiv, DOI arXiv:1809.10486; Buch K, 2019, J NEUROSURG, V131, P549, DOI 10.3171/2018.3.JNS1866; Carlson ML, 2021, NEW ENGL J MED, V384, P1335, DOI 10.1056/NEJMra2020394; George-Jones NA, 2021, LARYNGOSCOPE, V131, pE619, DOI 10.1002/lary.28695; Isensee F, 2021, NAT METHODS, V18, P203, DOI 10.1038/s41592-020-01008-z; Kanzaki J, 2003, OTOL NEUROTOL, V24, P642, DOI 10.1097/00129492-200307000-00019; Klein S, 2010, IEEE T MED IMAGING, V29, P196, DOI 10.1109/TMI.2009.2035616; Koos WT, 1998, J NEUROSURG, V88, P506, DOI 10.3171/jns.1998.88.3.0506; Lee CC, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-82665-8; Lees KA, 2018, OTOLARYNG HEAD NECK, V159, P535, DOI 10.1177/0194599818770413; MacKeith S, 2018, EUR ARCH OTO-RHINO-L, V275, P867, DOI 10.1007/s00405-018-4865-z; Pizzini FB, 2020, OTOL NEUROTOL, V41, pE103, DOI 10.1097/MAO.0000000000002436; Rai R, 2020, MED PHYS, V47, P3054, DOI 10.1002/mp.14173; Shamonin DP, 2014, FRONT NEUROINFORM, V7, DOI 10.3389/fninf.2013.00050; Shapey J, SEGMENTATION VESTIBU, P2021; Shapey J, 2021, J NEUROSURG, V134, P171, DOI 10.3171/2019.9.JNS191949; Tolisano AM, 2019, OTOL NEUROTOL, V40, pS67, DOI 10.1097/MAO.0000000000002208; van de Langenberg R, 2009, NEURORADIOLOGY, V51, P517, DOI 10.1007/s00234-009-0529-4; Varughese JK, 2010, CLIN OTOLARYNGOL, V35, P97, DOI 10.1111/j.1749-4486.2010.02099.x; Whittle IR, 2004, LANCET, V363, P1535, DOI 10.1016/S0140-6736(04)16153-9	20	0	0	3	3	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2022	4	4							e210300	10.1148/ryai.210300	http://dx.doi.org/10.1148/ryai.210300			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	3B4GB	35923375	Green Published			2022-12-18	WOS:000827900000005
J	Wiggins, WF; Tejani, AS				Wiggins, Walter F.; Tejani, Ali S.			On the Opportunities and Risks of Foundation Models for Natural Language Processing in Radiology COMMENT	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Wiggins, Walter F.] Duke Univ Hlth Syst, Dept Radiol, 2301 Erwin Rd, Durham, NC 27710 USA; [Wiggins, Walter F.] Duke Univ, Sch Med, Duke Ctr Artificial Intelligence Radiol, Durham, NC 27710 USA; [Tejani, Ali S.] Univ Texas Southwestern Med Ctr Dallas, Dept Radiol, Dallas, TX USA	Duke University; Duke University; University of Texas System; University of Texas Southwestern Medical Center Dallas	Wiggins, WF (corresponding author), Duke Univ Hlth Syst, Dept Radiol, 2301 Erwin Rd, Durham, NC 27710 USA.; Wiggins, WF (corresponding author), Duke Univ, Sch Med, Duke Ctr Artificial Intelligence Radiol, Durham, NC 27710 USA.	walter.wiggins@duke.edu		Wiggins, Walter/0000-0002-0258-2708				Danqi Chen, 2019, Arxiv, DOI arXiv:1907.11692; Jaan Altosaar, 2020, Arxiv, DOI arXiv:1904.05342; Jacob Devlin, 2019, Arxiv, DOI arXiv:1810.04805; Jaiswal Ajay, 2021, Proc Mach Learn Res, V158, P196; Kuling G, 2022, J IMAGING, V8, DOI 10.3390/jimaging8050131; Linna N, 2022, INT J MED INFORM, V163, DOI 10.1016/j.ijmedinf.2022.104779; Rishi Bommasani, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2108.07258; Vaswani A., 2017, ARXIV, DOI DOI 10.48550/ARXIV.1706.03762; Wiggins WF, 2021, RADIOL-ARTIF INTELL, V3, DOI 10.1148/ryai.2021210035; Yan A, RADIOL ARTIF INTELL, V4	10	0	0	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2022	4	4							e220119	10.1148/ryai.220119	http://dx.doi.org/10.1148/ryai.220119			3	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	3B4GB	35923379	Green Published			2022-12-18	WOS:000827900000008
J	Dadoun, H; Rousseau, AL; de Kerviler, E; Correas, JM; Tissier, AM; Joujou, F; Bodard, S; Khezzane, K; De Margerie-Mellon, C; Delingette, H; Ayache, N				Dadoun, Hind; Rousseau, Anne-Laure; de Kerviler, Eric; Correas, Jean-Michel; Tissier, Anne-Marie; Joujou, Fanny; Bodard, Sylvain; Khezzane, Kemel; De Margerie-Mellon, Constance; Delingette, Herve; Ayache, Nicholas			Deep Learning for the Detection, Localization, and Characterization of Focal Liver Lesions on Abdominal US Images	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Computer-aided Diagnosis (CAD); Ultrasound; Abdomen/GI; Liver; Tissue Characterization; Supervised Learning; Transfer Learning; Convolutional Neural Network (CNN)	ULTRASOUND; DIAGNOSIS	Purpose: To train and assess the performance of a deep learning-based network designed to detect, localize, and characterize focal liver lesions (FLLs) in the liver parenchyma on abdominal US images. Materials and Methods: In this retrospective, multicenter, institutional review board-approved study, two object detectors, Faster region-based convolutional neural network (Faster R-CNN) and Detection Transformer (DETR), were fine-tuned on a dataset of 1026 patients (n = 2551 B-mode abdominal US images obtained between 2014 and 2018). Performance of the networks was analyzed on a test set of 48 additional patients (n = 155 B-mode abdominal US images obtained in 2019) and compared with the performance of three caregivers (one nonexpert and two experts) blinded to the clinical history. The sign test was used to compare accuracy, specificity, sensitivity, and positive predictive value among all raters. Results: DETR achieved a specificity of 90% (95% CI: 75, 100) and a sensitivity of 97% (95% CI: 97, 97) for the detection of FLLs. The performance of DETR met or exceeded that of the three caregivers for this task. DETR correctly localized 80% of the lesions, and it achieved a specificity of 81% (95% CI: 67, 91) and a sensitivity of 82% (95% CI: 62, 100) for FLL characterization (benign vs malignant) among lesions localized by all raters. The performance of DETR met or exceeded that of two experts and Faster R-CNN for these tasks. Conclusion: DETR demonstrated high specificity for detection, localization, and characterization of FLLs on abdominal US images. Supplemental material is available for this article. (C) RSNA, 2022.	[Dadoun, Hind; Delingette, Herve; Ayache, Nicholas] Univ Cote dAzur, Sophia Andpolis, Epione Team, INRIA, 2004 Route Lucioles, F-06902 Valbonne, France; [Rousseau, Anne-Laure] Univ Paris, Dept Vasc Surg, Georges Pompidou European Hosp, AP HP, Paris, France; [Rousseau, Anne-Laure] NHance Ngo, St Germain En Laye, France; [de Kerviler, Eric; Joujou, Fanny; Khezzane, Kemel; De Margerie-Mellon, Constance] Univ Paris, Dept Radiol, Hop St Louis, AP HP, Paris, France; [Correas, Jean-Michel; Tissier, Anne-Marie; Bodard, Sylvain] Univ Paris, Dept Adult Radiol, Paris, France; [Correas, Jean-Michel; Tissier, Anne-Marie; Bodard, Sylvain] Univ Hop Necker, Paris, France	Inria; UDICE-French Research Universities; Universite Cote d'Azur; Assistance Publique Hopitaux Paris (APHP); Hopital Universitaire Europeen Georges-Pompidou - APHP; UDICE-French Research Universities; Universite Paris Cite; Assistance Publique Hopitaux Paris (APHP); Hopital Universitaire Saint-Louis - APHP; UDICE-French Research Universities; Universite Paris Cite; UDICE-French Research Universities; Universite Paris Cite	Dadoun, H (corresponding author), Univ Cote dAzur, Sophia Andpolis, Epione Team, INRIA, 2004 Route Lucioles, F-06902 Valbonne, France.	hind.dadoun@inria.fr		BODARD, Sylvain/0000-0001-5381-3361; Correas, Jean-Michel/0000-0002-8596-4145; Dadoun, Hind/0000-0002-9832-5414	French government through the 3IA Cote d'Azur Investments in the Future project [ANR-19-P3IA-0002]	French government through the 3IA Cote d'Azur Investments in the Future project	Supported in part by the French government through the 3IA Cote d'Azur Investments in the Future project managed by the National Research Agency (ANR) (reference no. ANR-19-P3IA-0002).	Alexander Kirillov, 2020, Arxiv, DOI arXiv:2005.12872; Axel Camara, 2020, Arxiv, DOI arXiv:2012.03583; Barret Zoph, 2019, Arxiv, DOI arXiv:1906.11172; BLAND JM, 1995, BRIT MED J, V310, P170, DOI 10.1136/bmj.310.6973.170; Bray F, 2018, CA-CANCER J CLIN, V68, P394, DOI 10.3322/caac.21492; Cadier B, 2017, HEPATOLOGY, V65, P1237, DOI 10.1002/hep.28961; Craig AJ, 2020, NAT REV GASTRO HEPAT, V17, P139, DOI 10.1038/s41575-019-0229-4; Dadoun H, 2021, I S BIOMED IMAGING, P743, DOI 10.1109/ISBI48211.2021.9434112; Dosovitskiy A., 2021, ICLR; Goyal P., 2017, ARXIV, DOI DOI 10.48550/ARXIV.1706.02677; Hanna RF, 2016, ABDOM RADIOL, V41, P71, DOI 10.1007/s00261-015-0592-8; Harvey CJ, 2001, EUR RADIOL, V11, P1578, DOI 10.1007/s003300101002; Hassan TM, 2017, ARAB J SCI ENG, V42, P3127, DOI 10.1007/s13369-016-2387-9; Linnet K, 2000, CLIN CHEM, V46, P867; Marrero JA, 2014, AM J GASTROENTEROL, V109, P1328, DOI 10.1038/ajg.2014.213; Park H, 2013, WORLD J GASTROENTERO, V19, P219, DOI 10.3748/wjg.v19.i2.219; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Schmauch B, 2019, DIAGN INTERV IMAG, V100, P227, DOI 10.1016/j.diii.2019.02.009; Shah S, 2015, CRIT ULTRASOUND J, V7, DOI 10.1186/s13089-015-0028-2; Sutskever I., 2013, P 30 INT C MACH LEAR, P1139, DOI DOI 10.1007/S00287-015-0911-Z; Ta CN, 2018, RADIOLOGY, V286, P1062, DOI 10.1148/radiol.2017170365; Trinchet JC, 2009, GASTROEN CLIN BIOL, V33, P830, DOI 10.1016/j.gcb.2009.04.003; Yang Q, 2020, EBIOMEDICINE, V56, DOI 10.1016/j.ebiom.2020.102777; Yao Z, 2018, BMC CANCER, V18, DOI 10.1186/s12885-018-5003-4; Yasaka K, 2018, RADIOLOGY, V286, P899, DOI 10.1148/radiol.2017170706	25	0	0	4	4	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2022	4	3							e210110	10.1148/ryai.210110	http://dx.doi.org/10.1148/ryai.210110			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9YQ	35652113	Green Published			2022-12-18	WOS:000826924200002
J	Gibson, E; Georgescu, B; Ceccaldi, P; Trigan, PH; Yoo, Y; Das, J; Re, TJ; Rs, V; Balachandran, A; Eibenberger, E; Chekkoury, A; Brehm, B; Bodanapally, UK; Nicolaou, S; Sanelli, PC; Schroeppel, TJ; Flohr, T; Comaniciu, D; Lui, YW				Gibson, Eli; Georgescu, Bogdan; Ceccaldi, Pascal; Trigan, Pierre-Hugo; Yoo, Youngjin; Das, Jyotipriya; Re, Thomas J.; Rs, Vishwanath; Balachandran, Abishek; Eibenberger, Eva; Chekkoury, Andrei; Brehm, Barbara; Bodanapally, Uttam K.; Nicolaou, Savvas; Sanelli, Pina C.; Schroeppel, Thomas J.; Flohr, Thomas; Comaniciu, Dorin; Lui, Yvonne W.			Artificial Intelligence with Statistical Confidence Scores for Detection of Acute or Subacute Hemorrhage on Noncontrast CT Head Scans	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						CT; Head/Neck; Hemorrhage; Convolutional Neural Network (CNN)	STROKE; VOLUME	Purpose: To present a method that automatically detects, subtypes, and locates acute or subacute intracranial hemorrhage (ICH) on noncontrast CT (NCCT) head scans; generates detection confidence scores to identify high-confidence data subsets with higher accuracy; and improves radiology worklist prioritization. Such scores may enable clinicians to better use artificial intelligence (AI) tools. Materials and Methods: This retrospective study included 46057 studies from seven "internal" centers for development (training, architecture selection, hyperparameter tuning, and operating-point calibration; n = 25 946) and evaluation (n = 2947) and three "external" centers for calibration (n = 400) and evaluation (n = 16 764). Internal centers contributed developmental data, whereas external centers did not. Deep neural networks predicted the presence of ICH and subtypes (intraparenchymal, intraventricular, subarachnoid, subdural, and/or epidural hemorrhage) and segmentations per case. Two ICH confidence scores are discussed: a calibrated classifier entropy score and a Dempster-Shafer score. Evaluation was completed by using receiver operating characteristic curve analysis and report turn-around time (RTAT) modeling on the evaluation set and on confidence score-defined subsets using bootstrapping. Results: The areas under the receiver operating characteristic curve for ICH were 0.97 (0.97, 0.98) and 0.95 (0.94, 0.95) on internal and external center data, respectively. On 80% of the data stratified by calibrated classifier and Dempster-Shafer scores, the system improved the Youden indexes, increasing them from 0.84 to 0.93 (calibrated classifier) and from 0.84 to 0.92 (Dempster-Shafer) for internal centers and increasing them from 0.78 to 0.88 (calibrated classifier) and from 0.78 to 0.89 (Dempster-Shafer) for external centers (P,.001). Models estimated shorter RTAT for AI-prioritized worklists with confidence measures than for AI-prioritized worklists without confidence measures, shortening RTAT by 27% (calibrated classifier) and 27% (Dempster-Shafer) for internal centers and shortening RTAT by 25% (calibrated classifier) and 27% (Dempster-Shafer) for external centers (P,.001). Conclusion: AI that provided statistical confidence measures for ICH detection on NCCT scans reliably detected and subtyped hemorrhages, identified high-confidence predictions, and improved worklist prioritization in simulation. Supplemental material is available for this article. (C) RSNA, 2022.	[Gibson, Eli; Georgescu, Bogdan; Ceccaldi, Pascal; Trigan, Pierre-Hugo; Yoo, Youngjin; Das, Jyotipriya; Re, Thomas J.; Comaniciu, Dorin] Siemens Healthineers, Dept Digital Technol & Innovat, 755 Coll Rd E, Princeton, NJ 08540 USA; [Rs, Vishwanath; Balachandran, Abishek] Siemens Healthineers, Dept Digital Technol & Innovat, Bangalore, Karnataka, India; [Eibenberger, Eva; Chekkoury, Andrei; Brehm, Barbara; Flohr, Thomas] Siemens Healthineers, Dept Computed Tomog, Forchheim, Germany; [Bodanapally, Uttam K.] Univ Maryland, Med Ctr, Dept Radiol, Baltimore, MD 21201 USA; [Nicolaou, Savvas] Vancouver Gen Hosp, Dept Radiol, Vancouver, BC, Canada; [Sanelli, Pina C.] Northwell Hlth, Dept Radiol, New York, NY USA; [Schroeppel, Thomas J.] UCHlth Mem Hosp, Dept Surg, Colorado Springs, CO USA; [Lui, Yvonne W.] NYU, Sch Med, NYU Langone Hlth, Dept Radiol, New York, NY USA	Siemens AG; Siemens AG; University System of Maryland; University of Maryland Baltimore; University of British Columbia; Northwell Health; New York University; NYU Langone Medical Center	Gibson, E (corresponding author), Siemens Healthineers, Dept Digital Technol & Innovat, 755 Coll Rd E, Princeton, NJ 08540 USA.	eli.gibson@siemens-healthineers.com	; Gibson, Eli/E-2191-2016	Georgescu, Bogdan/0000-0001-5388-5699; Yoo, Youngjin/0000-0002-0001-0503; R S, VISHWANATH/0000-0002-9494-471X; Gibson, Eli/0000-0001-9207-7280; Balachandran, Dr.Abishek/0000-0002-3726-7839	Siemens Healthineers	Siemens Healthineers	Supported in part by Siemens Healthineers.	[Anonymous], STROKE FACT SHEET; Arbabshirani MR, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-017-0015-z; Bershad EM, 2015, J STROKE CEREBROVASC, V24, P1256, DOI 10.1016/j.jstrokecerebrovasdis.2015.01.029; BRODERICK JP, 1993, STROKE, V24, P987, DOI 10.1161/01.STR.24.7.987; Davis SM, 2006, NEUROLOGY, V66, P1175, DOI 10.1212/01.wnl.0000208408.98482.99; Ethan M. Rudd, 2019, Arxiv, DOI arXiv:1810.12278; Flanders AE, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190211; Ghesu FC, 2019, LECT NOTES COMPUT SC, V11769, P676, DOI 10.1007/978-3-030-32226-7_75; Ghesu FC, 2019, IEEE T PATTERN ANAL, V41, P176, DOI 10.1109/TPAMI.2017.2782687; Guo CA, 2017, PR MACH LEARN RES, V70; Hein M, 2019, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2019.00013; Kaivanto K, 2008, J CLIN EPIDEMIOL, V61, P517, DOI 10.1016/j.jclinepi.2007.10.011; Kuo WC, 2019, P NATL ACAD SCI USA, V116, P22737, DOI 10.1073/pnas.1908021116; Lebovitz S., 2019, 40 INT C INFORM SYST; National Institute for Health and Care Excellence, 2014, HEAD INJ ASS EARL MA; Rau CS, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16234787; Rodriguez-Luna D, 2016, STROKE, V47, P1124, DOI 10.1161/STROKEAHA.115.012170; Salmela MB, 2017, J AM COLL RADIOL, V14, pS34, DOI 10.1016/j.jacr.2017.01.051; Shetty VS, 2016, J AM COLL RADIOL, V13, P668, DOI 10.1016/j.jacr.2016.02.023; van Asch CJJ, 2010, LANCET NEUROL, V9, P167, DOI 10.1016/S1474-4422(09)70340-0; Wardlaw JM, 2012, LANCET, V379, P2364, DOI 10.1016/S0140-6736(12)60738-7; Yang D, 2017, P INT C MED IM COMP, P507, DOI [10.1007/978-3-319-66179-7_58, DOI 10.1007/978-3-319-66179-758]; Yaniv G, 2018, SOC IMAGING INFORMAT	23	0	0	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2022	4	3							e210115	10.1148/ryai.210115	http://dx.doi.org/10.1148/ryai.210115			11	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9YQ	35652116	Green Published			2022-12-18	WOS:000826924200003
J	Langner, T; Mora, AM; Strand, R; Ahlstrom, H; Kullberg, J				Langner, Taro; Mora, Andres Martinez; Strand, Robin; Ahlstrom, Hakan; Kullberg, Joel			MIMIR: Deep Regression for Automated Analysis of UK Biobank MRI Scans	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						MRI; Adipose Tissue; Obesity; Metabolic Disorders; Volume Analysis; Whole-Body Imaging; Quantification; Supervised Learning; Convolutional Neural Network (CNN)		UK Biobank (UKB) has recruited more than 500000 volunteers from the United Kingdom, collecting health-related information on genetics, lifestyle, blood biochemistry, and more. Ongoing medical imaging of 100 000 participants with 70 000 follow-up sessions will yield up to 170 000 MRI scans, enabling image analysis of body composition, organs, and muscle. This study presents an experimental inference engine for automated analysis of UKB neck-to-knee body 1.5-T MRI scans. This retrospective cross-validation study includes data from 38 916 participants (52% female; mean age, 64 years) to capture baseline characteristics, such as age, height, weight, and sex, as well as measurements of body composition, organ volumes, and abstract properties, such as grip strength, pulse rate, and type 2 diabetes status. Prediction intervals for each end point were generated based on uncertainty quantification. On a subsequent release of UKB data, the proposed method predicted 12 body composition metrics with a 3% median error and yielded mostly well-calibrated individual prediction intervals. The processing of MRI scans from 1000 participants required 10 minutes. The underlying method used convolutional neural networks for image-based mean-variance regression on two-dimensional representations of the MRI data. An implementation was made publicly available for fast and fully automated estimation of 72 different measurements from future releases of UKB image data. (C) RSNA, 2022.	[Langner, Taro; Mora, Andres Martinez; Strand, Robin; Ahlstrom, Hakan; Kullberg, Joel] Uppsala Univ, Akad Sjukhuset, Dept Surg Sci, Ingang 78,1tr, S-75185 Uppsala, Sweden; [Strand, Robin] Uppsala Univ, Akad Sjukhuset, Dept Informat Technol, Ingang 78,1tr, S-75185 Uppsala, Sweden; [Ahlstrom, Hakan; Kullberg, Joel] Antaros Med AB, Molndal, Sweden	Uppsala University; Uppsala University Hospital; Uppsala University; Uppsala University Hospital	Langner, T (corresponding author), Uppsala Univ, Akad Sjukhuset, Dept Surg Sci, Ingang 78,1tr, S-75185 Uppsala, Sweden.	taro.langner@surgsci.uu.se		Martinez Mora, Andres/0000-0002-7293-8220; Langner, Taro/0000-0002-8616-7666	Swedish Heart-Lung Foundation; Swedish Research Council [2016-01040, 2019-04756, 2020-0500, 2021-70492]; UK Biobank Resource [14237]	Swedish Heart-Lung Foundation(Swedish Heart-Lung Foundation); Swedish Research Council(Swedish Research CouncilEuropean Commission); UK Biobank Resource	Supported by the Swedish Heart-Lung Foundation and the Swedish Research Council (2016-01040, 2019-04756, 2020-0500, 2021-70492) and the UK Biobank Resource under application no. 14237.	Alexander Pritzel, 2017, Arxiv, DOI arXiv:1612.01474; Bagur AT, 2020, COMM COM INF SC, V1248, P131, DOI 10.1007/978-3-030-52791-4_11; Basty N, 2020, I S BIOMED IMAGING, P345, DOI 10.1109/ISBI45749.2020.9098650; Eastwood SV, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162388; Gustafsson FK, 2020, IEEE COMPUT SOC CONF, P1289, DOI 10.1109/CVPRW50498.2020.00167; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Irving B, 2017, COMM COM INF SC, V723, P663, DOI 10.1007/978-3-319-60964-5_58; Jonsson BA, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13163-9; Kart T, 2021, INVEST RADIOL, V56, P401, DOI 10.1097/RLI.0000000000000755; Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012; Kullberg J, ARXIV; Langner T, 2021, COMPUT MED IMAG GRAP, V93, DOI 10.1016/j.compmedimag.2021.101994; Langner T, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-77981-4; Langner T, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-74633-5; Linge J, 2018, OBESITY, V26, P1785, DOI 10.1002/oby.22210; Littlejohns TJ, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-15948-9; Liu Y, 2021, ELIFE, V10, DOI 10.7554/eLife.65554; Wagner R, 2020, DIABETES, V69, DOI 10.2337/db20-102-OR; West J, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0163332; Wilman HR, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0172921	20	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2022	4	3							e210178	10.1148/ryai.210178	http://dx.doi.org/10.1148/ryai.210178			5	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9YQ	35652115	Green Published			2022-12-18	WOS:000826924200005
J	Yamashita, R; Kapoor, T; Alam, MN; Galimzianova, A; Syed, SA; Akdogan, MU; Alkim, E; Wentland, AL; Madhuripan, N; Goff, D; Barbee, V; Sheybani, ND; Sagreiya, H; Rubin, DL; Desser, TS				Yamashita, Rikiya; Kapoor, Tara; Alam, Minhaj Nur; Galimzianova, Alfiia; Syed, Saad Ali; Akdogan, Mete Ugur; Alkim, Emel; Wentland, Andrew Louis; Madhuripan, Nikhil; Goff, Daniel; Barbee, Victoria; Sheybani, Natasha Diba; Sagreiya, Hersh; Rubin, Daniel L.; Desser, Terry S.			Toward Reduction in False-Positive Thyroid Nodule Biopsies with a Deep Learning-based Risk Stratification System Using US Cine-Clip Images	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Neural Networks; US; Abdomen/GI; Head/Neck; Thyroid; Computer Applications-3D; Oncology; Diagnosis; Supervised Learning; Transfer Learning; Convolutional Neural Network (CNN)	AMERICAN-COLLEGE; ULTRASOUND; DIAGNOSIS; CANCER; MANAGEMENT; BENIGN	Purpose: To develop a deep learning-based risk stratification system for thyroid nodules using US cine images. Materials and Methods: In this retrospective study, 192 biopsy-confirmed thyroid nodules (175 benign, 17 malignant) in 167 unique patients (mean age, 56 years 6 16 [SD], 137 women) undergoing cine US between April 2017 and May 2018 with American College of Radiology (ACR) Thyroid Imaging Reporting and Data System (TI-RADS)-structured radiology reports were evaluated. A deep learning-based system that exploits the cine images obtained during three-dimensional volumetric thyroid scans and outputs malignancy risk was developed and compared, using fivefold cross-validation, against a two-dimensional (2D) deep learning-based model (Static2DCNN), a radiomics-based model using cine images (Cine-Radiomics), and the ACR TI-RADS level, with histopathologic diagnosis as ground truth. The system was used to revise the ACR TI-RADS recommendation, and its diagnostic performance was compared against the original ACR TI-RADS. Results: The system achieved higher average area under the receiver operating characteristic curve (AUC, 0.88) than Static-2DCNN (0.72, P = .03) and tended toward higher average AUC than Cine-Radiomics (0.78, P =.16) and ACR TI-RADS level (0.80, P =.21). The system downgraded recommendations for 92 benign and two malignant nodules and upgraded none. The revised recommendation achieved higher specificity (139 of 175, 79.4%) than the original ACR TI-RADS (47 of 175, 26.9%; P,.001), with no difference in sensitivity (12 of 17, 71% and 14 of 17, 82%, respectively; P =.63). Conclusion: The risk stratification system using US cine images had higher diagnostic performance than prior models and improved specificity of ACR TI-RADS when used to revise ACR TI-RADS recommendation. Supplemental material is available for this article. (C) RSNA, 2022	[Yamashita, Rikiya; Kapoor, Tara; Alam, Minhaj Nur; Galimzianova, Alfiia; Akdogan, Mete Ugur; Alkim, Emel; Sheybani, Natasha Diba; Sagreiya, Hersh; Rubin, Daniel L.] Stanford Univ, Sch Med, Dept Biomed Data Sci, 300 Pasteur Dr, Stanford, CA 94305 USA; [Syed, Saad Ali; Wentland, Andrew Louis; Madhuripan, Nikhil; Goff, Daniel; Barbee, Victoria; Rubin, Daniel L.; Desser, Terry S.] Stanford Univ, Sch Med, Dept Radiol, 300 Pasteur Dr, Stanford, CA 94305 USA	Stanford University; Stanford University	Desser, TS (corresponding author), Stanford Univ, Sch Med, Dept Radiol, 300 Pasteur Dr, Stanford, CA 94305 USA.	tsdesser@stanford.edu		Alam, Minhaj/0000-0003-3095-2232; Wentland, Andrew/0000-0003-1736-8218; Goff, Daniel/0000-0003-2109-1696; Akdogan, Mete Ugur/0000-0003-1520-1481	Yahoo Faculty Research and Engagement Program; National Institutes of Health (NIH) [K00CA234954, NCI/F99/K00]; National Science Foundation	Yahoo Faculty Research and Engagement Program; National Institutes of Health (NIH)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); National Science Foundation(National Science Foundation (NSF))	Supported in part by the Yahoo Faculty Research and Engagement Program. E.A. supported by the National Institutes of Health (NIH) award numbers PADLY, PADPM, PAEPI, PAFFL, PAWAO, PCOXK, PCQUD, and PCRMR. N.D.S. supported by the NIH NCI/F99/K00 Predoctoral-to-Postdoctoral Fellow Transition Award (K00CA234954). D.L.R. supported by a grant from the National Science Foundation.	[Anonymous], 1999, 10153 BS EN; Azizi G, 2021, ULTRASOUND MED BIOL, V47, P1299, DOI 10.1016/j.ultrasmedbio.2021.01.010; Bessey LJ, 2013, J SURG RES, V184, P761, DOI 10.1016/j.jss.2013.03.086; Buda M, 2019, RADIOLOGY, V292, P695, DOI 10.1148/radiol.2019181343; Buda M, 2018, NEURAL NETWORKS, V106, P249, DOI 10.1016/j.neunet.2018.07.011; Galimzianova A, 2020, AM J ROENTGENOL, V214, P885, DOI 10.2214/AJR.19.21350; Gillies RJ, 2016, RADIOLOGY, V278, P563, DOI 10.1148/radiol.2015151169; Hahn Lewis D, 2017, Cancers Head Neck, V2, P1, DOI 10.1186/s41199-016-0021-x; Haugen BR, 2016, THYROID, V26, P1, DOI 10.1089/thy.2015.0020; Hoang JK, 2018, AM J ROENTGENOL, V211, P162, DOI 10.2214/AJR.17.19192; Hoang JK, 2018, RADIOLOGY, V287, P185, DOI 10.1148/radiol.2018172572; Jang M, 2012, J ULTRAS MED, V31, P197, DOI 10.7863/jum.2012.31.2.197; Kim SC, 2016, EUR RADIOL, V26, P3353, DOI 10.1007/s00330-015-4193-2; Kosinski AS, 2013, STAT MED, V32, P964, DOI 10.1002/sim.5587; Li HL, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25005-7; Li WB, 2015, ULTRASOUND MED BIOL, V41, P3096, DOI 10.1016/j.ultrasmedbio.2015.06.022; Li XC, 2019, LANCET ONCOL, V20, P193, DOI 10.1016/S1470-2045(18)30762-9; Nikiforov YE, 2016, JAMA ONCOL, V2, P1023, DOI 10.1001/jamaoncol.2016.0386; Park VY, 2021, EUR RADIOL, V31, P2405, DOI 10.1007/s00330-020-07365-9; Park VY, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-54434-1; Peng S, 2021, LANCET DIGIT HEALTH, V3, pE250, DOI 10.1016/S2589-7500(21)00041-8; Rubin DL, 2019, TOMOGRAPHY, V5, P170, DOI 10.18383/j.tom.2018.00055; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474; Slapa RZ, 2011, THYROID RES, V4, DOI 10.1186/1756-6614-4-1; Slapa RZ, 2006, EUR RADIOL, V16, P428, DOI 10.1007/s00330-005-2903-x; Song J, 2019, MEDICINE, V98, DOI 10.1097/MD.0000000000015133; Tessler FN, 2017, J AM COLL RADIOL, V14, P587, DOI 10.1016/j.jacr.2017.01.046; Thomas J, 2020, THYROID, V30, P878, DOI 10.1089/thy.2019.0752; van Griethuysen JJM, 2017, CANCER RES, V77, pE104, DOI 10.1158/0008-5472.CAN-17-0339; Vaswani A., 2017, ARXIV, DOI DOI 10.48550/ARXIV.1706.03762; Wang S, 2020, FRONT ONCOL, V10, DOI 10.3389/fonc.2020.591846; Wu GG, 2021, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.575166; Zhou X. H., 2011, STAT METHODS DIAGNOS, DOI 10.1002/9780470906514	35	0	0	4	4	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2022	4	3							e210174	10.1148/ryai.210174	http://dx.doi.org/10.1148/ryai.210174			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9YQ	35652118	Green Published			2022-12-18	WOS:000826924200004
J	Dutt, R; Mendonca, D; Phen, HM; Broida, S; Ghassemi, M; Gichoya, J; Banerjee, I; Yoon, T; Trivedi, H				Dutt, Raman; Mendonca, Dylan; Phen, Huai Ming; Broida, Samuel; Ghassemi, Marzyeh; Gichoya, Judy; Banerjee, Imon; Yoon, Tim; Trivedi, Hari			Automatic Localization and Brand Detection of Cervical Spine Hardware on Radiographs Using Weakly Supervised Machine Learning	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Spine; Convolutional Neural Network; Deep Learning Algorithms; Machine Learning Algorithms; Prostheses; Semisupervised Learning	FUSION; DISKECTOMY; MYELOPATHY; RADICULOPATHY; ARTHROPLASTY; MULTICENTER; ADJACENT; TRENDS	Purpose: To develop an end-to-end pipeline to localize and identify cervical spine hardware brands on routine cervical spine radiographs. Materials and Methods: In this single-center retrospective study, patients who received cervical spine implants between 2014 and 2018 were identified. Information on the implant model was retrieved from the surgical notes. The dataset was filtered for implants present in at least three patients, which yielded five anterior and five posterior hardware models for classification. Images for training were manually annotated with bounding boxes for anterior and posterior hardware. An object detection model was trained and implemented to localize hardware on the remaining images. An image classification model was then trained to differentiate between five anterior and five posterior hardware models. Model performance was evaluated on a holdout test set with 1000 iterations of bootstrapping. Results: A total of 984 patients (mean age, 62 years +/- 12 [standard deviation]; 525 women) were included for model training, validation, and testing. The hardware localization model achieved an intersection over union of 86.8% and an F1 score of 94.9%. For brand classification, an F1 score, sensitivity, and specificity of 98.7% +/- 0.5, 98.7% 6 0.5, and 99.2% +/- 0.3, respectively, were attained for anterior hardware, with values of 93.5% +/- 2.0, 92.6% +/- 2.0, and 96.1% +/- 2.0, respectively, attained for posterior hardware. Conclusion: The developed pipeline was able to accurately localize and classify brands of hardware implants using a weakly supervised learning framework. (C)RSNA, 2022	[Dutt, Raman] Shiv Nadar Univ, Dept Comp Sci, Greater Noida, Uttar Pradesh, India; [Mendonca, Dylan] Univ Toronto, Dept Chem Engn & Appl Chem, Toronto, ON, Canada; [Ghassemi, Marzyeh] Univ Toronto, Dept Comp Sci, Toronto, ON, Canada; [Phen, Huai Ming; Broida, Samuel; Gichoya, Judy; Yoon, Tim; Trivedi, Hari] Emory Univ, Dept Radiol, Atlanta, GA 30322 USA; [Banerjee, Imon] Emory Univ, Dept Biomed Informat, Atlanta, GA 30322 USA	Shiv Nadar University; University of Toronto; University of Toronto; Emory University; Emory University	Trivedi, H (corresponding author), Emory Univ, Dept Radiol, Atlanta, GA 30322 USA.	hari.trivedi@emory.edu		Mendonca, Dylan/0000-0002-9090-5668; Banerjee, Imon/0000-0002-3327-8004; Yoon, S. Tim/0000-0003-1010-6952				Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265; [Anonymous], 2019, SPINAL IMPLANTS MARK; Borjali A, 2021, MED PHYS, V48, P2327, DOI 10.1002/mp.14705; Burneikiene S, 2015, SPINE J, V15, P427, DOI 10.1016/j.spinee.2014.09.017; Bydon Mohamad, 2014, Surg Neurol Int, V5, pS74, DOI 10.4103/2152-7806.130676; Chung JY, 2014, SPINE J, V14, P2290, DOI 10.1016/j.spinee.2014.01.027; Galivanche AR, 2020, NEUROSPINE, V17, P871, DOI 10.14245/ns.2040134.067; Gessert N, 2020, METHODSX, V7, DOI 10.1016/j.mex.2020.100864; Hadrien Bertr, 2020, Arxiv, DOI arXiv:2002.02582; Harris CR, 2020, NATURE, V585, P357, DOI 10.1038/s41586-020-2649-2; Hilibrand AS, 1999, J BONE JOINT SURG AM, V81A, P519, DOI 10.2106/00004623-199904000-00009; Hopkins BS, 2019, WORLD NEUROSURG, V127, pE436, DOI 10.1016/j.wneu.2019.03.165; Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243; Ishihara Hirokazu, 2004, Spine J, V4, P624, DOI 10.1016/j.spinee.2004.04.011; Kang YJ, 2020, J ORTHOP TRANSL, V21, P13, DOI 10.1016/j.jot.2019.11.004; Kingma D.P, P 3 INT C LEARNING R; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Marques G, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106691; Miglani V., 2021, ADV MACHINE LEARNING, V1141, P315, DOI 10.1007/978-981-15-3383-9_29; Paszke A, 2019, ARXIV; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Rajaee SS, 2014, BONE JOINT J, V96B, P807, DOI 10.1302/0301-620X.96B6.31149; Saifi C, 2018, SPINE J, V18, P1022, DOI 10.1016/j.spinee.2017.10.072; Sampath P, 2000, SPINE, V25, P670, DOI 10.1097/00007632-200003150-00004; Sampath P, 1999, SPINE, V24, P591, DOI 10.1097/00007632-199903150-00021; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Veeravagu A, 2016, NEUROSURG FOCUS, V40, DOI 10.3171/2016.3.FOCUS1669; Wang LN, 2016, INT ORTHOP, V40, P1267, DOI 10.1007/s00264-016-3194-3; Wang WCV, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20133661; Yi PH, 2020, SKELETAL RADIOL, V49, P1623, DOI 10.1007/s00256-020-03463-3; Yi PH, 2020, KNEE, V27, P535, DOI 10.1016/j.knee.2019.11.020	31	0	0	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2022	4	2							e210099	10.1148/ryai.210099	http://dx.doi.org/10.1148/ryai.210099			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9YB	35391772	Green Published			2022-12-18	WOS:000826922700006
J	Horii, SC				Horii, Steven C.			Improving Our Understanding of Indolent Lesions: A New Role for AI	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Horii, Steven C.] Univ Penn, Dept Radiol, Perelman Sch Med, 3400 Spruce St, Philadelphia, PA 19104 USA	University of Pennsylvania	Horii, SC (corresponding author), Univ Penn, Dept Radiol, Perelman Sch Med, 3400 Spruce St, Philadelphia, PA 19104 USA.	steve.horii@pennmedicine.upenn.edu						Center for Medicare and Medicaid Services, RAD PREF SPEC MEAS S; D'Ippolito Giuseppe, 2018, Radiol Bras, V51, pV, DOI 10.1590/0100-3984.2018.51.4e1; DeLuca A, NEAR REAL TIME NATUR; Ganeshan D, 2018, ACAD RADIOL, V25, P66, DOI 10.1016/j.acra.2017.08.005; Johnson AJ, 2009, RADIOLOGY, V253, P74, DOI 10.1148/radiol.2531090138; Megibow AJ, 2017, J AM COLL RADIOL, V14, P911, DOI 10.1016/j.jacr.2017.03.010; Pons E, 2016, RADIOLOGY, V279, P329, DOI 10.1148/radiol.16142770; Yamashita R, 2022, RADIOL ARTIF INTELL, V4	8	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2022	4	2							e210312	10.1148/ryai.210312	http://dx.doi.org/10.1148/ryai.210312			2	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9YB	35391778	Green Published			2022-12-18	WOS:000826922700017
J	Huisman, M; Lessmann, N				Huisman, Merel; Lessmann, Nikolas			Automatic Brand Identification of Orthopedic Implants from Radiographs: Ready for the Next Step?	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Huisman, Merel] Univ Med Ctr Utrecht, Dept Radiol, Heidelberglaan 100, NL-3508 Utrecht, Netherlands; [Lessmann, Nikolas] Radboud Univ Nijmegen, Dept Radiol & Nucl Med, Med Ctr, Nijmegen, Netherlands	Utrecht University; Utrecht University Medical Center; Radboud University Nijmegen	Huisman, M (corresponding author), Univ Med Ctr Utrecht, Dept Radiol, Heidelberglaan 100, NL-3508 Utrecht, Netherlands.			Lessmann, Nikolas/0000-0001-7935-9611				Borjali A, 2021, MED PHYS, V48, P2327, DOI 10.1002/mp.14705; Dutt R, 2022, RADIOL ARTIF INTELL, V2; Karnuta JM, 2021, J ARTHROPLASTY, V36, pS290, DOI 10.1016/j.arth.2020.11.015; Malchau H, 2018, J ORTHOP RES, V36, P2319, DOI 10.1002/jor.24014; Patel R, 2021, RADIOL-ARTIF INTELL, V3, DOI 10.1148/ryai.2021200183; Ren M, 2022, SKELETAL RADIOL, V51, P407, DOI 10.1007/s00256-021-03884-8; Sagheb E, 2021, J ARTHROPLASTY, V36, P922, DOI 10.1016/j.arth.2020.09.029; Yi PH, 2020, KNEE, V27, P535, DOI 10.1016/j.knee.2019.11.020	8	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2022	4	2							e220008	10.1148/ryai.220008	http://dx.doi.org/10.1148/ryai.220008			2	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9YB	35391760	Green Published			2022-12-18	WOS:000826922700018
J	Magni, V; Interlenghi, M; Cozzi, A; Ali, M; Salvatore, C; Azzena, AA; Capra, D; Carriero, S; Della Pepa, G; Fazzini, D; Granata, G; Monti, CB; Muscogiuri, G; Pellegrino, G; Schiaffino, S; Castiglioni, I; Papa, S; Sardanelli, F				Magni, Veronica; Interlenghi, Matteo; Cozzi, Andrea; Ali, Marco; Salvatore, Christian; Azzena, Alcide A.; Capra, Davide; Carriero, Serena; Della Pepa, Gianmarco; Fazzini, Deborah; Granata, Giuseppe; Monti, Caterina B.; Muscogiuri, Giulia; Pellegrino, Giuseppe; Schiaffino, Simone; Castiglioni, Isabella; Papa, Sergio; Sardanelli, Francesco			Development and Validation of an AI-driven Mammographic Breast Density Classification Tool Based on Radiologist Consensus	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Mammography; Breast; Convolutional Neural Network (CNN); Deep Learning Algorithms; Machine Learning Algorithms	CANCER RISK; PREDICTION	Mammographic breast density (BD) is commonly visually assessed using the Breast Imaging Reporting and Data System (BI-RADS) four-category scale. To overcome inter- and intraobserver variability of visual assessment, the authors retrospectively developed and externally validated a software for BD classification based on convolutional neural networks from mammograms obtained between 2017 and 2020. The tool was trained using the majority BD category determined by seven board-certified radiologists who independently visually assessed 760 mediolateral oblique (MLO) images in 380 women (mean age, 57 years +/- 6 [SD]) from center 1; this process mimicked training from a consensus of several human readers. External validation of the model was performed by the three radiologists whose BD assessment was closest to the majority (consensus) of the initial seven on a dataset of 384 MLO images in 197 women (mean age, 56 years +/- 13) obtained from center 2. The model achieved an accuracy of 89.3% in distinguishing BI-RADS a or b (nondense breasts) versus c or d (dense breasts) categories, with an agreement of 90.4% (178 of 197 mammograms) and a reliability of 0.807 (Cohen k) compared with the mode of the three readers. This study demonstrates accuracy and reliability of a fully automated software for BD classification. (C)RSNA, 2022	[Magni, Veronica; Cozzi, Andrea; Capra, Davide; Monti, Caterina B.; Sardanelli, Francesco] Univ Milan, Dept Biomed Sci Hlth, Milan, Italy; [Azzena, Alcide A.; Carriero, Serena; Della Pepa, Gianmarco; Granata, Giuseppe; Muscogiuri, Giulia; Pellegrino, Giuseppe] Univ Milan, Postgrad Sch Radiodiagnost, Milan, Italy; [Interlenghi, Matteo; Salvatore, Christian] DeepTrace Technol, Milan, Italy; [Ali, Marco; Fazzini, Deborah; Papa, Sergio] CDI Ctr Diagnost Italiano, Unit Diagnost Imaging & Stereoract Radiosurg, Milan, Italy; [Ali, Marco] Bracco Imaging, Milan, Italy; [Salvatore, Christian] Univ Sch Adv Studies IUSS Pavia, Dept Sci Technol & Soc, Piazza Vittoria 15, I-27100 Pavia, Italy; [Schiaffino, Simone; Sardanelli, Francesco] IRCCS Policlin San Donato, Unit Radiol, San Donato Milanese, Italy; [Castiglioni, Isabella] Consiglio Nazl Belle Ric, Inst Biomed Imaging & Physiol, Segrate, Italy; [Castiglioni, Isabella] Univ Milano Bicocca, Dept Phys, Milan, Italy	University of Milan; University of Milan; Bracco; IUSS PAVIA; IRCCS Policlinico San Donato; University of Milano-Bicocca	Salvatore, C (corresponding author), DeepTrace Technol, Milan, Italy.; Salvatore, C (corresponding author), Univ Sch Adv Studies IUSS Pavia, Dept Sci Technol & Soc, Piazza Vittoria 15, I-27100 Pavia, Italy.	salvatore@deeptracetech.com	Cozzi, Andrea/C-5453-2019; Capra, Davide/AAV-3777-2020; Salvatore, Christian/J-9828-2016	Cozzi, Andrea/0000-0003-4922-7065; Capra, Davide/0000-0001-7978-4730; Salvatore, Christian/0000-0001-9312-4675; Azzena, Alcide Alessandro/0000-0002-6403-4694				Alomaim W, 2019, J MED IMAGING RADIAT, V50, P53, DOI 10.1016/j.jmir.2018.11.002; Bakker MF, 2019, NEW ENGL J MED, V381, P2091, DOI 10.1056/NEJMoa1903986; Brandt KR, 2016, RADIOLOGY, V279, P710, DOI 10.1148/radiol.2015151261; Castiglioni I, 2021, PHYS MEDICA, V83, P9, DOI 10.1016/j.ejmp.2021.02.006; Damases CN, 2017, BRIT J RADIOL, V90, DOI 10.1259/bjr.20170064; Freer PE, 2015, RADIOGRAPHICS, V35, P302, DOI 10.1148/rg.352140106; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Keating NL, 2019, JAMA-J AM MED ASSOC, V321, P2275, DOI 10.1001/jama.2019.5919; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Lehman CD, 2019, RADIOLOGY, V290, P52, DOI 10.1148/radiol.2018180694; McCormack VA, 2006, CANCER EPIDEM BIOMAR, V15, P1159, DOI 10.1158/1055-9965.EPI-06-0034; Moshina N, 2018, ACTA RADIOL, V59, P154, DOI 10.1177/0284185117712540; Nazari SS, 2018, BREAST CANCER-TOKYO, V25, P259, DOI 10.1007/s12282-018-0857-5; Sartor H, 2016, EUR RADIOL, V26, P4354, DOI 10.1007/s00330-016-4309-3; Sickles EA, 2013, ACR BI RADS ATLAS BR, V5th, P46; Sprague BL, 2016, ANN INTERN MED, V165, P457, DOI 10.7326/M15-2934; Tyrer J, 2004, STAT MED, V23, P1111, DOI 10.1002/sim.1668; Weinstein SP, 2021, J AM COLL RADIOL, V18, pS456, DOI 10.1016/j.jacr.2021.09.002; Yeo I, 2020, J MED IMAGING, V7, DOI 10.1117/1.JMI.7.3.035501; Youk JH, 2016, AM J ROENTGENOL, V206, P1056, DOI 10.2214/AJR.15.15472	20	0	0	3	3	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2022	4	2							e210199	10.1148/ryai.210199	http://dx.doi.org/10.1148/ryai.210199			5	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9YB	35391766	Green Published			2022-12-18	WOS:000826922700013
J	Mongan, J; Vagal, A; Wu, CC				Mongan, John; Vagal, Achala; Wu, Carol C.			Imaging AI in Practice: Introducing the Special Issue	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Mongan, John] Univ Calif San Francisco, Ctr Intelligent Imaging, Dept Radiol & Biomed Imaging, 505 Pamassus Ave,Box 0628, San Francisco, CA 94143 USA; [Vagal, Achala] Univ Cincinnati, Dept Radiol, Cincinnati, OH USA; [Wu, Carol C.] Univ Texas MD Anderson Canc Ctr, Dept Thorac Imaging, Houston, TX 77030 USA	University of California System; University of California San Francisco; University System of Ohio; University of Cincinnati; University of Texas System; UTMD Anderson Cancer Center	Mongan, J (corresponding author), Univ Calif San Francisco, Ctr Intelligent Imaging, Dept Radiol & Biomed Imaging, 505 Pamassus Ave,Box 0628, San Francisco, CA 94143 USA.	john.mongan@ucsf.edu		Vagal, Achala/0000-0001-6428-6499; Mongan, John/0000-0003-2765-7451				Goel A, 2022, RADIOL ARTIF INTELL, V4; Hahn LD, 2022, RADIOL ARTIF INTELL, V4; Kahn CE, 2019, RADIOL-ARTIF INTELL, V1, DOI [10.1148/ryai.2019184001, 10.1148/ryai2019184001]; Magni V, 2022, RADIOL ARTIF INTELL, V4; Monti CB, 2022, RADIOL ARTIF INTELL, V4; Retson TA, 2022, RADIOL ARTIF INTELL, V2; Rudie JD, 2022, RADIOL-ARTIF INTELL, V4, DOI 10.1148/ryai.210059; Sanders JW, 2022, RADIOL ARTIF INTELL, V4; Seyam M, 2022, RADIOL-ARTIF INTELL, V4, DOI 10.1148/ryai.210168	9	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2022	4	2							e220039	10.1148/ryai.220039	http://dx.doi.org/10.1148/ryai.220039			2	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9YB	35391763	Green Published			2022-12-18	WOS:000826922700019
J	Retson, TA; Hasenstab, KA; Kligerman, SJ; Jacobs, KE; Yen, AC; Brouha, SS; Hahn, LD; Hsiao, A				Retson, Tara A.; Hasenstab, Kyle A.; Kligerman, Seth J.; Jacobs, Kathleen E.; Yen, Andrew C.; Brouha, Sharon S.; Hahn, Lewis D.; Hsiao, Albert			Reader Perceptions and Impact of AI on CT Assessment of Air Trapping	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Technology Assessment; Quantification	HIGH-RESOLUTION CT; COMPUTED-TOMOGRAPHY; PULMONARY-FUNCTION; DIAGNOSIS; PROGRESSION; VOLUMETRY	Quantitative imaging measurements can be facilitated by artificial intelligence (AI) algorithms, but how they might impact decision-making and be perceived by radiologists remains uncertain. After creation of a dedicated inspiratory-expiratory CT examination and concurrent deployment of a quantitative AI algorithm for assessing air trapping, five cardiothoracic radiologists retrospectively evaluated severity of air trapping on 17 examination studies. Air trapping severity of each lobe was evaluated in three stages: qualitatively (visually); semiquantitatively, allowing manual region-of-interest measurements; and quantitatively, using results from an AI algorithm. Readers were surveyed on each case for their perceptions of the AI algorithm. The algorithm improved interreader agreement (intraclass correlation coefficients: visual, 0.28; semiquantitative, 0.40; quantitative, 0.84; P < .001) and improved correlation with pulmonary function testing (forced expiratory volume in 1 second-to-forced vital capacity ratio) (visual r = -0.26, semiquantitative r = -0.32, quantitative r = -0.44). Readers perceived moderate agreement with the AI algorithm (Likert scale average, 3.7 of 5), a mild impact on their final assessment (average, 2.6), and a neutral perception of overall utility (average, 3.5). Though the AI algorithm objectively improved interreader consistency and correlation with pulmonary function testing, individual readers did not immediately perceive this benefit, revealing a potential barrier to clinical adoption. (C)RSNA, 2021	[Retson, Tara A.; Kligerman, Seth J.; Jacobs, Kathleen E.; Yen, Andrew C.; Brouha, Sharon S.; Hahn, Lewis D.; Hsiao, Albert] Univ Calif San Diego, Dept Radiol, 9452 Med Ctr Dr,4th Floor, La Jolla, CA 92037 USA; [Hasenstab, Kyle A.] San Diego State Univ, Dept Math & Stat, San Diego, CA 92182 USA	University of California System; University of California San Diego; California State University System; San Diego State University	Retson, TA (corresponding author), Univ Calif San Diego, Dept Radiol, 9452 Med Ctr Dr,4th Floor, La Jolla, CA 92037 USA.	tretson@health.ucsd.edu		Hsiao, Albert/0000-0002-9412-1369; Retson, Tara/0000-0002-0009-7733	Microsoft AI for Health; Amazon Web Services; National Institutes of Health [T32 EB005970]; Radiological Society of North America [RR1879]; Friedman Family Endowed Radiology Fellowship; National Science Foundation [2026809]	Microsoft AI for Health(Microsoft); Amazon Web Services; National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Radiological Society of North America; Friedman Family Endowed Radiology Fellowship; National Science Foundation(National Science Foundation (NSF))	Supported by research grants from Microsoft AI for Health and Amazon Web Services. T.A.R. supported by the National Institutes of Health (T32 EB005970), the Radiological Society of North America (grant RR1879), and the Friedman Family Endowed Radiology Fellowship. A.H. supported by the National Science Foundation (grant no. 2026809).	Arakawa H, 1998, AM J ROENTGENOL, V170, P1349, DOI 10.2214/ajr.170.5.9574614; Bin Saeedan M, 2020, INSIGHTS IMAGING, V11, DOI 10.1186/s13244-019-0822-7; Bond RR, 2018, J ELECTROCARDIOL, V51, pS6, DOI 10.1016/j.jelectrocard.2018.08.007; Callister ME, 2015, THORAX, V70, P1188, DOI 10.1136/thoraxjnl-2015-207168corr1; Chen A, 2020, RADIOGRAPHICS, V40, P28, DOI 10.1148/rg.2020190099; Criado E, 2010, RADIOGRAPHICS, V30, P1567, DOI 10.1148/rg.306105512; de Jong PA, 2006, THORAX, V61, P799, DOI 10.1136/thx.2005.053249; Devaraj A, 2017, RADIOLOGY, V284, P630, DOI 10.1148/radiol.2017151022; Gazourian L, 2017, CLIN TRANSPLANT, V31, DOI 10.1111/ctr.12943; Goddard K, 2012, J AM MED INFORM ASSN, V19, P121, DOI 10.1136/amiajnl-2011-000089; Hall GL, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0023932; Hallgren Kevin A, 2012, Tutor Quant Methods Psychol, V8, P23; Hasenstab Kyle A, 2021, Radiol Cardiothorac Imaging, V3, pe200477, DOI 10.1148/ryct.2021200477; Hoesein FAM, 2017, EUR RESPIR J, V49, DOI 10.1183/13993003.01791-2016; Jeon KN, 2012, INVEST RADIOL, V47, P457, DOI 10.1097/RLI.0b013e318250a5aa; Liu K, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180084; Lowe KE, 2019, COPD-J COPD FDN, V6, P384, DOI 10.15326/jcopdf.6.5.2019.0149; Mehta HJ, 2014, CHEST, V145, P464, DOI 10.1378/chest.13-0708; Miller Wallace T Jr, 2014, Ann Am Thorac Soc, V11, P874, DOI 10.1513/AnnalsATS.201311-390OC; Pompe E, 2020, RADIOLOGY, V295, P218, DOI 10.1148/radiol.2020191429; Pompe E, 2015, AM J RESP CRIT CARE, V191, P1084, DOI 10.1164/rccm.201411-2105LE; Ram S, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0248902; Salim M, 2020, JAMA ONCOL, V6, P1581, DOI 10.1001/jamaoncol.2020.3321; Schaffter T, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.0265; Schoppe O, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-19449-7; STERN EJ, 1994, INVEST RADIOL, V29, P564, DOI 10.1097/00004424-199405000-00007; Suinesiaputra Avail, 2012, Statistical Atlases and Computational Models of the Heart. Imaging and Modelling Challenges. Second International Workshop, STACOM 2011 Held in Conjunction with MICCAI 2011. Revised Selected Papers, P88, DOI 10.1007/978-3-642-28326-0_9; Van Herck A, 2019, J HEART LUNG TRANSPL, V38, pS16, DOI 10.1016/j.healun.2019.01.024; Verleden SE, 2016, AM J TRANSPLANT, V16, P3262, DOI 10.1111/ajt.13945; Zhang K, 2020, CELL, V181, P1423, DOI 10.1016/j.cell.2020.04.045	30	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2022	4	2							e210160	10.1148/ryai.2021210160	http://dx.doi.org/10.1148/ryai.2021210160			6	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9YB	35391767	Green Published			2022-12-18	WOS:000826922700001
J	Sanders, JW; Kudchadker, RJ; Tang, C; Mok, H; Venkatesan, AM; Thames, HD; Frank, SJ				Sanders, Jeremiah W.; Kudchadker, Rajat J.; Tang, Chad; Mok, Henry; Venkatesan, Aradhana M.; Thames, Howard D.; Frank, Steven J.			Prospective Evaluation of Prostate and Organs at Risk Segmentation Software for MRI-based Prostate Radiation Therapy	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						MRI; Neural Networks; Radiation Therapy; Radiation Therapy/Oncology; Genital/Reproductive; Prostate; Segmentation; Dosimetry	LOW-DOSE-RATE; INTEROBSERVER VARIABILITY; ASSISTED RADIOSURGERY; POSTIMPLANT DOSIMETRY; BRACHYTHERAPY; DIAGNOSIS	The segmentation of the prostate and surrounding organs at risk (OARs) is a necessary workflow step for performing dose-volume histogram analyses of prostate radiation therapy procedures. Low-dose-rate prostate brachytherapy (LDRPBT) is a curative prostate radiation therapy treatment that delivers a single fraction of radiation over a period of days. Prior studies have demonstrated the feasibility of fully convolutional networks to segment the prostate and surrounding OARs for LDRPBT dose-volume histogram analyses. However, performance evaluations have been limited to measures of global similarity between algorithm predictions and a reference. To date, the clinical use of automatic segmentation algorithms for LDRPBT has not been evaluated, to the authors' knowledge. The purpose of this work was to assess the performance of fully convolutional networks for prostate and OAR delineation on a prospectively identified cohort of patients who underwent LDRPBT by using clinically relevant metrics. Thirty patients underwent LDRPBT and were imaged with fully balanced steady-state free precession MRI after implantation. Custom automatic segmentation software was used to segment the prostate and four OARs. Dose-volume histogram analyses were performed by using both the original automatically generated contours and the physician-refined contours. Dosimetry parameters of the prostate, external urinary sphincter, and rectum were compared without and with the physician refinements. This study observed that physician refinements to the automatic contours did not significantly affect dosimetry parameters. (C)RSNA, 2022	[Sanders, Jeremiah W.] Univ Texas MD Anderson Canc Ctr, Dept Imaging Phys, 1515 Holcombe Blvd, Houston, TX 77030 USA; [Kudchadker, Rajat J.] Univ Texas MD Anderson Canc Ctr, Dept Radiat Phys, 1515 Holcombe Blvd, Houston, TX 77030 USA; [Tang, Chad; Mok, Henry; Frank, Steven J.] Univ Texas MD Anderson Canc Ctr, Dept Radiat Oncol, 1515 Holcombe Blvd, Houston, TX 77030 USA; [Venkatesan, Aradhana M.] Univ Texas MD Anderson Canc Ctr, Dept Diagnost Radiol, 1515 Holcombe Blvd, Houston, TX 77030 USA; [Thames, Howard D.] Univ Texas MD Anderson Canc Ctr, Dept Biostat, 1515 Holcombe Blvd, Houston, TX 77030 USA	University of Texas System; UTMD Anderson Cancer Center; University of Texas System; UTMD Anderson Cancer Center; University of Texas System; UTMD Anderson Cancer Center; University of Texas System; UTMD Anderson Cancer Center; University of Texas System; UTMD Anderson Cancer Center	Sanders, JW (corresponding author), Univ Texas MD Anderson Canc Ctr, Dept Imaging Phys, 1515 Holcombe Blvd, Houston, TX 77030 USA.	jsanders1@mdanderson.org		Sanders, Jeremiah/0000-0002-5342-4128				Al-Qaisieh B, 2002, RADIOTHER ONCOL, V62, P267, DOI 10.1016/S0167-8140(01)00475-3; Boyce-Fappiano D, 2020, BRACHYTHERAPY, V19, P574, DOI 10.1016/j.brachy.2020.06.011; Cha EE, 2021, RADIOTHER ONCOL, V159, P1, DOI 10.1016/j.radonc.2021.02.040; Chicco D, 2020, BMC GENOMICS, V21, DOI 10.1186/s12864-019-6413-7; Crook Juanita, 2002, Brachytherapy, V1, P66, DOI 10.1016/S1538-4721(02)00014-4; Crook JM, 2020, RADIOTHER ONCOL, V149, P64, DOI 10.1016/j.radonc.2020.04.038; Davis BJ, 2012, BRACHYTHERAPY, V11, P6, DOI 10.1016/j.brachy.2011.07.005; De Brabandere M, 2012, RADIOTHER ONCOL, V104, P192, DOI 10.1016/j.radonc.2012.06.014; Dubois DF, 1998, RADIOLOGY, V207, P785, DOI 10.1148/radiology.207.3.9609905; Frank SJ, 2017, BRACHYTHERAPY, V16, P672, DOI 10.1016/j.brachy.2017.01.014; Frank SJ, 2008, INT J RADIAT ONCOL, V71, P5, DOI 10.1016/j.ijrobp.2008.01.028; Lee WR, 2002, INT J RADIAT ONCOL, V54, P457, DOI 10.1016/S0360-3016(02)02950-4; Ma JF, 2017, BRACHYTHERAPY, V16, P743, DOI 10.1016/j.brachy.2016.11.014; Nath R, 2009, MED PHYS, V36, P5310, DOI 10.1118/1.3246613; Sanders JW, 2021, INT J RADIAT ONCOL, V109, P614, DOI 10.1016/j.ijrobp.2020.09.040; Sanders JW, 2020, INT J RADIAT ONCOL, V108, P1292, DOI 10.1016/j.ijrobp.2020.06.076; Sanders JW, RADIOTHER ONCOL; Schutzer ME, 2015, PROSTATE CANCER P D, V18, P96, DOI 10.1038/pcan.2015.4; Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683; Tanderup K, 2014, SEMIN RADIAT ONCOL, V24, P181, DOI 10.1016/j.semradonc.2014.02.007; Uribe Jennifer, 2021, BJUI Compass, V2, P9, DOI 10.1002/bco2.49; Venkatesan AM, 2017, BRACHYTHERAPY, V16, P688, DOI 10.1016/j.brachy.2016.12.012	22	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2022	4	2							e210151	10.1148/ryai.210151	http://dx.doi.org/10.1148/ryai.210151			6	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9YB	35391775	Green Published			2022-12-18	WOS:000826922700009
J	Tadavarthi, Y; Makeeva, V; Wagstaff, W; Zhan, H; Podlasek, A; Bhatia, N; Heilbrun, M; Krupinski, E; Safdar, N; Banerjee, I; Gichoya, J; Trivedi, H				Tadavarthi, Yasasvi; Makeeva, Valeria; Wagstaff, William; Zhan, Henry; Podlasek, Anna; Bhatia, Neil; Heilbrun, Marta; Krupinski, Elizabeth; Safdar, Nabile; Banerjee, Imon; Gichoya, Judy; Trivedi, Hari			Overview of Noninterpretive Artificial Intelligence Models for Safety, Quality, Workflow, and Education Applications in Radiology Practice	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Review						Use of AI in Education; Application Domain; Supervised Learning; Safety	INFORMATION EXTRACTION; AUTOMATED DETECTION; THYROID-NODULES; IMAGE QUALITY; CT; RECONSTRUCTION; TRANSFORM; FRAMEWORK; SCAN; RISK	Artificial intelligence has become a ubiquitous term in radiology over the past several years, and much attention has been given to applications that aid radiologists in the detection of abnormalities and diagnosis of diseases. However, there are many potential applications related to radiologic image quality, safety, and workflow improvements that present equal, if not greater, value propositions to radiology practices, insurance companies, and hospital systems. This review focuses on six major categories for artificial intelligence applications: study selection and protocoling, image acquisition, worklist prioritization, study reporting, business applications, and resident education. All of these categories can substantially affect different aspects of radiology practices and workflows. Each of these categories has different value propositions in terms of whether they could be used to increase efficiency, improve patient safety, increase revenue, or save costs. Each application is covered in depth in the context of both current and future areas of work. (C)RSNA, 2022	[Tadavarthi, Yasasvi] Med Coll Georgia, Dept Med, Augusta, GA 30912 USA; [Makeeva, Valeria; Wagstaff, William; Zhan, Henry; Heilbrun, Marta; Krupinski, Elizabeth; Safdar, Nabile; Gichoya, Judy; Trivedi, Hari] Emory Univ, Dept Radiol & Imaging Sci, 1364 E Clifton Rd NE, Atlanta, GA 30322 USA; [Bhatia, Neil] Emory Univ, Sch Med, 1364 E Clifton Rd NE, Atlanta, GA 30322 USA; [Banerjee, Imon] Emory Univ, Dept Biomed Informat, 1364 E Clifton Rd NE, Atlanta, GA 30322 USA; [Podlasek, Anna] Southend Univ Hosp NHS Fdn Trust, Westcliff On Sea, England	University System of Georgia; Augusta University; Emory University; Emory University; Emory University	Trivedi, H (corresponding author), Emory Univ, Dept Radiol & Imaging Sci, 1364 E Clifton Rd NE, Atlanta, GA 30322 USA.	hari.trivedi@emory.edu	Podlasek, Anna/AAF-9959-2020	Podlasek, Anna/0000-0001-7297-7169; Tadavarthi, Yasasvi/0000-0002-0387-2299; Heilbrun, Marta/0000-0001-8827-0854; Safdar, Nabile/0000-0002-1131-8052; Banerjee, Imon/0000-0002-3327-8004; Wagstaff, William/0000-0002-7071-2973				Allen Bibb Jr, 2007, J Am Coll Radiol, V4, P106, DOI 10.1016/j.jacr.2006.10.003; AlMuhaideb S, 2019, ANN SAUDI MED, V39, P373, DOI 10.5144/0256-4947.2019.373; American College of Radiology, ACR SEL; Annarumma M, 2019, RADIOLOGY, V291, P195, DOI 10.1148/radiol.2018180921; [Anonymous], BUSINESS WIRE; [Anonymous], COMBATTING DENIALS U; Arbabshirani MR, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-017-0015-z; At RadNet, HLTHCARE IT NEWS; Bairstow PJ, 2010, INT J QUAL HEALTH C, V22, P194, DOI 10.1093/intqhc/mzq016; Balakrishnan G, 2019, IEEE T MED IMAGING, V38, P1788, DOI 10.1109/TMI.2019.2897538; Banerjee I, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.8719; Banerjee Imon, 2018, AMIA Annu Symp Proc, V2018, P215; Barnard R, 2019, ACAD RADIOL, V26, P1686, DOI 10.1016/j.acra.2019.06.017; Bash S, 2020, APPL RADIOL, V49, P20; Bermudez C, 2018, PROC SPIE, V10574, DOI 10.1117/12.2293515; Bernardy Mark, 2009, J Am Coll Radiol, V6, P844, DOI 10.1016/j.jacr.2009.08.003; Bhargavan M, 2009, RADIOLOGY, V252, P458, DOI 10.1148/radiol.2522081895; Blackmore CC, 2011, J AM COLL RADIOL, V8, P19, DOI 10.1016/j.jacr.2010.07.009; Boland GWL, 2009, EUR RADIOL, V19, P9, DOI 10.1007/s00330-008-1159-7; Booij R, 2019, EUR RADIOL, V29, P2079, DOI 10.1007/s00330-018-5745-z; Brown AD, 2017, ACAD RADIOL, V24, P160, DOI 10.1016/j.acra.2016.09.013; Cai TR, 2016, RADIOGRAPHICS, V36, P176, DOI 10.1148/rg.2016150080; Cannavale A, 2013, RADIOL RES PRACT, V2013, DOI 10.1155/2013/219259; Cao XH, 2018, LECT NOTES COMPUT SC, V11046, P55, DOI 10.1007/978-3-030-00919-9_7; Carrodeguas E, 2019, J AM COLL RADIOL, V16, P336, DOI 10.1016/j.jacr.2018.10.020; Centers for Medicare & Medicaid Services, MED PROGR REV PAYM P; Chan LL, 2020, KIDNEY INT, V97, P383, DOI 10.1016/j.kint.2019.10.023; Chen H, 2017, IEEE T MED IMAGING, V36, P2524, DOI 10.1109/TMI.2017.2715284; Chetlen AL, 2019, ACAD RADIOL, V26, P526, DOI 10.1016/j.acra.2018.07.001; Chong LR, 2020, AM J ROENTGENOL, V215, P1155, DOI 10.2214/AJR.19.22594; Cochon LR, 2019, RADIOLOGY, V291, P700, DOI 10.1148/radiol.2019182826; Delfim RLC, 2017, ARCH ENDOCRIN METAB, V61, P211, DOI 10.1590/2359-3997000000262; Daiki Tamada, 2020, Arxiv, DOI arXiv:2002.12889; Das A, 2019, COGN SYST RES, V54, P165, DOI 10.1016/j.cogsys.2018.12.009; Denck J, 2019, J DIGIT IMAGING, V32, P1103, DOI 10.1007/s10278-019-00241-z; Do BH, 2013, J DIGIT IMAGING, V26, P709, DOI 10.1007/s10278-012-9531-1; Do HM, 2020, ACAD RADIOL, V27, P96, DOI 10.1016/j.acra.2019.09.014; Doyle J, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0213373; Dunnick N Reed, 2005, J Am Coll Radiol, V2, P401, DOI 10.1016/j.jacr.2004.12.008; Duszak R, 2012, J AM COLL RADIOL, V9, P403, DOI 10.1016/j.jacr.2012.01.006; Dutta S, 2013, ANN EMERG MED, V62, P162, DOI 10.1016/j.annemergmed.2013.02.001; Eberhard M, 2020, J THORAC IMAG, V35, pS17, DOI 10.1097/RTI.0000000000000482; Esses SJ, 2018, J MAGN RESON IMAGING, V47, P723, DOI 10.1002/jmri.25779; Forsberg D, 2017, J DIGIT IMAGING, V30, P86, DOI 10.1007/s10278-016-9911-z; Gamechi ZS, 2019, EUR RADIOL, V29, P4613, DOI 10.1007/s00330-018-5931-z; Ginat DT, 2020, NEURORADIOLOGY, V62, P335, DOI 10.1007/s00234-019-02330-w; Goldberg-Stein S, 2019, J AM COLL RADIOL, V16, P1292, DOI 10.1016/j.jacr.2019.05.042; Golding LP, 2019, J AM COLL RADIOL, V16, P1357, DOI 10.1016/j.jacr.2019.05.004; Gong E, 2018, J MAGN RESON IMAGING, V48, P330, DOI 10.1002/jmri.25970; Hammer MM, 2019, AM J ROENTGENOL, V212, P1077, DOI 10.2214/AJR.18.20692; Haskins G, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01060-x; Hassanpour S, 2016, ARTIF INTELL MED, V66, P29, DOI 10.1016/j.artmed.2015.09.007; Hendee WR, 2010, RADIOLOGY, V257, P240, DOI 10.1148/radiol.10100063; Higaki T, 2019, JPN J RADIOL, V37, P73, DOI 10.1007/s11604-018-0796-2; Huang SC, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0266-y; Ip IK, 2013, AM J MED, V126, P687, DOI 10.1016/j.amjmed.2012.11.034; Ironside N, 2019, STROKE, V50, P3416, DOI 10.1161/STROKEAHA.119.026561; Jayannathan V, 2009, INT J MED INFORM, V78, P284, DOI 10.1016/j.ijmedinf.2008.08.006; Jha S, 2020, ACAD RADIOL, V27, P153, DOI 10.1016/j.acra.2019.11.002; Jin KH, 2017, IEEE T IMAGE PROCESS, V26, P4509, DOI 10.1109/TIP.2017.2713099; Jiwani A, 2014, BMC HEALTH SERV RES, V14, DOI 10.1186/s12913-014-0556-7; Jose V. Manjon, 2019, Arxiv, DOI arXiv:1911.04798; Jungmann F, 2020, J DIGIT IMAGING, V33, P1026, DOI 10.1007/s10278-020-00342-0; Kalra A, 2020, J AM COLL RADIOL, V17, P1149, DOI 10.1016/j.jacr.2020.03.012; Kamel PI, 2018, J DIGIT IMAGING, V31, P327, DOI 10.1007/s10278-018-0087-6; Kang SK, 2019, J AM COLL RADIOL, V16, P1587, DOI 10.1016/j.jacr.2019.04.026; Katsari K, 2021, EJNMMI PHYS, V8, DOI 10.1186/s40658-021-00374-7; Khanna R, 2014, NEUROHOSPITALIST, V4, P26, DOI 10.1177/1941874413495701; Klink T, 2014, EUR J RADIOL, V83, P1645, DOI 10.1016/j.ejrad.2014.05.033; Kurasawa Hisashi, 2016, J Diabetes Sci Technol, V10, P730, DOI 10.1177/1932296815614866; Lakhani P, 2018, J AM COLL RADIOL, V15, P350, DOI 10.1016/j.jacr.2017.09.044; Lakhani P, 2012, J DIGIT IMAGING, V25, P30, DOI 10.1007/s10278-011-9426-6; Lakhani P, 2010, J DIGIT IMAGING, V23, P647, DOI 10.1007/s10278-009-9237-1; Lauritsch G, 1998, P SOC PHOTO-OPT INS, V3338, P1127, DOI 10.1117/12.310839; Le V, 2020, J NUCL MED, V61; Lee SJ, 2020, J DIGIT IMAGING, V33, P1393, DOI 10.1007/s10278-020-00350-0; Lee YH, 2018, J DIGIT IMAGING, V31, P604, DOI 10.1007/s10278-018-0066-y; Lehnert BE, 2010, J AM COLL RADIOL, V7, P192, DOI 10.1016/j.jacr.2009.11.010; Levine Wilton C, 2015, Anesthesiol Clin, V33, P697, DOI 10.1016/j.anclin.2015.07.006; Li YK, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62922-y; Lin YW, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0218942; Loria K., 2020, RADIOLOGY TODAY MAGA, V21, P10; Lou R, 2020, J DIGIT IMAGING, V33, P131, DOI 10.1007/s10278-019-00271-7; Lundervold AS, 2019, Z MED PHYS, V29, P102, DOI 10.1016/j.zemedi.2018.11.002; Luo L, 2019, HEALTH CARE MANAG SC, V22, P68, DOI 10.1007/s10729-017-9421-7; Majid AS, 2003, RADIOGRAPHICS, V23, P881, DOI 10.1148/rg.234025083; Meng X, 2019, J BIOMED INFORM, V93, DOI 10.1016/j.jbi.2019.103169; Mieloszyk RJ, 2019, J AM COLL RADIOL, V16, P554, DOI 10.1016/j.jacr.2018.12.046; Mitchell DG, 2015, HEPATOLOGY, V61, P1056, DOI 10.1002/hep.27304; Mohamed AA, 2018, MED PHYS, V45, P314, DOI 10.1002/mp.12683; Nelson A, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0103-3; Neri E, 2019, INSIGHTS IMAGING, V10, DOI 10.1186/s13244-019-0738-2; Oliveira L, 2015, STUD HEALTH TECHNOL, V216, P1028, DOI 10.3233/978-1-61499-564-7-1028; Orsie D?, 2013, ACR BI RADS ATLAS; Ouyang JH, 2019, MED PHYS, V46, P3555, DOI 10.1002/mp.13626; Pham AD, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-266; Pines JM, 2015, ACAD EMERG MED, V22, P985, DOI 10.1111/acem.12716; Pons E, 2016, RADIOLOGY, V279, P329, DOI 10.1148/radiol.16142770; Potter CA, 2019, RADIOGRAPHICS, V39, P1717, DOI 10.1148/rg.2019190142; Prevedello LM, 2017, RADIOLOGY, V285, P923, DOI 10.1148/radiol.2017162664; Rajendran Suraj, 2020, AMIA Jt Summits Transl Sci Proc, V2020, P507; Rasmy L, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00455-y; Richardson ML, 2021, ACAD RADIOL, V28, P1225, DOI 10.1016/j.acra.2020.01.012; Rubin DL, 2017, RADIOLOGY, V283, P836, DOI 10.1148/radiol.2016161553; Saha A, 2019, J MAGN RESON IMAGING, V50, P456, DOI 10.1002/jmri.26636; Saltybaeva N, 2018, INVEST RADIOL, V53, P641, DOI 10.1097/RLI.0000000000000482; Saltybaeva N, 2017, MED PHYS, V44, P5697, DOI 10.1002/mp.12519; Sanborn BJ., HEALTHCARE FINANCE N; Schofield R, 2020, J CARDIOVASC COMPUT, V14, P219, DOI 10.1016/j.jcct.2019.04.008; Shan HM, 2019, NAT MACH INTELL, V1, P269, DOI 10.1038/s42256-019-0057-9; Singh S, 2010, RADIOLOGY, V257, P373, DOI 10.1148/radiol.10092212; Sreekumari A, 2019, AM J NEURORADIOL, V40, P217, DOI 10.3174/ajnr.A5926; Stern RG, 2013, AM J MED, V126, P657, DOI 10.1016/j.amjmed.2013.03.011; Syed AB, 2018, SEMIN MUSCULOSKEL R, V22, P540, DOI 10.1055/s-0038-1673383; Taira RK, 2001, RADIOGRAPHICS, V21, P237, DOI 10.1148/radiographics.21.1.g01ja18237; Tajmir SH, 2018, ACAD RADIOL, V25, P747, DOI 10.1016/j.acra.2018.03.007; Tanenbaum L, 2018, P AM SOC NEURORADIOL; Taplin SH, 2002, AM J ROENTGENOL, V178, P797, DOI 10.2214/ajr.178.4.1780797; The Joint Commission, NAT PAT SAF GOALS EF; Trivedi H, 2018, J DIGIT IMAGING, V31, P245, DOI 10.1007/s10278-017-0021-3; U.S. Food and Drug Administration, MAMMOGRAPHY QUALITY; Wang L, 2020, P AM SOC NEURORADIOL; Wang Y, 2018, NEUROIMAGE, V174, P550, DOI 10.1016/j.neuroimage.2018.03.045; Wei DM, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101763; Wildman-Tobriner B, 2019, RADIOLOGY, V292, P112, DOI 10.1148/radiol.2019182128; Winkel DJ, 2019, INVEST RADIOL, V54, P55, DOI 10.1097/RLI.0000000000000509; Wismuller A, 2020, P SPIE MEDICAL IMAGI; Xu J., 2017, ARXIV; Yan ZH, 2017, RADIOLOGY, V282, P717, DOI 10.1148/radiol.2016151985; Yong PL., 2010, HEALTHCARE IMPERATIV; Zhang EL, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/ab7e7d; Zhang HM, 2020, J OPER RES SOC CHINA, V8, P311, DOI 10.1007/s40305-019-00287-4; Zhang JY, 2020, ACAD RADIOL, V27, P780, DOI 10.1016/j.acra.2019.07.028; Zhu B, 2018, NATURE, V555, P487, DOI 10.1038/nature25988; Zimmerman SL, 2011, RADIOGRAPHICS, V31, P881, DOI 10.1148/rg.313105195	137	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2022	4	2							e210114	10.1148/ryai.210114	http://dx.doi.org/10.1148/ryai.210114			12	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9YB	35391770	Green Published			2022-12-18	WOS:000826922700007
J	Ueda, D; Ehara, S; Yamamoto, A; Iwata, S; Abo, K; Walston, SL; Matsumoto, T; Shimazaki, A; Yoshiyama, M; Miki, Y				Ueda, Daiju; Ehara, Shoichi; Yamamoto, Akira; Iwata, Shinichi; Abo, Koji; Walston, Shannon L.; Matsumoto, Toshimasa; Shimazaki, Akitoshi; Yoshiyama, Minoru; Miki, Yukio			Development and Validation of Artificial Intelligence-based Method for Diagnosis of Mitral Regurgitation from Chest Radiographs	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Computer-aided Diagnosis (CAD); Cardiac; Heart; Valves; Supervised Learning; Convolutional Neural Network (CNN); Deep Learning Algorithms; Machine Learning Algorithms	CARDIAC AUSCULTATORY SKILLS; VALVULAR HEART-DISEASE; RECOMMENDATIONS; ASSOCIATION	Purpose: To develop an artificial intelligence-based model to detect mitral regurgitation on chest radiographs. Materials and Methods: This retrospective study included echocardiographs and associated chest radiographs consecutively collected at a single institution between July 2016 and May 2019. Associated radiographs were those obtained within 30 days of echocardiography. These radiographs were labeled as positive or negative for mitral regurgitation on the basis of the echocardiographic reports and were divided into training, validation, and test datasets. An artificial intelligence model was developed by using the training dataset and was tuned by using the validation dataset. To evaluate the model, the area under the curve, sensitivity, specificity, accuracy, positive predictive value, and negative predictive value were assessed by using the test dataset. Results: This study included a total of 10 367 images from 5270 patients. The training dataset included 8240 images (4216 patients), the validation dataset included 1073 images (527 patients), and the test dataset included 1054 images (527 patients). The area under the curve, sensitivity, specificity, accuracy, positive predictive value, and negative predictive value in the test dataset were 0.80 (95% CI: 0.77, 0.82), 71% (95% CI: 67, 75), 74% (95% CI: 70, 77), 73% (95% CI: 70, 75), 68% (95% CI: 64, 72), and 77% (95% CI: 73, 80), respectively. Conclusion: The developed deep learning-based artificial intelligence model may possibly differentiate patients with and without mitral regurgitation by using chest radiographs. (C)RSNA, 2022	[Ueda, Daiju; Yamamoto, Akira; Walston, Shannon L.; Matsumoto, Toshimasa; Shimazaki, Akitoshi; Miki, Yukio] Osaka City Univ, Grad Sch Med, Dept Diagnost & Intervent Radiol, Abeno Ku, 1-4-3 Asahi Machi, Osaka 5458585, Japan; [Ehara, Shoichi; Iwata, Shinichi; Yoshiyama, Minoru] Osaka City Univ, Grad Sch Med, Dept Cardiovasc Med, Abeno Ku, 1-4-3 Asahi Machi, Osaka 5458585, Japan; [Abo, Koji] Osaka City Univ Hosp, Cent Clin Lab, Osaka, Japan	Osaka Metropolitan University; Osaka Metropolitan University; Osaka Metropolitan University	Ueda, D (corresponding author), Osaka City Univ, Grad Sch Med, Dept Diagnost & Intervent Radiol, Abeno Ku, 1-4-3 Asahi Machi, Osaka 5458585, Japan.	ai.labo.ocu@gmail.com	Walston, Shannon/GQP-8928-2022	Matsumoto, Toshimasa/0000-0002-8527-1795; Miki, Yukio/0000-0003-0621-0044; Iwata, Shinichi/0000-0003-3607-8937; Yamamoto, Akira/0000-0002-4567-9745; Walston, Shannon/0000-0002-7268-8313	Japan Society for the Promotion of Science [JP20K16769]	Japan Society for the Promotion of Science(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of Science)	Supported in part by the Japan Society for the Promotion of Science (KAKENHI grant JP20K16769).	[Anonymous], XP MR; Avierinos JF, 2002, CIRCULATION, V106, P1355, DOI 10.1161/01.CIR.0000028933.34260.09; CARPENTIER A, 1983, J THORAC CARDIOV SUR, V86, P323; Enriquez-Sarano M, 2005, NEW ENGL J MED, V352, P875, DOI 10.1056/NEJMoa041451; Enriquez-Sarano M, 2009, LANCET, V373, P1382, DOI 10.1016/S0140-6736(09)60692-9; Etchells E, 1997, JAMA-J AM MED ASSOC, V277, P564, DOI 10.1001/jama.277.7.564; GAHL K, 1977, BRIT HEART J, V39, P13; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Higgins, 2010, THORACIC IMAGING PUL; Hinton G, 2018, JAMA-J AM MED ASSOC, V320, P1101, DOI 10.1001/jama.2018.11100; Iung B, 2003, EUR HEART J, V24, P1231, DOI 10.1016/S0195-668X(03)00201-X; Lang RM, 2015, EUR HEART J-CARD IMG, V16, P233, DOI 10.1093/ehjci/jev014; LeCun Y., 2015, NATURE, V521, P436, DOI DOI 10.1038/NATURE14539; Mangione S, 2001, AM J MED, V110, P210, DOI 10.1016/S0002-9343(00)00673-2; Mangione S, 1997, JAMA-J AM MED ASSOC, V278, P717, DOI 10.1001/jama.278.9.717; Nishimura RA, 2017, CIRCULATION, V135, pE1159, DOI 10.1161/CIR.0000000000000503; Nishimura RA, 2014, CIRCULATION, V129, P2440, DOI 10.1161/CIR.0000000000000029; Nkomo VT, 2006, LANCET, V368, P1005, DOI 10.1016/S0140-6736(06)69208-8; Otto CM, 2014, NEW ENGL J MED, V371, P744, DOI 10.1056/NEJMra1313875; R. Core Team, 2019, R LANG ENV STAT COMP; Salmi LR, 2016, MAYO CLIN PROC, V91, P1594, DOI 10.1016/j.mayocp.2016.07.017; Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI 10.1007/s11263-019-01228-7; TensorFlow, US; Woolley K, 1999, RADIOGRAPHICS, V19, P965, DOI 10.1148/radiographics.19.4.g99jl10965; Zoghbi WA, 2003, J AM SOC ECHOCARDIOG, V16, P777, DOI 10.1016/S0894-7317(03)00335-3	25	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2022	4	2							e210221	10.1148/ryai.210221	http://dx.doi.org/10.1148/ryai.210221			7	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9YB	35391769	Green Published			2022-12-18	WOS:000826922700016
J	Vagal, A; Saba, L				Vagal, Achala; Saba, Luca			Artificial Intelligence in "Code Stroke"- A Paradigm Shift: Do Radiologists Need to Change Their Practice?	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material							ISCHEMIC-STROKE; ENDOVASCULAR THERAPY; THROMBECTOMY; CLINICIAN; HEALTH		[Vagal, Achala] Univ Cincinnati, Med Ctr, Deparunent Radiol, Cincinnati, OH 45267 USA; [Saba, Luca] Univ Cagliari, Dept Diagnost Imaging & Radiol, Cagliari, Italy	University System of Ohio; University of Cincinnati; University of Cagliari	Vagal, A (corresponding author), Univ Cincinnati, Med Ctr, Deparunent Radiol, Cincinnati, OH 45267 USA.	vagala@ucmail.uc.edu		Vagal, Achala/0000-0001-6428-6499				Adhya J, 2021, NEURORADIOL J, V34, P476, DOI 10.1177/19714009211012353; Al-Kawaz M, 2022, J NEUROINTERV SURG, V14, P233, DOI 10.1136/neurintsurg-2021-017365; Albers GW, 2018, NEW ENGL J MED, V378, P708, DOI 10.1056/NEJMoa1713973; [Anonymous], VIZ AI; Barber PA, 2000, LANCET, V355, P1670, DOI 10.1016/S0140-6736(00)02237-6; Berkhemer OA, 2015, NEW ENGL J MED, V372, P11, DOI 10.1056/NEJMoa1411587; Bouslama M, 2021, STROKE, V52, P634, DOI 10.1161/STROKEAHA.120.031651; Brainarray, US; Campbell BCV, 2015, NEW ENGL J MED, V372, P1009, DOI 10.1056/NEJMoa1414792; Chatterjee ASN., 2019, STROKE, V50; Elijovich L, 2022, J NEUROINTERV SURG, V14, P704, DOI 10.1136/neurintsurg-2021-017714; Fatahi N, 2019, J MULTIDISCIP HEALTH, V12, P555, DOI 10.2147/JMDH.S207649; Friedberg E, 2018, J AM COLL RADIOL, V15, P1158, DOI 10.1016/j.jacr.2018.05.016; Geuskens RREG, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0141571; Goyal M, 2015, NEW ENGL J MED, V372, P1019, DOI 10.1056/NEJMoa1414905; Guberina N, 2018, NEURORADIOLOGY, V60, P889, DOI 10.1007/s00234-018-2066-5; Gunderman RB, 2016, RADIOLOGY, V281, P6, DOI 10.1148/radiol.2016152781; Hassan AE, 2021, J NEUROINTERV SURG, V13, P406, DOI 10.1136/neurintsurg-2020-016897; Hassan AE, 2020, INTERV NEURORADIOL, V26, P615, DOI 10.1177/1591019920953055; Hill MD, 1998, LANCET, V352, pSIII10; Jovin TG, 2015, NEW ENGL J MED, V372, P2296, DOI 10.1056/NEJMoa1503780; Kohli A, 2018, J AM COLL RADIOL, V15, P535, DOI 10.1016/j.jacr.2017.12.029; Kunz WG, 2020, NEUROLOGY, V95, pE2465, DOI 10.1212/WNL.0000000000010867; Liebeskind DS, 2018, EBIOMEDICINE, V35, P14, DOI 10.1016/j.ebiom.2018.08.031; Maegerlein C, 2019, RADIOLOGY, V291, P140, DOI 10.1148/radiol.2019181228; Meretoja A, 2017, NEUROLOGY, V88, P2123, DOI 10.1212/WNL.0000000000003981; Morey JR, 2021, CEREBROVASC DIS, V50, P450, DOI 10.1159/000515320; Nagel S, 2017, INT J STROKE, V12, P615, DOI 10.1177/1747493016681020; Nicholas E., 2016, LANCET NEUROL, V18, P88; Nogueira RG, 2018, NEW ENGL J MED, V378, P11, DOI 10.1056/NEJMoa1706442; Oakden-Rayner L, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180089; Powers WJ, 2018, STROKE, V49, pE46, DOI 10.1161/STR.0000000000000158; RAPIDAI, PUSH BOUND STROK PAT; Ratner M, 2018, NAT BIOTECHNOL, V36, P673, DOI 10.1038/nbt0818-673a; Saver JL, 2015, NEW ENGL J MED, V372, P2285, DOI 10.1056/NEJMoa1415061; Soun JE, 2021, AM J NEURORADIOL, V42, P2, DOI 10.3174/ajnr.A6883; Vagal A, 2019, NEUROLOGY, V93, P888, DOI 10.1212/WNL.0000000000008481; van Leeuwen KG, 2021, INSIGHTS IMAGING, V12, DOI 10.1186/s13244-021-01077-4; Voter AF, 2021, AM J NEURORADIOL, V42, P1550, DOI 10.3174/ajnr.A7179; Weikert T, 2020, EUR RADIOL, V30, P6545, DOI 10.1007/s00330-020-06998-0	40	0	0	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2022	4	2							e210204	10.1148/ryai.210204	http://dx.doi.org/10.1148/ryai.210204			3	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9YB	35391761	Green Published			2022-12-18	WOS:000826922700014
J	Yamashita, R; Bird, K; Cheung, PYC; Decker, JH; Flory, MN; Goff, D; Morimoto, LN; Shon, A; Wentland, AL; Rubin, DL; Desser, TS				Yamashita, Rikiya; Bird, Kristen; Cheung, Philip Yue-Cheng; Decker, Johannes Hugo; Flory, Marta Nicole; Goff, Daniel; Morimoto, Linda Nayeli; Shon, Andy; Wentland, Andrew Louis; Rubin, Daniel L.; Desser, Terry S.			Automated Identification and Measurement Extraction of Pancreatic Cystic Lesions from Free-Text Radiology Reports Using Natural Language Processing	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Informatics; Abdomen/GI; Pancreas; Cysts; Computer ApplicationsGeneral (Informatics); Named Entity Recognition	PREVALENCE; MANAGEMENT	Purpose: To automatically identify a cohort of patients with pancreatic cystic lesions (PCLs) and extract PCL measurements from historical CT and MRI reports using natural language processing (NLP) and a question answering system. Materials and Methods: Institutional review board approval was obtained for this retrospective Health Insurance Portability and Accountability Act-compliant study, and the requirement to obtain informed consent was waived. A cohort of free-text CT and MRI reports generated between January 1991 and July 2019 that covered the pancreatic region were identified. A PCL identification model was developed by modifying a rule-based information extraction model; measurement extraction was performed using a state-of-the-art question answering system. The system's performance was evaluated against radiologists' annotations. Results: For this study, 430 426 free-text radiology reports from 199 783 unique patients were identified. The NLP model for identifying PCL was applied to 1000 test samples. The interobserver agreement between the model and two radiologists was almost perfect (Fleiss k = 0.951), and the false-positive rate and true-positive rate were 3.0% and 98.2%, respectively, against consensus of radiologists' annotations as ground truths. The overall accuracy and Lin concordance correlation coefficient for measurement extraction were 0.958 and 0.874, respectively, against radiologists' annotations as ground truths. Conclusion: An NLP-based system was developed that identifies patients with PCLs and extracts measurements from a large single-institution archive of free-text radiology reports. This approach may prove valuable to study the natural history and potential risks of PCLs and can be applied to many other use cases. (C)RSNA, 2022	[Yamashita, Rikiya; Rubin, Daniel L.] Stanford Univ, Sch Med, Dept Biomed Data Sci, 300 Pasteur Dr, Stanford, CA 94305 USA; [Bird, Kristen; Cheung, Philip Yue-Cheng; Decker, Johannes Hugo; Flory, Marta Nicole; Goff, Daniel; Morimoto, Linda Nayeli; Shon, Andy; Wentland, Andrew Louis; Rubin, Daniel L.; Desser, Terry S.] Stanford Univ, Sch Med, Dept Radiol, 300 Pasteur Dr, Stanford, CA 94305 USA	Stanford University; Stanford University	Desser, TS (corresponding author), Stanford Univ, Sch Med, Dept Radiol, 300 Pasteur Dr, Stanford, CA 94305 USA.	tsdesser@stanford.edu	; Rubin, Daniel/E-3740-2010	Goff, Daniel/0000-0003-2109-1696; Decker, Johannes/0000-0002-4143-2673; Wentland, Andrew/0000-0003-1736-8218; Rubin, Daniel/0000-0001-5057-4369				Alex Beatrice, 2007, P WORKSH BIONLP 2007, P65, DOI DOI 10.3115/1572392.1572404; Andrew Y. Ng, 2019, Arxiv, DOI arXiv:1901.07031; Bozkurt S, 2019, J DIGIT IMAGING, V32, P544, DOI 10.1007/s10278-019-00237-9; Dadas S, 2020, IEEE ACCESS, V8, P135091, DOI 10.1109/ACCESS.2020.3011598; de Jong K, 2010, CLIN GASTROENTEROL H, V8, P806, DOI 10.1016/j.cgh.2010.05.017; Eduard Hovy, 2020, Arxiv, DOI arXiv:1909.02250; Gardner TB, 2013, AM J GASTROENTEROL, V108, P1546, DOI 10.1038/ajg.2013.103; Ip IK, 2011, RADIOLOGY, V259, P136, DOI 10.1148/radiol.10100970; Jacob Devlin, 2019, Arxiv, DOI arXiv:1810.04805; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; LIN LI, 1989, BIOMETRICS, V45, P255, DOI 10.2307/2532051; Lu Wei, 2015, P 2015 C EMP METH NA, P857, DOI DOI 10.18653/V1/D15; McErlean A, 2013, RADIOLOGY, V269, P450, DOI 10.1148/radiol.13122665; Megibow AJ, 2017, J AM COLL RADIOL, V14, P911, DOI 10.1016/j.jacr.2017.03.010; Moayyedi P, 2015, GASTROENTEROLOGY, V148, P692, DOI 10.1053/j.gastro.2015.02.035; Pandey P, 2019, RADIOLOGY, V292, P647, DOI 10.1148/radiol.2019181686; Percy Liang, 2018, Arxiv, DOI arXiv:1806.03822; Roch AM, 2015, HPB, V17, P447, DOI 10.1111/hpb.12375; Sevenster M, 2015, APPL CLIN INFORM, V6, P600, DOI 10.4338/ACI-2014-11-RA-0110; Vaswani A., 2017, ARXIV, DOI DOI 10.48550/ARXIV.1706.03762; Wolf Thomas, 2019, ARXIV, DOI DOI 10.48550/ARXIV.1910.03771; Xie FG, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0236817; Zhang XM, 2002, RADIOLOGY, V223, P547, DOI 10.1148/radiol.2232010815	24	0	0	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2022	4	2							e210092	10.1148/ryai.210092	http://dx.doi.org/10.1148/ryai.210092			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9YB	35391762	Green Published			2022-12-18	WOS:000826922700004
J	Hasenstab, KA; Tabalon, J; Yuan, N; Retson, T; Hsiao, A				Hasenstab, Kyle A.; Tabalon, Joseph; Yuan, Nancy; Retson, Tara; Hsiao, Albert			CNN-based Deformable Registration Facilitates Fast and Accurate Air Trapping Measurements at Inspiratory and Expiratory CT (Jan, 10.1148/ryai.219003, 2022)	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Correction															National Institutes of Health [T32 EB005970]; RSNA [RR1879]; National Heart, Lung, and Blood Institute [U01 HL089897, U01 HL089856]; COPD Foundation; AstraZeneca; Bayer Pharmaceuticals; Boehringer-Ingelheim; Genentech; GlaxoSmithKline; Novartis; Pfizer; Sunovion	National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); RSNA; National Heart, Lung, and Blood Institute(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Heart Lung & Blood Institute (NHLBI)); COPD Foundation; AstraZeneca(AstraZeneca); Bayer Pharmaceuticals(Bayer AG); Boehringer-Ingelheim(Boehringer Ingelheim); Genentech(Roche HoldingGenentech); GlaxoSmithKline(GlaxoSmithKline); Novartis(Novartis); Pfizer(Pfizer); Sunovion	The funding information should read: Training support for T.R. by the National Institutes of Health (T32 EB005970), RSNA (RR1879), and the Friedman Family Endowed Radiology Fellowship. Training support for N.Y. by the U.S. National Library of Medicine. The project described was supported by Award Number U01 HL089897 and Award Number U01 HL089856 from the National Heart, Lung, and Blood Institute. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Heart, Lung, and Blood Institute or the National Institutes of Health. COPD Foundation Funding: COPDGene is also supported by the COPD Foundation through contributions made to an Industry Advisory Board that has included AstraZeneca, Bayer Pharmaceuticals, Boehringer-Ingelheim, Genentech, GlaxoSmithKline, Novartis, Pfizer, and Sunovion.	Hasenstab Kyle A, 2022, Radiol Artif Intell, V4, pe219003, DOI 10.1148/ryai.219003	1	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2022	4	1												1	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9WA					2022-12-18	WOS:000826917400011
J	Hasenstab, KA; Tabalon, J; Yuan, N; Retson, T; Hsiao, A				Hasenstab, Kyle A.; Tabalon, Joseph; Yuan, Nancy; Retson, Tara; Hsiao, Albert			CNN-based Deformable Registration Facilitates Fast and Accurate Air Trapping Measurements at Inspiratory and Expiratory CT (10.1148/ryai.2021210211)	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Correction															National Institutes of Health [T32 EB005970]; RSNA [RR1879]; National Heart, Lung, and Blood Institute [U01 HL089897, U01 HL089856]; COPD Foundation; AstraZeneca; Bayer Pharmaceuticals; Boehringer-Ingelheim; Genentech; GlaxoSmithKline; Novartis; Pfizer; Sunovion	National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); RSNA; National Heart, Lung, and Blood Institute(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Heart Lung & Blood Institute (NHLBI)); COPD Foundation; AstraZeneca(AstraZeneca); Bayer Pharmaceuticals(Bayer AG); Boehringer-Ingelheim(Boehringer Ingelheim); Genentech(Roche HoldingGenentech); GlaxoSmithKline(GlaxoSmithKline); Novartis(Novartis); Pfizer(Pfizer); Sunovion	The funding information should read: Training support for T.R. by the National Institutes of Health (T32 EB005970), RSNA (RR1879), and the Friedman Family Endowed Radiology Fellowship. Training support for N.Y. by the U.S. National Library of Medicine. The project described was supported by Award Number U01 HL089897 and Award Number U01 HL089856 from the National Heart, Lung, and Blood Institute. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Heart, Lung, and Blood Institute or the National Institutes of Health. COPD Foundation Funding: COPDGene is also supported by the COPD Foundation through contributions made to an Industry Advisory Board that has included AstraZeneca, Bayer Pharmaceuticals, Boehringer-Ingelheim, Genentech, GlaxoSmithKline, Novartis, Pfizer, and Sunovion.	Hasenstab KA, 2022, RADIOL-ARTIF INTELL, V4, DOI 10.1148/ryai.2021210211	1	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2022	4	1								10.1148/ryai.219003	http://dx.doi.org/10.1148/ryai.219003			1	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9WA		Green Published			2022-12-18	WOS:000826917400005
J	Savadjiev, P; Gallix, B; Rezanejad, M; Bhatnagar, S; Semionov, A; Siddiqi, K; Forghani, R; Reinhold, C; Eidelman, DH; Dandurand, RJ				Savadjiev, Peter; Gallix, Benoit; Rezanejad, Morteza; Bhatnagar, Sahir; Semionov, Alexandre; Siddiqi, Kaleem; Forghani, Reza; Reinhold, Caroline; Eidelman, David H.; Dandurand, Ronald J.			Improved Detection of Chronic Obstructive Pulmonary Disease at Chest CT Using the Mean Curvature of Isophotes	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							SCALE-SPACE; SMOKERS; COPD; MANAGEMENT; DIAGNOSIS	Purpose: To determine if the mean curvature of isophotes (MCI), a standard computer vision technique, can be used to improve detection of chronic obstructive pulmonary disease (COPD) at chest CT. Materials and Methods: In this retrospective study, chest CT scans were obtained in 243 patients with COPD and 31 controls (among all 274: 151 women [mean age, 70 years; range, 44-90 years] and 123 men [mean age, 71 years; range, 29-90 years]) from two community practices between 2006 and 2019. A convolutional neural network (CNN) architecture was trained on either CT images or CT images transformed through the MCI algorithm. Separately, a linear classification based on a single feature derived from the MCI computation (called hMCI1) was also evaluated. All three models were evaluated with cross-validation, using precision-macro and recallmacro metrics, that is, the mean of per-class precision and recall values, respectively (the latter being equivalent to balanced accuracy). Results: Linear classification based on hMCI1 resulted in a higher recall-macro relative to the CNN trained and applied on CT images (0.85 [95% CI: 0.84, 0.86] vs 0.77 [95% CI: 0.75, 0.79]) but with a similar reduction in precision-macro (0.66 [95% CI: 0.65, 0.67] vs 0.77 [95% CI: 0.75, 0.79]). The CNN model trained and applied on MCI-transformed images had a higher recall-macro (0.85 [95% CI: 0.83, 0.87] vs 0.77 [95% CI: 0.75, 0.79]) and precision-macro (0.85 [95% CI: 0.83, 0.87] vs 0.77 [95% CI: 0.75, 0.79]) relative to the CNN trained and applied on CT images. Conclusion: The MCI algorithm may be valuable toward the automated detection and diagnosis of COPD on chest CT scans as part of a CNN-based pipeline or with stand-alone features. (C)RSNA, 2022	[Savadjiev, Peter; Bhatnagar, Sahir; Semionov, Alexandre; Forghani, Reza; Reinhold, Caroline] McGill Univ, Hlth Ctr, Dept Diagnost Radiol, 1001 Decarie Blvd, Montreal, PQ H4A 3J1, Canada; [Forghani, Reza; Reinhold, Caroline; Eidelman, David H.; Dandurand, Ronald J.] McGill Univ, Hlth Ctr, Res Inst, 1001 Decarie Blvd, Montreal, PQ H4A 3J1, Canada; [Eidelman, David H.; Dandurand, Ronald J.] McGill Univ, Hlth Ctr, Res Inst, Meakins Christie Labs, 1001 Decarie Blvd, Montreal, PQ H4A 3J1, Canada; [Dandurand, Ronald J.] McGill Univ, Hlth Ctr, Res Inst, Ctr Innovat Med, 1001 Decarie Blvd, Montreal, PQ H4A 3J1, Canada; [Dandurand, Ronald J.] McGill Univ, Hlth Ctr, Montreal Chest Inst, 1001 Decarie Blvd, Montreal, PQ H4A 3J1, Canada; [Savadjiev, Peter] McGill Univ, Dept Pathol, Montreal, PQ, Canada; [Savadjiev, Peter] McGill Univ, Dept Oncol, Med Phys Unit, Montreal, PQ, Canada; [Savadjiev, Peter; Siddiqi, Kaleem] McGill Univ, Sch Comp Sci, Montreal, PQ, Canada; [Bhatnagar, Sahir] McGill Univ, Segal Canc Ctr, Dept Epidemiol Biostat & Occupat Hlth, Montreal, PQ, Canada; [Forghani, Reza] McGill Univ, Jewish Gen Hosp, Lady Davis Inst Med Res, Montreal, PQ, Canada; [Eidelman, David H.; Dandurand, Ronald J.] McGill Univ, Dept Med, Montreal, PQ, Canada; [Gallix, Benoit] IHU Strasbourg, Inst Chiruigie Guidee & Image, Strasbourg, France; [Rezanejad, Morteza] Univ Toronto, Dept Psychol, Bernhardt Walther Lab, Toronto, ON, Canada; [Dandurand, Ronald J.] Lakeshore Gen Hosp, Pointe Claire, PQ, Canada	McGill University; McGill University; McGill University; McGill University; McGill University; McGill University; McGill University; McGill University; McGill University; Lady Davis Institute; McGill University; McGill University; UDICE-French Research Universities; Universites de Strasbourg Etablissements Associes; Universite de Strasbourg; University of Toronto; McGill University	Savadjiev, P (corresponding author), McGill Univ, Hlth Ctr, Dept Diagnost Radiol, 1001 Decarie Blvd, Montreal, PQ H4A 3J1, Canada.; Savadjiev, P (corresponding author), McGill Univ, Dept Pathol, Montreal, PQ, Canada.; Savadjiev, P (corresponding author), McGill Univ, Dept Oncol, Med Phys Unit, Montreal, PQ, Canada.; Savadjiev, P (corresponding author), McGill Univ, Sch Comp Sci, Montreal, PQ, Canada.	peter.savadjiev@mcgill.ca		Rezanejad, Morteza/0000-0001-8744-8534; Reinhold, Caroline/0000-0002-8852-3273; Savadjiev, Peter/0000-0001-5396-0994; Forghani, Reza/0000-0002-8572-1864; Bhatnagar, Sahir/0000-0001-8956-2509	Natural Sciences and Engineering Research Council of Canada	Natural Sciences and Engineering Research Council of Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)CGIAR)	P.S. supported by a Discovery Grant from the Natural Sciences and Engineering Research Council of Canada.	Agusti A, 2010, RESP RES, V11, DOI 10.1186/1465-9921-11-122; Barnes PJ, 2021, EXPERT REV RESP MED, V15, P27, DOI 10.1080/17476348.2020.1804364; Bourbeau J, 2014, COPD, V11, P125, DOI 10.3109/15412555.2012.665520; Celli BR, 2004, EUR RESPIR J, V23, P932, DOI 10.1183/09031936.04.00014304; Ciompi F, 2017, SCI REP-UK, V7, DOI 10.1038/srep46479; Clough JR, 2019, LECT NOTES COMPUT SC, V11492, P16, DOI 10.1007/978-3-030-20351-1_2; Estepar RSJ, 2013, AM J RESP CRIT CARE, V188, P231, DOI 10.1164/rccm.201301-0162OC; Everitt B.S., 1977, ANAL CONTINGENCY TAB; Gonzalez G, 2018, AM J RESP CRIT CARE, V197, P193, DOI 10.1164/rccm.201705-0860OC; GRIFFIN LD, 1995, IMAGE VISION COMPUT, V13, P543, DOI 10.1016/0262-8856(95)91145-4; Han MLK, 2021, AM J RESP CRIT CARE, V203, P414, DOI 10.1164/rccm.202008-3328PP; Kirby M, 2018, AM J RESP CRIT CARE, V197, P56, DOI 10.1164/rccm.201704-0692OC; Kuijper A, 2004, INT J COMPUT VISION, V57, P67, DOI 10.1023/B:VISI.0000013091.14851.24; QUANJER PH, 1993, EUR RESPIR J, V6, P5, DOI 10.1183/09041950.005s1693; Regan EA, 2015, JAMA INTERN MED, V175, P1539, DOI 10.1001/jamainternmed.2015.2735; Regan EA, 2010, COPD, V7, P32, DOI 10.3109/15412550903499522; Rezanejad Morteza, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P4111, DOI 10.1109/CVPR.2019.00424; Savadjiev P, 2021, AM J RESP CRIT CARE, V203; Shaker SB, 2012, EUR RESPIR J, V40, P1142, DOI 10.1183/09031936.00207911; Tang LYW, 2020, LANCET DIGIT HEALTH, V2, pE259, DOI 10.1016/S2589-7500(20)30064-9; Vasilescu DM, 2019, AM J RESP CRIT CARE, V200, P575, DOI 10.1164/rccm.201811-2083OC; Vogelmeier CF, 2017, AM J RESP CRIT CARE, V195, P557, DOI 10.1164/rccm.201701-0218PP; Walsh SLF, 2018, LANCET RESP MED, V6, P837, DOI 10.1016/S2213-2600(18)30286-8; Wells AU, 2018, EUR RESPIR J, V51, DOI 10.1183/13993003.00692-2018; Woodruff PG, 2016, NEW ENGL J MED, V374, P1811, DOI 10.1056/NEJMoa1505971	26	0	0	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2022	4	1							e210105	10.1148/ryai.210105	http://dx.doi.org/10.1148/ryai.210105			7	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9WA	35146436	Green Published			2022-12-18	WOS:000826917400009
J	Vannier, MW				Vannier, Michael W.			Isophotes, Scale Space, and Invariants in Lung CT for COPD Diagnosis	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Vannier, Michael W.] Univ Chicago, Med Ctr, Dept Radiol, 5841 S Maryland Ave, Chicago, IL 60637 USA	University of Chicago; University of Chicago Medical Center	Vannier, MW (corresponding author), Univ Chicago, Med Ctr, Dept Radiol, 5841 S Maryland Ave, Chicago, IL 60637 USA.	mvannier@uchicago.edu		Vannier, Michael/0000-0001-9898-384X				Lindeberg T., 1994, SCALE SPACE THEORY C; Lodwick G S, 1966, Invest Radiol, V1, P72, DOI 10.1097/00004424-196601000-00032; Romeny BMT, 2011, BIOL MED PHYS BIOMED, P177, DOI 10.1007/978-3-642-15816-2_7; Savadjiev P, 2022, RADIOL ARTIF INTELL, V4; Tang LYW, 2020, LANCET DIGIT HEALTH, V2, pE259, DOI 10.1016/S2589-7500(20)30064-9; van Ginneken B, 2017, RADIOL PHYS TECHNOL, V10, P23, DOI 10.1007/s12194-017-0394-5	7	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2022	4	1							e210301	10.1148/ryai.210301	http://dx.doi.org/10.1148/ryai.210301			2	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9WA	35146438	Green Published			2022-12-18	WOS:000826917400010
J	Dahlblom, V; Andersson, I; Lang, K; Tingberg, A; Zackrisson, S; Dustler, M				Dahlblom, Victor; Andersson, Ingvar; Lang, Kristina; Tingberg, Anders; Zackrisson, Sophia; Dustler, Magnus			Artificial Intelligence Detection of Missed Cancers at Digital Mammography That Were Detected at Digital Breast Tomosynthesis	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Computer-aided Diagnosis; Mammography; Breast; Diagnosis; Classification; Application Domain	COMPUTER-AIDED DETECTION; PERFORMANCE	Purpose: To investigate how an artificial intelligence (AI) system performs at digital mammography (DM) from a screening population with ground truth defined by digital breast tomosynthesis (DBT), and whether AI could detect breast cancers at DM that had originally only been detected at DBT. Materials and Methods: In this secondary analysis of data from a prospective study, DM examinations from 14 768 women (mean age, 57 years), examined with both DM and DBT with independent double reading in the Malm. Breast Tomosynthesis Screening Trial (MBTST) (ClinicalTrials.gov: NCT01091545; data collection, 2010-2015), were analyzed with an AI system. Of 136 screeningdetected cancers, 95 cancers were detected at DM and 41 cancers were detected only at DBT. The system identifies suspicious areas in the image, scored 1-100, and provides a risk score of 1 to 10 for the whole examination. A cancer was defined as AI detected if the cancer lesion was correctly localized and scored at least 62 (threshold determined by the AI system developers), therefore resulting in the highest examination risk score of 10. Data were analyzed with descriptive statistics, and detection performance was analyzed with receiver operating characteristics. Results: The highest examination risk score was assigned to 10% (1493 of 14 786) of the examinations. With 90.8% specificity, the AI system detected 75% (71 of 95) of the DM-detected cancers and 44% (18 of 41) of cancers at DM that had originally been detected only at DBT. The majority were invasive cancers (17 of 18). Conclusion: Almost half of the additional DBT-only screening-detected cancers in the MBTST were detected at DM with AI. AI did not reach double reading performance; however, if combined with double reading, AI has the potential to achieve a substantial portion of the benefit of DBT screening. (C) RSNA, 2021.	[Dahlblom, Victor; Andersson, Ingvar; Lang, Kristina; Zackrisson, Sophia; Dustler, Magnus] Lund Univ, Dept Translat Med, Diagnost Radiol, Malmo, Sweden; [Tingberg, Anders; Dustler, Magnus] Lund Univ, Dept Translat Med, Med Radiat Phys, Malmo, Sweden; [Dahlblom, Victor; Zackrisson, Sophia] Skane Univ Hosp, Dept Med Imaging & Physiol, Carl Bertil Laurens Gata 9, S-20502 Malmo, Sweden; [Andersson, Ingvar; Lang, Kristina] Skane Univ Hosp, Unilabs Breast Ctr, Carl Bertil Laurens Gata 9, S-20502 Malmo, Sweden; [Tingberg, Anders] Skane Univ Hosp, Dept Radiat Phys, Carl Bertil Laurens Gata 9, S-20502 Malmo, Sweden	Lund University; Lund University; Lund University; Skane University Hospital; Lund University; Skane University Hospital; Lund University; Skane University Hospital	Dahlblom, V (corresponding author), Lund Univ, Dept Translat Med, Diagnost Radiol, Malmo, Sweden.; Dahlblom, V (corresponding author), Skane Univ Hosp, Dept Med Imaging & Physiol, Carl Bertil Laurens Gata 9, S-20502 Malmo, Sweden.	victor.dahlblom@med.lu.se	Dahlblom, Victor/AFR-0947-2022	Dahlblom, Victor/0000-0002-4330-5387; Lang, Kristina/0000-0001-9250-1897; Dustler, Magnus/0000-0002-5699-9664; Tingberg, Anders/0000-0003-3078-0725	Governmental Funding for Clinical Research, Analytic Imaging Diagnostics Arena (AIDA)/VINNOVA; Swedish Cancer Society	Governmental Funding for Clinical Research, Analytic Imaging Diagnostics Arena (AIDA)/VINNOVA; Swedish Cancer Society(Swedish Cancer Society)	This study was funded by Governmental Funding for Clinical Research, Analytic Imaging Diagnostics Arena (AIDA)/VINNOVA and The Swedish Cancer Society.	Becker AS, 2017, INVEST RADIOL, V52, P434, DOI 10.1097/RLI.0000000000000358; Bernardi D, 2016, LANCET ONCOL, V17, P1105, DOI 10.1016/S1470-2045(16)30101-2; Burt JR, 2018, BRIT J RADIOL, V91, DOI 10.1259/bjr.20170545; Dembrower K, 2020, LANCET DIGIT HEALTH, V2, pE468, DOI 10.1016/S2589-7500(20)30185-0; Fornvik D, 2019, EUR RADIOL, V29, P330, DOI 10.1007/s00330-018-5582-0; Henriksen EL, 2019, ACTA RADIOL, V60, P13, DOI 10.1177/0284185118770917; Houssami N, 2017, TRANSL CANCER RES, V6, P869, DOI 10.21037/tcr.2017.06.39; Hupse R, 2013, EUR RADIOL, V23, P93, DOI 10.1007/s00330-012-2562-7; Johnson K, 2019, RADIOLOGY, V293, P273, DOI 10.1148/radiol.2019190132; Katzen J, 2018, CLIN IMAG, V52, P305, DOI 10.1016/j.clinimag.2018.08.014; Kim HE, 2020, LANCET DIGIT HEALTH, V2, pE138, DOI 10.1016/S2589-7500(20)30003-0; Kooi T, 2017, MED IMAGE ANAL, V35, P303, DOI 10.1016/j.media.2016.07.007; Lang K, 2021, EUR RADIOL, V31, P1687, DOI 10.1007/s00330-020-07165-1; Lang K, 2016, EUR RADIOL, V26, P3899, DOI 10.1007/s00330-016-4265-y; Lang K, 2016, EUR RADIOL, V26, P184, DOI 10.1007/s00330-015-3803-3; Marmot MG, 2013, BRIT J CANCER, V108, P2205, DOI 10.1038/bjc.2013.177; McKinney SM, 2020, NATURE, V577, P89, DOI 10.1038/s41586-019-1799-6; Pacile S, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190208; Perry N, 2008, ANN ONCOL, V19, P614, DOI 10.1093/annonc/mdm481; Rao VM, 2010, J AM COLL RADIOL, V7, P802, DOI 10.1016/j.jacr.2010.05.019; Ribli D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22437-z; Rodriguez-Ruiz A, 2019, EUR RADIOL, V29, P4825, DOI 10.1007/s00330-019-06186-9; Rodriguez-Ruiz A, 2019, JNCI-J NATL CANCER I, V111, P916, DOI 10.1093/jnci/djy222; Rodriguez-Ruiz A, 2019, RADIOLOGY, V290, P305, DOI 10.1148/radiol.2018181371; Rosso A, 2015, BREAST, V24, P680, DOI 10.1016/j.breast.2015.08.007; Salim M, 2020, JAMA ONCOL, V6, P1581, DOI 10.1001/jamaoncol.2020.3321; Sartor H, 2016, EUR RADIOL, V26, P4354, DOI 10.1007/s00330-016-4309-3; Sasaki M, 2020, BREAST CANCER-TOKYO, V27, P642, DOI 10.1007/s12282-020-01061-8; Schaffter T, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.0265; Siu AL, 2016, ANN INTERN MED, V164, P279, DOI 10.7326/M15-2886; Skaane P, 2018, BREAST CANCER RES TR, V169, P489, DOI 10.1007/s10549-018-4705-2; Zackrisson S, 2019, LANCET ONCOL, V20, pE7, DOI 10.1016/S1470-2045(18)30943-4; Zackrisson S, 2018, LANCET ONCOL, V19, P1493, DOI [10.1016/S1470-2045(18)30521-7, 10.1016/s1470-2045(18)30521-7]	33	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2021	3	6							e200299	10.1148/ryai.2021200299	http://dx.doi.org/10.1148/ryai.2021200299			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9UW	34870215	Green Published			2022-12-18	WOS:000826914400005
J	Gao, RQ; Tang, YC; Khan, MS; Xu, KW; Paulson, AB; Sullivan, S; Huo, YK; Deppen, S; Massion, PP; Sandler, KL; Landman, BA				Gao, Riqiang; Tang, Yucheng; Khan, Mirza S.; Xu, Kaiwen; Paulson, Alexis B.; Sullivan, Shelbi; Huo, Yuankai; Deppen, Stephen; Massion, Pierre P.; Sandler, Kim L.; Landman, Bennett A.			Cancer Risk Estimation Combining Lung Screening CT with Clinical Data Elements	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Computer-aided Diagnosis (CAD); CT; Lung; Thorax	PULMONARY NODULES; SELECTION	Purpose: To develop a model to estimate lung cancer risk using lung cancer screening CT and clinical data elements (CDEs) without manual reading efforts. Materials and Methods: Two screening cohorts were retrospectively studied: the National Lung Screening Trial (NLST; participants enrolled between August 2002 and April 2004) and the Vanderbilt Lung Screening Program (VLSP; participants enrolled between 2015 and 2018). Fivefold cross-validation using the NLST dataset was used for initial development and assessment of the co-learning model using whole CT scans and CDEs. The VLSP dataset was used for external testing of the developed model. Area under the receiver operating characteristic curve (AUC) and area under the precision-recall curve were used to measure the performance of the model. The developed model was compared with published risk-prediction models that used only CDEs or imaging data alone. The Brock model was also included for comparison by imputing missing values for patients without a dominant pulmonary nodule. Results: A total of 23 505 patients from the NLST (mean age, 62 years 6 5 [standard deviation]; 13 838 men, 9667 women) and 147 patients from the VLSP (mean age, 65 years +/- 5; 82 men, 65 women) were included. Using cross-validation on the NLST dataset, the AUC of the proposed co-learning model (AUC, 0.88) was higher than the published models predicted with CDEs only (AUC, 0.69; P < .05) and with images only (AUC, 0.86; P < .05). Additionally, using the external VLSP test dataset, the co-learning model had a higher performance than each of the published individual models (AUC, 0.91 [co-learning] vs 0.59 [CDE-only] and 0.88 [imageonly]; P < .05 for both comparisons). Conclusion: The proposed co-learning predictive model combining chest CT images and CDEs had a higher performance for lung cancer risk prediction than models that contained only CDE or only image data; the proposed model also had a higher performance than the Brock model. Supplemental material is available for this article. (C) RSNA, 2021.	[Gao, Riqiang; Xu, Kaiwen; Huo, Yuankai; Landman, Bennett A.] Vanderbilt Univ, Dept Comp Sci, 400 24th Ave S,Featheringill Hall,Room 371, Nashville, TN 37235 USA; [Tang, Yucheng; Huo, Yuankai; Landman, Bennett A.] Vanderbilt Univ, Dept Elect & Comp Engn, 400 24th Ave S,Featheringill Hall,Room 371, Nashville, TN 37235 USA; [Paulson, Alexis B.; Sandler, Kim L.] Vanderbilt Univ, Med Ctr, Dept Radiol & Radiol Sci, Nashville, TN 37232 USA; [Sullivan, Shelbi; Deppen, Stephen] Vanderbilt Univ, Med Ctr, Dept Thorac Surg, Nashville, TN USA; [Khan, Mirza S.] Vanderbilt Univ, Med Ctr, Dept Gen Internal Med & Publ Hlth, Nashville, TN USA; [Khan, Mirza S.] Vanderbilt Univ, Med Ctr, Dept Biomed Informat, Nashville, TN USA; [Massion, Pierre P.] Vanderbilt Univ, Med Ctr, Div Allergy Pulm & Crit Care Med, Dept Med, Nashville, TN USA	Vanderbilt University; Vanderbilt University; Vanderbilt University; Vanderbilt University; Vanderbilt University; Vanderbilt University; Vanderbilt University	Gao, RQ (corresponding author), Vanderbilt Univ, Dept Comp Sci, 400 24th Ave S,Featheringill Hall,Room 371, Nashville, TN 37235 USA.	riqiang.gao@vanderbilt.edu		Khan, Mirza/0000-0001-7007-9437; Gao, Riqiang/0000-0002-8729-1941; Xu, Kaiwen/0000-0002-2664-255X	National Science Foundation [CAREER 1452485, R01 EB017230]; National Cancer Institute [UO1 CA196405]; National Center for Research Resources [UL1 RR024975-01]; Vanderbilt Institute for Clinical and Translational Research Clinical Translational Science Award (NCATS/NIH) [ULTR000445]; Vanderbilt University Medical Center; Patient-Centered Outcomes Research Institute (PCORI) [CDRN-1306-04869]; Martineau Innovation Fund Grant through the Vanderbilt-Ingram Cancer Center Thoracic Working Group; NCI Early Detection Research Network [2U01CA152662]; National Center for Advancing Translational Sciences [2 UL1 TR000445-06]	National Science Foundation(National Science Foundation (NSF)); National Cancer Institute(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Cancer Institute (NCI)); National Center for Research Resources(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Research Resources (NCRR)); Vanderbilt Institute for Clinical and Translational Research Clinical Translational Science Award (NCATS/NIH); Vanderbilt University Medical Center; Patient-Centered Outcomes Research Institute (PCORI)(Patient-Centered Outcomes Research Institute - PCORI); Martineau Innovation Fund Grant through the Vanderbilt-Ingram Cancer Center Thoracic Working Group; NCI Early Detection Research Network(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Cancer Institute (NCI)); National Center for Advancing Translational Sciences(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Advancing Translational Sciences (NCATS))	This research was supported by National Science Foundation CAREER 1452485 and R01 EB017230. P.P.M. supported in part by the National Cancer Institute (UO1 CA196405). This study was supported in part using the resources of the Advanced Computing Center for Research and Education (ACCRE) at Vanderbilt University, Nashville, Tenn. This project was supported in part by the National Center for Research Resources, grant UL1 RR024975-01, and is now at the National Center for Advancing Translational Sciences, grant 2 UL1 TR000445-06. The de-identified imaging dataset(s) used for the analysis described were obtained from ImageVU, a research resource supported by the Vanderbilt Institute for Clinical and Translational Research Clinical Translational Science Award (ULTR000445 from NCATS/NIH), Vanderbilt University Medical Center institutional funding and Patient-Centered Outcomes Research Institute (PCORI; contract CDRN-1306-04869). This study was funded in part by the Martineau Innovation Fund Grant through the Vanderbilt-Ingram Cancer Center Thoracic Working Group and NCI Early Detection Research Network 2U01CA152662 to P.P.M.	Ardila D, 2019, NAT MED, V25, P954, DOI 10.1038/s41591-019-0447-x; Armato SG, 2011, MED PHYS, V38, P915, DOI 10.1118/1.3528204; Church TR, 2013, NEW ENGL J MED, V368, P1980, DOI 10.1056/NEJMoa1209120; DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595; Gao R, ARXIV 210712842 PREP; Gao R, PROC SPIE, V1596; Gao RQ, 2021, PROC SPIE, V11313, DOI 10.1117/12.2548464; Gao RQ, 2020, NEUROCOMPUTING, V397, P48, DOI 10.1016/j.neucom.2020.02.033; Gao RQ, 2019, LECT NOTES COMPUT SC, V11861, P310, DOI 10.1007/978-3-030-32692-0_36; Gao RQ, 2018, IEEE SIGNAL PROC LET, V25, P308, DOI 10.1109/LSP.2017.2789251; Gatsonis CA, 2011, RADIOLOGY, V258, P243, DOI 10.1148/radiol.10091808; Goodfellow I., 2014, NEURIPS, P2672, DOI [10.3156/jsoft.29.5_177_2, DOI 10.1145/3422622]; Gould MK, 2013, CHEST, V143, pE93, DOI 10.1378/chest.12-2351; Guo CA, 2017, PR MACH LEARN RES, V70; Henschke CI, 2013, ANN INTERN MED, V158, P246, DOI 10.7326/0003-4819-158-4-201302190-00004; Horeweg N, 2013, EUR RESPIR J, V42, P1659, DOI 10.1183/09031936.00197712; Huang P, 2019, LANCET DIGIT HEALTH, V1, pE353, DOI 10.1016/S2589-7500(19)30159-1; Humphrey LL, 2013, ANN INTERN MED, V159, P411, DOI 10.7326/0003-4819-159-6-201309170-00690; Ilse M, 2018, PR MACH LEARN RES, V80; Kaggle, DAT SCI BOWL 2017; Li YM, 2020, I S BIOMED IMAGING, P1866, DOI 10.1109/ISBI45749.2020.9098317; Liao FZ, 2019, IEEE T NEUR NET LEAR, V30, P3484, DOI 10.1109/TNNLS.2019.2892409; Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005; Liu LH, 2018, LECT NOTES COMPUT SC, V11045, P74, DOI 10.1007/978-3-030-00889-5_9; Liu WY, 2017, PROC CVPR IEEE, P6738, DOI 10.1109/CVPR.2017.713; Lung-RADS, RADIOLOGY REFERENCE; Massion PP, 2020, AM J RESP CRIT CARE, V202, P241, DOI 10.1164/rccm.201903-0505OC; McWilliams A, 2013, NEW ENGL J MED, V369, P910, DOI 10.1056/NEJMoa1214726; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Setio AAA, 2017, MED IMAGE ANAL, V42, P1, DOI 10.1016/j.media.2017.06.015; Shen Wei, 2015, Inf Process Med Imaging, V24, P588, DOI 10.1007/978-3-319-19992-4_46; Siegel RL, 2019, CA-CANCER J CLIN, V69, P7, DOI 10.3322/caac.21551; Tammemagi MC, 2013, NEW ENGL J MED, V368, P728, DOI 10.1056/NEJMoa1211776; Tammemagi MC, 2017, LANCET ONCOL, V18, P1523, DOI [10.1016/S1470-2045(17)30597-1, 10.1016/s1470-2045(17)30597-1]	34	0	0	1	2	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2021	3	6							e210032	10.1148/ryai.2021210032	http://dx.doi.org/10.1148/ryai.2021210032			9	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9UW	34870220	Green Published			2022-12-18	WOS:000826914400010
J	Linguraru, MG; Maier-Hein, L; Summers, RM; Kahn, CE				Linguraru, Marius George; Maier-Hein, Lena; Summers, Ronald M.; Kahn, Charles E., Jr.			RSNA-MICCAI Panel Discussion: 2. Leveraging the Full Potential of AI-Radiologists and Data Scientists Working Together	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Adults and Pediatrics; Segmentation; Feature Detection; Quantification; Diagnosis/Classification; Prognosis/Classification		In March 2021, the Radiological Society of North America hosted a virtual panel discussion with members of the Medical Image Computing and Computer Assisted Intervention Society. Both organizations share a vision to develop radiologic and medical imaging techniques through advanced quantitative imaging biomarkers and artificial intelligence. The panel addressed how radiologists and data scientists can collaborate to advance the science of AI in radiology. (C) RSNA, 2021	[Linguraru, Marius George] Childrens Natl Hosp, Sheikh Zayed Inst Pediat Surg Innovat, Washington, DC USA; [Maier-Hein, Lena] German Canc Res Ctr, Dept Comp Assisted Med Intervent, Heidelberg, Germany; [Summers, Ronald M.] NIH, Dept Radiol & Imaging Sci, Clin Ctr, Bldg 10, Bethesda, MD 20892 USA; [Kahn, Charles E., Jr.] Univ Penn, Dept Radiol, 3400 Spruce St,1 Silverstein, Philadelphia, PA 19104 USA	Children's National Health System; Helmholtz Association; German Cancer Research Center (DKFZ); National Institutes of Health (NIH) - USA; NIH Clinical Center (CC); University of Pennsylvania	Kahn, CE (corresponding author), Univ Penn, Dept Radiol, 3400 Spruce St,1 Silverstein, Philadelphia, PA 19104 USA.	ckahn@upenn.edu		Kahn, Charles/0000-0002-6654-7434	Intramural Research Program of the National Institutes of Health Clinical Center	Intramural Research Program of the National Institutes of Health Clinical Center(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	Supported in part by the Intramural Research Program of the National Institutes of Health Clinical Center.	Avery RA, 2016, NEUROLOGY, V87, P2403, DOI 10.1212/WNL.0000000000003402; Cerrolaza JJ, 2016, J UROLOGY, V195, P1093, DOI 10.1016/j.juro.2015.10.173; Cob E, 2021, RADIOL-ARTIF INTELL, V3, DOI 10.1148/ryai.2021200254; Dayan I, 2021, NAT MED, V27, P1735, DOI 10.1038/s41591-021-01506-3; Erickson BJ, 2019, RADIOL-ARTIF INTELL, V1, DOI [10.1148/ryai.2019190072, 10.1148/ryai.2019190113, 10.1148/ryai.2019190126]; Flanders AE, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190211; Grace K, 2018, J ARTIF INTELL RES, V62, P729, DOI 10.1613/jair.1.11222; Kahn CE, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019194002; Konecny J, ARXIV; Langlotz CP, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019190058; Maier-Hein L, 2020, MED IMAGE ANAL, V66, DOI 10.1016/j.media.2020.101796; Maier-Hein L, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-07619-7; Mazurowski MA, 2021, RADIOL ARTIF INTELL, V3; Mongan J., 2021, RADIOL ARTIF INTELL, V3; Mongan J, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020200029; Pickhardt PJ, 2020, LANCET DIGIT HEALTH, V2, pE192, DOI 10.1016/S2589-7500(20)30025-X; Porras AR, 2021, LANCET DIGIT HEALTH, V3, pE635, DOI 10.1016/S2589-7500(21)00137-0; Reinke A, ARXIV; Reyes M, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190043; Shih G, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180041; Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369; Yan K, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.3.036501	22	0	0	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2021	3	6							e210248	10.1148/ryai.2021210248	http://dx.doi.org/10.1148/ryai.2021210248			5	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9UW	34870225	Green Published			2022-12-18	WOS:000826914400015
J	Pollack, BL; Batmanghelich, K; Cai, SS; Gordon, E; Wallace, S; Catania, R; Morillo-Hernandez, C; Furlan, A; Borhani, AA				Pollack, Brian L.; Batmanghelich, Kayhan; Cai, Stephen S.; Gordon, Emile; Wallace, Stephen; Catania, Roberta; Morillo-Hernandez, Carlos; Furlan, Alessandro; Borhani, Amir A.			Deep Learning Prediction of Voxel-Level Liver Stiffness in Patients with Nonalcoholic Fatty Liver Disease	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						MR Imaging; Abdomen/GI; Liver; Cirrhosis; Computer Applications/Virtual Imaging; Experimental Investigations; Feature Detection; Classification; Reconstruction Algorithms; Supervised Learning; Convolutional Neural Network (CNN)	MAGNETIC-RESONANCE ELASTOGRAPHY; GLOBAL EPIDEMIOLOGY; FIBROSIS	Purpose: To reconstruct virtual MR elastography (MRE) images based on traditional MRI inputs with a machine learning algorithm. Materials and Methods: In this single-institution, retrospective study, 149 patients (mean age, 58 years +/- 12 [standard deviation]; 71 men) with nonalcoholic fatty liver disease who underwent MRI and MRE between January 2016 and January 2019 were evaluated. Nine conventional MRI sequences and clinical data were used to train a convolutional neural network to reconstruct MRE images at the per-voxel level. The architecture was further modified to accept multichannel three-dimensional inputs and to allow inclusion of clinical and demographic information. Liver stiffness and fibrosis category (F0 [no fibrosis] to F4 [significant fibrosis]) of reconstructed images were assessed by using voxel- and patient-level agreement by correlation, sensitivity, and specificity calculations; in addition, classification by receiver operator characteristic analyses was performed, and Dice score was used to evaluate hepatic stiffness locality. Results: The model for predicting liver stiffness incorporated four image sequences (precontrast T1-weighted liver acquisition with volume acquisition [LAVA] water and LAVA fat, 120-second-delay T1-weighted LAVA water, and single-shot fast spin-echo T2 weighted) and clinical data. The model had a patient-level and voxel-level correlation of 0.50 +/- 0.05 and 0.34 +/- 0.03, respectively. By using a stiffness threshold of 3.54 kPa to make a binary classification into no fibrosis or mild fibrosis (F0-F1) versus clinically significant fibrosis (F2-F4), the model had sensitivity of 80% 6 4, specificity of 75% 6 5, accuracy of 78% 6 3, area under the receiver operating characteristic curve of 84 +/- 0.04, and a Dice score of 0.74. Conclusion: The generation of virtual elastography images is feasible by using conventional MRI and clinical data with a machine learning algorithm. Supplemental material is available for this article. (C) RSNA, 2021.	[Pollack, Brian L.; Batmanghelich, Kayhan] Univ Pittsburgh, Sch Med, Dept Biomed Informat, Pittsburgh, PA USA; [Morillo-Hernandez, Carlos] Univ Pittsburgh, Sch Med, Dept Radiol, Pittsburgh, PA USA; [Cai, Stephen S.; Gordon, Emile; Wallace, Stephen; Catania, Roberta; Furlan, Alessandro; Borhani, Amir A.] Univ Pittsburgh, Med Ctr, Dept Radiol, Pittsburgh, PA USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh	Borhani, AA (corresponding author), Northwestern Univ, Dept Radiol, 676 N St Clair St,Suite 800, Chicago, IL 60611 USA.	amir.borhani@northwestern.edu		Pollack, Brian/0000-0001-9565-7096	Pittsburgh Liver Research Center's Pilot and Feasibility program from National Institute of Diabetes and Digestive and Kidney Diseases, NIH [P30DK120531]; NIH [1R-1Hl141813-01]; National Science Foundation [1839332]; SAP SE; Pittsburgh Liver Research Center (PF Award) [P30 DK1120531]; National Library of Medicine Training Grant	Pittsburgh Liver Research Center's Pilot and Feasibility program from National Institute of Diabetes and Digestive and Kidney Diseases, NIH; NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); National Science Foundation(National Science Foundation (NSF)); SAP SE; Pittsburgh Liver Research Center (PF Award); National Library of Medicine Training Grant	A.A.B. supported by Pittsburgh Liver Research Center's Pilot and Feasibility program, funded by grant P30DK120531 from National Institute of Diabetes and Digestive and Kidney Diseases, NIH. B.L.P., K.B. supported by a grant from the NIH (1R-1Hl141813-01), National Science Foundation (grant number 1839332), and SAP SE (research grant), and Pittsburgh Liver Research Center (P&F Award P30 DK1120531). Additional funding was provided by a National Library of Medicine Training Grant.	Angulo P, 2002, NEW ENGL J MED, V346, P1221, DOI 10.1038/nrdp.2015.80; Araujo AR, 2018, LIVER INT, V38, P47, DOI 10.1111/liv.13643; Bravo AA, 2001, NEW ENGL J MED, V344, P495, DOI 10.1056/NEJM200102153440706; Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49; Choi KJ, 2018, RADIOLOGY, V289, P688, DOI 10.1148/radiol.2018180763; Furlan A, 2020, AM J ROENTGENOL, V214, pW20, DOI 10.2214/AJR.19.21267; He LL, 2019, AM J ROENTGENOL, V213, P592, DOI 10.2214/AJR.19.21082; Kavur AE, CHAOS COMBINED CT MR; Li W, 2019, EUR RADIOL, V29, P1496, DOI 10.1007/s00330-018-5680-z; Lowekamp B. gabehart, KASPERMARSTALSIMPLEE; Manduca A, 2001, MED IMAGE ANAL, V5, P237, DOI 10.1016/S1361-8415(00)00039-6; MUTHUPILLAI R, 1995, SCIENCE, V269, P1854, DOI 10.1126/science.7569924; Paszke A, 2019, ADV NEUR IN, V32; Petitclerc L, 2017, J MAGN RESON IMAGING, V45, P1276, DOI 10.1002/jmri.25550; Resoundant, OURT; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Schawkat K, 2020, EUR RADIOL, V30, P4675, DOI 10.1007/s00330-020-06831-8; Singh S, 2016, EUR RADIOL, V26, P1431, DOI 10.1007/s00330-015-3949-z; Tapper EB, 2017, NEW ENGL J MED, V377, P756, DOI 10.1056/NEJMra1610570; Vallat R., 2018, J OPEN SOURCE SOFTW, V3, P1026, DOI [10.21105/joss.01026, DOI 10.21105/JOSS.01026]; Yasaka K, 2018, RADIOLOGY, V287, P146, DOI 10.1148/radiol.2017171928; Yin M, 2016, RADIOLOGY, V278, P114, DOI 10.1148/radiol.2015142141; Younossi ZM, 2016, HEPATOLOGY, V64, P73, DOI 10.1002/hep.28431	23	0	0	3	4	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2021	3	6							e200274	10.1148/ryai.2021200274	http://dx.doi.org/10.1148/ryai.2021200274			14	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9UW	34870213	Green Published			2022-12-18	WOS:000826914400003
J	Sandfort, V; Yan, K; Graffy, PM; Pickhardt, PJ; Summers, RM				Sandfort, Veit; Yan, Ke; Graffy, Peter M.; Pickhardt, Perry J.; Summers, Ronald M.			Use of Variational Autoencoders with Unsupervised Learning to Detect Incorrect Organ Segmentations at CT (vol 3, e200218, 2021)	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Correction															Intramural Research Program of the National Institutes of Health Clinical Center	Intramural Research Program of the National Institutes of Health Clinical Center(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	The following funding statement should have been included: This research was supported in part by the Intramural Research Program of the National Institutes of Health Clinical Center.	Sandfort V, 2021, RADIOL-ARTIF INTELL, V3, DOI 10.1148/ryai.2021200218	1	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2021	3	5								10.1148/ryai.2021219002	http://dx.doi.org/10.1148/ryai.2021219002			1	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9TT		Green Published			2022-12-18	WOS:000826911500015
J	Yi, PH; Fritz, J				Yi, Paul H.; Fritz, Jan			Radiology Alchemy: GAN We Do It?	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Yi, Paul H.] Univ Maryland, Sch Med, Dept Radiol & Nucl Med, Med Intelligent Imaging Ctr, Baltimore, MD 21201 USA; [Yi, Paul H.] Johns Hopkins Univ, Whiting Sch Engn, Malone Ctr Engn Healthcare, 601 N Caroline St, Baltimore, MD 21287 USA; [Fritz, Jan] NYU, Dept Radiol, Grossman Sch Med, 560 1St Ave, New York, NY 10016 USA	University System of Maryland; University of Maryland Baltimore; Johns Hopkins University; New York University	Yi, PH (corresponding author), Univ Maryland, Sch Med, Dept Radiol & Nucl Med, Med Intelligent Imaging Ctr, Baltimore, MD 21201 USA.; Yi, PH (corresponding author), Johns Hopkins Univ, Whiting Sch Engn, Malone Ctr Engn Healthcare, 601 N Caroline St, Baltimore, MD 21287 USA.	pyi@som.umaryland.edu						Fayad LM, 2021, INVEST RADIOL, V56, P357, DOI 10.1097/RLI.0000000000000751; Fritz J, 2021, AM J ROENTGENOL, V216, P718, DOI 10.2214/AJR.20.22902; Fritz J, 2021, RADIOLOGY, V298, P350, DOI 10.1148/radiol.2020204045; Fritz J, 2019, RADIOLOGY, V293, P631, DOI 10.1148/radiol.2019192046; Hutson M., RES ALLEGE MACHINE L; Jans LBO, 2021, RADIOLOGY, V298, P343, DOI 10.1148/radiol.2020201537; Korkinof D, 2021, RADIOL-ARTIF INTELL, V3, DOI 10.1148/ryai.2020190181; Kumar NM, 2018, RADIOLOGY, V289, P465, DOI 10.1148/radiol.2018173007; Sveinsson B, RADIOL ARTIF INTELL, V3; Wright NC, PREVALENCE BURDEN MU	10	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2021	3	5							e210125	10.1148/ryai.2021210125	http://dx.doi.org/10.1148/ryai.2021210125			2	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9TT	34617033	Green Published			2022-12-18	WOS:000826911500014
J	Chan, HP				Chan, Heang-Ping			Promise and Potential Pitfalls: Re-creating Images or Generating New Images for AI Modeling	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Chan, Heang-Ping] Univ Michigan, Dept Radiol, 1500 E Med Ctr Dr,Med Inn Bldg C477, Ann Arbor, MI 48109 USA	University of Michigan System; University of Michigan	Chan, HP (corresponding author), Univ Michigan, Dept Radiol, 1500 E Med Ctr Dr,Med Inn Bldg C477, Ann Arbor, MI 48109 USA.	chanhp@umich.edu		Chan, Heang-Ping/0000-0001-7777-9006				Chan HP, 2020, BRIT J RADIOL, V93, DOI 10.1259/bjr.20190580; Hussain Zeshan, 2017, AMIA Annu Symp Proc, V2017, P979; Pesteie M, 2019, IEEE T MED IMAGING, V38, P2807, DOI 10.1109/TMI.2019.2914656; Sahiner B, 2019, MED PHYS, V46, pe1, DOI 10.1002/mp.13264; Shu H, 2021, RADIOL-ARTIF INTELL, V3, DOI 10.1148/ryai.2021200097; Yi X, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101552	6	0	0	2	2	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2021	3	4							e210102	10.1148/ryai.2021210102	http://dx.doi.org/10.1148/ryai.2021210102			2	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SU	34350415	Green Published			2022-12-18	WOS:000826909000015
J	Christensen, S; Mlynash, M; MacLaren, J; Federau, C; Albers, GW; Lansberg, MG				Christensen, Soren; Mlynash, Michael; MacLaren, Julian; Federau, Christian; Albers, Gregory W.; Lansberg, Maarten G.			Optimizing Deep Learning Algorithms for Segmentation of Acute Infarcts on Non-Contrast Material-enhanced CT Scans of the Brain Using Simulated Lesions	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						Adults; CT-Quantitative; Stroke	STROKE	Purpose: To test the efficacy of lesion segmentation using a deep learning algorithm on non-contrast material-enhanced CT (NCCT) images with synthetic lesions resembling acute infarcts. Materials and Methods: In this retrospective study, 40 diffusion-weighted imaging (DWI) lesions in patients with acute stroke (median age, 69 years; range, 62-76 years; 17 women; screened between 2011 and 2017) were coregistered to 40 normal NCCT scans (median age, 70 years; range, 55-76 years; 25 women; screened between 2008 and 2011), which produced 640 combinations of DWI-NCCT with and without lesions for training (n = 420), validation (n = 110), and testing (n = 110). The signal intensity on the NCCT scans was depressed by 4 HU (a 13% drop) in the region of the diffusion-weighted lesion. Two U-Net architectures (standard and symmetry aware) were trained with two different training strategies. One was a naive strategy, in which the model started training with random coefficients. The other was a progressive strategy, which started with coefficients derived from a model trained on a dataset with lesions that were depressed by 10 HU. The Dice scores from the two architectures and training strategies were compared from the test dataset. Results: Dice scores of symmetry-aware U-Nets were 25% higher than those of standard U-Nets (median, 0.49 vs 0.65; P < .001). Use of a progressive training strategy had no clear effect on model performance. Conclusion: Symmetry-aware U-Nets offer promise for segmentation of acute stroke lesions on NCCT scans.	[Christensen, Soren; Mlynash, Michael; MacLaren, Julian; Albers, Gregory W.; Lansberg, Maarten G.] Stanford Univ, Stanford Stroke Ctr, Dept Neurol, 780 Welch Rd,Suite 350, Palo Alto, CA 94304 USA; [Federau, Christian] Swiss Fed Inst Technol, Inst Biomed Engn, Zurich, Switzerland; [Federau, Christian] Univ Zurich, Zurich, Switzerland	Stanford University; Swiss Federal Institutes of Technology Domain; ETH Zurich; University of Zurich	Lansberg, MG (corresponding author), Stanford Univ, Stanford Stroke Ctr, Dept Neurol, 780 Welch Rd,Suite 350, Palo Alto, CA 94304 USA.	lansberg@stanford.edu		Albers, Gregory/0000-0003-0263-4632; Federau, Christian/0000-0002-3803-6602	National Institutes of Health/National Institute of Neurological Disorders and Stroke [R01NS075209]	National Institutes of Health/National Institute of Neurological Disorders and Stroke(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Neurological Disorders & Stroke (NINDS))	Supported in part by National Institutes of Health/National Institute of Neurological Disorders and Stroke grant R01NS075209.	Antica L., 2020, RETINA UNET; Dzialowski I, 2004, J NEUROIMAGING, V14, P42, DOI 10.1177/1051228403258135; Federau C, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190217; Isensee F, ARXIV180910486 CSCV; Lansberg MG, 2012, LANCET NEUROL, V11, P860, DOI 10.1016/S1474-4422(12)70203-X; Marstal K, 2016, IEEE COMPUT SOC CONF, P574, DOI 10.1109/CVPRW.2016.78; Mikhail P, 2020, J STROKE CEREBROVASC, V29, DOI 10.1016/j.jstrokecerebrovasdis.2020.104715; Nemoto EM, 2012, TRANSL STROKE RES, V3, P369, DOI 10.1007/s12975-012-0193-6; Qiu W, 2020, RADIOLOGY, V294, P638, DOI 10.1148/radiol.2020191193; Ronneberger O., ARXIV150504597 CSCV; von Kummer R, 2017, NEURORADIOLOGY, V59, P545, DOI 10.1007/s00234-017-1847-6; vonKummer R, 1997, NEUROLOGY, V49, pS52; Vos PC, 2013, PROC SPIE, V8670, DOI 10.1117/12.2008074; Zhang H, ARXIV171106636 CSCV	14	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2021	3	4							e200127	10.1148/ryai.2021200127	http://dx.doi.org/10.1148/ryai.2021200127			6	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SU	34350404	Green Published			2022-12-18	WOS:000826909000002
J	Josselyn, N; MacLean, MT; Jean, C; Fuchs, B; Moon, BF; Hwuang, E; Iyer, SK; Litt, H; Han, YC; Kaghazchi, F; Bravo, PE; Witschey, WR				Josselyn, Nicholas; MacLean, Matthew T.; Jean, Christopher; Fuchs, Ben; Moon, Brianna F.; Hwuang, Eileen; Iyer, Srikant Kamesh; Litt, Harold; Han, Yuchi; Kaghazchi, Fatemeh; Bravo, Paco E.; Witschey, Walter R.			Classification of Myocardial F-18-FDG PET Uptake Patterns Using Deep Learning	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article						PET; Heart; Computer Aided Diagnosis; Computer Application-Detection/Diagnosis	HEART; IDENTIFICATION; VALIDATION	Purpose: To perform automated myocardial segmentation and uptake classification from whole-body fluorine 18 fluorodeoxyglucose (FDG) PET. Materials and Methods: In this retrospective study, consecutive patients who underwent FDG PET imaging for oncologic indications were included (July-August 2018). The left ventricle (LV) on whole-body FDG PET images was manually segmented and classified as showing no myocardial uptake, diffuse uptake, or partial uptake. A total of 609 patients (mean age, 64 years 6 14 [standard deviation]; 309 women) were included and split between training (60%, 365 patients), validation (20%, 122 patients), and testing (20%, 122 patients) datasets. Two sequential neural networks were developed to automatically segment the LV and classify the myocardial uptake pattern using segmentation and classification training data provided by human experts. Linear regression was performed to correlate findings from human experts and deep learning. Classification performance was evaluated using receiver operating characteristic (ROC) analysis. Results: There was moderate agreement of uptake pattern between experts and deep learning (as a fraction of correctly categorized images) with 78% (36 of 46) for no uptake, 71% (34 of 48) for diffuse uptake, and 71% (20 of 28) for partial uptake. There was no bias in LV volume for partial or diffuse uptake categories (P =.56); however, deep learning underestimated LV volumes in the no uptake category. There was good correlation for LV volume (R-2 = 0.35, beta =.71). ROC analysis showed the area under the curve for classifying no uptake and diffuse uptake was high (>= 0.90) but lower for partial uptake (0.77). The feasibility of a myocardial uptake index (MUI) for quantifying the degree of myocardial activity patterns was shown, and there was excellent visual agreement between MUI and uptake patterns. Conclusion: Deep learning was able to segment and classify myocardial uptake patterns on FDG PET images.	[Josselyn, Nicholas; MacLean, Matthew T.; Jean, Christopher; Fuchs, Ben; Litt, Harold; Han, Yuchi; Kaghazchi, Fatemeh; Bravo, Paco E.; Witschey, Walter R.] Univ Penn, Perelman Sch Med, Dept Radiol, 3400 Civ Ctr Blvd,South Pavilion,Room 11-155, Philadelphia, PA 19104 USA; [Moon, Brianna F.; Hwuang, Eileen; Iyer, Srikant Kamesh] Univ Penn, Perelman Sch Med, Dept Bioengn, 3400 Civ Ctr Blvd,South Pavilion,Room 11-155, Philadelphia, PA 19104 USA; [Han, Yuchi; Bravo, Paco E.] Univ Penn, Perelman Sch Med, Dept Med, 3400 Civ Ctr Blvd,South Pavilion,Room 11-155, Philadelphia, PA 19104 USA	University of Pennsylvania; Pennsylvania Medicine; University of Pennsylvania; Pennsylvania Medicine; University of Pennsylvania; Pennsylvania Medicine	Witschey, WR (corresponding author), Univ Penn, Perelman Sch Med, Dept Radiol, 3400 Civ Ctr Blvd,South Pavilion,Room 11-155, Philadelphia, PA 19104 USA.	witschey@pennmedicine.upenn.edu		Moon, Brianna/0000-0003-0642-0551; Fuchs, Benjamin/0000-0002-5346-7195; Han, Yuchi/0000-0001-7582-1848				Andrew Zisserman, 2015, Arxiv, DOI arXiv:1409.1556; Berthon B, 2015, PHYS MEDICA, V31, P969, DOI 10.1016/j.ejmp.2015.07.139; Bycroft C, 2018, NATURE, V562, P203, DOI 10.1038/s41586-018-0579-z; Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056; Guglielmo P, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62353-9; Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216; Hagan M.T., 2014, NEURAL NETWORK DESIG, V2nd; Hajiaghayi M, 2017, IEEE T BIO-MED ENG, V64, P134, DOI 10.1109/TBME.2016.2542243; Hoh CK, 2007, NUCL MED BIOL, V34, P737, DOI 10.1016/j.nucmedbio.2007.07.001; Hwang D, 2018, J NUCL MED, V59, P1624, DOI 10.2967/jnumed.117.202317; Inglese E, 2007, J NUCL MED, V48, P1662, DOI 10.2967/jnumed.107.041574; Kang SK, 2018, HUM BRAIN MAPP, V39, P3769, DOI 10.1002/hbm.24210; Kim SJW, 2019, PHYS MEDICA, V58, P32, DOI 10.1016/j.ejmp.2019.01.003; Langah R, 2009, J NUCL CARDIOL, V16, P801, DOI 10.1007/s12350-009-9110-0; LUCIGNANI G, 1992, EUR J NUCL MED, V19, P874, DOI 10.1007/BF00168164; Manabe O, 2020, JACC-CARDIOVASC IMAG, V13, P1096, DOI 10.1016/j.jcmg.2019.11.021; Manabe O, 2019, EUR J NUCL MED MOL I, V46, P1240, DOI 10.1007/s00259-018-4195-9; Manabe O, 2016, J NUCL CARDIOL, V23, P244, DOI 10.1007/s12350-015-0226-0; Minamimoto R, 2013, ANN NUCL MED, V27, P572, DOI 10.1007/s12149-013-0721-9; NEELY JR, 1974, ANNU REV PHYSIOL, V36, P413, DOI 10.1146/annurev.ph.36.030174.002213; Nose H, 2014, J MED INVESTIG, V61, P53, DOI 10.2152/jmi.61.53; Okumura W, 2004, J NUCL MED, V45, P1989; Park J, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aacdd4; RANDLE PJ, 1963, LANCET, V1, P785; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Tang RB, 2016, CLIN NUCL MED, V41, pE327, DOI 10.1097/RLU.0000000000001063; Uehara A, 1999, ANN NUCL MED, V13, P95, DOI 10.1007/BF03164884; Yang Chengliang, 2018, AMIA Annu Symp Proc, V2018, P1571	29	0	0	1	2	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2021	3	4							e200148	10.1148/ryai.2021200148	http://dx.doi.org/10.1148/ryai.2021200148			8	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SU	34350405	Green Published			2022-12-18	WOS:000826909000003
J	Li, MD; Torriani, M				Li, Matthew D.; Torriani, Martin			Radiologist-level Scaphoid Fracture Detection: Next Steps for Clinical Application	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Li, Matthew D.; Torriani, Martin] Harvard Med Sch, Massachusetts Gen Hosp, Div Musculoskeletal Imaging & Intervent, Dept Radiol, 55 Fruit St,Yawkey 6E, Boston, MA 02114 USA	Harvard University; Harvard Medical School; Massachusetts General Hospital	Li, MD (corresponding author), Harvard Med Sch, Massachusetts Gen Hosp, Div Musculoskeletal Imaging & Intervent, Dept Radiol, 55 Fruit St,Yawkey 6E, Boston, MA 02114 USA.	mdli@mgh.harvard.edu						Arun N, MEDRXIV; Balci A, 2015, EMERG RADIOL, V22, P251, DOI 10.1007/s10140-014-1278-1; Hendrix N, 2021, RADIOL ARTIF INTELL, V3; Jamjoom BA, 2019, INJURY, V50, P1306, DOI 10.1016/j.injury.2019.05.009; Langerhuizen DWG, 2020, CLIN ORTHOP RELAT R, V478, P2653, DOI 10.1097/CORR.0000000000001318; Lindsey R, 2018, P NATL ACAD SCI USA, V115, P11591, DOI 10.1073/pnas.1806905115; Mahajan V, 2020, ACAD RADIOL, V27, P132, DOI 10.1016/j.acra.2019.09.009; Ozkaya E, 2022, EUR J TRAUMA EMERG S, V48, P585, DOI 10.1007/s00068-020-01468-0; Reyes M, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190043; Saporta A, MEDRXIV	10	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2021	3	4							e210111	10.1148/ryai.2021210111	http://dx.doi.org/10.1148/ryai.2021210111			2	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SU	34350417	Green Published			2022-12-18	WOS:000826909000017
J	Astuto, B; Flament, I; Namiri, NK; Shah, R; Bharadwaj, U; Link, TM; Bucknor, MD; Pedoia, V; Majumdar, S				Astuto, Bruno; Flament, Io; Namiri, Nikan K.; Shah, Rutwik; Bharadwaj, Upasana; Link, Thomas M.; Bucknor, Matthew D.; Pedoia, Valentina; Majumdar, Sharmila			Automatic Deep Learning-assisted Detection and Grading of Abnormalities in Knee MRI Studies (vol 3, e219001, 2021)	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Correction																		Astuto B, 2021, RADIOL-ARTIF INTELL, V3, DOI 10.1148/ryai.2021200165	1	0	0	2	2	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2021	3	3								10.1148/ryai.2021219001	http://dx.doi.org/10.1148/ryai.2021219001			1	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SA		Bronze, Green Published			2022-12-18	WOS:000826907000013
J	Li, MD; Chang, CY				Li, Matthew D.; Chang, Connie Y.			Putting the Pieces Together: Deep Learning for Knee MRI Multitissue Abnormality Detection and Severity Grading	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Li, Matthew D.] Harvard Med Sch, Massachusetts Gen Hosp, Dept Radiol, Div Musculoskeletal Imaging & Intervent, 55 Fruit St,Yawkey 6E, Boston, MA 02114 USA	Harvard University; Harvard Medical School; Massachusetts General Hospital	Li, MD (corresponding author), Harvard Med Sch, Massachusetts Gen Hosp, Dept Radiol, Div Musculoskeletal Imaging & Intervent, 55 Fruit St,Yawkey 6E, Boston, MA 02114 USA.	mdli@mgh.harvard.edu		Chang, Connie/0000-0003-1304-1576				[Anonymous], 1999, 10153 BS EN; Astuto B, 2021, RADIOL-ARTIF INTELL, V3, DOI 10.1148/ryai.2021200165; Chilamkurthy S, 2018, LANCET, V392, P2388, DOI 10.1016/S0140-6736(18)31645-3; Draelos RL, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101857; Huang SC, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00341-z; Johnson A. E. W., 2019, ARXIV; Li MD, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0255-1; Peterfy CG, 2004, OSTEOARTHR CARTILAGE, V12, P177, DOI 10.1016/j.joca.2003.11.003; Rauschecker AM, 2020, RADIOLOGY, V295, P626, DOI 10.1148/radiol.2020190283; Rudie JD, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190146	10	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2021	3	3							e210022	10.1148/ryai.2021210022	http://dx.doi.org/10.1148/ryai.2021210022			2	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z9SA	34138986	Green Published			2022-12-18	WOS:000826907000010
J	Andreisek, G				Andreisek, Gustav			Advances in Daily Musculoskeletal Imaging: Automated Analysis of Classic Radiographs	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material							TOTAL KNEE ARTHROPLASTY; ALIGNMENT		[Andreisek, Gustav] Cantonal Hosp Munsterlingen, Inst Radiol, Spitalcampus 1, CH-8596 Munsterlingen, Switzerland; [Andreisek, Gustav] Univ Zurich, Zurich, Switzerland	University of Zurich	Andreisek, G (corresponding author), Cantonal Hosp Munsterlingen, Inst Radiol, Spitalcampus 1, CH-8596 Munsterlingen, Switzerland.; Andreisek, G (corresponding author), Univ Zurich, Zurich, Switzerland.	gustav@andreisek.de		Andreisek, Gustav/0000-0001-7000-9033				Bonicoli Enrico, 2014, Eur J Orthop Surg Traumatol, V24, P1249, DOI 10.1007/s00590-013-1304-0; Borton Z, 2021, RADIOGRAPHY, V27, P260, DOI 10.1016/j.radi.2020.08.001; Bowman A, 2016, KNEE, V23, P203, DOI 10.1016/j.knee.2015.11.013; Goossen A, 2012, METHOD INFORM MED, V51, P406, DOI 10.3414/ME11-02-0033; Maderbacher G, 2017, INT ORTHOP, V41, P1553, DOI 10.1007/s00264-017-3408-3; Mooney R, 2013, J CHILD ORTHOP, V7, P543, DOI 10.1007/s11832-013-0530-7; Najefi AA., 2020, FOOT EDINB, V44; Schock J, 2021, RADIOL-ARTIF INTELL, V3, DOI 10.1148/ryai.2020200198; Zahn RK, 2019, KNEE SURG SPORT TR A, V27, P1470, DOI 10.1007/s00167-018-5056-6	9	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2021	3	2							e200300	10.1148/ryai.2021200300	http://dx.doi.org/10.1148/ryai.2021200300			2	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z3LD	33939771	Green Published			2022-12-18	WOS:000826483100009
J	Cadrin-Chenevert, A				Cadrin-Chenevert, Alexandre			Toward a More Quantitative and Specific Representation of Normality	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Cadrin-Chenevert, Alexandre] Laval Univ, CISSS Lanaudiere, Dept Med Imaging, 1000 Blvd St Anne, St Charles Borromee, PQ J6E 6J2, Canada	Laval University	Cadrin-Chenevert, A (corresponding author), Laval Univ, CISSS Lanaudiere, Dept Med Imaging, 1000 Blvd St Anne, St Charles Borromee, PQ J6E 6J2, Canada.	alexandre.cadrin-chenevert.1@ulaval.ca						Castiglione J., 2021, RADIOL-ARTIF INTELL, V3, DOI DOI 10.1148/RYAI.2021200130; Chartrand G, 2017, RADIOGRAPHICS, V37, P2113, DOI 10.1148/rg.2017170077; Gilligan LA, 2020, PEDIATR RADIOL, V50, P455, DOI 10.1007/s00247-019-04562-7; Hartung MP, 2020, RADIOGRAPHICS, V40, P1658, DOI 10.1148/rg.2020200020; Pan I, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190198; Prado CMM, 2012, CLIN NUTR, V31, P583, DOI 10.1016/j.clnu.2012.06.010; Reyes M, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190043; Rister B, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00715-8; ROBINSON D, 1993, METHOD INFORM MED, V32, P225; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Soudack M, 2012, PEDIATR RADIOL, V42, P343, DOI 10.1007/s00247-011-2302-1; Weston AD, 2019, RADIOLOGY, V290, P669, DOI 10.1148/radiol.2018181432	12	0	0	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2021	3	2							e210005	10.1148/ryai.2021210005	http://dx.doi.org/10.1148/ryai.2021210005			2	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z3LD	33939776	Green Published			2022-12-18	WOS:000826483100011
J	Erickson, BJ; Kitamura, F				Erickson, Bradley J.; Kitamura, Felipe			Magician's Corner: 8: How to Connect an Artificial Intelligence Tool to PACS	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Erickson, Bradley J.] Mayo Clin, Dept Radiol, 200 First St SW, Rochester, MN 55905 USA; [Kitamura, Felipe] Univ Fed Sao Paulo, Dept Diagnost Imaging, Sao Paulo, Brazil	Mayo Clinic; Universidade Federal de Sao Paulo (UNIFESP)	Erickson, BJ (corresponding author), Mayo Clin, Dept Radiol, 200 First St SW, Rochester, MN 55905 USA.	bje@mayo.edu	Kitamura, Felipe Campos/AAC-7075-2021; Kitamura, Felipe Campos/AAC-4368-2021	Kitamura, Felipe Campos/0000-0002-9992-5630; Erickson, Bradley/0000-0001-7926-6095				BIDGOOD WD, 1992, RADIOGRAPHICS, V12, P345, DOI 10.1148/radiographics.12.2.1561424; Erickson BJ, 2019, RADIOL-ARTIF INTELL, V1, DOI [10.1148/ryai.2019190072, 10.1148/ryai.2019190113, 10.1148/ryai.2019190126]; Filice RW, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190095; Hofmanninger J, ARXIV200111767; Horii SC, 1997, RADIOGRAPHICS, V17, P1297, DOI 10.1148/radiographics.17.5.9308117; Mildenberger P, 2002, EUR RADIOL, V12, P920, DOI 10.1007/s003300101100; Mongan J, RADIOLARTIFINTELL202, V2	7	0	0	1	3	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2021	3	1							e200105	10.1148/ryai.2021200105	http://dx.doi.org/10.1148/ryai.2021200105			4	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z3HE	33937854	Green Published			2022-12-18	WOS:000826472300009
J	Stember, JN; Celik, H; Gutman, D; Swinburne, N; Young, R; Eskreis-Winkler, S; Holodny, A; Jambawalikar, S; Wood, BJ; Chang, PD; Krupinski, E; Bagci, U				Stember, Joseph N.; Celik, Haydar; Gutman, David; Swinburne, Nathaniel; Young, Robert; Eskreis-Winkler, Sarah; Holodny, Andrei; Jambawalikar, Sachin; Wood, Bradford J.; Chang, Peter D.; Krupinski, Elizabeth; Bagci, Ulas			Integrating Eye Tracking and Speech Recognition Accurately Annotates MR Brain Images for Deep Learning: Proof of Principle	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Article							SEGMENTATION; PLATFORM	Purpose: To generate and assess an algorithm combining eye tracking and speech recognition to extract brain lesion location labels automatically for deep learning (DL). Materials and Methods: In this retrospective study, 700 two-dimensional brain tumor MRI scans from the Brain Tumor Segmentation database were clinically interpreted. For each image, a single radiologist dictated a standard phrase describing the lesion into a microphone, simulating clinical interpretation. Eye-tracking data were recorded simultaneously. Using speech recognition, gaze points corresponding to each lesion were obtained. Lesion locations were used to train a keypoint detection convolutional neural network to find new lesions. A network was trained to localize lesions for an independent test set of 85 images. The statistical measure to evaluate our method was percent accuracy. Results: Eye tracking with speech recognition was 92% accurate in labeling lesion locations from the training dataset, thereby demonstrating that fully simulated interpretation can yield reliable tumor location labels. These labels became those that were used to train the DL network. The detection network trained on these labels predicted lesion location of a separate testing set with 85% accuracy. Conclusion: The DL network was able to locate brain tumors on the basis of training data that were labeled automatically from simulated clinical image interpretation. (C) RSNA, 2020	[Stember, Joseph N.; Gutman, David; Swinburne, Nathaniel; Young, Robert; Eskreis-Winkler, Sarah; Holodny, Andrei] Mem Sloan Kettering Canc Ctr, Dept Radiol, 1275 York Ave, New York, NY 10065 USA; [Celik, Haydar; Wood, Bradford J.] NIH, Ctr Clin, Bethesda, MD 20892 USA; [Jambawalikar, Sachin] Columbia Univ, Dept Radiol, Med Ctr, New York, NY USA; [Chang, Peter D.] Univ Calif Irvine, Dept Radiol, Irvine, CA USA; [Krupinski, Elizabeth] Emory Univ, Dept Radiol & Imaging Sci, Atlanta, GA 30322 USA; [Bagci, Ulas] Univ Cent Florida, Ctr Res Comp Vis, Orlando, FL 32816 USA	Memorial Sloan Kettering Cancer Center; National Institutes of Health (NIH) - USA; NIH Clinical Center (CC); Columbia University; University of California System; University of California Irvine; Emory University; State University System of Florida; University of Central Florida	Stember, JN (corresponding author), Mem Sloan Kettering Canc Ctr, Dept Radiol, 1275 York Ave, New York, NY 10065 USA.	joestember@gmail.com	; Wood, Bradford/M-7995-2017	Swinburne, Nathaniel/0000-0001-5831-7287; Wood, Bradford/0000-0002-4297-0051; Jambawalikar, Sachin/0000-0003-1839-6798; Stember, Joseph/0000-0003-3169-9590; Eskreis-Winkler, Sarah/0000-0003-2427-3532; Holodny, Andrei/0000-0002-1159-2705				Amazon Mechanical Turk, AM MECH TURK; Charron O, 2018, COMPUT BIOL MED, V95, P43, DOI 10.1016/j.compbiomed.2018.02.004; Chartrand G, 2017, RADIOGRAPHICS, V37, P2113, DOI 10.1148/rg.2017170077; Dikici E, ARXIV 190804701 PREP; Fedorov A, 2012, MAGN RESON IMAGING, V30, P1323, DOI 10.1016/j.mri.2012.05.001; fiverr website, US; Geis JR, 2019, RADIOLOGY, V293, P436, DOI 10.1148/radiol.2019191586; Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5; Kaggle, FAC KEYP DET; Khosravan N, 2019, MED IMAGE ANAL, V51, P101, DOI 10.1016/j.media.2018.10.010; Khosravan N, 2017, LECT NOTES COMPUT SC, V10081, P94, DOI 10.1007/978-3-319-61188-4_9; Kikinis R, 2011, IEEE ENG MED BIO, P6982, DOI 10.1109/IEMBS.2011.6091765; Kim Youngjun, 2018, AMIA Annu Symp Proc, V2018, P663; Kohli M, 2017, AM J ROENTGENOL, V208, P754, DOI 10.2214/AJR.16.17224; Langlotz CP, 2019, RADIOLOGY, V291, P781, DOI 10.1148/radiol.2019190613; Lionbridge website, US; Liu Y, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0185844; MD.ai website, PLATF MED AI; Neri E, 2019, INSIGHTS IMAGING, V10, DOI 10.1186/s13244-019-0738-2; Orting S, ARXIV 190209159 PREP; Rubin DL, 2019, TOMOGRAPHY, V5, P170, DOI 10.18383/j.tom.2018.00055; Shirokikh B, ARXIV 190902799 PREP; Slicer, 3D SLIC WEBS; Stember JN, 2019, J DIGIT IMAGING, V32, P597, DOI 10.1007/s10278-019-00220-4; Tang A, 2018, CAN ASSOC RADIOL J, V69, P120, DOI 10.1016/j.carj.2018.02.002; XNAT website, US; Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015	27	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JAN	2021	3	1							e200047	10.1148/ryai.2020200047	http://dx.doi.org/10.1148/ryai.2020200047			7	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	2Z3HE	33842890	Green Published, Bronze			2022-12-18	WOS:000826472300005
J	Tenenholtz, NA; Wood, MJ				Tenenholtz, Neil A.; Wood, Monica J.			Automated De-Identification: Embracing the Imperfect	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Tenenholtz, Neil A.] Microsoft Res New England, 1 Mem Dr, Cambridge, MA 02142 USA; [Wood, Monica J.] Massachusetts Gen Hosp, Dept Radiol, Boston, MA USA		Tenenholtz, NA (corresponding author), Microsoft Res New England, 1 Mem Dr, Cambridge, MA 02142 USA.	neil.tenenholtz@microsoft.com		Tenenholtz, Neil/0000-0003-1250-3716				Brown TB, ARXIV200514165V4 CSC; Flanders AE, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190211; Kahn CE, 2009, RADIOLOGY, V252, P852, DOI 10.1148/radiol.2523081992; Radford A., 2019, OPENAI BLOG, V1, P9, DOI DOI 10.18653/V1/P19-1195; Shih G, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180041; Steinkamp JM, 2020, RADIOL ARTIF INTELL, V2	6	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2020	2	6							e200230	10.1148/ryai.2020200230	http://dx.doi.org/10.1148/ryai.2020200230			3	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CZ	33939785	Green Published			2022-12-18	WOS:000826480100012
J	Flanders, AE; Prevedello, LM; Shih, G; Halabi, SS; Kalpathy-Cramer, J; Ball, R; Mongan, JT; Stein, A; Kitamura, FC; Lungren, MP; Choudhary, G; Cala, L; Coelho, L; Mogensen, M; Moron, F; Miller, E; Ikuta, I; Zohrabian, V; Mc-Donnell, O; Lincoln, C; Shah, L; Joyner, D; Agarwal, A; Lee, RK; Nath, J				Flanders, Adam E.; Prevedello, Luciano M.; Shih, George; Halabi, Safwan S.; Kalpathy-Cramer, Jayashree; Ball, Robyn; Mongan, John T.; Stein, Anouk; Kitamura, Felipe C.; Lungren, Matthew P.; Choudhary, Gagandeep; Cala, Lesley; Coelho, Luiz; Mogensen, Monique; Moron, Fanny; Miller, Elka; Ikuta, Ichiro; Zohrabian, Vahe; Mc-Donnell, Olivia; Lincoln, Christie; Shah, Lubdha; Joyner, David; Agarwal, Amit; Lee, Ryan K.; Nath, Jaya		RSNA-ASNR 2019 Brain Hemorrhage CT	Construction of a Machine Learning Dataset through Collaboration: The RSNA 2019 Brain CT Hemorrhage Challenge (vol 2, e190211, 2020)	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Correction													Kitamura, Felipe Campos/AAC-7075-2021; Lee, Ryan/HCI-5836-2022	Kitamura, Felipe Campos/0000-0002-9992-5630; 				Flanders AE, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190211	1	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2020	2	4												1	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CX					2022-12-18	WOS:000826472900014
J	Flanders, AE				Flanders, Adam E.			Construction of a Machine Learning Dataset through Collaboration (vol 2, 10.1148/ryai.2020209002, 2020)	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Correction																		Flanders AE, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190211	1	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2020	2	4								10.1148/ryai.2020190211	http://dx.doi.org/10.1148/ryai.2020190211			1	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CX		Green Published, Bronze			2022-12-18	WOS:000826472900015
J	Halabi, SS				Halabi, Safwan S.			Taking Matters into Your Own Hands	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Halabi, Safwan S.] Stanford Univ, Dept Radiol, Sch Med, 300 Pasteur Dr,MC 5105, Stanford, CA 94305 USA		Halabi, SS (corresponding author), Stanford Univ, Dept Radiol, Sch Med, 300 Pasteur Dr,MC 5105, Stanford, CA 94305 USA.	safwan.halabi@stanford.edu	Halabi, Safwan/H-2279-2018	Halabi, Safwan/0000-0003-1317-984X				Berst MJ, 2001, AM J ROENTGENOL, V176, P507, DOI 10.2214/ajr.176.2.1760507; Greulich W., 1999, RADIOGRAPHIC ATLAS B; Halabi SS, 2019, RADIOLOGY, V290, P498, DOI 10.1148/radiol.2018180736; Harvey H., 2019, ARTIFICIAL INTELLIGE, P61; JOHNSON GF, 1973, AM J ROENTGENOL, V118, P320, DOI 10.2214/ajr.118.2.320; Larson DB, 2018, RADIOLOGY, V287, P313, DOI 10.1148/radiol.2017170236; Lee H, 2017, J DIGIT IMAGING, V30, P427, DOI 10.1007/s10278-017-9955-8; Pan I, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190198; Pan I, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019190053; Thodberg HH, 2010, ACAD RADIOL, V17, P1425, DOI 10.1016/j.acra.2010.06.007	10	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	JUL	2020	2	4							e200150	10.1148/ryai.2020200150	http://dx.doi.org/10.1148/ryai.2020200150			2	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CX	33939791	Green Published			2022-12-18	WOS:000826472900013
J	Brody, WR				Brody, William R.			Radiology and Technology: Where We've Been, Where We're Going-And Why I Am So Excited	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Brody, William R.] Salk Inst Biol Studies, 10010 N Taney Pines Rd, La Jolla, CA 92037 USA		Brody, WR (corresponding author), Salk Inst Biol Studies, 10010 N Taney Pines Rd, La Jolla, CA 92037 USA.	wrbrody@gmail.com							0	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2020	2	3							e190205	10.1148/ryai.2020190205	http://dx.doi.org/10.1148/ryai.2020190205			2	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CW	33937826	Bronze, Green Published			2022-12-18	WOS:000826470300006
J	Flanders, AE; Prevedello, LM; Shih, G; Halabi, SS; Kalpathy-Cramer, J; Ball, R; Mongan, JT; Stein, A; Kitamura, FC; Lungren, MP; Choudhary, G; Cala, L; Coelho, L; Mogensen, M; Moron, F; Miller, E; Ikuta, I; Zohrabian, V; Mc-Donnell, O; Lincoln, C; Shah, L; Joyner, D; Agarwal, A; Lee, RK; Nath, J				Flanders, Adam E.; Prevedello, Luciano M.; Shih, George; Halabi, Safwan S.; Kalpathy-Cramer, Jayashree; Ball, Robyn; Mongan, John T.; Stein, Anouk; Kitamura, Felipe C.; Lungren, Matthew P.; Choudhary, Gagandeep; Cala, Lesley; Coelho, Luiz; Mogensen, Monique; Moron, Fanny; Miller, Elka; Ikuta, Ichiro; Zohrabian, Vahe; Mc-Donnell, Olivia; Lincoln, Christie; Shah, Lubdha; Joyner, David; Agarwal, Amit; Lee, Ryan K.; Nath, Jaya		RSNA-ASNR 2019 Brain Hemorrhage	Construction of a Machine Learning Dataset through Collaboration (vol 2, 10.1148/ryai.2020190211, 2020)	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Correction													Lee, Ryan/HCI-5836-2022					Flanders AE, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190211	1	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2020	2	3												1	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CW					2022-12-18	WOS:000826470300008
J	Flanders, AE				Flanders, Adam E.			Construction of a Machine Learning Dataset through Collaboration (vol 2, 10.1148/ryai.2020209002, 2020)	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Correction																		HEPP MB, 2020, RADIOLOGY ARTIFICIAL, V2, DOI DOI 10.1148/RYAI.2020209002	1	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAY	2020	2	3												1	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CW					2022-12-18	WOS:000826470300009
J	Kahn, CE				Kahn, Charles E., Jr.			Looking Ahead	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material												ckahn@rsna.org		Kahn, Charles/0000-0002-6654-7434					0	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2019	1	6							e194003	10.1148/ryai.2019194003	http://dx.doi.org/10.1148/ryai.2019194003			1	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CQ	33937808	Bronze, Green Accepted			2022-12-18	WOS:000826296100010
J	Schoepf, UJ; Abadia, AF				Schoepf, U. Joseph; Abadia, Andres F.			Greasing the Skids: Deep Learning for Fully Automated Quantification of Epicardial Fat	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Schoepf, U. Joseph; Abadia, Andres F.] Med Univ South Carolina, Div Cardiovasc Imaging, Dept Radiol & Radiol Sci, Ashley River Town,25 Courtenay Dr,MSC 226, Charleston, SC 29425 USA	Medical University of South Carolina	Schoepf, UJ (corresponding author), Med Univ South Carolina, Div Cardiovasc Imaging, Dept Radiol & Radiol Sci, Ashley River Town,25 Courtenay Dr,MSC 226, Charleston, SC 29425 USA.	schoepf@musc.edu		Abadia, Andres/0000-0002-8611-2614				Abazid RM, 2017, J THORAC IMAG, V32, P378, DOI 10.1097/RTI.0000000000000296; Bastarrika G, 2010, ACAD RADIOL, V17, P727, DOI 10.1016/j.acra.2010.01.015; Commandeur F, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019190045; Francisco, IN PRESS; Motwani M, 2017, EUR HEART J, V38, P500, DOI 10.1093/eurheartj/ehw188; Retson TA, 2019, J THORAC IMAG, V34, P192, DOI 10.1097/RTI.0000000000000385; Rodriguez-Granillo GA, 2019, J THORAC IMAG, V34, P33, DOI 10.1097/RTI.0000000000000370; Schwartz FR, 2019, J THORAC IMAG, V34, P12, DOI 10.1097/RTI.0000000000000369; Spearman JV, 2014, EUR RADIOL, V24, P519, DOI 10.1007/s00330-013-3052-2; Tesche C, 2018, RADIOLOGY, V288, P64, DOI 10.1148/radiol.2018171291	10	0	0	0	2	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2019	1	6							e190140	10.1148/ryai.2019190140	http://dx.doi.org/10.1148/ryai.2019190140			2	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CQ	33937806	Bronze, Green Published			2022-12-18	WOS:000826296100008
J	Siegel, EL				Siegel, Eliot L.			Making AI Even Smarter Using Ensembles: A Challenge to Future Challenges and Implications for Clinical Care	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Siegel, Eliot L.] Univ Maryland, Sch Med, Dept Diagnost Radiol & Nucl Med, 10 N Greene St, Baltimore, MD 21201 USA; [Siegel, Eliot L.] Univ Maryland, Sch Med, VA Maryland Healthcare Syst, 10 N Greene St, Baltimore, MD 21201 USA		Siegel, EL (corresponding author), Univ Maryland, Sch Med, Dept Diagnost Radiol & Nucl Med, 10 N Greene St, Baltimore, MD 21201 USA.; Siegel, EL (corresponding author), Univ Maryland, Sch Med, VA Maryland Healthcare Syst, 10 N Greene St, Baltimore, MD 21201 USA.	esiegel@som.umaryland.edu		Siegel, Eliot/0000-0002-7458-6281				Bodily KD, 2005, ACAD RADIOL, V12, P67, DOI 10.1016/j.acra.2004.10.055; Chalian M, 2016, AM J ROENTGENOL, V206, P1217, DOI 10.2214/AJR.15.14540; Chan S, 2019, BRIT J RADIOL, V92, DOI 10.1259/bjr.20180416; Coffey K, 2017, AM J ROENTGENOL, V208, P1386, DOI 10.2214/AJR.16.16871; Halabi SS, 2019, RADIOLOGY, V290, P498, DOI 10.1148/radiol.2018180736; Hukkinen K, 2006, ACTA RADIOL, V47, P655, DOI 10.1080/02841850600803842; Lakhman Y, 2016, EUR RADIOL, V26, P2089, DOI 10.1007/s00330-015-4040-5; Ma Y, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, P1, DOI [10.1007/978-1-4419-9326-7, 10.1007/978-1-4419-9326-7_1]; Pan I, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019190053; Zan E, 2010, RADIOLOGY, V255, P135, DOI 10.1148/radiol.09090831	10	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	NOV	2019	1	6							e190187	10.1148/ryai.2019190187	http://dx.doi.org/10.1148/ryai.2019190187			2	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CQ	33937807	Green Published			2022-12-18	WOS:000826296100009
J	Liu, TT				Liu, Tiffany Ting			Deep Learning Approaches Substantially Improve Automated Extraction of Information from Free-Text Medical Reports	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material									[Liu, Tiffany Ting] Stanford Univ, Lucas Ctr Imaging, Dept Radiol, 1201 Welch Rd, Stanford, CA 94305 USA; [Liu, Tiffany Ting] Roche Sequencing Solut, Santa Clara, CA 95050 USA		Liu, TT (corresponding author), Stanford Univ, Lucas Ctr Imaging, Dept Radiol, 1201 Welch Rd, Stanford, CA 94305 USA.; Liu, TT (corresponding author), Roche Sequencing Solut, Santa Clara, CA 95050 USA.	ttl2@alumni.stanford.edu		Liu, Tiffany Ting/0000-0002-7450-9059				Chen MC, 2018, RADIOLOGY, V286, P845, DOI 10.1148/radiol.2017171115; Hassanpour S, 2016, J DIGIT IMAGING, V29, P59, DOI 10.1007/s10278-015-9823-3; Liu Y, ARXIV 170302442; Pennington Jeffrey., 2014, P 2014 C EMP METH NA, P1532, DOI [10.3115/v1/D14-1162, DOI 10.3115/V1/D14-1162]; Qiu JX, 2018, IEEE J BIOMED HEALTH, V22, P244, DOI 10.1109/JBHI.2017.2700722; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Steinkamp JM, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019180052	7	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	SEP	2019	1	5							e190118	10.1148/ryai.2019190118	http://dx.doi.org/10.1148/ryai.2019190118			2	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CP	33939786	Green Published			2022-12-18	WOS:000826294400005
J	Kahn, CE				Kahn, Charles E., Jr.			Do the Right Thing	RADIOLOGY-ARTIFICIAL INTELLIGENCE			English	Editorial Material												ckahn@rsna.org						Anderson Michael, 2019, AMA J Ethics, V21, pE125, DOI 10.1001/amajethics.2019.125; [Anonymous], ROYAL AUSTR NZ COLL; [Anonymous], ETH RAD EUR N AM MUL; Crigger Elliott, 2019, AMA J Ethics, V21, pE188, DOI 10.1001/amajethics.2019.188; Jalal S, 2019, CAN ASSOC RADIOL J, V70, P10, DOI 10.1016/j.carj.2018.09.004; Kohli M, 2018, J AM COLL RADIOL, V15, P1317, DOI 10.1016/j.jacr.2018.05.020	6	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	2638-6100			RADIOL-ARTIF INTELL	Radiology-Artificial Intelligence	MAR	2019	1	2							e194001	10.1148/ryai.2019194001	http://dx.doi.org/10.1148/ryai.2019194001			1	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	VL3CM	33937790	Green Published			2022-12-18	WOS:000826288900006
