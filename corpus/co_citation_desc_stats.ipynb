{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run './model/multi_corpus.py'\n",
    "%run './constants.py'\n",
    "\n",
    "sns.set(rc = {'figure.figsize':(15,8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender Studies Graph with 1070 nodes and 2505 edges\n",
      "Geometry Graph with 749 nodes and 1262 edges\n",
      "Geophysics Graph with 22475 nodes and 119997 edges\n",
      "Economics Graph with 5710 nodes and 81283 edges\n",
      "Language & Linguistics Graph with 1925 nodes and 13565 edges\n",
      "Probability & Statistics Graph with 2802 nodes and 13312 edges\n",
      "Material Engineering Graph with 32157 nodes and 450244 edges\n",
      "Artificial Intelligence Graph with 2817 nodes and 15003 edges\n",
      "Sociology Graph with 3037 nodes and 31327 edges\n",
      "International Business Graph with 4191 nodes and 82833 edges\n",
      "Political Science Graph with 3367 nodes and 21319 edges\n",
      "Genetics & Genomics Graph with 11868 nodes and 73011 edges\n",
      "Immunology Graph with 17730 nodes and 271452 edges\n",
      "Human Resources & Organizations Graph with 4657 nodes and 43787 edges\n",
      "Ethnic & Cultural Studies Graph with 747 nodes and 1502 edges\n",
      "Neurology Graph with 22058 nodes and 348235 edges\n"
     ]
    }
   ],
   "source": [
    "corpora = co_citation_graphs()\n",
    "Gs = {field_name: corpus['G'] for (field_name, corpus) in corpora.items()}\n",
    "Dfs = {field_name: corpus['Df'] for (field_name, corpus) in corpora.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "\n",
    "for field_name, corpus in corpora.items():\n",
    "\n",
    "    print(field_name)\n",
    "\n",
    "    df = corpus['Df']\n",
    "    G = corpus['G']\n",
    "\n",
    "    start_date, end_date = (\n",
    "        df\n",
    "        .filter(pl.col('Doi').is_in(list(G.nodes)))\n",
    "        .select(pl.col('Date').min().alias('Min'), pl.col('Date').max().alias('Max'))\n",
    "        .row(0)\n",
    "    )\n",
    "\n",
    "    degree = dict(G.degree()).values()\n",
    "\n",
    "    large_component = max(nx.connected_components(G), key=len)\n",
    "    G_large_component = G.subgraph(large_component)\n",
    "\n",
    "    d[field_name] = {\n",
    "        'Nodes': nx.number_of_nodes(G),\n",
    "        'Edges': nx.number_of_edges(G),\n",
    "        'Density': nx.density(G),\n",
    "        'AvgDegree': sum(degree) / len(degree),\n",
    "        'AvgClustering': nx.average_clustering(G),\n",
    "        'DiameterLargestComponent': nx.diameter(G.subgraph(large_component)),\n",
    "        'AvgShortestPath': nx.average_shortest_path_length(G_large_component),\n",
    "        'ShortestPath': nx.shortest_path_length(G),\n",
    "        'Triangles': sum(nx.triangles(G).values()) / 3,\n",
    "        'Gini': gini(degree),\n",
    "        'Louvain': len(nx_comm.louvain_communities(G)),\n",
    "        'Components': len(list(nx.connected_components(G))),\n",
    "        'Clustering': nx.average_clustering(G),\n",
    "        'Transitivity': nx.transitivity(G),\n",
    "        'Centralization': float((len(G) * max(degree) - sum(degree))) / (len(G)-1)**2,\n",
    "        'Isolates': nx.number_of_isolates(G),\n",
    "        'Loops': nx.number_of_selfloops(G),\n",
    "        # 'LabelPropagation': len(nx_comm.label_propagation_communities(G)),\n",
    "    }\n",
    "\n",
    "df = pl.DataFrame([{'Field': field_name} | desc_d for field_name, desc_d in d.items()])\n",
    "\n",
    "latex = df.to_pandas().to_latex(\n",
    "    index=False,\n",
    "    na_rep=' ',\n",
    "    bold_rows=True,\n",
    "    float_format=\"%.2f\",\n",
    ")\n",
    "with open(os.path.join(LATEX_TABLE_PATH, 'co_citation_desc_stats.tex'), 'w+') as file:\n",
    "    file.write(latex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "\n",
    "for field_name, corpus in corpora.items():\n",
    "\n",
    "    print(field_name)\n",
    "\n",
    "    df = corpus['Df']\n",
    "    G = corpus['G']\n",
    "    nodes = list(G.nodes)\n",
    "\n",
    "    large_component = max(nx.connected_components(G), key=len)\n",
    "    G_large_component = G.subgraph(large_component)\n",
    "\n",
    "    # NODES EDGES\n",
    "    number_of_nodes = nx.number_of_nodes(G)\n",
    "    number_of_edges = nx.number_of_edges(G)\n",
    "\n",
    "    # DENSITY\n",
    "    density = nx.density(G)\n",
    "\n",
    "    # TRIANGLES\n",
    "    triangles = sum(nx.triangles(G).values()) / 3\n",
    "\n",
    "    # DEGREE\n",
    "    degree = dict(G.degree()).values()\n",
    "    avg_degree = sum(degree) / len(degree)\n",
    "\n",
    "    # GINI\n",
    "    degrees = G.degree()\n",
    "    gini = 1 - sum((degrees[n] / len(G.edges))**2 for n in G.nodes)\n",
    "\n",
    "    # COMPONENTS\n",
    "    n_connected_components = len(list(nx.connected_components(G)))\n",
    "\n",
    "    # DIAMETER\n",
    "    \n",
    "    diameter = nx.diameter(G.subgraph(large_component))\n",
    "    \n",
    "    # SHORTEST PATH\n",
    "    shortest_path = nx.shortest_path_length(G)\n",
    "\n",
    "    # AVG SHORTEST PATH\n",
    "    average_shortest_path_length = nx.average_shortest_path_length(G_large_component)\n",
    "\n",
    "    # CLUSTERING\n",
    "    clustering = nx.average_clustering(G)\n",
    "    transitivity = nx.transitivity(G)\n",
    "\n",
    "    # DATES\n",
    "    start_date, end_date = (\n",
    "        df\n",
    "        .filter(pl.col('Doi').is_in(nodes))\n",
    "        .select(\n",
    "            pl.col('Date').min().alias('Min'),\n",
    "            pl.col('Date').max().alias('Max'),\n",
    "        )\n",
    "        .row(0)\n",
    "    )\n",
    "\n",
    "    # CENTRALIZATION\n",
    "    degrees = dict(G.degree()).values()\n",
    "    centralization = float((len(G) * max(degrees) - sum(degrees))) / (len(G)-1)**2\n",
    "\n",
    "    # COMMUNITIES\n",
    "    louvain_communities = len(nx_comm.louvain_communities(G))\n",
    "    label_propagation_communities = len(nx_comm.label_propagation_communities(G))\n",
    "\n",
    "    # ISOLATES LOOPS CYCLES\n",
    "    isolates = nx.number_of_isolates(G)\n",
    "    loops = nx.number_of_selfloops(G)\n",
    "\n",
    "    d[field_name] = {\n",
    "        'Nodes': number_of_nodes,\n",
    "        'Edges': number_of_edges,\n",
    "        'Density': round(density, 4),\n",
    "        'Diameter': diameter,\n",
    "        'Geodesic': average_shortest_path_length,\n",
    "        'Triangles': triangles,\n",
    "        'AvgDegree': round(avg_degree, 4),\n",
    "        'Gini': round(gini, 4),\n",
    "        'Louvain': louvain_communities,\n",
    "        'Components': n_connected_components,\n",
    "        'Clustering': round(clustering, 4),\n",
    "        'Transitivity': round(transitivity, 4),\n",
    "        'StartDate': start_date,\n",
    "        'EndDate': end_date,\n",
    "        'Centralization': round(centralization, 4),\n",
    "        'Isolates': isolates,\n",
    "        'Loops': loops,\n",
    "    }\n",
    "\n",
    "ds = [{'Field': field_name} | desc_d for field_name, desc_d in d.items()]\n",
    "df = pl.DataFrame(ds)\n",
    "\n",
    "latex = df.to_pandas().to_latex(\n",
    "    index=False,\n",
    "    na_rep=' ',\n",
    "    bold_rows=True,\n",
    "    float_format=\"%.2f\",\n",
    ")\n",
    "with open(os.path.join(LATEX_TABLE_PATH, 'co_citation_desc_stats.tex'), 'w+') as file:\n",
    "    file.write(latex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
