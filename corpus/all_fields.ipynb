{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run './model/multi_corpus.py'\n",
    "%run './constants.py'\n",
    "\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "import umap.umap_ as umap\n",
    "\n",
    "import functools\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora = citation_graphs()\n",
    "Gs = {field_name: corpus['G'] for (field_name, corpus) in corpora.items()}\n",
    "Dfs = {field_name: corpus['Df'] for (field_name, corpus) in corpora.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorization_method(method, texts):\n",
    "    match method:\n",
    "        case 'tfidf':\n",
    "            tfidf = TfidfVectorizer()\n",
    "            vecs = tfidf.fit_transform(texts.to_list()).toarray()\n",
    "        case 'doc2vec':\n",
    "            documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(texts.str.split(' ').to_list())]\n",
    "            model = Doc2Vec(documents, vector_size=100, window=2, min_count=1, workers=4)\n",
    "            vecs = np.array([model.dv[i] for i in range(len(texts))])\n",
    "    return vecs\n",
    "\n",
    "def format_field_name(field_name):\n",
    "    if ' & ' in field_name:\n",
    "        return ' &\\n'.join(field_name.split(' & '))\n",
    "    elif ' ' in field_name:\n",
    "        return '\\n'.join(field_name.split(' '))\n",
    "    else:\n",
    "        return field_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5_000\n",
    "\n",
    "df_fields = []\n",
    "for field_name, df in Dfs.items():\n",
    "\n",
    "    G = Gs[field_name]\n",
    "    in_deg = G.in_degree()\n",
    "    sorted_in_deg = sorted(in_deg, key=lambda tup: tup[1])\n",
    "    top_in_deg = [doi for doi, _ in sorted_in_deg][:n]\n",
    "\n",
    "    df_fields.append(\n",
    "        df\n",
    "        .filter(pl.col('Doi').is_in(top_in_deg))\n",
    "        .select(\n",
    "            pl.col('Doi'),\n",
    "            pl.col('Text').arr.join(' '),\n",
    "            pl.lit(field_name).alias('Field'),\n",
    "        )\n",
    "    )\n",
    "df_fields = pl.concat(df_fields)\n",
    "\n",
    "print(df_fields.shape)\n",
    "\n",
    "texts = df_fields['Text'].to_numpy()\n",
    "fields = df_fields['Field'].to_numpy()\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_embedding = tfidf.fit_transform(texts)\n",
    "\n",
    "reducer = umap.UMAP(random_state=42)\n",
    "embs = reducer.fit_transform(tfidf_embedding)\n",
    "\n",
    "df_fields = (\n",
    "    df_fields\n",
    "    .with_columns(pl.Series('Embedding', embs))\n",
    "    .with_columns(\n",
    "        pl.col('Embedding').arr.first().alias('x'),\n",
    "        pl.col('Embedding').arr.last().alias('y'),\n",
    "    )\n",
    ")\n",
    "\n",
    "print(df_fields.shape)\n",
    "\n",
    "centroids = (\n",
    "    df_fields\n",
    "    .groupby('Field')\n",
    "    .agg(\n",
    "        pl.col('x').mean(),\n",
    "        pl.col('y').mean(),\n",
    "    )\n",
    ")\n",
    "\n",
    "print(centroids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set_theme(style='white')\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "g = sns.scatterplot(data=df_fields, x=\"x\", y=\"y\", hue=\"Field\", alpha=0.5, edgecolor='k') # , palette=\"deep\", edgecolor='none'\n",
    "\n",
    "for (field_name, x, y) in centroids.rows():\n",
    "    field_name = format_field_name(field_name)\n",
    "    plt.text(x, y, field_name, horizontalalignment='center', size='medium', color='black', weight='semibold')\n",
    "\n",
    "\n",
    "sns.despine(bottom = True, left = True)\n",
    "g.set(xlabel=None, ylabel=None, xticklabels=[], yticklabels=[])\n",
    "plt.legend(frameon=False)\n",
    "\n",
    "plt.savefig(\n",
    "    os.path.join(LATEX_FIGURES_PATH, 'all_tfidf_umap.png'), \n",
    "    transparent=True, \n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = centroids.select(['x', 'y']).to_numpy()\n",
    "\n",
    "distances = np.round(squareform(pdist(coords)), 2)\n",
    "\n",
    "dist_df = pl.from_numpy(distances)\n",
    "\n",
    "mask = np.triu(np.ones_like(dist_df))\n",
    "\n",
    "labels = [format_field_name(field_name) for field_name in centroids['Field']]\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(dist_df, annot=True, xticklabels=labels, yticklabels=labels, mask=mask)\n",
    "\n",
    "plt.savefig(\n",
    "    os.path.join(LATEX_FIGURES_PATH, 'all_tfidf_umap_distance_heatmap.png'), \n",
    "    transparent=True, \n",
    "    dpi=300,\n",
    "    bbox_inches='tight'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desc Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora = citation_graphs()\n",
    "Gs_citation = {field_name: corpus['G'] for (field_name, corpus) in corpora.items()}\n",
    "\n",
    "corpora = co_citation_graphs()\n",
    "Gs_co_citation = {field_name: corpus['G'] for (field_name, corpus) in corpora.items()}\n",
    "\n",
    "corpora = co_occurence_graphs()\n",
    "Gs_co_occurrence = {field_name: corpus['G'] for (field_name, corpus) in corpora.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fields = []\n",
    "nodes = []\n",
    "edges = []\n",
    "for field_name, G in Gs_citation.items():\n",
    "    fields.append(field_name)\n",
    "    nodes.append(nx.number_of_nodes(G))\n",
    "    edges.append(nx.number_of_edges(G))\n",
    "\n",
    "df_citation_desc = pd.DataFrame({\n",
    "    (\"\", \"Field\"): fields,\n",
    "    (\"Citation\", \"Nodes\"): nodes,\n",
    "    (\"Citation\", \"Edges\"): edges,\n",
    "})\n",
    "\n",
    "fields = []\n",
    "nodes = []\n",
    "edges = []\n",
    "for field_name, G in Gs_co_citation.items():\n",
    "    fields.append(field_name)\n",
    "    nodes.append(nx.number_of_nodes(G))\n",
    "    edges.append(nx.number_of_edges(G))\n",
    "\n",
    "df_co_citation_desc = pd.DataFrame({\n",
    "    (\"\", \"Field\"): fields,\n",
    "    (\"Co-Citation\", \"Nodes\"): nodes,\n",
    "    (\"Co-Citation\", \"Edges\"): edges,\n",
    "})\n",
    "\n",
    "fields = []\n",
    "nodes = []\n",
    "edges = []\n",
    "for field_name, G in Gs_co_occurrence.items():\n",
    "    fields.append(field_name)\n",
    "    nodes.append(nx.number_of_nodes(G))\n",
    "    edges.append(nx.number_of_edges(G))\n",
    "\n",
    "df_co_occurrence_desc = pd.DataFrame({\n",
    "    (\"\", \"Field\"): fields,\n",
    "    (\"Co-Occurrence\", \"Nodes\"): nodes,\n",
    "    (\"Co-Occurrence\", \"Edges\"): edges,\n",
    "})\n",
    "\n",
    "# merged = pd.merge(dfs, on=[('', 'Field')])\n",
    "# merged\n",
    "\n",
    "\n",
    "import functools\n",
    "dfs = [\n",
    "    df_citation_desc,\n",
    "    df_co_citation_desc,\n",
    "    df_co_occurrence_desc,\n",
    "]\n",
    "df_final = functools.reduce(lambda left, right: pd.merge(left, right, on=[('', 'Field')]), dfs)\n",
    "df_final\n",
    "\n",
    "latex = df_final.to_latex(\n",
    "    index=False,\n",
    "    na_rep=' ',\n",
    "    bold_rows=True,\n",
    "    float_format=\"%.2f\",\n",
    ")\n",
    "\n",
    "with open(os.path.join(LATEX_TABLE_PATH, 'all_desc_stats.tex'), 'w+') as file:\n",
    "    file.write(latex)\n",
    "\n",
    "print(latex)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora = citation_graphs()\n",
    "Gs_citation = {field_name: corpus['G'] for (field_name, corpus) in corpora.items()}\n",
    "\n",
    "corpora = co_citation_graphs()\n",
    "Gs_co_citation = {field_name: corpus['G'] for (field_name, corpus) in corpora.items()}\n",
    "\n",
    "corpora = co_occurence_graphs()\n",
    "Gs_co_occurrence = {field_name: corpus['G'] for (field_name, corpus) in corpora.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = {}\n",
    "for field_name, G in Gs_citation.items():\n",
    "    print(field_name)\n",
    "    communities[field_name] = nx.community.louvain_communities(G)\n",
    "\n",
    "citation_comms = {field_name: len(comms) for field_name, comms in communities.items()}\n",
    "\n",
    "df_citation_comms = pl.DataFrame({\n",
    "    \"Field\": list(citation_comms.keys()),\n",
    "    \"Citation\": list(citation_comms.values()),\n",
    "})\n",
    "\n",
    "communities = {}\n",
    "for field_name, G in Gs_co_citation.items():\n",
    "    print(field_name)\n",
    "    communities[field_name] = nx.community.louvain_communities(G)\n",
    "\n",
    "co_citation_comms = {field_name: len(comms) for field_name, comms in communities.items()}\n",
    "\n",
    "df_co_citation_comms = pl.DataFrame({\n",
    "    \"Field\": list(co_citation_comms.keys()),\n",
    "    \"Co-Citation\": list(co_citation_comms.values()),\n",
    "})\n",
    "\n",
    "communities = {}\n",
    "for field_name, G in Gs_co_occurrence.items():\n",
    "    print(field_name)\n",
    "    communities[field_name] = nx.community.louvain_communities(G)\n",
    "\n",
    "co_occurrence_comms = {field_name: len(comms) for field_name, comms in communities.items()}\n",
    "\n",
    "df_co_occurrence_comms = pl.DataFrame({\n",
    "    \"Field\": list(co_occurrence_comms.keys()),\n",
    "    \"Co-Occurrence\": list(co_occurrence_comms.values()),\n",
    "})\n",
    "\n",
    "dfs = [df_citation_comms, df_co_citation_comms, df_co_occurrence_comms]\n",
    "\n",
    "df_final = functools.reduce(lambda left, right: left.join(right, on='Field'), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex = df_final.to_pandas().to_latex(index=False, bold_rows=True)\n",
    "\n",
    "with open(os.path.join(LATEX_TABLE_PATH, 'all_louvain_communities.tex'), 'w+') as file:\n",
    "    file.write(latex)\n",
    "\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_final\n",
    "    .select(pl.exclude('Field'))\n",
    "    .select(\n",
    "        pl.pearson_corr('Citation', 'Co-Citation').alias('Citation Co-Citation'),\n",
    "        pl.pearson_corr('Citation', 'Co-Occurrence').alias('Citation Co-Occurrence'),\n",
    "        pl.pearson_corr('Co-Citation', 'Co-Occurrence').alias('Co-Citation Co-Occurrence'),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_comps = {}\n",
    "for field_name, G in Gs_citation.items():\n",
    "    print(field_name)\n",
    "    citation_comps[field_name] = nx.number_weakly_connected_components(G)\n",
    "\n",
    "df_citation_comps = pl.DataFrame({\n",
    "    \"Field\": list(citation_comps.keys()),\n",
    "    \"Citation\": list(citation_comps.values()),\n",
    "})\n",
    "\n",
    "co_citation_comps = {}\n",
    "for field_name, G in Gs_co_citation.items():\n",
    "    print(field_name)\n",
    "    co_citation_comps[field_name] = nx.number_connected_components(G)\n",
    "\n",
    "df_co_citation_comps = pl.DataFrame({\n",
    "    \"Field\": list(co_citation_comps.keys()),\n",
    "    \"Co-Citation\": list(co_citation_comps.values()),\n",
    "})\n",
    "\n",
    "co_occurrence_comps = {}\n",
    "for field_name, G in Gs_co_occurrence.items():\n",
    "    print(field_name)\n",
    "    co_occurrence_comps[field_name] = nx.number_connected_components(G)\n",
    "\n",
    "df_co_occurrence_comps = pl.DataFrame({\n",
    "    \"Field\": list(co_occurrence_comps.keys()),\n",
    "    \"Co-Occurrence\": list(co_occurrence_comps.values()),\n",
    "})\n",
    "\n",
    "dfs = [df_citation_comps, df_co_citation_comps, df_co_occurrence_comps]\n",
    "\n",
    "df_final = functools.reduce(lambda left, right: left.join(right, on='Field'), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex = df_final.to_pandas().to_latex(index=False, bold_rows=True)\n",
    "\n",
    "with open(os.path.join(LATEX_TABLE_PATH, 'all_components.tex'), 'w+') as file:\n",
    "    file.write(latex)\n",
    "\n",
    "print(latex)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora = co_citation_graphs()\n",
    "Gs = {field_name: corpus['G'] for (field_name, corpus) in corpora.items()}\n",
    "Dfs = {field_name: corpus['Df'] for (field_name, corpus) in corpora.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_degree(G):\n",
    "    degree = dict(G.degree()).values()\n",
    "    return sum(degree) / len(degree)\n",
    "\n",
    "def triangles(G):\n",
    "    return sum(nx.triangles(G).values()) / 3\n",
    "\n",
    "def gini(G):\n",
    "    x = list(dict(G.degree()).values())\n",
    "    mad = np.abs(np.subtract.outer(x, x)).mean()\n",
    "    rmad = mad/np.mean(x)\n",
    "    gini = 0.5 * rmad\n",
    "    return gini\n",
    "\n",
    "def louvain_communities(G):\n",
    "    return len(nx.community.louvain_communities(G))\n",
    "\n",
    "def components(G):\n",
    "    return len(list(nx.connected_components(G)))\n",
    "\n",
    "def centralization(G):\n",
    "    degree = dict(G.degree()).values()\n",
    "    return float((len(G) * max(degree) - sum(degree))) / (len(G)-1)**2\n",
    "\n",
    "measurments = {\n",
    "    # 'Nodes': nx.number_of_nodes,\n",
    "    # 'Edges': nx.number_of_edges,\n",
    "    'Density': nx.density,\n",
    "    'AvgDegree': avg_degree,\n",
    "    # 'DiameterLargestComponent': nx.diameter(G.subgraph(large_component)),\n",
    "    # 'AvgShortestPath': nx.average_shortest_path_length(G_large_component),\n",
    "    # 'ShortestPath': nx.shortest_path_length,\n",
    "    'Triangles': triangles,\n",
    "    # 'Gini': gini,\n",
    "    'Louvain': louvain_communities,\n",
    "    'Components': components,\n",
    "    'AvgClustering': nx.average_clustering,\n",
    "    'Transitivity': nx.transitivity,\n",
    "    'Centralization': centralization,\n",
    "    # 'Isolates': nx.number_of_isolates(G),\n",
    "    # 'Loops': nx.number_of_selfloops(G),\n",
    "    # 'LabelPropagation': len(nx_comm.label_propagation_communities(G)),\n",
    "}\n",
    "\n",
    "measurment_combs = list(itertools.combinations(measurments.keys(), 2))\n",
    "print(len(measurment_combs))\n",
    "print(list(measurments.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.reset_defaults()\n",
    "\n",
    "for i, (m1, m2) in enumerate(measurment_combs):\n",
    "\n",
    "    print(f'\\r{m1} - {m2}', flush=True, end=' ')\n",
    "\n",
    "    f1 = measurments[m1]\n",
    "    f2 = measurments[m2]\n",
    "\n",
    "    dict1 = {field_name: f1(G) for field_name, G in Gs.items() if field_name not in ['Gender Studies', 'Geometry', 'Ethnic & Cultural Studies']}\n",
    "    dict2 = {field_name: f2(G) for field_name, G in Gs.items() if field_name not in ['Gender Studies', 'Geometry', 'Ethnic & Cultural Studies']}\n",
    "\n",
    "    df1 = pl.DataFrame([\n",
    "        pl.Series('Field', list(dict1.keys()), pl.Utf8),\n",
    "        pl.Series(m1, list(dict1.values()), pl.Float32),\n",
    "    ])\n",
    "    df2 = pl.DataFrame([\n",
    "        pl.Series('Field', list(dict2.keys()), pl.Utf8),\n",
    "        pl.Series(m2, list(dict2.values()), pl.Float32),\n",
    "    ])\n",
    "\n",
    "    df = df1.join(df2, on='Field')\n",
    "\n",
    "    x_mean, y_mean, x_median, y_median = df.select(\n",
    "        pl.col(m1).mean().alias('x_mean'),\n",
    "        pl.col(m2).mean().alias('y_mean'),\n",
    "        pl.col(m1).median().alias('x_median'),\n",
    "        pl.col(m2).median().alias('y_median'),\n",
    "    ).row(0)\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    sns.scatterplot(data=df, x=m1, y=m2)\n",
    "\n",
    "    plt.axhline(y=y_mean, c='r') \n",
    "    plt.axvline(x=x_mean, c='r') \n",
    "\n",
    "    plt.axhline(y=y_median, c='b') \n",
    "    plt.axvline(x=x_median, c='b') \n",
    "\n",
    "    for field_name, x, y in df.rows():\n",
    "        field_name = format_field_name(field_name)\n",
    "        plt.text(x, y, field_name, horizontalalignment='left', size='medium', color='black', weight='semibold')\n",
    "\n",
    "    plt.savefig(\n",
    "        os.path.join(LATEX_FIGURES_PATH, 'all_bivariate', f'{m1}_{m2}.png'),\n",
    "        transparent=True, \n",
    "        dpi=150,\n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
