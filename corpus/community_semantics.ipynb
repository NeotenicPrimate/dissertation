{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run './model/multi_corpus.py'\n",
    "%run './constants.py'\n",
    "\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "from matplotlib import cm\n",
    "\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora = co_occurence_graphs(n_edges=100)\n",
    "Gs = {field_name: corpus['G'] for (field_name, corpus) in corpora.items()}\n",
    "Dfs = {field_name: corpus['Df'] for (field_name, corpus) in corpora.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import scipy\n",
    "\n",
    "G = Gs['Sociology']\n",
    "\n",
    "method = 'grivan_newman' # louvain, girvan_newman\n",
    "\n",
    "if method == 'louvain':\n",
    "    hier_comms = list(nx.community.louvain_partitions(G, weight='weight', resolution=1, threshold=1e-07, seed=None))\n",
    "    hier_comms.append([{node} for community in hier_comms[-1] for node in community])\n",
    "if method == 'grivan_newman':\n",
    "    hier_comms = list(nx.community.girvan_newman(G))\n",
    "\n",
    "print('Nodes: ', len(G))\n",
    "print('Levels: ', len(hier_comms)-1)\n",
    "\n",
    "nodes = set.union(*hier_comms[-1])\n",
    "ids = dict(zip(nodes, range(len(nodes))))\n",
    "\n",
    "M_dst = np.full((len(nodes), len(nodes)), len(hier_comms))\n",
    "\n",
    "dsts = []\n",
    "modularities = []\n",
    "for i, level in enumerate(hier_comms):\n",
    "    modularity = nx.community.modularity(G, level, weight='weight', resolution=1)\n",
    "    modularities.append(modularity)\n",
    "    dst = len(hier_comms) - i - 1\n",
    "    for cluster in level:\n",
    "        for u, v in itertools.combinations(cluster, 2):\n",
    "            M_dst[ids[u]][ids[v]] = dst\n",
    "            M_dst[ids[v]][ids[u]] = dst\n",
    "    dsts.append(dst)\n",
    "\n",
    "np.fill_diagonal(M_dst, 0)\n",
    "A_dst = scipy.spatial.distance.squareform(M_dst)\n",
    "M_linkage = scipy.cluster.hierarchy.linkage(A_dst)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(25, 15))\n",
    "scipy.cluster.hierarchy.dendrogram(M_linkage, labels=list(ids.keys()), leaf_rotation=90., leaf_font_size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(len(modularities))\n",
    "y = modularities\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(len(dsts))\n",
    "y = dsts\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = 'Sociology'\n",
    "\n",
    "G = Gs[field_name]\n",
    "df = Dfs[field_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from community import community_louvain\n",
    "from itertools import combinations\n",
    "\n",
    "def merge_communities(graph):\n",
    "    # Identify the Louvain communities\n",
    "    # partition = community_louvain.best_partition(graph)\n",
    "    partition = {}\n",
    "    for i, community in enumerate(nx.community.louvain_communities(G)):\n",
    "        for node in community:\n",
    "            partition[node] = i\n",
    "\n",
    "    # Create a dictionary of communities to nodes\n",
    "    communities = {}\n",
    "    for node, community in partition.items():\n",
    "        if community not in communities:\n",
    "            communities[community] = []\n",
    "        communities[community].append(node)\n",
    "\n",
    "    # Create a new graph to hold the super-nodes\n",
    "    super_graph = nx.Graph()\n",
    "\n",
    "    # Iterate over each community\n",
    "    for community, nodes in communities.items():\n",
    "        # Create a super-node in the new graph\n",
    "        super_graph.add_node(community, size=len(nodes))\n",
    "\n",
    "        # Calculate the total weight of the edges within the community\n",
    "        total_weight = sum(graph[u][v]['weight'] for u, v in combinations(nodes, 2) if graph.has_edge(u, v))\n",
    "\n",
    "        # Create a self-loop edge on the super-node with the total weight\n",
    "        super_graph.add_edge(community, community, weight=total_weight)\n",
    "\n",
    "    # Iterate over each pair of communities\n",
    "    for community1, community2 in combinations(communities.keys(), 2):\n",
    "        # Calculate the total weight of the edges between the communities\n",
    "        total_weight = sum(graph[u][v]['weight'] for u in communities[community1] for v in communities[community2] if graph.has_edge(u, v))\n",
    "\n",
    "        # Create an edge between the super-nodes with the total weight\n",
    "        if total_weight > 0:\n",
    "            super_graph.add_edge(community1, community2, weight=total_weight)\n",
    "\n",
    "    return super_graph, partition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_merged, partition = merge_communities(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_sizes = {n: d['size'] * 50 for n, d in G_merged.nodes(data=True)}\n",
    "nodelist = list(node_sizes.keys())\n",
    "node_size = list(node_sizes.values())\n",
    "\n",
    "edge_sizes = {(u, v): d['weight'] * 50 for u, v, d in G_merged.edges(data=True)}\n",
    "edgelist = list(edge_sizes.keys())\n",
    "edge_size = list(edge_sizes.values())\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(15, 15))\n",
    "\n",
    "pos = nx.nx_agraph.graphviz_layout(G_merged, prog='sfdp') # dot, twopi, fdp, sfdp, circo\n",
    "\n",
    "nx.draw_networkx_nodes(\n",
    "    G_merged, \n",
    "    pos,\n",
    "    nodelist=nodelist,\n",
    "    node_size=node_size,\n",
    "    # node_color='#00ABB3',\n",
    "    # node_color=node_color,\n",
    "    node_shape='o',\n",
    "    alpha=None,\n",
    "    cmap=plt.cm.Blues,\n",
    "    ax=ax,\n",
    "    linewidths=1.0,\n",
    "    edgecolors='k',\n",
    ").set_zorder(1)\n",
    "\n",
    "nx.draw_networkx_labels(G_merged, pos=pos, ax=ax, labels=dict(zip(nodelist, nodelist)))\n",
    "\n",
    "nx.draw_networkx_edges(\n",
    "    G_merged, \n",
    "    pos,\n",
    "    width=1.0,\n",
    "    edge_color='k',\n",
    "    style='solid',\n",
    "    alpha=0.5,\n",
    "    arrowsize=10,\n",
    "    ax=ax,\n",
    "    nodelist=nodelist,\n",
    "    node_size=node_size,\n",
    "    node_shape='o',\n",
    "    connectionstyle='arc3',\n",
    "    # width=width,\n",
    ").set_zorder(-1)\n",
    "\n",
    "ax.grid(False)\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig(\n",
    "#     os.path.join(LATEX_FIGURES_PATH, 'co_occurrence_graphs', f'{field_name.capitalize()}.png'), \n",
    "#     transparent=True, \n",
    "#     dpi=150 \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define parameters\n",
    "sizes = [25, 25, 25]\n",
    "p_matrix = [\n",
    "    [0.5, 0.1, 0.01], \n",
    "    [0.1, 0.5, 0.01],\n",
    "    [0.01, 0.01, 0.5],\n",
    "]\n",
    "\n",
    "# Create a stochastic block model\n",
    "G = nx.stochastic_block_model(sizes, p_matrix, seed=0)\n",
    "nx.write_weighted_edgelist(G, './link_clustering/weighted_edgelist.edgelist', delimiter='\\t')\n",
    "\n",
    "# Use the Louvain method for community detection\n",
    "communities = nx.community.louvain_communities(G)\n",
    "communities = {n: i for i, comm in enumerate(communities) for n in comm}\n",
    "\n",
    "# Get the number of communities\n",
    "num_communities = len(set(communities.values()))\n",
    "cmap = cm.get_cmap('plasma', num_communities)\n",
    "color_map = [cmap(communities[node]) for node in G]\n",
    "\n",
    "pos = nx.spring_layout(G)\n",
    "print(pos)\n",
    "# KDE\n",
    "pos_array = defaultdict(list)\n",
    "for n, coord in pos.items():\n",
    "    if n == 25:\n",
    "        pos_array[0].append(coord)    \n",
    "    pos_array[communities[n]].append(coord)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos=pos, node_color=color_map, alpha=0.9, edgecolors='k')\n",
    "nx.draw_networkx_edges(G, pos=pos, alpha=0.1)\n",
    "nx.draw_networkx_labels(G, pos=pos)\n",
    "\n",
    "for comm, arr in pos_array.items():\n",
    "    \n",
    "    df = pd.DataFrame(arr)\n",
    "    df.columns = ['x', 'y']\n",
    "\n",
    "    sns.kdeplot(data=df, x=\"x\", y=\"y\", levels=5, thresh=0.1, color=cmap(comm)) # , fill=True\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comm = (\n",
    "    pl.DataFrame([\n",
    "        pl.Series('Doi', list(comms_dict.keys())),\n",
    "        pl.Series('Community', list(comms_dict.values())),\n",
    "    ])\n",
    "    .join(df, on='Doi', how='left')\n",
    "    .select(\n",
    "        pl.col('Doi'), \n",
    "        pl.col('Community'), \n",
    "        pl.col('Text'),\n",
    "    )\n",
    "    .groupby('Community')\n",
    "    .agg(\n",
    "        pl.col('Doi'), \n",
    "        pl.col('Text')\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col('Text')\n",
    "        .arr.eval(pl.element().explode())\n",
    "    )\n",
    "    .sort(pl.col('Doi').arr.lengths(), descending=True)\n",
    ")\n",
    "df_comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [\n",
    "    ({0, 1, 6, 2, 3, 4},),\n",
    "    ({0, 1, 6}, {2, 3, 4}),\n",
    "    ({0, 1, 6}, {2, 3}, {4}),\n",
    "    ({0}, {1}, {6}, {2}, {3}, {4}),\n",
    "]\n",
    "\n",
    "clusters = [tuple([frozenset(cluster) for cluster in level]) for level in clusters]\n",
    "\n",
    "root = clusters[0][0]\n",
    "n_levels = len(clusters)\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "for i in range(len(clusters)-1):\n",
    "    for parent in clusters[i]:\n",
    "        for child in clusters[i+1]:\n",
    "            if set(child).issubset(set(parent)):\n",
    "                if child != parent:\n",
    "                    G.add_edge(parent, child)\n",
    "                    G[parent][child]['weight'] = n_levels - (len(nx.shortest_path(G, root, child)) - 1)\n",
    "\n",
    "\n",
    "pos = nx.nx_agraph.graphviz_layout(G, prog=\"dot\")\n",
    "nx.draw(G, with_labels=True, pos=pos)\n",
    "\n",
    "edge_labels = {(u, v): d['weight'] for u, v, d in G.edges(data=True)}\n",
    "\n",
    "nx.draw_networkx_edge_labels(\n",
    "    G, pos,\n",
    "    edge_labels=edge_labels,\n",
    "    font_color='k'\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_dst = [\n",
    "    # 0  1  2  3  4  6\n",
    "    [ 0, 1, 3, 3, 3, 1], # 0\n",
    "    [ 1, 0, 3, 3, 3, 1], # 1\n",
    "    \n",
    "    [ 3, 3, 0, 1, 2, 3], # 2\n",
    "    [ 3, 3, 1, 0, 2, 3], # 3\n",
    "\n",
    "    [ 3, 3, 2, 2, 0, 3], # 4\n",
    "\n",
    "    [ 1, 1, 3, 3, 3, 0], # 6\n",
    "]\n",
    "\n",
    "A_dst = scipy.spatial.distance.squareform(M_dst)\n",
    "\n",
    "M_linkage = scipy.cluster.hierarchy.linkage(A_dst)\n",
    "\n",
    "scipy.cluster.hierarchy.dendrogram(M_linkage)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.reset_defaults()\n",
    "cmap = cm.plasma\n",
    "\n",
    "node_size = 50\n",
    "\n",
    "# pos = nx.nx_agraph.graphviz_layout(Gc, prog=\"twopi\") # dot, twopi, fdp, sfdp, circo\n",
    "pos = nx.multipartite_layout(Gc, subset_key=\"layer\", align=\"horizontal\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "nodes = nx.draw_networkx_nodes(\n",
    "    Gc, \n",
    "    pos, \n",
    "    # nodelist=nodes_with_term,\n",
    "    node_size=node_size,\n",
    "    node_color='red',\n",
    "    node_shape='o',\n",
    "    alpha=None,\n",
    "    # cmap=cmap,\n",
    "    vmin=None,\n",
    "    vmax=None,\n",
    "    ax=None,\n",
    "    linewidths=1.0, \n",
    "    edgecolors='k', \n",
    "    # label=None, \n",
    "    margins=None\n",
    ")\n",
    "nodes.set_zorder(1)\n",
    "\n",
    "edges = nx.draw_networkx_edges(\n",
    "    Gc, \n",
    "    pos,\n",
    "    edgelist=None,\n",
    "    width=1.0,\n",
    "    edge_color='k',\n",
    "    style='solid',\n",
    "    alpha=0.5,\n",
    "    arrowstyle=None,\n",
    "    arrowsize=10,\n",
    "    edge_cmap=None,\n",
    "    edge_vmin=None,\n",
    "    edge_vmax=None,\n",
    "    ax=None,\n",
    "    arrows=None,\n",
    "    label=None,\n",
    "    node_size=node_size,\n",
    "    nodelist=None,\n",
    "    node_shape='o',\n",
    "    connectionstyle='arc3',\n",
    "    min_source_margin=0,\n",
    "    min_target_margin=0,\n",
    ")\n",
    "\n",
    "for c in edges:\n",
    "    c.set_zorder(-1)\n",
    "# edges.set_zorder(-1)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.grid(False)\n",
    "plt.box(False)\n",
    "\n",
    "# root = root.replace('/', '-')\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig(\n",
    "#     os.path.join(LATEX_FIGURES_PATH, 'genealogy_trees', f'{root}.png'), \n",
    "#     transparent=True, \n",
    "#     dpi=300,\n",
    "#     bbox_inches='tight',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_leaves = dict(\n",
    "    pl.read_parquet(f'./output/main_dfs/{field_name}.parquet')\n",
    "    .select(\n",
    "        pl.col('Doi'), \n",
    "        pl.concat_str([\n",
    "            pl.lit('('),\n",
    "            pl.col('Authors').arr.first().str.split(', ').arr.first(),\n",
    "            pl.lit(', '),\n",
    "            pl.col('Date').dt.year(),\n",
    "            pl.lit(')')\n",
    "        ])\n",
    "    )\n",
    "    .filter(pl.col('Doi').is_in(leaves))\n",
    "    .to_numpy()\n",
    ")\n",
    "\n",
    "leaves = dict(zip(leaves, leaves))\n",
    "leaves.update(new_leaves)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 18))\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "# ax.set_xlabel('Node')\n",
    "ax.set_ylabel('Distance')\n",
    "\n",
    "dendrogram(Z, labels=list(leaves.values()), ax=ax)\n",
    "ax.yaxis.grid(False)\n",
    "ax.xaxis.grid(False)\n",
    "\n",
    "# fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.number_connected_components(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nx.to_numpy_array(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = linkage(m, method='ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dn = dendrogram(Z, labels=G.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Gs['Sociology']\n",
    "print(G)\n",
    "print(nx.number_connected_components(G))\n",
    "nodes = list(G.nodes)\n",
    "\n",
    "comms = nx.community.louvain_communities(G)\n",
    "print(len(comms))\n",
    "\n",
    "df = Dfs['Sociology']\n",
    "df = df.select(pl.col('Doi'), pl.col('Text'), pl.col('References'))\n",
    "\n",
    "labelled_comms = {}\n",
    "for i, comm in enumerate(comms):\n",
    "    labelled_comms.update(dict.fromkeys(comm, i))\n",
    "\n",
    "df_comms = pl.from_dict({\n",
    "    'Doi': labelled_comms.keys(),\n",
    "    'Community': labelled_comms.values(),\n",
    "})\n",
    "\n",
    "df_comms = df_comms.join(df, on='Doi', how='left')\n",
    "\n",
    "df_comms = df_comms.with_columns(pl.col('Text').arr.eval(pl.element().unique()))\n",
    "\n",
    "df_comms = (\n",
    "    df_comms\n",
    "    .explode('References')\n",
    "    .join(\n",
    "        df_comms.select(pl.col('Doi'), pl.col('Community')),\n",
    "        right_on='Doi',\n",
    "        left_on='References',\n",
    "        how='left',\n",
    "        suffix='Reference'\n",
    "    )\n",
    ")\n",
    "\n",
    "nx.set_node_attributes(G, labelled_comms, 'Community')\n",
    "\n",
    "df_comms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core = (\n",
    "    df_comms\n",
    "    .groupby('References')\n",
    "    .agg(\n",
    "        pl.col('Doi'),\n",
    "        pl.col('Community'),\n",
    "    )\n",
    "    .filter(pl.col('Community').arr.unique().arr.lengths().eq(1))\n",
    "    .select(\n",
    "        pl.col('References'),\n",
    "        pl.lit(True).alias('Core'),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dois, cores = (\n",
    "    df\n",
    "    .join(df_core, left_on='Doi', right_on='References', how='left')\n",
    "    .fill_null(False)\n",
    "    .select(\n",
    "        pl.col('Doi'),\n",
    "        pl.col('Core'),\n",
    "    )\n",
    ")\n",
    "\n",
    "core_attrs = dict(\n",
    "    zip(\n",
    "        dois.to_list(),\n",
    "        cores.to_list(),\n",
    "    )\n",
    ")\n",
    "\n",
    "nx.set_node_attributes(G, core_attrs, 'Core')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_comms\n",
    "    .select(\n",
    "        pl.col('Doi'),\n",
    "        pl.col('Community'),\n",
    "        pl.col('CommunityReference'),\n",
    "    )\n",
    "    .groupby(pl.col('Doi'))\n",
    "    .agg(pl.all())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_node_attributes(G, labelled_comms, 'Community')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_comms\n",
    "    .explode('Text')\n",
    "    .groupby('Text')\n",
    "    .agg(pl.col('Community'))\n",
    "    .filter(pl.col('Community').arr.lengths().eq(1))\n",
    "    .with_columns(pl.col('Community').arr.first())\n",
    "    .groupby('Community')\n",
    "    .agg(pl.col('Text'))\n",
    "    # .unique(subset=['Community', 'Text'])\n",
    "    # .groupby('Community')\n",
    "    # .agg(pl.col('Text'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
